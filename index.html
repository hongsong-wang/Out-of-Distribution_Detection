<!DOCTYPE html>
<html>
<head>
<title>Paper collected by Wang</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">


/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

span#pid {
  color:red;
  
}
span#filename{
  font-style: oblique;
}

span#title{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: italic;
  font-size: 20px;
  border:1px solid #B50;
}
span#abs{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: oblique;
  font-size: 18px;
}
</style>
</head>
<body>

</p></br></br><div id='section'>Paperid: <span id='pid'>1, <a href='https://arxiv.org/pdf/2512.23427.pdf' target='_blank'>https://arxiv.org/pdf/2512.23427.pdf</a></span>   <span><a href='https://github.com/JesseBrouw/UncertSAM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jesse Brouwers, Xiaoyan Xing, Alexander Timans
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.23427">Towards Integrating Uncertainty for Domain-Agnostic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models for segmentation such as the Segment Anything Model (SAM) family exhibit strong zero-shot performance, but remain vulnerable in shifted or limited-knowledge domains. This work investigates whether uncertainty quantification can mitigate such challenges and enhance model generalisability in a domain-agnostic manner. To this end, we (1) curate UncertSAM, a benchmark comprising eight datasets designed to stress-test SAM under challenging segmentation conditions including shadows, transparency, and camouflage; (2) evaluate a suite of lightweight, post-hoc uncertainty estimation methods; and (3) assess a preliminary uncertainty-guided prediction refinement step. Among evaluated approaches, a last-layer Laplace approximation yields uncertainty estimates that correlate well with segmentation errors, indicating a meaningful signal. While refinement benefits are preliminary, our findings underscore the potential of incorporating uncertainty into segmentation models to support robust, domain-agnostic performance. Our benchmark and code are made publicly available.
<div id='section'>Paperid: <span id='pid'>2, <a href='https://arxiv.org/pdf/2512.18978.pdf' target='_blank'>https://arxiv.org/pdf/2512.18978.pdf</a></span>   <span><a href='https://github.com/ChenBaiyang/FROD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Baiyang Chen, Zhong Yuan, Zheng Liu, Dezhong Peng, Yongxiang Li, Chang Liu, Guiduo Duan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.18978">Outlier detection in mixed-attribute data: a semi-supervised approach with fuzzy approximations and relative entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection is a critical task in data mining, aimed at identifying objects that significantly deviate from the norm. Semi-supervised methods improve detection performance by leveraging partially labeled data but typically overlook the uncertainty and heterogeneity of real-world mixed-attribute data. This paper introduces a semi-supervised outlier detection method, namely fuzzy rough sets-based outlier detection (FROD), to effectively handle these challenges. Specifically, we first utilize a small subset of labeled data to construct fuzzy decision systems, through which we introduce the attribute classification accuracy based on fuzzy approximations to evaluate the contribution of attribute sets in outlier detection. Unlabeled data is then used to compute fuzzy relative entropy, which provides a characterization of outliers from the perspective of uncertainty. Finally, we develop the detection algorithm by combining attribute classification accuracy with fuzzy relative entropy. Experimental results on 16 public datasets show that FROD is comparable with or better than leading detection algorithms. All datasets and source codes are accessible at https://github.com/ChenBaiyang/FROD. This manuscript is the accepted author version of a paper published by Elsevier. The final published version is available at https://doi.org/10.1016/j.ijar.2025.109373
<div id='section'>Paperid: <span id='pid'>3, <a href='https://arxiv.org/pdf/2512.07847.pdf' target='_blank'>https://arxiv.org/pdf/2512.07847.pdf</a></span>   <span><a href='https://github.com/Mohamedelrefaie/CarBench' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Elrefaie, Dule Shu, Matt Klenk, Faez Ahmed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.07847">CarBench: A Comprehensive Benchmark for Neural Surrogates on High-Fidelity 3D Car Aerodynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Benchmarking has been the cornerstone of progress in computer vision, natural language processing, and the broader deep learning domain, driving algorithmic innovation through standardized datasets and reproducible evaluation protocols. The growing availability of large-scale Computational Fluid Dynamics (CFD) datasets has opened new opportunities for applying machine learning to aerodynamic and engineering design. Yet, despite this progress, there exists no standardized benchmark for large-scale numerical simulations in engineering design. In this work, we introduce CarBench, the first comprehensive benchmark dedicated to large-scale 3D car aerodynamics, performing a large-scale evaluation of state-of-the-art models on DrivAerNet++, the largest public dataset for automotive aerodynamics, containing over 8,000 high-fidelity car simulations. We assess eleven architectures spanning neural operator methods (e.g., Fourier Neural Operator), geometric deep learning (PointNet, RegDGCNN, PointMAE, PointTransformer), transformer-based neural solvers (Transolver, Transolver++, AB-UPT), and implicit field networks (TripNet). Beyond standard interpolation tasks, we perform cross-category experiments in which transformer-based solvers trained on a single car archetype are evaluated on unseen categories. Our analysis covers predictive accuracy, physical consistency, computational efficiency, and statistical uncertainty. To accelerate progress in data-driven engineering, we open-source the benchmark framework, including training pipelines, uncertainty estimation routines based on bootstrap resampling, and pretrained model weights, establishing the first reproducible foundation for large-scale learning from high-fidelity CFD simulations, available at https://github.com/Mohamedelrefaie/CarBench.
<div id='section'>Paperid: <span id='pid'>4, <a href='https://arxiv.org/pdf/2512.07130.pdf' target='_blank'>https://arxiv.org/pdf/2512.07130.pdf</a></span>   <span><a href='https://github.com/ZebinX/Mimir-Uncertainty-Driving' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zebin Xing, Yupeng Zheng, Qichao Zhang, Zhixing Ding, Pengxuan Yang, Songen Gu, Zhongpu Xia, Dongbin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.07130">Mimir: Hierarchical Goal-Driven Diffusion with Uncertainty Propagation for End-to-End Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>End-to-end autonomous driving has emerged as a pivotal direction in the field of autonomous systems. Recent works have demonstrated impressive performance by incorporating high-level guidance signals to steer low-level trajectory planners. However, their potential is often constrained by inaccurate high-level guidance and the computational overhead of complex guidance modules. To address these limitations, we propose Mimir, a novel hierarchical dual-system framework capable of generating robust trajectories relying on goal points with uncertainty estimation: (1) Unlike previous approaches that deterministically model, we estimate goal point uncertainty with a Laplace distribution to enhance robustness; (2) To overcome the slow inference speed of the guidance system, we introduce a multi-rate guidance mechanism that predicts extended goal points in advance. Validated on challenging Navhard and Navtest benchmarks, Mimir surpasses previous state-of-the-art methods with a 20% improvement in the driving score EPDMS, while achieving 1.6 times improvement in high-level module inference speed without compromising accuracy. The code and models will be released soon to promote reproducibility and further development. The code is available at https://github.com/ZebinX/Mimir-Uncertainty-Driving
<div id='section'>Paperid: <span id='pid'>5, <a href='https://arxiv.org/pdf/2512.05482.pdf' target='_blank'>https://arxiv.org/pdf/2512.05482.pdf</a></span>   <span><a href='https://github.com/mm1129/concept_based_rare_detector_2025' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mai Tsujimoto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.05482">Concept-based Explainable Data Mining with VLM for 3D Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rare-object detection remains a challenging task in autonomous driving systems, particularly when relying solely on point cloud data. Although Vision-Language Models (VLMs) exhibit strong capabilities in image understanding, their potential to enhance 3D object detection through intelligent data mining has not been fully explored. This paper proposes a novel cross-modal framework that leverages 2D VLMs to identify and mine rare objects from driving scenes, thereby improving 3D object detection performance. Our approach synthesizes complementary techniques such as object detection, semantic feature extraction, dimensionality reduction, and multi-faceted outlier detection into a cohesive, explainable pipeline that systematically identifies rare but critical objects in driving scenes. By combining Isolation Forest and t-SNE-based outlier detection methods with concept-based filtering, the framework effectively identifies semantically meaningful rare objects. A key strength of this approach lies in its ability to extract and annotate targeted rare object concepts such as construction vehicles, motorcycles, and barriers. This substantially reduces the annotation burden and focuses only on the most valuable training samples. Experiments on the nuScenes dataset demonstrate that this concept-guided data mining strategy enhances the performance of 3D object detection models while utilizing only a fraction of the training data, with particularly notable improvements for challenging object categories such as trailers and bicycles compared with the same amount of random data. This finding has substantial implications for the efficient curation of datasets in safety-critical autonomous systems.
<div id='section'>Paperid: <span id='pid'>6, <a href='https://arxiv.org/pdf/2512.05131.pdf' target='_blank'>https://arxiv.org/pdf/2512.05131.pdf</a></span>   <span><a href='https://github.com/TianlingXu/AREA3D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianling Xu, Shengzhe Gan, Leslie Gu, Yuelei Li, Fangneng Zhan, Hanspeter Pfister
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.05131">AREA3D: Active Reconstruction Agent with Unified Feed-Forward 3D Perception and Vision-Language Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active 3D reconstruction enables an agent to autonomously select viewpoints to efficiently obtain accurate and complete scene geometry, rather than passively reconstructing scenes from pre-collected images. However, existing active reconstruction methods often rely on hand-crafted geometric heuristics, which can lead to redundant observations without substantially improving reconstruction quality. To address this limitation, we propose AREA3D, an active reconstruction agent that leverages feed-forward 3D reconstruction models and vision-language guidance. Our framework decouples view-uncertainty modeling from the underlying feed-forward reconstructor, enabling precise uncertainty estimation without expensive online optimization. In addition, an integrated vision-language model provides high-level semantic guidance, encouraging informative and diverse viewpoints beyond purely geometric cues. Extensive experiments on both scene-level and object-level benchmarks demonstrate that AREA3D achieves state-of-the-art reconstruction accuracy, particularly in the sparse-view regime. Code will be made available at: https://github.com/TianlingXu/AREA3D .
<div id='section'>Paperid: <span id='pid'>7, <a href='https://arxiv.org/pdf/2512.00953.pdf' target='_blank'>https://arxiv.org/pdf/2512.00953.pdf</a></span>   <span><a href='https://github.com/KaijingOfficial/DEMR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haojian Huang, Kaijing Ma, Jin Chen, Haodong Chen, Zhou Wu, Xianghao Zang, Han Fang, Chao Ban, Hao Sun, Mulin Chen, Zhongjiang He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.00953">Adaptive Evidential Learning for Temporal-Semantic Robustness in Moment Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the domain of moment retrieval, accurately identifying temporal segments within videos based on natural language queries remains challenging. Traditional methods often employ pre-trained models that struggle with fine-grained information and deterministic reasoning, leading to difficulties in aligning with complex or ambiguous moments. To overcome these limitations, we explore Deep Evidential Regression (DER) to construct a vanilla Evidential baseline. However, this approach encounters two major issues: the inability to effectively handle modality imbalance and the structural differences in DER's heuristic uncertainty regularizer, which adversely affect uncertainty estimation. This misalignment results in high uncertainty being incorrectly associated with accurate samples rather than challenging ones. Our observations indicate that existing methods lack the adaptability required for complex video scenarios. In response, we propose Debiased Evidential Learning for Moment Retrieval (DEMR), a novel framework that incorporates a Reflective Flipped Fusion (RFF) block for cross-modal alignment and a query reconstruction task to enhance text sensitivity, thereby reducing bias in uncertainty estimation. Additionally, we introduce a Geom-regularizer to refine uncertainty predictions, enabling adaptive alignment with difficult moments and improving retrieval accuracy. Extensive testing on standard datasets and debiased datasets ActivityNet-CD and Charades-CD demonstrates significant enhancements in effectiveness, robustness, and interpretability, positioning our approach as a promising solution for temporal-semantic robustness in moment retrieval. The code is publicly available at https://github.com/KaijingOfficial/DEMR.
<div id='section'>Paperid: <span id='pid'>8, <a href='https://arxiv.org/pdf/2511.22019.pdf' target='_blank'>https://arxiv.org/pdf/2511.22019.pdf</a></span>   <span><a href='https://github.com/zhenxianglin/ICPE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenxiang Lin, Maryam Haghighat, Will Browne, Dimity Miller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.22019">Intra-Class Probabilistic Embeddings for Uncertainty Estimation in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs), such as CLIP, have gained popularity for their strong open vocabulary classification performance, but they are prone to assigning high confidence scores to misclassifications, limiting their reliability in safety-critical applications. We introduce a training-free, post-hoc uncertainty estimation method for contrastive VLMs that can be used to detect erroneous predictions. The key to our approach is to measure visual feature consistency within a class, using feature projection combined with multivariate Gaussians to create class-specific probabilistic embeddings. Our method is VLM-agnostic, requires no fine-tuning, demonstrates robustness to distribution shift, and works effectively with as few as 10 training images per class. Extensive experiments on ImageNet, Flowers102, Food101, EuroSAT and DTD show state-of-the-art error detection performance, significantly outperforming both deterministic and probabilistic VLM baselines. Code is available at https://github.com/zhenxianglin/ICPE.
<div id='section'>Paperid: <span id='pid'>9, <a href='https://arxiv.org/pdf/2511.21666.pdf' target='_blank'>https://arxiv.org/pdf/2511.21666.pdf</a></span>   <span><a href='https://github.com/MIT-SPARK/PoseUncertaintySets' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/MIT-SPARK/PoseUncertaintySets' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lorenzo Shaikewitz, Charis Georgiou, Luca Carlone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.21666">Uncertainty Quantification for Visual Object Pose Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantifying the uncertainty of an object's pose estimate is essential for robust control and planning. Although pose estimation is a well-studied robotics problem, attaching statistically rigorous uncertainty is not well understood without strict distributional assumptions. We develop distribution-free pose uncertainty bounds about a given pose estimate in the monocular setting. Our pose uncertainty only requires high probability noise bounds on pixel detections of 2D semantic keypoints on a known object. This noise model induces an implicit, non-convex set of pose uncertainty constraints. Our key contribution is SLUE (S-Lemma Uncertainty Estimation), a convex program to reduce this set to a single ellipsoidal uncertainty bound that is guaranteed to contain the true object pose with high probability. SLUE solves a relaxation of the minimum volume bounding ellipsoid problem inspired by the celebrated S-lemma. It requires no initial guess of the bound's shape or size and is guaranteed to contain the true object pose with high probability. For tighter uncertainty bounds at the same confidence, we extend SLUE to a sum-of-squares relaxation hierarchy which is guaranteed to converge to the minimum volume ellipsoidal uncertainty bound for a given set of keypoint constraints. We show this pose uncertainty bound can easily be projected to independent translation and axis-angle orientation bounds. We evaluate SLUE on two pose estimation datasets and a real-world drone tracking scenario. Compared to prior work, SLUE generates substantially smaller translation bounds and competitive orientation bounds. We release code at https://github.com/MIT-SPARK/PoseUncertaintySets.
<div id='section'>Paperid: <span id='pid'>10, <a href='https://arxiv.org/pdf/2511.21624.pdf' target='_blank'>https://arxiv.org/pdf/2511.21624.pdf</a></span>   <span><a href='https://github.com/kayzliu/tagfn' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kay Liu, Yuwei Han, Haoyan Xu, Henry Peng Zou, Yue Zhao, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.21624">TAGFN: A Text-Attributed Graph Dataset for Fake News Detection in the Age of LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have recently revolutionized machine learning on text-attributed graphs, but the application of LLMs to graph outlier detection, particularly in the context of fake news detection, remains significantly underexplored. One of the key challenges is the scarcity of large-scale, realistic, and well-annotated datasets that can serve as reliable benchmarks for outlier detection. To bridge this gap, we introduce TAGFN, a large-scale, real-world text-attributed graph dataset for outlier detection, specifically fake news detection. TAGFN enables rigorous evaluation of both traditional and LLM-based graph outlier detection methods. Furthermore, it facilitates the development of misinformation detection capabilities in LLMs through fine-tuning. We anticipate that TAGFN will be a valuable resource for the community, fostering progress in robust graph-based outlier detection and trustworthy AI. The dataset is publicly available at https://huggingface.co/datasets/kayzliu/TAGFN and our code is available at https://github.com/kayzliu/tagfn.
<div id='section'>Paperid: <span id='pid'>11, <a href='https://arxiv.org/pdf/2511.20457.pdf' target='_blank'>https://arxiv.org/pdf/2511.20457.pdf</a></span>   <span><a href='https://github.com/afrakilic/BTN_Volterra_Sys_ID' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Afra Kilic, Kim Batselier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.20457">A Fully Probabilistic Tensor Network for Regularized Volterra System Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling nonlinear systems with Volterra series is challenging because the number of kernel coefficients grows exponentially with the model order. This work introduces Bayesian Tensor Network Volterra kernel machines (BTN-V), extending the Bayesian Tensor Network framework to Volterra system identification. BTN-V represents Volterra kernels using canonical polyadic decomposition, reducing model complexity from O(I^D) to O(DIR). By treating all tensor components and hyperparameters as random variables, BTN-V provides predictive uncertainty estimation at no additional computational cost. Sparsity-inducing hierarchical priors enable automatic rank determination and the learning of fading-memory behavior directly from data, improving interpretability and preventing overfitting. Empirical results demonstrate competitive accuracy, enhanced uncertainty quantification, and reduced computational cost.
<div id='section'>Paperid: <span id='pid'>12, <a href='https://arxiv.org/pdf/2511.18816.pdf' target='_blank'>https://arxiv.org/pdf/2511.18816.pdf</a></span>   <span><a href='https://github.com/hdnugit/SupLID' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nimeshika Udayangani, Sarah Erfani, Christopher Leckie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.18816">SupLID: Geometrical Guidance for Out-of-Distribution Detection in Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection in semantic segmentation aims to localize anomalous regions at the pixel level, advancing beyond traditional image-level OOD techniques to better suit real-world applications such as autonomous driving. Recent literature has successfully explored the adaptation of commonly used image-level OOD methods--primarily based on classifier-derived confidence scores (e.g., energy or entropy)--for this pixel-precise task. However, these methods inherit a set of limitations, including vulnerability to overconfidence. In this work, we introduce SupLID, a novel framework that effectively guides classifier-derived OOD scores by exploiting the geometrical structure of the underlying semantic space, particularly using Linear Intrinsic Dimensionality (LID). While LID effectively characterizes the local structure of high-dimensional data by analyzing distance distributions, its direct application at the pixel level remains challenging. To overcome this, SupLID constructs a geometrical coreset that captures the intrinsic structure of the in-distribution (ID) subspace. It then computes OOD scores at the superpixel level, enabling both efficient real-time inference and improved spatial smoothness. We demonstrate that geometrical cues derived from SupLID serve as a complementary signal to traditional classifier confidence, enhancing the model's ability to detect diverse OOD scenarios. Designed as a post-hoc scoring method, SupLID can be seamlessly integrated with any semantic segmentation classifier at deployment time. Our results demonstrate that SupLID significantly enhances existing classifier-based OOD scores, achieving state-of-the-art performance across key evaluation metrics, including AUR, FPR, and AUP. Code is available at https://github.com/hdnugit/SupLID.
<div id='section'>Paperid: <span id='pid'>13, <a href='https://arxiv.org/pdf/2511.14907.pdf' target='_blank'>https://arxiv.org/pdf/2511.14907.pdf</a></span>   <span><a href='https://github.com/Luoxd1996/nnMIL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangde Luo, Jinxi Xiang, Yuanfeng Ji, Ruijiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.14907">nnMIL: A generalizable multiple instance learning framework for computational pathology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational pathology holds substantial promise for improving diagnosis and guiding treatment decisions. Recent pathology foundation models enable the extraction of rich patch-level representations from large-scale whole-slide images (WSIs), but current approaches for aggregating these features into slide-level predictions remain constrained by design limitations that hinder generalizability and reliability. Here, we developed nnMIL, a simple yet broadly applicable multiple-instance learning framework that connects patch-level foundation models to robust slide-level clinical inference. nnMIL introduces random sampling at both the patch and feature levels, enabling large-batch optimization, task-aware sampling strategies, and efficient and scalable training across datasets and model architectures. A lightweight aggregator performs sliding-window inference to generate ensemble slide-level predictions and supports principled uncertainty estimation. Across 40,000 WSIs encompassing 35 clinical tasks and four pathology foundation models, nnMIL consistently outperformed existing MIL methods for disease diagnosis, histologic subtyping, molecular biomarker detection, and pan- cancer prognosis prediction. It further demonstrated strong cross-model generalization, reliable uncertainty quantification, and robust survival stratification in multiple external cohorts. In conclusion, nnMIL offers a practical and generalizable solution for translating pathology foundation models into clinically meaningful predictions, advancing the development and deployment of reliable AI systems in real-world settings.
<div id='section'>Paperid: <span id='pid'>14, <a href='https://arxiv.org/pdf/2511.14276.pdf' target='_blank'>https://arxiv.org/pdf/2511.14276.pdf</a></span>   <span><a href='https://github.com/ContactSoftwareAI/TabEmbedBench' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Frederik Hoppe, Lars Kleinemeier, Astrid Franz, Udo Göbel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.14276">Comparing Task-Agnostic Embedding Models for Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent foundation models for tabular data achieve strong task-specific performance via in-context learning. Nevertheless, they focus on direct prediction by encapsulating both representation learning and task-specific inference inside a single, resource-intensive network. This work specifically focuses on representation learning, i.e., on transferable, task-agnostic embeddings. We systematically evaluate task-agnostic representations from tabular foundation models (TabPFN and TabICL) alongside with classical feature engineering (TableVectorizer) across a variety of application tasks as outlier detection (ADBench) and supervised learning (TabArena Lite). We find that simple TableVectorizer features achieve comparable or superior performance while being up to three orders of magnitude faster than tabular foundation models. The code is available at https://github.com/ContactSoftwareAI/TabEmbedBench.
<div id='section'>Paperid: <span id='pid'>15, <a href='https://arxiv.org/pdf/2511.10561.pdf' target='_blank'>https://arxiv.org/pdf/2511.10561.pdf</a></span>   <span><a href='https://github.com/dskoda/quests' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Benjamin Yu, Vincenzo Lordi, Daniel Schwalbe-Koda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.10561">Maximizing Efficiency of Dataset Compression for Machine Learning Potentials With Information Theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning interatomic potentials (MLIPs) balance high accuracy and lower costs compared to density functional theory calculations, but their performance often depends on the size and diversity of training datasets. Large datasets improve model accuracy and generalization but are computationally expensive to produce and train on, while smaller datasets risk discarding rare but important atomic environments and compromising MLIP accuracy/reliability. Here, we develop an information-theoretical framework to quantify the efficiency of dataset compression methods and propose an algorithm that maximizes this efficiency. By framing atomistic dataset compression as an instance of the minimum set cover (MSC) problem over atom-centered environments, our method identifies the smallest subset of structures that contains as much information as possible from the original dataset while pruning redundant information. The approach is extensively demonstrated on the GAP-20 and TM23 datasets, and validated on 64 varied datasets from the ColabFit repository. Across all cases, MSC consistently retains outliers, preserves dataset diversity, and reproduces the long-tail distributions of forces even at high compression rates, outperforming other subsampling methods. Furthermore, MLIPs trained on MSC-compressed datasets exhibit reduced error for out-of-distribution data even in low-data regimes. We explain these results using an outlier analysis and show that such quantitative conclusions could not be achieved with conventional dimensionality reduction methods. The algorithm is implemented in the open-source QUESTS package and can be used for several tasks in atomistic modeling, from data subsampling, outlier detection, and training improved MLIPs at a lower cost.
<div id='section'>Paperid: <span id='pid'>16, <a href='https://arxiv.org/pdf/2511.08377.pdf' target='_blank'>https://arxiv.org/pdf/2511.08377.pdf</a></span>   <span><a href='https://github.com/namwob44/Psychic' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Bowman, Xiaoli Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.08377">Human Motion Intent Inferencing in Teleoperation Through a SINDy Paradigm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intent inferencing in teleoperation has been instrumental in aligning operator goals and coordinating actions with robotic partners. However, current intent inference methods often ignore subtle motion that can be strong indicators for a sudden change in intent. Specifically, we aim to tackle 1) if we can detect sudden jumps in operator trajectories, 2) how we appropriately use these sudden jump motions to infer an operator's goal state, and 3) how to incorporate these discontinuous and continuous dynamics to infer operator motion. Our framework, called Psychic, models these small indicative motions through a jump-drift-diffusion stochastic differential equation to cover discontinuous and continuous dynamics. Kramers-Moyal (KM) coefficients allow us to detect jumps with a trajectory which we pair with a statistical outlier detection algorithm to nominate goal transitions. Through identifying jumps, we can perform early detection of existing goals and discover undefined goals in unstructured scenarios. Our framework then applies a Sparse Identification of Nonlinear Dynamics (SINDy) model using KM coefficients with the goal transitions as a control input to infer an operator's motion behavior in unstructured scenarios. We demonstrate Psychic can produce probabilistic reachability sets and compare our strategy to a negative log-likelihood model fit. We perform a retrospective study on 600 operator trajectories in a hands-free teleoperation task to evaluate the efficacy of our opensource package, Psychic, in both offline and online learning.
<div id='section'>Paperid: <span id='pid'>17, <a href='https://arxiv.org/pdf/2511.07068.pdf' target='_blank'>https://arxiv.org/pdf/2511.07068.pdf</a></span>   <span><a href='https://github.com/HHU-MMBS/clustermine_wacv_official' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/HHU-MMBS/clustermine_wacv_official' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikolas Adaloglou, Diana Petrusheva, Mohamed Asker, Felix Michels, Markus Kollmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.07068">ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large-scale visual out-of-distribution (OOD) detection has witnessed remarkable progress by leveraging vision-language models such as CLIP. However, a significant limitation of current methods is their reliance on a pre-defined set of in-distribution (ID) ground-truth label names (positives). These fixed label names can be unavailable, unreliable at scale, or become less relevant due to in-distribution shifts after deployment. Towards truly unsupervised OOD detection, we utilize widely available text corpora for positive label mining, bypassing the need for positives. In this paper, we utilize widely available text corpora for positive label mining under a general concept mining paradigm. Within this framework, we propose ClusterMine, a novel positive label mining method. ClusterMine is the first method to achieve state-of-the-art OOD detection performance without access to positive labels. It extracts positive concepts from a large text corpus by combining visual-only sample consistency (via clustering) and zero-shot image-text consistency. Our experimental study reveals that ClusterMine is scalable across a plethora of CLIP models and achieves state-of-the-art robustness to covariate in-distribution shifts. The code is available at https://github.com/HHU-MMBS/clustermine_wacv_official.
<div id='section'>Paperid: <span id='pid'>18, <a href='https://arxiv.org/pdf/2511.01458.pdf' target='_blank'>https://arxiv.org/pdf/2511.01458.pdf</a></span>   <span><a href='https://github.com/DennisPierantozzi/QASNNE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dennis Pierantozzi, Luca Carlini, Mauro Orazio Drago, Chiara Lena, Cesare Hassan, Elena De Momi, Danail Stoyanov, Sophia Bano, Mobarak I. Hoque
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.01458">When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safety and reliability are essential for deploying Visual Question Answering (VQA) in surgery, where incorrect or ambiguous responses can harm the patient. Most surgical VQA research focuses on accuracy or linguistic quality while overlooking safety behaviors such as ambiguity awareness, referral to human experts, or triggering a second opinion. Inspired by Automatic Failure Detection (AFD), we study uncertainty estimation as a key enabler of safer decision making. We introduce Question Aligned Semantic Nearest Neighbor Entropy (QA-SNNE), a black box uncertainty estimator that incorporates question semantics into prediction confidence. It measures semantic entropy by comparing generated answers with nearest neighbors in a medical text embedding space, conditioned on the question. We evaluate five models, including domain specific Parameter-Efficient Fine-Tuned (PEFT) models and zero-shot Large Vision-Language Models (LVLMs), on EndoVis18-VQA and PitVQA. PEFT models degrade under mild paraphrasing, while LVLMs are more resilient. Across three LVLMs and two PEFT baselines, QA-SNNE improves AUROC in most in-template settings and enhances hallucination detection. The Area Under the ROC Curve (AUROC) increases by 15-38% for zero-shot models, with gains maintained under out-of-template stress. QA-SNNE offers a practical and interpretable step toward AFD in surgical VQA by linking semantic uncertainty to question context. Combining LVLM backbones with question aligned uncertainty estimation can improve safety and clinician trust. The code and model are available at https://github.com/DennisPierantozzi/QASNNE
<div id='section'>Paperid: <span id='pid'>19, <a href='https://arxiv.org/pdf/2510.24372.pdf' target='_blank'>https://arxiv.org/pdf/2510.24372.pdf</a></span>   <span><a href='https://belletts.github.io/Belle/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyang Zhang, Yifan Gao, Xuenan Xu, Baoxiangli, Wen Wu, Chao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.24372">Bayesian Speech synthesizers Can Learn from Multiple Teachers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Codec-based text-to-speech (TTS) models have recently gained traction for their efficiency and strong performance in voice cloning. However, codec-based TTS faces limitations due to the challenges of pretraining robust speech codecs and the quality degradation introduced by quantization errors. Emerging evidence suggests that continuous-valued generative models can alleviate these issues and serve as a promising alternative. Yet, effectively modelling diverse speech patterns and developing reliable sampling strategies for continuous-valued autoregressive (AR) TTS remains underexplored. In this work, we propose BELLE, Bayesian evidential learning with language modelling for TTS, a novel continuous-valued AR framework that directly predicts mel-spectrograms from textual input. BELLE treats each mel-spectrogram frame as a Gaussian distribution sampled from a learned hyper distribution, enabling principled uncertainty estimation, particularly in scenarios with parallel data (i.e., one text-audio prompt paired with multiple speech samples). To obtain such data, diverse speech samples are synthesized using multiple pre-trained TTS models given the same text-audio prompts, which are distilled into BELLE via Bayesian evidential learning. Experimental results indicate that BELLE demonstrates highly competitive performance compared with the current best open-source TTS models, even though BELLE is trained on a large amount of synthetic data and uses only approximately one-tenth of their training data. Audio samples generated by BELLE are available at https://belletts.github.io/Belle/. The code, checkpoints, and synthetic data will be released after the paper is accepted.
<div id='section'>Paperid: <span id='pid'>20, <a href='https://arxiv.org/pdf/2510.21691.pdf' target='_blank'>https://arxiv.org/pdf/2510.21691.pdf</a></span>   <span><a href='https://github.com/EdwardBerman/EquiUQ' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Edward Berman, Jacob Ginesin, Marco Pacini, Robin Walters
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.21691">On Uncertainty Calibration for Equivariant Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-sparse settings such as robotic manipulation, molecular physics, and galaxy morphology classification are some of the hardest domains for deep learning. For these problems, equivariant networks can help improve modeling across undersampled parts of the input space, and uncertainty estimation can guard against overconfidence. However, until now, the relationships between equivariance and model confidence, and more generally equivariance and model calibration, has yet to be studied. Since traditional classification and regression error terms show up in the definitions of calibration error, it is natural to suspect that previous work can be used to help understand the relationship between equivariance and calibration error. In this work, we present a theory relating equivariance to uncertainty estimation. By proving lower and upper bounds on uncertainty calibration errors (ECE and ENCE) under various equivariance conditions, we elucidate the generalization limits of equivariant models and illustrate how symmetry mismatch can result in miscalibration in both classification and regression. We complement our theoretical framework with numerical experiments that clarify the relationship between equivariance and uncertainty using a variety of real and simulated datasets, and we comment on trends with symmetry mismatch, group size, and aleatoric and epistemic uncertainties.
<div id='section'>Paperid: <span id='pid'>21, <a href='https://arxiv.org/pdf/2510.20134.pdf' target='_blank'>https://arxiv.org/pdf/2510.20134.pdf</a></span>   <span><a href='https://github.com/GIT-LJc/LogitGap' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiachen Liang, Ruibing Hou, Minyang Hu, Hong Chang, Shiguang Shan, Xilin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.20134">Revisiting Logit Distributions for Reliable Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical for ensuring the reliability of deep learning models in open-world applications. While post-hoc methods are favored for their efficiency and ease of deployment, existing approaches often underexploit the rich information embedded in the model's logits space. In this paper, we propose LogitGap, a novel post-hoc OOD detection method that explicitly exploits the relationship between the maximum logit and the remaining logits to enhance the separability between in-distribution (ID) and OOD samples. To further improve its effectiveness, we refine LogitGap by focusing on a more compact and informative subset of the logit space. Specifically, we introduce a training-free strategy that automatically identifies the most informative logits for scoring. We provide both theoretical analysis and empirical evidence to validate the effectiveness of our approach. Extensive experiments on both vision-language and vision-only models demonstrate that LogitGap consistently achieves state-of-the-art performance across diverse OOD detection scenarios and benchmarks. Code is available at https://github.com/GIT-LJc/LogitGap.
<div id='section'>Paperid: <span id='pid'>22, <a href='https://arxiv.org/pdf/2510.17179.pdf' target='_blank'>https://arxiv.org/pdf/2510.17179.pdf</a></span>   <span><a href='https://github.com/BlackJack0083/PlanktonOoD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingzi Han, Jiakai He, Chuanlong Xie, Jianping Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.17179">Benchmarking Out-of-Distribution Detection for Plankton Recognition: A Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated plankton recognition models face significant challenges during real-world deployment due to distribution shifts (Out-of-Distribution, OoD) between training and test data. This stems from plankton's complex morphologies, vast species diversity, and the continuous discovery of novel species, which leads to unpredictable errors during inference. Despite rapid advancements in OoD detection methods in recent years, the field of plankton recognition still lacks a systematic integration of the latest computer vision developments and a unified benchmark for large-scale evaluation. To address this, this paper meticulously designed a series of OoD benchmarks simulating various distribution shift scenarios based on the DYB-PlanktonNet dataset \cite{875n-f104-21}, and systematically evaluated twenty-two OoD detection methods. Extensive experimental results demonstrate that the ViM \cite{wang2022vim} method significantly outperforms other approaches in our constructed benchmarks, particularly excelling in Far-OoD scenarios with substantial improvements in key metrics. This comprehensive evaluation not only provides a reliable reference for algorithm selection in automated plankton recognition but also lays a solid foundation for future research in plankton OoD detection. To our knowledge, this study marks the first large-scale, systematic evaluation and analysis of Out-of-Distribution data detection methods in plankton recognition. Code is available at https://github.com/BlackJack0083/PlanktonOoD.
<div id='section'>Paperid: <span id='pid'>23, <a href='https://arxiv.org/pdf/2510.16127.pdf' target='_blank'>https://arxiv.org/pdf/2510.16127.pdf</a></span>   <span><a href='https://github.com/CI-NYC/densityratios' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Oliver J. Hines, Caleb H. Miles
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.16127">Learning density ratios in causal inference using Bregman-Riesz regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ratio of two probability density functions is a fundamental quantity that appears in many areas of statistics and machine learning, including causal inference, reinforcement learning, covariate shift, outlier detection, independence testing, importance sampling, and diffusion modeling. Naively estimating the numerator and denominator densities separately using, e.g., kernel density estimators, can lead to unstable performance and suffers from the curse of dimensionality as the number of covariates increases. For this reason, several methods have been developed for estimating the density ratio directly based on (a) Bregman divergences or (b) recasting the density ratio as the odds in a probabilistic classification model that predicts whether an observation is sampled from the numerator or denominator distribution. Additionally, the density ratio can be viewed as the Riesz representer of a continuous linear map, making it amenable to estimation via (c) minimization of the so-called Riesz loss, which was developed to learn the Riesz representer in the Riesz regression procedure in causal inference. In this paper we show that all three of these methods can be unified in a common framework, which we call Bregman-Riesz regression. We further show how data augmentation techniques can be used to apply density ratio learning methods to causal problems, where the numerator distribution typically represents an unobserved intervention. We show through simulations how the choice of Bregman divergence and data augmentation strategy can affect the performance of the resulting density ratio learner. A Python package is provided for researchers to apply Bregman-Riesz regression in practice using gradient boosting, neural networks, and kernel methods.
<div id='section'>Paperid: <span id='pid'>24, <a href='https://arxiv.org/pdf/2510.15541.pdf' target='_blank'>https://arxiv.org/pdf/2510.15541.pdf</a></span>   <span><a href='https://github.com/Saumya4321/mc-dropout-boundary-correlation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saumya B
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.15541">An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate brain tumor segmentation from MRI is vital for diagnosis and treatment planning. Although Monte Carlo (MC) Dropout is widely used to estimate model uncertainty, its effectiveness in identifying segmentation errors -- especially near tumor boundaries -- remains unclear. This study empirically examines the relationship between MC Dropout--based uncertainty and segmentation error in 2D brain tumor MRI segmentation using a U-Net trained under four augmentation settings: none, horizontal flip, rotation, and scaling. Uncertainty was computed from 50 stochastic forward passes and correlated with pixel-wise errors using Pearson and Spearman coefficients. Results show weak global correlations ($r \approx 0.30$--$0.38$) and negligible boundary correlations ($|r| < 0.05$). Although differences across augmentations were statistically significant ($p < 0.001$), they lacked practical relevance. These findings suggest that MC Dropout uncertainty provides limited cues for boundary error localization, underscoring the need for alternative or hybrid uncertainty estimation methods in medical image segmentation.
<div id='section'>Paperid: <span id='pid'>25, <a href='https://arxiv.org/pdf/2510.14403.pdf' target='_blank'>https://arxiv.org/pdf/2510.14403.pdf</a></span>   <span><a href='https://github.com/tuuuc/DCMIL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Tu, Kun Huang, Jie Zhang, Qianjin Feng, Yu Zhang, Zhenyuan Ning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.14403">DCMIL: A Progressive Representation Learning Model of Whole Slide Images for Cancer Prognosis Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The burgeoning discipline of computational pathology shows promise in harnessing whole slide images (WSIs) to quantify morphological heterogeneity and develop objective prognostic modes for human cancers. However, progress is impeded by the computational bottleneck of gigapixel-size inputs and the scarcity of dense manual annotations. Current methods often overlook fine-grained information across multi-magnification WSIs and variations in tumor microenvironments. Here, we propose an easy-to-hard progressive representation learning model, termed dual-curriculum contrastive multi-instance learning (DCMIL), to efficiently process WSIs for cancer prognosis. The model does not rely on dense annotations and enables the direct transformation of gigapixel-size WSIs into outcome predictions. Extensive experiments on twelve cancer types (5,954 patients, 12.54 million tiles) demonstrate that DCMIL outperforms standard WSI-based prognostic models. Additionally, DCMIL identifies fine-grained prognosis-salient regions, provides robust instance uncertainty estimation, and captures morphological differences between normal and tumor tissues, with the potential to generate new biological insights. All codes have been made publicly accessible at https://github.com/tuuuc/DCMIL.
<div id='section'>Paperid: <span id='pid'>26, <a href='https://arxiv.org/pdf/2510.10947.pdf' target='_blank'>https://arxiv.org/pdf/2510.10947.pdf</a></span>   <span><a href='https://github.com/voilalab/uncertainty_quantification_LPN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Namhoon Kim, Sara Fridovich-Keil
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.10947">Towards Distribution-Shift Uncertainty Estimation for Inverse Problems with Generative Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models have shown strong potential as data-driven priors for solving inverse problems such as reconstructing medical images from undersampled measurements. While these priors improve reconstruction quality with fewer measurements, they risk hallucinating features when test images lie outside the training distribution. Existing uncertainty quantification methods in this setting (i) require an in-distribution calibration dataset, which may not be available, (ii) provide heuristic rather than statistical estimates, or (iii) quantify uncertainty from model capacity or limited measurements rather than distribution shift. We propose an instance-level, calibration-free uncertainty indicator that is sensitive to distribution shift, requires no knowledge of the training distribution, and incurs no retraining cost. Our key hypothesis is that reconstructions of in-distribution images remain stable under random measurement variations, while reconstructions of out-of-distribution (OOD) images exhibit greater instability. We use this stability as a proxy for detecting distribution shift. Our proposed OOD indicator is efficiently computable for any computational imaging inverse problem; we demonstrate it on tomographic reconstruction of MNIST digits, where a learned proximal network trained only on digit "0" is evaluated on all ten digits. Reconstructions of OOD digits show higher variability and correspondingly higher reconstruction error, validating this indicator. These results suggest a deployment strategy that pairs generative priors with lightweight guardrails, enabling aggressive measurement reduction for in-distribution cases while automatically warning when priors are applied out of distribution.
<div id='section'>Paperid: <span id='pid'>27, <a href='https://arxiv.org/pdf/2510.07030.pdf' target='_blank'>https://arxiv.org/pdf/2510.07030.pdf</a></span>   <span><a href='https://dtourrecovery.github.io/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhinav Kumar, Fan Yang, Sergio Aguilera Marinovic, Soshi Iba, Rana Soltani Zarrin, Dmitry Berenson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.07030">Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-fingered hands are emerging as powerful platforms for performing fine manipulation tasks, including tool use. However, environmental perturbations or execution errors can impede task performance, motivating the use of recovery behaviors that enable normal task execution to resume. In this work, we take advantage of recent advances in diffusion models to construct a framework that autonomously identifies when recovery is necessary and optimizes contact-rich trajectories to recover. We use a diffusion model trained on the task to estimate when states are not conducive to task execution, framed as an out-of-distribution detection problem. We then use diffusion sampling to project these states in-distribution and use trajectory optimization to plan contact-rich recovery trajectories. We also propose a novel diffusion-based approach that distills this process to efficiently diffuse the full parameterization, including constraints, goal state, and initialization, of the recovery trajectory optimization problem, saving time during online execution. We compare our method to a reinforcement learning baseline and other methods that do not explicitly plan contact interactions, including on a hardware screwdriver-turning task where we show that recovering using our method improves task performance by 96% and that ours is the only method evaluated that can attempt recovery without causing catastrophic task failure. Videos can be found at https://dtourrecovery.github.io/.
<div id='section'>Paperid: <span id='pid'>28, <a href='https://arxiv.org/pdf/2510.02109.pdf' target='_blank'>https://arxiv.org/pdf/2510.02109.pdf</a></span>   <span><a href='https://github.com/utkuozbulak/spurbreast' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jong Bum Won, Wesley De Neve, Joris Vankerschaver, Utku Ozbulak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02109">SpurBreast: A Curated Dataset for Investigating Spurious Correlations in Real-world Breast MRI Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) have demonstrated remarkable success in medical imaging, yet their real-world deployment remains challenging due to spurious correlations, where models can learn non-clinical features instead of meaningful medical patterns. Existing medical imaging datasets are not designed to systematically study this issue, largely due to restrictive licensing and limited supplementary patient data. To address this gap, we introduce SpurBreast, a curated breast MRI dataset that intentionally incorporates spurious correlations to evaluate their impact on model performance. Analyzing over 100 features involving patient, device, and imaging protocol, we identify two dominant spurious signals: magnetic field strength (a global feature influencing the entire image) and image orientation (a local feature affecting spatial alignment). Through controlled dataset splits, we demonstrate that DNNs can exploit these non-clinical signals, achieving high validation accuracy while failing to generalize to unbiased test data. Alongside these two datasets containing spurious correlations, we also provide benchmark datasets without spurious correlations, allowing researchers to systematically investigate clinically relevant and irrelevant features, uncertainty estimation, adversarial robustness, and generalization strategies. Models and datasets are available at https://github.com/utkuozbulak/spurbreast.
<div id='section'>Paperid: <span id='pid'>29, <a href='https://arxiv.org/pdf/2509.26294.pdf' target='_blank'>https://arxiv.org/pdf/2509.26294.pdf</a></span>   <span><a href='https://github.com/lionelblonde/ngt-pytorch' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lionel BlondÃ©, Joao A. Candido Ramos, Alexandros Kalousis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.26294">Noise-Guided Transport for Imitation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider imitation learning in the low-data regime, where only a limited number of expert demonstrations are available. In this setting, methods that rely on large-scale pretraining or high-capacity architectures can be difficult to apply, and efficiency with respect to demonstration data becomes critical. We introduce Noise-Guided Transport (NGT), a lightweight off-policy method that casts imitation as an optimal transport problem solved via adversarial training. NGT requires no pretraining or specialized architectures, incorporates uncertainty estimation by design, and is easy to implement and tune. Despite its simplicity, NGT achieves strong performance on challenging continuous control tasks, including high-dimensional Humanoid tasks, under ultra-low data regimes with as few as 20 transitions. Code is publicly available at: https://github.com/lionelblonde/ngt-pytorch.
<div id='section'>Paperid: <span id='pid'>30, <a href='https://arxiv.org/pdf/2509.25438.pdf' target='_blank'>https://arxiv.org/pdf/2509.25438.pdf</a></span>   <span><a href='https://github.com/Akuna23Matata/LPM_exploration' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhibo Hou, Zhiyu An, Wan Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25438">Beyond Noisy-TVs: Noise-Robust Exploration Via Learning Progress Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When there exists an unlearnable source of randomness (noisy-TV) in the environment, a naively intrinsic reward driven exploring agent gets stuck at that source of randomness and fails at exploration. Intrinsic reward based on uncertainty estimation or distribution similarity, while eventually escapes noisy-TVs as time unfolds, suffers from poor sample efficiency and high computational cost. Inspired by recent findings from neuroscience that humans monitor their improvements during exploration, we propose a novel method for intrinsically-motivated exploration, named Learning Progress Monitoring (LPM). During exploration, LPM rewards model improvements instead of prediction error or novelty, effectively rewards the agent for observing learnable transitions rather than the unlearnable transitions. We introduce a dual-network design that uses an error model to predict the expected prediction error of the dynamics model in its previous iteration, and use the difference between the model errors of the current iteration and previous iteration to guide exploration. We theoretically show that the intrinsic reward of LPM is zero-equivariant and a monotone indicator of Information Gain (IG), and that the error model is necessary to achieve monotonicity correspondence with IG. We empirically compared LPM against state-of-the-art baselines in noisy environments based on MNIST, 3D maze with 160x120 RGB inputs, and Atari. Results show that LPM's intrinsic reward converges faster, explores more states in the maze experiment, and achieves higher extrinsic reward in Atari. This conceptually simple approach marks a shift-of-paradigm of noise-robust exploration. For code to reproduce our experiments, see https://github.com/Akuna23Matata/LPM_exploration
<div id='section'>Paperid: <span id='pid'>31, <a href='https://arxiv.org/pdf/2509.22380.pdf' target='_blank'>https://arxiv.org/pdf/2509.22380.pdf</a></span>   <span><a href='https://github.com/stat-ml/multidimensional_uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Kotelevskii, Maiya Goloburda, Vladimir Kondratyev, Alexander Fishkov, Mohsen Guizani, Eric Moulines, Maxim Panov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22380">Multidimensional Uncertainty Quantification via Optimal Transport</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most uncertainty quantification (UQ) approaches provide a single scalar value as a measure of model reliability. However, different uncertainty measures could provide complementary information on the prediction confidence. Even measures targeting the same type of uncertainty (e.g., ensemble-based and density-based measures of epistemic uncertainty) may capture different failure modes. We take a multidimensional view on UQ by stacking complementary UQ measures into a vector. Such vectors are assigned with Monge-Kantorovich ranks produced by an optimal-transport-based ordering method. The prediction is then deemed more uncertain than the other if it has a higher rank. The resulting VecUQ-OT algorithm uses entropy-regularized optimal transport. The transport map is learned on vectors of scores from in-distribution data and, by design, applies to unseen inputs, including out-of-distribution cases, without retraining. Our framework supports flexible non-additive uncertainty fusion (including aleatoric and epistemic components). It yields a robust ordering for downstream tasks such as selective prediction, misclassification detection, out-of-distribution detection, and selective generation. Across synthetic, image, and text data, VecUQ-OT shows high efficiency even when individual measures fail. The code for the method is available at: https://github.com/stat-ml/multidimensional_uncertainty.
<div id='section'>Paperid: <span id='pid'>32, <a href='https://arxiv.org/pdf/2509.21055.pdf' target='_blank'>https://arxiv.org/pdf/2509.21055.pdf</a></span>   <span><a href='https://github.com/YuzunoKawori/Mambo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Songyue Cai, Zongqian Wu, Yujie Mo, Liang Peng, Ping Hu, Xiaoshuang Shi, Xiaofeng Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21055">Background Prompt for Few-Shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing foreground-background (FG-BG) decomposition methods for the few-shot out-of-distribution (FS-OOD) detection often suffer from low robustness due to over-reliance on the local class similarity and a fixed background patch extraction strategy. To address these challenges, we propose a new FG-BG decomposition framework, namely Mambo, for FS-OOD detection. Specifically, we propose to first learn a background prompt to obtain the local background similarity containing both the background and image semantic information, and then refine the local background similarity using the local class similarity. As a result, we use both the refined local background similarity and the local class similarity to conduct background extraction, reducing the dependence of the local class similarity in previous methods. Furthermore, we propose the patch self-calibrated tuning to consider the sample diversity to flexibly select numbers of background patches for different samples, and thus exploring the issue of fixed background extraction strategies in previous methods. Extensive experiments on real-world datasets demonstrate that our proposed Mambo achieves the best performance, compared to SOTA methods in terms of OOD detection and near OOD detection setting. The source code will be released at https://github.com/YuzunoKawori/Mambo.
<div id='section'>Paperid: <span id='pid'>33, <a href='https://arxiv.org/pdf/2509.17098.pdf' target='_blank'>https://arxiv.org/pdf/2509.17098.pdf</a></span>   <span><a href='https://github.com/suiannaius/SURE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuzhu Li, An Sui, Fuping Wu, Xiahai Zhuang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17098">Uncertainty-Supervised Interpretable and Robust Evidential Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation has been widely studied in medical image segmentation as a tool to provide reliability, particularly in deep learning approaches. However, previous methods generally lack effective supervision in uncertainty estimation, leading to low interpretability and robustness of the predictions. In this work, we propose a self-supervised approach to guide the learning of uncertainty. Specifically, we introduce three principles about the relationships between the uncertainty and the image gradients around boundaries and noise. Based on these principles, two uncertainty supervision losses are designed. These losses enhance the alignment between model predictions and human interpretation. Accordingly, we introduce novel quantitative metrics for evaluating the interpretability and robustness of uncertainty. Experimental results demonstrate that compared to state-of-the-art approaches, the proposed method can achieve competitive segmentation performance and superior results in out-of-distribution (OOD) scenarios while significantly improving the interpretability and robustness of uncertainty estimation. Code is available via https://github.com/suiannaius/SURE.
<div id='section'>Paperid: <span id='pid'>34, <a href='https://arxiv.org/pdf/2509.16926.pdf' target='_blank'>https://arxiv.org/pdf/2509.16926.pdf</a></span>   <span><a href='https://github.com/Ragib-Amin-Nihal/BEATsCA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ragib Amin Nihal, Benjamin Yen, Takeshi Ashizawa, Kazuhiro Nakadai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16926">Cross-Attention with Confidence Weighting for Multi-Channel Audio Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-channel audio alignment is a key requirement in bioacoustic monitoring, spatial audio systems, and acoustic localization. However, existing methods often struggle to address nonlinear clock drift and lack mechanisms for quantifying uncertainty. Traditional methods like Cross-correlation and Dynamic Time Warping assume simple drift patterns and provide no reliability measures. Meanwhile, recent deep learning models typically treat alignment as a binary classification task, overlooking inter-channel dependencies and uncertainty estimation. We introduce a method that combines cross-attention mechanisms with confidence-weighted scoring to improve multi-channel audio synchronization. We extend BEATs encoders with cross-attention layers to model temporal relationships between channels. We also develop a confidence-weighted scoring function that uses the full prediction distribution instead of binary thresholding. Our method achieved first place in the BioDCASE 2025 Task 1 challenge with 0.30 MSE average across test datasets, compared to 0.58 for the deep learning baseline. On individual datasets, we achieved 0.14 MSE on ARU data (77% reduction) and 0.45 MSE on zebra finch data (18% reduction). The framework supports probabilistic temporal alignment, moving beyond point estimates. While validated in a bioacoustic context, the approach is applicable to a broader range of multi-channel audio tasks where alignment confidence is critical. Code available on: https://github.com/Ragib-Amin-Nihal/BEATsCA
<div id='section'>Paperid: <span id='pid'>35, <a href='https://arxiv.org/pdf/2509.11728.pdf' target='_blank'>https://arxiv.org/pdf/2509.11728.pdf</a></span>   <span><a href='https://github.com/edahelsinki/JK-kNN/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lauri SeppÃ¤lÃ¤inen, Jakub KubeÄka, Jonas Elm, Kai PuolamÃ¤ki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11728">Fast and Interpretable Machine Learning Modelling of Atmospheric Molecular Clusters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding how atmospheric molecular clusters form and grow is key to resolving one of the biggest uncertainties in climate modelling: the formation of new aerosol particles. While quantum chemistry offers accurate insights into these early-stage clusters, its steep computational costs limit large-scale exploration. In this work, we present a fast, interpretable, and surprisingly powerful alternative: $k$-nearest neighbour ($k$-NN) regression model. By leveraging chemically informed distance metrics, including a kernel-induced metric and one learned via metric learning for kernel regression (MLKR), we show that simple $k$-NN models can rival more complex kernel ridge regression (KRR) models in accuracy, while reducing computational time by orders of magnitude. We perform this comparison with the well-established Faber-Christensen-Huang-Lilienfeld (FCHL19) molecular descriptor, but other descriptors (e.g., FCHL18, MBDF, and CM) can be shown to have similar performance. Applied to both simple organic molecules in the QM9 benchmark set and large datasets of atmospheric molecular clusters (sulphuric acid-water and sulphuric-multibase -base systems), our $k$-NN models achieve near-chemical accuracy, scale seamlessly to datasets with over 250,000 entries, and even appears to extrapolate to larger unseen clusters with minimal error (often nearing 1 kcal/mol). With built-in interpretability and straightforward uncertainty estimation, this work positions $k$-NN as a potent tool for accelerating discovery in atmospheric chemistry and beyond.
<div id='section'>Paperid: <span id='pid'>36, <a href='https://arxiv.org/pdf/2509.07925.pdf' target='_blank'>https://arxiv.org/pdf/2509.07925.pdf</a></span>   <span><a href='https://github.com/ODYSSEYWT/GUQ' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tuo Wang, Adithya Kulkarni, Tyler Cody, Peter A. Beling, Yujun Yan, Dawei Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07925">GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is essential for enhancing the reliability of Large Language Models (LLMs), particularly in high-stakes applications. Existing methods often overlook semantic dependencies, relying on token-level probability measures that fail to capture structural relationships within the generated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty Estimation for Large Language Models, a structure-aware framework that leverages dependency parse trees and hierarchical graph pooling to refine uncertainty quantification. By incorporating supervised learning, GENUINE effectively models semantic and structural relationships, improving confidence assessments. Extensive experiments across NLP tasks show that GENUINE achieves up to 29% higher AUROC than semantic entropy-based approaches and reduces calibration errors by over 15%, demonstrating the effectiveness of graph-based uncertainty modeling. The code is available at https://github.com/ODYSSEYWT/GUQ.
<div id='section'>Paperid: <span id='pid'>37, <a href='https://arxiv.org/pdf/2509.06988.pdf' target='_blank'>https://arxiv.org/pdf/2509.06988.pdf</a></span>   <span><a href='https://github.com/Aie0923/ClaFR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingsheng Wang, Shuo Lu, Jian Liang, Aihua Zheng, Ran He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06988">Frustratingly Easy Feature Reconstruction for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection helps models identify data outside the training categories, crucial for security applications. While feature-based post-hoc methods address this by evaluating data differences in the feature space without changing network parameters, they often require access to training data, which may not be suitable for some data privacy scenarios. This may not be suitable in scenarios where data privacy protection is a concern. In this paper, we propose a simple yet effective post-hoc method, termed Classifier-based Feature Reconstruction (ClaFR), from the perspective of subspace projection. It first performs an orthogonal decomposition of the classifier's weights to extract the class-known subspace, then maps the original data features into this subspace to obtain new data representations. Subsequently, the OOD score is determined by calculating the feature reconstruction error of the data within the subspace. Compared to existing OOD detection algorithms, our method does not require access to training data while achieving leading performance on multiple OOD benchmarks. Our code is released at https://github.com/Aie0923/ClaFR.
<div id='section'>Paperid: <span id='pid'>38, <a href='https://arxiv.org/pdf/2508.18142.pdf' target='_blank'>https://arxiv.org/pdf/2508.18142.pdf</a></span>   <span><a href='https://github.com/UserMirrorer/UserMirrorer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianjun Wei, Huizhong Guo, Yingpeng Du, Zhu Sun, Chen Huang, Dongxia Wang, Jie Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18142">Mirroring Users: Towards Building Preference-aligned User Simulator with User Feedback in Recommendation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>User simulation is increasingly vital to develop and evaluate recommender systems (RSs). While Large Language Models (LLMs) offer promising avenues to simulate user behavior, they often struggle with the absence of specific domain alignment required for RSs and the efficiency demands of large-scale simulation. A vast yet underutilized resource for enhancing this alignment is the extensive user feedback inherent in RSs. However, directly leveraging such feedback presents two significant challenges. First, user feedback in RSs is often ambiguous and noisy, which negatively impacts effective preference alignment. Second, the massive volume of feedback largely hinders the efficiency of preference alignment, necessitating an efficient filtering mechanism to identify more informative samples. To overcome these hurdles, we introduce a novel data construction framework that leverages user feedback in RSs with advanced LLM capabilities to generate high-quality simulation data. Our framework unfolds in two key phases: (1) employing LLMs to generate cognitive decision-making processes on constructed simulation samples, reducing ambiguity in raw user feedback; (2) data distillation based on uncertainty estimation and behavior sampling to filter challenging yet denoised simulation samples. Accordingly, we fine-tune lightweight LLMs, as user simulators, using such high-quality dataset with corresponding decision-making processes. Extensive experiments verify that our framework significantly boosts the alignment with human preferences and in-domain reasoning capabilities of fine-tuned LLMs, and provides more insightful and interpretable signals when interacting with RSs. We believe our work will advance the RS community and offer valuable insights for broader human-centric AI research.
<div id='section'>Paperid: <span id='pid'>39, <a href='https://arxiv.org/pdf/2508.17886.pdf' target='_blank'>https://arxiv.org/pdf/2508.17886.pdf</a></span>   <span><a href='https://github.com/hao-duan/PGTuner' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Duan, Yitong Song, Bin Yao, Anqi Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17886">PGTuner: An Efficient Framework for Automatic and Transferable Configuration Tuning of Proximity Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Approximate Nearest Neighbor Search (ANNS) plays a crucial role in many key areas. Proximity graphs (PGs) are the leading method for ANNS, offering the best balance between query efficiency and accuracy. However, their performance heavily depends on various construction and query parameters, which are difficult to optimize due to their complex inter-dependencies. Given that users often prioritize specific accuracy levels, efficiently identifying the optimal PG configurations to meet these targets is essential. Although some studies have explored automatic configuration tuning for PGs, they are limited by inefficiencies and suboptimal results. These issues stem from the need to construct numerous PGs for searching and re-tuning from scratch whenever the dataset changes, as well as the failure to capture the complex dependencies between configurations, query performance, and tuning objectives.
  To address these challenges, we propose PGTuner, an efficient framework for automatic PG configuration tuning leveraging pre-training knowledge and model transfer techniques. PGTuner improves efficiency through a pre-trained query performance prediction (QPP) model, eliminating the need to build multiple PGs. It also features a deep reinforcement learning-based parameter configuration recommendation (PCR) model to recommend optimal configurations for specific datasets and accuracy targets. Additionally, PGTuner incorporates out-of-distribution detection and deep active learning for efficient tuning in dynamic scenarios and transferring to new datasets. Extensive experiments demonstrate that PGTuner can stably achieve the top-level tuning effect across different datasets while significantly improving tuning efficiency by up to 14.69X, with a 14.64X boost in dynamic scenarios. The code and data for PGTuner are available online at https://github.com/hao-duan/PGTuner.
<div id='section'>Paperid: <span id='pid'>40, <a href='https://arxiv.org/pdf/2508.17768.pdf' target='_blank'>https://arxiv.org/pdf/2508.17768.pdf</a></span>   <span><a href='https://github.com/toufiqmusah/nn-uncertainty.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Toufiq Musah, Chinasa Kalaiwo, Maimoona Akram, Ubaida Napari Abdulai, Maruf Adewole, Farouk Dako, Adaobi Chiazor Emegoakor, Udunna C. Anazodo, Prince Ebenezer Adjei, Confidence Raymond
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17768">Towards Trustworthy Breast Tumor Segmentation in Ultrasound using Monte Carlo Dropout and Deep Ensembles for Epistemic Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated segmentation of BUS images is important for precise lesion delineation and tumor characterization, but is challenged by inherent artifacts and dataset inconsistencies. In this work, we evaluate the use of a modified Residual Encoder U-Net for breast ultrasound segmentation, with a focus on uncertainty quantification. We identify and correct for data duplication in the BUSI dataset, and use a deduplicated subset for more reliable estimates of generalization performance. Epistemic uncertainty is quantified using Monte Carlo dropout, deep ensembles, and their combination. Models are benchmarked on both in-distribution and out-of-distribution datasets to demonstrate how they generalize to unseen cross-domain data. Our approach achieves state-of-the-art segmentation accuracy on the Breast-Lesion-USG dataset with in-distribution validation, and provides calibrated uncertainty estimates that effectively signal regions of low model confidence. Performance declines and increased uncertainty observed in out-of-distribution evaluation highlight the persistent challenge of domain shift in medical imaging, and the importance of integrated uncertainty modeling for trustworthy clinical deployment. \footnote{Code available at: https://github.com/toufiqmusah/nn-uncertainty.git}
<div id='section'>Paperid: <span id='pid'>41, <a href='https://arxiv.org/pdf/2508.17408.pdf' target='_blank'>https://arxiv.org/pdf/2508.17408.pdf</a></span>   <span><a href='https://github.com/mp31192/E-BayesSAM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bin Huang, Zhong Liu, Huiying Wen, Bingsheng Huang, Xin Chen, Shuo Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17408">E-BayesSAM: Efficient Bayesian Adaptation of SAM with Self-Optimizing KAN-Based Interpretation for Uncertainty-Aware Ultrasonic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although the Segment Anything Model (SAM) has advanced medical image segmentation, its Bayesian adaptation for uncertainty-aware segmentation remains hindered by three key issues: (1) instability in Bayesian fine-tuning of large pre-trained SAMs; (2) high computation cost due to SAM's massive parameters; (3) SAM's black-box design limits interpretability. To overcome these, we propose E-BayesSAM, an efficient framework combining Token-wise Variational Bayesian Inference (T-VBI) for efficienty Bayesian adaptation and Self-Optimizing Kolmogorov-Arnold Network (SO-KAN) for improving interpretability. T-VBI innovatively reinterprets SAM's output tokens as dynamic probabilistic weights and reparameterizes them as latent variables without auxiliary training, enabling training-free VBI for uncertainty estimation. SO-KAN improves token prediction with learnable spline activations via self-supervised learning, providing insight to prune redundant tokens to boost efficiency and accuracy. Experiments on five ultrasound datasets demonstrated that E-BayesSAM achieves: (i) real-time inference (0.03s/image), (ii) superior segmentation accuracy (average DSC: Pruned E-BayesSAM's 89.0\% vs. E-BayesSAM's 88.0% vs. MedSAM's 88.3%), and (iii) identification of four critical tokens governing SAM's decisions. By unifying efficiency, reliability, and interpretability, E-BayesSAM bridges SAM's versatility with clinical needs, advancing deployment in safety-critical medical applications. The source code is available at https://github.com/mp31192/E-BayesSAM.
<div id='section'>Paperid: <span id='pid'>42, <a href='https://arxiv.org/pdf/2508.09196.pdf' target='_blank'>https://arxiv.org/pdf/2508.09196.pdf</a></span>   <span><a href='https://github.com/asimukaye/fiva' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Asim Ukaye, Numan Saeed, Karthik Nandakumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.09196">FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Different CT segmentation datasets are typically obtained from different scanners under different capture settings and often provide segmentation labels for a limited and often disjoint set of organs. Using these heterogeneous data effectively while preserving patient privacy can be challenging. This work presents a novel federated learning approach to achieve universal segmentation across diverse abdominal CT datasets by utilizing model uncertainty for aggregation and predictive uncertainty for inference. Our approach leverages the inherent noise in stochastic mini-batch gradient descent to estimate a distribution over the model weights to provide an on-the-go uncertainty over the model parameters at the client level. The parameters are then aggregated at the server using the additional uncertainty information using a Bayesian-inspired inverse-variance aggregation scheme. Furthermore, the proposed method quantifies prediction uncertainty by propagating the uncertainty from the model weights, providing confidence measures essential for clinical decision-making. In line with recent work shown, predictive uncertainty is utilized in the inference stage to improve predictive performance. Experimental evaluations demonstrate the effectiveness of this approach in improving both the quality of federated aggregation and uncertainty-weighted inference compared to previously established baselines. The code for this work is made available at: https://github.com/asimukaye/fiva
<div id='section'>Paperid: <span id='pid'>43, <a href='https://arxiv.org/pdf/2508.03827.pdf' target='_blank'>https://arxiv.org/pdf/2508.03827.pdf</a></span>   <span><a href='https://github.com/ComputationalDesignLab/snbo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pavankumar Koratikere, Leifur Leifsson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03827">Scalable Neural Network-based Blackbox Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Optimization (BO) is a widely used approach for blackbox optimization that leverages a Gaussian process (GP) model and an acquisition function to guide future sampling. While effective in low-dimensional settings, BO faces scalability challenges in high-dimensional spaces and with large number of function evaluations due to the computational complexity of GP models. In contrast, neural networks (NNs) offer better scalability and can model complex functions, which led to the development of NN-based BO approaches. However, these methods typically rely on estimating model uncertainty in NN prediction -- a process that is often computationally intensive and complex, particularly in high dimensions. To address these limitations, a novel method, called scalable neural network-based blackbox optimization (SNBO), is proposed that does not rely on model uncertainty estimation. Specifically, SNBO adds new samples using separate criteria for exploration and exploitation, while adaptively controlling the sampling region to ensure efficient optimization. SNBO is evaluated on a range of optimization problems spanning from 10 to 102 dimensions and compared against four state-of-the-art baseline algorithms. Across the majority of test problems, SNBO attains function values better than the best-performing baseline algorithm, while requiring 40-60% fewer function evaluations and reducing the runtime by at least an order of magnitude.
<div id='section'>Paperid: <span id='pid'>44, <a href='https://arxiv.org/pdf/2508.00587.pdf' target='_blank'>https://arxiv.org/pdf/2508.00587.pdf</a></span>   <span><a href='https://github.com/glasbruch/ULRE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Marc HÃ¶lle, Walter Kellermann, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00587">Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic segmentation models trained on known object classes often fail in real-world autonomous driving scenarios by confidently misclassifying unknown objects. While pixel-wise out-of-distribution detection can identify unknown objects, existing methods struggle in complex scenes where rare object classes are often confused with truly unknown objects. We introduce an uncertainty-aware likelihood ratio estimation method that addresses these limitations. Our approach uses an evidential classifier within a likelihood ratio test to distinguish between known and unknown pixel features from a semantic segmentation model, while explicitly accounting for uncertainty. Instead of producing point estimates, our method outputs probability distributions that capture uncertainty from both rare training examples and imperfect synthetic outliers. We show that by incorporating uncertainty in this way, outlier exposure can be leveraged more effectively. Evaluated on five standard benchmark datasets, our method achieves the lowest average false positive rate (2.5%) among state-of-the-art while maintaining high average precision (90.91%) and incurring only negligible computational overhead. Code is available at https://github.com/glasbruch/ULRE.
<div id='section'>Paperid: <span id='pid'>45, <a href='https://arxiv.org/pdf/2508.00568.pdf' target='_blank'>https://arxiv.org/pdf/2508.00568.pdf</a></span>   <span><a href='https://jchao-xie.github.io/CoProU/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingchao Xie, Oussema Dhaouadi, Weirong Chen, Johannes Meier, Jacques Kaiser, Daniel Cremers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00568">CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and augmented reality, with unsupervised approaches eliminating the need for expensive ground-truth labels. However, these methods struggle when dynamic objects violate the static scene assumption, leading to erroneous pose estimations. We tackle this problem by uncertainty modeling, which is a commonly used technique that creates robust masks to filter out dynamic objects and occlusions without requiring explicit motion segmentation. Traditional uncertainty modeling considers only single-frame information, overlooking the uncertainties across consecutive frames. Our key insight is that uncertainty must be propagated and combined across temporal frames to effectively identify unreliable regions, particularly in dynamic scenes. To address this challenge, we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end approach that combines target frame uncertainty with projected reference frame uncertainty using a principled probabilistic formulation. Built upon vision transformer backbones, our model simultaneously learns depth, uncertainty estimation, and camera poses. Consequently, experiments on the KITTI and nuScenes datasets demonstrate significant improvements over previous unsupervised monocular end-to-end two-frame-based methods and exhibit strong performance in challenging highway scenes where other approaches often fail. Additionally, comprehensive ablation studies validate the effectiveness of cross-frame uncertainty propagation.
<div id='section'>Paperid: <span id='pid'>46, <a href='https://arxiv.org/pdf/2507.20008.pdf' target='_blank'>https://arxiv.org/pdf/2507.20008.pdf</a></span>   <span><a href='https://github.com/padmavathi026/Smart-Fare-Prediction' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Padmavathi Moorthy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20008">Robust Taxi Fare Prediction Under Noisy Conditions: A Comparative Study of GAT, TimesNet, and XGBoost</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Precise fare prediction is crucial in ride-hailing platforms and urban mobility systems. This study examines three machine learning models-Graph Attention Networks (GAT), XGBoost, and TimesNet to evaluate their predictive capabilities for taxi fares using a real-world dataset comprising over 55 million records. Both raw (noisy) and denoised versions of the dataset are analyzed to assess the impact of data quality on model performance. The study evaluated the models along multiple axes, including predictive accuracy, calibration, uncertainty estimation, out-of-distribution (OOD) robustness, and feature sensitivity. We also explore pre-processing strategies, including KNN imputation, Gaussian noise injection, and autoencoder-based denoising. The study reveals critical differences between classical and deep learning models under realistic conditions, offering practical guidelines for building robust and scalable models in urban fare prediction systems.
<div id='section'>Paperid: <span id='pid'>47, <a href='https://arxiv.org/pdf/2507.19969.pdf' target='_blank'>https://arxiv.org/pdf/2507.19969.pdf</a></span>   <span><a href='https://github.com/vis-nlp/Text2Vis' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mizanur Rahman, Md Tahmid Rahman Laskar, Shafiq Joty, Enamul Hoque
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19969">Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated data visualization plays a crucial role in simplifying data interpretation, enhancing decision-making, and improving efficiency. While large language models (LLMs) have shown promise in generating visualizations from natural language, the absence of comprehensive benchmarks limits the rigorous evaluation of their capabilities. We introduce Text2Vis, a benchmark designed to assess text-to-visualization models, covering 20+ chart types and diverse data science queries, including trend analysis, correlation, outlier detection, and predictive analytics. It comprises 1,985 samples, each with a data table, natural language query, short answer, visualization code, and annotated charts. The queries involve complex reasoning, conversational turns, and dynamic data retrieval. We benchmark 11 open-source and closed-source models, revealing significant performance gaps, highlighting key challenges, and offering insights for future advancements. To close this gap, we propose the first cross-modal actor-critic agentic framework that jointly refines the textual answer and visualization code, increasing GPT-4o`s pass rate from 26% to 42% over the direct approach and improving chart quality. We also introduce an automated LLM-based evaluation framework that enables scalable assessment across thousands of samples without human annotation, measuring answer correctness, code execution success, visualization readability, and chart accuracy. We release Text2Vis at https://github.com/vis-nlp/Text2Vis.
<div id='section'>Paperid: <span id='pid'>48, <a href='https://arxiv.org/pdf/2507.19847.pdf' target='_blank'>https://arxiv.org/pdf/2507.19847.pdf</a></span>   <span><a href='https://github.com/ZhuWenjie98/KRNFT' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/ZhuWenjie98/KRNFT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjie Zhu, Yabin Zhang, Xin Jin, Wenjun Zeng, Lei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19847">Knowledge Regularized Negative Feature Tuning of Vision-Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for building reliable machine learning models. Although negative prompt tuning has enhanced the OOD detection capabilities of vision-language models, these tuned models often suffer from reduced generalization performance on unseen classes and styles. To address this challenge, we propose a novel method called Knowledge Regularized Negative Feature Tuning (KR-NFT), which integrates an innovative adaptation architecture termed Negative Feature Tuning (NFT) and a corresponding knowledge-regularization (KR) optimization strategy. Specifically, NFT applies distribution-aware transformations to pre-trained text features, effectively separating positive and negative features into distinct spaces. This separation maximizes the distinction between in-distribution (ID) and OOD images. Additionally, we introduce image-conditional learnable factors through a lightweight meta-network, enabling dynamic adaptation to individual images and mitigating sensitivity to class and style shifts. Compared to traditional negative prompt tuning, NFT demonstrates superior efficiency and scalability. To optimize this adaptation architecture, the KR optimization strategy is designed to enhance the discrimination between ID and OOD sets while mitigating pre-trained knowledge forgetting. This enhances OOD detection performance on trained ID classes while simultaneously improving OOD detection on unseen ID datasets. Notably, when trained with few-shot samples from ImageNet dataset, KR-NFT not only improves ID classification accuracy and OOD detection but also significantly reduces the FPR95 by 5.44\% under an unexplored generalization setting with unseen ID categories. Codes can be found at \href{https://github.com/ZhuWenjie98/KRNFT}.
<div id='section'>Paperid: <span id='pid'>49, <a href='https://arxiv.org/pdf/2507.15036.pdf' target='_blank'>https://arxiv.org/pdf/2507.15036.pdf</a></span>   <span><a href='https://lyessaadsaoud.github.io/EBA-AI/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lyes Saad Saoud, Irfan Hussain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15036">EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Underwater image enhancement is vital for marine conservation, particularly coral reef monitoring. However, AI-based enhancement models often face dataset bias, high computational costs, and lack of transparency, leading to potential misinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware AI framework to address these challenges. EBA-AI leverages CLIP embeddings to detect and mitigate dataset bias, ensuring balanced representation across varied underwater environments. It also integrates adaptive processing to optimize energy efficiency, significantly reducing GPU usage while maintaining competitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100 show that while PSNR drops by a controlled 1.0 dB, computational savings enable real-time feasibility for large-scale marine monitoring. Additionally, uncertainty estimation and explainability techniques enhance trust in AI-driven environmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet, WaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing efficiency, fairness, and interpretability in underwater image processing. By addressing key limitations of AI-driven enhancement, this work contributes to sustainable, bias-aware, and computationally efficient marine conservation efforts. For interactive visualizations, animations, source code, and access to the preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/
<div id='section'>Paperid: <span id='pid'>50, <a href='https://arxiv.org/pdf/2507.10225.pdf' target='_blank'>https://arxiv.org/pdf/2507.10225.pdf</a></span>   <span><a href='https://github.com/Jarvisgivemeasuit/SynOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinglun Li, Kaixun Jiang, Zhaoyu Chen, Bo Lin, Yao Tang, Weifeng Ge, Wenqiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10225">Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision-language models have exhibited remarkable abilities in detecting out-of-distribution (OOD) samples. However, some challenging OOD samples, which lie close to in-distribution (InD) data in image feature space, can still lead to misclassification. The emergence of foundation models like diffusion models and multimodal large language models (MLLMs) offers a potential solution to this issue. In this work, we propose SynOOD, a novel approach that harnesses foundation models to generate synthetic, challenging OOD data for fine-tuning CLIP models, thereby enhancing boundary-level discrimination between InD and OOD samples. Our method uses an iterative in-painting process guided by contextual prompts from MLLMs to produce nuanced, boundary-aligned OOD samples. These samples are refined through noise adjustments based on gradients from OOD scores like the energy score, effectively sampling from the InD/OOD boundary. With these carefully synthesized images, we fine-tune the CLIP image encoder and negative label features derived from the text encoder to strengthen connections between near-boundary OOD samples and a set of negative labels. Finally, SynOOD achieves state-of-the-art performance on the large-scale ImageNet benchmark, with minimal increases in parameters and runtime. Our approach significantly surpasses existing methods, and the code is available at https://github.com/Jarvisgivemeasuit/SynOOD.
<div id='section'>Paperid: <span id='pid'>51, <a href='https://arxiv.org/pdf/2507.04511.pdf' target='_blank'>https://arxiv.org/pdf/2507.04511.pdf</a></span>   <span><a href='https://github.com/0xFAFA/FA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinhua Lu, Runhe Lai, Yanqi Wu, Kanghao Chen, Wei-Shi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04511">FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision-language models (VLMs) have advanced out-of-distribution (OOD) detection recently. However, existing CLIP-based methods often focus on learning OOD-related knowledge to improve OOD detection, showing limited generalization or reliance on external large-scale auxiliary datasets. In this study, instead of delving into the intricate OOD-related knowledge, we propose an innovative CLIP-based framework based on Forced prompt leArning (FA), designed to make full use of the In-Distribution (ID) knowledge and ultimately boost the effectiveness of OOD detection. Our key insight is to learn a prompt (i.e., forced prompt) that contains more diversified and richer descriptions of the ID classes beyond the textual semantics of class labels. Specifically, it promotes better discernment for ID images, by forcing more notable semantic similarity between ID images and the learnable forced prompt. Moreover, we introduce a forced coefficient, encouraging the forced prompt to learn more comprehensive and nuanced descriptions of the ID classes. In this way, FA is capable of achieving notable improvements in OOD detection, even when trained without any external auxiliary datasets, while maintaining an identical number of trainable parameters as CoOp. Extensive empirical evaluations confirm our method consistently outperforms current state-of-the-art methods. Code is available at https://github.com/0xFAFA/FA.
<div id='section'>Paperid: <span id='pid'>52, <a href='https://arxiv.org/pdf/2507.03923.pdf' target='_blank'>https://arxiv.org/pdf/2507.03923.pdf</a></span>   <span><a href='https://github.com/hieuphamha19/CSDS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ha-Hieu Pham, Nguyen Lan Vi Vu, Thanh-Huy Nguyen, Ulas Bagci, Min Xu, Trung-Nghia Le, Huy-Hieu Pham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03923">Learning Disentangled Stain and Structural Representations for Semi-Supervised Histopathology Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate gland segmentation in histopathology images is essential for cancer diagnosis and prognosis. However, significant variability in Hematoxylin and Eosin (H&E) staining and tissue morphology, combined with limited annotated data, poses major challenges for automated segmentation. To address this, we propose Color-Structure Dual-Student (CSDS), a novel semi-supervised segmentation framework designed to learn disentangled representations of stain appearance and tissue structure. CSDS comprises two specialized student networks: one trained on stain-augmented inputs to model chromatic variation, and the other on structure-augmented inputs to capture morphological cues. A shared teacher network, updated via Exponential Moving Average (EMA), supervises both students through pseudo-labels. To further improve label reliability, we introduce stain-aware and structure-aware uncertainty estimation modules that adaptively modulate the contribution of each student during training. Experiments on the GlaS and CRAG datasets show that CSDS achieves state-of-the-art performance in low-label settings, with Dice score improvements of up to 1.2% on GlaS and 0.7% on CRAG at 5% labeled data, and 0.7% and 1.4% at 10%. Our code and pre-trained models are available at https://github.com/hieuphamha19/CSDS.
<div id='section'>Paperid: <span id='pid'>53, <a href='https://arxiv.org/pdf/2506.24000.pdf' target='_blank'>https://arxiv.org/pdf/2506.24000.pdf</a></span>   <span><a href='https://github.com/TomSheng21/tta-vlm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.24000">The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) methods have gained significant attention for enhancing the performance of vision-language models (VLMs) such as CLIP during inference, without requiring additional labeled data. However, current TTA researches generally suffer from major limitations such as duplication of baseline results, limited evaluation metrics, inconsistent experimental settings, and insufficient analysis. These problems hinder fair comparisons between TTA methods and obscure their practical strengths and weaknesses. To address these challenges, we introduce TTA-VLM, a comprehensive benchmark for evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7 online TTA methods within a unified and reproducible framework, and evaluates them across 15 widely used datasets. Unlike prior studies focused solely on CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA to assess generality. Beyond classification accuracy, TTA-VLM incorporates various evaluation metrics, including robustness, calibration, out-of-distribution detection, and stability, enabling a more holistic assessment of TTA methods. Through extensive experiments, we find that 1) existing TTA methods produce limited gains compared to the previous pioneering work; 2) current TTA methods exhibit poor collaboration with training-time fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced model trustworthiness. We release TTA-VLM to provide fair comparison and comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the community to develop more reliable and generalizable TTA strategies.
<div id='section'>Paperid: <span id='pid'>54, <a href='https://arxiv.org/pdf/2506.19513.pdf' target='_blank'>https://arxiv.org/pdf/2506.19513.pdf</a></span>   <span><a href='https://github.com/HT86159/Evidential-Conflict' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Huang, Zhekun Liu, Rui Wang, Yang Zhang, Liping Jing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19513">Visual hallucination detection in large vision-language models via evidential conflict</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the remarkable multimodal capabilities of Large Vision-Language Models (LVLMs), discrepancies often occur between visual inputs and textual outputs--a phenomenon we term visual hallucination. This critical reliability gap poses substantial risks in safety-critical Artificial Intelligence (AI) applications, necessitating a comprehensive evaluation benchmark and effective detection methods. Firstly, we observe that existing visual-centric hallucination benchmarks mainly assess LVLMs from a perception perspective, overlooking hallucinations arising from advanced reasoning capabilities. We develop the Perception-Reasoning Evaluation Hallucination (PRE-HAL) dataset, which enables the systematic evaluation of both perception and reasoning capabilities of LVLMs across multiple visual semantics, such as instances, scenes, and relations. Comprehensive evaluation with this new benchmark exposed more visual vulnerabilities, particularly in the more challenging task of relation reasoning. To address this issue, we propose, to the best of our knowledge, the first Dempster-Shafer theory (DST)-based visual hallucination detection method for LVLMs through uncertainty estimation. This method aims to efficiently capture the degree of conflict in high-level features at the model inference phase. Specifically, our approach employs simple mass functions to mitigate the computational complexity of evidence combination on power sets. We conduct an extensive evaluation of state-of-the-art LVLMs, LLaVA-v1.5, mPLUG-Owl2 and mPLUG-Owl3, with the new PRE-HAL benchmark. Experimental results indicate that our method outperforms five baseline uncertainty metrics, achieving average AUROC improvements of 4%, 10%, and 7% across three LVLMs. Our code is available at https://github.com/HT86159/Evidential-Conflict.
<div id='section'>Paperid: <span id='pid'>55, <a href='https://arxiv.org/pdf/2506.09548.pdf' target='_blank'>https://arxiv.org/pdf/2506.09548.pdf</a></span>   <span><a href='https://takuokawara.github.io/RAL2025_project_page/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taku Okawara, Kenji Koide, Aoki Takanose, Shuji Oishi, Masashi Yokozuka, Kentaro Uno, Kazuya Yoshida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09548">Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which is robust to challenging conditions such as featureless environments and deformable terrains. We developed an online learning-based leg kinematics model named the neural leg kinematics model, which incorporates tactile information (foot reaction force) to implicitly express the nonlinear dynamics between robot feet and the ground. Online training of this model enhances its adaptability to weight load changes of a robot (e.g., assuming delivery or transportation tasks) and terrain conditions. According to the \textit{neural adaptive leg odometry factor} and online uncertainty estimation of the leg kinematics model-based motion predictions, we jointly solve online training of this kinematics model and odometry estimation on a unified factor graph to retain the consistency of both. The proposed method was verified through real experiments using a quadruped robot in two challenging situations: 1) a sandy beach, representing an extremely featureless area with a deformable terrain, and 2) a campus, including multiple featureless areas and terrain types of asphalt, gravel (deformable terrain), and grass. Experimental results showed that our odometry estimation incorporating the \textit{neural leg kinematics model} outperforms state-of-the-art works. Our project page is available for further details: https://takuokawara.github.io/RAL2025_project_page/
<div id='section'>Paperid: <span id='pid'>56, <a href='https://arxiv.org/pdf/2506.09460.pdf' target='_blank'>https://arxiv.org/pdf/2506.09460.pdf</a></span>   <span><a href='https://github.com/amir-khb/SSUDOSDG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Amirreza Khoshbakht, Erchan Aptoula
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09460">Evidential Deep Learning with Spectral-Spatial Uncertainty Disentanglement for Open-Set Hyperspectral Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open-set domain generalization(OSDG) for hyperspectral image classification presents significant challenges due to the presence of unknown classes in target domains and the need for models to generalize across multiple unseen domains without target-specific adaptation. Existing domain adaptation methods assume access to target domain data during training and fail to address the fundamental issue of domain shift when unknown classes are present, leading to negative transfer and reduced classification performance. To address these limitations, we propose a novel open-set domain generalization framework that combines four key components: Spectrum-Invariant Frequency Disentanglement (SIFD) for domain-agnostic feature extraction, Dual-Channel Residual Network (DCRN) for robust spectral-spatial feature learning, Evidential Deep Learning (EDL) for uncertainty quantification, and Spectral-Spatial Uncertainty Disentanglement (SSUD) for reliable open-set classification. The SIFD module extracts domain-invariant spectral features in the frequency domain through attention-weighted frequency analysis and domain-agnostic regularization, while DCRN captures complementary spectral and spatial information via parallel pathways with adaptive fusion. EDL provides principled uncertainty estimation using Dirichlet distributions, enabling the SSUD module to make reliable open-set decisions through uncertainty-aware pathway weighting and adaptive rejection thresholding. Experimental results on three cross-scene hyperspectral classification tasks show that our approach achieves performance comparable to state-of-the-art domain adaptation methods while requiring no access to the target domain during training. The implementation will be made available at https://github.com/amir-khb/SSUDOSDG upon acceptance.
<div id='section'>Paperid: <span id='pid'>57, <a href='https://arxiv.org/pdf/2506.09399.pdf' target='_blank'>https://arxiv.org/pdf/2506.09399.pdf</a></span>   <span><a href='https://github.com/workerbcd/ooddcc' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiyu Guo, Zijian Wang, Tan Pan, Brian C. Lovell, Mahsa Baktashmotlagh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09399">Improving Out-of-Distribution Detection via Dynamic Covariance Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is essential for the trustworthiness of AI systems. Methods using prior information (i.e., subspace-based methods) have shown effective performance by extracting information geometry to detect OOD data with a more appropriate distance metric. However, these methods fail to address the geometry distorted by ill-distributed samples, due to the limitation of statically extracting information geometry from the training distribution. In this paper, we argue that the influence of ill-distributed samples can be corrected by dynamically adjusting the prior geometry in response to new data. Based on this insight, we propose a novel approach that dynamically updates the prior covariance matrix using real-time input features, refining its information. Specifically, we reduce the covariance along the direction of real-time input features and constrain adjustments to the residual space, thus preserving essential data characteristics and avoiding effects on unintended directions in the principal space. We evaluate our method on two pre-trained models for the CIFAR dataset and five pre-trained models for ImageNet-1k, including the self-supervised DINO model. Extensive experiments demonstrate that our approach significantly enhances OOD detection across various models. The code is released at https://github.com/workerbcd/ooddcc.
<div id='section'>Paperid: <span id='pid'>58, <a href='https://arxiv.org/pdf/2506.08541.pdf' target='_blank'>https://arxiv.org/pdf/2506.08541.pdf</a></span>   <span><a href='https://traj-flow.github.io/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Yan, Brian Zhang, Yutong Zhang, Daniel Yang, Joshua White, Di Chen, Jiachao Liu, Langechuan Liu, Binnan Zhuang, Shaoshuai Shi, Renjie Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08541">TrajFlow: Multi-modal Motion Prediction via Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient and accurate motion prediction is crucial for ensuring safety and informed decision-making in autonomous driving, particularly under dynamic real-world conditions that necessitate multi-modal forecasts. We introduce TrajFlow, a novel flow matching-based motion prediction framework that addresses the scalability and efficiency challenges of existing generative trajectory prediction methods. Unlike conventional generative approaches that employ i.i.d. sampling and require multiple inference passes to capture diverse outcomes, TrajFlow predicts multiple plausible future trajectories in a single pass, significantly reducing computational overhead while maintaining coherence across predictions. Moreover, we propose a ranking loss based on the Plackett-Luce distribution to improve uncertainty estimation of predicted trajectories. Additionally, we design a self-conditioning training technique that reuses the model's own predictions to construct noisy inputs during a second forward pass, thereby improving generalization and accelerating inference. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across various key metrics, underscoring its effectiveness for safety-critical autonomous driving applications. The code and other details are available on the project website https://traj-flow.github.io/.
<div id='section'>Paperid: <span id='pid'>59, <a href='https://arxiv.org/pdf/2506.07288.pdf' target='_blank'>https://arxiv.org/pdf/2506.07288.pdf</a></span>   <span><a href='https://github.com/SSSKJ/EviNET' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Guan, Haohui Wang, Jian Kang, Lihui Liu, Dawei Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07288">EVINET: Towards Open-World Graph Learning via Evidential Reasoning Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph learning has been crucial to many real-world tasks, but they are often studied with a closed-world assumption, with all possible labels of data known a priori. To enable effective graph learning in an open and noisy environment, it is critical to inform the model users when the model makes a wrong prediction to in-distribution data of a known class, i.e., misclassification detection or when the model encounters out-of-distribution from novel classes, i.e., out-of-distribution detection. This paper introduces Evidential Reasoning Network (EVINET), a framework that addresses these two challenges by integrating Beta embedding within a subjective logic framework. EVINET includes two key modules: Dissonance Reasoning for misclassification detection and Vacuity Reasoning for out-of-distribution detection. Extensive experiments demonstrate that EVINET outperforms state-of-the-art methods across multiple metrics in the tasks of in-distribution classification, misclassification detection, and out-of-distribution detection. EVINET demonstrates the necessity of uncertainty estimation and logical reasoning for misclassification detection and out-of-distribution detection and paves the way for open-world graph learning. Our code and data are available at https://github.com/SSSKJ/EviNET.
<div id='section'>Paperid: <span id='pid'>60, <a href='https://arxiv.org/pdf/2506.06719.pdf' target='_blank'>https://arxiv.org/pdf/2506.06719.pdf</a></span>   <span><a href='https://github.com/pxpana/BIG5OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mufhumudzi Muthivhi, Jiahao Huo, Fredrik Gustafsson, Terence L. van Zyl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06719">Improving Wildlife Out-of-Distribution Detection: Africas Big Five</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mitigating human-wildlife conflict seeks to resolve unwanted encounters between these parties. Computer Vision provides a solution to identifying individuals that might escalate into conflict, such as members of the Big Five African animals. However, environments often contain several varied species. The current state-of-the-art animal classification models are trained under a closed-world assumption. They almost always remain overconfident in their predictions even when presented with unknown classes. This study investigates out-of-distribution (OOD) detection of wildlife, specifically the Big Five. To this end, we select a parametric Nearest Class Mean (NCM) and a non-parametric contrastive learning approach as baselines to take advantage of pretrained and projected features from popular classification encoders. Moreover, we compare our baselines to various common OOD methods in the literature. The results show feature-based methods reflect stronger generalisation capability across varying classification thresholds. Specifically, NCM with ImageNet pre-trained features achieves a 2%, 4% and 22% improvement on AUPR-IN, AUPR-OUT and AUTC over the best OOD methods, respectively. The code can be found here https://github.com/pxpana/BIG5OOD
<div id='section'>Paperid: <span id='pid'>61, <a href='https://arxiv.org/pdf/2506.01205.pdf' target='_blank'>https://arxiv.org/pdf/2506.01205.pdf</a></span>   <span><a href='https://github.com/coastalcph/lm_ambiguity' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonia Karamolegkou, Oliver Eberle, Phillip Rust, Carina Kauf, Anders SÃ¸gaard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01205">Trick or Neat: Adversarial Ambiguity and Language Model Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting ambiguity is important for language understanding, including uncertainty estimation, humour detection, and processing garden path sentences. We assess language models' sensitivity to ambiguity by introducing an adversarial ambiguity dataset that includes syntactic, lexical, and phonological ambiguities along with adversarial variations (e.g., word-order changes, synonym replacements, and random-based alterations). Our findings show that direct prompting fails to robustly identify ambiguity, while linear probes trained on model representations can decode ambiguity with high accuracy, sometimes exceeding 90\%. Our results offer insights into the prompting paradigm and how language models encode ambiguity at different layers. We release both our code and data: https://github.com/coastalcph/lm_ambiguity.
<div id='section'>Paperid: <span id='pid'>62, <a href='https://arxiv.org/pdf/2506.01114.pdf' target='_blank'>https://arxiv.org/pdf/2506.01114.pdf</a></span>   <span><a href='https://github.com/duygunuryldz/uncertainty_in_the_wild' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yavuz Bakman, Duygu Nur Yaldiz, Sungmin Kang, Tuo Zhang, Baturalp Buyukates, Salman Avestimehr, Sai Praneeth Karimireddy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01114">Reconsidering LLM Uncertainty Estimation Methods in the Wild</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Model (LLM) Uncertainty Estimation (UE) methods have become a crucial tool for detecting hallucinations in recent years. While numerous UE methods have been proposed, most existing studies evaluate them in isolated short-form QA settings using threshold-independent metrics such as AUROC or PRR. However, real-world deployment of UE methods introduces several challenges. In this work, we systematically examine four key aspects of deploying UE methods in practical settings. Specifically, we assess (1) the sensitivity of UE methods to decision threshold selection, (2) their robustness to query transformations such as typos, adversarial prompts, and prior chat history, (3) their applicability to long-form generation, and (4) strategies for handling multiple UE scores for a single query. Our evaluations on 19 UE methods reveal that most of them are highly sensitive to threshold selection when there is a distribution shift in the calibration dataset. While these methods generally exhibit robustness against previous chat history and typos, they are significantly vulnerable to adversarial prompts. Additionally, while existing UE methods can be adapted for long-form generation through various strategies, there remains considerable room for improvement. Lastly, ensembling multiple UE scores at test time provides a notable performance boost, which highlights its potential as a practical improvement strategy. Code is available at: https://github.com/duygunuryldz/uncertainty_in_the_wild.
<div id='section'>Paperid: <span id='pid'>63, <a href='https://arxiv.org/pdf/2506.00918.pdf' target='_blank'>https://arxiv.org/pdf/2506.00918.pdf</a></span>   <span><a href='https://github.com/biggzlar/IO-CUE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lennart Bramlage, CristÃ³bal Curio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00918">Principled Input-Output-Conditioned Post-Hoc Uncertainty Estimation for Regression Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is critical in safety-sensitive applications but is often omitted from off-the-shelf neural networks due to adverse effects on predictive performance. Retrofitting uncertainty estimates post-hoc typically requires access to model parameters or gradients, limiting feasibility in practice. We propose a theoretically grounded framework for post-hoc uncertainty estimation in regression tasks by fitting an auxiliary model to both original inputs and frozen model outputs. Drawing from principles of maximum likelihood estimation and sequential parameter fitting, we formalize an exact post-hoc optimization objective that recovers the canonical MLE of Gaussian parameters, without requiring sampling or approximation at inference. While prior work has used model outputs to estimate uncertainty, we explicitly characterize the conditions under which this is valid and demonstrate the extent to which structured outputs can support quasi-epistemic inference. We find that using diverse auxiliary data, such as augmented subsets of the original training data, significantly enhances OOD detection and metric performance. Our hypothesis that frozen model outputs contain generalizable latent information about model error and predictive uncertainty is tested and confirmed. Finally, we ensure that our method maintains proper estimation of input-dependent uncertainty without relying exclusively on base model forecasts. These findings are demonstrated in toy problems and adapted to both UCI and depth regression benchmarks. Code: https://github.com/biggzlar/IO-CUE.
<div id='section'>Paperid: <span id='pid'>64, <a href='https://arxiv.org/pdf/2505.24443.pdf' target='_blank'>https://arxiv.org/pdf/2505.24443.pdf</a></span>   <span><a href='https://github.com/heejokong/DivCon' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Heejo Kong, Sung-Jin Kim, Gunho Jung, Seong-Whan Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.24443">Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional semi-supervised learning (SSL) ideally assumes that labeled and unlabeled data share an identical class distribution, however in practice, this assumption is easily violated, as unlabeled data often includes unknown class data, i.e., outliers. The outliers are treated as noise, considerably degrading the performance of SSL models. To address this drawback, we propose a novel framework, Diversify and Conquer (DAC), to enhance SSL robustness in the context of open-set semi-supervised learning. In particular, we note that existing open-set SSL methods rely on prediction discrepancies between inliers and outliers from a single model trained on labeled data. This approach can be easily failed when the labeled data is insufficient, leading to performance degradation that is worse than naive SSL that do not account for outliers. In contrast, our approach exploits prediction disagreements among multiple models that are differently biased towards the unlabeled distribution. By leveraging the discrepancies arising from training on unlabeled data, our method enables robust outlier detection even when the labeled data is underspecified. Our key contribution is constructing a collection of differently biased models through a single training process. By encouraging divergent heads to be differently biased towards outliers while making consistent predictions for inliers, we exploit the disagreement among these heads as a measure to identify unknown concepts. Our code is available at https://github.com/heejokong/DivCon.
<div id='section'>Paperid: <span id='pid'>65, <a href='https://arxiv.org/pdf/2505.16985.pdf' target='_blank'>https://arxiv.org/pdf/2505.16985.pdf</a></span>   <span><a href='https://github.com/mona4399/FeatureMixing' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Moru Liu, Hao Dong, Jessica Kelly, Olga Fink, Mario Trapp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16985">Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection and segmentation are crucial for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. While prior research has primarily focused on unimodal image data, real-world applications are inherently multimodal, requiring the integration of multiple modalities for improved OOD detection. A key challenge is the lack of supervision signals from unknown data, leading to overconfident predictions on OOD samples. To address this challenge, we propose Feature Mixing, an extremely simple and fast method for multimodal outlier synthesis with theoretical support, which can be further optimized to help the model better distinguish between in-distribution (ID) and OOD data. Feature Mixing is modality-agnostic and applicable to various modality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal dataset for OOD segmentation, featuring synthetic OOD objects across diverse scenes and weather conditions. Extensive experiments on SemanticKITTI, nuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that Feature Mixing achieves state-of-the-art performance with a $10 \times$ to $370 \times$ speedup. Our source code and dataset will be available at https://github.com/mona4399/FeatureMixing.
<div id='section'>Paperid: <span id='pid'>66, <a href='https://arxiv.org/pdf/2505.12842.pdf' target='_blank'>https://arxiv.org/pdf/2505.12842.pdf</a></span>   <span><a href='https://github.com/Wuzheng02/GEM-OODforGUIagents' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheng Wu, Pengzhou Cheng, Zongru Wu, Lingzhong Dong, Zhuosheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12842">GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graphical user interface (GUI) agents have recently emerged as an intriguing paradigm for human-computer interaction, capable of automatically executing user instructions to operate intelligent terminal devices. However, when encountering out-of-distribution (OOD) instructions that violate environmental constraints or exceed the current capabilities of agents, GUI agents may suffer task breakdowns or even pose security threats. Therefore, effective OOD detection for GUI agents is essential. Traditional OOD detection methods perform suboptimally in this domain due to the complex embedding space and evolving GUI environments. In this work, we observe that the in-distribution input semantic space of GUI agents exhibits a clustering pattern with respect to the distance from the centroid. Based on the finding, we propose GEM, a novel method based on fitting a Gaussian mixture model over input embedding distances extracted from the GUI agent that reflect its capability boundary. Evaluated on eight datasets spanning smartphones, computers, and web browsers, our method achieves an average accuracy improvement of 23.70\% over the best-performing baseline while only increasing training time by 4.9\% and testing time by 6.5\%. We also experimentally demonstrate that GEM can improve the step-wise success rate by 9.40\% by requesting assistance from the cloud model when encountering OOD samples. Analysis verifies the generalization ability of our method through experiments on nine different backbones. The codes are available at https://github.com/Wuzheng02/GEM-OODforGUIagents.
<div id='section'>Paperid: <span id='pid'>67, <a href='https://arxiv.org/pdf/2505.06843.pdf' target='_blank'>https://arxiv.org/pdf/2505.06843.pdf</a></span>   <span><a href='https://github.com/GuanZihan/Benign-Samples-Matter' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06843">Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent studies have uncovered a troubling vulnerability in the fine-tuning stage of large language models (LLMs): even fine-tuning on entirely benign datasets can lead to a significant increase in the harmfulness of LLM outputs. Building on this finding, our red teaming study takes this threat one step further by developing a more effective attack. Specifically, we analyze and identify samples within benign datasets that contribute most to safety degradation, then fine-tune LLMs exclusively on these samples. We approach this problem from an outlier detection perspective and propose Self-Inf-N, to detect and extract outliers for fine-tuning. Our findings reveal that fine-tuning LLMs on 100 outlier samples selected by Self-Inf-N in the benign datasets severely compromises LLM safety alignment. Extensive experiments across seven mainstream LLMs demonstrate that our attack exhibits high transferability across different architectures and remains effective in practical scenarios. Alarmingly, our results indicate that most existing mitigation strategies fail to defend against this attack, underscoring the urgent need for more robust alignment safeguards. Codes are available at https://github.com/GuanZihan/Benign-Samples-Matter.
<div id='section'>Paperid: <span id='pid'>68, <a href='https://arxiv.org/pdf/2505.04046.pdf' target='_blank'>https://arxiv.org/pdf/2505.04046.pdf</a></span>   <span><a href='https://github.com/Willy1005/2025-IJCAI-RDML' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuyang Wang, Siyuan Duan, Qizhi Li, Guiduo Duan, Yuan Sun, Dezhong Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04046">Reliable Disentanglement Multi-view Learning Against View Adversarial Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trustworthy multi-view learning has attracted extensive attention because evidence learning can provide reliable uncertainty estimation to enhance the credibility of multi-view predictions. Existing trusted multi-view learning methods implicitly assume that multi-view data is secure. However, in safety-sensitive applications such as autonomous driving and security monitoring, multi-view data often faces threats from adversarial perturbations, thereby deceiving or disrupting multi-view models. This inevitably leads to the adversarial unreliability problem (AUP) in trusted multi-view learning. To overcome this tricky problem, we propose a novel multi-view learning framework, namely Reliable Disentanglement Multi-view Learning (RDML). Specifically, we first propose evidential disentanglement learning to decompose each view into clean and adversarial parts under the guidance of corresponding evidences, which is extracted by a pretrained evidence extractor. Then, we employ the feature recalibration module to mitigate the negative impact of adversarial perturbations and extract potential informative features from them. Finally, to further ignore the irreparable adversarial interferences, a view-level evidential attention mechanism is designed. Extensive experiments on multi-view classification tasks with adversarial attacks show that RDML outperforms the state-of-the-art methods by a relatively large margin. Our code is available at https://github.com/Willy1005/2025-IJCAI-RDML.
<div id='section'>Paperid: <span id='pid'>69, <a href='https://arxiv.org/pdf/2505.03494.pdf' target='_blank'>https://arxiv.org/pdf/2505.03494.pdf</a></span>   <span><a href='https://github.com/chenzhao2023/UPMAD_Net_BrainSeg' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanyuan Jia, Ni Yao, Danyang Sun, Chuang Han, Yanting Li, Jiaofen Nan, Fubao Zhu, Chen Zhao, Weihua Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03494">UPMAD-Net: A Brain Tumor Segmentation Network with Uncertainty Guidance and Adaptive Multimodal Feature Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Brain tumor segmentation has a significant impact on the diagnosis and treatment of brain tumors. Accurate brain tumor segmentation remains challenging due to their irregular shapes, vague boundaries, and high variability. Objective: We propose a brain tumor segmentation method that combines deep learning with prior knowledge derived from a region-growing algorithm. Methods: The proposed method utilizes a multi-scale feature fusion (MSFF) module and adaptive attention mechanisms (AAM) to extract multi-scale features and capture global contextual information. To enhance the model's robustness in low-confidence regions, the Monte Carlo Dropout (MC Dropout) strategy is employed for uncertainty estimation. Results: Extensive experiments demonstrate that the proposed method achieves superior performance on Brain Tumor Segmentation (BraTS) datasets, significantly outperforming various state-of-the-art methods. On the BraTS2021 dataset, the test Dice scores are 89.18% for Enhancing Tumor (ET) segmentation, 93.67% for Whole Tumor (WT) segmentation, and 91.23% for Tumor Core (TC) segmentation. On the BraTS2019 validation set, the validation Dice scores are 87.43%, 90.92%, and 90.40% for ET, WT, and TC segmentation, respectively. Ablation studies further confirmed the contribution of each module to segmentation accuracy, indicating that each component played a vital role in overall performance improvement. Conclusion: This study proposed a novel 3D brain tumor segmentation network based on the U-Net architecture. By incorporating the prior knowledge and employing the uncertainty estimation method, the robustness and performance were improved. The code for the proposed method is available at https://github.com/chenzhao2023/UPMAD_Net_BrainSeg.
<div id='section'>Paperid: <span id='pid'>70, <a href='https://arxiv.org/pdf/2504.07793.pdf' target='_blank'>https://arxiv.org/pdf/2504.07793.pdf</a></span>   <span><a href='https://github.com/limchaos/Likelihood-OOD.git' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/limchaos/Likelihood-OOD.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Ding, Arturas Aleksandraus, Amirhossein Ahmadian, Jonas Unger, Fredrik Lindsten, Gabriel Eilertsen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07793">Revisiting Likelihood-Based Out-of-Distribution Detection by Modeling Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical for ensuring the reliability of deep learning systems, particularly in safety-critical applications. Likelihood-based deep generative models have historically faced criticism for their unsatisfactory performance in OOD detection, often assigning higher likelihood to OOD data than in-distribution samples when applied to image data. In this work, we demonstrate that likelihood is not inherently flawed. Rather, several properties in the images space prohibit likelihood as a valid detection score. Given a sufficiently good likelihood estimator, specifically using the probability flow formulation of a diffusion model, we show that likelihood-based methods can still perform on par with state-of-the-art methods when applied in the representation space of pre-trained encoders. The code of our work can be found at $\href{https://github.com/limchaos/Likelihood-OOD.git}{\texttt{https://github.com/limchaos/Likelihood-OOD.git}}$.
<div id='section'>Paperid: <span id='pid'>71, <a href='https://arxiv.org/pdf/2504.03915.pdf' target='_blank'>https://arxiv.org/pdf/2504.03915.pdf</a></span>   <span><a href='https://github.com/AIDC-rPPG/RF-Net' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rufei Ma, Chao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03915">RF-BayesPhysNet: A Bayesian rPPG Uncertainty Estimation Method for Complex Scenarios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Remote photoplethysmography (rPPG) technology infers heart rate by capturing subtle color changes in facial skin
  using a camera, demonstrating great potential in non-contact heart rate measurement. However, measurement
  accuracy significantly decreases in complex scenarios such as lighting changes and head movements compared
  to ideal laboratory conditions. Existing deep learning models often neglect the quantification of measurement
  uncertainty, limiting their credibility in dynamic scenes. To address the issue of insufficient rPPG measurement
  reliability in complex scenarios, this paper introduces Bayesian neural networks to the rPPG field for the first time,
  proposing the Robust Fusion Bayesian Physiological Network (RF-BayesPhysNet), which can model both aleatoric
  and epistemic uncertainty. It leverages variational inference to balance accuracy and computational efficiency.
  Due to the current lack of uncertainty estimation metrics in the rPPG field, this paper also proposes a new set of
  methods, using Spearman correlation coefficient, prediction interval coverage, and confidence interval width, to
  measure the effectiveness of uncertainty estimation methods under different noise conditions. Experiments show
  that the model, with only double the parameters compared to traditional network models, achieves a MAE of 2.56
  on the UBFC-RPPG dataset, surpassing most models. It demonstrates good uncertainty estimation capability
  in no-noise and low-noise conditions, providing prediction confidence and significantly enhancing robustness in
  real-world applications. We have open-sourced the code at https://github.com/AIDC-rPPG/RF-Net
<div id='section'>Paperid: <span id='pid'>72, <a href='https://arxiv.org/pdf/2504.01957.pdf' target='_blank'>https://arxiv.org/pdf/2504.01957.pdf</a></span>   <span><a href='https://hcis-lab.github.io/GaussianLSS/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shu-Wei Lu, Yi-Hsuan Tsai, Yi-Ting Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01957">Toward Real-world BEV Perception: Depth Uncertainty Estimation via Gaussian Splatting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bird's-eye view (BEV) perception has gained significant attention because it provides a unified representation to fuse multiple view images and enables a wide range of down-stream autonomous driving tasks, such as forecasting and planning. Recent state-of-the-art models utilize projection-based methods which formulate BEV perception as query learning to bypass explicit depth estimation. While we observe promising advancements in this paradigm, they still fall short of real-world applications because of the lack of uncertainty modeling and expensive computational requirement. In this work, we introduce GaussianLSS, a novel uncertainty-aware BEV perception framework that revisits unprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm, and enhances them with depth un-certainty modeling. GaussianLSS represents spatial dispersion by learning a soft depth mean and computing the variance of the depth distribution, which implicitly captures object extents. We then transform the depth distribution into 3D Gaussians and rasterize them to construct uncertainty-aware BEV features. We evaluate GaussianLSS on the nuScenes dataset, achieving state-of-the-art performance compared to unprojection-based methods. In particular, it provides significant advantages in speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory compared to projection-based methods, while achieving competitive performance with only a 0.4% IoU difference.
<div id='section'>Paperid: <span id='pid'>73, <a href='https://arxiv.org/pdf/2503.22719.pdf' target='_blank'>https://arxiv.org/pdf/2503.22719.pdf</a></span>   <span><a href='https://github.com/sarahmart/LLM-ABS-ARMMAN-prediction' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarah Martinson, Lingkai Kong, Cheol Woo Kim, Aparna Taneja, Milind Tambe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22719">LLM-based Agent Simulation for Maternal Health Interventions: Uncertainty Estimation and Decision-focused Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Agent-based simulation is crucial for modeling complex human behavior, yet traditional approaches require extensive domain knowledge and large datasets. In data-scarce healthcare settings where historic and counterfactual data are limited, large language models (LLMs) offer a promising alternative by leveraging broad world knowledge. This study examines an LLM-driven simulation of a maternal mobile health program, predicting beneficiaries' listening behavior when they receive health information via automated messages (control) or live representatives (intervention). Since uncertainty quantification is critical for decision-making in health interventions, we propose an LLM epistemic uncertainty estimation method based on binary entropy across multiple samples. We enhance model robustness through ensemble approaches, improving F1 score and model calibration compared to individual models. Beyond direct evaluation, we take a decision-focused approach, demonstrating how LLM predictions inform intervention feasibility and trial implementation in data-limited settings. The proposed method extends to public health, disaster response, and other domains requiring rapid intervention assessment under severe data constraints. All code and prompts used for this work can be found at https://github.com/sarahmart/LLM-ABS-ARMMAN-prediction.
<div id='section'>Paperid: <span id='pid'>74, <a href='https://arxiv.org/pdf/2503.21338.pdf' target='_blank'>https://arxiv.org/pdf/2503.21338.pdf</a></span>   <span><a href='https://github.com/nubot-nudt/UGNA-VPR' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/nubot-nudt/UGNA-VPR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yehui Shen, Lei Zhang, Qingqiu Li, Xiongwei Zhao, Yue Wang, Huimin Lu, Xieyuanli Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.21338">UGNA-VPR: A Novel Training Paradigm for Visual Place Recognition Based on Uncertainty-Guided NeRF Augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual place recognition (VPR) is crucial for robots to identify previously visited locations, playing an important role in autonomous navigation in both indoor and outdoor environments. However, most existing VPR datasets are limited to single-viewpoint scenarios, leading to reduced recognition accuracy, particularly in multi-directional driving or feature-sparse scenes. Moreover, obtaining additional data to mitigate these limitations is often expensive. This paper introduces a novel training paradigm to improve the performance of existing VPR networks by enhancing multi-view diversity within current datasets through uncertainty estimation and NeRF-based data augmentation. Specifically, we initially train NeRF using the existing VPR dataset. Then, our devised self-supervised uncertainty estimation network identifies places with high uncertainty. The poses of these uncertain places are input into NeRF to generate new synthetic observations for further training of VPR networks. Additionally, we propose an improved storage method for efficient organization of augmented and original training data. We conducted extensive experiments on three datasets and tested three different VPR backbone networks. The results demonstrate that our proposed training paradigm significantly improves VPR performance by fully utilizing existing data, outperforming other training approaches. We further validated the effectiveness of our approach on self-recorded indoor and outdoor datasets, consistently demonstrating superior results. Our dataset and code have been released at \href{https://github.com/nubot-nudt/UGNA-VPR}{https://github.com/nubot-nudt/UGNA-VPR}.
<div id='section'>Paperid: <span id='pid'>75, <a href='https://arxiv.org/pdf/2503.18363.pdf' target='_blank'>https://arxiv.org/pdf/2503.18363.pdf</a></span>   <span><a href='https://wen-yuan-zhang.github.io/MonoInstance/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenyuan Zhang, Yixiao Yang, Han Huang, Liang Han, Kanle Shi, Yu-Shen Liu, Zhizhong Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18363">MonoInstance: Enhancing Monocular Priors via Multi-view Instance Alignment for Neural Rendering and Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monocular depth priors have been widely adopted by neural rendering in multi-view based tasks such as 3D reconstruction and novel view synthesis. However, due to the inconsistent prediction on each view, how to more effectively leverage monocular cues in a multi-view context remains a challenge. Current methods treat the entire estimated depth map indiscriminately, and use it as ground truth supervision, while ignoring the inherent inaccuracy and cross-view inconsistency in monocular priors. To resolve these issues, we propose MonoInstance, a general approach that explores the uncertainty of monocular depths to provide enhanced geometric priors for neural rendering and reconstruction. Our key insight lies in aligning each segmented instance depths from multiple views within a common 3D space, thereby casting the uncertainty estimation of monocular depths into a density measure within noisy point clouds. For high-uncertainty areas where depth priors are unreliable, we further introduce a constraint term that encourages the projected instances to align with corresponding instance masks on nearby views. MonoInstance is a versatile strategy which can be seamlessly integrated into various multi-view neural rendering frameworks. Our experimental results demonstrate that MonoInstance significantly improves the performance in both reconstruction and novel view synthesis under various benchmarks.
<div id='section'>Paperid: <span id='pid'>76, <a href='https://arxiv.org/pdf/2503.17125.pdf' target='_blank'>https://arxiv.org/pdf/2503.17125.pdf</a></span>   <span><a href='https://lamour-rl.github.io/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chan Kim, Seung-Woo Seo, Seong-Woo Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17125">LaMOuR: Leveraging Language Models for Out-of-Distribution Recovery in Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Reinforcement Learning (DRL) has demonstrated strong performance in robotic control but remains susceptible to out-of-distribution (OOD) states, often resulting in unreliable actions and task failure. While previous methods have focused on minimizing or preventing OOD occurrences, they largely neglect recovery once an agent encounters such states. Although the latest research has attempted to address this by guiding agents back to in-distribution states, their reliance on uncertainty estimation hinders scalability in complex environments. To overcome this limitation, we introduce Language Models for Out-of-Distribution Recovery (LaMOuR), which enables recovery learning without relying on uncertainty estimation. LaMOuR generates dense reward codes that guide the agent back to a state where it can successfully perform its original task, leveraging the capabilities of LVLMs in image description, logical reasoning, and code generation. Experimental results show that LaMOuR substantially enhances recovery efficiency across diverse locomotion tasks and even generalizes effectively to complex environments, including humanoid locomotion and mobile manipulation, where existing methods struggle. The code and supplementary materials are available at https://lamour-rl.github.io/.
<div id='section'>Paperid: <span id='pid'>77, <a href='https://arxiv.org/pdf/2503.16707.pdf' target='_blank'>https://arxiv.org/pdf/2503.16707.pdf</a></span>   <span><a href='https://github.com/TyroneLi/CUA_O3D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinlong Li, Cristiano Saltori, Fabio Poiesi, Nicu Sebe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16707">Cross-Modal and Uncertainty-Aware Agglomeration for Open-Vocabulary 3D Scene Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The lack of a large-scale 3D-text corpus has led recent works to distill open-vocabulary knowledge from vision-language models (VLMs). However, these methods typically rely on a single VLM to align the feature spaces of 3D models within a common language space, which limits the potential of 3D models to leverage the diverse spatial and semantic capabilities encapsulated in various foundation models. In this paper, we propose Cross-modal and Uncertainty-aware Agglomeration for Open-vocabulary 3D Scene Understanding dubbed CUA-O3D, the first model to integrate multiple foundation models-such as CLIP, DINOv2, and Stable Diffusion-into 3D scene understanding. We further introduce a deterministic uncertainty estimation to adaptively distill and harmonize the heterogeneous 2D feature embeddings from these models. Our method addresses two key challenges: (1) incorporating semantic priors from VLMs alongside the geometric knowledge of spatially-aware vision foundation models, and (2) using a novel deterministic uncertainty estimation to capture model-specific uncertainties across diverse semantic and geometric sensitivities, helping to reconcile heterogeneous representations during training. Extensive experiments on ScanNetV2 and Matterport3D demonstrate that our method not only advances open-vocabulary segmentation but also achieves robust cross-domain alignment and competitive spatial perception capabilities. The code will be available at: https://github.com/TyroneLi/CUA_O3D.
<div id='section'>Paperid: <span id='pid'>78, <a href='https://arxiv.org/pdf/2503.16247.pdf' target='_blank'>https://arxiv.org/pdf/2503.16247.pdf</a></span>   <span><a href='https://github.com/remic-othr/OpenMIBOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Max Gutbrod, David Rauber, Danilo Weber Nunes, Christoph Palm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16247">OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing reliance on Artificial Intelligence (AI) in critical domains such as healthcare demands robust mechanisms to ensure the trustworthiness of these systems, especially when faced with unexpected or anomalous inputs. This paper introduces the Open Medical Imaging Benchmarks for Out-Of-Distribution Detection (OpenMIBOOD), a comprehensive framework for evaluating out-of-distribution (OOD) detection methods specifically in medical imaging contexts. OpenMIBOOD includes three benchmarks from diverse medical domains, encompassing 14 datasets divided into covariate-shifted in-distribution, near-OOD, and far-OOD categories. We evaluate 24 post-hoc methods across these benchmarks, providing a standardized reference to advance the development and fair comparison of OOD detection methods. Results reveal that findings from broad-scale OOD benchmarks in natural image domains do not translate to medical applications, underscoring the critical need for such benchmarks in the medical field. By mitigating the risk of exposing AI models to inputs outside their training distribution, OpenMIBOOD aims to support the advancement of reliable and trustworthy AI systems in healthcare. The repository is available at https://github.com/remic-othr/OpenMIBOOD.
<div id='section'>Paperid: <span id='pid'>79, <a href='https://arxiv.org/pdf/2503.15801.pdf' target='_blank'>https://arxiv.org/pdf/2503.15801.pdf</a></span>   <span><a href='https://github.com/ryeii/CDRM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyu An, Zhibo Hou, Wan Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15801">Disentangling Uncertainties by Learning Compressed Data Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study aleatoric and epistemic uncertainty estimation in a learned regressive system dynamics model. Disentangling aleatoric uncertainty (the inherent randomness of the system) from epistemic uncertainty (the lack of data) is crucial for downstream tasks such as risk-aware control and reinforcement learning, efficient exploration, and robust policy transfer. While existing approaches like Gaussian Processes, Bayesian networks, and model ensembles are widely adopted, they suffer from either high computational complexity or inaccurate uncertainty estimation. To address these limitations, we propose the Compressed Data Representation Model (CDRM), a framework that learns a neural network encoding of the data distribution and enables direct sampling from the output distribution. Our approach incorporates a novel inference procedure based on Langevin dynamics sampling, allowing CDRM to predict arbitrary output distributions rather than being constrained to a Gaussian prior. Theoretical analysis provides the conditions where CDRM achieves better memory and computational complexity compared to bin-based compression methods. Empirical evaluations show that CDRM demonstrates a superior capability to identify aleatoric and epistemic uncertainties separately, achieving AUROCs of 0.8876 and 0.9981 on a single test set containing a mixture of both uncertainties. Qualitative results further show that CDRM's capability extends to datasets with multimodal output distributions, a challenging scenario where existing methods consistently fail. Code and supplementary materials are available at https://github.com/ryeii/CDRM.
<div id='section'>Paperid: <span id='pid'>80, <a href='https://arxiv.org/pdf/2503.14832.pdf' target='_blank'>https://arxiv.org/pdf/2503.14832.pdf</a></span>   <span><a href='https://github.com/YuhangLiuu/H2ST' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/YuhangLiuu/H2ST' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhang Liu, Wenjie Zhao, Yunhui Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14832">H2ST: Hierarchical Two-Sample Tests for Continual Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Task Incremental Learning (TIL) is a specialized form of Continual Learning (CL) in which a model incrementally learns from non-stationary data streams. Existing TIL methodologies operate under the closed-world assumption, presuming that incoming data remains in-distribution (ID). However, in an open-world setting, incoming samples may originate from out-of-distribution (OOD) sources, with their task identities inherently unknown. Continually detecting OOD samples presents several challenges for current OOD detection methods: reliance on model outputs leads to excessive dependence on model performance, selecting suitable thresholds is difficult, hindering real-world deployment, and binary ID/OOD classification fails to provide task-level identification. To address these issues, we propose a novel continual OOD detection method called the Hierarchical Two-sample Tests (H2ST). H2ST eliminates the need for threshold selection through hypothesis testing and utilizes feature maps to better exploit model capabilities without excessive dependence on model performance. The proposed hierarchical architecture enables task-level detection with superior performance and lower overhead compared to non-hierarchical classifier two-sample tests. Extensive experiments and analysis validate the effectiveness of H2ST in open-world TIL scenarios and its superiority to the existing methods. Code is available at \href{https://github.com/YuhangLiuu/H2ST}{https://github.com/YuhangLiuu/H2ST}.
<div id='section'>Paperid: <span id='pid'>81, <a href='https://arxiv.org/pdf/2503.10605.pdf' target='_blank'>https://arxiv.org/pdf/2503.10605.pdf</a></span>   <span><a href='https://github.com/ika-rwth-aachen/OCCUQ' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Severin Heidrich, Till Beemelmanns, Alexey Nekrasov, Bastian Leibe, Lutz Eckstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10605">OCCUQ: Exploring Efficient Uncertainty Quantification for 3D Occupancy Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving has the potential to significantly enhance productivity and provide numerous societal benefits. Ensuring robustness in these safety-critical systems is essential, particularly when vehicles must navigate adverse weather conditions and sensor corruptions that may not have been encountered during training. Current methods often overlook uncertainties arising from adversarial conditions or distributional shifts, limiting their real-world applicability. We propose an efficient adaptation of an uncertainty estimation technique for 3D occupancy prediction. Our method dynamically calibrates model confidence using epistemic uncertainty estimates. Our evaluation under various camera corruption scenarios, such as fog or missing cameras, demonstrates that our approach effectively quantifies epistemic uncertainty by assigning higher uncertainty values to unseen data. We introduce region-specific corruptions to simulate defects affecting only a single camera and validate our findings through both scene-level and region-level assessments. Our results show superior performance in Out-of-Distribution (OoD) detection and confidence calibration compared to common baselines such as Deep Ensembles and MC-Dropout. Our approach consistently demonstrates reliable uncertainty measures, indicating its potential for enhancing the robustness of autonomous driving systems in real-world scenarios. Code and dataset are available at https://github.com/ika-rwth-aachen/OCCUQ .
<div id='section'>Paperid: <span id='pid'>82, <a href='https://arxiv.org/pdf/2503.07082.pdf' target='_blank'>https://arxiv.org/pdf/2503.07082.pdf</a></span>   <span><a href='https://github.com/Orion-AI-Lab/EOUncertaintyGeneralization' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Spyros Kondylatos, Nikolaos Ioannis Bountos, Dimitrios Michail, Xiao Xiang Zhu, Gustau Camps-Valls, Ioannis Papoutsis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07082">On the Generalization of Representation Uncertainty in Earth Observation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Computer Vision have introduced the concept of pretrained representation uncertainty, enabling zero-shot uncertainty estimation. This holds significant potential for Earth Observation (EO), where trustworthiness is critical, yet the complexity of EO data poses challenges to uncertainty-aware methods. In this work, we investigate the generalization of representation uncertainty in EO, considering the domain's unique semantic characteristics. We pretrain uncertainties on large EO datasets and propose an evaluation framework to assess their zero-shot performance in multi-label classification and segmentation EO tasks. Our findings reveal that, unlike uncertainties pretrained on natural images, EO-pretraining exhibits strong generalization across unseen EO domains, geographic locations, and target granularities, while maintaining sensitivity to variations in ground sampling distance. We demonstrate the practical utility of pretrained uncertainties showcasing their alignment with task-specific uncertainties in downstream tasks, their sensitivity to real-world EO image noise, and their ability to generate spatial uncertainty estimates out-of-the-box. Initiating the discussion on representation uncertainty in EO, our study provides insights into its strengths and limitations, paving the way for future research in the field. Code and weights are available at: https://github.com/Orion-AI-Lab/EOUncertaintyGeneralization.
<div id='section'>Paperid: <span id='pid'>83, <a href='https://arxiv.org/pdf/2503.01020.pdf' target='_blank'>https://arxiv.org/pdf/2503.01020.pdf</a></span>   <span><a href='https://github.com/PyJulie/Medical-VLMs-OOD-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lie Ju, Sijin Zhou, Yukun Zhou, Huimin Lu, Zhuoting Zhu, Pearse A. Keane, Zongyuan Ge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.01020">Delving into Out-of-Distribution Detection with Medical Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in medical vision-language models (VLMs) demonstrate impressive performance in image classification tasks, driven by their strong zero-shot generalization capabilities. However, given the high variability and complexity inherent in medical imaging data, the ability of these models to detect out-of-distribution (OOD) data in this domain remains underexplored. In this work, we conduct the first systematic investigation into the OOD detection potential of medical VLMs. We evaluate state-of-the-art VLM-based OOD detection methods across a diverse set of medical VLMs, including both general and domain-specific purposes. To accurately reflect real-world challenges, we introduce a cross-modality evaluation pipeline for benchmarking full-spectrum OOD detection, rigorously assessing model robustness against both semantic shifts and covariate shifts. Furthermore, we propose a novel hierarchical prompt-based method that significantly enhances OOD detection performance. Extensive experiments are conducted to validate the effectiveness of our approach. The codes are available at https://github.com/PyJulie/Medical-VLMs-OOD-Detection.
<div id='section'>Paperid: <span id='pid'>84, <a href='https://arxiv.org/pdf/2502.19755.pdf' target='_blank'>https://arxiv.org/pdf/2502.19755.pdf</a></span>   <span><a href='https://github.com/hugo0076/HALO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hugo Lyons Keenan, Sarah Erfani, Christopher Leckie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19755">HALO: Robust Out-of-Distribution Detection via Joint Optimisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective out-of-distribution (OOD) detection is crucial for the safe deployment of machine learning models in real-world scenarios. However, recent work has shown that OOD detection methods are vulnerable to adversarial attacks, potentially leading to critical failures in high-stakes applications. This discovery has motivated work on robust OOD detection methods that are capable of maintaining performance under various attack settings. Prior approaches have made progress on this problem but face a number of limitations: often only exhibiting robustness to attacks on OOD data or failing to maintain strong clean performance. In this work, we adapt an existing robust classification framework, TRADES, extending it to the problem of robust OOD detection and discovering a novel objective function. Recognising the critical importance of a strong clean/robust trade-off for OOD detection, we introduce an additional loss term which boosts classification and detection performance. Our approach, called HALO (Helper-based AdversariaL OOD detection), surpasses existing methods and achieves state-of-the-art performance across a number of datasets and attack settings. Extensive experiments demonstrate an average AUROC improvement of 3.15 in clean settings and 7.07 under adversarial attacks when compared to the next best method. Furthermore, HALO exhibits resistance to transferred attacks, offers tuneable performance through hyperparameter selection, and is compatible with existing OOD detection frameworks out-of-the-box, leaving open the possibility of future performance gains. Code is available at: https://github.com/hugo0076/HALO
<div id='section'>Paperid: <span id='pid'>85, <a href='https://arxiv.org/pdf/2502.17912.pdf' target='_blank'>https://arxiv.org/pdf/2502.17912.pdf</a></span>   <span><a href='https://github.com/draym28/DeGEM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhan Chen, Yihong Luo, Yifan Song, Pengwen Dai, Jing Tang, Xiaochun Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17912">Decoupled Graph Energy-based Model for Node Out-of-Distribution Detection on Heterophilic Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite extensive research efforts focused on OOD detection on images, OOD detection on nodes in graph learning remains underexplored. The dependence among graph nodes hinders the trivial adaptation of existing approaches on images that assume inputs to be i.i.d. sampled, since many unique features and challenges specific to graphs are not considered, such as the heterophily issue. Recently, GNNSafe, which considers node dependence, adapted energy-based detection to the graph domain with state-of-the-art performance, however, it has two serious issues: 1) it derives node energy from classification logits without specifically tailored training for modeling data distribution, making it less effective at recognizing OOD data; 2) it highly relies on energy propagation, which is based on homophily assumption and will cause significant performance degradation on heterophilic graphs, where the node tends to have dissimilar distribution with its neighbors. To address the above issues, we suggest training EBMs by MLE to enhance data distribution modeling and remove energy propagation to overcome the heterophily issues. However, training EBMs via MLE requires performing MCMC sampling on both node feature and node neighbors, which is challenging due to the node interdependence and discrete graph topology. To tackle the sampling challenge, we introduce DeGEM, which decomposes the learning process into two parts: a graph encoder that leverages topology information for node representations and an energy head that operates in latent space. Extensive experiments validate that DeGEM, without OOD exposure during training, surpasses previous state-of-the-art methods, achieving an average AUROC improvement of 6.71% on homophilic graphs and 20.29% on heterophilic graphs, and even outperform methods trained with OOD exposure. Our code is available at: https://github.com/draym28/DeGEM.
<div id='section'>Paperid: <span id='pid'>86, <a href='https://arxiv.org/pdf/2502.16824.pdf' target='_blank'>https://arxiv.org/pdf/2502.16824.pdf</a></span>   <span><a href='https://github.com/umkiyoung/DiBO' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/umkiyoung/DiBO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeyoung Yun, Kiyoung Om, Jaewoo Lee, Sujin Yun, Jinkyoo Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16824">Posterior Inference with Diffusion Models for High-dimensional Black-box Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimizing high-dimensional and complex black-box functions is crucial in numerous scientific applications. While Bayesian optimization (BO) is a powerful method for sample-efficient optimization, it struggles with the curse of dimensionality and scaling to thousands of evaluations. Recently, leveraging generative models to solve black-box optimization problems has emerged as a promising framework. However, those methods often underperform compared to BO methods due to limited expressivity and difficulty of uncertainty estimation in high-dimensional spaces. To overcome these issues, we introduce \textbf{DiBO}, a novel framework for solving high-dimensional black-box optimization problems. Our method iterates two stages. First, we train a diffusion model to capture the data distribution and deep ensembles to predict function values with uncertainty quantification. Second, we cast the candidate selection as a posterior inference problem to balance exploration and exploitation in high-dimensional spaces. Concretely, we fine-tune diffusion models to amortize posterior inference. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines across synthetic and real-world tasks. Our code is publicly available \href{https://github.com/umkiyoung/DiBO}{here}.
<div id='section'>Paperid: <span id='pid'>87, <a href='https://arxiv.org/pdf/2502.12849.pdf' target='_blank'>https://arxiv.org/pdf/2502.12849.pdf</a></span>   <span><a href='https://github.com/gigug/LIR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gianluca Guglielmo, Marc Masana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12849">Leveraging Intermediate Representations for Better Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world applications, machine learning models must reliably detect Out-of-Distribution (OoD) samples to prevent unsafe decisions. Current OoD detection methods often rely on analyzing the logits or the embeddings of the penultimate layer of a neural network. However, little work has been conducted on the exploitation of the rich information encoded in intermediate layers. To address this, we analyze the discriminative power of intermediate layers and show that they can positively be used for OoD detection. Therefore, we propose to regularize intermediate layers with an energy-based contrastive loss, and by grouping multiple layers in a single aggregated response. We demonstrate that intermediate layer activations improves OoD detection performance by running a comprehensive evaluation across multiple datasets.
<div id='section'>Paperid: <span id='pid'>88, <a href='https://arxiv.org/pdf/2502.12713.pdf' target='_blank'>https://arxiv.org/pdf/2502.12713.pdf</a></span>   <span><a href='https://github.com/ThierryJudge/contouring-uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Thierry Judge, Olivier Bernard, Woo-Jin Cho Kim, Alberto Gomez, Arian Beqiri, Agisilaos Chartsias, Pierre-Marc Jodoin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12713">Uncertainty Propagation for Echocardiography Clinical Metric Estimation via Contour Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Echocardiography plays a fundamental role in the extraction of important clinical parameters (e.g. left ventricular volume and ejection fraction) required to determine the presence and severity of heart-related conditions. When deploying automated techniques for computing these parameters, uncertainty estimation is crucial for assessing their utility. Since clinical parameters are usually derived from segmentation maps, there is no clear path for converting pixel-wise uncertainty values into uncertainty estimates in the downstream clinical metric calculation. In this work, we propose a novel uncertainty estimation method based on contouring rather than segmentation. Our method explicitly predicts contour location uncertainty from which contour samples can be drawn. Finally, the sampled contours can be used to propagate uncertainty to clinical metrics. Our proposed method not only provides accurate uncertainty estimations for the task of contouring but also for the downstream clinical metrics on two cardiac ultrasound datasets. Code is available at: https://github.com/ThierryJudge/contouring-uncertainty.
<div id='section'>Paperid: <span id='pid'>89, <a href='https://arxiv.org/pdf/2502.11638.pdf' target='_blank'>https://arxiv.org/pdf/2502.11638.pdf</a></span>   <span><a href='https://github.com/dlotfi/MedOODFlow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dariush Lotfi, Mohammad-Ali Nikouei Mahani, Mohamad Koohi-Moghadam, Kyongtae Ty Bae
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11638">Safeguarding AI in Medical Imaging: Post-Hoc Out-of-Distribution Detection with Normalizing Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In AI-driven medical imaging, the failure to detect out-of-distribution (OOD) data poses a severe risk to clinical reliability, potentially leading to critical diagnostic errors. Current OOD detection methods often demand impractical retraining or modifications to pre-trained models, hindering their adoption in regulated clinical environments. To address this challenge, we propose a post-hoc normalizing flow-based approach that seamlessly integrates with existing pre-trained models without altering their weights. Our evaluation used a novel in-house built dataset, MedOOD, meticulously curated to simulate clinically relevant distributional shifts, alongside the MedMNIST benchmark dataset. On our in-house MedOOD dataset, our method achieved an AUROC of 84.61%, outperforming state-of-the-art methods like ViM (80.65%) and MDS (80.87%). Similarly, on MedMNIST, it reached an exceptional AUROC of 93.8%, surpassing leading approaches such as ViM (88.08%) and ReAct (87.05%). This superior performance, coupled with its post-hoc integration capability, positions our method as a vital safeguard for enhancing safety in medical imaging workflows. The model and code to build OOD datasets are publicly accessible at https://github.com/dlotfi/MedOODFlow.
<div id='section'>Paperid: <span id='pid'>90, <a href='https://arxiv.org/pdf/2502.10691.pdf' target='_blank'>https://arxiv.org/pdf/2502.10691.pdf</a></span>   <span><a href='https://yousuf907.github.io/ncoodg' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Yousuf Harun, Jhair Gallardo, Christopher Kanan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.10691">Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection and OOD generalization are widely studied in Deep Neural Networks (DNNs), yet their relationship remains poorly understood. We empirically show that the degree of Neural Collapse (NC) in a network layer is inversely related with these objectives: stronger NC improves OOD detection but degrades generalization, while weaker NC enhances generalization at the cost of detection. This trade-off suggests that a single feature space cannot simultaneously achieve both tasks. To address this, we develop a theoretical framework linking NC to OOD detection and generalization. We show that entropy regularization mitigates NC to improve generalization, while a fixed Simplex Equiangular Tight Frame (ETF) projector enforces NC for better detection. Based on these insights, we propose a method to control NC at different DNN layers. In experiments, our method excels at both tasks across OOD datasets and DNN architectures. Code for our experiments is available at: https://yousuf907.github.io/ncoodg
<div id='section'>Paperid: <span id='pid'>91, <a href='https://arxiv.org/pdf/2502.09824.pdf' target='_blank'>https://arxiv.org/pdf/2502.09824.pdf</a></span>   <span><a href='https://onurbagoren.github.io/PUGS/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Onur Bagoren, Marc Micatka, Katherine A. Skinner, Aaron Marburg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09824">PUGS: Perceptual Uncertainty for Grasp Selection in Underwater Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When navigating and interacting in challenging environments where sensory information is imperfect and incomplete, robots must make decisions that account for these shortcomings. We propose a novel method for quantifying and representing such perceptual uncertainty in 3D reconstruction through occupancy uncertainty estimation. We develop a framework to incorporate it into grasp selection for autonomous manipulation in underwater environments. Instead of treating each measurement equally when deciding which location to grasp from, we present a framework that propagates uncertainty inherent in the multi-view reconstruction process into the grasp selection. We evaluate our method with both simulated and the real world data, showing that by accounting for uncertainty, the grasp selection becomes robust against partial and noisy measurements. Code will be made available at https://onurbagoren.github.io/PUGS/
<div id='section'>Paperid: <span id='pid'>92, <a href='https://arxiv.org/pdf/2502.08695.pdf' target='_blank'>https://arxiv.org/pdf/2502.08695.pdf</a></span>   <span><a href='https://github.com/rwl93/bnp4ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Randolph W. Linderman, Yiran Chen, Scott W. Linderman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08695">A Bayesian Nonparametric Perspective on Mahalanobis Distance for Out of Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian nonparametric methods are naturally suited to the problem of out-of-distribution (OOD) detection. However, these techniques have largely been eschewed in favor of simpler methods based on distances between pre-trained or learned embeddings of data points. Here we show a formal relationship between Bayesian nonparametric models and the relative Mahalanobis distance score (RMDS), a commonly used method for OOD detection. Building on this connection, we propose Bayesian nonparametric mixture models with hierarchical priors that generalize the RMDS. We evaluate these models on the OpenOOD detection benchmark and show that Bayesian nonparametric methods can improve upon existing OOD methods, especially in regimes where training classes differ in their covariance structure and where there are relatively few data points per class.
<div id='section'>Paperid: <span id='pid'>93, <a href='https://arxiv.org/pdf/2502.08105.pdf' target='_blank'>https://arxiv.org/pdf/2502.08105.pdf</a></span>   <span><a href='https://github.com/ca1man-2022/Awesome-GOOD-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingyi Cai, Yunliang Jiang, Yixin Liu, Ming Li, Changqin Huang, Shirui Pan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08105">Out-of-Distribution Detection on Graphs: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph machine learning has witnessed rapid growth, driving advancements across diverse domains. However, the in-distribution assumption, where training and testing data share the same distribution, often breaks in real-world scenarios, leading to degraded model performance under distribution shifts. This challenge has catalyzed interest in graph out-of-distribution (GOOD) detection, which focuses on identifying graph data that deviates from the distribution seen during training, thereby enhancing model robustness. In this paper, we provide a rigorous definition of GOOD detection and systematically categorize existing methods into four types: enhancement-based, reconstruction-based, information propagation-based, and classification-based approaches. We analyze the principles and mechanisms of each approach and clarify the distinctions between GOOD detection and related fields, such as graph anomaly detection, outlier detection, and GOOD generalization. Beyond methodology, we discuss practical applications and theoretical foundations, highlighting the unique challenges posed by graph data. Finally, we discuss the primary challenges and propose future directions to advance this emerging field. The repository of this survey is available at https://github.com/ca1man-2022/Awesome-GOOD-Detection.
<div id='section'>Paperid: <span id='pid'>94, <a href='https://arxiv.org/pdf/2502.06351.pdf' target='_blank'>https://arxiv.org/pdf/2502.06351.pdf</a></span>   <span><a href='https://github.com/sandylaker/ib-edl' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yawei Li, David RÃ¼gamer, Bernd Bischl, Mina Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06351">Calibrating LLMs with Information-Theoretic Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fine-tuned large language models (LLMs) often exhibit overconfidence, particularly when trained on small datasets, resulting in poor calibration and inaccurate uncertainty estimates. Evidential Deep Learning (EDL), an uncertainty-aware approach, enables uncertainty estimation in a single forward pass, making it a promising method for calibrating fine-tuned LLMs. However, despite its computational efficiency, EDL is prone to overfitting, as its training objective can result in overly concentrated probability distributions. To mitigate this, we propose regularizing EDL by incorporating an information bottleneck (IB). Our approach IB-EDL suppresses spurious information in the evidence generated by the model and encourages truly predictive information to influence both the predictions and uncertainty estimates. Extensive experiments across various fine-tuned LLMs and tasks demonstrate that IB-EDL outperforms both existing EDL and non-EDL approaches. By improving the trustworthiness of LLMs, IB-EDL facilitates their broader adoption in domains requiring high levels of confidence calibration. Code is available at https://github.com/sandylaker/ib-edl.
<div id='section'>Paperid: <span id='pid'>95, <a href='https://arxiv.org/pdf/2502.05964.pdf' target='_blank'>https://arxiv.org/pdf/2502.05964.pdf</a></span>   <span><a href='https://github.com/jhornauer/GrUMoDepth' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Julia Hornauer, Amir El-Ghoussani, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05964">Revisiting Gradient-based Uncertainty for Monocular Depth Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monocular depth estimation, similar to other image-based tasks, is prone to erroneous predictions due to ambiguities in the image, for example, caused by dynamic objects or shadows. For this reason, pixel-wise uncertainty assessment is required for safety-critical applications to highlight the areas where the prediction is unreliable. We address this in a post hoc manner and introduce gradient-based uncertainty estimation for already trained depth estimation models. To extract gradients without depending on the ground truth depth, we introduce an auxiliary loss function based on the consistency of the predicted depth and a reference depth. The reference depth, which acts as pseudo ground truth, is in fact generated using a simple image or feature augmentation, making our approach simple and effective. To obtain the final uncertainty score, the derivatives w.r.t. the feature maps from single or multiple layers are calculated using back-propagation. We demonstrate that our gradient-based approach is effective in determining the uncertainty without re-training using the two standard depth estimation benchmarks KITTI and NYU. In particular, for models trained with monocular sequences and therefore most prone to uncertainty, our method outperforms related approaches. In addition, we publicly provide our code and models: https://github.com/jhornauer/GrUMoDepth
<div id='section'>Paperid: <span id='pid'>96, <a href='https://arxiv.org/pdf/2502.03946.pdf' target='_blank'>https://arxiv.org/pdf/2502.03946.pdf</a></span>   <span><a href='https://github.com/datasciapps/CleanSurvival' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yousef Koka, David Selby, Gerrit GroÃmann, Sebastian Vollmer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03946">CleanSurvival: Automated data preprocessing for time-to-event models using reinforcement learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data preprocessing is a critical yet frequently neglected aspect of machine learning, often paid little attention despite its potentially significant impact on model performance. While automated machine learning pipelines are starting to recognize and integrate data preprocessing into their solutions for classification and regression tasks, this integration is lacking for more specialized tasks like survival or time-to-event models. As a result, survival analysis not only faces the general challenges of data preprocessing but also suffers from the lack of tailored, automated solutions in this area.
  To address this gap, this paper presents 'CleanSurvival', a reinforcement-learning-based solution for optimizing preprocessing pipelines, extended specifically for survival analysis. The framework can handle continuous and categorical variables, using Q-learning to select which combination of data imputation, outlier detection and feature extraction techniques achieves optimal performance for a Cox, random forest, neural network or user-supplied time-to-event model. The package is available on GitHub: https://github.com/datasciapps/CleanSurvival
  Experimental benchmarks on real-world datasets show that the Q-learning-based data preprocessing results in superior predictive performance to standard approaches, finding such a model up to 10 times faster than undirected random grid search. Furthermore, a simulation study demonstrates the effectiveness in different types and levels of missingness and noise in the data.
<div id='section'>Paperid: <span id='pid'>97, <a href='https://arxiv.org/pdf/2501.18463.pdf' target='_blank'>https://arxiv.org/pdf/2501.18463.pdf</a></span>   <span><a href='https://github.com/hoshi23/OOD-X-Benchmarks' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiho Noda, Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18463">A Benchmark and Evaluation for Real-World Out-of-Distribution Detection Using Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a task that detects OOD samples during inference to ensure the safety of deployed models. However, conventional benchmarks have reached performance saturation, making it difficult to compare recent OOD detection methods. To address this challenge, we introduce three novel OOD detection benchmarks that enable a deeper understanding of method characteristics and reflect real-world conditions. First, we present ImageNet-X, designed to evaluate performance under challenging semantic shifts. Second, we propose ImageNet-FS-X for full-spectrum OOD detection, assessing robustness to covariate shifts (feature distribution shifts). Finally, we propose Wilds-FS-X, which extends these evaluations to real-world datasets, offering a more comprehensive testbed. Our experiments reveal that recent CLIP-based OOD detection methods struggle to varying degrees across the three proposed benchmarks, and none of them consistently outperforms the others. We hope the community goes beyond specific benchmarks and includes more challenging conditions reflecting real-world scenarios. The code is https://github.com/hoshi23/OOD-X-Benchmarks.
<div id='section'>Paperid: <span id='pid'>98, <a href='https://arxiv.org/pdf/2501.17289.pdf' target='_blank'>https://arxiv.org/pdf/2501.17289.pdf</a></span>   <span><a href='https://github.com/rohban-lab/CTS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mojtaba Nafez, Moein Madadi, Arad Maleki, Mahdi Hajialilue, Zeinab Sadat Taghavi, Sepehr Rezaee, Ali Ansari, Bahar Dibaei Nia, Kian Shamsaie, Mohammadreza Salehi, Mackenzie W. Mathis, Mahdieh Soleymani Baghshah, Mohammad Sabokrou, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17289">A Contrastive Teacher-Student Framework for Novelty Detection under Style Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There have been several efforts to improve Novelty Detection (ND) performance. However, ND methods often suffer significant performance drops under minor distribution shifts caused by changes in the environment, known as style shifts. This challenge arises from the ND setup, where the absence of out-of-distribution (OOD) samples during training causes the detector to be biased toward the dominant style features in the in-distribution (ID) data. As a result, the model mistakenly learns to correlate style with core features, using this shortcut for detection. Robust ND is crucial for real-world applications like autonomous driving and medical imaging, where test samples may have different styles than the training data. Motivated by this, we propose a robust ND method that crafts an auxiliary OOD set with style features similar to the ID set but with different core features. Then, a task-based knowledge distillation strategy is utilized to distinguish core features from style features and help our model rely on core features for discriminating crafted OOD and ID sets. We verified the effectiveness of our method through extensive experimental evaluations on several datasets, including synthetic and real-world benchmarks, against nine different ND methods.
<div id='section'>Paperid: <span id='pid'>99, <a href='https://arxiv.org/pdf/2501.16971.pdf' target='_blank'>https://arxiv.org/pdf/2501.16971.pdf</a></span>   <span><a href='https://github.com/rohban-lab/RODEO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mohammad Jafari, Hamid Reza Dehbashi, Ali Ansari, Sepehr Ghobadi, Masoud Hadi, Arshia Soltani Moakhar, Mohammad Azizmalayeri, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16971">RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, there have been significant improvements in various forms of image outlier detection. However, outlier detection performance under adversarial settings lags far behind that in standard settings. This is due to the lack of effective exposure to adversarial scenarios during training, especially on unseen outliers, leading to detection models failing to learn robust features. To bridge this gap, we introduce RODEO, a data-centric approach that generates effective outliers for robust outlier detection. More specifically, we show that incorporating outlier exposure (OE) and adversarial training can be an effective strategy for this purpose, as long as the exposed training outliers meet certain characteristics, including diversity, and both conceptual differentiability and analogy to the inlier samples. We leverage a text-to-image model to achieve this goal. We demonstrate both quantitatively and qualitatively that our adaptive OE method effectively generates ``diverse'' and ``near-distribution'' outliers, leveraging information from both text and image domains. Moreover, our experimental results show that utilizing our synthesized outliers significantly enhances the performance of the outlier detector, particularly in adversarial settings.
<div id='section'>Paperid: <span id='pid'>100, <a href='https://arxiv.org/pdf/2501.15271.pdf' target='_blank'>https://arxiv.org/pdf/2501.15271.pdf</a></span>   <span><a href='https://github.com/rohban-lab/ZARND' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mohammad Jafari, Hamid Reza Dehbashi, Zeinab Sadat Taghavi, Mohammad Sabokrou, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15271">Killing it with Zero-Shot: Adversarially Robust Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty Detection (ND) plays a crucial role in machine learning by identifying new or unseen data during model inference. This capability is especially important for the safe and reliable operation of automated systems. Despite advances in this field, existing techniques often fail to maintain their performance when subject to adversarial attacks. Our research addresses this gap by marrying the merits of nearest-neighbor algorithms with robust features obtained from models pretrained on ImageNet. We focus on enhancing the robustness and performance of ND algorithms. Experimental results demonstrate that our approach significantly outperforms current state-of-the-art methods across various benchmarks, particularly under adversarial conditions. By incorporating robust pretrained features into the k-NN algorithm, we establish a new standard for performance and robustness in the field of robust ND. This work opens up new avenues for research aimed at fortifying machine learning systems against adversarial vulnerabilities. Our implementation is publicly available at https://github.com/rohban-lab/ZARND.
<div id='section'>Paperid: <span id='pid'>101, <a href='https://arxiv.org/pdf/2501.12835.pdf' target='_blank'>https://arxiv.org/pdf/2501.12835.pdf</a></span>   <span><a href='https://github.com/s-nlp/AdaRAGUE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Viktor Moskvoretskii, Maria Lysyuk, Mikhail Salnikov, Nikolay Ivanov, Sergey Pletenev, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Irina Nikishina, Alexander Panchenko
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12835">Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Retrieval Augmented Generation (RAG) improves correctness of Question Answering (QA) and addresses hallucinations in Large Language Models (LLMs), yet greatly increase computational costs. Besides, RAG is not always needed as may introduce irrelevant information. Recent adaptive retrieval methods integrate LLMs' intrinsic knowledge with external information appealing to LLM self-knowledge, but they often neglect efficiency evaluations and comparisons with uncertainty estimation techniques. We bridge this gap by conducting a comprehensive analysis of 35 adaptive retrieval methods, including 8 recent approaches and 27 uncertainty estimation techniques, across 6 datasets using 10 metrics for QA performance, self-knowledge, and efficiency. Our findings show that uncertainty estimation techniques often outperform complex pipelines in terms of efficiency and self-knowledge, while maintaining comparable QA performance.
<div id='section'>Paperid: <span id='pid'>102, <a href='https://arxiv.org/pdf/2501.11258.pdf' target='_blank'>https://arxiv.org/pdf/2501.11258.pdf</a></span>   <span><a href='https://github.com/talze/frequency-dropout' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tal Zeevi, Lawrence H. Staib, John A. Onofrey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11258">Enhancing Uncertainty Estimation in Semantic Segmentation via Monte-Carlo Frequency Dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monte-Carlo (MC) Dropout provides a practical solution for estimating predictive distributions in deterministic neural networks. Traditional dropout, applied within the signal space, may fail to account for frequency-related noise common in medical imaging, leading to biased predictive estimates. A novel approach extends Dropout to the frequency domain, allowing stochastic attenuation of signal frequencies during inference. This creates diverse global textural variations in feature maps while preserving structural integrity -- a factor we hypothesize and empirically show is contributing to accurately estimating uncertainties in semantic segmentation. We evaluated traditional MC-Dropout and the MC-frequency Dropout in three segmentation tasks involving different imaging modalities: (i) prostate zones in biparametric MRI, (ii) liver tumors in contrast-enhanced CT, and (iii) lungs in chest X-ray scans. Our results show that MC-Frequency Dropout improves calibration, convergence, and semantic uncertainty, thereby improving prediction scrutiny, boundary delineation, and has the potential to enhance medical decision-making.
<div id='section'>Paperid: <span id='pid'>103, <a href='https://arxiv.org/pdf/2501.06999.pdf' target='_blank'>https://arxiv.org/pdf/2501.06999.pdf</a></span>   <span><a href='https://github.com/lihenryhfl/pcdm' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/lihenryhfl/pcdm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Henry Li, Ronen Basri, Yuval Kluger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06999">Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cascaded models are multi-scale generative models with a marked capacity for producing perceptually impressive samples at high resolutions. In this work, we show that they can also be excellent likelihood models, so long as we overcome a fundamental difficulty with probabilistic multi-scale models: the intractability of the likelihood function. Chiefly, in cascaded models each intermediary scale introduces extraneous variables that cannot be tractably marginalized out for likelihood evaluation. This issue vanishes by modeling the diffusion process on latent spaces induced by a class of transformations we call hierarchical volume-preserving maps, which decompose spatially structured data in a hierarchical fashion without introducing local distortions in the latent space. We demonstrate that two such maps are well-known in the literature for multiscale modeling: Laplacian pyramids and wavelet transforms. Not only do such reparameterizations allow the likelihood function to be directly expressed as a joint likelihood over the scales, we show that the Laplacian pyramid and wavelet transform also produces significant improvements to the state-of-the-art on a selection of benchmarks in likelihood modeling, including density estimation, lossless compression, and out-of-distribution detection. Investigating the theoretical basis of our empirical gains we uncover deep connections to score matching under the Earth Mover's Distance (EMD), which is a well-known surrogate for perceptual similarity. Code can be found at \href{https://github.com/lihenryhfl/pcdm}{this https url}.
<div id='section'>Paperid: <span id='pid'>104, <a href='https://arxiv.org/pdf/2501.05656.pdf' target='_blank'>https://arxiv.org/pdf/2501.05656.pdf</a></span>   <span><a href='https://github.com/FAIR4HEP/PFIN4UQAD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ayush Khot, Xiwei Wang, Avik Roy, Volodymyr Kindratenko, Mark S. Neubauer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05656">Evidential Deep Learning for Uncertainty Quantification and Out-of-Distribution Detection in Jet Identification using Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current methods commonly used for uncertainty quantification (UQ) in deep learning (DL) models utilize Bayesian methods which are computationally expensive and time-consuming. In this paper, we provide a detailed study of UQ based on evidential deep learning (EDL) for deep neural network models designed to identify jets in high energy proton-proton collisions at the Large Hadron Collider and explore its utility in anomaly detection. EDL is a DL approach that treats learning as an evidence acquisition process designed to provide confidence (or epistemic uncertainty) about test data. Using publicly available datasets for jet classification benchmarking, we explore hyperparameter optimizations for EDL applied to the challenge of UQ for jet identification. We also investigate how the uncertainty is distributed for each jet class, how this method can be implemented for the detection of anomalies, how the uncertainty compares with Bayesian ensemble methods, and how the uncertainty maps onto latent spaces for the models. Our studies uncover some pitfalls of EDL applied to anomaly detection and a more effective way to quantify uncertainty from EDL as compared with the foundational EDL setup. These studies illustrate a methodological approach to interpreting EDL in jet classification models, providing new insights on how EDL quantifies uncertainty and detects out-of-distribution data which may lead to improved EDL methods for DL models applied to classification tasks.
<div id='section'>Paperid: <span id='pid'>105, <a href='https://arxiv.org/pdf/2501.02975.pdf' target='_blank'>https://arxiv.org/pdf/2501.02975.pdf</a></span>   <span><a href='https://github.com/Xiaofeng-Tan/MGBOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Gao, Xiaofeng Tan, Jie Zhou, Weiping Ding, Witold Pedrycz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02975">Fuzzy Granule Density-Based Outlier Detection with Multi-Scale Granular Balls</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection refers to the identification of anomalous samples that deviate significantly from the distribution of normal data and has been extensively studied and used in a variety of practical tasks. However, most unsupervised outlier detection methods are carefully designed to detect specified outliers, while real-world data may be entangled with different types of outliers. In this study, we propose a fuzzy rough sets-based multi-scale outlier detection method to identify various types of outliers. Specifically, a novel fuzzy rough sets-based method that integrates relative fuzzy granule density is first introduced to improve the capability of detecting local outliers. Then, a multi-scale view generation method based on granular-ball computing is proposed to collaboratively identify group outliers at different levels of granularity. Moreover, reliable outliers and inliers determined by the three-way decision are used to train a weighted support vector machine to further improve the performance of outlier detection. The proposed method innovatively transforms unsupervised outlier detection into a semi-supervised classification problem and for the first time explores the fuzzy rough sets-based outlier detection from the perspective of multi-scale granular balls, allowing for high adaptability to different types of outliers. Extensive experiments carried out on both artificial and UCI datasets demonstrate that the proposed outlier detection method significantly outperforms the state-of-the-art methods, improving the results by at least 8.48% in terms of the Area Under the ROC Curve (AUROC) index. { The source codes are released at \url{https://github.com/Xiaofeng-Tan/MGBOD}. }
<div id='section'>Paperid: <span id='pid'>106, <a href='https://arxiv.org/pdf/2501.01816.pdf' target='_blank'>https://arxiv.org/pdf/2501.01816.pdf</a></span>   <span><a href='https://github.com/mobei1006/AMY' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hu Ding, Yan Yan, Yang Lu, Jing-Hao Xue, Hanzi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01816">Uncertainty-Aware Label Refinement on Hypergraphs for Personalized Federated Facial Expression Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most facial expression recognition (FER) models are trained on large-scale expression data with centralized learning. Unfortunately, collecting a large amount of centralized expression data is difficult in practice due to privacy concerns of facial images. In this paper, we investigate FER under the framework of personalized federated learning, which is a valuable and practical decentralized setting for real-world applications. To this end, we develop a novel uncertainty-Aware label refineMent on hYpergraphs (AMY) method. For local training, each local model consists of a backbone, an uncertainty estimation (UE) block, and an expression classification (EC) block. In the UE block, we leverage a hypergraph to model complex high-order relationships between expression samples and incorporate these relationships into uncertainty features. A personalized uncertainty estimator is then introduced to estimate reliable uncertainty weights of samples in the local client. In the EC block, we perform label propagation on the hypergraph, obtaining high-quality refined labels for retraining an expression classifier. Based on the above, we effectively alleviate heterogeneous sample uncertainty across clients and learn a robust personalized FER model in each client. Experimental results on two challenging real-world facial expression databases show that our proposed method consistently outperforms several state-of-the-art methods. This indicates the superiority of hypergraph modeling for uncertainty estimation and label refinement on the personalized federated FER task. The source code will be released at https://github.com/mobei1006/AMY.
<div id='section'>Paperid: <span id='pid'>107, <a href='https://arxiv.org/pdf/2412.16884.pdf' target='_blank'>https://arxiv.org/pdf/2412.16884.pdf</a></span>   <span><a href='https://github.com/gmr523/pop' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingrong Gong, Chaoqi Chen, Qingqiang Sun, Yue Wang, Hui Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16884">Out-of-Distribution Detection with Prototypical Outlier Proxy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a crucial task for deploying deep learning models in the wild. One of the major challenges is that well-trained deep models tend to perform over-confidence on unseen test data. Recent research attempts to leverage real or synthetic outliers to mitigate the issue, which may significantly increase computational costs and be biased toward specific outlier characteristics. In this paper, we propose a simple yet effective framework, Prototypical Outlier Proxy (POP), which introduces virtual OOD prototypes to reshape the decision boundaries between ID and OOD data. Specifically, we transform the learnable classifier into a fixed one and augment it with a set of prototypical weight vectors. Then, we introduce a hierarchical similarity boundary loss to impose adaptive penalties depending on the degree of misclassification. Extensive experiments across various benchmarks demonstrate the effectiveness of POP. Notably, POP achieves average FPR95 reductions of 7.70%, 6.30%, and 5.42% over the second-best methods on CIFAR-10, CIFAR-100, and ImageNet-200, respectively. Moreover, compared to the recent method NPOS, which relies on outlier synthesis, POP trains 7.2X faster and performs inference 19.5X faster. The source code is available at: https://github.com/gmr523/pop.
<div id='section'>Paperid: <span id='pid'>108, <a href='https://arxiv.org/pdf/2412.15844.pdf' target='_blank'>https://arxiv.org/pdf/2412.15844.pdf</a></span>   <span><a href='https://github.com/mikkoim/taxonomist-studio' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mikko ImpiÃ¶, Philipp M. Rehsen, Jenni Raitoharju
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15844">Efficient Curation of Invertebrate Image Datasets Using Feature Embeddings and Automatic Size Comparison</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The amount of image datasets collected for environmental monitoring purposes has increased in the past years as computer vision assisted methods have gained interest. Computer vision applications rely on high-quality datasets, making data curation important. However, data curation is often done ad-hoc and the methods used are rarely published. We present a method for curating large-scale image datasets of invertebrates that contain multiple images of the same taxa and/or specimens and have relatively uniform background in the images. Our approach is based on extracting feature embeddings with pretrained deep neural networks, and using these embeddings to find visually most distinct images by comparing their embeddings to the group prototype embedding. Also, we show that a simple area-based size comparison approach is able to find a lot of common erroneous images, such as images containing detached body parts and misclassified samples. In addition to the method, we propose using novel metrics for evaluating human-in-the-loop outlier detection methods. The implementations of the proposed curation methods, as well as a benchmark dataset containing annotated erroneous images, are publicly available in https://github.com/mikkoim/taxonomist-studio.
<div id='section'>Paperid: <span id='pid'>109, <a href='https://arxiv.org/pdf/2412.13394.pdf' target='_blank'>https://arxiv.org/pdf/2412.13394.pdf</a></span>   <span><a href='https://github.com/microsoft/geospatial-ood-detection' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/microsoft/geospatial-ood-detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Burak Ekim, Girmaw Abebe Tadesse, Caleb Robinson, Gilles Hacheme, Michael Schmitt, Rahul Dodhia, Juan M. Lavista Ferres
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13394">Distribution Shifts at Scale: Out-of-distribution Detection in Earth Observation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training robust deep learning models is crucial in Earth Observation, where globally deployed models often face distribution shifts that degrade performance, especially in low-data regions. Out-of-distribution (OOD) detection addresses this by identifying inputs that deviate from in-distribution (ID) data. However, existing methods either assume access to OOD data or compromise primary task performance, limiting real-world use. We introduce TARDIS, a post-hoc OOD detection method designed for scalable geospatial deployment. Our core innovation lies in generating surrogate distribution labels by leveraging ID data within the feature space. TARDIS takes a pre-trained model, ID data, and data from an unknown distribution (WILD), separates WILD into surrogate ID and OOD labels based on internal activations, and trains a binary classifier to detect distribution shifts. We validate on EuroSAT and xBD across 17 setups covering covariate and semantic shifts, showing near-upper-bound surrogate labeling performance in 13 cases and matching the performance of top post-hoc activation- and scoring-based methods. Finally, deploying TARDIS on Fields of the World reveals actionable insights into pre-trained model behavior at scale. The code is available at \href{https://github.com/microsoft/geospatial-ood-detection}{https://github.com/microsoft/geospatial-ood-detection}
<div id='section'>Paperid: <span id='pid'>110, <a href='https://arxiv.org/pdf/2412.12453.pdf' target='_blank'>https://arxiv.org/pdf/2412.12453.pdf</a></span>   <span><a href='https://github.com/thuiar/MIntOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanlei Zhang, Qianrui Zhou, Hua Xu, Jianhua Su, Roberto Evans, Kai Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12453">Multimodal Classification and Out-of-distribution Detection for Multimodal Intent Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal intent understanding is a significant research area that requires effective leveraging of multiple modalities to analyze human language. Existing methods face two main challenges in this domain. Firstly, they have limitations in capturing the nuanced and high-level semantics underlying complex in-distribution (ID) multimodal intents. Secondly, they exhibit poor generalization when confronted with unseen out-of-distribution (OOD) data in real-world scenarios. To address these issues, we propose a novel method for both ID classification and OOD detection (MIntOOD). We first introduce a weighted feature fusion network that models multimodal representations. This network dynamically learns the importance of each modality, adapting to multimodal contexts. To develop discriminative representations for both tasks, we synthesize pseudo-OOD data from convex combinations of ID data and engage in multimodal representation learning from both coarse-grained and fine-grained perspectives. The coarse-grained perspective focuses on distinguishing between ID and OOD binary classes, while the fine-grained perspective not only enhances the discrimination between different ID classes but also captures instance-level interactions between ID and OOD samples, promoting proximity among similar instances and separation from dissimilar ones. We establish baselines for three multimodal intent datasets and build an OOD benchmark. Extensive experiments on these datasets demonstrate that our method significantly improves OOD detection performance with a 3~10% increase in AUROC scores while achieving new state-of-the-art results in ID classification. Data and codes are available at https://github.com/thuiar/MIntOOD.
<div id='section'>Paperid: <span id='pid'>111, <a href='https://arxiv.org/pdf/2412.12154.pdf' target='_blank'>https://arxiv.org/pdf/2412.12154.pdf</a></span>   <span><a href='https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sihan Chen, Zhuangzhuang Qian, Wingchun Siu, Xingcan Hu, Jiaqi Li, Shawn Li, Yuehan Qin, Tiankai Yang, Zhuo Xiao, Wanghao Ye, Yichi Zhang, Yushun Dong, Yue Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12154">PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD), also known as anomaly detection, is a critical machine learning (ML) task with applications in fraud detection, network intrusion detection, clickstream analysis, recommendation systems, and social network moderation. Among open-source libraries for outlier detection, the Python Outlier Detection (PyOD) library is the most widely adopted, with over 8,500 GitHub stars, 25 million downloads, and diverse industry usage. However, PyOD currently faces three limitations: (1) insufficient coverage of modern deep learning algorithms, (2) fragmented implementations across PyTorch and TensorFlow, and (3) no automated model selection, making it hard for non-experts.
  To address these issues, we present PyOD Version 2 (PyOD 2), which integrates 12 state-of-the-art deep learning models into a unified PyTorch framework and introduces a large language model (LLM)-based pipeline for automated OD model selection. These improvements simplify OD workflows, provide access to 45 algorithms, and deliver robust performance on various datasets. In this paper, we demonstrate how PyOD 2 streamlines the deployment and automation of OD models and sets a new standard in both research and industry. PyOD 2 is accessible at [https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod). This study aligns with the Web Mining and Content Analysis track, addressing topics such as the robustness of Web mining methods and the quality of algorithmically-generated Web data.
<div id='section'>Paperid: <span id='pid'>112, <a href='https://arxiv.org/pdf/2412.11466.pdf' target='_blank'>https://arxiv.org/pdf/2412.11466.pdf</a></span>   <span><a href='https://github.com/UESTC-nnLab/MVOL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yutian Lei, Luping Ji, Pei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11466">Mining In-distribution Attributes in Outliers for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is indispensable for deploying reliable machine learning systems in real-world scenarios. Recent works, using auxiliary outliers in training, have shown good potential. However, they seldom concern the intrinsic correlations between in-distribution (ID) and OOD data. In this work, we discover an obvious correlation that OOD data usually possesses significant ID attributes. These attributes should be factored into the training process, rather than blindly suppressed as in previous approaches. Based on this insight, we propose a structured multi-view-based out-of-distribution detection learning (MVOL) framework, which facilitates rational handling of the intrinsic in-distribution attributes in outliers. We provide theoretical insights on the effectiveness of MVOL for OOD detection. Extensive experiments demonstrate the superiority of our framework to others. MVOL effectively utilizes both auxiliary OOD datasets and even wild datasets with noisy in-distribution data. Code is available at https://github.com/UESTC-nnLab/MVOL.
<div id='section'>Paperid: <span id='pid'>113, <a href='https://arxiv.org/pdf/2412.11148.pdf' target='_blank'>https://arxiv.org/pdf/2412.11148.pdf</a></span>   <span><a href='https://github.com/SMSD75/Redefining_Normal_ACCV24/tree/main' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammadreza Salehi, Nikolaos Apostolikas, Efstratios Gavves, Cees G. M. Snoek, Yuki M. Asano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11148">Redefining Normal: A Novel Object-Level Approach for Multi-Object Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the realm of novelty detection, accurately identifying outliers in data without specific class information poses a significant challenge. While current methods excel in single-object scenarios, they struggle with multi-object situations due to their focus on individual objects. Our paper suggests a novel approach: redefining `normal' at the object level in training datasets. Rather than the usual image-level view, we consider the most dominant object in a dataset as the norm, offering a perspective that is more effective for real-world scenarios. Adapting to our object-level definition of `normal', we modify knowledge distillation frameworks, where a student network learns from a pre-trained teacher network. Our first contribution, DeFeND(Dense Feature Fine-tuning on Normal Data), integrates dense feature fine-tuning into the distillation process, allowing the teacher network to focus on object-level features with a self-supervised loss. The second is masked knowledge distillation, where the student network works with partially hidden inputs, honing its ability to deduce and generalize from incomplete data. This approach not only fares well in single-object novelty detection but also considerably surpasses existing methods in multi-object contexts. The implementation is available at: https://github.com/SMSD75/Redefining_Normal_ACCV24/tree/main
<div id='section'>Paperid: <span id='pid'>114, <a href='https://arxiv.org/pdf/2412.08513.pdf' target='_blank'>https://arxiv.org/pdf/2412.08513.pdf</a></span>   <span><a href='https://github.com/Wickstrom/REPEAT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kristoffer K. WickstrÃ¸m, Thea BrÃ¼sch, Michael C. Kampffmeyer, Robert Jenssen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.08513">REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Incorporating uncertainty is crucial to provide trustworthy explanations of deep learning models. Recent works have demonstrated how uncertainty modeling can be particularly important in the unsupervised field of representation learning explainable artificial intelligence (R-XAI). Current R-XAI methods provide uncertainty by measuring variability in the importance score. However, they fail to provide meaningful estimates of whether a pixel is certainly important or not. In this work, we propose a new R-XAI method called REPEAT that addresses the key question of whether or not a pixel is \textit{certainly} important. REPEAT leverages the stochasticity of current R-XAI methods to produce multiple estimates of importance, thus considering each pixel in an image as a Bernoulli random variable that is either important or unimportant. From these Bernoulli random variables we can directly estimate the importance of a pixel and its associated certainty, thus enabling users to determine certainty in pixel importance. Our extensive evaluation shows that REPEAT gives certainty estimates that are more intuitive, better at detecting out-of-distribution data, and more concise.
<div id='section'>Paperid: <span id='pid'>115, <a href='https://arxiv.org/pdf/2412.07169.pdf' target='_blank'>https://arxiv.org/pdf/2412.07169.pdf</a></span>   <span><a href='https://github.com/code-supplement-25/rate-in' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tal Zeevi, Ravid Shwartz-Ziv, Yann LeCun, Lawrence H. Staib, John A. Onofrey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07169">Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty estimation is crucial for deploying neural networks in risk-sensitive applications such as medical diagnosis. Monte Carlo Dropout is a widely used technique for approximating predictive uncertainty by performing stochastic forward passes with dropout during inference. However, using static dropout rates across all layers and inputs can lead to suboptimal uncertainty estimates, as it fails to adapt to the varying characteristics of individual inputs and network layers. Existing approaches optimize dropout rates during training using labeled data, resulting in fixed inference-time parameters that cannot adjust to new data distributions, compromising uncertainty estimates in Monte Carlo simulations.
  In this paper, we propose Rate-In, an algorithm that dynamically adjusts dropout rates during inference by quantifying the information loss induced by dropout in each layer's feature maps. By treating dropout as controlled noise injection and leveraging information-theoretic principles, Rate-In adapts dropout rates per layer and per input instance without requiring ground truth labels. By quantifying the functional information loss in feature maps, we adaptively tune dropout rates to maintain perceptual quality across diverse medical imaging tasks and architectural configurations. Our extensive empirical study on synthetic data and real-world medical imaging tasks demonstrates that Rate-In improves calibration and sharpens uncertainty estimates compared to fixed or heuristic dropout rates without compromising predictive performance. Rate-In offers a practical, unsupervised, inference-time approach to optimizing dropout for more reliable predictive uncertainty estimation in critical applications.
<div id='section'>Paperid: <span id='pid'>116, <a href='https://arxiv.org/pdf/2412.06014.pdf' target='_blank'>https://arxiv.org/pdf/2412.06014.pdf</a></span>   <span><a href='https://aaltoml.github.io/BayesVLM/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Baumann, Rui Li, Marcus Klasson, Santeri Mentu, Shyamgopal Karthik, Zeynep Akata, Arno Solin, Martin Trapp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06014">Post-hoc Probabilistic Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs), such as CLIP and SigLIP, have found remarkable success in classification, retrieval, and generative tasks. For this, VLMs deterministically map images and text descriptions to a joint latent space in which their similarity is assessed using the cosine similarity. However, a deterministic mapping of inputs fails to capture uncertainties over concepts arising from domain shifts when used in downstream tasks. In this work, we propose post-hoc uncertainty estimation in VLMs that does not require additional training. Our method leverages a Bayesian posterior approximation over the last layers in VLMs and analytically quantifies uncertainties over cosine similarities. We demonstrate its effectiveness for uncertainty quantification and support set selection in active learning. Compared to baselines, we obtain improved and well-calibrated predictive uncertainties, interpretable uncertainty estimates, and sample-efficient active learning. Our results show promise for safety-critical applications of large-scale models.
<div id='section'>Paperid: <span id='pid'>117, <a href='https://arxiv.org/pdf/2412.05897.pdf' target='_blank'>https://arxiv.org/pdf/2412.05897.pdf</a></span>   <span><a href='https://github.com/tmlr-group/WePe' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Nie, Yonggang Zhang, Tongliang Liu, Yiu-ming Cheung, Bo Han, Xinmei Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05897">Epistemic Uncertainty for Generated Image Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel framework for AI-generated image detection through epistemic uncertainty, aiming to address critical security concerns in the era of generative models. Our key insight stems from the observation that distributional discrepancies between training and testing data manifest distinctively in the epistemic uncertainty space of machine learning models. In this context, the distribution shift between natural and generated images leads to elevated epistemic uncertainty in models trained on natural images when evaluating generated ones. Hence, we exploit this phenomenon by using epistemic uncertainty as a proxy for detecting generated images. This converts the challenge of generated image detection into the problem of uncertainty estimation, underscoring the generalization performance of the model used for uncertainty estimation. Fortunately, advanced large-scale vision models pre-trained on extensive natural images have shown excellent generalization performance for various scenarios. Thus, we utilize these pre-trained models to estimate the epistemic uncertainty of images and flag those with high uncertainty as generated. Extensive experiments demonstrate the efficacy of our method. Code is available at https://github.com/tmlr-group/WePe.
<div id='section'>Paperid: <span id='pid'>118, <a href='https://arxiv.org/pdf/2412.05723.pdf' target='_blank'>https://arxiv.org/pdf/2412.05723.pdf</a></span>   <span><a href='https://github.com/Wang-ML-Lab/bayesian-peft' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haizhou Shi, Yibin Wang, Ligong Han, Huan Zhang, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05723">Training-Free Bayesianization for Low-Rank Adapters of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating the uncertainty of responses from Large Language Models (LLMs) remains a critical challenge. While recent Bayesian methods have demonstrated effectiveness in quantifying uncertainty through low-rank weight updates, they typically require complex fine-tuning or post-training procedures. In this paper, we propose Training-Free Bayesianization (TFB), a simple yet theoretically grounded framework that efficiently transforms trained low-rank adapters into Bayesian ones without additional training. TFB systematically searches for the maximally acceptable level of variance in the weight posterior, constrained within a family of low-rank isotropic Gaussian distributions. Our theoretical analysis shows that under mild conditions, this search process is equivalent to KL-regularized variational optimization, a generalized form of variational inference. Through comprehensive experiments, we show that TFB achieves superior uncertainty estimation and generalization compared to existing methods while eliminating the need for complex Bayesianization training procedures. Code will be available at https://github.com/Wang-ML-Lab/bayesian-peft.
<div id='section'>Paperid: <span id='pid'>119, <a href='https://arxiv.org/pdf/2412.05292.pdf' target='_blank'>https://arxiv.org/pdf/2412.05292.pdf</a></span>   <span><a href='https://github.com/Cverchen/TagFog' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiankang Chen, Tong Zhang, Wei-Shi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05292">TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial in many real-world applications. However, intelligent models are often trained solely on in-distribution (ID) data, leading to overconfidence when misclassifying OOD data as ID classes. In this study, we propose a new learning framework which leverage simple Jigsaw-based fake OOD data and rich semantic embeddings (`anchors') from the ChatGPT description of ID knowledge to help guide the training of the image encoder. The learning framework can be flexibly combined with existing post-hoc approaches to OOD detection, and extensive empirical evaluations on multiple OOD detection benchmarks demonstrate that rich textual representation of ID knowledge and fake OOD knowledge can well help train a visual encoder for OOD detection. With the learning framework, new state-of-the-art performance was achieved on all the benchmarks. The code is available at \url{https://github.com/Cverchen/TagFog}.
<div id='section'>Paperid: <span id='pid'>120, <a href='https://arxiv.org/pdf/2412.04935.pdf' target='_blank'>https://arxiv.org/pdf/2412.04935.pdf</a></span>   <span><a href='https://github.com/niazoys/RLS_PSDF' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Mohaiminul Islam, Coen de Vente, Bart Liefers, Caroline Klaver, Erik J Bekkers, Clara I. SÃ¡nchez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04935">Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a new approach for uncertainty-aware retinal layer segmentation in Optical Coherence Tomography (OCT) scans using probabilistic signed distance functions (SDF). Traditional pixel-wise and regression-based methods primarily encounter difficulties in precise segmentation and lack of geometrical grounding respectively. To address these shortcomings, our methodology refines the segmentation by predicting a signed distance function (SDF) that effectively parameterizes the retinal layer shape via level set. We further enhance the framework by integrating probabilistic modeling, applying Gaussian distributions to encapsulate the uncertainty in the shape parameterization. This ensures a robust representation of the retinal layer morphology even in the presence of ambiguous input, imaging noise, and unreliable segmentations. Both quantitative and qualitative evaluations demonstrate superior performance when compared to other methods. Additionally, we conducted experiments on artificially distorted datasets with various noise types-shadowing, blinking, speckle, and motion-common in OCT scans to showcase the effectiveness of our uncertainty estimation. Our findings demonstrate the possibility to obtain reliable segmentation of retinal layers, as well as an initial step towards the characterization of layer integrity, a key biomarker for disease progression. Our code is available at \url{https://github.com/niazoys/RLS_PSDF}.
<div id='section'>Paperid: <span id='pid'>121, <a href='https://arxiv.org/pdf/2412.04789.pdf' target='_blank'>https://arxiv.org/pdf/2412.04789.pdf</a></span>   <span><a href='https://github.com/CARG-uOttawa/DrIFT.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fardad Dadboud, Hamid Azad, Varun Mehta, Miodrag Bolic, Iraj Mantegh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04789">DrIFT: Autonomous Drone Dataset with Integrated Real and Synthetic Data, Flexible Views, and Transformed Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dependable visual drone detection is crucial for the secure integration of drones into the airspace. However, drone detection accuracy is significantly affected by domain shifts due to environmental changes, varied points of view, and background shifts. To address these challenges, we present the DrIFT dataset, specifically developed for visual drone detection under domain shifts. DrIFT includes fourteen distinct domains, each characterized by shifts in point of view, synthetic-to-real data, season, and adverse weather. DrIFT uniquely emphasizes background shift by providing background segmentation maps to enable background-wise metrics and evaluation. Our new uncertainty estimation metric, MCDO-map, features lower postprocessing complexity, surpassing traditional methods. We use the MCDO-map in our uncertainty-aware unsupervised domain adaptation method, demonstrating superior performance to SOTA unsupervised domain adaptation techniques. The dataset is available at: https://github.com/CARG-uOttawa/DrIFT.git.
<div id='section'>Paperid: <span id='pid'>122, <a href='https://arxiv.org/pdf/2412.02900.pdf' target='_blank'>https://arxiv.org/pdf/2412.02900.pdf</a></span>   <span><a href='https://github.com/vibujithan/macaw-2D.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Vibujithan Vigneshwaran, Erik Ohara, Matthias Wilms, Nils Forkert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02900">MACAW: A Causal Generative Model for Medical Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although deep learning techniques show promising results for many neuroimaging tasks in research settings, they have not yet found widespread use in clinical scenarios. One of the reasons for this problem is that many machine learning models only identify correlations between the input images and the outputs of interest, which can lead to many practical problems, such as encoding of uninformative biases and reduced explainability. Thus, recent research is exploring if integrating a priori causal knowledge into deep learning models is a potential avenue to identify these problems. This work introduces a new causal generative architecture named Masked Causal Flow (MACAW) for neuroimaging applications. Within this context, three main contributions are described. First, a novel approach that integrates complex causal structures into normalizing flows is proposed. Second, counterfactual prediction is performed to identify the changes in effect variables associated with a cause variable. Finally, an explicit Bayesian inference for classification is derived and implemented, providing an inherent uncertainty estimation. The feasibility of the proposed method was first evaluated using synthetic data and then using MRI brain data from more than 23000 participants of the UK biobank study. The evaluation results show that the proposed method can (1) accurately encode causal reasoning and generate counterfactuals highlighting the structural changes in the brain known to be associated with aging, (2) accurately predict a subject's age from a single 2D MRI slice, and (3) generate new samples assuming other values for subject-specific indicators such as age, sex, and body mass index. The code for a toy dataset is available at the following link: https://github.com/vibujithan/macaw-2D.git.
<div id='section'>Paperid: <span id='pid'>123, <a href='https://arxiv.org/pdf/2412.01590.pdf' target='_blank'>https://arxiv.org/pdf/2412.01590.pdf</a></span>   <span><a href='https://github.com/bhattarailab/NCDD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01590">NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of deep learning tools in gastrointestinal vision holds the potential for significant advancements in diagnosis, treatment, and overall patient care. A major challenge, however, is these tools' tendency to make overconfident predictions, even when encountering unseen or newly emerging disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an out-of-distribution (OOD) detection problem, where previously unseen and emerging diseases are identified as OOD examples. However, gastrointestinal images pose a unique challenge due to the overlapping feature representations between in- Distribution (ID) and OOD examples. Existing approaches often overlook this characteristic, as they are primarily developed for natural image datasets, where feature distinctions are more apparent. Despite the overlap, we hypothesize that the features of an in-distribution example will cluster closer to the centroids of their ground truth class, resulting in a shorter distance to the nearest centroid. In contrast, OOD examples maintain an equal distance from all class centroids. Based on this observation, we propose a novel nearest-centroid distance deficit (NCCD) score in the feature space for gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness of our approach compared to several state-of-the-art methods. The code and implementation details are publicly available at: https://github.com/bhattarailab/NCDD
<div id='section'>Paperid: <span id='pid'>124, <a href='https://arxiv.org/pdf/2412.01250.pdf' target='_blank'>https://arxiv.org/pdf/2412.01250.pdf</a></span>   <span><a href='https://intelligolabs.github.io/CoIN/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesco Taioli, Edoardo Zorzi, Gianni Franchi, Alberto Castellini, Alessandro Farinelli, Marco Cristani, Yiming Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01250">Collaborative Instance Object Navigation: Leveraging Uncertainty-Awareness to Minimize Human-Agent Dialogues</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language-driven instance object navigation assumes that human users initiate the task by providing a detailed description of the target instance to the embodied agent. While this description is crucial for distinguishing the target from visually similar instances in a scene, providing it prior to navigation can be demanding for human. To bridge this gap, we introduce Collaborative Instance object Navigation (CoIN), a new task setting where the agent actively resolve uncertainties about the target instance during navigation in natural, template-free, open-ended dialogues with human. We propose a novel training-free method, Agent-user Interaction with UncerTainty Awareness (AIUTA), which operates independently from the navigation policy, and focuses on the human-agent interaction reasoning with Vision-Language Models (VLMs) and Large Language Models (LLMs). First, upon object detection, a Self-Questioner model initiates a self-dialogue within the agent to obtain a complete and accurate observation description with a novel uncertainty estimation technique. Then, an Interaction Trigger module determines whether to ask a question to the human, continue or halt navigation, minimizing user input. For evaluation, we introduce CoIN-Bench, with a curated dataset designed for challenging multi-instance scenarios. CoIN-Bench supports both online evaluation with humans and reproducible experiments with simulated user-agent interactions. On CoIN-Bench, we show that AIUTA serves as a competitive baseline, while existing language-driven instance navigation methods struggle in complex multi-instance scenes. Code and benchmark will be available upon acceptance at https://intelligolabs.github.io/CoIN/
<div id='section'>Paperid: <span id='pid'>125, <a href='https://arxiv.org/pdf/2412.00984.pdf' target='_blank'>https://arxiv.org/pdf/2412.00984.pdf</a></span>   <span><a href='https://github.com/kayzliu/tgtod' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/kayzliu/tgtod' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kay Liu, Jiahao Ding, MohamadAli Torkamani, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00984">TGTOD: A Global Temporal Graph Transformer for Outlier Detection at Scale</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Transformers have revolutionized machine learning on various data, existing Transformers for temporal graphs face limitations in (1) restricted receptive fields, (2) overhead of subgraph extraction, and (3) suboptimal generalization capability beyond link prediction. In this paper, we rethink temporal graph Transformers and propose TGTOD, a novel end-to-end Temporal Graph Transformer for Outlier Detection. TGTOD employs global attention to model both structural and temporal dependencies within temporal graphs. To tackle scalability, our approach divides large temporal graphs into spatiotemporal patches, which are then processed by a hierarchical Transformer architecture comprising Patch Transformer, Cluster Transformer, and Temporal Transformer. We evaluate TGTOD on three public datasets under two settings, comparing with a wide range of baselines. Our experimental results demonstrate the effectiveness of TGTOD, achieving AP improvement of 61% on Elliptic. Furthermore, our efficiency evaluation shows that TGTOD reduces training time by 44x compared to existing Transformers for temporal graphs. To foster reproducibility, we make our implementation publicly available at https://github.com/kayzliu/tgtod.
<div id='section'>Paperid: <span id='pid'>126, <a href='https://arxiv.org/pdf/2411.15736.pdf' target='_blank'>https://arxiv.org/pdf/2411.15736.pdf</a></span>   <span><a href='https://github.com/BaoshunWq/ood-GaCoOp' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Baoshun Tong, Kaiyu Song, Hanjiang Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15736">Enhancing Few-Shot Out-of-Distribution Detection with Gradient Aligned Context Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Few-shot out-of-distribution (OOD) detection aims to detect OOD images from unseen classes with only a few labeled in-distribution (ID) images. To detect OOD images and classify ID samples, prior methods have been proposed by regarding the background regions of ID samples as the OOD knowledge and performing OOD regularization and ID classification optimization. However, the gradient conflict still exists between ID classification optimization and OOD regularization caused by biased recognition. To address this issue, we present Gradient Aligned Context Optimization (GaCoOp) to mitigate this gradient conflict. Specifically, we decompose the optimization gradient to identify the scenario when the conflict occurs. Then we alleviate the conflict in inner ID samples and optimize the prompts via leveraging gradient projection. Extensive experiments over the large-scale ImageNet OOD detection benchmark demonstrate that our GaCoOp can effectively mitigate the conflict and achieve great performance. Code will be available at https://github.com/BaoshunWq/ood-GaCoOp.
<div id='section'>Paperid: <span id='pid'>127, <a href='https://arxiv.org/pdf/2411.13619.pdf' target='_blank'>https://arxiv.org/pdf/2411.13619.pdf</a></span>   <span><a href='https://github.com/LarsDoorenbos/NCIS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Doorenbos, Raphael Sznitman, Pablo MÃ¡rquez-Neila
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13619">Non-Linear Outlier Synthesis for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The reliability of supervised classifiers is severely hampered by their limitations in dealing with unexpected inputs, leading to great interest in out-of-distribution (OOD) detection. Recently, OOD detectors trained on synthetic outliers, especially those generated by large diffusion models, have shown promising results in defining robust OOD decision boundaries. Building on this progress, we present NCIS, which enhances the quality of synthetic outliers by operating directly in the diffusion's model embedding space rather than combining disjoint models as in previous work and by modeling class-conditional manifolds with a conditional volume-preserving network for more expressive characterization of the training distribution. We demonstrate that these improvements yield new state-of-the-art OOD detection results on standard ImageNet100 and CIFAR100 benchmarks and provide insights into the importance of data pre-processing and other key design choices. We make our code available at \url{https://github.com/LarsDoorenbos/NCIS}.
<div id='section'>Paperid: <span id='pid'>128, <a href='https://arxiv.org/pdf/2411.13024.pdf' target='_blank'>https://arxiv.org/pdf/2411.13024.pdf</a></span>   <span><a href='https://github.com/liuhw01/POI' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanwei Liu, Huiling Cai, Qingcheng Lin, Xuefeng Li, Hui Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13024">Prior-based Objective Inference Mining Potential Uncertainty for Facial Expression Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Annotation ambiguity caused by the inherent subjectivity of visual judgment has always been a major challenge for Facial Expression Recognition (FER) tasks, particularly for largescale datasets from in-the-wild scenarios. A potential solution is the evaluation of relatively objective emotional distributions to help mitigate the ambiguity of subjective annotations. To this end, this paper proposes a novel Prior-based Objective Inference (POI) network. This network employs prior knowledge to derive a more objective and varied emotional distribution and tackles the issue of subjective annotation ambiguity through dynamic knowledge transfer. POI comprises two key networks: Firstly, the Prior Inference Network (PIN) utilizes the prior knowledge of AUs and emotions to capture intricate motion details. To reduce over-reliance on priors and facilitate objective emotional inference, PIN aggregates inferential knowledge from various key facial subregions, encouraging mutual learning. Secondly, the Target Recognition Network (TRN) integrates subjective emotion annotations and objective inference soft labels provided by the PIN, fostering an understanding of inherent facial expression diversity, thus resolving annotation ambiguity. Moreover, we introduce an uncertainty estimation module to quantify and balance facial expression confidence. This module enables a flexible approach to dealing with the uncertainties of subjective annotations. Extensive experiments show that POI exhibits competitive performance on both synthetic noisy datasets and multiple real-world datasets. All codes and training logs will be publicly available at https://github.com/liuhw01/POI.
<div id='section'>Paperid: <span id='pid'>129, <a href='https://arxiv.org/pdf/2411.10701.pdf' target='_blank'>https://arxiv.org/pdf/2411.10701.pdf</a></span>   <span><a href='https://github.com/xbyym/DLSR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ying Yang, De Cheng, Chaowei Fang, Yubiao Wang, Changzhe Jiao, Lechao Cheng, Nannan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10701">Diffusion-based Layer-wise Semantic Reconstruction for Unsupervised Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised out-of-distribution (OOD) detection aims to identify out-of-domain data by learning only from unlabeled In-Distribution (ID) training samples, which is crucial for developing a safe real-world machine learning system. Current reconstruction-based methods provide a good alternative approach by measuring the reconstruction error between the input and its corresponding generative counterpart in the pixel/feature space. However, such generative methods face a key dilemma: improving the reconstruction power of the generative model while keeping a compact representation of the ID data. To address this issue, we propose the diffusion-based layer-wise semantic reconstruction approach for unsupervised OOD detection. The innovation of our approach is that we leverage the diffusion model's intrinsic data reconstruction ability to distinguish ID samples from OOD samples in the latent feature space. Moreover, to set up a comprehensive and discriminative feature representation, we devise a multi-layer semantic feature extraction strategy. By distorting the extracted features with Gaussian noise and applying the diffusion model for feature reconstruction, the separation of ID and OOD samples is implemented according to the reconstruction errors. Extensive experimental results on multiple benchmarks built upon various datasets demonstrate that our method achieves state-of-the-art performance in terms of detection accuracy and speed. Code is available at <https://github.com/xbyym/DLSR>.
<div id='section'>Paperid: <span id='pid'>130, <a href='https://arxiv.org/pdf/2411.04826.pdf' target='_blank'>https://arxiv.org/pdf/2411.04826.pdf</a></span>   <span><a href='https://github.com/Csyunling/D3epth' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyu Chen, Hong Liu, Wenhao Li, Ying Zhu, Guoquan Wang, Jianbing Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04826">D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic Scenes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Depth estimation is a crucial technology in robotics. Recently, self-supervised depth estimation methods have demonstrated great potential as they can efficiently leverage large amounts of unlabelled real-world data. However, most existing methods are designed under the assumption of static scenes, which hinders their adaptability in dynamic environments. To address this issue, we present D$^3$epth, a novel method for self-supervised depth estimation in dynamic scenes. It tackles the challenge of dynamic objects from two key perspectives. First, within the self-supervised framework, we design a reprojection constraint to identify regions likely to contain dynamic objects, allowing the construction of a dynamic mask that mitigates their impact at the loss level. Second, for multi-frame depth estimation, we introduce a cost volume auto-masking strategy that leverages adjacent frames to identify regions associated with dynamic objects and generate corresponding masks. This provides guidance for subsequent processes. Furthermore, we propose a spectral entropy uncertainty module that incorporates spectral entropy to guide uncertainty estimation during depth fusion, effectively addressing issues arising from cost volume computation in dynamic environments. Extensive experiments on KITTI and Cityscapes datasets demonstrate that the proposed method consistently outperforms existing self-supervised monocular depth estimation baselines. Code is available at \url{https://github.com/Csyunling/D3epth}.
<div id='section'>Paperid: <span id='pid'>131, <a href='https://arxiv.org/pdf/2411.01893.pdf' target='_blank'>https://arxiv.org/pdf/2411.01893.pdf</a></span>   <span><a href='https://zju3dv.github.io/GD-PoseMVS/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yitong Dong, Yijin Li, Zhaoyang Huang, Weikang Bian, Jingbo Liu, Hujun Bao, Zhaopeng Cui, Hongsheng Li, Guofeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01893">A Global Depth-Range-Free Multi-View Stereo Transformer Network with Pose Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel multi-view stereo (MVS) framework that gets rid of the depth range prior. Unlike recent prior-free MVS methods that work in a pair-wise manner, our method simultaneously considers all the source images. Specifically, we introduce a Multi-view Disparity Attention (MDA) module to aggregate long-range context information within and across multi-view images. Considering the asymmetry of the epipolar disparity flow, the key to our method lies in accurately modeling multi-view geometric constraints. We integrate pose embedding to encapsulate information such as multi-view camera poses, providing implicit geometric constraints for multi-view disparity feature fusion dominated by attention. Additionally, we construct corresponding hidden states for each source image due to significant differences in the observation quality of the same pixel in the reference frame across multiple source frames. We explicitly estimate the quality of the current pixel corresponding to sampled points on the epipolar line of the source image and dynamically update hidden states through the uncertainty estimation module. Extensive results on the DTU dataset and Tanks&Temple benchmark demonstrate the effectiveness of our method. The code is available at our project page: https://zju3dv.github.io/GD-PoseMVS/.
<div id='section'>Paperid: <span id='pid'>132, <a href='https://arxiv.org/pdf/2410.20807.pdf' target='_blank'>https://arxiv.org/pdf/2410.20807.pdf</a></span>   <span><a href='https://github.com/mala-lab/AdaptOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjun Miao, Guansong Pang, Jin Zheng, Xiao Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20807">Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One key challenge in Out-of-Distribution (OOD) detection is the absence of ground-truth OOD samples during training. One principled approach to address this issue is to use samples from external datasets as outliers (i.e., pseudo OOD samples) to train OOD detectors. However, we find empirically that the outlier samples often present a distribution shift compared to the true OOD samples, especially in Long-Tailed Recognition (LTR) scenarios, where ID classes are heavily imbalanced, \ie, the true OOD samples exhibit very different probability distribution to the head and tailed ID classes from the outliers. In this work, we propose a novel approach, namely normalized outlier distribution adaptation (AdaptOD), to tackle this distribution shift problem. One of its key components is dynamic outlier distribution adaptation that effectively adapts a vanilla outlier distribution based on the outlier samples to the true OOD distribution by utilizing the OOD knowledge in the predicted OOD samples during inference. Further, to obtain a more reliable set of predicted OOD samples on long-tailed ID data, a novel dual-normalized energy loss is introduced in AdaptOD, which leverages class- and sample-wise normalized energy to enforce a more balanced prediction energy on imbalanced ID samples. This helps avoid bias toward the head samples and learn a substantially better vanilla outlier distribution than existing energy losses during training. It also eliminates the need of manually tuning the sensitive margin hyperparameters in energy losses. Empirical results on three popular benchmarks for OOD detection in LTR show the superior performance of AdaptOD over state-of-the-art methods. Code is available at https://github.com/mala-lab/AdaptOD.
<div id='section'>Paperid: <span id='pid'>133, <a href='https://arxiv.org/pdf/2410.20631.pdf' target='_blank'>https://arxiv.org/pdf/2410.20631.pdf</a></span>   <span><a href='https://github.com/RanchoGoose/PViT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianhao Zhang, Zhixiang Chen, Lyudmila S. Mihaylova
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20631">PViT: Prior-augmented Vision Transformer for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision Transformers (ViTs) have achieved remarkable success over various vision tasks, yet their robustness against data distribution shifts and inherent inductive biases remain underexplored. To enhance the robustness of ViT models for image Out-of-Distribution (OOD) detection, we introduce a novel and generic framework named Prior-augmented Vision Transformer (PViT). Taking as input the prior class logits from a pretrained model, we train PViT to predict the class logits. During inference, PViT identifies OOD samples by quantifying the divergence between the predicted class logits and the prior logits obtained from pre-trained models. Unlike existing state-of-the-art(SOTA) OOD detection methods, PViT shapes the decision boundary between ID and OOD by utilizing the proposed prior guided confidence, without requiring additional data modeling, generation methods, or structural modifications. Extensive experiments on the large-scale ImageNet benchmark, evaluated against over seven OOD datasets, demonstrate that PViT significantly outperforms existing SOTA OOD detection methods in terms of FPR95 and AUROC. The codebase is publicly available at https://github.com/RanchoGoose/PViT.
<div id='section'>Paperid: <span id='pid'>134, <a href='https://arxiv.org/pdf/2410.14975.pdf' target='_blank'>https://arxiv.org/pdf/2410.14975.pdf</a></span>   <span><a href='https://github.com/daintlab/ReGuide' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jihyo Kim, Seulbi Lee, Sangheum Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14975">Reflexive Guidance: Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the recent emergence of foundation models trained on internet-scale data and demonstrating remarkable generalization capabilities, such foundation models have become more widely adopted, leading to an expanding range of application domains. Despite this rapid proliferation, the trustworthiness of foundation models remains underexplored. Specifically, the out-of-distribution detection (OoDD) capabilities of large vision-language models (LVLMs), such as GPT-4o, which are trained on massive multi-modal data, have not been sufficiently addressed. The disparity between their demonstrated potential and practical reliability raises concerns regarding the safe and trustworthy deployment of foundation models. To address this gap, we evaluate and analyze the OoDD capabilities of various proprietary and open-source LVLMs. Our investigation contributes to a better understanding of how these foundation models represent confidence scores through their generated natural language responses. Furthermore, we propose a self-guided prompting approach, termed Reflexive Guidance (ReGuide), aimed at enhancing the OoDD capability of LVLMs by leveraging self-generated image-adaptive concept suggestions. Experimental results demonstrate that our ReGuide enhances the performance of current LVLMs in both image classification and OoDD tasks. The lists of sampled images, along with the prompts and responses for each sample are available at https://github.com/daintlab/ReGuide.
<div id='section'>Paperid: <span id='pid'>135, <a href='https://arxiv.org/pdf/2410.13338.pdf' target='_blank'>https://arxiv.org/pdf/2410.13338.pdf</a></span>   <span><a href='https://github.com/decisionintelligence/SSD-TS/' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/decisionintelligence/SSD-TS/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongfan Gao, Wangmeng Shen, Xiangfei Qiu, Ronghui Xu, Jilin Hu, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13338">SSD-TS: Exploring the Potential of Linear State Space Models for Diffusion Models in Time Series Imputation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Probabilistic time series imputation has been widely applied in real-world scenarios due to its ability for uncertainty estimation and denoising diffusion probabilistic models~(DDPMs) have achieved great success in probabilistic time series imputation tasks with its power to model complex distributions. However, current DDPM-based probabilistic time series imputation methodologies are confronted with two types of challenges: 1)\textit{The backbone modules of the denoising parts are not capable of achieving sequence modeling with low time complexity.} 2)~\textit{The architecture of denoising modules can not handle the dependencies in the time series data effectively.} To address the first challenge, we explore the potential of state space model, namely Mamba, as the backbone denoising module for DDPMs. To tackle the second challenge, we carefully devise several SSM-based blocks for time series data modeling. Experimental results demonstrate that our approach can achieve state-of-the-art time series imputation results on multiple real-world datasets. Our datasets and code are available at \href{https://github.com/decisionintelligence/SSD-TS/}{https://github.com/decisionintelligence/SSD-TS/}
<div id='section'>Paperid: <span id='pid'>136, <a href='https://arxiv.org/pdf/2410.11576.pdf' target='_blank'>https://arxiv.org/pdf/2410.11576.pdf</a></span>   <span><a href='https://github.com/QingyangZhang/DUL' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/QingyangZhang/DUL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingyang Zhang, Qiuxuan Feng, Joey Tianyi Zhou, Yatao Bian, Qinghua Hu, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.11576">The Best of Both Worlds: On the Dilemma of Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for model trustworthiness which aims to sensitively identify semantic OOD samples and robustly generalize for covariate-shifted OOD samples. However, we discover that the superior OOD detection performance of state-of-the-art methods is achieved by secretly sacrificing the OOD generalization ability. Specifically, the classification accuracy of these models could deteriorate dramatically when they encounter even minor noise. This phenomenon contradicts the goal of model trustworthiness and severely restricts their applicability in real-world scenarios. What is the hidden reason behind such a limitation? In this work, we theoretically demystify the ``\textit{sensitive-robust}'' dilemma that lies in many existing OOD detection methods. Consequently, a theory-inspired algorithm is induced to overcome such a dilemma. By decoupling the uncertainty learning objective from a Bayesian perspective, the conflict between OOD detection and OOD generalization is naturally harmonized and a dual-optimal performance could be expected. Empirical studies show that our method achieves superior performance on standard benchmarks. To our best knowledge, this work is the first principled OOD detection method that achieves state-of-the-art OOD detection performance without compromising OOD generalization ability. Our code is available at \href{https://github.com/QingyangZhang/DUL}{https://github.com/QingyangZhang/DUL}.
<div id='section'>Paperid: <span id='pid'>137, <a href='https://arxiv.org/pdf/2410.11236.pdf' target='_blank'>https://arxiv.org/pdf/2410.11236.pdf</a></span>   <span><a href='https://grenoble-zhang.github.io/Ctrl-U-Page/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guiyu Zhang, Huan-ang Gao, Zijian Jiang, Hao Zhao, Zhedong Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.11236">Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we focus on the task of conditional image generation, where an image is synthesized according to user instructions. The critical challenge underpinning this task is ensuring both the fidelity of the generated images and their semantic alignment with the provided conditions. To tackle this issue, previous studies have employed supervised perceptual losses derived from pre-trained models, i.e., reward models, to enforce alignment between the condition and the generated result. However, we observe one inherent shortcoming: considering the diversity of synthesized images, the reward model usually provides inaccurate feedback when encountering newly generated data, which can undermine the training process. To address this limitation, we propose an uncertainty-aware reward modeling, called Ctrl-U, including uncertainty estimation and uncertainty-aware regularization, designed to reduce the adverse effects of imprecise feedback from the reward model. Given the inherent cognitive uncertainty within reward models, even images generated under identical conditions often result in a relatively large discrepancy in reward loss. Inspired by the observation, we explicitly leverage such prediction variance as an uncertainty indicator. Based on the uncertainty estimation, we regularize the model training by adaptively rectifying the reward. In particular, rewards with lower uncertainty receive higher loss weights, while those with higher uncertainty are given reduced weights to allow for larger variability. The proposed uncertainty regularization facilitates reward fine-tuning through consistency construction. Extensive experiments validate the effectiveness of our methodology in improving the controllability and generation quality, as well as its scalability across diverse conditional scenarios. Codes are publicly available at https://grenoble-zhang.github.io/Ctrl-U-Page/.
<div id='section'>Paperid: <span id='pid'>138, <a href='https://arxiv.org/pdf/2410.10744.pdf' target='_blank'>https://arxiv.org/pdf/2410.10744.pdf</a></span>   <span><a href='https://github.com/AdaptiveMotorControlLab/AROS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mackenzie W. Mathis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10744">Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite significant advancements in out-of-distribution (OOD) detection, existing methods still struggle to maintain robustness against adversarial attacks, compromising their reliability in critical real-world applications. Previous studies have attempted to address this challenge by exposing detectors to auxiliary OOD datasets alongside adversarial training. However, the increased data complexity inherent in adversarial training, and the myriad of ways that OOD samples can arise during testing, often prevent these approaches from establishing robust decision boundaries. To address these limitations, we propose AROS, a novel approach leveraging neural ordinary differential equations (NODEs) with Lyapunov stability theorem in order to obtain robust embeddings for OOD detection. By incorporating a tailored loss function, we apply Lyapunov stability theory to ensure that both in-distribution (ID) and OOD data converge to stable equilibrium points within the dynamical system. This approach encourages any perturbed input to return to its stable equilibrium, thereby enhancing the model's robustness against adversarial perturbations. To not use additional data, we generate fake OOD embeddings by sampling from low-likelihood regions of the ID data feature space, approximating the boundaries where OOD data are likely to reside. To then further enhance robustness, we propose the use of an orthogonal binary layer following the stable feature space, which maximizes the separation between the equilibrium points of ID and OOD samples. We validate our method through extensive experiments across several benchmarks, demonstrating superior performance, particularly under adversarial attacks. Notably, our approach improves robust detection performance from 37.8% to 80.1% on CIFAR-10 vs. CIFAR-100 and from 29.0% to 67.0% on CIFAR-100 vs. CIFAR-10.
<div id='section'>Paperid: <span id='pid'>139, <a href='https://arxiv.org/pdf/2410.09299.pdf' target='_blank'>https://arxiv.org/pdf/2410.09299.pdf</a></span>   <span><a href='https://github.com/HuXiaoling/Regre4Regis' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoling Hu, Karthik Gopinath, Peirong Liu, Malte Hoffmann, Koen Van Leemput, Oula Puonti, Juan Eugenio Iglesias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09299">Hierarchical Uncertainty Estimation for Learning-based Registration in Neuroimaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over recent years, deep learning based image registration has achieved impressive accuracy in many domains, including medical imaging and, specifically, human neuroimaging with magnetic resonance imaging (MRI). However, the uncertainty estimation associated with these methods has been largely limited to the application of generic techniques (e.g., Monte Carlo dropout) that do not exploit the peculiarities of the problem domain, particularly spatial modeling. Here, we propose a principled way to propagate uncertainties (epistemic or aleatoric) estimated at the level of spatial location by these methods, to the level of global transformation models, and further to downstream tasks. Specifically, we justify the choice of a Gaussian distribution for the local uncertainty modeling, and then propose a framework where uncertainties spread across hierarchical levels, depending on the choice of transformation model. Experiments on publicly available data sets show that Monte Carlo dropout correlates very poorly with the reference registration error, whereas our uncertainty estimates correlate much better. Crucially, the results also show that uncertainty-aware fitting of transformations improves the registration accuracy of brain MRI scans. Finally, we illustrate how sampling from the posterior distribution of the transformations can be used to propagate uncertainties to downstream neuroimaging tasks. Code is available at: https://github.com/HuXiaoling/Regre4Regis.
<div id='section'>Paperid: <span id='pid'>140, <a href='https://arxiv.org/pdf/2410.07185.pdf' target='_blank'>https://arxiv.org/pdf/2410.07185.pdf</a></span>   <span><a href='https://github.com/lakpa-tamang9/margin_ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lakpa D. Tamang, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07185">Margin-bounded Confidence Scores for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many critical Machine Learning applications, such as autonomous driving and medical image diagnosis, the detection of out-of-distribution (OOD) samples is as crucial as accurately classifying in-distribution (ID) inputs. Recently Outlier Exposure (OE) based methods have shown promising results in detecting OOD inputs via model fine-tuning with auxiliary outlier data. However, most of the previous OE-based approaches emphasize more on synthesizing extra outlier samples or introducing regularization to diversify OOD sample space, which is rather unquantifiable in practice. In this work, we propose a novel and straightforward method called Margin bounded Confidence Scores (MaCS) to address the nontrivial OOD detection problem by enlarging the disparity between ID and OOD scores, which in turn makes the decision boundary more compact facilitating effective segregation with a simple threshold. Specifically, we augment the learning objective of an OE regularized classifier with a supplementary constraint, which penalizes high confidence scores for OOD inputs compared to that of ID and significantly enhances the OOD detection performance while maintaining the ID classification accuracy. Extensive experiments on various benchmark datasets for image classification tasks demonstrate the effectiveness of the proposed method by significantly outperforming state-of-the-art (S.O.T.A) methods on various benchmarking metrics. The code is publicly available at https://github.com/lakpa-tamang9/margin_ood
<div id='section'>Paperid: <span id='pid'>141, <a href='https://arxiv.org/pdf/2410.04525.pdf' target='_blank'>https://arxiv.org/pdf/2410.04525.pdf</a></span>   <span><a href='https://github.com/berkerdemirel/ORA-OOD-Detection-with-Relative-Angles' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Berker Demirel, Marco Fumero, Francesco Locatello
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04525">Out-of-Distribution Detection with Relative Angles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning systems deployed in real-world applications often encounter data that is different from their in-distribution (ID). A reliable model should ideally abstain from making decisions in this out-of-distribution (OOD) setting. Existing state-of-the-art methods primarily focus on feature distances, such as k-th nearest neighbors and distances to decision boundaries, either overlooking or ineffectively using in-distribution statistics. In this work, we propose a novel angle-based metric for OOD detection that is computed relative to the in-distribution structure. We demonstrate that the angles between feature representations and decision boundaries, viewed from the mean of in-distribution features, serve as an effective discriminative factor between ID and OOD data. We evaluate our method on nine ImageNet-pretrained models. Our approach achieves the lowest FPR in 5 out of 9 ImageNet models, obtains the best average FPR overall, and consistently ranking among the top 3 across all evaluated models. Furthermore, we highlight the benefits of contrastive representations by showing strong performance with ResNet SCL and CLIP architectures. Finally, we demonstrate that the scale-invariant nature of our score enables an ensemble strategy via simple score summation. Code is available at https://github.com/berkerdemirel/ORA-OOD-Detection-with-Relative-Angles.
<div id='section'>Paperid: <span id='pid'>142, <a href='https://arxiv.org/pdf/2410.00393.pdf' target='_blank'>https://arxiv.org/pdf/2410.00393.pdf</a></span>   <span><a href='https://github.com/MengyuanChen21/Re-EDL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengyuan Chen, Junyu Gao, Changsheng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00393">Revisiting Essential and Nonessential Settings of Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evidential Deep Learning (EDL) is an emerging method for uncertainty estimation that provides reliable predictive uncertainty in a single forward pass, attracting significant attention. Grounded in subjective logic, EDL derives Dirichlet concentration parameters from neural networks to construct a Dirichlet probability density function (PDF), modeling the distribution of class probabilities. Despite its success, EDL incorporates several nonessential settings: In model construction, (1) a commonly ignored prior weight parameter is fixed to the number of classes, while its value actually impacts the balance between the proportion of evidence and its magnitude in deriving predictive scores. In model optimization, (2) the empirical risk features a variance-minimizing optimization term that biases the PDF towards a Dirac delta function, potentially exacerbating overconfidence. (3) Additionally, the structural risk typically includes a KL-divergence-minimizing regularization, whose optimization direction extends beyond the intended purpose and contradicts common sense, diminishing the information carried by the evidence magnitude. Therefore, we propose Re-EDL, a simplified yet more effective variant of EDL, by relaxing the nonessential settings and retaining the essential one, namely, the adoption of projected probability from subjective logic. Specifically, Re-EDL treats the prior weight as an adjustable hyperparameter rather than a fixed scalar, and directly optimizes the expectation of the Dirichlet PDF provided by deprecating both the variance-minimizing optimization term and the divergence regularization term. Extensive experiments and state-of-the-art performance validate the effectiveness of our method. The source code is available at https://github.com/MengyuanChen21/Re-EDL.
<div id='section'>Paperid: <span id='pid'>143, <a href='https://arxiv.org/pdf/2409.19840.pdf' target='_blank'>https://arxiv.org/pdf/2409.19840.pdf</a></span>   <span><a href='https://github.com/Saehyung-Lee/HFTT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saehyung Lee, Jisoo Mok, Sangha Park, Yongho Shin, Dahuin Jung, Sungroh Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19840">Textual Training for the Hassle-Free Removal of Unwanted Visual Data: Case Studies on OOD and Hateful Image Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In our study, we explore methods for detecting unwanted content lurking in visual datasets. We provide a theoretical analysis demonstrating that a model capable of successfully partitioning visual data can be obtained using only textual data. Based on the analysis, we propose Hassle-Free Textual Training (HFTT), a streamlined method capable of acquiring detectors for unwanted visual content, using only synthetic textual data in conjunction with pre-trained vision-language models. HFTT features an innovative objective function that significantly reduces the necessity for human involvement in data annotation. Furthermore, HFTT employs a clever textual data synthesis method, effectively emulating the integration of unknown visual data distribution into the training process at no extra cost. The unique characteristics of HFTT extend its utility beyond traditional out-of-distribution detection, making it applicable to tasks that address more abstract concepts. We complement our analyses with experiments in out-of-distribution detection and hateful image detection. Our codes are available at https://github.com/Saehyung-Lee/HFTT
<div id='section'>Paperid: <span id='pid'>144, <a href='https://arxiv.org/pdf/2409.19370.pdf' target='_blank'>https://arxiv.org/pdf/2409.19370.pdf</a></span>   <span><a href='https://github.com/GtLinyer/MambaEviScrib' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoxiang Han, Xinyu Li, Jiang Shang, Yiman Liu, Keyan Chen, Shugong Xu, Qiaohong Liu, Qi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19370">MambaEviScrib: Mamba and Evidence-Guided Consistency Enhance CNN Robustness for Scribble-Based Weakly Supervised Ultrasound Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Segmenting anatomical structures and lesions from ultrasound images contributes to disease assessment. Weakly supervised learning (WSL) based on sparse annotation has achieved encouraging performance and demonstrated the potential to reduce annotation costs. This study attempts to introduce scribble-based WSL into ultrasound image segmentation tasks. However, ultrasound images often suffer from poor contrast and unclear edges, coupled with insufficient supervison signals for edges, posing challenges to edge prediction. Uncertainty modeling has been proven to facilitate models in dealing with these issues. Nevertheless, existing uncertainty estimation paradigms are not robust enough and often filter out predictions near decision boundaries, resulting in unstable edge predictions. Therefore, we propose leveraging predictions near decision boundaries effectively. Specifically, we introduce Dempster-Shafer Theory (DST) of evidence to design an Evidence-Guided Consistency strategy. This strategy utilizes high-evidence predictions, which are more likely to occur near high-density regions, to guide the optimization of low-evidence predictions that may appear near decision boundaries. Furthermore, the diverse sizes and locations of lesions in ultrasound images pose a challenge for CNNs with local receptive fields, as they struggle to model global information. Therefore, we introduce Visual Mamba based on structured state space sequence models, which achieves long-range dependency with linear computational complexity, and we construct a novel hybrid CNN-Mamba framework. During training, the collaboration between the CNN branch and the Mamba branch in the proposed framework draws inspiration from each other based on the EGC strategy. Experiments demonstrate the competitiveness of the proposed method. Dataset and code will be available on https://github.com/GtLinyer/MambaEviScrib.
<div id='section'>Paperid: <span id='pid'>145, <a href='https://arxiv.org/pdf/2409.17485.pdf' target='_blank'>https://arxiv.org/pdf/2409.17485.pdf</a></span>   <span><a href='https://github.com/Rubiscol/D2UE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Gu, Yi Lin, Kwang-Ting Cheng, Hao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17485">Revisiting Deep Ensemble Uncertainty for Enhanced Medical Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical anomaly detection (AD) is crucial in pathological identification and localization. Current methods typically rely on uncertainty estimation in deep ensembles to detect anomalies, assuming that ensemble learners should agree on normal samples while exhibiting disagreement on unseen anomalies in the output space. However, these methods may suffer from inadequate disagreement on anomalies or diminished agreement on normal samples. To tackle these issues, we propose D2UE, a Diversified Dual-space Uncertainty Estimation framework for medical anomaly detection. To effectively balance agreement and disagreement for anomaly detection, we propose Redundancy-Aware Repulsion (RAR), which uses a similarity kernel that remains invariant to both isotropic scaling and orthogonal transformations, explicitly promoting diversity in learners' feature space. Moreover, to accentuate anomalous regions, we develop Dual-Space Uncertainty (DSU), which utilizes the ensemble's uncertainty in input and output spaces. In input space, we first calculate gradients of reconstruction error with respect to input images. The gradients are then integrated with reconstruction outputs to estimate uncertainty for inputs, enabling effective anomaly discrimination even when output space disagreement is minimal. We conduct a comprehensive evaluation of five medical benchmarks with different backbones. Experimental results demonstrate the superiority of our method to state-of-the-art methods and the effectiveness of each component in our framework. Our code is available at https://github.com/Rubiscol/D2UE.
<div id='section'>Paperid: <span id='pid'>146, <a href='https://arxiv.org/pdf/2409.11884.pdf' target='_blank'>https://arxiv.org/pdf/2409.11884.pdf</a></span>   <span><a href='https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Lu, Yingsheng Wang, Lijun Sheng, Lingxiao He, Aihua Zheng, Jian Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11884">Out-of-Distribution Detection: A Task-Oriented Survey of Recent Advances</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection aims to detect test samples outside the training category space, which is an essential component in building reliable machine learning systems. Existing reviews on OOD detection primarily focus on method taxonomy, surveying the field by categorizing various approaches. However, many recent works concentrate on non-traditional OOD detection scenarios, such as test-time adaptation, multi-modal data sources and other novel contexts. In this survey, we uniquely review recent advances in OOD detection from the task-oriented perspective for the first time. According to the user's access to the model, that is, whether the OOD detection method is allowed to modify or retrain the model, we classify the methods as training-driven or training-agnostic. Besides, considering the rapid development of pre-trained models, large pre-trained model-based OOD detection is also regarded as an important category and discussed separately. Furthermore, we provide a discussion of the evaluation scenarios, a variety of applications, and several future research directions. We believe this survey with new taxonomy will benefit the proposal of new methods and the expansion of more practical scenarios. A curated list of related papers is provided in the Github repository: https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection.
<div id='section'>Paperid: <span id='pid'>147, <a href='https://arxiv.org/pdf/2409.11373.pdf' target='_blank'>https://arxiv.org/pdf/2409.11373.pdf</a></span>   <span><a href='https://rrow2024.github.io/call-for-papers' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Edgar Heinert, Stephan Tilgner, Timo Palm, Matthias Rottmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11373">Uncertainty and Prediction Quality Estimation for Semantic Segmentation via Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When employing deep neural networks (DNNs) for semantic segmentation in safety-critical applications like automotive perception or medical imaging, it is important to estimate their performance at runtime, e.g. via uncertainty estimates or prediction quality estimates. Previous works mostly performed uncertainty estimation on pixel-level. In a line of research, a connected-component-wise (segment-wise) perspective was taken, approaching uncertainty estimation on an object-level by performing so-called meta classification and regression to estimate uncertainty and prediction quality, respectively. In those works, each predicted segment is considered individually to estimate its uncertainty or prediction quality. However, the neighboring segments may provide additional hints on whether a given predicted segment is of high quality, which we study in the present work. On the basis of uncertainty indicating metrics on segment-level, we use graph neural networks (GNNs) to model the relationship of a given segment's quality as a function of the given segment's metrics as well as those of its neighboring segments. We compare different GNN architectures and achieve a notable performance improvement.
<div id='section'>Paperid: <span id='pid'>148, <a href='https://arxiv.org/pdf/2409.10044.pdf' target='_blank'>https://arxiv.org/pdf/2409.10044.pdf</a></span>   <span><a href='https://github.com/0Frett/PO-Uncertainty-Benchmarking' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10044">Benchmarking Large Language Model Uncertainty for Prompt Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prompt optimization algorithms for Large Language Models (LLMs) excel in multi-step reasoning but still lack effective uncertainty estimation. This paper introduces a benchmark dataset to evaluate uncertainty metrics, focusing on Answer, Correctness, Aleatoric, and Epistemic Uncertainty. Through analysis of models like GPT-3.5-Turbo and Meta-Llama-3.1-8B-Instruct, we show that current metrics align more with Answer Uncertainty, which reflects output confidence and diversity, rather than Correctness Uncertainty, highlighting the need for improved metrics that are optimization-objective-aware to better guide prompt optimization. Our code and dataset are available at https://github.com/0Frett/PO-Uncertainty-Benchmarking.
<div id='section'>Paperid: <span id='pid'>149, <a href='https://arxiv.org/pdf/2409.08946.pdf' target='_blank'>https://arxiv.org/pdf/2409.08946.pdf</a></span>   <span><a href='https://github.com/goose315/DELTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pengyun Wang, Yadi Cao, Chris Russell, Yanxin Shen, Junyu Luo, Ming Zhang, Siyu Heng, Xiao Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08946">DELTA: Dual Consistency Delving with Topological Uncertainty for Active Graph Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph domain adaptation has recently enabled knowledge transfer across different graphs. However, without the semantic information on target graphs, the performance on target graphs is still far from satisfactory. To address the issue, we study the problem of active graph domain adaptation, which selects a small quantitative of informative nodes on the target graph for extra annotation. This problem is highly challenging due to the complicated topological relationships and the distribution discrepancy across graphs. In this paper, we propose a novel approach named Dual Consistency Delving with Topological Uncertainty (DELTA) for active graph domain adaptation. Our DELTA consists of an edge-oriented graph subnetwork and a path-oriented graph subnetwork, which can explore topological semantics from complementary perspectives. In particular, our edge-oriented graph subnetwork utilizes the message passing mechanism to learn neighborhood information, while our path-oriented graph subnetwork explores high-order relationships from sub-structures. To jointly learn from two subnetworks, we roughly select informative candidate nodes with the consideration of consistency across two subnetworks. Then, we aggregate local semantics from its K-hop subgraph based on node degrees for topological uncertainty estimation. To overcome potential distribution shifts, we compare target nodes and their corresponding source nodes for discrepancy scores as an additional component for fine selection. Extensive experiments on benchmark datasets demonstrate that DELTA outperforms various state-of-the-art approaches. The code implementation of DELTA is available at https://github.com/goose315/DELTA.
<div id='section'>Paperid: <span id='pid'>150, <a href='https://arxiv.org/pdf/2409.06407.pdf' target='_blank'>https://arxiv.org/pdf/2409.06407.pdf</a></span>   <span><a href='https://aaltoml.github.io/uncertainty-nerf-gs/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcus Klasson, Riccardo Mereu, Juho Kannala, Arno Solin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06407">Sources of Uncertainty in 3D Scene Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The process of 3D scene reconstruction can be affected by numerous uncertainty sources in real-world scenes. While Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (GS) achieve high-fidelity rendering, they lack built-in mechanisms to directly address or quantify uncertainties arising from the presence of noise, occlusions, confounding outliers, and imprecise camera pose inputs. In this paper, we introduce a taxonomy that categorizes different sources of uncertainty inherent in these methods. Moreover, we extend NeRF- and GS-based methods with uncertainty estimation techniques, including learning uncertainty outputs and ensembles, and perform an empirical study to assess their ability to capture the sensitivity of the reconstruction. Our study highlights the need for addressing various uncertainty aspects when designing NeRF/GS-based methods for uncertainty-aware 3D reconstruction.
<div id='section'>Paperid: <span id='pid'>151, <a href='https://arxiv.org/pdf/2409.05672.pdf' target='_blank'>https://arxiv.org/pdf/2409.05672.pdf</a></span>   <span><a href='https://github.com/A-Chicharito-S/FoMo-0D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchen Shen, Haomin Wen, Leman Akoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.05672">FoMo-0D: A Foundation Model for Zero-shot Tabular Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) has a vast literature as it finds numerous real-world applications. Being an unsupervised task, model selection is a key bottleneck for OD without label supervision. Despite a long list of available OD algorithms with tunable hyperparameters, the lack of systematic approaches for unsupervised algorithm and hyperparameter selection limits their effective use in practice. In this paper, we present FoMo-0D, a pre-trained Foundation Model for zero/0-shot OD on tabular data, which bypasses the hurdle of model selection altogether. Having been pre-trained on synthetic data, FoMo-0D can directly predict the (outlier/inlier) label of test samples without parameter fine-tuning -- requiring no labeled data, and no additional training or hyperparameter tuning when given a new task. Extensive experiments on 57 real-world datasets against 26 baselines show that FoMo-0D is highly competitive; outperforming the majority of the baselines with no statistically significant difference from the 2nd best method. Further, FoMo-0D is efficient in inference time requiring only 7.7 ms per sample on average, with at least 7x speed-up compared to previous methods. To facilitate future research, our implementations for data synthesis and pre-training as well as model checkpoints are openly available at https://github.com/A-Chicharito-S/FoMo-0D.
<div id='section'>Paperid: <span id='pid'>152, <a href='https://arxiv.org/pdf/2409.04796.pdf' target='_blank'>https://arxiv.org/pdf/2409.04796.pdf</a></span>   <span><a href='https://github.com/AuroraZengfh/Local-Prompt' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/AuroraZengfh/Local-Prompt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fanhu Zeng, Zhen Cheng, Fei Zhu, Hongxin Wei, Xu-Yao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04796">Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection, aiming to distinguish outliers from known categories, has gained prominence in practical scenarios. Recently, the advent of vision-language models (VLM) has heightened interest in enhancing OOD detection for VLM through few-shot tuning. However, existing methods mainly focus on optimizing global prompts, ignoring refined utilization of local information with regard to outliers. Motivated by this, we freeze global prompts and introduce Local-Prompt, a novel coarse-to-fine tuning paradigm to emphasize regional enhancement with local prompts. Our method comprises two integral components: global prompt guided negative augmentation and local prompt enhanced regional regularization. The former utilizes frozen, coarse global prompts as guiding cues to incorporate negative augmentation, thereby leveraging local outlier knowledge. The latter employs trainable local prompts and a regional regularization to capture local information effectively, aiding in outlier identification. We also propose regional-related metric to empower the enrichment of OOD detection. Moreover, since our approach explores enhancing local prompts only, it can be seamlessly integrated with trained global prompts during inference to boost the performance. Comprehensive experiments demonstrate the effectiveness and potential of our method. Notably, our method reduces average FPR95 by 5.17% against state-of-the-art method in 4-shot tuning on challenging ImageNet-1k dataset, even outperforming 16-shot results of previous methods. Code is released at https://github.com/AuroraZengfh/Local-Prompt.
<div id='section'>Paperid: <span id='pid'>153, <a href='https://arxiv.org/pdf/2409.02917.pdf' target='_blank'>https://arxiv.org/pdf/2409.02917.pdf</a></span>   <span><a href='https://github.com/wrld/UC-NeRF' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Guo, Jiangliu Wang, Ruofeng Wei, Di Kang, Qi Dou, Yun-hui Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02917">UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visualizing surgical scenes is crucial for revealing internal anatomical structures during minimally invasive procedures. Novel View Synthesis is a vital technique that offers geometry and appearance reconstruction, enhancing understanding, planning, and decision-making in surgical scenes. Despite the impressive achievements of Neural Radiance Field (NeRF), its direct application to surgical scenes produces unsatisfying results due to two challenges: endoscopic sparse views and significant photometric inconsistencies. In this paper, we propose uncertainty-aware conditional NeRF for novel view synthesis to tackle the severe shape-radiance ambiguity from sparse surgical views. The core of UC-NeRF is to incorporate the multi-view uncertainty estimation to condition the neural radiance field for modeling the severe photometric inconsistencies adaptively. Specifically, our UC-NeRF first builds a consistency learner in the form of multi-view stereo network, to establish the geometric correspondence from sparse views and generate uncertainty estimation and feature priors. In neural rendering, we design a base-adaptive NeRF network to exploit the uncertainty estimation for explicitly handling the photometric inconsistencies. Furthermore, an uncertainty-guided geometry distillation is employed to enhance geometry learning. Experiments on the SCARED and Hamlyn datasets demonstrate our superior performance in rendering appearance and geometry, consistently outperforming the current state-of-the-art approaches. Our code will be released at https://github.com/wrld/UC-NeRF.
<div id='section'>Paperid: <span id='pid'>154, <a href='https://arxiv.org/pdf/2408.16757.pdf' target='_blank'>https://arxiv.org/pdf/2408.16757.pdf</a></span>   <span><a href='https://github.com/Visual-AI/Dissect-OOD-OSR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongjun Wang, Sagar Vaze, Kai Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16757">Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting test-time distribution shift has emerged as a key capability for safely deployed machine learning models, with the question being tackled under various guises in recent years. In this paper, we aim to provide a consolidated view of the two largest sub-fields within the community: out-of-distribution (OOD) detection and open-set recognition (OSR). In particular, we aim to provide rigorous empirical analysis of different methods across settings and provide actionable takeaways for practitioners and researchers. Concretely, we make the following contributions: (i) We perform rigorous cross-evaluation between state-of-the-art methods in the OOD detection and OSR settings and identify a strong correlation between the performances of methods for them; (ii) We propose a new, large-scale benchmark setting which we suggest better disentangles the problem tackled by OOD detection and OSR, re-evaluating state-of-the-art OOD detection and OSR methods in this setting; (iii) We surprisingly find that the best performing method on standard benchmarks (Outlier Exposure) struggles when tested at scale, while scoring rules which are sensitive to the deep feature magnitude consistently show promise; and (iv) We conduct empirical analysis to explain these phenomena and highlight directions for future research. Code: https://github.com/Visual-AI/Dissect-OOD-OSR
<div id='section'>Paperid: <span id='pid'>155, <a href='https://arxiv.org/pdf/2408.16115.pdf' target='_blank'>https://arxiv.org/pdf/2408.16115.pdf</a></span>   <span><a href='https://github.com/Richard-Bergna/GraphNeuralSDE' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/Richard-Bergna/GraphNeuralSDE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Richard Bergna, Sergio Calvo-OrdoÃ±ez, Felix L. Opolka, Pietro LiÃ², Jose Miguel Hernandez-Lobato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16115">Uncertainty Modeling in Graph Neural Networks via Stochastic Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel Stochastic Differential Equation (SDE) framework to address the problem of learning uncertainty-aware representations for graph-structured data. While Graph Neural Ordinary Differential Equations (GNODEs) have shown promise in learning node representations, they lack the ability to quantify uncertainty. To address this, we introduce Latent Graph Neural Stochastic Differential Equations (LGNSDE), which enhance GNODE by embedding randomness through a Bayesian prior-posterior mechanism for epistemic uncertainty and Brownian motion for aleatoric uncertainty. By leveraging the existence and uniqueness of solutions to graph-based SDEs, we prove that the variance of the latent space bounds the variance of model outputs, thereby providing theoretically sensible guarantees for the uncertainty estimates. Furthermore, we show mathematically that LGNSDEs are robust to small perturbations in the input, maintaining stability over time. Empirical results across several benchmarks demonstrate that our framework is competitive in out-of-distribution detection, robustness to noise, and active learning, underscoring the ability of LGNSDEs to quantify uncertainty reliably. Code is available at \href{https://github.com/Richard-Bergna/GraphNeuralSDE}{\texttt{github.com/Richard-Bergna/GraphNeuralSDE}}.
<div id='section'>Paperid: <span id='pid'>156, <a href='https://arxiv.org/pdf/2408.10798.pdf' target='_blank'>https://arxiv.org/pdf/2408.10798.pdf</a></span>   <span><a href='https://github.com/mojtaba-nafez/UNODE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mojtaba Nafez, Mohammad Jafari, Mohammad Bagher Soltani, Mohammad Azizmalayeri, Jafar Habibi, Mohammad Sabokrou, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10798">Universal Novelty Detection Through Adaptive Contrastive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty detection is a critical task for deploying machine learning models in the open world. A crucial property of novelty detection methods is universality, which can be interpreted as generalization across various distributions of training or test data. More precisely, for novelty detection, distribution shifts may occur in the training set or the test set. Shifts in the training set refer to cases where we train a novelty detector on a new dataset and expect strong transferability. Conversely, distribution shifts in the test set indicate the methods' performance when the trained model encounters a shifted test sample. We experimentally show that existing methods falter in maintaining universality, which stems from their rigid inductive biases. Motivated by this, we aim for more generalized techniques that have more adaptable inductive biases. In this context, we leverage the fact that contrastive learning provides an efficient framework to easily switch and adapt to new inductive biases through the proper choice of augmentations in forming the negative pairs. We propose a novel probabilistic auto-negative pair generation method AutoAugOOD, along with contrastive learning, to yield a universal novelty detector method. Our experiments demonstrate the superiority of our method under different distribution shifts in various image benchmark datasets. Notably, our method emerges universality in the lens of adaptability to different setups of novelty detection, including one-class, unlabeled multi-class, and labeled multi-class settings. Code: https://github.com/mojtaba-nafez/UNODE
<div id='section'>Paperid: <span id='pid'>157, <a href='https://arxiv.org/pdf/2408.10676.pdf' target='_blank'>https://arxiv.org/pdf/2408.10676.pdf</a></span>   <span><a href='https://github.com/dgshin21/RNA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dong Geun Shin, Hye Won Chung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10676">Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is a critical task for reliable machine learning. However, it becomes particularly challenging when the models are trained on long-tailed datasets, as the models often struggle to distinguish tail-class in-distribution samples from OOD samples. We examine the main challenges in this problem by identifying the trade-offs between OOD detection and in-distribution (ID) classification, faced by existing methods. We then introduce our method, called \textit{Representation Norm Amplification} (RNA), which solves this challenge by decoupling the two problems. The main idea is to use the norm of the representation as a new dimension for OOD detection, and to develop a training method that generates a noticeable discrepancy in the representation norm between ID and OOD data, while not perturbing the feature learning for ID classification. Our experiments show that RNA achieves superior performance in both OOD detection and classification compared to the state-of-the-art methods, by 1.70\% and 9.46\% in FPR95 and 2.43\% and 6.87\% in classification accuracy on CIFAR10-LT and ImageNet-LT, respectively. The code for this work is available at https://github.com/dgshin21/RNA.
<div id='section'>Paperid: <span id='pid'>158, <a href='https://arxiv.org/pdf/2408.03455.pdf' target='_blank'>https://arxiv.org/pdf/2408.03455.pdf</a></span>   <span><a href='https://github.com/Sandialabs/GP-BayesOpInf' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shane A. McQuarrie, Anirban Chaudhuri, Karen E. Willcox, Mengwu Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.03455">Bayesian learning with Gaussian processes for low-dimensional representations of time-dependent nonlinear systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents a data-driven method for learning low-dimensional time-dependent physics-based surrogate models whose predictions are endowed with uncertainty estimates. We use the operator inference approach to model reduction that poses the problem of learning low-dimensional model terms as a regression of state space data and corresponding time derivatives by minimizing the residual of reduced system equations. Standard operator inference models perform well with accurate training data that are dense in time, but producing stable and accurate models when the state data are noisy and/or sparse in time remains a challenge. Another challenge is the lack of uncertainty estimation for the predictions from the operator inference models. Our approach addresses these challenges by incorporating Gaussian process surrogates into the operator inference framework to (1) probabilistically describe uncertainties in the state predictions and (2) procure analytical time derivative estimates with quantified uncertainties. The formulation leads to a generalized least-squares regression and, ultimately, reduced-order models that are described probabilistically with a closed-form expression for the posterior distribution of the operators. The resulting probabilistic surrogate model propagates uncertainties from the observed state data to reduced-order predictions. We demonstrate the method is effective for constructing low-dimensional models of two nonlinear partial differential equations representing a compressible flow and a nonlinear diffusion-reaction process, as well as for estimating the parameters of a low-dimensional system of nonlinear ordinary differential equations representing compartmental models in epidemiology.
<div id='section'>Paperid: <span id='pid'>159, <a href='https://arxiv.org/pdf/2408.02761.pdf' target='_blank'>https://arxiv.org/pdf/2408.02761.pdf</a></span>   <span><a href='https://github.com/mckellwoodland/dimen_reduce_mahal' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>McKell Woodland, Nihil Patel, Austin Castelo, Mais Al Taie, Mohamed Eltaher, Joshua P. Yung, Tucker J. Netherton, Tiffany L. Calderone, Jessica I. Sanchez, Darrel W. Cleere, Ahmed Elsaiey, Nakul Gupta, David Victor, Laura Beretta, Ankit B. Patel, Kristy K. Brock
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02761">Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clinically deployed deep learning-based segmentation models are known to fail on data outside of their training distributions. While clinicians review the segmentations, these models tend to perform well in most instances, which could exacerbate automation bias. Therefore, detecting out-of-distribution images at inference is critical to warn the clinicians that the model likely failed. This work applied the Mahalanobis distance (MD) post hoc to the bottleneck features of four Swin UNETR and nnU-net models that segmented the liver on T1-weighted magnetic resonance imaging and computed tomography. By reducing the dimensions of the bottleneck features with either principal component analysis or uniform manifold approximation and projection, images the models failed on were detected with high performance and minimal computational load. In addition, this work explored a non-parametric alternative to the MD, a k-th nearest neighbors distance (KNN). KNN drastically improved scalability and performance over MD when both were applied to raw and average-pooled bottleneck features.
<div id='section'>Paperid: <span id='pid'>160, <a href='https://arxiv.org/pdf/2408.02307.pdf' target='_blank'>https://arxiv.org/pdf/2408.02307.pdf</a></span>   <span><a href='https://github.com/hjdw2/SEMBG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hojung Lee, Jong-Seok Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02307">Low-Cost Self-Ensembles Based on Multi-Branch Transformation and Grouped Convolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in low-cost ensemble learning have demonstrated improved efficiency for image classification. However, the existing low-cost ensemble methods show relatively lower accuracy compared to conventional ensemble learning. In this paper, we propose a new low-cost ensemble learning, which can simultaneously achieve high efficiency and classification performance. A CNN is transformed into a multi-branch structure without introduction of additional components, which maintains the computational complexity as that of the original single model and also enhances diversity among the branches' outputs via sufficient separation between different pathways of the branches. In addition, we propose a new strategy that applies grouped convolution in the branches with different numbers of groups in different branches, which boosts the diversity of the branches' outputs. For training, we employ knowledge distillation using the ensemble of the outputs as the teacher signal. The high diversity among the outputs enables to form a powerful teacher, enhancing the individual branch's classification performance and consequently the overall ensemble performance. Experimental results show that our method achieves state-of-the-art classification accuracy and higher uncertainty estimation performance compared to previous low-cost ensemble methods. The code is available at https://github.com/hjdw2/SEMBG.
<div id='section'>Paperid: <span id='pid'>161, <a href='https://arxiv.org/pdf/2408.01284.pdf' target='_blank'>https://arxiv.org/pdf/2408.01284.pdf</a></span>   <span><a href='https://github.com/liuyuan-wen/AV-OOD-GZSL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Liuyuan Wen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01284">Out-Of-Distribution Detection for Audio-visual Generalized Zero-Shot Learning: A General Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generalized Zero-Shot Learning (GZSL) is a challenging task requiring accurate classification of both seen and unseen classes. Within this domain, Audio-visual GZSL emerges as an extremely exciting yet difficult task, given the inclusion of both visual and acoustic features as multi-modal inputs. Existing efforts in this field mostly utilize either embedding-based or generative-based methods. However, generative training is difficult and unstable, while embedding-based methods often encounter domain shift problem. Thus, we find it promising to integrate both methods into a unified framework to leverage their advantages while mitigating their respective disadvantages. Our study introduces a general framework employing out-of-distribution (OOD) detection, aiming to harness the strengths of both approaches. We first employ generative adversarial networks to synthesize unseen features, enabling the training of an OOD detector alongside classifiers for seen and unseen classes. This detector determines whether a test feature belongs to seen or unseen classes, followed by classification utilizing separate classifiers for each feature type. We test our framework on three popular audio-visual datasets and observe a significant improvement comparing to existing state-of-the-art works. Codes can be found in https://github.com/liuyuan-wen/AV-OOD-GZSL.
<div id='section'>Paperid: <span id='pid'>162, <a href='https://arxiv.org/pdf/2408.00169.pdf' target='_blank'>https://arxiv.org/pdf/2408.00169.pdf</a></span>   <span><a href='https://github.com/Vujas-Eteph/LazyXMem' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>StÃ©phane VujasinoviÄ, Stefan Becker, Sebastian Bullinger, Norbert Scherer-Negenborn, Michael Arens, Rainer Stiefelhagen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00169">Strike the Balance: On-the-Fly Uncertainty based User Interactions for Long-Term Video Object Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce a variant of video object segmentation (VOS) that bridges interactive and semi-automatic approaches, termed Lazy Video Object Segmentation (ziVOS). In contrast, to both tasks, which handle video object segmentation in an off-line manner (i.e., pre-recorded sequences), we propose through ziVOS to target online recorded sequences. Here, we strive to strike a balance between performance and robustness for long-term scenarios by soliciting user feedback's on-the-fly during the segmentation process. Hence, we aim to maximize the tracking duration of an object of interest, while requiring minimal user corrections to maintain tracking over an extended period. We propose a competitive baseline, i.e., Lazy-XMem, as a reference for future works in ziVOS. Our proposed approach uses an uncertainty estimation of the tracking state to determine whether a user interaction is necessary to refine the model's prediction. To quantitatively assess the performance of our method and the user's workload, we introduce complementary metrics alongside those already established in the field. We evaluate our approach using the recently introduced LVOS dataset, which offers numerous long-term videos. Our code is publicly available at https://github.com/Vujas-Eteph/LazyXMem.
<div id='section'>Paperid: <span id='pid'>163, <a href='https://arxiv.org/pdf/2407.21794.pdf' target='_blank'>https://arxiv.org/pdf/2407.21794.pdf</a></span>   <span><a href='https://github.com/AtsuMiyai/Awesome-OOD-VLM' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/AtsuMiyai/Awesome-OOD-VLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, Ziwei Liu, Toshihiko Yamasaki, Kiyoharu Aizawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21794">Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD). To unify these problems, a generalized OOD detection framework was proposed, taxonomically categorizing these five problems. However, Vision Language Models (VLMs) such as CLIP have significantly changed the paradigm and blurred the boundaries between these fields, again confusing researchers. In this survey, we first present a generalized OOD detection v2, encapsulating the evolution of these fields in the VLM era. Our framework reveals that, with some field inactivity and integration, the demanding challenges have become OOD detection and AD. Then, we highlight the significant shift in the definition, problem settings, and benchmarks; we thus feature a comprehensive review of the methodology for OOD detection and related tasks to clarify their relationship to OOD detection. Finally, we explore the advancements in the emerging Large Vision Language Model (LVLM) era, such as GPT-4V. We conclude with open challenges and future directions. The resource is available at https://github.com/AtsuMiyai/Awesome-OOD-VLM.
<div id='section'>Paperid: <span id='pid'>164, <a href='https://arxiv.org/pdf/2407.16725.pdf' target='_blank'>https://arxiv.org/pdf/2407.16725.pdf</a></span>   <span><a href='https://github.com/alibaba/catex' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/alibaba/catex' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Liu, Zhihang Fu, Chao Chen, Sheng Jin, Ze Chen, Mingyuan Tao, Rongxin Jiang, Jieping Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16725">Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The key to OOD detection has two aspects: generalized feature representation and precise category description. Recently, vision-language models such as CLIP provide significant advances in both two issues, but constructing precise category descriptions is still in its infancy due to the absence of unseen categories. This work introduces two hierarchical contexts, namely perceptual context and spurious context, to carefully describe the precise category boundary through automatic prompt tuning. Specifically, perceptual contexts perceive the inter-category difference (e.g., cats vs apples) for current classification tasks, while spurious contexts further identify spurious (similar but exactly not) OOD samples for every single category (e.g., cats vs panthers, apples vs peaches). The two contexts hierarchically construct the precise description for a certain category, which is, first roughly classifying a sample to the predicted category and then delicately identifying whether it is truly an ID sample or actually OOD. Moreover, the precise descriptions for those categories within the vision-language framework present a novel application: CATegory-EXtensible OOD detection (CATEX). One can efficiently extend the set of recognizable categories by simply merging the hierarchical contexts learned under different sub-task settings. And extensive experiments are conducted to demonstrate CATEX's effectiveness, robustness, and category-extensibility. For instance, CATEX consistently surpasses the rivals by a large margin with several protocols on the challenging ImageNet-1K dataset. In addition, we offer new insights on how to efficiently scale up the prompt engineering in vision-language models to recognize thousands of object categories, as well as how to incorporate large language models (like GPT-3) to boost zero-shot applications. Code is publicly available at https://github.com/alibaba/catex.
<div id='section'>Paperid: <span id='pid'>165, <a href='https://arxiv.org/pdf/2407.16430.pdf' target='_blank'>https://arxiv.org/pdf/2407.16430.pdf</a></span>   <span><a href='https://github.com/alibaba/imood' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/alibaba/imood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Liu, Zhihang Fu, Sheng Jin, Chao Chen, Ze Chen, Rongxin Jiang, Fan Zhou, Yaowu Chen, Jieping Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16430">Rethinking Out-of-Distribution Detection on Imbalanced Data Distribution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting and rejecting unknown out-of-distribution (OOD) samples is critical for deployed neural networks to void unreliable predictions. In real-world scenarios, however, the efficacy of existing OOD detection methods is often impeded by the inherent imbalance of in-distribution (ID) data, which causes significant performance decline. Through statistical observations, we have identified two common challenges faced by different OOD detectors: misidentifying tail class ID samples as OOD, while erroneously predicting OOD samples as head class from ID. To explain this phenomenon, we introduce a generalized statistical framework, termed ImOOD, to formulate the OOD detection problem on imbalanced data distribution. Consequently, the theoretical analysis reveals that there exists a class-aware bias item between balanced and imbalanced OOD detection, which contributes to the performance gap. Building upon this finding, we present a unified training-time regularization technique to mitigate the bias and boost imbalanced OOD detectors across architecture designs. Our theoretically grounded method translates into consistent improvements on the representative CIFAR10-LT, CIFAR100-LT, and ImageNet-LT benchmarks against several state-of-the-art OOD detection approaches. Code is available at https://github.com/alibaba/imood.
<div id='section'>Paperid: <span id='pid'>166, <a href='https://arxiv.org/pdf/2407.15773.pdf' target='_blank'>https://arxiv.org/pdf/2407.15773.pdf</a></span>   <span><a href='https://github.com/yuyongcan/STAMP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongcan Yu, Lijun Sheng, Ran He, Jian Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15773">STAMP: Outlier-Aware Test-Time Adaptation with Stable Memory Replay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to address the distribution shift between the training and test data with only unlabeled data at test time. Existing TTA methods often focus on improving recognition performance specifically for test data associated with classes in the training set. However, during the open-world inference process, there are inevitably test data instances from unknown classes, commonly referred to as outliers. This paper pays attention to the problem that conducts both sample recognition and outlier rejection during inference while outliers exist. To address this problem, we propose a new approach called STAble Memory rePlay (STAMP), which performs optimization over a stable memory bank instead of the risky mini-batch. In particular, the memory bank is dynamically updated by selecting low-entropy and label-consistent samples in a class-balanced manner. In addition, we develop a self-weighted entropy minimization strategy that assigns higher weight to low-entropy samples. Extensive results demonstrate that STAMP outperforms existing TTA methods in terms of both recognition and outlier detection performance. The code is released at https://github.com/yuyongcan/STAMP.
<div id='section'>Paperid: <span id='pid'>167, <a href='https://arxiv.org/pdf/2407.14230.pdf' target='_blank'>https://arxiv.org/pdf/2407.14230.pdf</a></span>   <span><a href='https://github.com/master-Shix/ETSCL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyuan Yang, Bo Zhang, Yufei Shi, Ningze Zhong, Johnathan Loh, Huihui Fang, Yanwu Xu, Si Yong Yeo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14230">ETSCL: An Evidence Theory-Based Supervised Contrastive Learning Framework for Multi-modal Glaucoma Grading</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Glaucoma is one of the leading causes of vision impairment. Digital imaging techniques, such as color fundus photography (CFP) and optical coherence tomography (OCT), provide quantitative and noninvasive methods for glaucoma diagnosis. Recently, in the field of computer-aided glaucoma diagnosis, multi-modality methods that integrate the CFP and OCT modalities have achieved greater diagnostic accuracy compared to single-modality methods. However, it remains challenging to extract reliable features due to the high similarity of medical images and the unbalanced multi-modal data distribution. Moreover, existing methods overlook the uncertainty estimation of different modalities, leading to unreliable predictions. To address these challenges, we propose a novel framework, namely ETSCL, which consists of a contrastive feature extraction stage and a decision-level fusion stage. Specifically, the supervised contrastive loss is employed to enhance the discriminative power in the feature extraction process, resulting in more effective features. In addition, we utilize the Frangi vesselness algorithm as a preprocessing step to incorporate vessel information to assist in the prediction. In the decision-level fusion stage, an evidence theory-based multi-modality classifier is employed to combine multi-source information with uncertainty estimation. Extensive experiments demonstrate that our method achieves state-of-the-art performance. The code is available at \url{https://github.com/master-Shix/ETSCL}.
<div id='section'>Paperid: <span id='pid'>168, <a href='https://arxiv.org/pdf/2407.14208.pdf' target='_blank'>https://arxiv.org/pdf/2407.14208.pdf</a></span>   <span><a href='https://github.com/pascalschlachter/GMM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pascal Schlachter, Simon Wagner, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14208">Memory-Efficient Pseudo-Labeling for Online Source-Free Universal Domain Adaptation using a Gaussian Mixture Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In practice, domain shifts are likely to occur between training and test data, necessitating domain adaptation (DA) to adjust the pre-trained source model to the target domain. Recently, universal domain adaptation (UniDA) has gained attention for addressing the possibility of an additional category (label) shift between the source and target domain. This means new classes can appear in the target data, some source classes may no longer be present, or both at the same time. For practical applicability, UniDA methods must handle both source-free and online scenarios, enabling adaptation without access to the source data and performing batch-wise updates in parallel with prediction. In an online setting, preserving knowledge across batches is crucial. However, existing methods often require substantial memory, which is impractical because memory is limited and valuable, in particular on embedded systems. Therefore, we consider memory-efficiency as an additional constraint. To achieve memory-efficient online source-free universal domain adaptation (SF-UniDA), we propose a novel method that continuously captures the distribution of known classes in the feature space using a Gaussian mixture model (GMM). This approach, combined with entropy-based out-of-distribution detection, allows for the generation of reliable pseudo-labels. Finally, we combine a contrastive loss with a KL divergence loss to perform the adaptation. Our approach not only achieves state-of-the-art results in all experiments on the DomainNet and Office-Home datasets but also significantly outperforms the existing methods on the challenging VisDA-C dataset, setting a new benchmark for online SF-UniDA. Our code is available at https://github.com/pascalschlachter/GMM.
<div id='section'>Paperid: <span id='pid'>169, <a href='https://arxiv.org/pdf/2407.13163.pdf' target='_blank'>https://arxiv.org/pdf/2407.13163.pdf</a></span>   <span><a href='https://github.com/ArronDZhang/ROLeR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Zhang, Ruihong Qiu, Jiajun Liu, Sen Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13163">ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline reinforcement learning (RL) is an effective tool for real-world recommender systems with its capacity to model the dynamic interest of users and its interactive nature. Most existing offline RL recommender systems focus on model-based RL through learning a world model from offline data and building the recommendation policy by interacting with this model. Although these methods have made progress in the recommendation performance, the effectiveness of model-based offline RL methods is often constrained by the accuracy of the estimation of the reward model and the model uncertainties, primarily due to the extreme discrepancy between offline logged data and real-world data in user interactions with online platforms. To fill this gap, a more accurate reward model and uncertainty estimation are needed for the model-based RL methods. In this paper, a novel model-based Reward Shaping in Offline Reinforcement Learning for Recommender Systems, ROLeR, is proposed for reward and uncertainty estimation in recommendation systems. Specifically, a non-parametric reward shaping method is designed to refine the reward model. In addition, a flexible and more representative uncertainty penalty is designed to fit the needs of recommendation systems. Extensive experiments conducted on four benchmark datasets showcase that ROLeR achieves state-of-the-art performance compared with existing baselines. The source code can be downloaded at https://github.com/ArronDZhang/ROLeR.
<div id='section'>Paperid: <span id='pid'>170, <a href='https://arxiv.org/pdf/2407.11735.pdf' target='_blank'>https://arxiv.org/pdf/2407.11735.pdf</a></span>   <span><a href='https://github.com/walline/prosub' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Erik Wallin, Lennart Svensson, Fredrik Kahl, Lars Hammarstrand
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11735">ProSub: Probabilistic Open-Set Semi-Supervised Learning with Subspace-Based Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In open-set semi-supervised learning (OSSL), we consider unlabeled datasets that may contain unknown classes. Existing OSSL methods often use the softmax confidence for classifying data as in-distribution (ID) or out-of-distribution (OOD). Additionally, many works for OSSL rely on ad-hoc thresholds for ID/OOD classification, without considering the statistics of the problem. We propose a new score for ID/OOD classification based on angles in feature space between data and an ID subspace. Moreover, we propose an approach to estimate the conditional distributions of scores given ID or OOD data, enabling probabilistic predictions of data being ID or OOD. These components are put together in a framework for OSSL, termed \emph{ProSub}, that is experimentally shown to reach SOTA performance on several benchmark problems. Our code is available at https://github.com/walline/prosub.
<div id='section'>Paperid: <span id='pid'>171, <a href='https://arxiv.org/pdf/2407.11282.pdf' target='_blank'>https://arxiv.org/pdf/2407.11282.pdf</a></span>   <span><a href='https://github.com/qcznlp/uncertainty_attack' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingcheng Zeng, Mingyu Jin, Qinkai Yu, Zhenting Wang, Wenyue Hua, Zihao Zhou, Guangyan Sun, Yanda Meng, Shiqing Ma, Qifan Wang, Felix Juefei-Xu, Kaize Ding, Fan Yang, Ruixiang Tang, Yongfeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11282">Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are employed across various high-stakes domains, where the reliability of their outputs is crucial. One commonly used method to assess the reliability of LLMs' responses is uncertainty estimation, which gauges the likelihood of their answers being correct. While many studies focus on improving the accuracy of uncertainty estimations for LLMs, our research investigates the fragility of uncertainty estimation and explores potential attacks. We demonstrate that an attacker can embed a backdoor in LLMs, which, when activated by a specific trigger in the input, manipulates the model's uncertainty without affecting the final output. Specifically, the proposed backdoor attack method can alter an LLM's output probability distribution, causing the probability distribution to converge towards an attacker-predefined distribution while ensuring that the top-1 prediction remains unchanged. Our experimental results demonstrate that this attack effectively undermines the model's self-evaluation reliability in multiple-choice questions. For instance, we achieved a 100 attack success rate (ASR) across three different triggering strategies in four models. Further, we investigate whether this manipulation generalizes across different prompts and domains. This work highlights a significant threat to the reliability of LLMs and underscores the need for future defenses against such attacks. The code is available at https://github.com/qcznlp/uncertainty_attack.
<div id='section'>Paperid: <span id='pid'>172, <a href='https://arxiv.org/pdf/2407.07135.pdf' target='_blank'>https://arxiv.org/pdf/2407.07135.pdf</a></span>   <span><a href='https://github.com/paulnovello/multi-ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Novello, Yannick Prudent, Joseba Dalmau, Corentin Friedrich, Yann Pequignot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07135">Improving Out-of-Distribution Detection by Combining Existing Post-hoc Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since the seminal paper of Hendrycks et al. arXiv:1610.02136, Post-hoc deep Out-of-Distribution (OOD) detection has expanded rapidly. As a result, practitioners working on safety-critical applications and seeking to improve the robustness of a neural network now have a plethora of methods to choose from. However, no method outperforms every other on every dataset arXiv:2210.07242, so the current best practice is to test all the methods on the datasets at hand. This paper shifts focus from developing new methods to effectively combining existing ones to enhance OOD detection. We propose and compare four different strategies for integrating multiple detection scores into a unified OOD detector, based on techniques such as majority vote, empirical and copulas-based Cumulative Distribution Function modeling, and multivariate quantiles based on optimal transport. We extend common OOD evaluation metrics -- like AUROC and FPR at fixed TPR rates -- to these multi-dimensional OOD detectors, allowing us to evaluate them and compare them with individual methods on extensive benchmarks. Furthermore, we propose a series of guidelines to choose what OOD detectors to combine in more realistic settings, i.e. in the absence of known OOD data, relying on principles drawn from Outlier Exposure arXiv:1812.04606. The code is available at https://github.com/paulnovello/multi-ood.
<div id='section'>Paperid: <span id='pid'>173, <a href='https://arxiv.org/pdf/2407.06426.pdf' target='_blank'>https://arxiv.org/pdf/2407.06426.pdf</a></span>   <span><a href='https://github.com/lukeyoffe/debunc' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Luke Yoffe, Alfonso Amayuelas, William Yang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06426">DebUnc: Improving Large Language Model Agent Communication With Uncertainty Metrics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-agent debates have been introduced to improve the accuracy of Large Language Models (LLMs) by having multiple agents discuss solutions to a problem over several rounds of debate. However, models often generate incorrect yet confident-sounding responses, which can mislead others. This issue arises partly because agents do not consider how confident their peers are. To address this, we propose DebUnc, a debate framework that uses uncertainty metrics to assess agent confidence. Confidence is then conveyed through a modified attention mechanism that adjusts token weights, or through textual prompts. Evaluations across benchmarks show that attention-based methods are particularly effective and that performance continues to improve as uncertainty estimation becomes more reliable. The code is available at https://github.com/lukeyoffe/debunc.
<div id='section'>Paperid: <span id='pid'>174, <a href='https://arxiv.org/pdf/2407.06045.pdf' target='_blank'>https://arxiv.org/pdf/2407.06045.pdf</a></span>   <span><a href='https://github.com/mala-lab/OpenCIL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjun Miao, Guansong Pang, Trong-Tung Nguyen, Ruohang Fang, Jin Zheng, Xiao Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06045">OpenCIL: Benchmarking Out-of-Distribution Detection in Class-Incremental Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Class incremental learning (CIL) aims to learn a model that can not only incrementally accommodate new classes, but also maintain the learned knowledge of old classes. Out-of-distribution (OOD) detection in CIL is to retain this incremental learning ability, while being able to reject unknown samples that are drawn from different distributions of the learned classes. This capability is crucial to the safety of deploying CIL models in open worlds. However, despite remarkable advancements in the respective CIL and OOD detection, there lacks a systematic and large-scale benchmark to assess the capability of advanced CIL models in detecting OOD samples. To fill this gap, in this study we design a comprehensive empirical study to establish such a benchmark, named $\textbf{OpenCIL}$. To this end, we propose two principled frameworks for enabling four representative CIL models with 15 diverse OOD detection methods, resulting in 60 baseline models for OOD detection in CIL. The empirical evaluation is performed on two popular CIL datasets with six commonly-used OOD datasets. One key observation we find through our comprehensive evaluation is that the CIL models can be severely biased towards the OOD samples and newly added classes when they are exposed to open environments. Motivated by this, we further propose a new baseline for OOD detection in CIL, namely Bi-directional Energy Regularization ($\textbf{BER}$), which is specially designed to mitigate these two biases in different CIL models by having energy regularization on both old and new classes. Its superior performance is justified in our experiments. All codes and datasets are open-source at https://github.com/mala-lab/OpenCIL.
<div id='section'>Paperid: <span id='pid'>175, <a href='https://arxiv.org/pdf/2407.02830.pdf' target='_blank'>https://arxiv.org/pdf/2407.02830.pdf</a></span>   <span><a href='https://github.com/Tsuiky/3DRN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Fang, Tianyu Li, Yanghong Lin, Shudong Zhou, Wei Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02830">A Radiometric Correction based Optical Modeling Approach to Removing Reflection Noise in TLS Point Clouds of Urban Scenes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Point clouds are vital in computer vision tasks such as 3D reconstruction, autonomous driving, and robotics. However, TLS-acquired point clouds often contain virtual points from reflective surfaces, causing disruptions. This study presents a reflection noise elimination algorithm for TLS point clouds. Our innovative reflection plane detection algorithm, based on geometry-optical models and physical properties, identifies and categorizes reflection points per optical reflection theory. We've adapted the LSFH feature descriptor to retain reflection features, mitigating interference from symmetrical architectural structures. By incorporating the Hausdorff feature distance, the algorithm enhances resilience to ghosting and deformation, improving virtual point detection accuracy. Extensive experiments on the 3DRN benchmark dataset, featuring diverse urban environments with virtual TLS reflection noise, show our algorithm improves precision and recall rates for 3D points in reflective regions by 57.03\% and 31.80\%, respectively. Our method achieves a 9.17\% better outlier detection rate and 5.65\% higher accuracy than leading methods. Access the 3DRN dataset at (https://github.com/Tsuiky/3DRN).
<div id='section'>Paperid: <span id='pid'>176, <a href='https://arxiv.org/pdf/2407.01146.pdf' target='_blank'>https://arxiv.org/pdf/2407.01146.pdf</a></span>   <span><a href='https://github.com/aL3x-O-o-Hung/GLCSA_ECLoss' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Ling Yu Hung, Haoxin Zheng, Kai Zhao, Kaifeng Pang, Demetri Terzopoulos, Kyunghyun Sung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01146">Cross-Slice Attention and Evidential Critical Loss for Uncertainty-Aware Prostate Cancer Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current deep learning-based models typically analyze medical images in either 2D or 3D albeit disregarding volumetric information or suffering sub-optimal performance due to the anisotropic resolution of MR data. Furthermore, providing an accurate uncertainty estimation is beneficial to clinicians, as it indicates how confident a model is about its prediction. We propose a novel 2.5D cross-slice attention model that utilizes both global and local information, along with an evidential critical loss, to perform evidential deep learning for the detection in MR images of prostate cancer, one of the most common cancers and a leading cause of cancer-related death in men. We perform extensive experiments with our model on two different datasets and achieve state-of-the-art performance in prostate cancer detection along with improved epistemic uncertainty estimation. The implementation of the model is available at https://github.com/aL3x-O-o-Hung/GLCSA_ECLoss.
<div id='section'>Paperid: <span id='pid'>177, <a href='https://arxiv.org/pdf/2406.18999.pdf' target='_blank'>https://arxiv.org/pdf/2406.18999.pdf</a></span>   <span><a href='https://github.com/mikkoim/dnaimg-ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mikko ImpiÃ¶, Jenni Raitoharju
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18999">Improving Taxonomic Image-based Out-of-distribution Detection With DNA Barcodes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image-based species identification could help scaling biodiversity monitoring to a global scale. Many challenges still need to be solved in order to implement these systems in real-world applications. A reliable image-based monitoring system must detect out-of-distribution (OOD) classes it has not been presented before. This is challenging especially with fine-grained classes. Emerging environmental monitoring techniques, DNA metabarcoding and eDNA, can help by providing information on OOD classes that are present in a sample. In this paper, we study if DNA barcodes can also support in finding the outlier images based on the outlier DNA sequence's similarity to the seen classes. We propose a re-ordering approach that can be easily applied on any pre-trained models and existing OOD detection methods. We experimentally show that the proposed approach improves taxonomic OOD detection compared to all common baselines. We also show that the method works thanks to a correlation between visual similarity and DNA barcode proximity. The code and data are available at https://github.com/mikkoim/dnaimg-ood.
<div id='section'>Paperid: <span id='pid'>178, <a href='https://arxiv.org/pdf/2406.17274.pdf' target='_blank'>https://arxiv.org/pdf/2406.17274.pdf</a></span>   <span><a href='https://github.com/he159ok/Benchmark-of-Uncertainty-Estimation-Methods-in-Text-Summarization' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianfeng He, Runing Yang, Linlin Yu, Changbin Li, Ruoxi Jia, Feng Chen, Ming Jin, Chang-Tien Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.17274">Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Text summarization, a key natural language generation (NLG) task, is vital in various domains. However, the high cost of inaccurate summaries in risk-critical applications, particularly those involving human-in-the-loop decision-making, raises concerns about the reliability of uncertainty estimation on text summarization (UE-TS) evaluation methods. This concern stems from the dependency of uncertainty model metrics on diverse and potentially conflicting NLG metrics. To address this issue, we introduce a comprehensive UE-TS benchmark incorporating 31 NLG metrics across four dimensions. The benchmark evaluates the uncertainty estimation capabilities of two large language models and one pre-trained language model on three datasets, with human-annotation analysis incorporated where applicable. We also assess the performance of 14 common uncertainty estimation methods within this benchmark. Our findings emphasize the importance of considering multiple uncorrelated NLG metrics and diverse uncertainty estimation methods to ensure reliable and efficient evaluation of UE-TS techniques. Our code and data are available https://github.com/he159ok/Benchmark-of-Uncertainty-Estimation-Methods-in-Text-Summarization.
<div id='section'>Paperid: <span id='pid'>179, <a href='https://arxiv.org/pdf/2406.16942.pdf' target='_blank'>https://arxiv.org/pdf/2406.16942.pdf</a></span>   <span><a href='https://github.com/yuanyuanpeng0129/FMUE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanyuan Peng, Aidi Lin, Meng Wang, Tian Lin, Ke Zou, Yinglin Cheng, Tingkun Shi, Xulong Liao, Lixia Feng, Zhen Liang, Xinjian Chen, Huazhu Fu, Haoyu Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16942">Enhancing Diagnostic Reliability of Foundation Model with Uncertainty Estimation in OCT Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inability to express the confidence level and detect unseen classes has limited the clinical implementation of artificial intelligence in the real-world. We developed a foundation model with uncertainty estimation (FMUE) to detect 11 retinal conditions on optical coherence tomography (OCT). In the internal test set, FMUE achieved a higher F1 score of 96.76% than two state-of-the-art algorithms, RETFound and UIOS, and got further improvement with thresholding strategy to 98.44%. In the external test sets obtained from other OCT devices, FMUE achieved an accuracy of 88.75% and 92.73% before and after thresholding. Our model is superior to two ophthalmologists with a higher F1 score (95.17% vs. 61.93% &71.72%). Besides, our model correctly predicts high uncertainty scores for samples with ambiguous features, of non-target-category diseases, or with low-quality to prompt manual checks and prevent misdiagnosis. FMUE provides a trustworthy method for automatic retinal anomalies detection in the real-world clinical open set environment.
<div id='section'>Paperid: <span id='pid'>180, <a href='https://arxiv.org/pdf/2406.16045.pdf' target='_blank'>https://arxiv.org/pdf/2406.16045.pdf</a></span>   <span><a href='https://github.com/edadaltocg/detectors' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Eduardo Dadalto, Florence Alberge, Pierre Duhamel, Pablo Piantanida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16045">Combine and Conquer: A Meta-Analysis on Data Shift and Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a universal approach to seamlessly combine out-of-distribution (OOD) detection scores. These scores encompass a wide range of techniques that leverage the self-confidence of deep learning models and the anomalous behavior of features in the latent space. Not surprisingly, combining such a varied population using simple statistics proves inadequate. To overcome this challenge, we propose a quantile normalization to map these scores into p-values, effectively framing the problem into a multi-variate hypothesis test. Then, we combine these tests using established meta-analysis tools, resulting in a more effective detector with consolidated decision boundaries. Furthermore, we create a probabilistic interpretable criterion by mapping the final statistics into a distribution with known parameters. Through empirical investigation, we explore different types of shifts, each exerting varying degrees of impact on data. Our results demonstrate that our approach significantly improves overall robustness and performance across diverse OOD detection scenarios. Notably, our framework is easily extensible for future developments in detection scores and stands as the first to combine decision boundaries in this context. The code and artifacts associated with this work are publicly available\footnote{\url{https://github.com/edadaltocg/detectors}}.
<div id='section'>Paperid: <span id='pid'>181, <a href='https://arxiv.org/pdf/2406.15523.pdf' target='_blank'>https://arxiv.org/pdf/2406.15523.pdf</a></span>   <span><a href='https://github.com/UB-GOLD/UB-GOLD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yili Wang, Yixin Liu, Xu Shen, Chenyu Li, Kaize Ding, Rui Miao, Ying Wang, Shirui Pan, Xin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.15523">Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To build safe and reliable graph machine learning systems, unsupervised graph-level anomaly detection (GLAD) and unsupervised graph-level out-of-distribution (OOD) detection (GLOD) have received significant attention in recent years. Though those two lines of research indeed share the same objective, they have been studied independently in the community due to distinct evaluation setups, creating a gap that hinders the application and evaluation of methods from one to the other. To bridge the gap, in this work, we present a \underline{\textbf{U}}nified \underline{\textbf{B}}enchmark for unsupervised \underline{\textbf{G}}raph-level \underline{\textbf{O}}OD and anoma\underline{\textbf{L}}y \underline{\textbf{D}}etection (\ourmethod), a comprehensive evaluation framework that unifies GLAD and GLOD under the concept of generalized graph-level OOD detection. Our benchmark encompasses 35 datasets spanning four practical anomaly and OOD detection scenarios, facilitating the comparison of 18 representative GLAD/GLOD methods. We conduct multi-dimensional analyses to explore the effectiveness, OOD sensitivity spectrum, robustness, and efficiency of existing methods, shedding light on their strengths and limitations. Furthermore, we provide an open-source codebase (https://github.com/UB-GOLD/UB-GOLD) of \ourmethod to foster reproducible research and outline potential directions for future investigations based on our insights.
<div id='section'>Paperid: <span id='pid'>182, <a href='https://arxiv.org/pdf/2406.14593.pdf' target='_blank'>https://arxiv.org/pdf/2406.14593.pdf</a></span>   <span><a href='https://github.com/os-hxfan/MCME_FPGA_Acc.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Mark Chen, Liam Castelli, Martin Ferianc, Hongyu Zhou, Shuanglong Liu, Wayne Luk, Hongxiang Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14593">Enhancing Dropout-based Bayesian Neural Networks with Multi-Exit on FPGA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation plays a crucial role in various safety-critical applications such as medical diagnosis and autonomous driving. In recent years, Bayesian neural networks (BayesNNs) have gained substantial research and industrial interests due to their capability to make accurate predictions with reliable uncertainty estimation. However, the algorithmic complexity and the resulting hardware performance of BayesNNs hinder their adoption in real-life applications. To bridge this gap, this paper proposes an algorithm and hardware co-design framework that can generate field-programmable gate array (FPGA)-based accelerators for efficient BayesNNs. At the algorithm level, we propose novel multi-exit dropout-based BayesNNs with reduced computational and memory overheads while achieving high accuracy and quality of uncertainty estimation. At the hardware level, this paper introduces a transformation framework that can generate FPGA-based accelerators for the proposed efficient multi-exit BayesNNs. Several optimization techniques such as the mix of spatial and temporal mappings are introduced to reduce resource consumption and improve the overall hardware performance. Comprehensive experiments demonstrate that our approach can achieve higher energy efficiency compared to CPU, GPU, and other state-of-the-art hardware implementations. To support the future development of this research, we have open-sourced our code at: https://github.com/os-hxfan/MCME_FPGA_Acc.git
<div id='section'>Paperid: <span id='pid'>183, <a href='https://arxiv.org/pdf/2406.12784.pdf' target='_blank'>https://arxiv.org/pdf/2406.12784.pdf</a></span>   <span><a href='https://github.com/Cyno2232/UBENCH' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xunzhi Wang, Zhuowei Zhang, Gaonan Chen, Qiongyu Li, Bitong Luo, Zhixin Han, Haotian Wang, Zhiyu li, Hang Gao, Mengting Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12784">UBench: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite recent progress in systematic evaluation frameworks, benchmarking the uncertainty of large language models (LLMs) remains a highly challenging task. Existing methods for benchmarking the uncertainty of LLMs face three key challenges: the need for internal model access, additional training, or high computational costs. This is particularly unfavorable for closed-source models. To this end, we introduce UBench, a new benchmark for evaluating the uncertainty of LLMs. Unlike other benchmarks, UBench is based on confidence intervals. It encompasses 11,978 multiple-choice questions spanning knowledge, language, understanding, and reasoning capabilities. Based on this, we conduct extensive experiments. This includes comparisons with other advanced uncertainty estimation methods, the assessment of the uncertainty of 20 LLMs, and an exploration of the effects of Chain-of-Thought (CoT) prompts, role-playing (RP) prompts, and temperature on model uncertainty. Our analysis reveals several crucial insights: 1) Our confidence interval-based methods are highly effective for uncertainty quantification; 2) Regarding uncertainty, outstanding open-source models show competitive performance versus closed-source models; 3) CoT and RP prompts present potential ways to improve model reliability, while the influence of temperature changes follows no universal rule. Our implementation is available at https://github.com/Cyno2232/UBENCH.
<div id='section'>Paperid: <span id='pid'>184, <a href='https://arxiv.org/pdf/2406.12629.pdf' target='_blank'>https://arxiv.org/pdf/2406.12629.pdf</a></span>   <span><a href='https://github.com/X1AOX1A/SeTAR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yixia Li, Boya Xiong, Guanhua Chen, Yun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12629">SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for the safe deployment of neural networks. Existing CLIP-based approaches perform OOD detection by devising novel scoring functions or sophisticated fine-tuning methods. In this work, we propose SeTAR, a novel, training-free OOD detection method that leverages selective low-rank approximation of weight matrices in vision-language and vision-only models. SeTAR enhances OOD detection via post-hoc modification of the model's weight matrices using a simple greedy search algorithm. Based on SeTAR, we further propose SeTAR+FT, a fine-tuning extension optimizing model performance for OOD detection tasks. Extensive evaluations on ImageNet1K and Pascal-VOC benchmarks show SeTAR's superior performance, reducing the relatively false positive rate by up to 18.95% and 36.80% compared to zero-shot and fine-tuning baselines. Ablation studies further validate SeTAR's effectiveness, robustness, and generalizability across different model backbones. Our work offers a scalable, efficient solution for OOD detection, setting a new state-of-the-art in this area.
<div id='section'>Paperid: <span id='pid'>185, <a href='https://arxiv.org/pdf/2406.11657.pdf' target='_blank'>https://arxiv.org/pdf/2406.11657.pdf</a></span>   <span><a href='https://github.com/dong-river/Personalized-Judge' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijiang River Dong, Tiancheng Hu, Nigel Collier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11657">Can LLM be a Personalized Judge?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensuring that large language models (LLMs) reflect diverse user values and preferences is crucial as their user bases expand globally. It is therefore encouraging to see the growing interest in LLM personalization within the research community. However, current works often rely on the LLM-as-a-Judge approach for evaluation without thoroughly examining its validity. In this paper, we investigate the reliability of LLM-as-a-Personalized-Judge, asking LLMs to judge user preferences based on personas. Our findings suggest that directly applying LLM-as-a-Personalized-Judge is less reliable than previously assumed, showing low and inconsistent agreement with human ground truth. The personas typically used are often overly simplistic, resulting in low predictive power. To address these issues, we introduce verbal uncertainty estimation into the LLM-as-a-Personalized-Judge pipeline, allowing the model to express low confidence on uncertain judgments. This adjustment leads to much higher agreement (above 80%) on high-certainty samples for binary tasks. Through human evaluation, we find that the LLM-as-a-Personalized-Judge achieves comparable performance to third-party humans evaluation and even surpasses human performance on high-certainty samples. Our work indicates that certainty-enhanced LLM-as-a-Personalized-Judge offers a promising direction for developing more reliable and scalable methods for evaluating LLM personalization.
<div id='section'>Paperid: <span id='pid'>186, <a href='https://arxiv.org/pdf/2406.09867.pdf' target='_blank'>https://arxiv.org/pdf/2406.09867.pdf</a></span>   <span><a href='https://github.com/qqwsad5/IS-OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingming Long, Jie Zhang, Shiguang Shan, Xilin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09867">Rethinking the Evaluation of Out-of-Distribution Detection: A Sorites Paradox</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most existing out-of-distribution (OOD) detection benchmarks classify samples with novel labels as the OOD data. However, some marginal OOD samples actually have close semantic contents to the in-distribution (ID) sample, which makes determining the OOD sample a Sorites Paradox. In this paper, we construct a benchmark named Incremental Shift OOD (IS-OOD) to address the issue, in which we divide the test samples into subsets with different semantic and covariate shift degrees relative to the ID dataset. The data division is achieved through a shift measuring method based on our proposed Language Aligned Image feature Decomposition (LAID). Moreover, we construct a Synthetic Incremental Shift (Syn-IS) dataset that contains high-quality generated images with more diverse covariate contents to complement the IS-OOD benchmark. We evaluate current OOD detection methods on our benchmark and find several important insights: (1) The performance of most OOD detection methods significantly improves as the semantic shift increases; (2) Some methods like GradNorm may have different OOD detection mechanisms as they rely less on semantic shifts to make decisions; (3) Excessive covariate shifts in the image are also likely to be considered as OOD for some methods. Our code and data are released in https://github.com/qqwsad5/IS-OOD.
<div id='section'>Paperid: <span id='pid'>187, <a href='https://arxiv.org/pdf/2406.09486.pdf' target='_blank'>https://arxiv.org/pdf/2406.09486.pdf</a></span>   <span><a href='https://sites.google.com/view/semopo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shenghua Wan, Ziyuan Chen, Le Gan, Shuai Feng, De-Chuan Zhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09486">SeMOPO: Learning High-quality Model and Policy from Low-quality Offline Visual Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model-based offline reinforcement Learning (RL) is a promising approach that leverages existing data effectively in many real-world applications, especially those involving high-dimensional inputs like images and videos. To alleviate the distribution shift issue in offline RL, existing model-based methods heavily rely on the uncertainty of learned dynamics. However, the model uncertainty estimation becomes significantly biased when observations contain complex distractors with non-trivial dynamics. To address this challenge, we propose a new approach - \emph{Separated Model-based Offline Policy Optimization} (SeMOPO) - decomposing latent states into endogenous and exogenous parts via conservative sampling and estimating model uncertainty on the endogenous states only. We provide a theoretical guarantee of model uncertainty and performance bound of SeMOPO. To assess the efficacy, we construct the Low-Quality Vision Deep Data-Driven Datasets for RL (LQV-D4RL), where the data are collected by non-expert policy and the observations include moving distractors. Experimental results show that our method substantially outperforms all baseline methods, and further analytical experiments validate the critical designs in our method. The project website is \href{https://sites.google.com/view/semopo}{https://sites.google.com/view/semopo}.
<div id='section'>Paperid: <span id='pid'>188, <a href='https://arxiv.org/pdf/2406.09240.pdf' target='_blank'>https://arxiv.org/pdf/2406.09240.pdf</a></span>   <span><a href='https://wlin-at.github.io/cad_vi' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Lin, Muhammad Jehanzeb Mirza, Sivan Doveh, Rogerio Feris, Raja Giryes, Sepp Hochreiter, Leonid Karlinsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09240">Comparison Visual Instruction Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Comparing two images in terms of Commonalities and Differences (CaD) is a fundamental human capability that forms the basis of advanced visual reasoning and interpretation. It is essential for the generation of detailed and contextually relevant descriptions, performing comparative analysis, novelty detection, and making informed decisions based on visual data. However, surprisingly, little attention has been given to these fundamental concepts in the best current mimic of human visual intelligence - Large Multimodal Models (LMMs). We develop and contribute a new two-phase approach CaD-VI for collecting synthetic visual instructions, together with an instruction-following dataset CaD-Inst containing 349K image pairs with CaD instructions collected using CaD-VI. Our approach significantly improves the CaD spotting capabilities in LMMs, advancing the SOTA on a diverse set of related tasks by up to 17.5%. It is also complementary to existing difference-only instruction datasets, allowing automatic targeted refinement of those resources increasing their effectiveness for CaD tuning by up to 10%. Additionally, we propose an evaluation benchmark with 7.5K open-ended QAs to assess the CaD understanding abilities of LMMs.
<div id='section'>Paperid: <span id='pid'>189, <a href='https://arxiv.org/pdf/2406.02103.pdf' target='_blank'>https://arxiv.org/pdf/2406.02103.pdf</a></span>   <span><a href='https://github.com/nirgreshler/bayesian-online-planning' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nir Greshler, David Ben Eli, Carmel Rabinovitz, Gabi Guetta, Liran Gispan, Guy Zohar, Aviv Tamar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02103">A Bayesian Approach to Online Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The combination of Monte Carlo tree search and neural networks has revolutionized online planning. As neural network approximations are often imperfect, we ask whether uncertainty estimates about the network outputs could be used to improve planning. We develop a Bayesian planning approach that facilitates such uncertainty quantification, inspired by classical ideas from the meta-reasoning literature. We propose a Thompson sampling based algorithm for searching the tree of possible actions, for which we prove the first (to our knowledge) finite time Bayesian regret bound, and propose an efficient implementation for a restricted family of posterior distributions. In addition we propose a variant of the Bayes-UCB method applied to trees. Empirically, we demonstrate that on the ProcGen Maze and Leaper environments, when the uncertainty estimates are accurate but the neural network output is inaccurate, our Bayesian approach searches the tree much more effectively. In addition, we investigate whether popular uncertainty estimation methods are accurate enough to yield significant gains in planning. Our code is available at: https://github.com/nirgreshler/bayesian-online-planning.
<div id='section'>Paperid: <span id='pid'>190, <a href='https://arxiv.org/pdf/2406.00806.pdf' target='_blank'>https://arxiv.org/pdf/2406.00806.pdf</a></span>   <span><a href='https://github.com/tmlr-group/EOE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chentao Cao, Zhun Zhong, Zhanke Zhou, Yang Liu, Tongliang Liu, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00806">Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is essential when deploying machine learning models in open-world scenarios. Zero-shot OOD detection, requiring no training on in-distribution (ID) data, has been possible with the advent of vision-language models like CLIP. Existing methods build a text-based classifier with only closed-set labels. However, this largely restricts the inherent capability of CLIP to recognize samples from large and open label space. In this paper, we propose to tackle this constraint by leveraging the expert knowledge and reasoning capability of large language models (LLM) to Envision potential Outlier Exposure, termed EOE, without access to any actual OOD data. Owing to better adaptation to open-world scenarios, EOE can be generalized to different tasks, including far, near, and fine-grained OOD detection. Technically, we design (1) LLM prompts based on visual similarity to generate potential outlier class labels specialized for OOD detection, as well as (2) a new score function based on potential outlier penalty to distinguish hard OOD samples effectively. Empirically, EOE achieves state-of-the-art performance across different OOD tasks and can be effectively scaled to the ImageNet-1K dataset. The code is publicly available at: https://github.com/tmlr-group/EOE.
<div id='section'>Paperid: <span id='pid'>191, <a href='https://arxiv.org/pdf/2406.00345.pdf' target='_blank'>https://arxiv.org/pdf/2406.00345.pdf</a></span>   <span><a href='https://wnjxyk.github.io/DeCoOp' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhi Zhou, Ming Yang, Jiang-Xin Shi, Lan-Zhe Guo, Yu-Feng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00345">DeCoOp: Robust Prompt Tuning with Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs), such as CLIP, have demonstrated impressive zero-shot capabilities for various downstream tasks. Their performance can be further enhanced through few-shot prompt tuning methods. However, current studies evaluate the performance of learned prompts separately on base and new classes. This evaluation lacks practicality for real-world applications since downstream tasks cannot determine whether the data belongs to base or new classes in advance. In this paper, we explore a problem setting called Open-world Prompt Tuning (OPT), which involves tuning prompts on base classes and evaluating on a combination of base and new classes. By introducing Decomposed Prompt Tuning framework (DePT), we theoretically demonstrate that OPT can be solved by incorporating out-of-distribution detection into prompt tuning, thereby enhancing the base-to-new discriminability. Based on DePT, we present a novel prompt tuning approach, namely, Decomposed Context Optimization (DeCoOp), which introduces new-class detectors and sub-classifiers to further enhance the base-class and new-class discriminability. Experimental results on 11 benchmark datasets validate the effectiveness of DePT and demonstrate that DeCoOp outperforms current state-of-the-art methods, providing a significant 2% average accuracy improvement.
<div id='section'>Paperid: <span id='pid'>192, <a href='https://arxiv.org/pdf/2405.19882.pdf' target='_blank'>https://arxiv.org/pdf/2405.19882.pdf</a></span>   <span><a href='https://github.com/vojirt/PixOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>TomÃ¡Å¡ VojÃ­Å, Jan Å ochman, JiÅÃ­ Matas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19882">PixOOD: Pixel-Level Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a dense image prediction out-of-distribution detection algorithm, called PixOOD, which does not require training on samples of anomalous data and is not designed for a specific application which avoids traditional training biases. In order to model the complex intra-class variability of the in-distribution data at the pixel level, we propose an online data condensation algorithm which is more robust than standard K-means and is easily trainable through SGD. We evaluate PixOOD on a wide range of problems. It achieved state-of-the-art results on four out of seven datasets, while being competitive on the rest. The source code is available at https://github.com/vojirt/PixOOD.
<div id='section'>Paperid: <span id='pid'>193, <a href='https://arxiv.org/pdf/2405.18635.pdf' target='_blank'>https://arxiv.org/pdf/2405.18635.pdf</a></span>   <span><a href='https://github.com/deeplearning-wisc/id_label' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Du, Yiyou Sun, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18635">When and How Does In-Distribution Label Help Out-of-Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting data points deviating from the training distribution is pivotal for ensuring reliable machine learning. Extensive research has been dedicated to the challenge, spanning classical anomaly detection techniques to contemporary out-of-distribution (OOD) detection approaches. While OOD detection commonly relies on supervised learning from a labeled in-distribution (ID) dataset, anomaly detection may treat the entire ID data as a single class and disregard ID labels. This fundamental distinction raises a significant question that has yet to be rigorously explored: when and how does ID label help OOD detection? This paper bridges this gap by offering a formal understanding to theoretically delineate the impact of ID labels on OOD detection. We employ a graph-theoretic approach, rigorously analyzing the separability of ID data from OOD data in a closed-form manner. Key to our approach is the characterization of data representations through spectral decomposition on the graph. Leveraging these representations, we establish a provable error bound that compares the OOD detection performance with and without ID labels, unveiling conditions for achieving enhanced OOD detection. Lastly, we present empirical results on both simulated and real datasets, validating theoretical guarantees and reinforcing our insights. Code is publicly available at https://github.com/deeplearning-wisc/id_label.
<div id='section'>Paperid: <span id='pid'>194, <a href='https://arxiv.org/pdf/2405.17816.pdf' target='_blank'>https://arxiv.org/pdf/2405.17816.pdf</a></span>   <span><a href='https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingwen Wu, Ruiji Yu, Xinwen Cheng, Zhengbao He, Xiaolin Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17816">Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the open world, detecting out-of-distribution (OOD) data, whose labels are disjoint with those of in-distribution (ID) samples, is important for reliable deep neural networks (DNNs). To achieve better detection performance, one type of approach proposes to fine-tune the model with auxiliary OOD datasets to amplify the difference between ID and OOD data through a separation loss defined on model outputs. However, none of these studies consider enlarging the feature disparity, which should be more effective compared to outputs. The main difficulty lies in the diversity of OOD samples, which makes it hard to describe their feature distribution, let alone design losses to separate them from ID features. In this paper, we neatly fence off the problem based on an aggregation property of ID features named Neural Collapse (NC). NC means that the penultimate features of ID samples within a class are nearly identical to the last layer weight of the corresponding class. Based on this property, we propose a simple but effective loss called Separation Loss, which binds the features of OOD data in a subspace orthogonal to the principal subspace of ID features formed by NC. In this way, the features of ID and OOD samples are separated by different dimensions. By optimizing the feature separation loss rather than purely enlarging output differences, our detection achieves SOTA performance on CIFAR10, CIFAR100 and ImageNet benchmarks without any additional data augmentation or sampling, demonstrating the importance of feature separation in OOD detection. Code is available at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.
<div id='section'>Paperid: <span id='pid'>195, <a href='https://arxiv.org/pdf/2405.17419.pdf' target='_blank'>https://arxiv.org/pdf/2405.17419.pdf</a></span>   <span><a href='https://github.com/donghao51/MultiOOD' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/donghao51/MultiOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Dong, Yue Zhao, Eleni Chatzi, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17419">MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is important for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. Existing research has mainly focused on unimodal scenarios on image data. However, real-world applications are inherently multimodal, which makes it essential to leverage information from multiple modalities to enhance the efficacy of OOD detection. To establish a foundation for more realistic Multimodal OOD Detection, we introduce the first-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes and varying modality combinations. We first evaluate existing unimodal OOD detection algorithms on MultiOOD, observing that the mere inclusion of additional modalities yields substantial improvements. This underscores the importance of utilizing multiple modalities for OOD detection. Based on the observation of Modality Prediction Discrepancy between in-distribution (ID) and OOD data, and its strong correlation with OOD performance, we propose the Agree-to-Disagree (A2D) algorithm to encourage such discrepancy during training. Moreover, we introduce a novel outlier synthesis method, NP-Mix, which explores broader feature spaces by leveraging the information from nearest neighbor classes and complements A2D to strengthen OOD detection performance. Extensive experiments on MultiOOD demonstrate that training with A2D and NP-Mix improves existing OOD detection algorithms by a large margin. Our source code and MultiOOD benchmark are available at https://github.com/donghao51/MultiOOD.
<div id='section'>Paperid: <span id='pid'>196, <a href='https://arxiv.org/pdf/2405.16102.pdf' target='_blank'>https://arxiv.org/pdf/2405.16102.pdf</a></span>   <span><a href='https://github.com/zenghy96/Reliable-Source-Approximation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongye Zeng, Ke Zou, Zhihao Chen, Rui Zheng, Huazhu Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16102">Reliable Source Approximation: Source-Free Unsupervised Domain Adaptation for Vestibular Schwannoma MRI Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Source-Free Unsupervised Domain Adaptation (SFUDA) has recently become a focus in the medical image domain adaptation, as it only utilizes the source model and does not require annotated target data. However, current SFUDA approaches cannot tackle the complex segmentation task across different MRI sequences, such as the vestibular schwannoma segmentation. To address this problem, we proposed Reliable Source Approximation (RSA), which can generate source-like and structure-preserved images from the target domain for updating model parameters and adapting domain shifts. Specifically, RSA deploys a conditional diffusion model to generate multiple source-like images under the guidance of varying edges of one target image. An uncertainty estimation module is then introduced to predict and refine reliable pseudo labels of generated images, and the prediction consistency is developed to select the most reliable generations. Subsequently, all reliable generated images and their pseudo labels are utilized to update the model. Our RSA is validated on vestibular schwannoma segmentation across multi-modality MRI. The experimental results demonstrate that RSA consistently improves domain adaptation performance over other state-of-the-art SFUDA methods. Code is available at https://github.com/zenghy96/Reliable-Source-Approximation.
<div id='section'>Paperid: <span id='pid'>197, <a href='https://arxiv.org/pdf/2405.13758.pdf' target='_blank'>https://arxiv.org/pdf/2405.13758.pdf</a></span>   <span><a href='https://github.com/olivesgatech/GradTrust' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohit Prabhushankar, Ghassan AlRegib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13758">Counterfactual Gradients-based Quantification of Prediction Trust in Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The widespread adoption of deep neural networks in machine learning calls for an objective quantification of esoteric trust. In this paper we propose GradTrust, a classification trust measure for large-scale neural networks at inference. The proposed method utilizes variance of counterfactual gradients, i.e. the required changes in the network parameters if the label were different. We show that GradTrust is superior to existing techniques for detecting misprediction rates on $50000$ images from ImageNet validation dataset. Depending on the network, GradTrust detects images where either the ground truth is incorrect or ambiguous, or the classes are co-occurring. We extend GradTrust to Video Action Recognition on Kinetics-400 dataset. We showcase results on $14$ architectures pretrained on ImageNet and $5$ architectures pretrained on Kinetics-400. We observe the following: (i) simple methodologies like negative log likelihood and margin classifiers outperform state-of-the-art uncertainty and out-of-distribution detection techniques for misprediction rates, and (ii) the proposed GradTrust is in the Top-2 performing methods on $37$ of the considered $38$ experimental modalities. The code is available at: https://github.com/olivesgatech/GradTrust
<div id='section'>Paperid: <span id='pid'>198, <a href='https://arxiv.org/pdf/2405.11881.pdf' target='_blank'>https://arxiv.org/pdf/2405.11881.pdf</a></span>   <span><a href='https://github.com/clear-nus/diffpath' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alvin Heng, Alexandre H. Thiery, Harold Soh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11881">Out-of-Distribution Detection with a Single Unconditional Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical task in machine learning that seeks to identify abnormal samples. Traditionally, unsupervised methods utilize a deep generative model for OOD detection. However, such approaches require a new model to be trained for each inlier dataset. This paper explores whether a single model can perform OOD detection across diverse tasks. To that end, we introduce Diffusion Paths (DiffPath), which uses a single diffusion model originally trained to perform unconditional generation for OOD detection. We introduce a novel technique of measuring the rate-of-change and curvature of the diffusion paths connecting samples to the standard normal. Extensive experiments show that with a single model, DiffPath is competitive with prior work using individual models on a variety of OOD tasks involving different distributions. Our code is publicly available at https://github.com/clear-nus/diffpath.
<div id='section'>Paperid: <span id='pid'>199, <a href='https://arxiv.org/pdf/2405.04405.pdf' target='_blank'>https://arxiv.org/pdf/2405.04405.pdf</a></span>   <span><a href='https://github.com/liupei101/MIREL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei Liu, Luping Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.04405">Weakly-Supervised Residual Evidential Learning for Multi-Instance Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation (UE), as an effective means of quantifying predictive uncertainty, is crucial for safe and reliable decision-making, especially in high-risk scenarios. Existing UE schemes usually assume that there are completely-labeled samples to support fully-supervised learning. In practice, however, many UE tasks often have no sufficiently-labeled data to use, such as the Multiple Instance Learning (MIL) with only weak instance annotations. To bridge this gap, this paper, for the first time, addresses the weakly-supervised issue of Multi-Instance UE (MIUE) and proposes a new baseline scheme, Multi-Instance Residual Evidential Learning (MIREL). Particularly, at the fine-grained instance UE with only weak supervision, we derive a multi-instance residual operator through the Fundamental Theorem of Symmetric Functions. On this operator derivation, we further propose MIREL to jointly model the high-order predictive distribution at bag and instance levels for MIUE. Extensive experiments empirically demonstrate that our MIREL not only could often make existing MIL networks perform better in MIUE, but also could surpass representative UE methods by large margins, especially in instance-level UE tasks. Our source code is available at https://github.com/liupei101/MIREL.
<div id='section'>Paperid: <span id='pid'>200, <a href='https://arxiv.org/pdf/2405.02154.pdf' target='_blank'>https://arxiv.org/pdf/2405.02154.pdf</a></span>   <span><a href='https://github.com/ddrous/ncflow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Roussel Desmond Nzoyem, David A. W. Barton, Tom Deakin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02154">Neural Context Flows for Meta-Learning of Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Ordinary Differential Equations (NODEs) often struggle to adapt to new dynamic behaviors caused by parameter changes in the underlying physical system, even when these dynamics are similar to previously observed behaviors. This problem becomes more challenging when the changing parameters are unobserved, meaning their value or influence cannot be directly measured when collecting data. To address this issue, we introduce Neural Context Flow (NCF), a robust and interpretable Meta-Learning framework that includes uncertainty estimation. NCF uses Taylor expansion to enable contextual self-modulation, allowing context vectors to influence dynamics from other domains while also modulating themselves. After establishing theoretical guarantees, we empirically test NCF and compare it to related adaptation methods. Our results show that NCF achieves state-of-the-art Out-of-Distribution performance on 5 out of 6 linear and non-linear benchmark problems. Through extensive experiments, we explore the flexible model architecture of NCF and the encoded representations within the learned context vectors. Our findings highlight the potential implications of NCF for foundational models in the physical sciences, offering a promising approach to improving the adaptability and generalization of NODEs in various scientific applications. Our code is openly available at https://github.com/ddrous/ncflow.
<div id='section'>Paperid: <span id='pid'>201, <a href='https://arxiv.org/pdf/2405.01662.pdf' target='_blank'>https://arxiv.org/pdf/2405.01662.pdf</a></span>   <span><a href='https://github.com/Hewell0/ProjOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiuyu Zhu, Yiwei He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01662">Out-of-distribution detection based on subspace projection of high-dimensional features output by the last convolutional layer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection, crucial for reliable pattern classification, discerns whether a sample originates outside the training distribution. This paper concentrates on the high-dimensional features output by the final convolutional layer, which contain rich image features. Our key idea is to project these high-dimensional features into two specific feature subspaces, leveraging the dimensionality reduction capacity of the network's linear layers, trained with Predefined Evenly-Distribution Class Centroids (PEDCC)-Loss. This involves calculating the cosines of three projection angles and the norm values of features, thereby identifying distinctive information for in-distribution (ID) and OOD data, which assists in OOD detection. Building upon this, we have modified the batch normalization (BN) and ReLU layer preceding the fully connected layer, diminishing their impact on the output feature distributions and thereby widening the distribution gap between ID and OOD data features. Our method requires only the training of the classification network model, eschewing any need for input pre-processing or specific OOD data pre-tuning. Extensive experiments on several benchmark datasets demonstrates that our approach delivers state-of-the-art performance. Our code is available at https://github.com/Hewell0/ProjOOD.
<div id='section'>Paperid: <span id='pid'>202, <a href='https://arxiv.org/pdf/2404.17978.pdf' target='_blank'>https://arxiv.org/pdf/2404.17978.pdf</a></span>   <span><a href='https://github.com/mmajurski/ssl-gmm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Majurski, Sumeet Menon, Parniyan Farvardin, David Chapman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17978">A Method of Moments Embedding Constraint and its Application to Semi-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discriminative deep learning models with a linear+softmax final layer have a problem: the latent space only predicts the conditional probabilities $p(Y|X)$ but not the full joint distribution $p(Y,X)$, which necessitates a generative approach. The conditional probability cannot detect outliers, causing outlier sensitivity in softmax networks. This exacerbates model over-confidence impacting many problems, such as hallucinations, confounding biases, and dependence on large datasets. To address this we introduce a novel embedding constraint based on the Method of Moments (MoM). We investigate the use of polynomial moments ranging from 1st through 4th order hyper-covariance matrices. Furthermore, we use this embedding constraint to train an Axis-Aligned Gaussian Mixture Model (AAGMM) final layer, which learns not only the conditional, but also the joint distribution of the latent space. We apply this method to the domain of semi-supervised image classification by extending FlexMatch with our technique. We find our MoM constraint with the AAGMM layer is able to match the reported FlexMatch accuracy, while also modeling the joint distribution, thereby reducing outlier sensitivity. We also present a preliminary outlier detection strategy based on Mahalanobis distance and discuss future improvements to this strategy. Code is available at: \url{https://github.com/mmajurski/ssl-gmm}
<div id='section'>Paperid: <span id='pid'>203, <a href='https://arxiv.org/pdf/2404.15879.pdf' target='_blank'>https://arxiv.org/pdf/2404.15879.pdf</a></span>   <span><a href='https://github.com/uulm-mrm/mmood3d' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael KÃ¶sel, Marcel Schreiber, Michael Ulrich, Claudius GlÃ¤ser, Klaus Dietmayer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15879">Revisiting Out-of-Distribution Detection in LiDAR-based 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based 3D object detection has become an essential part of automated driving due to its ability to localize and classify objects precisely in 3D. However, object detectors face a critical challenge when dealing with unknown foreground objects, particularly those that were not present in their original training data. These out-of-distribution (OOD) objects can lead to misclassifications, posing a significant risk to the safety and reliability of automated vehicles. Currently, LiDAR-based OOD object detection has not been well studied. We address this problem by generating synthetic training data for OOD objects by perturbing known object categories. Our idea is that these synthetic OOD objects produce different responses in the feature map of an object detector compared to in-distribution (ID) objects. We then extract features using a pre-trained and fixed object detector and train a simple multilayer perceptron (MLP) to classify each detection as either ID or OOD. In addition, we propose a new evaluation protocol that allows the use of existing datasets without modifying the point cloud, ensuring a more authentic evaluation of real-world scenarios. The effectiveness of our method is validated through experiments on the newly proposed nuScenes OOD benchmark. The source code is available at https://github.com/uulm-mrm/mmood3d.
<div id='section'>Paperid: <span id='pid'>204, <a href='https://arxiv.org/pdf/2404.12368.pdf' target='_blank'>https://arxiv.org/pdf/2404.12368.pdf</a></span>   <span><a href='https://github.com/o4lc/Greg-OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sina Sharifi, Taha Entesari, Bardia Safaei, Vishal M. Patel, Mahyar Fazlyab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12368">Gradient-Regularized Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One of the challenges for neural networks in real-life applications is the overconfident errors these models make when the data is not from the original training distribution.
  Addressing this issue is known as Out-of-Distribution (OOD) detection.
  Many state-of-the-art OOD methods employ an auxiliary dataset as a surrogate for OOD data during training to achieve improved performance.
  However, these methods fail to fully exploit the local information embedded in the auxiliary dataset.
  In this work, we propose the idea of leveraging the information embedded in the gradient of the loss function during training to enable the network to not only learn a desired OOD score for each sample but also to exhibit similar behavior in a local neighborhood around each sample.
  We also develop a novel energy-based sampling method to allow the network to be exposed to more informative OOD samples during the training phase. This is especially important when the auxiliary dataset is large. We demonstrate the effectiveness of our method through extensive experiments on several OOD benchmarks, improving the existing state-of-the-art FPR95 by 4% on our ImageNet experiment.
  We further provide a theoretical analysis through the lens of certified robustness and Lipschitz analysis to showcase the theoretical foundation of our work. Our code is available at https://github.com/o4lc/Greg-OOD.
<div id='section'>Paperid: <span id='pid'>205, <a href='https://arxiv.org/pdf/2404.07032.pdf' target='_blank'>https://arxiv.org/pdf/2404.07032.pdf</a></span>   <span><a href='https://github.com/Medsemiseg' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenxi Zhang, Heng Zhou, Xiaoran Shi, Ran Ran, Chunna Tian, Feng Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07032">An Evidential-enhanced Tri-Branch Consistency Learning Method for Semi-supervised Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised segmentation presents a promising approach for large-scale medical image analysis, effectively reducing annotation burdens while achieving comparable performance. This methodology holds substantial potential for streamlining the segmentation process and enhancing its feasibility within clinical settings for translational investigations. While cross-supervised training, based on distinct co-training sub-networks, has become a prevalent paradigm for this task, addressing critical issues such as predication disagreement and label-noise suppression requires further attention and progress in cross-supervised training. In this paper, we introduce an Evidential Tri-Branch Consistency learning framework (ETC-Net) for semi-supervised medical image segmentation. ETC-Net employs three branches: an evidential conservative branch, an evidential progressive branch, and an evidential fusion branch. The first two branches exhibit complementary characteristics, allowing them to address prediction diversity and enhance training stability. We also integrate uncertainty estimation from the evidential learning into cross-supervised training, mitigating the negative impact of erroneous supervision signals. Additionally, the evidential fusion branch capitalizes on the complementary attributes of the first two branches and leverages an evidence-based Dempster-Shafer fusion strategy, supervised by more reliable and accurate pseudo-labels of unlabeled data. Extensive experiments conducted on LA, Pancreas-CT, and ACDC datasets demonstrate that ETC-Net surpasses other state-of-the-art methods for semi-supervised segmentation. The code will be made available in the near future at https://github.com/Medsemiseg.
<div id='section'>Paperid: <span id='pid'>206, <a href='https://arxiv.org/pdf/2404.06217.pdf' target='_blank'>https://arxiv.org/pdf/2404.06217.pdf</a></span>   <span><a href='https://github.com/liam0949/LLM-OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Li-Ming Zhan, Bo Liu, Xiao-Ming Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06217">VI-OOD: A Unified Representation Learning Framework for Textual Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection plays a crucial role in ensuring the safety and reliability of deep neural networks in various applications. While there has been a growing focus on OOD detection in visual data, the field of textual OOD detection has received less attention. Only a few attempts have been made to directly apply general OOD detection methods to natural language processing (NLP) tasks, without adequately considering the characteristics of textual data. In this paper, we delve into textual OOD detection with Transformers. We first identify a key problem prevalent in existing OOD detection methods: the biased representation learned through the maximization of the conditional likelihood $p(y\mid x)$ can potentially result in subpar performance. We then propose a novel variational inference framework for OOD detection (VI-OOD), which maximizes the likelihood of the joint distribution $p(x, y)$ instead of $p(y\mid x)$. VI-OOD is tailored for textual OOD detection by efficiently exploiting the representations of pre-trained Transformers. Through comprehensive experiments on various text classification tasks, VI-OOD demonstrates its effectiveness and wide applicability. Our code has been released at \url{https://github.com/liam0949/LLM-OOD}.
<div id='section'>Paperid: <span id='pid'>207, <a href='https://arxiv.org/pdf/2404.04550.pdf' target='_blank'>https://arxiv.org/pdf/2404.04550.pdf</a></span>   <span><a href='https://github.com/samahkh/NPB-REC' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Samah Khawaled, Moti Freiman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04550">NPB-REC: A Non-parametric Bayesian Deep-learning Approach for Undersampled MRI Reconstruction with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to reconstruct high-quality images from undersampled MRI data is vital in improving MRI temporal resolution and reducing acquisition times. Deep learning methods have been proposed for this task, but the lack of verified methods to quantify the uncertainty in the reconstructed images hampered clinical applicability. We introduce "NPB-REC", a non-parametric fully Bayesian framework, for MRI reconstruction from undersampled data with uncertainty estimation. We use Stochastic Gradient Langevin Dynamics during training to characterize the posterior distribution of the network parameters. This enables us to both improve the quality of the reconstructed images and quantify the uncertainty in the reconstructed images. We demonstrate the efficacy of our approach on a multi-coil MRI dataset from the fastMRI challenge and compare it to the baseline End-to-End Variational Network (E2E-VarNet). Our approach outperforms the baseline in terms of reconstruction accuracy by means of PSNR and SSIM ($34.55$, $0.908$ vs. $33.08$, $0.897$, $p<0.01$, acceleration rate $R=8$) and provides uncertainty measures that correlate better with the reconstruction error (Pearson correlation, $R=0.94$ vs. $R=0.91$). Additionally, our approach exhibits better generalization capabilities against anatomical distribution shifts (PSNR and SSIM of $32.38$, $0.849$ vs. $31.63$, $0.836$, $p<0.01$, training on brain data, inference on knee data, acceleration rate $R=8$). NPB-REC has the potential to facilitate the safe utilization of deep learning-based methods for MRI reconstruction from undersampled data. Code and trained models are available at \url{https://github.com/samahkh/NPB-REC}.
<div id='section'>Paperid: <span id='pid'>208, <a href='https://arxiv.org/pdf/2404.03248.pdf' target='_blank'>https://arxiv.org/pdf/2404.03248.pdf</a></span>   <span><a href='https://github.com/mala-lab/negprompt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianqi Li, Guansong Pang, Xiao Bai, Wenjun Miao, Jin Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.03248">Learning Transferable Negative Prompts for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing prompt learning methods have shown certain capabilities in Out-of-Distribution (OOD) detection, but the lack of OOD images in the target dataset in their training can lead to mismatches between OOD images and In-Distribution (ID) categories, resulting in a high false positive rate. To address this issue, we introduce a novel OOD detection method, named 'NegPrompt', to learn a set of negative prompts, each representing a negative connotation of a given class label, for delineating the boundaries between ID and OOD images. It learns such negative prompts with ID data only, without any reliance on external outlier data. Further, current methods assume the availability of samples of all ID classes, rendering them ineffective in open-vocabulary learning scenarios where the inference stage can contain novel ID classes not present during training. In contrast, our learned negative prompts are transferable to novel class labels. Experiments on various ImageNet benchmarks show that NegPrompt surpasses state-of-the-art prompt-learning-based OOD detection methods and maintains a consistent lead in hard OOD detection in closed- and open-vocabulary classification scenarios. Code is available at https://github.com/mala-lab/negprompt.
<div id='section'>Paperid: <span id='pid'>209, <a href='https://arxiv.org/pdf/2404.02515.pdf' target='_blank'>https://arxiv.org/pdf/2404.02515.pdf</a></span>   <span><a href='https://github.com/TakuOkawara/full_linear_wheel_odometry_factor' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taku Okawara, Kenji Koide, Shuji Oishi, Masashi Yokozuka, Atsuhiko Banno, Kentaro Uno, Kazuya Yoshida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.02515">Tightly-Coupled LiDAR-IMU-Wheel Odometry with Online Calibration of a Kinematic Model for Skid-Steering Robots</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tunnels and long corridors are challenging environments for mobile robots because a LiDAR point cloud should degenerate in these environments. To tackle point cloud degeneration, this study presents a tightly-coupled LiDAR-IMU-wheel odometry algorithm with an online calibration for skid-steering robots. We propose a full linear wheel odometry factor, which not only serves as a motion constraint but also performs the online calibration of kinematic models for skid-steering robots. Despite the dynamically changing kinematic model (e.g., wheel radii changes caused by tire pressures) and terrain conditions, our method can address the model error via online calibration. Moreover, our method enables an accurate localization in cases of degenerated environments, such as long and straight corridors, by calibration while the LiDAR-IMU fusion sufficiently operates. Furthermore, we estimate the uncertainty (i.e., covariance matrix) of the wheel odometry online for creating a reasonable constraint. The proposed method is validated through three experiments. The first indoor experiment shows that the proposed method is robust in severe degeneracy cases (long corridors) and changes in the wheel radii. The second outdoor experiment demonstrates that our method accurately estimates the sensor trajectory despite being in rough outdoor terrain owing to online uncertainty estimation of wheel odometry. The third experiment shows the proposed online calibration enables robust odometry estimation in changing terrains.
<div id='section'>Paperid: <span id='pid'>210, <a href='https://arxiv.org/pdf/2403.19137.pdf' target='_blank'>https://arxiv.org/pdf/2403.19137.pdf</a></span>   <span><a href='https://github.com/srvCodes/clap4clip' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurav Jha, Dong Gong, Lina Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.19137">CLAP4CLIP: Continual Learning with Probabilistic Finetuning for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual learning (CL) aims to help deep neural networks learn new knowledge while retaining what has been learned. Owing to their powerful generalizability, pre-trained vision-language models such as Contrastive Language-Image Pre-training (CLIP) have lately gained traction as practical CL candidates. However, the domain mismatch between the pre-training and the downstream CL tasks often calls for finetuning of the CLIP on the latter. Most existing finetuning methods exhibit deterministic nature. This makes them overlook the many possible interactions across the input modalities and deems them unsafe for high-risk tasks requiring reliable uncertainty estimation. To address these, our work proposes Continual LeArning with Probabilistic finetuning (CLAP) - a probabilistic modeling framework over visual-guided text features per task, thus providing more calibrated CL finetuning. Unlike recent data-hungry anti-forgetting CL techniques, CLAP alleviates forgetting by exploiting the rich pre-trained knowledge of CLIP for weight initialization and distribution regularization of task-specific parameters. Cooperating with the diverse range of existing prompting methods, CLAP can surpass the predominant deterministic finetuning approaches for CL with CLIP. We conclude with out-of-the-box applications of superior uncertainty estimation abilities of CLAP including novel data detection and exemplar selection within the existing CL setups. Our code is available at \url{https://github.com/srvCodes/clap4clip}.
<div id='section'>Paperid: <span id='pid'>211, <a href='https://arxiv.org/pdf/2403.17010.pdf' target='_blank'>https://arxiv.org/pdf/2403.17010.pdf</a></span>   <span><a href='https://github.com/ldkong1205/Calib3D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lingdong Kong, Xiang Xu, Jun Cen, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17010">Calib3D: Calibrating Model Preferences for Reliable 3D Scene Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safety-critical 3D scene understanding tasks necessitate not only accurate but also confident predictions from 3D perception models. This study introduces Calib3D, a pioneering effort to benchmark and scrutinize the reliability of 3D scene understanding models from an uncertainty estimation viewpoint. We comprehensively evaluate 28 state-of-the-art models across 10 diverse 3D datasets, uncovering insightful phenomena that cope with both the aleatoric and epistemic uncertainties in 3D scene understanding. We discover that despite achieving impressive levels of accuracy, existing models frequently fail to provide reliable uncertainty estimates -- a pitfall that critically undermines their applicability in safety-sensitive contexts. Through extensive analysis of key factors such as network capacity, LiDAR representations, rasterization resolutions, and 3D data augmentation techniques, we correlate these aspects directly with the model calibration efficacy. Furthermore, we introduce DeptS, a novel depth-aware scaling approach aimed at enhancing 3D model calibration. Extensive experiments across a wide range of configurations validate the superiority of our method. We hope this work could serve as a cornerstone for fostering reliable 3D scene understanding. Code and benchmark toolkit are publicly available.
<div id='section'>Paperid: <span id='pid'>212, <a href='https://arxiv.org/pdf/2403.15836.pdf' target='_blank'>https://arxiv.org/pdf/2403.15836.pdf</a></span>   <span><a href='https://github.com/HiLab-git/VLM-CPL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lanfeng Zhong, Zongyao Huang, Yang Liu, Wenjun Liao, Shichuan Zhang, Guotai Wang, Shaoting Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15836">VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Annotation-Free Pathological Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Classification of pathological images is the basis for automatic cancer diagnosis. Despite that deep learning methods have achieved remarkable performance, they heavily rely on labeled data, demanding extensive human annotation efforts. In this study, we present a novel human annotation-free method by leveraging pre-trained Vision-Language Models (VLMs). Without human annotation, pseudo-labels of the training set are obtained by utilizing the zero-shot inference capabilities of VLM, which may contain a lot of noise due to the domain gap between the pre-training and target datasets. To address this issue, we introduce VLM-CPL, a novel approach that contains two noisy label filtering techniques with a semi-supervised learning strategy. Specifically, we first obtain prompt-based pseudo-labels with uncertainty estimation by zero-shot inference with the VLM using multiple augmented views of an input. Then, by leveraging the feature representation ability of VLM, we obtain feature-based pseudo-labels via sample clustering in the feature space. Prompt-feature consensus is introduced to select reliable samples based on the consensus between the two types of pseudo-labels. We further propose High-confidence Cross Supervision by to learn from samples with reliable pseudo-labels and the remaining unlabeled samples. Additionally, we present an innovative open-set prompting strategy that filters irrelevant patches from whole slides to enhance the quality of selected patches. Experimental results on five public pathological image datasets for patch-level and slide-level classification showed that our method substantially outperformed zero-shot classification by VLMs, and was superior to existing noisy label learning methods. The code is publicly available at https://github.com/HiLab-git/VLM-CPL.
<div id='section'>Paperid: <span id='pid'>213, <a href='https://arxiv.org/pdf/2403.11256.pdf' target='_blank'>https://arxiv.org/pdf/2403.11256.pdf</a></span>   <span><a href='https://github.com/chenxi52/UPA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi Chen, Haosen Yang, Huicong Zhang, Hongxun Yao, Xiatian Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11256">Uncertainty-Aware Pseudo-Label Filtering for Source-Free Unsupervised Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Source-free unsupervised domain adaptation (SFUDA) aims to enable the utilization of a pre-trained source model in an unlabeled target domain without access to source data. Self-training is a way to solve SFUDA, where confident target samples are iteratively selected as pseudo-labeled samples to guide target model learning. However, prior heuristic noisy pseudo-label filtering methods all involve introducing extra models, which are sensitive to model assumptions and may introduce additional errors or mislabeling. In this work, we propose a method called Uncertainty-aware Pseudo-label-filtering Adaptation (UPA) to efficiently address this issue in a coarse-to-fine manner. Specially, we first introduce a sample selection module named Adaptive Pseudo-label Selection (APS), which is responsible for filtering noisy pseudo labels. The APS utilizes a simple sample uncertainty estimation method by aggregating knowledge from neighboring samples and confident samples are selected as clean pseudo-labeled. Additionally, we incorporate Class-Aware Contrastive Learning (CACL) to mitigate the memorization of pseudo-label noise by learning robust pair-wise representation supervised by pseudo labels. Through extensive experiments conducted on three widely used benchmarks, we demonstrate that our proposed method achieves competitive performance on par with state-of-the-art SFUDA methods. Code is available at https://github.com/chenxi52/UPA.
<div id='section'>Paperid: <span id='pid'>214, <a href='https://arxiv.org/pdf/2403.04073.pdf' target='_blank'>https://arxiv.org/pdf/2403.04073.pdf</a></span>   <span><a href='https://github.com/amazon-science/summarization-sicf-score' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianfeng He, Hang Su, Jason Cai, Igor Shalyminov, Hwanjun Song, Saab Mansour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04073">Semi-Supervised Dialogue Abstractive Summarization via High-Quality Pseudolabel Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised dialogue summarization (SSDS) leverages model-generated summaries to reduce reliance on human-labeled data and improve the performance of summarization models. While addressing label noise, previous works on semi-supervised learning primarily focus on natural language understanding tasks, assuming each sample has a unique label. However, these methods are not directly applicable to SSDS, as it is a generative task, and each dialogue can be summarized in different ways. In this work, we propose a novel scoring approach, SiCF, which encapsulates three primary dimensions of summarization model quality: Semantic invariance (indicative of model confidence), Coverage (factual recall), and Faithfulness (factual precision). Using the SiCF score, we select unlabeled dialogues with high-quality generated summaries to train summarization models. Comprehensive experiments on three public datasets demonstrate the effectiveness of SiCF scores in uncertainty estimation and semi-supervised learning for dialogue summarization tasks. Our code is available at \url{https://github.com/amazon-science/summarization-sicf-score}.
<div id='section'>Paperid: <span id='pid'>215, <a href='https://arxiv.org/pdf/2403.00543.pdf' target='_blank'>https://arxiv.org/pdf/2403.00543.pdf</a></span>   <span><a href='https://yutingli0606.github.io/SURE/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuting Li, Yingyi Chen, Xuanlong Yu, Dexiong Chen, Xi Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.00543">SURE: SUrvey REcipes for building reliable and robust deep networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we revisit techniques for uncertainty estimation within deep neural networks and consolidate a suite of techniques to enhance their reliability. Our investigation reveals that an integrated application of diverse techniques--spanning model regularization, classifier and optimization--substantially improves the accuracy of uncertainty predictions in image classification tasks. The synergistic effect of these techniques culminates in our novel SURE approach. We rigorously evaluate SURE against the benchmark of failure prediction, a critical testbed for uncertainty estimation efficacy. Our results showcase a consistently better performance than models that individually deploy each technique, across various datasets and model architectures. When applied to real-world challenges, such as data corruption, label noise, and long-tailed class distribution, SURE exhibits remarkable robustness, delivering results that are superior or on par with current state-of-the-art specialized methods. Particularly on Animal-10N and Food-101N for learning with noisy labels, SURE achieves state-of-the-art performance without any task-specific adjustments. This work not only sets a new benchmark for robust uncertainty estimation but also paves the way for its application in diverse, real-world scenarios where reliability is paramount. Our code is available at \url{https://yutingli0606.github.io/SURE/}.
<div id='section'>Paperid: <span id='pid'>216, <a href='https://arxiv.org/pdf/2402.19460.pdf' target='_blank'>https://arxiv.org/pdf/2402.19460.pdf</a></span>   <span><a href='https://github.com/bmucsanyi/untangle' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>BÃ¡lint MucsÃ¡nyi, Michael Kirchhof, Seong Joon Oh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.19460">Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one source of uncertainty. This paper presents the first benchmark of uncertainty disentanglement. We reimplement and evaluate a comprehensive range of uncertainty estimators, from Bayesian over evidential to deterministic ones, across a diverse range of uncertainty tasks on ImageNet. We find that, despite recent theoretical endeavors, no existing approach provides pairs of disentangled uncertainty estimators in practice. We further find that specialized uncertainty tasks are harder than predictive uncertainty tasks, where we observe saturating performance. Our results provide both practical advice for which uncertainty estimators to use for which specific task, and reveal opportunities for future research toward task-centric and disentangled uncertainties. All our reimplementations and Weights & Biases logs are available at https://github.com/bmucsanyi/untangle.
<div id='section'>Paperid: <span id='pid'>217, <a href='https://arxiv.org/pdf/2402.18451.pdf' target='_blank'>https://arxiv.org/pdf/2402.18451.pdf</a></span>   <span><a href='https://github.com/ayanglab/MambaMIR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Huang, Liutao Yang, Fanwen Wang, Yang Nan, Angelica I. Aviles-Rivero, Carola-Bibiane SchÃ¶nlieb, Daoqiang Zhang, Guang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18451">MambaMIR: An Arbitrary-Masked Mamba for Joint Medical Image Reconstruction and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent Mamba model has shown remarkable adaptability for visual representation learning, including in medical imaging tasks. This study introduces MambaMIR, a Mamba-based model for medical image reconstruction, as well as its Generative Adversarial Network-based variant, MambaMIR-GAN. Our proposed MambaMIR inherits several advantages, such as linear complexity, global receptive fields, and dynamic weights, from the original Mamba model. The innovated arbitrary-mask mechanism effectively adapt Mamba to our image reconstruction task, providing randomness for subsequent Monte Carlo-based uncertainty estimation. Experiments conducted on various medical image reconstruction tasks, including fast MRI and SVCT, which cover anatomical regions such as the knee, chest, and abdomen, have demonstrated that MambaMIR and MambaMIR-GAN achieve comparable or superior reconstruction results relative to state-of-the-art methods. Additionally, the estimated uncertainty maps offer further insights into the reliability of the reconstruction quality. The code is publicly available at https://github.com/ayanglab/MambaMIR.
<div id='section'>Paperid: <span id='pid'>218, <a href='https://arxiv.org/pdf/2402.16569.pdf' target='_blank'>https://arxiv.org/pdf/2402.16569.pdf</a></span>   <span><a href='https://github.com/mkirchhof/url' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Kirchhof, Mark Collier, Seong Joon Oh, Enkelejda Kasneci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16569">Pretrained Visual Uncertainties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty estimation is vital to trustworthy machine learning, yet uncertainties typically have to be learned for each task anew. This work introduces the first pretrained uncertainty modules for vision models. Similar to standard pretraining this enables the zero-shot transfer of uncertainties learned on a large pretraining dataset to specialized downstream datasets. We enable our large-scale pretraining on ImageNet-21k by solving a gradient conflict in previous uncertainty modules and accelerating the training by up to 180x. We find that the pretrained uncertainties generalize to unseen datasets. In scrutinizing the learned uncertainties, we find that they capture aleatoric uncertainty, disentangled from epistemic components. We demonstrate that this enables safe retrieval and uncertainty-aware dataset visualization. To encourage applications to further problems and domains, we release all pretrained checkpoints and code under https://github.com/mkirchhof/url .
<div id='section'>Paperid: <span id='pid'>219, <a href='https://arxiv.org/pdf/2402.14371.pdf' target='_blank'>https://arxiv.org/pdf/2402.14371.pdf</a></span>   <span><a href='https://github.com/lck666666/HR-APR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Changkun Liu, Shuai Chen, Yukun Zhao, Huajian Huang, Victor Prisacariu, Tristan Braud
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14371">HR-APR: APR-agnostic Framework with Uncertainty Estimation and Hierarchical Refinement for Camera Relocalisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Absolute Pose Regressors (APRs) directly estimate camera poses from monocular images, but their accuracy is unstable for different queries. Uncertainty-aware APRs provide uncertainty information on the estimated pose, alleviating the impact of these unreliable predictions. However, existing uncertainty modelling techniques are often coupled with a specific APR architecture, resulting in suboptimal performance compared to state-of-the-art (SOTA) APR methods. This work introduces a novel APR-agnostic framework, HR-APR, that formulates uncertainty estimation as cosine similarity estimation between the query and database features. It does not rely on or affect APR network architecture, which is flexible and computationally efficient. In addition, we take advantage of the uncertainty for pose refinement to enhance the performance of APR. The extensive experiments demonstrate the effectiveness of our framework, reducing 27.4\% and 15.2\% of computational overhead on the 7Scenes and Cambridge Landmarks datasets while maintaining the SOTA accuracy in single-image APRs.
<div id='section'>Paperid: <span id='pid'>220, <a href='https://arxiv.org/pdf/2402.12128.pdf' target='_blank'>https://arxiv.org/pdf/2402.12128.pdf</a></span>   <span><a href='https://github.com/gzq17/Weakly-Supervised-by-MIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanqiang Guo, Zimeng Tan, Jianjiang Feng, Jie Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12128">3D Vascular Segmentation Supervised by 2D Annotation of Maximum Intensity Projection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vascular structure segmentation plays a crucial role in medical analysis and clinical applications. The practical adoption of fully supervised segmentation models is impeded by the intricacy and time-consuming nature of annotating vessels in the 3D space. This has spurred the exploration of weakly-supervised approaches that reduce reliance on expensive segmentation annotations. Despite this, existing weakly supervised methods employed in organ segmentation, which encompass points, bounding boxes, or graffiti, have exhibited suboptimal performance when handling sparse vascular structure. To alleviate this issue, we employ maximum intensity projection (MIP) to decrease the dimensionality of 3D volume to 2D image for efficient annotation, and the 2D labels are utilized to provide guidance and oversight for training 3D vessel segmentation model. Initially, we generate pseudo-labels for 3D blood vessels using the annotations of 2D projections. Subsequently, taking into account the acquisition method of the 2D labels, we introduce a weakly-supervised network that fuses 2D-3D deep features via MIP to further improve segmentation performance. Furthermore, we integrate confidence learning and uncertainty estimation to refine the generated pseudo-labels, followed by fine-tuning the segmentation network. Our method is validated on five datasets (including cerebral vessel, aorta and coronary artery), demonstrating highly competitive performance in segmenting vessels and the potential to significantly reduce the time and effort required for vessel annotation. Our code is available at: https://github.com/gzq17/Weakly-Supervised-by-MIP.
<div id='section'>Paperid: <span id='pid'>221, <a href='https://arxiv.org/pdf/2402.11756.pdf' target='_blank'>https://arxiv.org/pdf/2402.11756.pdf</a></span>   <span><a href='https://github.com/Ybakman/LLM_Uncertainity' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yavuz Faruk Bakman, Duygu Nur Yaldiz, Baturalp Buyukates, Chenyang Tao, Dimitrios Dimitriadis, Salman Avestimehr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11756">MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative Large Language Models (LLMs) are widely utilized for their excellence in various tasks. However, their tendency to produce inaccurate or misleading outputs poses a potential risk, particularly in high-stakes environments. Therefore, estimating the correctness of generative LLM outputs is an important task for enhanced reliability. Uncertainty Estimation (UE) in generative LLMs is an evolving domain, where SOTA probability-based methods commonly employ length-normalized scoring. In this work, we propose Meaning-Aware Response Scoring (MARS) as an alternative to length-normalized scoring for UE methods. MARS is a novel scoring function that considers the semantic contribution of each token in the generated sequence in the context of the question. We demonstrate that integrating MARS into UE methods results in a universal and significant improvement in UE performance. We conduct experiments using three distinct closed-book question-answering datasets across five popular pre-trained LLMs. Lastly, we validate the efficacy of MARS on a Medical QA dataset. Code can be found https://github.com/Ybakman/LLM_Uncertainity.
<div id='section'>Paperid: <span id='pid'>222, <a href='https://arxiv.org/pdf/2402.10573.pdf' target='_blank'>https://arxiv.org/pdf/2402.10573.pdf</a></span>   <span><a href='https://github.com/zhzhengit/LinkNER' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Zhang, Yuhua Zhao, Hang Gao, Mengting Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10573">LinkNER: Linking Local Named Entity Recognition Models to Large Language Models using Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Named Entity Recognition (NER) serves as a fundamental task in natural language understanding, bearing direct implications for web content analysis, search engines, and information retrieval systems. Fine-tuned NER models exhibit satisfactory performance on standard NER benchmarks. However, due to limited fine-tuning data and lack of knowledge, it performs poorly on unseen entity recognition. As a result, the usability and reliability of NER models in web-related applications are compromised. Instead, Large Language Models (LLMs) like GPT-4 possess extensive external knowledge, but research indicates that they lack specialty for NER tasks. Furthermore, non-public and large-scale weights make tuning LLMs difficult. To address these challenges, we propose a framework that combines small fine-tuned models with LLMs (LinkNER) and an uncertainty-based linking strategy called RDC that enables fine-tuned models to complement black-box LLMs, achieving better performance. We experiment with both standard NER test sets and noisy social media datasets. LinkNER enhances NER task performance, notably surpassing SOTA models in robustness tests. We also quantitatively analyze the influence of key components like uncertainty estimation methods, LLMs, and in-context learning on diverse NER tasks, offering specific web-related recommendations. Code is available at https://github.com/zhzhengit/LinkNER.
<div id='section'>Paperid: <span id='pid'>223, <a href='https://arxiv.org/pdf/2402.08383.pdf' target='_blank'>https://arxiv.org/pdf/2402.08383.pdf</a></span>   <span><a href='https://github.com/AI4Science-WestlakeU/le-pde-uq' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tailin Wu, Willie Neiswanger, Hongtao Zheng, Stefano Ermon, Jure Leskovec
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08383">Uncertainty Quantification for Forward and Inverse Problems of PDEs via Latent Global Evolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based surrogate models have demonstrated remarkable advantages over classical solvers in terms of speed, often achieving speedups of 10 to 1000 times over traditional partial differential equation (PDE) solvers. However, a significant challenge hindering their widespread adoption in both scientific and industrial domains is the lack of understanding about their prediction uncertainties, particularly in scenarios that involve critical decision making. To address this limitation, we propose a method that integrates efficient and precise uncertainty quantification into a deep learning-based surrogate model. Our method, termed Latent Evolution of PDEs with Uncertainty Quantification (LE-PDE-UQ), endows deep learning-based surrogate models with robust and efficient uncertainty quantification capabilities for both forward and inverse problems. LE-PDE-UQ leverages latent vectors within a latent space to evolve both the system's state and its corresponding uncertainty estimation. The latent vectors are decoded to provide predictions for the system's state as well as estimates of its uncertainty. In extensive experiments, we demonstrate the accurate uncertainty quantification performance of our approach, surpassing that of strong baselines including deep ensembles, Bayesian neural network layers, and dropout. Our method excels at propagating uncertainty over extended auto-regressive rollouts, making it suitable for scenarios involving long-term predictions. Our code is available at: https://github.com/AI4Science-WestlakeU/le-pde-uq.
<div id='section'>Paperid: <span id='pid'>224, <a href='https://arxiv.org/pdf/2402.03502.pdf' target='_blank'>https://arxiv.org/pdf/2402.03502.pdf</a></span>   <span><a href='https://github.com/deeplearning-wisc/sal' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Du, Zhen Fang, Ilias Diakonikolas, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03502">How Does Unlabeled Data Provably Help Out-of-Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Using unlabeled data to regularize the machine learning models has demonstrated promise for improving safety and reliability in detecting out-of-distribution (OOD) data. Harnessing the power of unlabeled in-the-wild data is non-trivial due to the heterogeneity of both in-distribution (ID) and OOD data. This lack of a clean set of OOD samples poses significant challenges in learning an optimal OOD classifier. Currently, there is a lack of research on formally understanding how unlabeled data helps OOD detection. This paper bridges the gap by introducing a new learning framework SAL (Separate And Learn) that offers both strong theoretical guarantees and empirical effectiveness. The framework separates candidate outliers from the unlabeled data and then trains an OOD classifier using the candidate outliers and the labeled ID data. Theoretically, we provide rigorous error bounds from the lens of separability and learnability, formally justifying the two components in our algorithm. Our theory shows that SAL can separate the candidate outliers with small error rates, which leads to a generalization guarantee for the learned OOD classifier. Empirically, SAL achieves state-of-the-art performance on common benchmarks, reinforcing our theoretical insights. Code is publicly available at https://github.com/deeplearning-wisc/sal.
<div id='section'>Paperid: <span id='pid'>225, <a href='https://arxiv.org/pdf/2402.02653.pdf' target='_blank'>https://arxiv.org/pdf/2402.02653.pdf</a></span>   <span><a href='https://github.com/jeff024/PALM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haodong Lu, Dong Gong, Shuo Wang, Jason Xue, Lina Yao, Kristen Moore
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.02653">Learning with Mixture of Prototypes for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection aims to detect testing samples far away from the in-distribution (ID) training data, which is crucial for the safe deployment of machine learning models in the real world. Distance-based OOD detection methods have emerged with enhanced deep representation learning. They identify unseen OOD samples by measuring their distances from ID class centroids or prototypes. However, existing approaches learn the representation relying on oversimplified data assumptions, e.g, modeling ID data of each class with one centroid class prototype or using loss functions not designed for OOD detection, which overlook the natural diversities within the data. Naively enforcing data samples of each class to be compact around only one prototype leads to inadequate modeling of realistic data and limited performance. To tackle these issues, we propose PrototypicAl Learning with a Mixture of prototypes (PALM) which models each class with multiple prototypes to capture the sample diversities, and learns more faithful and compact samples embeddings to enhance OOD detection. Our method automatically identifies and dynamically updates prototypes, assigning each sample to a subset of prototypes via reciprocal neighbor soft assignment weights. PALM optimizes a maximum likelihood estimation (MLE) loss to encourage the sample embeddings to be compact around the associated prototypes, as well as a contrastive loss on all prototypes to enhance intra-class compactness and inter-class discrimination at the prototype level. Moreover, the automatic estimation of prototypes enables our approach to be extended to the challenging OOD detection task with unlabelled ID data. Extensive experiments demonstrate the superiority of PALM, achieving state-of-the-art average AUROC performance of 93.82 on the challenging CIFAR-100 benchmark. Code is available at https://github.com/jeff024/PALM.
<div id='section'>Paperid: <span id='pid'>226, <a href='https://arxiv.org/pdf/2402.00865.pdf' target='_blank'>https://arxiv.org/pdf/2402.00865.pdf</a></span>   <span><a href='https://github.com/Qinyu-Allen-Zhao/OptFSOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinyu Zhao, Ming Xu, Kartik Gupta, Akshay Asthana, Liang Zheng, Stephen Gould
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00865">Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Feature shaping refers to a family of methods that exhibit state-of-the-art performance for out-of-distribution (OOD) detection. These approaches manipulate the feature representation, typically from the penultimate layer of a pre-trained deep learning model, so as to better differentiate between in-distribution (ID) and OOD samples. However, existing feature-shaping methods usually employ rules manually designed for specific model architectures and OOD datasets, which consequently limit their generalization ability. To address this gap, we first formulate an abstract optimization framework for studying feature-shaping methods. We then propose a concrete reduction of the framework with a simple piecewise constant shaping function and show that existing feature-shaping methods approximate the optimal solution to the concrete optimization problem. Further, assuming that OOD data is inaccessible, we propose a formulation that yields a closed-form solution for the piecewise constant shaping function, utilizing solely the ID data. Through extensive experiments, we show that the feature-shaping function optimized by our method improves the generalization ability of OOD detection across a large variety of datasets and model architectures.
<div id='section'>Paperid: <span id='pid'>227, <a href='https://arxiv.org/pdf/2401.17826.pdf' target='_blank'>https://arxiv.org/pdf/2401.17826.pdf</a></span>   <span><a href='https://github.com/JokerJohn/Cloud_Map_Evaluation' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/JokerJohn/PALoc' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangcheng Hu, Linwei Zheng, Jin Wu, Ruoyu Geng, Yang Yu, Hexiang Wei, Xiaoyu Tang, Lujia Wang, Jianhao Jiao, Ming Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.17826">PALoc: Advancing SLAM Benchmarking with Prior-Assisted 6-DoF Trajectory Generation and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately generating ground truth (GT) trajectories is essential for Simultaneous Localization and Mapping (SLAM) evaluation, particularly under varying environmental conditions. This study introduces a systematic approach employing a prior map-assisted framework for generating dense six-degree-of-freedom (6-DoF) GT poses for the first time, enhancing the fidelity of both indoor and outdoor SLAM datasets. Our method excels in handling degenerate and stationary conditions frequently encountered in SLAM datasets, thereby increasing robustness and precision. A significant aspect of our approach is the detailed derivation of covariances within the factor graph, enabling an in-depth analysis of pose uncertainty propagation. This analysis crucially contributes to demonstrating specific pose uncertainties and enhancing trajectory reliability from both theoretical and empirical perspectives. Additionally, we provide an open-source toolbox (https://github.com/JokerJohn/Cloud_Map_Evaluation) for map evaluation criteria, facilitating the indirect assessment of overall trajectory precision. Experimental results show at least a 30\% improvement in map accuracy and a 20\% increase in direct trajectory accuracy compared to the Iterative Closest Point (ICP) \cite{sharp2002icp} algorithm across diverse campus environments, with substantially enhanced robustness. Our open-source solution (https://github.com/JokerJohn/PALoc), extensively applied in the FusionPortable\cite{Jiao2022Mar} dataset, is geared towards SLAM benchmark dataset augmentation and represents a significant advancement in SLAM evaluations.
<div id='section'>Paperid: <span id='pid'>228, <a href='https://arxiv.org/pdf/2401.08501.pdf' target='_blank'>https://arxiv.org/pdf/2401.08501.pdf</a></span>   <span><a href='https://github.com/IML-DKFZ/values' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kim-Celine Kahl, Carsten T. LÃ¼th, Maximilian Zenk, Klaus Maier-Hein, Paul F. Jaeger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08501">ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is an essential and heavily-studied component for the reliable application of semantic segmentation methods. While various studies exist claiming methodological advances on the one hand, and successful application on the other hand, the field is currently hampered by a gap between theory and practice leaving fundamental questions unanswered: Can data-related and model-related uncertainty really be separated in practice? Which components of an uncertainty method are essential for real-world performance? Which uncertainty method works well for which application? In this work, we link this research gap to a lack of systematic and comprehensive evaluation of uncertainty methods. Specifically, we identify three key pitfalls in current literature and present an evaluation framework that bridges the research gap by providing 1) a controlled environment for studying data ambiguities as well as distribution shifts, 2) systematic ablations of relevant method components, and 3) test-beds for the five predominant uncertainty applications: OoD-detection, active learning, failure detection, calibration, and ambiguity modeling. Empirical results on simulated as well as real-world data demonstrate how the proposed framework is able to answer the predominant questions in the field revealing for instance that 1) separation of uncertainty types works on simulated data but does not necessarily translate to real-world data, 2) aggregation of scores is a crucial but currently neglected component of uncertainty methods, 3) While ensembles are performing most robustly across the different downstream tasks and settings, test-time augmentation often constitutes a light-weight alternative. Code is at: https://github.com/IML-DKFZ/values
<div id='section'>Paperid: <span id='pid'>229, <a href='https://arxiv.org/pdf/2401.06176.pdf' target='_blank'>https://arxiv.org/pdf/2401.06176.pdf</a></span>   <span><a href='https://github.com/Ee1s/GOODAT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Luzhi Wang, Dongxiao He, He Zhang, Yixin Liu, Wenjie Wang, Shirui Pan, Di Jin, Tat-Seng Chua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06176">GOODAT: Towards Test-time Graph Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph neural networks (GNNs) have found widespread application in modeling graph data across diverse domains. While GNNs excel in scenarios where the testing data shares the distribution of their training counterparts (in distribution, ID), they often exhibit incorrect predictions when confronted with samples from an unfamiliar distribution (out-of-distribution, OOD). To identify and reject OOD samples with GNNs, recent studies have explored graph OOD detection, often focusing on training a specific model or modifying the data on top of a well-trained GNN. Despite their effectiveness, these methods come with heavy training resources and costs, as they need to optimize the GNN-based models on training data. Moreover, their reliance on modifying the original GNNs and accessing training data further restricts their universality. To this end, this paper introduces a method to detect Graph Out-of-Distribution At Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play solution that operates independently of training data and modifications of GNN architecture. With a lightweight graph masker, GOODAT can learn informative subgraphs from test samples, enabling the capture of distinct graph patterns between OOD and ID samples. To optimize the graph masker, we meticulously design three unsupervised objective functions based on the graph information bottleneck principle, motivating the masker to capture compact yet informative subgraphs for OOD detection. Comprehensive evaluations confirm that our GOODAT method outperforms state-of-the-art benchmarks across a variety of real-world datasets. The code is available at Github: https://github.com/Ee1s/GOODAT
<div id='section'>Paperid: <span id='pid'>230, <a href='https://arxiv.org/pdf/2401.03350.pdf' target='_blank'>https://arxiv.org/pdf/2401.03350.pdf</a></span>   <span><a href='https://pujacomputes.github.io/gduq/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Puja Trivedi, Mark Heimann, Rushil Anirudh, Danai Koutra, Jayaraman J. Thiagarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03350">Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While graph neural networks (GNNs) are widely used for node and graph representation learning tasks, the reliability of GNN uncertainty estimates under distribution shifts remains relatively under-explored. Indeed, while post-hoc calibration strategies can be used to improve in-distribution calibration, they need not also improve calibration under distribution shift. However, techniques which produce GNNs with better intrinsic uncertainty estimates are particularly valuable, as they can always be combined with post-hoc strategies later. Therefore, in this work, we propose G-$Î$UQ, a novel training framework designed to improve intrinsic GNN uncertainty estimates. Our framework adapts the principle of stochastic data centering to graph data through novel graph anchoring strategies, and is able to support partially stochastic GNNs. While, the prevalent wisdom is that fully stochastic networks are necessary to obtain reliable estimates, we find that the functional diversity induced by our anchoring strategies when sampling hypotheses renders this unnecessary and allows us to support G-$Î$UQ on pretrained models. Indeed, through extensive evaluation under covariate, concept and graph size shifts, we show that G-$Î$UQ leads to better calibrated GNNs for node and graph classification. Further, it also improves performance on the uncertainty-based tasks of out-of-distribution detection and generalization gap estimation. Overall, our work provides insights into uncertainty estimation for GNNs, and demonstrates the utility of G-$Î$UQ in obtaining reliable estimates.
<div id='section'>Paperid: <span id='pid'>231, <a href='https://arxiv.org/pdf/2401.00873.pdf' target='_blank'>https://arxiv.org/pdf/2401.00873.pdf</a></span>   <span><a href='https://github.com/emsansone/GEDI' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Emanuele Sansone, Robin Manhaeve
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00873">Unifying Self-Supervised Clustering and Energy-Based Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning excels at learning representations from large amounts of data. At the same time, generative models offer the complementary property of learning information about the underlying data generation process. In this study, we aim at establishing a principled connection between these two paradigms and highlight the benefits of their complementarity. In particular, we perform an analysis of self-supervised learning objectives, elucidating the underlying probabilistic graphical models and presenting a standardized methodology for their derivation from first principles. The analysis suggests a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a lower bound proven to reliably penalize the most important failure modes and unlocking full unification. Our theoretical findings are substantiated through experiments on synthetic and real-world data, including SVHN, CIFAR10, and CIFAR100, demonstrating that our objective function allows to jointly train a backbone network in a discriminative and generative fashion, consequently outperforming existing self-supervised learning strategies in terms of clustering, generation and out-of-distribution detection performance by a wide margin. We also demonstrate that the solution can be integrated into a neuro-symbolic framework to tackle a simple yet non-trivial instantiation of the symbol grounding problem. The code is publicly available at https://github.com/emsansone/GEDI.
<div id='section'>Paperid: <span id='pid'>232, <a href='https://arxiv.org/pdf/2411.17401.pdf' target='_blank'>https://arxiv.org/pdf/2411.17401.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pengfei Cao, Yuheng Chen, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17401">One Mind, Many Tongues: A Deep Dive into Language-Agnostic Knowledge Neurons in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have learned vast amounts of factual knowledge through self-supervised pre-training on large-scale corpora. Meanwhile, LLMs have also demonstrated excellent multilingual capabilities, which can express the learned knowledge in multiple languages. However, the knowledge storage mechanism in LLMs still remains mysterious. Some researchers attempt to demystify the factual knowledge in LLMs from the perspective of knowledge neurons, and subsequently discover language-agnostic knowledge neurons that store factual knowledge in a form that transcends language barriers. However, the preliminary finding suffers from two limitations: 1) High Uncertainty in Localization Results. Existing study only uses a prompt-based probe to localize knowledge neurons for each fact, while LLMs cannot provide consistent answers for semantically equivalent queries. Thus, it leads to inaccurate localization results with high uncertainty. 2) Lack of Analysis in More Languages. The study only analyzes language-agnostic knowledge neurons on English and Chinese data, without exploring more language families and languages. Naturally, it limits the generalizability of the findings. To address aforementioned problems, we first construct a new benchmark called Rephrased Multilingual LAMA (RML-LAMA), which contains high-quality cloze-style multilingual parallel queries for each fact. Then, we propose a novel method named Multilingual Integrated Gradients with Uncertainty Estimation (MATRICE), which quantifies the uncertainty across queries and languages during knowledge localization. Extensive experiments show that our method can accurately localize language-agnostic knowledge neurons. We also further investigate the role of language-agnostic knowledge neurons in cross-lingual knowledge editing, knowledge enhancement and new knowledge injection.
<div id='section'>Paperid: <span id='pid'>233, <a href='https://arxiv.org/pdf/2510.08044.pdf' target='_blank'>https://arxiv.org/pdf/2510.08044.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiyuan Yin, Chenjia Bai, Zihao Zhang, Junwei Jin, Xinxin Zhang, Chi Zhang, Xuelong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.08044">Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) demonstrate advanced reasoning abilities, enabling robots to understand natural language instructions and generate high-level plans with appropriate grounding. However, LLM hallucinations present a significant challenge, often leading to overconfident yet potentially misaligned or unsafe plans. While researchers have explored uncertainty estimation to improve the reliability of LLM-based planning, existing studies have not sufficiently differentiated between epistemic and intrinsic uncertainty, limiting the effectiveness of uncertainty estimation. In this paper, we present Combined Uncertainty estimation for Reliable Embodied planning (CURE), which decomposes the uncertainty into epistemic and intrinsic uncertainty, each estimated separately. Furthermore, epistemic uncertainty is subdivided into task clarity and task familiarity for more accurate evaluation. The overall uncertainty assessments are obtained using random network distillation and multi-layer perceptron regression heads driven by LLM features. We validated our approach in two distinct experimental settings: kitchen manipulation and tabletop rearrangement experiments. The results show that, compared to existing methods, our approach yields uncertainty estimates that are more closely aligned with the actual execution outcomes.
<div id='section'>Paperid: <span id='pid'>234, <a href='https://arxiv.org/pdf/2505.12457.pdf' target='_blank'>https://arxiv.org/pdf/2505.12457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Zhao, Kai Xiong, Xiao Ding, Li Du, YangouOuyang, Zhouhao Sun, Jiannan Guan, Wenbin Zhang, Bin Liu, Dong Hu, Bing Qin, Ting Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12457">UFO-RL: Uncertainty-Focused Optimization for Efficient Reinforcement Learning Data Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scaling RL for LLMs is computationally expensive, largely due to multi-sampling for policy optimization and evaluation, making efficient data selection crucial. Inspired by the Zone of Proximal Development (ZPD) theory, we hypothesize LLMs learn best from data within their potential comprehension zone. Addressing the limitation of conventional, computationally intensive multi-sampling methods for data assessment, we introduce UFO-RL. This novel framework uses a computationally efficient single-pass uncertainty estimation to identify informative data instances, achieving up to 185x faster data evaluation. UFO-RL leverages this metric to select data within the estimated ZPD for training. Experiments show that training with just 10% of data selected by UFO-RL yields performance comparable to or surpassing full-data training, reducing overall training time by up to 16x while enhancing stability and generalization. UFO-RL offers a practical and highly efficient strategy for scaling RL fine-tuning of LLMs by focusing learning on valuable data.
<div id='section'>Paperid: <span id='pid'>235, <a href='https://arxiv.org/pdf/2509.14151.pdf' target='_blank'>https://arxiv.org/pdf/2509.14151.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rongyu Zhang, Jiaming Liu, Xiaoqi Li, Xiaowei Chi, Dan Wang, Li Du, Yuan Du, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14151">BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-centric Bird's Eye View (BEV) perception holds considerable promise for autonomous driving. Recent studies have prioritized efficiency or accuracy enhancements, yet the issue of domain shift has been overlooked, leading to substantial performance degradation upon transfer. We identify major domain gaps in real-world cross-domain scenarios and initiate the first effort to address the Domain Adaptation (DA) challenge in multi-view 3D object detection for BEV perception. Given the complexity of BEV perception approaches with their multiple components, domain shift accumulation across multi-geometric spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain adaptation. In this paper, we introduce an innovative geometric-aware teacher-student framework, BEVUDA++, to diminish this issue, comprising a Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model. Specifically, RDT effectively blends target LiDAR with dependable depth predictions to generate depth-aware information based on uncertainty estimation, enhancing the extraction of Voxel and BEV features that are essential for understanding the target domain. To collaboratively reduce the domain shift, GCS maps features from multiple spaces into a unified geometric embedding space, thereby narrowing the gap in data distribution between the two domains. Additionally, we introduce a novel Uncertainty-guided Exponential Moving Average (UEMA) to further reduce error accumulation due to domain shifts informed by previously obtained uncertainty guidance. To demonstrate the superiority of our proposed method, we execute comprehensive experiments in four cross-domain scenarios, securing state-of-the-art performance in BEV 3D object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night adaptation.
<div id='section'>Paperid: <span id='pid'>236, <a href='https://arxiv.org/pdf/2504.16136.pdf' target='_blank'>https://arxiv.org/pdf/2504.16136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chiung-Yi Tseng, Junhao Song, Ziqian Bi, Tianyang Wang, Chia Xin Liang, Ming Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16136">Active Learning Methods for Efficient Data Utilization and Model Performance Enhancement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the era of data-driven intelligence, the paradox of data abundance and annotation scarcity has emerged as a critical bottleneck in the advancement of machine learning. This paper gives a detailed overview of Active Learning (AL), which is a strategy in machine learning that helps models achieve better performance using fewer labeled examples. It introduces the basic concepts of AL and discusses how it is used in various fields such as computer vision, natural language processing, transfer learning, and real-world applications. The paper focuses on important research topics such as uncertainty estimation, handling of class imbalance, domain adaptation, fairness, and the creation of strong evaluation metrics and benchmarks. It also shows that learning methods inspired by humans and guided by questions can improve data efficiency and help models learn more effectively. In addition, this paper talks about current challenges in the field, including the need to rebuild trust, ensure reproducibility, and deal with inconsistent methodologies. It points out that AL often gives better results than passive learning, especially when good evaluation measures are used. This work aims to be useful for both researchers and practitioners by providing key insights and proposing directions for future progress in active learning.
<div id='section'>Paperid: <span id='pid'>237, <a href='https://arxiv.org/pdf/2512.00380.pdf' target='_blank'>https://arxiv.org/pdf/2512.00380.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingwei Liu, Zheng Pei, Yanlin Wang, Zihao Wang, Zikang Li, Enci Lin, Xin Peng, Zibin Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.00380">Framework-Aware Code Generation with API Knowledge Graph-Constructed Data: A Study on HarmonyOS</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the context of software frameworks with limited resources (such as HarmonyOS), large language models (LLMs) often exhibit poor code generation performance because they lack sufficient exposure to such environments during pre-training. Although LLMs can usually maintain correct logical structures across programming languages, they frequently struggle when dealing with framework-specific APIs or syntax, resulting in errors. This indicates that while pre-training equips LLMs with general algorithmic capabilities, they remain unfamiliar with the distinctive syntax and API usage of underrepresented frameworks. As a result, even advanced commercial models like GPT-4o cannot reliably generate correct code without prior adaptation. To address this issue, we propose APIKG4SYN, a framework designed to exploit API knowledge graphs for the construction of API-oriented question-code pairs, specifically tailored for low-resource frameworks without requiring executable code. APIKG4SYN integrates both single-API and multi-API knowledge, where the latter is derived through uncertainty estimation (UE)-driven Monte Carlo Tree Search (MCTS), enabling the creation of a diverse and informative dataset for fine-tuning LLMs. Using HarmonyOS as a case study, we build the first benchmark for HarmonyOS code generation. Experimental results show that fine-tuning Qwen with APIKG4SYN raises pass@1 accuracy to 25.00%, compared with 17.59% for the baseline GPT model. These results confirm that API-oriented data significantly enhance LLM performance in low-resource software development scenarios.
<div id='section'>Paperid: <span id='pid'>238, <a href='https://arxiv.org/pdf/2510.08602.pdf' target='_blank'>https://arxiv.org/pdf/2510.08602.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cong Zeng, Shengkun Tang, Yuanzhou Chen, Zhiqiang Shen, Wenchao Yu, Xujiang Zhao, Haifeng Chen, Wei Cheng, Zhiqiang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.08602">Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid advancement of large language models (LLMs) such as ChatGPT, DeepSeek, and Claude has significantly increased the presence of AI-generated text in digital communication. This trend has heightened the need for reliable detection methods to distinguish between human-authored and machine-generated content. Existing approaches both zero-shot methods and supervised classifiers largely conceptualize this task as a binary classification problem, often leading to poor generalization across domains and models. In this paper, we argue that such a binary formulation fundamentally mischaracterizes the detection task by assuming a coherent representation of human-written texts. In reality, human texts do not constitute a unified distribution, and their diversity cannot be effectively captured through limited sampling. This causes previous classifiers to memorize observed OOD characteristics rather than learn the essence of `non-ID' behavior, limiting generalization to unseen human-authored inputs. Based on this observation, we propose reframing the detection task as an out-of-distribution (OOD) detection problem, treating human-written texts as distributional outliers while machine-generated texts are in-distribution (ID) samples. To this end, we develop a detection framework using one-class learning method including DeepSVDD and HRN, and score-based learning techniques such as energy-based method, enabling robust and generalizable performance. Extensive experiments across multiple datasets validate the effectiveness of our OOD-based approach. Specifically, the OOD-based method achieves 98.3% AUROC and AUPR with only 8.9% FPR95 on DeepFake dataset. Moreover, we test our detection framework on multilingual, attacked, and unseen-model and -domain text settings, demonstrating the robustness and generalizability of our framework. Code, pretrained weights, and demo will be released.
<div id='section'>Paperid: <span id='pid'>239, <a href='https://arxiv.org/pdf/2412.01033.pdf' target='_blank'>https://arxiv.org/pdf/2412.01033.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiwei Zhao, Xujiang Zhao, Yanchi Liu, Wei Cheng, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Huaxiu Yao, Haifeng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01033">SAUP: Situation Awareness Uncertainty Propagation on LLM Agent</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) integrated into multistep agent systems enable complex decision-making processes across various applications. However, their outputs often lack reliability, making uncertainty estimation crucial. Existing uncertainty estimation methods primarily focus on final-step outputs, which fail to account for cumulative uncertainty over the multistep decision-making process and the dynamic interactions between agents and their environments. To address these limitations, we propose SAUP (Situation Awareness Uncertainty Propagation), a novel framework that propagates uncertainty through each step of an LLM-based agent's reasoning process. SAUP incorporates situational awareness by assigning situational weights to each step's uncertainty during the propagation. Our method, compatible with various one-step uncertainty estimation techniques, provides a comprehensive and accurate uncertainty measure. Extensive experiments on benchmark datasets demonstrate that SAUP significantly outperforms existing state-of-the-art methods, achieving up to 20% improvement in AUROC.
<div id='section'>Paperid: <span id='pid'>240, <a href='https://arxiv.org/pdf/2509.15805.pdf' target='_blank'>https://arxiv.org/pdf/2509.15805.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyang Wang, Xi Xiao, Gaofei Chen, Xiaoying Liao, Guo Cheng, Yingrui Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15805">Boosting Active Learning with Knowledge Transfer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is at the core of Active Learning (AL). Most existing methods resort to complex auxiliary models and advanced training fashions to estimate uncertainty for unlabeled data. These models need special design and hence are difficult to train especially for domain tasks, such as Cryo-Electron Tomography (cryo-ET) classification in computational biology. To address this challenge, we propose a novel method using knowledge transfer to boost uncertainty estimation in AL. Specifically, we exploit the teacher-student mode where the teacher is the task model in AL and the student is an auxiliary model that learns from the teacher. We train the two models simultaneously in each AL cycle and adopt a certain distance between the model outputs to measure uncertainty for unlabeled data. The student model is task-agnostic and does not rely on special training fashions (e.g. adversarial), making our method suitable for various tasks. More importantly, we demonstrate that data uncertainty is not tied to concrete value of task loss but closely related to the upper-bound of task loss. We conduct extensive experiments to validate the proposed method on classical computer vision tasks and cryo-ET challenges. The results demonstrate its efficacy and efficiency.
<div id='section'>Paperid: <span id='pid'>241, <a href='https://arxiv.org/pdf/2412.06168.pdf' target='_blank'>https://arxiv.org/pdf/2412.06168.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Fu, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06168">Out-of-Distribution Detection with Overlap Index</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for the deployment of machine learning models in the open world. While existing OOD detectors are effective in identifying OOD samples that deviate significantly from in-distribution (ID) data, they often come with trade-offs. For instance, deep OOD detectors usually suffer from high computational costs, require tuning hyperparameters, and have limited interpretability, whereas traditional OOD detectors may have a low accuracy on large high-dimensional datasets. To address these limitations, we propose a novel effective OOD detection approach that employs an overlap index (OI)-based confidence score function to evaluate the likelihood of a given input belonging to the same distribution as the available ID samples. The proposed OI-based confidence score function is non-parametric, lightweight, and easy to interpret, hence providing strong flexibility and generality. Extensive empirical evaluations indicate that our OI-based OOD detector is competitive with state-of-the-art OOD detectors in terms of detection accuracy on a wide range of datasets while requiring less computation and memory costs. Lastly, we show that the proposed OI-based confidence score function inherits nice properties from OI (e.g., insensitivity to small distributional variations and robustness against Huber $Îµ$-contamination) and is a versatile tool for estimating OI and model accuracy in specific contexts.
<div id='section'>Paperid: <span id='pid'>242, <a href='https://arxiv.org/pdf/2402.16926.pdf' target='_blank'>https://arxiv.org/pdf/2402.16926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georg Pichler, Marco Romanelli, Divya Prakash Manivannan, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16926">On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem.
<div id='section'>Paperid: <span id='pid'>243, <a href='https://arxiv.org/pdf/2408.07819.pdf' target='_blank'>https://arxiv.org/pdf/2408.07819.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijia Wang, Qianqian Xu, Yangbangyan Jiang, Siran Dai, Qingming Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07819">Regularized Contrastive Partial Multi-view Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, multi-view outlier detection (MVOD) methods have advanced significantly, aiming to identify outliers within multi-view datasets. A key point is to better detect class outliers and class-attribute outliers, which only exist in multi-view data. However, existing methods either is not able to reduce the impact of outliers when learning view-consistent information, or struggle in cases with varying neighborhood structures. Moreover, most of them do not apply to partial multi-view data in real-world scenarios. To overcome these drawbacks, we propose a novel method named Regularized Contrastive Partial Multi-view Outlier Detection (RCPMOD). In this framework, we utilize contrastive learning to learn view-consistent information and distinguish outliers by the degree of consistency. Specifically, we propose (1) An outlier-aware contrastive loss with a potential outlier memory bank to eliminate their bias motivated by a theoretical analysis. (2) A neighbor alignment contrastive loss to capture the view-shared local structural correlation. (3) A spreading regularization loss to prevent the model from overfitting over outliers. With the Cross-view Relation Transfer technique, we could easily impute the missing view samples based on the features of neighbors. Experimental results on four benchmark datasets demonstrate that our proposed approach could outperform state-of-the-art competitors under different settings.
<div id='section'>Paperid: <span id='pid'>244, <a href='https://arxiv.org/pdf/2407.21742.pdf' target='_blank'>https://arxiv.org/pdf/2407.21742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junwei He, Qianqian Xu, Yangbangyan Jiang, Zitai Wang, Yuchen Sun, Qingming Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21742">HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the progressive advancements in deep graph learning, out-of-distribution (OOD) detection for graph data has emerged as a critical challenge. While the efficacy of auxiliary datasets in enhancing OOD detection has been extensively studied for image and text data, such approaches have not yet been explored for graph data. Unlike Euclidean data, graph data exhibits greater diversity but lower robustness to perturbations, complicating the integration of outliers. To tackle these challenges, we propose the introduction of \textbf{H}ybrid External and Internal \textbf{G}raph \textbf{O}utlier \textbf{E}xposure (HGOE) to improve graph OOD detection performance. Our framework involves using realistic external graph data from various domains and synthesizing internal outliers within ID subgroups to address the poor robustness and presence of OOD samples within the ID class. Furthermore, we develop a boundary-aware OE loss that adaptively assigns weights to outliers, maximizing the use of high-quality OOD samples while minimizing the impact of low-quality ones. Our proposed HGOE framework is model-agnostic and designed to enhance the effectiveness of existing graph OOD detection models. Experimental results demonstrate that our HGOE framework can significantly improve the performance of existing OOD detection models across all 8 real datasets.
<div id='section'>Paperid: <span id='pid'>245, <a href='https://arxiv.org/pdf/2503.22285.pdf' target='_blank'>https://arxiv.org/pdf/2503.22285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bin Zhang, Jinggang Chen, Xiaoyang Qu, Guokuan Li, Kai Lu, Jiguang Wan, Jing Xiao, Jianzong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22285">RUNA: Object-level Out-of-Distribution Detection via Regional Uncertainty Alignment of Multimodal Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enabling object detectors to recognize out-of-distribution (OOD) objects is vital for building reliable systems. A primary obstacle stems from the fact that models frequently do not receive supervisory signals from unfamiliar data, leading to overly confident predictions regarding OOD objects. Despite previous progress that estimates OOD uncertainty based on the detection model and in-distribution (ID) samples, we explore using pre-trained vision-language representations for object-level OOD detection. We first discuss the limitations of applying image-level CLIP-based OOD detection methods to object-level scenarios. Building upon these insights, we propose RUNA, a novel framework that leverages a dual encoder architecture to capture rich contextual information and employs a regional uncertainty alignment mechanism to distinguish ID from OOD objects effectively. We introduce a few-shot fine-tuning approach that aligns region-level semantic representations to further improve the model's capability to discriminate between similar objects. Our experiments show that RUNA substantially surpasses state-of-the-art methods in object-level OOD detection, particularly in challenging scenarios with diverse and complex object instances.
<div id='section'>Paperid: <span id='pid'>246, <a href='https://arxiv.org/pdf/2505.04713.pdf' target='_blank'>https://arxiv.org/pdf/2505.04713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis F. Gomez, Gonzalo Garrido-Lopez, Julian Fierrez, Aythami Morales, Ruben Tolosana, Javier Rueda, Enrique Navarro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04713">Comparison of Visual Trackers for Biomechanical Analysis of Running</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human pose estimation has witnessed significant advancements in recent years, mainly due to the integration of deep learning models, the availability of a vast amount of data, and large computational resources. These developments have led to highly accurate body tracking systems, which have direct applications in sports analysis and performance evaluation.
  This work analyzes the performance of six trackers: two point trackers and four joint trackers for biomechanical analysis in sprints. The proposed framework compares the results obtained from these pose trackers with the manual annotations of biomechanical experts for more than 5870 frames. The experimental framework employs forty sprints from five professional runners, focusing on three key angles in sprint biomechanics: trunk inclination, hip flex extension, and knee flex extension. We propose a post-processing module for outlier detection and fusion prediction in the joint angles.
  The experimental results demonstrate that using joint-based models yields root mean squared errors ranging from 11.41Â° to 4.37Â°. When integrated with the post-processing modules, these errors can be reduced to 6.99Â° and 3.88Â°, respectively. The experimental findings suggest that human pose tracking approaches can be valuable resources for the biomechanical analysis of running. However, there is still room for improvement in applications where high accuracy is required.
<div id='section'>Paperid: <span id='pid'>247, <a href='https://arxiv.org/pdf/2503.02233.pdf' target='_blank'>https://arxiv.org/pdf/2503.02233.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Zheng, Hongshen Xu, Yuncong Liu, Lu Chen, Pascale Fung, Kai Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.02233">Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) are prone to hallucination stemming from misaligned self-awareness, particularly when processing queries exceeding their knowledge boundaries. While existing mitigation strategies employ uncertainty estimation or query rejection mechanisms, they suffer from computational efficiency and sacrificed helpfulness. To address these issues, we propose the Explicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and slow reasoning systems to harmonize reliability and usability. The framework first employs a fast-thinking model to generate confidence-labeled responses, enabling immediate utilization of high-confidence outputs, whereas uncertain predictions trigger a slow refinement model for accuracy improvement. To align model behavior with our proposed object, we propose a hybrid training pipeline, enhancing self-awareness without degrading task performance. Evaluations on dialogue state tracking tasks demonstrate that EKBM achieves superior model reliability over uncertainty-based baselines. Further analysis reveals that refinement substantially boosts accuracy while maintaining low computational overhead. The framework establishes a scalable paradigm for deploying reliable LLMs in error-sensitive applications, effectively balancing accuracy and practical utility.
<div id='section'>Paperid: <span id='pid'>248, <a href='https://arxiv.org/pdf/2403.13204.pdf' target='_blank'>https://arxiv.org/pdf/2403.13204.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anh Bui, Vy Vo, Tung Pham, Dinh Phung, Trung Le
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13204">Diversity-Aware Agnostic Ensemble of Sharpness Minimizers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There has long been plenty of theoretical and empirical evidence supporting the success of ensemble learning. Deep ensembles in particular take advantage of training randomness and expressivity of individual neural networks to gain prediction diversity, ultimately leading to better generalization, robustness and uncertainty estimation. In respect of generalization, it is found that pursuing wider local minima result in models being more robust to shifts between training and testing sets. A natural research question arises out of these two approaches as to whether a boost in generalization ability can be achieved if ensemble learning and loss sharpness minimization are integrated. Our work investigates this connection and proposes DASH - a learning algorithm that promotes diversity and flatness within deep ensembles. More concretely, DASH encourages base learners to move divergently towards low-loss regions of minimal sharpness. We provide a theoretical backbone for our method along with extensive empirical evidence demonstrating an improvement in ensemble generalizability.
<div id='section'>Paperid: <span id='pid'>249, <a href='https://arxiv.org/pdf/2403.14676.pdf' target='_blank'>https://arxiv.org/pdf/2403.14676.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fei Wang, Qi Liu, Enhong Chen, Chuanren Liu, Zhenya Huang, Jinze Wu, Shijin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14676">Unified Uncertainty Estimation for Cognitive Diagnosis Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cognitive diagnosis models have been widely used in different areas, especially intelligent education, to measure users' proficiency levels on knowledge concepts, based on which users can get personalized instructions. As the measurement is not always reliable due to the weak links of the models and data, the uncertainty of measurement also offers important information for decisions. However, the research on the uncertainty estimation lags behind that on advanced model structures for cognitive diagnosis. Existing approaches have limited efficiency and leave an academic blank for sophisticated models which have interaction function parameters (e.g., deep learning-based models). To address these problems, we propose a unified uncertainty estimation approach for a wide range of cognitive diagnosis models. Specifically, based on the idea of estimating the posterior distributions of cognitive diagnosis model parameters, we first provide a unified objective function for mini-batch based optimization that can be more efficiently applied to a wide range of models and large datasets. Then, we modify the reparameterization approach in order to adapt to parameters defined on different domains. Furthermore, we decompose the uncertainty of diagnostic parameters into data aspect and model aspect, which better explains the source of uncertainty. Extensive experiments demonstrate that our method is effective and can provide useful insights into the uncertainty of cognitive diagnosis.
<div id='section'>Paperid: <span id='pid'>250, <a href='https://arxiv.org/pdf/2403.12534.pdf' target='_blank'>https://arxiv.org/pdf/2403.12534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiazhou Zhou, Xu Zheng, Yuanhuiyi Lyu, Lin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.12534">ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action Recognition and More</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Event cameras have recently been shown beneficial for practical vision tasks, such as action recognition, thanks to their high temporal resolution, power efficiency, and reduced privacy concerns. However, current research is hindered by 1) the difficulty in processing events because of their prolonged duration and dynamic actions with complex and ambiguous semantics and 2) the redundant action depiction of the event frame representation with fixed stacks. We find language naturally conveys abundant semantic information, rendering it stunningly superior in reducing semantic uncertainty. In light of this, we propose ExACT, a novel approach that, for the first time, tackles event-based action recognition from a cross-modal conceptualizing perspective. Our ExACT brings two technical contributions. Firstly, we propose an adaptive fine-grained event (AFE) representation to adaptively filter out the repeated events for the stationary objects while preserving dynamic ones. This subtly enhances the performance of ExACT without extra computational cost. Then, we propose a conceptual reasoning-based uncertainty estimation module, which simulates the recognition process to enrich the semantic representation. In particular, conceptual reasoning builds the temporal relation based on the action semantics, and uncertainty estimation tackles the semantic uncertainty of actions based on the distributional representation. Experiments show that our ExACT achieves superior recognition accuracy of 94.83%(+2.23%), 90.10%(+37.47%) and 67.24% on PAF, HARDVS and our SeAct datasets respectively.
<div id='section'>Paperid: <span id='pid'>251, <a href='https://arxiv.org/pdf/2508.02927.pdf' target='_blank'>https://arxiv.org/pdf/2508.02927.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Srikanth Muralidharan, Heitor R. Medeiros, Masih Aminbeidokhti, Eric Granger, Marco Pedersoli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02927">Infrared Object Detection with Ultra Small ConvNets: Is ImageNet Pretraining Still Useful?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many real-world applications require recognition models that are robust to different operational conditions and modalities, but at the same time run on small embedded devices, with limited hardware. While for normal size models, pre-training is known to be very beneficial in accuracy and robustness, for small models, that can be employed for embedded and edge devices, its effect is not clear. In this work, we investigate the effect of ImageNet pretraining on increasingly small backbone architectures (ultra-small models, with $<$1M parameters) with respect to robustness in downstream object detection tasks in the infrared visual modality. Using scaling laws derived from standard object recognition architectures, we construct two ultra-small backbone families and systematically study their performance. Our experiments on three different datasets reveal that while ImageNet pre-training is still useful, beyond a certain capacity threshold, it offers diminishing returns in terms of out-of-distribution detection robustness. Therefore, we advise practitioners to still use pre-training and, when possible avoid too small models as while they might work well for in-domain problems, they are brittle when working conditions are different.
<div id='section'>Paperid: <span id='pid'>252, <a href='https://arxiv.org/pdf/2411.11254.pdf' target='_blank'>https://arxiv.org/pdf/2411.11254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingming Long, Jie Zhang, Shiguang Shan, Xilin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11254">Semantic or Covariate? A Study on the Intractable Case of Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The primary goal of out-of-distribution (OOD) detection tasks is to identify inputs with semantic shifts, i.e., if samples from novel classes are absent in the in-distribution (ID) dataset used for training, we should reject these OOD samples rather than misclassifying them into existing ID classes. However, we find the current definition of "semantic shift" is ambiguous, which renders certain OOD testing protocols intractable for the post-hoc OOD detection methods based on a classifier trained on the ID dataset. In this paper, we offer a more precise definition of the Semantic Space and the Covariate Space for the ID distribution, allowing us to theoretically analyze which types of OOD distributions make the detection task intractable. To avoid the flaw in the existing OOD settings, we further define the "Tractable OOD" setting which ensures the distinguishability of OOD and ID distributions for the post-hoc OOD detection methods. Finally, we conduct several experiments to demonstrate the necessity of our definitions and validate the correctness of our theorems.
<div id='section'>Paperid: <span id='pid'>253, <a href='https://arxiv.org/pdf/2402.11476.pdf' target='_blank'>https://arxiv.org/pdf/2402.11476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiaozhi Tan, Long Bai, Guankun Wang, Mobarakol Islam, Hongliang Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11476">EndoOOD: Uncertainty-aware Out-of-distribution Detection in Capsule Endoscopy Diagnosis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wireless capsule endoscopy (WCE) is a non-invasive diagnostic procedure that enables visualization of the gastrointestinal (GI) tract. Deep learning-based methods have shown effectiveness in disease screening using WCE data, alleviating the burden on healthcare professionals. However, existing capsule endoscopy classification methods mostly rely on pre-defined categories, making it challenging to identify and classify out-of-distribution (OOD) data, such as undefined categories or anatomical landmarks. To address this issue, we propose the Endoscopy Out-of-Distribution (EndoOOD) framework, which aims to effectively handle the OOD detection challenge in WCE diagnosis. The proposed framework focuses on improving the robustness and reliability of WCE diagnostic capabilities by incorporating uncertainty-aware mixup training and long-tailed in-distribution (ID) data calibration techniques. Additionally, virtual-logit matching is employed to accurately distinguish between OOD and ID data while minimizing information loss. To assess the performance of our proposed solution, we conduct evaluations and comparisons with 12 state-of-the-art (SOTA) methods using two publicly available datasets. The results demonstrate the effectiveness of the proposed framework in enhancing diagnostic accuracy and supporting clinical decision-making.
<div id='section'>Paperid: <span id='pid'>254, <a href='https://arxiv.org/pdf/2508.14496.pdf' target='_blank'>https://arxiv.org/pdf/2508.14496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huan Ma, Jiadong Pan, Jing Liu, Yan Chen, Joey Tianyi Zhou, Guangyu Wang, Qinghua Hu, Hua Wu, Changqing Zhang, Haifeng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14496">Semantic Energy: Detecting LLM Hallucination Beyond Entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are being increasingly deployed in real-world applications, but they remain susceptible to hallucinations, which produce fluent yet incorrect responses and lead to erroneous decision-making. Uncertainty estimation is a feasible approach to detect such hallucinations. For example, semantic entropy estimates uncertainty by considering the semantic diversity across multiple sampled responses, thus identifying hallucinations. However, semantic entropy relies on post-softmax probabilities and fails to capture the model's inherent uncertainty, causing it to be ineffective in certain scenarios. To address this issue, we introduce Semantic Energy, a novel uncertainty estimation framework that leverages the inherent confidence of LLMs by operating directly on logits of penultimate layer. By combining semantic clustering with a Boltzmann-inspired energy distribution, our method better captures uncertainty in cases where semantic entropy fails. Experiments across multiple benchmarks show that Semantic Energy significantly improves hallucination detection and uncertainty estimation, offering more reliable signals for downstream applications such as hallucination detection.
<div id='section'>Paperid: <span id='pid'>255, <a href='https://arxiv.org/pdf/2406.02635.pdf' target='_blank'>https://arxiv.org/pdf/2406.02635.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Ragab, Peiliang Gong, Emadeldeen Eldele, Wenyu Zhang, Min Wu, Chuan-Sheng Foo, Daoqiang Zhang, Xiaoli Li, Zhenghua Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02635">Evidentially Calibrated Source-Free Time-Series Domain Adaptation with Temporal Imputation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Source-free domain adaptation (SFDA) aims to adapt a model pre-trained on a labeled source domain to an unlabeled target domain without access to source data, preserving the source domain's privacy. While SFDA is prevalent in computer vision, it remains largely unexplored in time series analysis. Existing SFDA methods, designed for visual data, struggle to capture the inherent temporal dynamics of time series, hindering adaptation performance. This paper proposes MAsk And imPUte (MAPU), a novel and effective approach for time series SFDA. MAPU addresses the critical challenge of temporal consistency by introducing a novel temporal imputation task. This task involves randomly masking time series signals and leveraging a dedicated temporal imputer to recover the original signal within the learned embedding space, bypassing the complexities of noisy raw data. Notably, MAPU is the first method to explicitly address temporal consistency in the context of time series SFDA. Additionally, it offers seamless integration with existing SFDA methods, providing greater flexibility. We further introduce E-MAPU, which incorporates evidential uncertainty estimation to address the overconfidence issue inherent in softmax predictions. To achieve that, we leverage evidential deep learning to obtain a better-calibrated pre-trained model and adapt the target encoder to map out-of-support target samples to a new feature representation closer to the source domain's support. This fosters better alignment, ultimately enhancing adaptation performance. Extensive experiments on five real-world time series datasets demonstrate that both MAPU and E-MAPU achieve significant performance gains compared to existing methods. These results highlight the effectiveness of our proposed approaches for tackling various time series domain adaptation problems.
<div id='section'>Paperid: <span id='pid'>256, <a href='https://arxiv.org/pdf/2403.02628.pdf' target='_blank'>https://arxiv.org/pdf/2403.02628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Biqing Qi, Xingquan Chen, Junqi Gao, Dong Li, Jianxing Liu, Ligang Wu, Bowen Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.02628">Interactive Continual Learning: Fast and Slow Thinking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advanced life forms, sustained by the synergistic interaction of neural cognitive mechanisms, continually acquire and transfer knowledge throughout their lifespan. In contrast, contemporary machine learning paradigms exhibit limitations in emulating the facets of continual learning (CL). Nonetheless, the emergence of large language models (LLMs) presents promising avenues for realizing CL via interactions with these models. Drawing on Complementary Learning System theory, this paper presents a novel Interactive Continual Learning (ICL) framework, enabled by collaborative interactions among models of various sizes. Specifically, we assign the ViT model as System1 and multimodal LLM as System2. To enable the memory module to deduce tasks from class information and enhance Set2Set retrieval, we propose the Class-Knowledge-Task Multi-Head Attention (CKT-MHA). Additionally, to improve memory retrieval in System1 through enhanced geometric representation, we introduce the CL-vMF mechanism, based on the von Mises-Fisher (vMF) distribution. Meanwhile, we introduce the von Mises-Fisher Outlier Detection and Interaction (vMF-ODI) strategy to identify hard examples, thus enhancing collaboration between System1 and System2 for complex reasoning realization. Comprehensive evaluation of our proposed ICL demonstrates significant resistance to forgetting and superior performance relative to existing methods. Code is available at github.com/ICL.
<div id='section'>Paperid: <span id='pid'>257, <a href='https://arxiv.org/pdf/2509.16696.pdf' target='_blank'>https://arxiv.org/pdf/2509.16696.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wataru Hashimoto, Hidetaka Kamigaito, Taro Watanabe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16696">Decoding Uncertainty: The Impact of Decoding Strategies for Uncertainty Estimation in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Decoding strategies manipulate the probability distribution underlying the output of a language model and can therefore affect both generation quality and its uncertainty. In this study, we investigate the impact of decoding strategies on uncertainty estimation in Large Language Models (LLMs). Our experiments show that Contrastive Search, which mitigates repetition, yields better uncertainty estimates on average across a range of preference-aligned LLMs. In contrast, the benefits of these strategies sometimes diverge when the model is only post-trained with supervised fine-tuning, i.e. without explicit alignment.
<div id='section'>Paperid: <span id='pid'>258, <a href='https://arxiv.org/pdf/2407.02138.pdf' target='_blank'>https://arxiv.org/pdf/2407.02138.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wataru Hashimoto, Hidetaka Kamigaito, Taro Watanabe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02138">Efficient Nearest Neighbor based Uncertainty Estimation for Natural Language Processing Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trustworthiness in model predictions is crucial for safety-critical applications in the real world. However, deep neural networks often suffer from the issues of uncertainty estimation, such as miscalibration. In this study, we propose $k$-Nearest Neighbor Uncertainty Estimation ($k$NN-UE), which is a new uncertainty estimation method that uses not only the distances from the neighbors, but also the ratio of labels in the neighbors. Experiments on sentiment analysis, natural language inference, and named entity recognition show that our proposed method outperforms the baselines and recent density-based methods in several calibration and uncertainty metrics. Moreover, our analyses indicate that approximate nearest neighbor search techniques reduce the inference overhead without significantly degrading the uncertainty estimation performance when they are appropriately combined.
<div id='section'>Paperid: <span id='pid'>259, <a href='https://arxiv.org/pdf/2407.02062.pdf' target='_blank'>https://arxiv.org/pdf/2407.02062.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wataru Hashimoto, Hidetaka Kamigaito, Taro Watanabe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02062">Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work investigates the impact of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks. For the future advance of NER in safety-critical fields like healthcare and finance, it is essential to achieve accurate predictions with calibrated confidence when applying Deep Neural Networks (DNNs), including Pre-trained Language Models (PLMs), as a real-world application. However, DNNs are prone to miscalibration, which limits their applicability. Moreover, existing methods for calibration and uncertainty estimation are computational expensive. Our investigation in NER found that data augmentation improves calibration and uncertainty in cross-genre and cross-lingual setting, especially in-domain setting. Furthermore, we showed that the calibration for NER tends to be more effective when the perplexity of the sentences generated by data augmentation is lower, and that increasing the size of the augmentation further improves calibration and uncertainty.
<div id='section'>Paperid: <span id='pid'>260, <a href='https://arxiv.org/pdf/2503.20462.pdf' target='_blank'>https://arxiv.org/pdf/2503.20462.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruoqi Wen, Rongpeng Li, Xing Xu, Zhifeng Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20462">Multi-agent Uncertainty-Aware Pessimistic Model-Based Reinforcement Learning for Connected Autonomous Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Reinforcement Learning (DRL) holds significant promise for achieving human-like Autonomous Vehicle (AV) capabilities, but suffers from low sample efficiency and challenges in reward design. Model-Based Reinforcement Learning (MBRL) offers improved sample efficiency and generalizability compared to Model-Free Reinforcement Learning (MFRL) in various multi-agent decision-making scenarios. Nevertheless, MBRL faces critical difficulties in estimating uncertainty during the model learning phase, thereby limiting its scalability and applicability in real-world scenarios. Additionally, most Connected Autonomous Vehicle (CAV) studies focus on single-agent decision-making, while existing multi-agent MBRL solutions lack computationally tractable algorithms with Probably Approximately Correct (PAC) guarantees, an essential factor for ensuring policy reliability with limited training data. To address these challenges, we propose MA-PMBRL, a novel Multi-Agent Pessimistic Model-Based Reinforcement Learning framework for CAVs, incorporating a max-min optimization approach to enhance robustness and decision-making. To mitigate the inherent subjectivity of uncertainty estimation in MBRL and avoid incurring catastrophic failures in AV, MA-PMBRL employs a pessimistic optimization framework combined with Projected Gradient Descent (PGD) for both model and policy learning. MA-PMBRL also employs general function approximations under partial dataset coverage to enhance learning efficiency and system-level performance. By bounding the suboptimality of the resulting policy under mild theoretical assumptions, we successfully establish PAC guarantees for MA-PMBRL, demonstrating that the proposed framework represents a significant step toward scalable, efficient, and reliable multi-agent decision-making for CAVs.
<div id='section'>Paperid: <span id='pid'>261, <a href='https://arxiv.org/pdf/2512.19725.pdf' target='_blank'>https://arxiv.org/pdf/2512.19725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Srishti Gupta, Riccardo Balia, Daniele Angioni, Fabio Brau, Maura Pintor, Ambra Demontis, Alessandro Sebastian, Salvatore Mario Carta, Fabio Roli, Battista Biggio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.19725">Out-of-Distribution Detection for Continual Learning: Design Principles and Benchmarking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent years have witnessed significant progress in the development of machine learning models across a wide range of fields, fueled by increased computational resources, large-scale datasets, and the rise of deep learning architectures. From malware detection to enabling autonomous navigation, modern machine learning systems have demonstrated remarkable capabilities. However, as these models are deployed in ever-changing real-world scenarios, their ability to remain reliable and adaptive over time becomes increasingly important. For example, in the real world, new malware families are continuously developed, whereas autonomous driving cars are employed in many different cities and weather conditions. Models trained in fixed settings can not respond effectively to novel conditions encountered post-deployment. In fact, most machine learning models are still developed under the assumption that training and test data are independent and identically distributed (i.i.d.), i.e., sampled from the same underlying (unknown) distribution. While this assumption simplifies model development and evaluation, it does not hold in many real-world applications, where data changes over time and unexpected inputs frequently occur. Retraining models from scratch whenever new data appears is computationally expensive, time-consuming, and impractical in resource-constrained environments. These limitations underscore the need for Continual Learning (CL), which enables models to incrementally learn from evolving data streams without forgetting past knowledge, and Out-of-Distribution (OOD) detection, which allows systems to identify and respond to novel or anomalous inputs. Jointly addressing both challenges is critical to developing robust, efficient, and adaptive AI systems.
<div id='section'>Paperid: <span id='pid'>262, <a href='https://arxiv.org/pdf/2505.23412.pdf' target='_blank'>https://arxiv.org/pdf/2505.23412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Srishti Gupta, Daniele Angioni, Maura Pintor, Ambra Demontis, Lea SchÃ¶nherr, Battista Biggio, Fabio Roli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23412">Buffer-free Class-Incremental Learning with Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Class-incremental learning (CIL) poses significant challenges in open-world scenarios, where models must not only learn new classes over time without forgetting previous ones but also handle inputs from unknown classes that a closed-set model would misclassify. Recent works address both issues by (i)~training multi-head models using the task-incremental learning framework, and (ii) predicting the task identity employing out-of-distribution (OOD) detectors. While effective, the latter mainly relies on joint training with a memory buffer of past data, raising concerns around privacy, scalability, and increased training time. In this paper, we present an in-depth analysis of post-hoc OOD detection methods and investigate their potential to eliminate the need for a memory buffer. We uncover that these methods, when applied appropriately at inference time, can serve as a strong substitute for buffer-based OOD detection. We show that this buffer-free approach achieves comparable or superior performance to buffer-based methods both in terms of class-incremental learning and the rejection of unknown samples. Experimental results on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets support our findings, offering new insights into the design of efficient and privacy-preserving CIL systems for open-world settings.
<div id='section'>Paperid: <span id='pid'>263, <a href='https://arxiv.org/pdf/2402.12862.pdf' target='_blank'>https://arxiv.org/pdf/2402.12862.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wen Wu, Bo Li, Chao Zhang, Chung-Cheng Chiu, Qiujia Li, Junwen Bai, Tara N. Sainath, Philip C. Woodland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12862">Handling Ambiguity in Emotion: From Out-of-Domain Detection to Distribution Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The subjective perception of emotion leads to inconsistent labels from human annotators. Typically, utterances lacking majority-agreed labels are excluded when training an emotion classifier, which cause problems when encountering ambiguous emotional expressions during testing. This paper investigates three methods to handle ambiguous emotion. First, we show that incorporating utterances without majority-agreed labels as an additional class in the classifier reduces the classification performance of the other emotion classes. Then, we propose detecting utterances with ambiguous emotions as out-of-domain samples by quantifying the uncertainty in emotion classification using evidential deep learning. This approach retains the classification accuracy while effectively detects ambiguous emotion expressions. Furthermore, to obtain fine-grained distinctions among ambiguous emotions, we propose representing emotion as a distribution instead of a single class label. The task is thus re-framed from classification to distribution estimation where every individual annotation is taken into account, not just the majority opinion. The evidential uncertainty measure is extended to quantify the uncertainty in emotion distribution estimation. Experimental results on the IEMOCAP and CREMA-D datasets demonstrate the superior capability of the proposed method in terms of majority class prediction, emotion distribution estimation, and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>264, <a href='https://arxiv.org/pdf/2509.12982.pdf' target='_blank'>https://arxiv.org/pdf/2509.12982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erblin Isaku, Hassan Sartaj, Shaukat Ali, Beatriz Sanguino, Tongtong Wang, Guoyuan Li, Houxiang Zhang, Thomas Peyrucain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12982">Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-adaptive robots (SARs) in complex, uncertain environments must proactively detect and address abnormal behaviors, including out-of-distribution (OOD) cases. To this end, digital twins offer a valuable solution for OOD detection. Thus, we present a digital twin-based approach for OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to forecast SAR states and employs reconstruction error and Monte Carlo dropout for uncertainty quantification. By combining reconstruction error with predictive variance, the digital twin effectively detects OOD behaviors, even in previously unseen conditions. The digital twin also includes an explainability layer that links potential OOD to specific SAR states, offering insights for self-adaptation. We evaluated ODiSAR by creating digital twins of two industrial robots: one navigating an office environment, and another performing maritime ship navigation. In both cases, ODiSAR forecasts SAR behaviors (i.e., robot trajectories and vessel motion) and proactively detects OOD events. Our results showed that ODiSAR achieved high detection performance -- up to 98\% AUROC, 96\% TNR@TPR95, and 95\% F1-score -- while providing interpretable insights to support self-adaptation.
<div id='section'>Paperid: <span id='pid'>265, <a href='https://arxiv.org/pdf/2504.19816.pdf' target='_blank'>https://arxiv.org/pdf/2504.19816.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erblin Isaku, Hassan Sartaj, Shaukat Ali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19816">Digital Twin-based Out-of-Distribution Detection in Autonomous Vessels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An autonomous vessel (AV) is a complex cyber-physical system (CPS) with software enabling many key functionalities, e.g., navigation software enables an AV to autonomously or semi-autonomously follow a path to its destination. Digital twins of such AVs enable advanced functionalities such as running what-if scenarios, performing predictive maintenance, and enabling fault diagnosis. Due to technological improvements, real-time analyses using continuous data from vessels' real-time operations have become increasingly possible. However, the literature has little explored developing advanced analyses in real-time data in AVs with digital twins built with machine learning techniques. To this end, we present a novel digital twin-based approach (ODDIT) to detect future out-of-distribution (OOD) states of an AV before reaching them, enabling proactive intervention. Such states may indicate anomalies requiring attention (e.g., manual correction by the ship master) and assist testers in scenario-centered testing. The digital twin consists of two machine-learning models predicting future vessel states and whether the predicted state will be OOD. We evaluated ODDIT with five vessels across waypoint and zigzag maneuvering under simulated conditions, including sensor and actuator noise and environmental disturbances i.e., ocean current. ODDIT achieved high accuracy in detecting OOD states, with AUROC and TNR@TPR95 scores reaching 99\% across multiple vessels.
<div id='section'>Paperid: <span id='pid'>266, <a href='https://arxiv.org/pdf/2407.21497.pdf' target='_blank'>https://arxiv.org/pdf/2407.21497.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Liu, Xiliang Zhu, Tong Han, Yuhao Huang, Jian Wang, Lian Liu, Fang Wang, Dong Ni, Zhongshan Gou, Xin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21497">Mitral Regurgitation Recognition based on Unsupervised Out-of-Distribution Detection with Residual Diffusion Amplification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mitral regurgitation (MR) is a serious heart valve disease. Early and accurate diagnosis of MR via ultrasound video is critical for timely clinical decision-making and surgical intervention. However, manual MR diagnosis heavily relies on the operator's experience, which may cause misdiagnosis and inter-observer variability. Since MR data is limited and has large intra-class variability, we propose an unsupervised out-of-distribution (OOD) detection method to identify MR rather than building a deep classifier. To our knowledge, we are the first to explore OOD in MR ultrasound videos. Our method consists of a feature extractor, a feature reconstruction model, and a residual accumulation amplification algorithm. The feature extractor obtains features from the video clips and feeds them into the feature reconstruction model to restore the original features. The residual accumulation amplification algorithm then iteratively performs noise feature reconstruction, amplifying the reconstructed error of OOD features. This algorithm is straightforward yet efficient and can seamlessly integrate as a plug-and-play component in reconstruction-based OOD detection methods. We validated the proposed method on a large ultrasound dataset containing 893 non-MR and 267 MR videos. Experimental results show that our OOD detection method can effectively identify MR samples.
<div id='section'>Paperid: <span id='pid'>267, <a href='https://arxiv.org/pdf/2411.05791.pdf' target='_blank'>https://arxiv.org/pdf/2411.05791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Divo, Eric Endress, Kevin Endler, Kristian Kersting, Devendra Singh Dhami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05791">Forecasting Company Fundamentals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Company fundamentals are key to assessing companies' financial and overall success and stability. Forecasting them is important in multiple fields, including investing and econometrics. While statistical and contemporary machine learning methods have been applied to many time series tasks, there is a lack of comparison of these approaches on this particularly challenging data regime. To this end, we try to bridge this gap and thoroughly evaluate the theoretical properties and practical performance of 24 deterministic and probabilistic company fundamentals forecasting models on real company data. We observe that deep learning models provide superior forecasting performance to classical models, in particular when considering uncertainty estimation. To validate the findings, we compare them to human analyst expectations and find that their accuracy is comparable to the automatic forecasts. We further show how these high-quality forecasts can benefit automated stock allocation. We close by presenting possible ways of integrating domain experts to further improve performance and increase reliability.
<div id='section'>Paperid: <span id='pid'>268, <a href='https://arxiv.org/pdf/2411.00850.pdf' target='_blank'>https://arxiv.org/pdf/2411.00850.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihua Shao, Yan Gu, Siyu Chen, Haiyang Liu, Zixian Zhu, Zijian Ling, Minxi Yan, Ziyang Yan, Chenyu Zhang, Michele Magno, Haotong Qin, Yan Wang, Jingcai Guo, Ling Shao, Hao Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00850">GWQ: Gradient-Aware Weight Quantization for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) show impressive performance in solving complex language tasks. However, its large number of parameters presents significant challenges for the deployment. So, compressing LLMs to low bits can enable to deploy on resource-constrained devices. To address this problem, we propose gradient-aware weight quantization (GWQ), the first quantization approach for low-bit weight quantization that leverages gradients to localize outliers, requiring only a minimal amount of calibration data for outlier detection. GWQ retains the top 1\% outliers preferentially at FP16 precision, while the remaining non-outlier weights are stored in a low-bit. We widely evaluate GWQ on different task include language modeling, grounding detection, massive multitask language understanding and vision-language question and answering. Results show that models quantified by GWQ performs better than other quantization method. During quantization process, GWQ only need one calibration set to realize effective quant. Also, GWQ achieves 1.2x inference speedup in comparison to the original model and effectively reduces the inference memory.
<div id='section'>Paperid: <span id='pid'>269, <a href='https://arxiv.org/pdf/2405.14039.pdf' target='_blank'>https://arxiv.org/pdf/2405.14039.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, Zhuosheng Zhang, Rui Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14039">Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world data deviating from the independent and identically distributed (i.i.d.) assumption of in-distribution training data poses security threats to deep networks, thus advancing out-of-distribution (OOD) detection algorithms. Detection methods in generative language models (GLMs) mainly focus on uncertainty estimation and embedding distance measurement, with the latter proven to be most effective in traditional linguistic tasks like summarization and translation. However, another complex generative scenario mathematical reasoning poses significant challenges to embedding-based methods due to its high-density feature of output spaces, but this feature causes larger discrepancies in the embedding shift trajectory between different samples in latent spaces. Hence, we propose a trajectory-based method TV score, which uses trajectory volatility for OOD detection in mathematical reasoning. Experiments show that our method outperforms all traditional algorithms on GLMs under mathematical reasoning scenarios and can be extended to more applications with high-density features in output spaces, such as multiple-choice questions.
<div id='section'>Paperid: <span id='pid'>270, <a href='https://arxiv.org/pdf/2403.04571.pdf' target='_blank'>https://arxiv.org/pdf/2403.04571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yoshua Bengio, Nikolay Malkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04571">Machine learning and information theory concepts towards an AI Mathematician</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The current state-of-the-art in artificial intelligence is impressive, especially in terms of mastery of language, but not so much in terms of mathematical reasoning. What could be missing? Can we learn something useful about that gap from how the brains of mathematicians go about their craft? This essay builds on the idea that current deep learning mostly succeeds at system 1 abilities -- which correspond to our intuition and habitual behaviors -- but still lacks something important regarding system 2 abilities -- which include reasoning and robust uncertainty estimation. It takes an information-theoretical posture to ask questions about what constitutes an interesting mathematical statement, which could guide future work in crafting an AI mathematician. The focus is not on proving a given theorem but on discovering new and interesting conjectures. The central hypothesis is that a desirable body of theorems better summarizes the set of all provable statements, for example by having a small description length while at the same time being close (in terms of number of derivation steps) to many provable statements.
<div id='section'>Paperid: <span id='pid'>271, <a href='https://arxiv.org/pdf/2506.23881.pdf' target='_blank'>https://arxiv.org/pdf/2506.23881.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Reihaneh Zohrabi, Hosein Hasani, Mahdieh Soleymani Baghshah, Anna Rohrbach, Marcus Rohrbach, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23881">Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring the reliability and safety of machine learning models in real-world applications, where they frequently face data distributions unseen during training. Despite progress, existing methods are often vulnerable to spurious correlations that mislead models and compromise robustness. To address this, we propose SPROD, a novel prototype-based OOD detection approach that explicitly addresses the challenge posed by unknown spurious correlations. Our post-hoc method refines class prototypes to mitigate bias from spurious features without additional data or hyperparameter tuning, and is broadly applicable across diverse backbones and OOD detection settings. We conduct a comprehensive spurious correlation OOD detection benchmarking, comparing our method against existing approaches and demonstrating its superior performance across challenging OOD datasets, such as CelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced Animals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3% over the second best.
<div id='section'>Paperid: <span id='pid'>272, <a href='https://arxiv.org/pdf/2506.01116.pdf' target='_blank'>https://arxiv.org/pdf/2506.01116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyi Liu, Lipeng Ma, Yixuan Li, Weidong Yang, Qingyuan Zhou, Jiayi Song, Shuhao Li, Ben Fei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01116">ChemAU: Harness the Reasoning of LLMs in Chemical Research with Adaptive Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are widely used across various scenarios due to their exceptional reasoning capabilities and natural language understanding. While LLMs demonstrate strong performance in tasks involving mathematics and coding, their effectiveness diminishes significantly when applied to chemistry-related problems. Chemistry problems typically involve long and complex reasoning steps, which contain specific terminology, including specialized symbol systems and complex nomenclature conventions. These characteristics often cause general LLMs to experience hallucinations during the reasoning process due to their lack of specific knowledge. However, existing methods are struggling to effectively leverage chemical expertise and formulas. Moreover, current uncertainty estimation methods, designed to mitigate potential reasoning errors, are unable to precisely identify specific steps or key knowledge. In this work, we propose a novel framework called ChemAU, which incorporates our adaptive uncertainty estimation method that applies different uncertainty values based on the position of reasoning steps within the whole reasoning chain. Leveraging this method, ChemAU identifies gaps in chemistry knowledge and precisely supplements chemical expertise with the specialized domain model, thereby correcting and updating the previously flawed reasoning chain. Our experiments with three popular LLMs across three chemistry datasets demonstrate that ChemAU significantly enhances both reasoning accuracy and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>273, <a href='https://arxiv.org/pdf/2503.08162.pdf' target='_blank'>https://arxiv.org/pdf/2503.08162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kangan Qian, Ziang Luo, Sicong Jiang, Zilin Huang, Jinyu Miao, Zhikun Ma, Tianze Zhu, Jiayin Li, Yangfan He, Zheng Fu, Yining Shi, Boyue Wang, Hezhe Lin, Ziyu Chen, Jiangbo Yu, Xinyu Jiao, Mengmeng Yang, Kun Jiang, Diange Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08162">FASIONAD++ : Integrating High-Level Instruction and Information Bottleneck in FAt-Slow fusION Systems for Enhanced Safety in Autonomous Driving with Adaptive Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensuring safe, comfortable, and efficient planning is crucial for autonomous driving systems. While end-to-end models trained on large datasets perform well in standard driving scenarios, they struggle with complex low-frequency events. Recent Large Language Models (LLMs) and Vision Language Models (VLMs) advancements offer enhanced reasoning but suffer from computational inefficiency. Inspired by the dual-process cognitive model "Thinking, Fast and Slow", we propose $\textbf{FASIONAD}$ -- a novel dual-system framework that synergizes a fast end-to-end planner with a VLM-based reasoning module. The fast system leverages end-to-end learning to achieve real-time trajectory generation in common scenarios, while the slow system activates through uncertainty estimation to perform contextual analysis and complex scenario resolution. Our architecture introduces three key innovations: (1) A dynamic switching mechanism enabling slow system intervention based on real-time uncertainty assessment; (2) An information bottleneck with high-level plan feedback that optimizes the slow system's guidance capability; (3) A bidirectional knowledge exchange where visual prompts enhance the slow system's reasoning while its feedback refines the fast planner's decision-making. To strengthen VLM reasoning, we develop a question-answering mechanism coupled with reward-instruct training strategy. In open-loop experiments, FASIONAD achieves a $6.7\%$ reduction in average $L2$ trajectory error and $28.1\%$ lower collision rate.
<div id='section'>Paperid: <span id='pid'>274, <a href='https://arxiv.org/pdf/2501.11031.pdf' target='_blank'>https://arxiv.org/pdf/2501.11031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lipeng Ma, Weidong Yang, Yixuan Li, Ben Fei, Mingjie Zhou, Shuhao Li, Sihang Jiang, Bo Xu, Yanghua Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11031">AdaptiveLog: An Adaptive Log Analysis Framework with the Collaboration of Large and Small Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated log analysis is crucial to ensure high availability and reliability of complex systems. The advent of LLMs in NLP has ushered in a new era of language model-driven automated log analysis, garnering significant interest. Within this field, two primary paradigms based on language models for log analysis have become prominent. Small Language Models (SLMs) follow the pre-train and fine-tune paradigm, focusing on the specific log analysis task through fine-tuning on supervised datasets. On the other hand, LLMs following the in-context learning paradigm, analyze logs by providing a few examples in prompt contexts without updating parameters. Despite their respective strengths, we notice that SLMs are more cost-effective but less powerful, whereas LLMs with large parameters are highly powerful but expensive and inefficient. To trade-off between the performance and inference costs of both models in automated log analysis, this paper introduces an adaptive log analysis framework known as AdaptiveLog, which effectively reduces the costs associated with LLM while ensuring superior results. This framework collaborates an LLM and a small language model, strategically allocating the LLM to tackle complex logs while delegating simpler logs to the SLM. Specifically, to efficiently query the LLM, we propose an adaptive selection strategy based on the uncertainty estimation of the SLM, where the LLM is invoked only when the SLM is uncertain. In addition, to enhance the reasoning ability of the LLM in log analysis tasks, we propose a novel prompt strategy by retrieving similar error-prone cases as the reference, enabling the model to leverage past error experiences and learn solutions from these cases. Extensive experiments demonstrate that AdaptiveLog achieves state-of-the-art results across different tasks, elevating the overall accuracy of log analysis while maintaining cost efficiency.
<div id='section'>Paperid: <span id='pid'>275, <a href='https://arxiv.org/pdf/2404.07580.pdf' target='_blank'>https://arxiv.org/pdf/2404.07580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinhong Wang, Yi Cheng, Jintai Chen, Hongxia Xu, Danny Chen, Jian Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07580">Multi-rater Prompting for Ambiguous Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-rater annotations commonly occur when medical images are independently annotated by multiple experts (raters). In this paper, we tackle two challenges arisen in multi-rater annotations for medical image segmentation (called ambiguous medical image segmentation): (1) How to train a deep learning model when a group of raters produces a set of diverse but plausible annotations, and (2) how to fine-tune the model efficiently when computation resources are not available for re-training the entire model on a different dataset domain. We propose a multi-rater prompt-based approach to address these two challenges altogether. Specifically, we introduce a series of rater-aware prompts that can be plugged into the U-Net model for uncertainty estimation to handle multi-annotation cases. During the prompt-based fine-tuning process, only 0.3% of learnable parameters are required to be updated comparing to training the entire model. Further, in order to integrate expert consensus and disagreement, we explore different multi-rater incorporation strategies and design a mix-training strategy for comprehensive insight learning. Extensive experiments verify the effectiveness of our new approach for ambiguous medical image segmentation on two public datasets while alleviating the heavy burden of model re-training.
<div id='section'>Paperid: <span id='pid'>276, <a href='https://arxiv.org/pdf/2509.01564.pdf' target='_blank'>https://arxiv.org/pdf/2509.01564.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeguan Xiao, Diyang Dou, Boya Xiong, Yun Chen, Guanhua Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01564">Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have achieved remarkable success across a wide range of natural language tasks, but often exhibit overconfidence and generate plausible yet incorrect answers. This overconfidence, especially in models undergone Reinforcement Learning from Human Feedback (RLHF), poses significant challenges for reliable uncertainty estimation and safe deployment. In this paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel self-evaluation-based calibration method that leverages the internal hidden states of LLMs to derive more accurate confidence scores. Instead of relying on the model's final output, our approach extracts internal beliefs from multiple intermediate layers during self-evaluation. By aggregating these layer-wise beliefs and calculating the expectation over the resulting confidence score distribution, EAGLE produces a refined confidence score that more faithfully reflects the model's internal certainty. Extensive experiments on diverse datasets and LLMs demonstrate that EAGLE significantly improves calibration performance over existing baselines. We also provide an in-depth analysis of EAGLE, including a layer-wise examination of uncertainty patterns, a study of the impact of self-evaluation prompts, and an analysis of the effect of self-evaluation score range.
<div id='section'>Paperid: <span id='pid'>277, <a href='https://arxiv.org/pdf/2403.16594.pdf' target='_blank'>https://arxiv.org/pdf/2403.16594.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kudaibergen Abutalip, Numan Saeed, Ikboljon Sobirov, Vincent Andrearczyk, Adrien Depeursinge, Mohammad Yaqub
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.16594">EDUE: Expert Disagreement-Guided One-Pass Uncertainty Estimation for Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying deep learning (DL) models in medical applications relies on predictive performance and other critical factors, such as conveying trustworthy predictive uncertainty. Uncertainty estimation (UE) methods provide potential solutions for evaluating prediction reliability and improving the model confidence calibration. Despite increasing interest in UE, challenges persist, such as the need for explicit methods to capture aleatoric uncertainty and align uncertainty estimates with real-life disagreements among domain experts. This paper proposes an Expert Disagreement-Guided Uncertainty Estimation (EDUE) for medical image segmentation. By leveraging variability in ground-truth annotations from multiple raters, we guide the model during training and incorporate random sampling-based strategies to enhance calibration confidence. Our method achieves 55% and 23% improvement in correlation on average with expert disagreements at the image and pixel levels, respectively, better calibration, and competitive segmentation performance compared to the state-of-the-art deep ensembles, requiring only a single forward pass.
<div id='section'>Paperid: <span id='pid'>278, <a href='https://arxiv.org/pdf/2510.13750.pdf' target='_blank'>https://arxiv.org/pdf/2510.13750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiqi Huang, Vivek Datla, Chenyang Zhu, Alfy Samuel, Daben Liu, Anoop Kumar, Ritesh Soni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.13750">Confidence-Based Response Abstinence: Improving LLM Trustworthiness via Activation-Based Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a method for confidence estimation in retrieval-augmented generation (RAG) systems that aligns closely with the correctness of large language model (LLM) outputs. Confidence estimation is especially critical in high-stakes domains such as finance and healthcare, where the cost of an incorrect answer outweighs that of not answering the question. Our approach extends prior uncertainty quantification methods by leveraging raw feed-forward network (FFN) activations as auto-regressive signals, avoiding the information loss inherent in token logits and probabilities after projection and softmax normalization. We model confidence prediction as a sequence classification task, and regularize training with a Huber loss term to improve robustness against noisy supervision. Applied in a real-world financial industry customer-support setting with complex knowledge bases, our method outperforms strong baselines and maintains high accuracy under strict latency constraints. Experiments on Llama 3.1 8B model show that using activations from only the 16th layer preserves accuracy while reducing response latency. Our results demonstrate that activation-based confidence modeling offers a scalable, architecture-aware path toward trustworthy RAG deployment.
<div id='section'>Paperid: <span id='pid'>279, <a href='https://arxiv.org/pdf/2505.23811.pdf' target='_blank'>https://arxiv.org/pdf/2505.23811.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hadi Askari, Shivanshu Gupta, Fei Wang, Anshuman Chhabra, Muhao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23811">LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pretrained Large Language Models (LLMs) achieve strong performance across a wide range of tasks, yet exhibit substantial variability in the various layers' training quality with respect to specific downstream applications, limiting their downstream performance. It is therefore critical to estimate layer-wise training quality in a manner that accounts for both model architecture and training data. However, existing approaches predominantly rely on model-centric heuristics (such as spectral statistics, outlier detection, or uniform allocation) while overlooking the influence of data. To address these limitations, we propose LayerIF, a data-driven framework that leverages Influence Functions to quantify the training quality of individual layers in a principled and task-sensitive manner. By isolating each layer's gradients and measuring the sensitivity of the validation loss to training examples by computing layer-wise influences, we derive data-driven estimates of layer importance. Notably, our method produces task-specific layer importance estimates for the same LLM, revealing how layers specialize for different test-time evaluation tasks. We demonstrate the utility of our scores by leveraging them for two downstream applications: (a) expert allocation in LoRA-MoE architectures and (b) layer-wise sparsity distribution for LLM pruning. Experiments across multiple LLM architectures demonstrate that our model-agnostic, influence-guided allocation leads to consistent gains in task performance.
<div id='section'>Paperid: <span id='pid'>280, <a href='https://arxiv.org/pdf/2512.21685.pdf' target='_blank'>https://arxiv.org/pdf/2512.21685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haochen Lv, Yan Lin, Shengnan Guo, Xiaowei Mao, Hong Nie, Letian Gong, Youfang Lin, Huaiyu Wan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.21685">RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate traffic flow forecasting is crucial for intelligent transportation services such as navigation and ride-hailing. In such applications, uncertainty estimation in forecasting is important because it helps evaluate traffic risk levels, assess forecast reliability, and provide timely warnings. As a result, probabilistic traffic flow forecasting (PTFF) has gained significant attention, as it produces both point forecasts and uncertainty estimates. However, existing PTFF approaches still face two key challenges: (1) how to uncover and model the causes of traffic flow uncertainty for reliable forecasting, and (2) how to capture the spatiotemporal correlations of uncertainty for accurate prediction. To address these challenges, we propose RIPCN, a Road Impedance Principal Component Network that integrates domain-specific transportation theory with spatiotemporal principal component learning for PTFF. RIPCN introduces a dynamic impedance evolution network that captures directional traffic transfer patterns driven by road congestion level and flow variability, revealing the direct causes of uncertainty and enhancing both reliability and interpretability. In addition, a principal component network is designed to forecast the dominant eigenvectors of future flow covariance, enabling the model to capture spatiotemporal uncertainty correlations. This design allows for accurate and efficient uncertainty estimation while also improving point prediction performance. Experimental results on real-world datasets show that our approach outperforms existing probabilistic forecasting methods.
<div id='section'>Paperid: <span id='pid'>281, <a href='https://arxiv.org/pdf/2508.12997.pdf' target='_blank'>https://arxiv.org/pdf/2508.12997.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haishun Chen, Cai Xu, Jinlong Yu, Yilin Zhang, Ziyu Guan, Wei Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12997">Fairness-Aware Multi-view Evidential Learning with Adaptive Prior</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-view evidential learning aims to integrate information from multiple views to improve prediction performance and provide trustworthy uncertainty esitimation. Most previous methods assume that view-specific evidence learning is naturally reliable. However, in practice, the evidence learning process tends to be biased. Through empirical analysis on real-world data, we reveal that samples tend to be assigned more evidence to support data-rich classes, thereby leading to unreliable uncertainty estimation in predictions. This motivates us to delve into a new Biased Evidential Multi-view Learning (BEML) problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning (FAML). FAML first introduces an adaptive prior based on training trajectory, which acts as a regularization strategy to flexibly calibrate the biased evidence learning process. Furthermore, we explicitly incorporate a fairness constraint based on class-wise evidence variance to promote balanced evidence allocation. In the multi-view fusion stage, we propose an opinion alignment mechanism to mitigate view-specific bias across views, thereby encouraging the integration of consistent and mutually supportive evidence. Extensive experiments on five real-world multi-view datasets demonstrate that FAML achieves more balanced evidence allocation and improves both prediction performance and the reliability of uncertainty estimation compared to state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>282, <a href='https://arxiv.org/pdf/2409.07020.pdf' target='_blank'>https://arxiv.org/pdf/2409.07020.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenjun Li, Dian Yang, Shun Yao, Shuyue Wang, Ye Wu, Le Zhang, Qiannuo Li, Kang Ik Kevin Cho, Johanna Seitz-Holland, Lipeng Ning, Jon Haitz Legarreta, Yogesh Rathi, Carl-Fredrik Westin, Lauren J. O'Donnell, Nir A. Sochen, Ofer Pasternak, Fan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07020">DDEvENet: Evidence-based Ensemble Learning for Uncertainty-aware Brain Parcellation Using Diffusion MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we developed an Evidence-based Ensemble Neural Network, namely EVENet, for anatomical brain parcellation using diffusion MRI. The key innovation of EVENet is the design of an evidential deep learning framework to quantify predictive uncertainty at each voxel during a single inference. To do so, we design an evidence-based ensemble learning framework for uncertainty-aware parcellation to leverage the multiple dMRI parameters derived from diffusion MRI. Using EVENet, we obtained accurate parcellation and uncertainty estimates across different datasets from healthy and clinical populations and with different imaging acquisitions. The overall network includes five parallel subnetworks, where each is dedicated to learning the FreeSurfer parcellation for a certain diffusion MRI parameter. An evidence-based ensemble methodology is then proposed to fuse the individual outputs. We perform experimental evaluations on large-scale datasets from multiple imaging sources, including high-quality diffusion MRI data from healthy adults and clinically diffusion MRI data from participants with various brain diseases (schizophrenia, bipolar disorder, attention-deficit/hyperactivity disorder, Parkinson's disease, cerebral small vessel disease, and neurosurgical patients with brain tumors). Compared to several state-of-the-art methods, our experimental results demonstrate highly improved parcellation accuracy across the multiple testing datasets despite the differences in dMRI acquisition protocols and health conditions. Furthermore, thanks to the uncertainty estimation, our EVENet approach demonstrates a good ability to detect abnormal brain regions in patients with lesions, enhancing the interpretability and reliability of the segmentation results.
<div id='section'>Paperid: <span id='pid'>283, <a href='https://arxiv.org/pdf/2408.08208.pdf' target='_blank'>https://arxiv.org/pdf/2408.08208.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bohao Wang, Feng Liu, Changwang Zhang, Jiawei Chen, Yudi Wu, Sheng Zhou, Xingyu Lou, Jun Wang, Yan Feng, Chun Chen, Can Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08208">LLM4DSR: Leveraging Large Language Model for Denoising Sequential Recommendation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sequential Recommenders generate recommendations based on users' historical interaction sequences. However, in practice, these collected sequences are often contaminated by noisy interactions, which significantly impairs recommendation performance. Accurately identifying such noisy interactions without additional information is particularly challenging due to the absence of explicit supervisory signals indicating noise. Large Language Models (LLMs), equipped with extensive open knowledge and semantic reasoning abilities, offer a promising avenue to bridge this information gap. However, employing LLMs for denoising in sequential recommendation presents notable challenges: 1) Direct application of pretrained LLMs may not be competent for the denoising task, frequently generating nonsensical responses; 2) Even after fine-tuning, the reliability of LLM outputs remains questionable, especially given the complexity of the denoising task and the inherent hallucinatory issue of LLMs.
  To tackle these challenges, we propose LLM4DSR, a tailored approach for denoising sequential recommendation using LLMs. We constructed a self-supervised fine-tuning task to activate LLMs' capabilities to identify noisy items and suggest replacements. Furthermore, we developed an uncertainty estimation module that ensures only high-confidence responses are utilized for sequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing corrected sequences to be flexibly applied across various recommendation models. Extensive experiments validate the superiority of LLM4DSR over existing methods.
<div id='section'>Paperid: <span id='pid'>284, <a href='https://arxiv.org/pdf/2411.03359.pdf' target='_blank'>https://arxiv.org/pdf/2411.03359.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geng Yu, Jianing Zhu, Jiangchao Yao, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.03359">Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for deploying reliable machine learning models in open-world applications. Recent advances in CLIP-based OOD detection have shown promising results via regularizing prompt tuning with OOD features extracted from ID data. However, the irrelevant context mined from ID data can be spurious due to the inaccurate foreground-background decomposition, thus limiting the OOD detection performance. In this work, we propose a novel framework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem for effective OOD detection with only the given few-shot ID data. Specifically, SCT introduces modulating factors respectively on the two components of the original learning objective. It adaptively directs the optimization process between the two tasks during training on data with different prediction uncertainty to calibrate the influence of OOD regularization, which is compatible with many prompt tuning based OOD detection methods. Extensive experiments and analyses have been conducted to characterize and demonstrate the effectiveness of the proposed SCT. The code is publicly available.
<div id='section'>Paperid: <span id='pid'>285, <a href='https://arxiv.org/pdf/2407.05521.pdf' target='_blank'>https://arxiv.org/pdf/2407.05521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zehuan Zhang, Matej Genci, Hongxiang Fan, Andreas Wetscherek, Wayne Luk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.05521">Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and reliable Magnetic Resonance Imaging (MRI) analysis is particularly important for adaptive radiotherapy, a recent medical advance capable of improving cancer diagnosis and treatment. Recent studies have shown that IVIM-NET, a deep neural network (DNN), can achieve high accuracy in MRI analysis, indicating the potential of deep learning to enhance diagnostic capabilities in healthcare. However, IVIM-NET does not provide calibrated uncertainty information needed for reliable and trustworthy predictions in healthcare. Moreover, the expensive computation and memory demands of IVIM-NET reduce hardware performance, hindering widespread adoption in realistic scenarios. To address these challenges, this paper proposes an algorithm-hardware co-optimization flow for high-performance and reliable MRI analysis. At the algorithm level, a transformation design flow is introduced to convert IVIM-NET to a mask-based Bayesian Neural Network (BayesNN), facilitating reliable and efficient uncertainty estimation. At the hardware level, we propose an FPGA-based accelerator with several hardware optimizations, such as mask-zero skipping and operation reordering. Experimental results demonstrate that our co-design approach can satisfy the uncertainty requirements of MRI analysis, while achieving 7.5 times and 32.5 times speedup on an Xilinx VU13P FPGA compared to GPU and CPU implementations with reduced power consumption.
<div id='section'>Paperid: <span id='pid'>286, <a href='https://arxiv.org/pdf/2406.16198.pdf' target='_blank'>https://arxiv.org/pdf/2406.16198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zehuan Zhang, Hongxiang Fan, Hao Mark Chen, Lukasz Dudziak, Wayne Luk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16198">Hardware-Aware Neural Dropout Search for Reliable Uncertainty Prediction on FPGA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The increasing deployment of artificial intelligence (AI) for critical decision-making amplifies the necessity for trustworthy AI, where uncertainty estimation plays a pivotal role in ensuring trustworthiness. Dropout-based Bayesian Neural Networks (BayesNNs) are prominent in this field, offering reliable uncertainty estimates. Despite their effectiveness, existing dropout-based BayesNNs typically employ a uniform dropout design across different layers, leading to suboptimal performance. Moreover, as diverse applications require tailored dropout strategies for optimal performance, manually optimizing dropout configurations for various applications is both error-prone and labor-intensive. To address these challenges, this paper proposes a novel neural dropout search framework that automatically optimizes both the dropout-based BayesNNs and their hardware implementations on FPGA. We leverage one-shot supernet training with an evolutionary algorithm for efficient dropout optimization. A layer-wise dropout search space is introduced to enable the automatic design of dropout-based BayesNNs with heterogeneous dropout configurations. Extensive experiments demonstrate that our proposed framework can effectively find design configurations on the Pareto frontier. Compared to manually-designed dropout-based BayesNNs on GPU, our search approach produces FPGA designs that can achieve up to 33X higher energy efficiency. Compared to state-of-the-art FPGA designs of BayesNN, the solutions from our approach can achieve higher algorithmic performance and energy efficiency.
<div id='section'>Paperid: <span id='pid'>287, <a href='https://arxiv.org/pdf/2404.07770.pdf' target='_blank'>https://arxiv.org/pdf/2404.07770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufeng Yue, Meng Yu, Luojie Yang, Yi Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07770">Joint Conditional Diffusion Model for Image Restoration with Mixed Degradations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image restoration is rather challenging in adverse weather conditions, especially when multiple degradations occur simultaneously. Blind image decomposition was proposed to tackle this issue, however, its effectiveness heavily relies on the accurate estimation of each component. Although diffusion-based models exhibit strong generative abilities in image restoration tasks, they may generate irrelevant contents when the degraded images are severely corrupted. To address these issues, we leverage physical constraints to guide the whole restoration process, where a mixed degradation model based on atmosphere scattering model is constructed. Then we formulate our Joint Conditional Diffusion Model (JCDM) by incorporating the degraded image and degradation mask to provide precise guidance. To achieve better color and detail recovery results, we further integrate a refinement network to reconstruct the restored image, where Uncertainty Estimation Block (UEB) is employed to enhance the features. Extensive experiments performed on both multi-weather and weather-specific datasets demonstrate the superiority of our method over state-of-the-art competing methods.
<div id='section'>Paperid: <span id='pid'>288, <a href='https://arxiv.org/pdf/2503.00325.pdf' target='_blank'>https://arxiv.org/pdf/2503.00325.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Ling, Yachen Chang, Hailiang Zhao, Xinkui Zhao, Kingsum Chow, Shuiguang Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00325">CADRef: Robust Out-of-Distribution Detection via Class-Aware Decoupled Relative Feature Leveraging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) have been widely criticized for their overconfidence when dealing with out-of-distribution (OOD) samples, highlighting the critical need for effective OOD detection to ensure the safe deployment of DNNs in real-world settings. Existing post-hoc OOD detection methods primarily enhance the discriminative power of logit-based approaches by reshaping sample features, yet they often neglect critical information inherent in the features themselves. In this paper, we propose the Class-Aware Relative Feature-based method (CARef), which utilizes the error between a sample's feature and its class-aware average feature as a discriminative criterion. To further refine this approach, we introduce the Class-Aware Decoupled Relative Feature-based method (CADRef), which decouples sample features based on the alignment of signs between the relative feature and corresponding model weights, enhancing the discriminative capabilities of CARef. Extensive experimental results across multiple datasets and models demonstrate that both proposed methods exhibit effectiveness and robustness in OOD detection compared to state-of-the-art methods. Specifically, our two methods outperform the best baseline by 2.82% and 3.27% in AUROC, with improvements of 4.03% and 6.32% in FPR95, respectively.
<div id='section'>Paperid: <span id='pid'>289, <a href='https://arxiv.org/pdf/2408.15566.pdf' target='_blank'>https://arxiv.org/pdf/2408.15566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinglun Li, Xinyu Zhou, Kaixun Jiang, Lingyi Hong, Pinxue Guo, Zhaoyu Chen, Weifeng Ge, Wenqiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15566">TagOOD: A Novel Approach to Out-of-Distribution Detection via Vision-Language Representations and Class Center Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal fusion, leveraging data like vision and language, is rapidly gaining traction. This enriched data representation improves performance across various tasks. Existing methods for out-of-distribution (OOD) detection, a critical area where AI models encounter unseen data in real-world scenarios, rely heavily on whole-image features. These image-level features can include irrelevant information that hinders the detection of OOD samples, ultimately limiting overall performance. In this paper, we propose \textbf{TagOOD}, a novel approach for OOD detection that leverages vision-language representations to achieve label-free object feature decoupling from whole images. This decomposition enables a more focused analysis of object semantics, enhancing OOD detection performance. Subsequently, TagOOD trains a lightweight network on the extracted object features to learn representative class centers. These centers capture the central tendencies of IND object classes, minimizing the influence of irrelevant image features during OOD detection. Finally, our approach efficiently detects OOD samples by calculating distance-based metrics as OOD scores between learned centers and test samples. We conduct extensive experiments to evaluate TagOOD on several benchmark datasets and demonstrate its superior performance compared to existing OOD detection methods. This work presents a novel perspective for further exploration of multimodal information utilization in OOD detection, with potential applications across various tasks.
<div id='section'>Paperid: <span id='pid'>290, <a href='https://arxiv.org/pdf/2406.09262.pdf' target='_blank'>https://arxiv.org/pdf/2406.09262.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Spencer Young, Porter Jenkins, Longchao Da, Jeff Dotson, Hua Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09262">Fully Heteroscedastic Count Regression with Deep Double Poisson Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks capable of accurate, input-conditional uncertainty representation are essential for real-world AI systems. Deep ensembles of Gaussian networks have proven highly effective for continuous regression due to their ability to flexibly represent aleatoric uncertainty via unrestricted heteroscedastic variance, which in turn enables accurate epistemic uncertainty estimation. However, no analogous approach exists for count regression, despite many important applications. To address this gap, we propose the Deep Double Poisson Network (DDPN), a novel neural discrete count regression model that outputs the parameters of the Double Poisson distribution, enabling arbitrarily high or low predictive aleatoric uncertainty for count data and improving epistemic uncertainty estimation when ensembled. We formalize and prove that DDPN exhibits robust regression properties similar to heteroscedastic Gaussian models via learnable loss attenuation, and introduce a simple loss modification to control this behavior. Experiments on diverse datasets demonstrate that DDPN outperforms current baselines in accuracy, calibration, and out-of-distribution detection, establishing a new state-of-the-art in deep count regression.
<div id='section'>Paperid: <span id='pid'>291, <a href='https://arxiv.org/pdf/2405.17494.pdf' target='_blank'>https://arxiv.org/pdf/2405.17494.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryan Benkert, Mohit Prabhushankar, Ghassan AlRegib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17494">Transitional Uncertainty with Layered Intermediate Predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we discuss feature engineering for single-pass uncertainty estimation. For accurate uncertainty estimates, neural networks must extract differences in the feature space that quantify uncertainty. This could be achieved by current single-pass approaches that maintain feature distances between data points as they traverse the network. While initial results are promising, maintaining feature distances within the network representations frequently inhibits information compression and opposes the learning objective. We study this effect theoretically and empirically to arrive at a simple conclusion: preserving feature distances in the output is beneficial when the preserved features contribute to learning the label distribution and act in opposition otherwise. We then propose Transitional Uncertainty with Layered Intermediate Predictions (TULIP) as a simple approach to address the shortcomings of current single-pass estimators. Specifically, we implement feature preservation by extracting features from intermediate representations before information is collapsed by subsequent layers. We refer to the underlying preservation mechanism as transitional feature preservation. We show that TULIP matches or outperforms current single-pass methods on standard benchmarks and in practical settings where these methods are less reliable (imbalances, complex architectures, medical modalities).
<div id='section'>Paperid: <span id='pid'>292, <a href='https://arxiv.org/pdf/2403.10190.pdf' target='_blank'>https://arxiv.org/pdf/2403.10190.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Zhou, Mohit Prabhushankar, Ghassan AlRegib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10190">Perceptual Quality-based Model Training under Annotator Label Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Annotators exhibit disagreement during data labeling, which can be termed as annotator label uncertainty. Annotator label uncertainty manifests in variations of labeling quality. Training with a single low-quality annotation per sample induces model reliability degradations. In this work, we first examine the effects of annotator label uncertainty in terms of the model's generalizability and prediction uncertainty. We observe that the model's generalizability and prediction uncertainty degrade with the presence of low-quality noisy labels. Meanwhile, our evaluation of existing uncertainty estimation algorithms indicates their incapability in response to annotator label uncertainty. To mitigate performance degradation, prior methods show that training models with labels collected from multiple independent annotators can enhance generalizability. However, they require massive annotations. Hence, we introduce a novel perceptual quality-based model training framework to objectively generate multiple labels for model training to enhance reliability, while avoiding massive annotations. Specifically, we first select a subset of samples with low perceptual quality scores ranked by statistical regularities of visual signals. We then assign de-aggregated labels to each sample in this subset to obtain a training set with multiple labels. Our experiments and analysis demonstrate that training with the proposed framework alleviates the degradation of generalizability and prediction uncertainty caused by annotator label uncertainty.
<div id='section'>Paperid: <span id='pid'>293, <a href='https://arxiv.org/pdf/2509.11301.pdf' target='_blank'>https://arxiv.org/pdf/2509.11301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthias WÃ¼est, Francis Engelmann, Ondrej Miksik, Marc Pollefeys, Daniel Barath
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11301">UnLoc: Leveraging Depth Uncertainties for Floorplan Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose UnLoc, an efficient data-driven solution for sequential camera localization within floorplans. Floorplan data is readily available, long-term persistent, and robust to changes in visual appearance. We address key limitations of recent methods, such as the lack of uncertainty modeling in depth predictions and the necessity for custom depth networks trained for each environment. We introduce a novel probabilistic model that incorporates uncertainty estimation, modeling depth predictions as explicit probability distributions. By leveraging off-the-shelf pre-trained monocular depth models, we eliminate the need to rely on per-environment-trained depth networks, enhancing generalization to unseen spaces. We evaluate UnLoc on large-scale synthetic and real-world datasets, demonstrating significant improvements over existing methods in terms of accuracy and robustness. Notably, we achieve $2.7$ times higher localization recall on long sequences (100 frames) and $16.7$ times higher on short ones (15 frames) than the state of the art on the challenging LaMAR HGE dataset.
<div id='section'>Paperid: <span id='pid'>294, <a href='https://arxiv.org/pdf/2505.05903.pdf' target='_blank'>https://arxiv.org/pdf/2505.05903.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Umberto Albertin, Mauro Martini, Alessandro Navone, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.05903">Adaptive Robot Localization with Ultra-wideband Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultra-wideband (UWB) technology has shown remarkable potential as a low-cost general solution for robot localization. However, limitations of the UWB signal for precise positioning arise from the disturbances caused by the environment itself, due to reflectance, multi-path effect, and Non-Line-of-Sight (NLOS) conditions. This problem is emphasized in cluttered indoor spaces where service robotic platforms usually operate. Both model-based and learning-based methods are currently under investigation to precisely predict the UWB error patterns. Despite the great capability in approximating strong non-linearity, learning-based methods often do not consider environmental factors and require data collection and re-training for unseen data distributions, making them not practically feasible on a large scale. The goal of this research is to develop a robust and adaptive UWB localization method for indoor confined spaces. A novelty detection technique is used to recognize outlier conditions from nominal UWB range data with a semi-supervised autoencoder. Then, the obtained novelty scores are combined with an Extended Kalman filter, leveraging a dynamic estimation of covariance and bias error for each range measurement received from the UWB anchors. The resulting solution is a compact, flexible, and robust system which enables the localization system to adapt the trustworthiness of UWB data spatially and temporally in the environment. The extensive experimentation conducted with a real robot in a wide range of testing scenarios demonstrates the advantages and benefits of the proposed solution in indoor cluttered spaces presenting NLoS conditions, reaching an average improvement of almost 60% and greater than 25cm of absolute positioning error.
<div id='section'>Paperid: <span id='pid'>295, <a href='https://arxiv.org/pdf/2503.12600.pdf' target='_blank'>https://arxiv.org/pdf/2503.12600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Feng, Yihang Sun, Jiaxuan You
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.12600">GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The powerful capabilities of Large Language Models (LLMs) have led to their growing use in evaluating human-generated content, particularly in evaluating research ideas within academic settings. Existing solutions primarily rely on prompt-based LLM methods or fine-tuned lightweight language models for idea evaluation. However, these methods are often unstable and struggle to comprehend the complex semantic information embedded in the ideas, impeding their ability to perform high-quality evaluations. To address the above challenges, we propose GraphEval, a lightweight graph-based LLM framework for idea evaluation. Our insight is that a complex idea can be broken down into comprehensible viewpoint nodes using prompts from small LLMs. These viewpoint nodes can then be linked together through edges created from LLM-based relation extraction and/or BERT similarity scores. The created viewpoint-graph can be used to conveniently propagate scores across view-nodes to improve the robustness of the idea evaluations. In particular, we propose two lightweight graph-based methods for idea evaluation: (1) GraphEval-LP: a training-free label propagation algorithm that propagates evaluation scores from known view-nodes to unknown nodes; (2) GraphEval-GNN: a Graph Neural Networks (GNN) that is trained to predict the evaluation scores given the observed graph with minimal computation resources. Moreover, to overcome LLM's limitation in objectively assessing the novelty of ideas, we further propose a novelty detection model to GraphEval-GNN to enhance its capability in judging idea novelty. Experiments on two datasets show GraphEval improves F1 scores by at least 14% with low computation and API costs. Additionally, GraphEval can effectively detect plagiarized ideas.
<div id='section'>Paperid: <span id='pid'>296, <a href='https://arxiv.org/pdf/2409.07135.pdf' target='_blank'>https://arxiv.org/pdf/2409.07135.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ariel Priarone, Umberto Albertin, Carlo Cena, Mauro Martini, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07135">Unsupervised Novelty Detection Methods Benchmarking with Wavelet Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty detection is a critical task in various engineering fields. Numerous approaches to novelty detection rely on supervised or semi-supervised learning, which requires labelled datasets for training. However, acquiring labelled data, when feasible, can be expensive and time-consuming. For these reasons, unsupervised learning is a powerful alternative that allows performing novelty detection without needing labelled samples. In this study, numerous unsupervised machine learning algorithms for novelty detection are compared, highlighting their strengths and weaknesses in the context of vibration sensing. The proposed framework uses a continuous metric, unlike most traditional methods that merely flag anomalous samples without quantifying the degree of anomaly. Moreover, a new dataset is gathered from an actuator vibrating at specific frequencies to benchmark the algorithms and evaluate the framework. Novel conditions are introduced by altering the input wave signal. Our findings offer valuable insights into the adaptability and robustness of unsupervised learning techniques for real-world novelty detection applications.
<div id='section'>Paperid: <span id='pid'>297, <a href='https://arxiv.org/pdf/2404.05351.pdf' target='_blank'>https://arxiv.org/pdf/2404.05351.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Umberto Albertin, Alessandro Navone, Mauro Martini, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.05351">Semi-Supervised Novelty Detection for Precise Ultra-Wideband Error Signal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultra-Wideband (UWB) technology is an emerging low-cost solution for localization in a generic environment. However, UWB signal can be affected by signal reflections and non-line-of-sight (NLoS) conditions between anchors; hence, in a broader sense, the specific geometry of the environment and the disposition of obstructing elements in the map may drastically hinder the reliability of UWB for precise robot localization. This work aims to mitigate this problem by learning a map-specific characterization of the UWB quality signal with a fingerprint semi-supervised novelty detection methodology. An unsupervised autoencoder neural network is trained on nominal UWB map conditions, and then it is used to predict errors derived from the introduction of perturbing novelties in the environment. This work poses a step change in the understanding of UWB localization and its reliability in evolving environmental conditions. The resulting performance of the proposed method is proved by fine-grained experiments obtained with a visual tracking ground truth.
<div id='section'>Paperid: <span id='pid'>298, <a href='https://arxiv.org/pdf/2509.24202.pdf' target='_blank'>https://arxiv.org/pdf/2509.24202.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linwei Tao, Yi-Fan Yeh, Bo Kai, Minjing Dong, Tao Huang, Tom A. Lamb, Jialin Yu, Philip H. S. Torr, Chang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24202">Can Large Language Models Express Uncertainty Like Human?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) are increasingly used in high-stakes settings, where overconfident responses can mislead users. Reliable confidence estimation has been shown to enhance trust and task accuracy. Yet existing methods face practical barriers: logits are often hidden, multi-sampling is computationally expensive, and verbalized numerical uncertainty (e.g., giving a 0-100 score) deviates from natural communication. We revisit linguistic confidence (LC), where models express uncertainty through hedging language (e.g., probably, might), offering a lightweight and human-centered alternative. To advance this direction, we (1) release the first diverse, large-scale dataset of hedging expressions with human-annotated confidence scores, and (2) propose a lightweight mapper that converts hedges into confidence scores at near-zero cost. Building on these resources, we (3) conduct the first systematic study of LC across modern LLMs and QA benchmarks, revealing that while most LLMs underperform in expressing reliable LC, carefully designed prompting achieves competitive calibration and discriminability. Finally, we (4) introduce a fine-tuning framework that further improves LC reliability. Taken together, our work positions linguistic confidence as a scalable, efficient, and human-aligned approach to LLM uncertainty estimation, and calls for deeper exploration of this promising yet underexplored direction.
<div id='section'>Paperid: <span id='pid'>299, <a href='https://arxiv.org/pdf/2507.13835.pdf' target='_blank'>https://arxiv.org/pdf/2507.13835.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin V. Vejling, Shashi Raj Pandey, Christophe A. N. Biscio, Petar Popovski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13835">Conformal Data Contamination Tests for Trading or Sharing of Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The amount of quality data in many machine learning tasks is limited to what is available locally to data owners. The set of quality data can be expanded through trading or sharing with external data agents. However, data buyers need quality guarantees before purchasing, as external data may be contaminated or irrelevant to their specific learning task. Previous works primarily rely on distributional assumptions about data from different agents, relegating quality checks to post-hoc steps involving costly data valuation procedures. We propose a distribution-free, contamination-aware data-sharing framework that identifies external data agents whose data is most valuable for model personalization. To achieve this, we introduce novel two-sample testing procedures, grounded in rigorous theoretical foundations for conformal outlier detection, to determine whether an agent's data exceeds a contamination threshold. The proposed tests, termed conformal data contamination tests, remain valid under arbitrary contamination levels while enabling false discovery rate control via the Benjamini-Hochberg procedure. Empirical evaluations across diverse collaborative learning scenarios demonstrate the robustness and effectiveness of our approach. Overall, the conformal data contamination test distinguishes itself as a generic procedure for aggregating data with statistically rigorous quality guarantees.
<div id='section'>Paperid: <span id='pid'>300, <a href='https://arxiv.org/pdf/2505.23854.pdf' target='_blank'>https://arxiv.org/pdf/2505.23854.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linwei Tao, Yi-Fan Yeh, Minjing Dong, Tao Huang, Philip Torr, Chang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23854">Revisiting Uncertainty Estimation and Calibration of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As large language models (LLMs) are increasingly deployed in high-stakes applications, robust uncertainty estimation is essential for ensuring the safe and trustworthy deployment of LLMs. We present the most comprehensive study to date of uncertainty estimation in LLMs, evaluating 80 models spanning open- and closed-source families, dense and Mixture-of-Experts (MoE) architectures, reasoning and non-reasoning modes, quantization variants and parameter scales from 0.6B to 671B. Focusing on three representative black-box single-pass methods, including token probability-based uncertainty (TPU), numerical verbal uncertainty (NVU), and linguistic verbal uncertainty (LVU), we systematically evaluate uncertainty calibration and selective classification using the challenging MMLU-Pro benchmark, which covers both reasoning-intensive and knowledge-based tasks. Our results show that LVU consistently outperforms TPU and NVU, offering stronger calibration and discrimination while being more interpretable. We also find that high accuracy does not imply reliable uncertainty, and that model scale, post-training, reasoning ability and quantization all influence estimation performance. Notably, LLMs exhibit better uncertainty estimates on reasoning tasks than on knowledge-heavy ones, and good calibration does not necessarily translate to effective error ranking. These findings highlight the need for multi-perspective evaluation and position LVU as a practical tool for improving the reliability of LLMs in real-world settings.
<div id='section'>Paperid: <span id='pid'>301, <a href='https://arxiv.org/pdf/2503.22725.pdf' target='_blank'>https://arxiv.org/pdf/2503.22725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinxu Lin, Linwei Tao, Minjing Dong, Chang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22725">Uncertainty Weighted Gradients for Model Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model calibration is essential for ensuring that the predictions of deep neural networks accurately reflect true probabilities in real-world classification tasks. However, deep networks often produce over-confident or under-confident predictions, leading to miscalibration. Various methods have been proposed to address this issue by designing effective loss functions for calibration, such as focal loss. In this paper, we analyze its effectiveness and provide a unified loss framework of focal loss and its variants, where we mainly attribute their superiority in model calibration to the loss weighting factor that estimates sample-wise uncertainty. Based on our analysis, existing loss functions fail to achieve optimal calibration performance due to two main issues: including misalignment during optimization and insufficient precision in uncertainty estimation. Specifically, focal loss cannot align sample uncertainty with gradient scaling and the single logit cannot indicate the uncertainty. To address these issues, we reformulate the optimization from the perspective of gradients, which focuses on uncertain samples. Meanwhile, we propose using the Brier Score as the loss weight factor, which provides a more accurate uncertainty estimation via all the logits. Extensive experiments on various models and datasets demonstrate that our method achieves state-of-the-art (SOTA) performance.
<div id='section'>Paperid: <span id='pid'>302, <a href='https://arxiv.org/pdf/2410.12295.pdf' target='_blank'>https://arxiv.org/pdf/2410.12295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linwei Tao, Haolan Guo, Minjing Dong, Chang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12295">Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Calibration is crucial in deep learning applications, especially in fields like healthcare and autonomous driving, where accurate confidence estimates are vital for decision-making. However, deep neural networks often suffer from miscalibration, with reliability diagrams and Expected Calibration Error (ECE) being the only standard perspective for evaluating calibration performance. In this paper, we introduce the concept of consistency as an alternative perspective on model calibration, inspired by uncertainty estimation literature in large language models (LLMs). We highlight its advantages over the traditional reliability-based view. Building on this concept, we propose a post-hoc calibration method called Consistency Calibration (CC), which adjusts confidence based on the model's consistency across perturbed inputs. CC is particularly effective in locally uncertainty estimation, as it requires no additional data samples or label information, instead generating input perturbations directly from the source data. Moreover, we show that performing perturbations at the logit level significantly improves computational efficiency. We validate the effectiveness of CC through extensive comparisons with various post-hoc and training-time calibration methods, demonstrating state-of-the-art performance on standard datasets such as CIFAR-10, CIFAR-100, and ImageNet, as well as on long-tailed datasets like ImageNet-LT.
<div id='section'>Paperid: <span id='pid'>303, <a href='https://arxiv.org/pdf/2509.18954.pdf' target='_blank'>https://arxiv.org/pdf/2509.18954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minoo Dolatabadi, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18954">Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based localization and SLAM often rely on iterative matching algorithms, particularly the Iterative Closest Point (ICP) algorithm, to align sensor data with pre-existing maps or previous scans. However, ICP is prone to errors in featureless environments and dynamic scenes, leading to inaccurate pose estimation. Accurately predicting the uncertainty associated with ICP is crucial for robust state estimation but remains challenging, as existing approaches often rely on handcrafted models or simplified assumptions. Moreover, a few deep learning-based methods for localizability estimation either depend on a pre-built map, which may not always be available, or provide a binary classification of localizable versus non-localizable, which fails to properly model uncertainty. In this work, we propose a data-driven framework that leverages deep learning to estimate the registration error covariance of ICP before matching, even in the absence of a reference map. By associating each LiDAR scan with a reliable 6-DoF error covariance estimate, our method enables seamless integration of ICP within Kalman filtering, enhancing localization accuracy and robustness. Extensive experiments on the KITTI dataset demonstrate the effectiveness of our approach, showing that it accurately predicts covariance and, when applied to localization using a pre-built map or SLAM, reduces localization errors and improves robustness.
<div id='section'>Paperid: <span id='pid'>304, <a href='https://arxiv.org/pdf/2509.10951.pdf' target='_blank'>https://arxiv.org/pdf/2509.10951.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Wilkinghoff, Haici Yang, Janek Ebbers, FranÃ§ois G. Germain, Gordon Wichern, Jonathan Le Roux
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10951">Local Density-Based Anomaly Score Normalization for Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State-of-the-art anomalous sound detection (ASD) systems in domain-shifted conditions rely on projecting audio signals into an embedding space and using distance-based outlier detection to compute anomaly scores. One of the major difficulties to overcome is the so-called domain mismatch between the anomaly score distributions of a source domain and a target domain that differ acoustically and in terms of the amount of training data provided. A decision threshold that is optimal for one domain may be highly sub-optimal for the other domain and vice versa. This significantly degrades the performance when only using a single decision threshold, as is required when generalizing to multiple data domains that are possibly unseen during training while still using the same trained ASD system as in the source domain. To reduce this mismatch between the domains, we propose a simple local-density-based anomaly score normalization scheme. In experiments conducted on several ASD datasets, we show that the proposed normalization scheme consistently improves performance for various types of embedding-based ASD systems and yields better results than existing anomaly score normalization approaches.
<div id='section'>Paperid: <span id='pid'>305, <a href='https://arxiv.org/pdf/2503.05245.pdf' target='_blank'>https://arxiv.org/pdf/2503.05245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Johanna P. MÃ¼ller, Robert Wright, Thomas G. Day, Lorenzo Venturini, Samuel F. Budd, Hadrien Reynaud, Joseph V. Hajnal, Reza Razavi, Bernhard Kainz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05245">L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate analysis of prenatal ultrasound (US) is essential for early detection of developmental anomalies. However, operator dependency and technical limitations (e.g. intrinsic artefacts and effects, setting errors) can complicate image interpretation and the assessment of diagnostic uncertainty. We present L-FUSION (Laplacian Fetal US Segmentation with Integrated FoundatiON models), a framework that integrates uncertainty quantification through unsupervised, normative learning and large-scale foundation models for robust segmentation of fetal structures in normal and pathological scans. We propose to utilise the aleatoric logit distributions of Stochastic Segmentation Networks and Laplace approximations with fast Hessian estimations to estimate epistemic uncertainty only from the segmentation head. This enables us to achieve reliable abnormality quantification for instant diagnostic feedback. Combined with an integrated Dropout component, L-FUSION enables reliable differentiation of lesions from normal fetal anatomy with enhanced uncertainty maps and segmentation counterfactuals in US imaging. It improves epistemic and aleatoric uncertainty interpretation and removes the need for manual disease-labelling. Evaluations across multiple datasets show that L-FUSION achieves superior segmentation accuracy and consistent uncertainty quantification, supporting on-site decision-making and offering a scalable solution for advancing fetal ultrasound analysis in clinical settings.
<div id='section'>Paperid: <span id='pid'>306, <a href='https://arxiv.org/pdf/2406.01975.pdf' target='_blank'>https://arxiv.org/pdf/2406.01975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Fu, Tunhou Zhang, Hai Li, Yiran Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01975">Can Dense Connectivity Benefit Outlier Detection? An Odyssey with NAS</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Out-of-Distribution (OOD) Detection is the driving force behind safe and reliable deployment of Convolutional Neural Networks (CNNs) in real world applications. However, existing studies focus on OOD detection through confidence score and deep generative model-based methods, without considering the impact of DNN structures, especially dense connectivity in architecture fabrications. In addition, existing outlier detection approaches exhibit high variance in generalization performance, lacking stability and confidence in evaluating and ranking different outlier detectors. In this work, we propose a novel paradigm, Dense Connectivity Search of Outlier Detector (DCSOD), that automatically explore the dense connectivity of CNN architectures on near-OOD detection task using Neural Architecture Search (NAS). We introduce a hierarchical search space containing versatile convolution operators and dense connectivity, allowing a flexible exploration of CNN architectures with diverse connectivity patterns. To improve the quality of evaluation on OOD detection during search, we propose evolving distillation based on our multi-view feature learning explanation. Evolving distillation stabilizes training for OOD detection evaluation, thus improves the quality of search. We thoroughly examine DCSOD on CIFAR benchmarks under OOD detection protocol. Experimental results show that DCSOD achieve remarkable performance over widely used architectures and previous NAS baselines. Notably, DCSOD achieves state-of-the-art (SOTA) performance on CIFAR benchmark, with AUROC improvement of $\sim$1.0%.
<div id='section'>Paperid: <span id='pid'>307, <a href='https://arxiv.org/pdf/2401.08689.pdf' target='_blank'>https://arxiv.org/pdf/2401.08689.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingqiu Zhou, Aojun Zhou, Hongsheng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08689">NODI: Out-Of-Distribution Detection with Noise from Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a crucial part of deploying machine learning models safely. It has been extensively studied with a plethora of methods developed in the literature. This problem is tackled with an OOD score computation, however, previous methods compute the OOD scores with limited usage of the in-distribution dataset. For instance, the OOD scores are computed with information from a small portion of the in-distribution data. Furthermore, these methods encode images with a neural image encoder. The robustness of these methods is rarely checked with respect to image encoders of different training methods and architectures. In this work, we introduce the diffusion process into the OOD task. The diffusion model integrates information on the whole training set into the predicted noise vectors. What's more, we deduce a closed-form solution for the noise vector (stable point). Then the noise vector is converted into our OOD score, we test both the deep model predicted noise vector and the closed-form noise vector on the OOD benchmarks \cite{openood}. Our method outperforms previous OOD methods across all types of image encoders (Table. \ref{main}). A $3.5\%$ performance gain is achieved with the MAE-based image encoder. Moreover, we studied the robustness of OOD methods by applying different types of image encoders. Some OOD methods failed to generalize well when switching image encoders from ResNet to Vision Transformers, our method performs exhibits good robustness with all the image encoders.
<div id='section'>Paperid: <span id='pid'>308, <a href='https://arxiv.org/pdf/2512.00229.pdf' target='_blank'>https://arxiv.org/pdf/2512.00229.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pirzada Suhail, Rehna Afroz, Amit Sethi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.00229">TIE: A Training-Inversion-Exclusion Framework for Visually Interpretable and Uncertainty-Guided Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks often struggle to recognize when an input lies outside their training experience, leading to unreliable and overconfident predictions. Building dependable machine learning systems therefore requires methods that can both estimate predictive \textit{uncertainty} and detect \textit{out-of-distribution (OOD)} samples in a unified manner. In this paper, we propose \textbf{TIE: a Training--Inversion--Exclusion} framework for visually interpretable and uncertainty-guided anomaly detection that jointly addresses these challenges through iterative refinement. TIE extends a standard $n$-class classifier to an $(n+1)$-class model by introducing a garbage class initialized with Gaussian noise to represent outlier inputs. Within each epoch, TIE performs a closed-loop process of \textit{training, inversion, and exclusion}, where highly uncertain inverted samples reconstructed from the just-trained classifier are excluded into the garbage class. Over successive iterations, the inverted samples transition from noisy artifacts into visually coherent class prototypes, providing transparent insight into how the model organizes its learned manifolds. During inference, TIE rejects OOD inputs by either directly mapping them to the garbage class or producing low-confidence, uncertain misclassifications within the in-distribution classes that are easily separable, all without relying on external OOD datasets. A comprehensive threshold-based evaluation using multiple OOD metrics and performance measures such as \textit{AUROC}, \textit{AUPR}, and \textit{FPR@95\%TPR} demonstrates that TIE offers a unified and interpretable framework for robust anomaly detection and calibrated uncertainty estimation (UE) achieving near-perfect OOD detection with \textbf{\(\!\approx\!\) 0 FPR@95\%TPR} when trained on MNIST or FashionMNIST and tested against diverse unseen datasets.
<div id='section'>Paperid: <span id='pid'>309, <a href='https://arxiv.org/pdf/2505.23448.pdf' target='_blank'>https://arxiv.org/pdf/2505.23448.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pirzada Suhail, Rehna Afroz, Amit Sethi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23448">Network Inversion for Uncertainty-Aware Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection and uncertainty estimation (UE) are critical components for building safe machine learning systems, especially in real-world scenarios where unexpected inputs are inevitable. In this work, we propose a novel framework that combines network inversion with classifier training to simultaneously address both OOD detection and uncertainty estimation. For a standard n-class classification task, we extend the classifier to an (n+1)-class model by introducing a "garbage" class, initially populated with random gaussian noise to represent outlier inputs. After each training epoch, we use network inversion to reconstruct input images corresponding to all output classes that initially appear as noisy and incoherent and are therefore excluded to the garbage class for retraining the classifier. This cycle of training, inversion, and exclusion continues iteratively till the inverted samples begin to resemble the in-distribution data more closely, suggesting that the classifier has learned to carve out meaningful decision boundaries while sanitising the class manifolds by pushing OOD content into the garbage class. During inference, this training scheme enables the model to effectively detect and reject OOD samples by classifying them into the garbage class. Furthermore, the confidence scores associated with each prediction can be used to estimate uncertainty for both in-distribution and OOD inputs. Our approach is scalable, interpretable, and does not require access to external OOD datasets or post-hoc calibration techniques while providing a unified solution to the dual challenges of OOD detection and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>310, <a href='https://arxiv.org/pdf/2504.01849.pdf' target='_blank'>https://arxiv.org/pdf/2504.01849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohin Shah, Alex Irpan, Alexander Matt Turner, Anna Wang, Arthur Conmy, David Lindner, Jonah Brown-Cohen, Lewis Ho, Neel Nanda, Raluca Ada Popa, Rishub Jain, Rory Greig, Samuel Albanie, Scott Emmons, Sebastian Farquhar, SÃ©bastien Krier, Senthooran Rajamanoharan, Sophie Bridgers, Tobi Ijitoye, Tom Everitt, Victoria Krakovna, Vikrant Varma, Vladimir Mikulik, Zachary Kenton, Dave Orr, Shane Legg, Noah Goodman, Allan Dafoe, Four Flynn, Anca Dragan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01849">An Approach to Technical AGI Safety and Security</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial General Intelligence (AGI) promises transformative benefits but also presents significant risks. We develop an approach to address the risk of harms consequential enough to significantly harm humanity. We identify four areas of risk: misuse, misalignment, mistakes, and structural risks. Of these, we focus on technical approaches to misuse and misalignment. For misuse, our strategy aims to prevent threat actors from accessing dangerous capabilities, by proactively identifying dangerous capabilities, and implementing robust security, access restrictions, monitoring, and model safety mitigations. To address misalignment, we outline two lines of defense. First, model-level mitigations such as amplified oversight and robust training can help to build an aligned model. Second, system-level security measures such as monitoring and access control can mitigate harm even if the model is misaligned. Techniques from interpretability, uncertainty estimation, and safer design patterns can enhance the effectiveness of these mitigations. Finally, we briefly outline how these ingredients could be combined to produce safety cases for AGI systems.
<div id='section'>Paperid: <span id='pid'>311, <a href='https://arxiv.org/pdf/2503.20187.pdf' target='_blank'>https://arxiv.org/pdf/2503.20187.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pirzada Suhail, Pravesh Khaparde, Amit Sethi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20187">Network Inversion for Generating Confidently Classified Counterfeits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In vision classification, generating inputs that elicit confident predictions is key to understanding model behavior and reliability, especially under adversarial or out-of-distribution (OOD) conditions. While traditional adversarial methods rely on perturbing existing inputs to fool a model, they are inherently input-dependent and often fail to ensure both high confidence and meaningful deviation from the training data. In this work, we extend network inversion techniques to generate Confidently Classified Counterfeits (CCCs), synthetic samples that are confidently classified by the model despite being significantly different from the training distribution and independent of any specific input. We alter inversion technique by replacing soft vector conditioning with one-hot class conditioning and introducing a Kullback-Leibler divergence loss between the one-hot label and the classifier's output distribution. CCCs offer a model-centric perspective on confidence, revealing that models can assign high confidence to entirely synthetic, out-of-distribution inputs. This challenges the core assumption behind many OOD detection techniques based on thresholding prediction confidence, which assume that high-confidence outputs imply in-distribution data, and highlights the need for more robust uncertainty estimation in safety-critical applications.
<div id='section'>Paperid: <span id='pid'>312, <a href='https://arxiv.org/pdf/2411.17777.pdf' target='_blank'>https://arxiv.org/pdf/2411.17777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pirzada Suhail, Hao Tang, Amit Sethi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17777">Network Inversion and Its Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks have emerged as powerful tools across various applications, yet their decision-making process often remains opaque, leading to them being perceived as "black boxes." This opacity raises concerns about their interpretability and reliability, especially in safety-critical scenarios. Network inversion techniques offer a solution by allowing us to peek inside these black boxes, revealing the features and patterns learned by the networks behind their decision-making processes and thereby provide valuable insights into how neural networks arrive at their conclusions, making them more interpretable and trustworthy. This paper presents a simple yet effective approach to network inversion using a meticulously conditioned generator that learns the data distribution in the input space of the trained neural network, enabling the reconstruction of inputs that would most likely lead to the desired outputs. To capture the diversity in the input space for a given output, instead of simply revealing the conditioning labels to the generator, we encode the conditioning label information into vectors and intermediate matrices and further minimize the cosine similarity between features of the generated images. Additionally, we incorporate feature orthogonality as a regularization term to boost image diversity which penalises the deviations of the Gram matrix of the features from the identity matrix, ensuring orthogonality and promoting distinct, non-redundant representations for each label. The paper concludes by exploring immediate applications of the proposed network inversion approach in interpretability, out-of-distribution detection, and training data reconstruction.
<div id='section'>Paperid: <span id='pid'>313, <a href='https://arxiv.org/pdf/2409.17286.pdf' target='_blank'>https://arxiv.org/pdf/2409.17286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael E. Kim, Chenyu Gao, Karthik Ramadass, Praitayini Kanakaraj, Nancy R. Newlin, Gaurav Rudravaram, Kurt G. Schilling, Blake E. Dewey, David A. Bennett, Sid OBryant, Robert C. Barber, Derek Archer, Timothy J. Hohman, Shunxing Bao, Zhiyuan Li, Bennett A. Landman, Nazirah Mohd Khairi, The Alzheimers Disease Neuroimaging Initiative, The HABSHD Study Team
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17286">Scalable quality control on processing of large diffusion-weighted and structural magnetic resonance imaging datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proper quality control (QC) is time consuming when working with large-scale medical imaging datasets, yet necessary, as poor-quality data can lead to erroneous conclusions or poorly trained machine learning models. Most efforts to reduce data QC time rely on outlier detection, which cannot capture every instance of algorithm failure. Thus, there is a need to visually inspect every output of data processing pipelines in a scalable manner. We design a QC pipeline that allows for low time cost and effort across a team setting for a large database of diffusion weighted and structural magnetic resonance images. Our proposed method satisfies the following design criteria: 1.) a consistent way to perform and manage quality control across a team of researchers, 2.) quick visualization of preprocessed data that minimizes the effort and time spent on the QC process without compromising the condition or caliber of the QC, and 3.) a way to aggregate QC results across pipelines and datasets that can be easily shared. In addition to meeting these design criteria, we also provide information on what a successful output should be and common occurrences of algorithm failures for various processing pipelines. Our method reduces the time spent on QC by a factor of over 20 when compared to naively opening outputs in an image viewer and demonstrate how it can facilitate aggregation and sharing of QC results within a team. While researchers must spend time on robust visual QC of data, there are mechanisms by which the process can be streamlined and efficient.
<div id='section'>Paperid: <span id='pid'>314, <a href='https://arxiv.org/pdf/2404.04971.pdf' target='_blank'>https://arxiv.org/pdf/2404.04971.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianghao Wu, Dong Guo, Guotai Wang, Qiang Yue, Huijun Yu, Kang Li, Shaoting Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04971">FPL+: Filtered Pseudo Label-based Unsupervised Cross-Modality Adaptation for 3D Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adapting a medical image segmentation model to a new domain is important for improving its cross-domain transferability, and due to the expensive annotation process, Unsupervised Domain Adaptation (UDA) is appealing where only unlabeled images are needed for the adaptation. Existing UDA methods are mainly based on image or feature alignment with adversarial training for regularization, and they are limited by insufficient supervision in the target domain. In this paper, we propose an enhanced Filtered Pseudo Label (FPL+)-based UDA method for 3D medical image segmentation. It first uses cross-domain data augmentation to translate labeled images in the source domain to a dual-domain training set consisting of a pseudo source-domain set and a pseudo target-domain set. To leverage the dual-domain augmented images to train a pseudo label generator, domain-specific batch normalization layers are used to deal with the domain shift while learning the domain-invariant structure features, generating high-quality pseudo labels for target-domain images. We then combine labeled source-domain images and target-domain images with pseudo labels to train a final segmentor, where image-level weighting based on uncertainty estimation and pixel-level weighting based on dual-domain consensus are proposed to mitigate the adverse effect of noisy pseudo labels. Experiments on three public multi-modal datasets for Vestibular Schwannoma, brain tumor and whole heart segmentation show that our method surpassed ten state-of-the-art UDA methods, and it even achieved better results than fully supervised learning in the target domain in some cases.
<div id='section'>Paperid: <span id='pid'>315, <a href='https://arxiv.org/pdf/2402.14259.pdf' target='_blank'>https://arxiv.org/pdf/2402.14259.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyuan Wang, Jinhao Duan, Chenxi Yuan, Qingyu Chen, Tianlong Chen, Yue Zhang, Ren Wang, Xiaoshuang Shi, Kaidi Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14259">Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial for the reliability of safety-critical human and artificial intelligence (AI) interaction systems, particularly in the domain of healthcare engineering. However, a robust and general uncertainty measure for free-form answers has not been well-established in open-ended medical question-answering (QA) tasks, where generative inequality introduces a large number of irrelevant words and sequences within the generated set for uncertainty quantification (UQ), which can lead to biases. This paper introduces Word-Sequence Entropy (WSE), a method that calibrates uncertainty at both the word and sequence levels, considering semantic relevance. WSE quantifies uncertainty in a way that is more closely aligned with the reliability of LLMs during uncertainty quantification (UQ). We compare WSE with six baseline methods on five free-form medical QA datasets, utilizing seven popular large language models (LLMs). Experimental results demonstrate that WSE exhibits superior performance in UQ under two standard criteria for correctness evaluation. Additionally, in terms of real-world medical QA applications, the performance of LLMs is significantly enhanced (e.g., a 6.36% improvement in model accuracy on the COVID-QA dataset) by employing responses with lower uncertainty that are identified by WSE as final answers, without any additional task-specific fine-tuning or architectural modifications.
<div id='section'>Paperid: <span id='pid'>316, <a href='https://arxiv.org/pdf/2509.20193.pdf' target='_blank'>https://arxiv.org/pdf/2509.20193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fahmida Islam, Adnan Mahmood, Noorain Mukhtiar, Kasun Eranda Wijethilake, Quan Z. Sheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20193">FairEquityFL -- A Fair and Equitable Client Selection in Federated Learning for Heterogeneous IoV Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated Learning (FL) has been extensively employed for a number of applications in machine learning, i.e., primarily owing to its privacy preserving nature and efficiency in mitigating the communication overhead. Internet of Vehicles (IoV) is one of the promising applications, wherein FL can be utilized to train a model more efficiently. Since only a subset of the clients can participate in each FL training round, challenges arise pertinent to fairness in the client selection process. Over the years, a number of researchers from both academia and industry have proposed numerous FL frameworks. However, to the best of our knowledge, none of them have employed fairness for FL-based client selection in a dynamic and heterogeneous IoV environment. Accordingly, in this paper, we envisage a FairEquityFL framework to ensure an equitable opportunity for all the clients to participate in the FL training process. In particular, we have introduced a sampling equalizer module within the selector component for ensuring fairness in terms of fair collaboration opportunity for all the clients in the client selection process. The selector is additionally responsible for both monitoring and controlling the clients' participation in each FL training round. Moreover, an outlier detection mechanism is enforced for identifying malicious clients based on the model performance in terms of considerable fluctuation in either accuracy or loss minimization. The selector flags suspicious clients and temporarily suspend such clients from participating in the FL training process. We further evaluate the performance of FairEquityFL on a publicly available dataset, FEMNIST. Our simulation results depict that FairEquityFL outperforms baseline models to a considerable extent.
<div id='section'>Paperid: <span id='pid'>317, <a href='https://arxiv.org/pdf/2503.04441.pdf' target='_blank'>https://arxiv.org/pdf/2503.04441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohit Menon, Nils Dengler, Sicong Pan, Gokul Krishna Chenchani, Maren Bennewitz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04441">EvidMTL: Evidential Multi-Task Learning for Uncertainty-Aware Semantic Surface Mapping from Monocular RGB Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For scene understanding in unstructured environments, an accurate and uncertainty-aware metric-semantic mapping is required to enable informed action selection by autonomous systems. Existing mapping methods often suffer from overconfident semantic predictions, and sparse and noisy depth sensing, leading to inconsistent map representations. In this paper, we therefore introduce EvidMTL, a multi-task learning framework that uses evidential heads for depth estimation and semantic segmentation, enabling uncertainty-aware inference from monocular RGB images. To enable uncertainty-calibrated evidential multi-task learning, we propose a novel evidential depth loss function that jointly optimizes the belief strength of the depth prediction in conjunction with evidential segmentation loss. Building on this, we present EvidKimera, an uncertainty-aware semantic surface mapping framework, which uses evidential depth and semantics prediction for improved 3D metric-semantic consistency. We train and evaluate EvidMTL on the NYUDepthV2 and assess its zero-shot performance on ScanNetV2, demonstrating superior uncertainty estimation compared to conventional approaches while maintaining comparable depth estimation and semantic segmentation. In zero-shot mapping tests on ScanNetV2, EvidKimera outperforms Kimera in semantic surface mapping accuracy and consistency, highlighting the benefits of uncertainty-aware mapping and underscoring its potential for real-world robotic applications.
<div id='section'>Paperid: <span id='pid'>318, <a href='https://arxiv.org/pdf/2405.17659.pdf' target='_blank'>https://arxiv.org/pdf/2405.17659.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Huang, Liutao Yang, Fanwen Wang, Yang Nan, Weiwen Wu, Chengyan Wang, Kuangyu Shi, Angelica I. Aviles-Rivero, Carola-Bibiane SchÃ¶nlieb, Daoqiang Zhang, Guang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17659">Enhancing Global Sensitivity and Uncertainty Quantification in Medical Image Reconstruction with Monte Carlo Arbitrary-Masked Mamba</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has been extensively applied in medical image reconstruction, where Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) represent the predominant paradigms, each possessing distinct advantages and inherent limitations: CNNs exhibit linear complexity with local sensitivity, whereas ViTs demonstrate quadratic complexity with global sensitivity. The emerging Mamba has shown superiority in learning visual representation, which combines the advantages of linear scalability and global sensitivity. In this study, we introduce MambaMIR, an Arbitrary-Masked Mamba-based model with wavelet decomposition for joint medical image reconstruction and uncertainty estimation. A novel Arbitrary Scan Masking (ASM) mechanism "masks out" redundant information to introduce randomness for further uncertainty estimation. Compared to the commonly used Monte Carlo (MC) dropout, our proposed MC-ASM provides an uncertainty map without the need for hyperparameter tuning and mitigates the performance drop typically observed when applying dropout to low-level tasks. For further texture preservation and better perceptual quality, we employ the wavelet transformation into MambaMIR and explore its variant based on the Generative Adversarial Network, namely MambaMIR-GAN. Comprehensive experiments have been conducted for multiple representative medical image reconstruction tasks, demonstrating that the proposed MambaMIR and MambaMIR-GAN outperform other baseline and state-of-the-art methods in different reconstruction tasks, where MambaMIR achieves the best reconstruction fidelity and MambaMIR-GAN has the best perceptual quality. In addition, our MC-ASM provides uncertainty maps as an additional tool for clinicians, while mitigating the typical performance drop caused by the commonly used dropout.
<div id='section'>Paperid: <span id='pid'>319, <a href='https://arxiv.org/pdf/2403.16732.pdf' target='_blank'>https://arxiv.org/pdf/2403.16732.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Durasov, Doruk Oner, Jonathan Donier, Hieu Le, Pascal Fua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.16732">Enabling Uncertainty Estimation in Iterative Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Turning pass-through network architectures into iterative ones, which use their own output as input, is a well-known approach for boosting performance. In this paper, we argue that such architectures offer an additional benefit: The convergence rate of their successive outputs is highly correlated with the accuracy of the value to which they converge. Thus, we can use the convergence rate as a useful proxy for uncertainty. This results in an approach to uncertainty estimation that provides state-of-the-art estimates at a much lower computational cost than techniques like Ensembles, and without requiring any modifications to the original iterative model. We demonstrate its practical value by embedding it in two application domains: road detection in aerial images and the estimation of aerodynamic properties of 2D and 3D shapes.
<div id='section'>Paperid: <span id='pid'>320, <a href='https://arxiv.org/pdf/2402.11223.pdf' target='_blank'>https://arxiv.org/pdf/2402.11223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Ni, Zhuowen Zou, Wenjun Huang, Hanning Chen, William Youngwoo Chung, Samuel Cho, Ranganath Krishnan, Pietro Mercati, Mohsen Imani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11223">HEAL: Brain-inspired Hyperdimensional Efficient Active Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drawing inspiration from the outstanding learning capability of our human brains, Hyperdimensional Computing (HDC) emerges as a novel computing paradigm, and it leverages high-dimensional vector presentation and operations for brain-like lightweight Machine Learning (ML). Practical deployments of HDC have significantly enhanced the learning efficiency compared to current deep ML methods on a broad spectrum of applications. However, boosting the data efficiency of HDC classifiers in supervised learning remains an open question. In this paper, we introduce Hyperdimensional Efficient Active Learning (HEAL), a novel Active Learning (AL) framework tailored for HDC classification. HEAL proactively annotates unlabeled data points via uncertainty and diversity-guided acquisition, leading to a more efficient dataset annotation and lowering labor costs. Unlike conventional AL methods that only support classifiers built upon deep neural networks (DNN), HEAL operates without the need for gradient or probabilistic computations. This allows it to be effortlessly integrated with any existing HDC classifier architecture. The key design of HEAL is a novel approach for uncertainty estimation in HDC classifiers through a lightweight HDC ensemble with prior hypervectors. Additionally, by exploiting hypervectors as prototypes (i.e., compact representations), we develop an extra metric for HEAL to select diverse samples within each batch for annotation. Our evaluation shows that HEAL surpasses a diverse set of baselines in AL quality and achieves notably faster acquisition than many BNN-powered or diversity-guided AL methods, recording 11 times to 40,000 times speedup in acquisition runtime per batch.
<div id='section'>Paperid: <span id='pid'>321, <a href='https://arxiv.org/pdf/2512.02073.pdf' target='_blank'>https://arxiv.org/pdf/2512.02073.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qirui Ji, Bin Qin, Yifan Jin, Yunze Zhao, Chuxiong Sun, Changwen Zheng, Jianwen Cao, Jiangmeng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.02073">HTG-GCL: Leveraging Hierarchical Topological Granularity from Cellular Complexes for Graph Contrastive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph contrastive learning (GCL) aims to learn discriminative semantic invariance by contrasting different views of the same graph that share critical topological patterns. However, existing GCL approaches with structural augmentations often struggle to identify task-relevant topological structures, let alone adapt to the varying coarse-to-fine topological granularities required across different downstream tasks. To remedy this issue, we introduce Hierarchical Topological Granularity Graph Contrastive Learning (HTG-GCL), a novel framework that leverages transformations of the same graph to generate multi-scale ring-based cellular complexes, embodying the concept of topological granularity, thereby generating diverse topological views. Recognizing that a certain granularity may contain misleading semantics, we propose a multi-granularity decoupled contrast and apply a granularity-specific weighting mechanism based on uncertainty estimation. Comprehensive experiments on various benchmarks demonstrate the effectiveness of HTG-GCL, highlighting its superior performance in capturing meaningful graph representations through hierarchical topological information.
<div id='section'>Paperid: <span id='pid'>322, <a href='https://arxiv.org/pdf/2511.18058.pdf' target='_blank'>https://arxiv.org/pdf/2511.18058.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Huang, Zhitong Xiong, Chenying Liu, Xiao Xiang Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.18058">Hierarchical Semi-Supervised Active Learning for Remote Sensing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The performance of deep learning models in remote sensing (RS) strongly depends on the availability of high-quality labeled data. However, collecting large-scale annotations is costly and time-consuming, while vast amounts of unlabeled imagery remain underutilized. To address this challenge, we propose a Hierarchical Semi-Supervised Active Learning (HSSAL) framework that integrates semi-supervised learning (SSL) and a novel hierarchical active learning (HAL) in a closed iterative loop. In each iteration, SSL refines the model using both labeled data through supervised learning and unlabeled data via weak-to-strong self-training, improving feature representation and uncertainty estimation. Guided by the refined representations and uncertainty cues of unlabeled samples, HAL then conducts sample querying through a progressive clustering strategy, selecting the most informative instances that jointly satisfy the criteria of scalability, diversity, and uncertainty. This hierarchical process ensures both efficiency and representativeness in sample selection. Extensive experiments on three benchmark RS scene classification datasets, including UCM, AID, and NWPU-RESISC45, demonstrate that HSSAL consistently outperforms SSL- or AL-only baselines. Remarkably, with only 8%, 4%, and 2% labeled training data on UCM, AID, and NWPU-RESISC45, respectively, HSSAL achieves over 95% of fully-supervised accuracy, highlighting its superior label efficiency through informativeness exploitation of unlabeled data. Our code will be publicly available.
<div id='section'>Paperid: <span id='pid'>323, <a href='https://arxiv.org/pdf/2508.15529.pdf' target='_blank'>https://arxiv.org/pdf/2508.15529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiyuan Tan, Yingying Shen, Haohui Zhu, Zhiwei Zhan, Shan Zhao, Mingfei Tu, Hongcheng Luo, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15529">ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Synthesizing extrapolated views from recorded driving logs is critical for simulating driving scenes for autonomous driving vehicles, yet it remains a challenging task. Recent methods leverage generative priors as pseudo ground truth, but often lead to poor geometric consistency and over-smoothed renderings. To address these limitations, we propose ExtraGS, a holistic framework for trajectory extrapolation that integrates both geometric and generative priors. At the core of ExtraGS is a novel Road Surface Gaussian(RSG) representation based on a hybrid Gaussian-Signed Distance Function (SDF) design, and Far Field Gaussians (FFG) that use learnable scaling factors to efficiently handle distant objects. Furthermore, we develop a self-supervised uncertainty estimation framework based on spherical harmonics that enables selective integration of generative priors only where extrapolation artifacts occur. Extensive experiments on multiple datasets, diverse multi-camera setups, and various generative priors demonstrate that ExtraGS significantly enhances the realism and geometric consistency of extrapolated views, while preserving high fidelity along the original trajectory.
<div id='section'>Paperid: <span id='pid'>324, <a href='https://arxiv.org/pdf/2502.16725.pdf' target='_blank'>https://arxiv.org/pdf/2502.16725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongzhe Cheng, Tianyou Zheng, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16725">DOSE3 : Diffusion-based Out-of-distribution detection on SE(3) trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution(OOD) detection, a fundamental machine learning task aimed at identifying abnormal samples, traditionally requires model retraining for different inlier distributions. While recent research demonstrates the applicability of diffusion models to OOD detection, existing approaches are limited to Euclidean or latent image spaces. Our work extends OOD detection to trajectories in the Special Euclidean Group in 3D ($\mathbb{SE}(3)$), addressing a critical need in computer vision, robotics, and engineering applications that process object pose sequences in $\mathbb{SE}(3)$. We present $\textbf{D}$iffusion-based $\textbf{O}$ut-of-distribution detection on $\mathbb{SE}(3)$ ($\mathbf{DOSE3}$), a novel OOD framework that extends diffusion to a unified sample space of $\mathbb{SE}(3)$ pose sequences. Through extensive validation on multiple benchmark datasets, we demonstrate $\mathbf{DOSE3}$'s superior performance compared to state-of-the-art OOD detection frameworks.
<div id='section'>Paperid: <span id='pid'>325, <a href='https://arxiv.org/pdf/2505.08685.pdf' target='_blank'>https://arxiv.org/pdf/2505.08685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meritxell Riera-Marin, Sikha O K, Julia Rodriguez-Comas, Matthias Stefan May, Zhaohong Pan, Xiang Zhou, Xiaokun Liang, Franciskus Xaverius Erick, Andrea Prenner, Cedric Hemon, Valentin Boussot, Jean-Louis Dillenseger, Jean-Claude Nunes, Abdul Qayyum, Moona Mazher, Steven A Niederer, Kaisar Kushibar, Carlos Martin-Isla, Petia Radeva, Karim Lekadir, Theodore Barfoot, Luis C. Garcia Peraza Herrera, Ben Glocker, Tom Vercauteren, Lucas Gago, Justin Englemann, Joy-Marie Kleiss, Anton Aubanell, Andreu Antolin, Javier Garcia-Lopez, Miguel A. Gonzalez Ballester, Adrian Galdran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08685">Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL) has become the dominant approach for medical image segmentation, yet ensuring the reliability and clinical applicability of these models requires addressing key challenges such as annotation variability, calibration, and uncertainty estimation. This is why we created the Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS), which highlights the critical role of multiple annotators in establishing a more comprehensive ground truth, emphasizing that segmentation is inherently subjective and that leveraging inter-annotator variability is essential for robust model evaluation. Seven teams participated in the challenge, submitting a variety of DL models evaluated using metrics such as Dice Similarity Coefficient (DSC), Expected Calibration Error (ECE), and Continuous Ranked Probability Score (CRPS). By incorporating consensus and dissensus ground truth, we assess how DL models handle uncertainty and whether their confidence estimates align with true segmentation performance. Our findings reinforce the importance of well-calibrated models, as better calibration is strongly correlated with the quality of the results. Furthermore, we demonstrate that segmentation models trained on diverse datasets and enriched with pre-trained knowledge exhibit greater robustness, particularly in cases deviating from standard anatomical structures. Notably, the best-performing models achieved high DSC and well-calibrated uncertainty estimates. This work underscores the need for multi-annotator ground truth, thorough calibration assessments, and uncertainty-aware evaluations to develop trustworthy and clinically reliable DL-based medical image segmentation models.
<div id='section'>Paperid: <span id='pid'>326, <a href='https://arxiv.org/pdf/2405.19320.pdf' target='_blank'>https://arxiv.org/pdf/2405.19320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shicong Cen, Jincheng Mei, Katayoon Goshvadi, Hanjun Dai, Tong Yang, Sherry Yang, Dale Schuurmans, Yuejie Chi, Bo Dai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19320">Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning from human feedback (RLHF) has demonstrated great promise in aligning large language models (LLMs) with human preference. Depending on the availability of preference data, both online and offline RLHF are active areas of investigation. A key bottleneck is understanding how to incorporate uncertainty estimation in the reward function learned from the preference data for RLHF, regardless of how the preference data is collected. While the principles of optimism or pessimism under uncertainty are well-established in standard reinforcement learning (RL), a practically-implementable and theoretically-grounded form amenable to large language models is not yet available, as standard techniques for constructing confidence intervals become intractable under arbitrary policy parameterizations.
  In this paper, we introduce a unified approach to online and offline RLHF -- value-incentivized preference optimization (VPO) -- which regularizes the maximum-likelihood estimate of the reward function with the corresponding value function, modulated by a $\textit{sign}$ to indicate whether the optimism or pessimism is chosen. VPO also directly optimizes the policy with implicit reward modeling, and therefore shares a simpler RLHF pipeline similar to direct preference optimization. Theoretical guarantees of VPO are provided for both online and offline settings, matching the rates of their standard RL counterparts. Moreover, experiments on text summarization and dialog verify the practicality and effectiveness of VPO.
<div id='section'>Paperid: <span id='pid'>327, <a href='https://arxiv.org/pdf/2511.06072.pdf' target='_blank'>https://arxiv.org/pdf/2511.06072.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Behrad Tajalli, Stefanos Koffas, Stjepan Picek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.06072">CatBack: Universal Backdoor Attacks on Tabular Data via Categorical Encoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Backdoor attacks in machine learning have drawn significant attention for their potential to compromise models stealthily, yet most research has focused on homogeneous data such as images. In this work, we propose a novel backdoor attack on tabular data, which is particularly challenging due to the presence of both numerical and categorical features. Our key idea is a novel technique to convert categorical values into floating-point representations. This approach preserves enough information to maintain clean-model accuracy compared to traditional methods like one-hot or ordinal encoding. By doing this, we create a gradient-based universal perturbation that applies to all features, including categorical ones. We evaluate our method on five datasets and four popular models. Our results show up to a 100% attack success rate in both white-box and black-box settings (including real-world applications like Vertex AI), revealing a severe vulnerability for tabular data. Our method is shown to surpass the previous works like Tabdoor in terms of performance, while remaining stealthy against state-of-the-art defense mechanisms. We evaluate our attack against Spectral Signatures, Neural Cleanse, Beatrix, and Fine-Pruning, all of which fail to defend successfully against it. We also verify that our attack successfully bypasses popular outlier detection mechanisms.
<div id='section'>Paperid: <span id='pid'>328, <a href='https://arxiv.org/pdf/2509.02327.pdf' target='_blank'>https://arxiv.org/pdf/2509.02327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>I. Shavindra Jayasekera, Jacob Si, Filippo Valdettaro, Wenlong Chen, A. Aldo Faisal, Yingzhen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02327">Variational Uncertainty Decomposition for In-Context Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As large language models (LLMs) gain popularity in conducting prediction tasks in-context, understanding the sources of uncertainty in in-context learning becomes essential to ensuring reliability. The recent hypothesis of in-context learning performing predictive Bayesian inference opens the avenue for Bayesian uncertainty estimation, particularly for decomposing uncertainty into epistemic uncertainty due to lack of in-context data and aleatoric uncertainty inherent in the in-context prediction task. However, the decomposition idea remains under-explored due to the intractability of the latent parameter posterior from the underlying Bayesian model. In this work, we introduce a variational uncertainty decomposition framework for in-context learning without explicitly sampling from the latent parameter posterior, by optimising auxiliary queries as probes to obtain an upper bound to the aleatoric uncertainty of an LLM's in-context learning procedure, which also induces a lower bound to the epistemic uncertainty. Through experiments on synthetic and real-world tasks, we show quantitatively and qualitatively that the decomposed uncertainties obtained from our method exhibit desirable properties of epistemic and aleatoric uncertainty.
<div id='section'>Paperid: <span id='pid'>329, <a href='https://arxiv.org/pdf/2502.11948.pdf' target='_blank'>https://arxiv.org/pdf/2502.11948.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Min-Hsuan Yeh, Max Kamachee, Seongheon Park, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11948">HalluEntity: Benchmarking and Understanding Entity-Level Hallucination Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To mitigate the impact of hallucination nature of LLMs, many studies propose detecting hallucinated generation through uncertainty estimation. However, these approaches predominantly operate at the sentence or paragraph level, failing to pinpoint specific spans or entities responsible for hallucinated content. This lack of granularity is especially problematic for long-form outputs that mix accurate and fabricated information. To address this limitation, we explore entity-level hallucination detection. We propose a new data set, HalluEntity, which annotates hallucination at the entity level. Based on the dataset, we comprehensively evaluate uncertainty-based hallucination detection approaches across 17 modern LLMs. Our experimental results show that uncertainty estimation approaches focusing on individual token probabilities tend to over-predict hallucinations, while context-aware methods show better but still suboptimal performance. Through an in-depth qualitative study, we identify relationships between hallucination tendencies and linguistic properties and highlight important directions for future research. HalluEntity: https://huggingface.co/datasets/samuelyeh/HalluEntity
<div id='section'>Paperid: <span id='pid'>330, <a href='https://arxiv.org/pdf/2410.14746.pdf' target='_blank'>https://arxiv.org/pdf/2410.14746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anthony Sicilia, Mert Inan, Malihe Alikhani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14746">Accounting for Sycophancy in Language Model Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective human-machine collaboration requires machine learning models to externalize uncertainty, so users can reflect and intervene when necessary. For language models, these representations of uncertainty may be impacted by sycophancy bias: proclivity to agree with users, even if they are wrong. For instance, models may be over-confident in (incorrect) problem solutions suggested by a user. We study the relationship between sycophancy and uncertainty estimation for the first time. We propose a generalization of the definition of sycophancy bias to measure downstream impacts on uncertainty estimation, and also propose a new algorithm (SyRoUP) to account for sycophancy in the uncertainty estimation process. Unlike previous works on sycophancy, we study a broad array of user behaviors, varying both correctness and confidence of user suggestions to see how model answers (and their certainty) change. Our experiments across conversation forecasting and question-answering tasks show that user confidence plays a critical role in modulating the effects of sycophancy, and that SyRoUP can better predict these effects. From these results, we argue that externalizing both model and user uncertainty can help to mitigate the impacts of sycophancy bias.
<div id='section'>Paperid: <span id='pid'>331, <a href='https://arxiv.org/pdf/2409.03801.pdf' target='_blank'>https://arxiv.org/pdf/2409.03801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yewen Li, Chaojie Wang, Xiaobo Xia, Xu He, Ruyi An, Dong Li, Tongliang Liu, Bo An, Xinrun Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03801">Resultant: Incremental Effectiveness on Likelihood for Unsupervised Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised out-of-distribution (U-OOD) detection is to identify OOD data samples with a detector trained solely on unlabeled in-distribution (ID) data. The likelihood function estimated by a deep generative model (DGM) could be a natural detector, but its performance is limited in some popular "hard" benchmarks, such as FashionMNIST (ID) vs. MNIST (OOD). Recent studies have developed various detectors based on DGMs to move beyond likelihood. However, despite their success on "hard" benchmarks, most of them struggle to consistently surpass or match the performance of likelihood on some "non-hard" cases, such as SVHN (ID) vs. CIFAR10 (OOD) where likelihood could be a nearly perfect detector. Therefore, we appeal for more attention to incremental effectiveness on likelihood, i.e., whether a method could always surpass or at least match the performance of likelihood in U-OOD detection. We first investigate the likelihood of variational DGMs and find its detection performance could be improved in two directions: i) alleviating latent distribution mismatch, and ii) calibrating the dataset entropy-mutual integration. Then, we apply two techniques for each direction, specifically post-hoc prior and dataset entropy-mutual calibration. The final method, named Resultant, combines these two directions for better incremental effectiveness compared to either technique alone. Experimental results demonstrate that the Resultant could be a new state-of-the-art U-OOD detector while maintaining incremental effectiveness on likelihood in a wide range of tasks.
<div id='section'>Paperid: <span id='pid'>332, <a href='https://arxiv.org/pdf/2406.18067.pdf' target='_blank'>https://arxiv.org/pdf/2406.18067.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaqian Hao, Chenguang Hu, Yingying Gao, Shilei Zhang, Junlan Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18067">Exploring Energy-Based Models for Out-of-Distribution Detection in Dialect Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The diverse nature of dialects presents challenges for models trained on specific linguistic patterns, rendering them susceptible to errors when confronted with unseen or out-of-distribution (OOD) data. This study introduces a novel margin-enhanced joint energy model (MEJEM) tailored specifically for OOD detection in dialects. By integrating a generative model and the energy margin loss, our approach aims to enhance the robustness of dialect identification systems. Furthermore, we explore two OOD scores for OOD dialect detection, and our findings conclusively demonstrate that the energy score outperforms the softmax score. Leveraging Sharpness-Aware Minimization to optimize the training process of the joint model, we enhance model generalization by minimizing both loss and sharpness. Experiments conducted on dialect identification tasks validate the efficacy of Energy-Based Models and provide valuable insights into their performance.
<div id='section'>Paperid: <span id='pid'>333, <a href='https://arxiv.org/pdf/2401.02611.pdf' target='_blank'>https://arxiv.org/pdf/2401.02611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyao Li, Pengguang Chen, Shaozuo Yu, Shu Liu, Jiaya Jia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02611">MOODv2: Masked Image Modeling for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The crux of effective out-of-distribution (OOD) detection lies in acquiring a robust in-distribution (ID) representation, distinct from OOD samples. While previous methods predominantly leaned on recognition-based techniques for this purpose, they often resulted in shortcut learning, lacking comprehensive representations. In our study, we conducted a comprehensive analysis, exploring distinct pretraining tasks and employing various OOD score functions. The results highlight that the feature representations pre-trained through reconstruction yield a notable enhancement and narrow the performance gap among various score functions. This suggests that even simple score functions can rival complex ones when leveraging reconstruction-based pretext tasks. Reconstruction-based pretext tasks adapt well to various score functions. As such, it holds promising potential for further expansion. Our OOD detection framework, MOODv2, employs the masked image modeling pretext task. Without bells and whistles, MOODv2 impressively enhances 14.30% AUROC to 95.68% on ImageNet and achieves 99.98% on CIFAR-10.
<div id='section'>Paperid: <span id='pid'>334, <a href='https://arxiv.org/pdf/2510.17131.pdf' target='_blank'>https://arxiv.org/pdf/2510.17131.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin Gao, Jiyao Liu, Guanghao Li, Yueming Lyu, Jianxiong Gao, Weichen Yu, Ningsheng Xu, Liang Wang, Caifeng Shan, Ziwei Liu, Chenyang Si
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.17131">GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements have explored text-to-image diffusion models for synthesizing out-of-distribution (OOD) samples, substantially enhancing the performance of OOD detection. However, existing approaches typically rely on perturbing text-conditioned embeddings, resulting in semantic instability and insufficient shift diversity, which limit generalization to realistic OOD. To address these challenges, we propose GOOD, a novel and flexible framework that directly guides diffusion sampling trajectories towards OOD regions using off-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level guidance: (1) Image-level guidance based on the gradient of log partition to reduce input likelihood, drives samples toward low-density regions in pixel space. (2) Feature-level guidance, derived from k-NN distance in the classifier's latent space, promotes sampling in feature-sparse regions. Hence, this dual-guidance design enables more controllable and diverse OOD sample generation. Additionally, we introduce a unified OOD score that adaptively combines image and feature discrepancies, enhancing detection robustness. We perform thorough quantitative and qualitative analyses to evaluate the effectiveness of GOOD, demonstrating that training with samples generated by GOOD can notably enhance OOD detection performance.
<div id='section'>Paperid: <span id='pid'>335, <a href='https://arxiv.org/pdf/2509.15735.pdf' target='_blank'>https://arxiv.org/pdf/2509.15735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Davide Ettori, Nastaran Darabi, Sina Tayebati, Ranganath Krishnan, Mahesh Subedar, Omesh Tickoo, Amit Ranjan Trivedi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15735">EigenTrack: Spectral Activation Feature Tracking for Hallucination and Out-of-Distribution Detection in LLMs and VLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) offer broad utility but remain prone to hallucination and out-of-distribution (OOD) errors. We propose EigenTrack, an interpretable real-time detector that uses the spectral geometry of hidden activations, a compact global signature of model dynamics. By streaming covariance-spectrum statistics such as entropy, eigenvalue gaps, and KL divergence from random baselines into a lightweight recurrent classifier, EigenTrack tracks temporal shifts in representation structure that signal hallucination and OOD drift before surface errors appear. Unlike black- and grey-box methods, it needs only a single forward pass without resampling. Unlike existing white-box detectors, it preserves temporal context, aggregates global signals, and offers interpretable accuracy-latency trade-offs.
<div id='section'>Paperid: <span id='pid'>336, <a href='https://arxiv.org/pdf/2505.23223.pdf' target='_blank'>https://arxiv.org/pdf/2505.23223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyuan Pan, Chenlu Ye, Joseph Melkonian, Jiaqi W. Ma, Tong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23223">Daunce: Data Attribution through Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training data attribution (TDA) methods aim to identify which training examples influence a model's predictions on specific test data most. By quantifying these influences, TDA supports critical applications such as data debugging, curation, and valuation. Gradient-based TDA methods rely on gradients and second-order information, limiting their applicability at scale. While recent random projection-based methods improve scalability, they often suffer from degraded attribution accuracy. Motivated by connections between uncertainty and influence functions, we introduce Daunce - a simple yet effective data attribution approach through uncertainty estimation. Our method operates by fine-tuning a collection of perturbed models and computing the covariance of per-example losses across these models as the attribution score. Daunce is scalable to large language models (LLMs) and achieves more accurate attribution compared to existing TDA methods. We validate Daunce on tasks ranging from vision tasks to LLM fine-tuning, and further demonstrate its compatibility with black-box model access. Applied to OpenAI's GPT models, our method achieves, to our knowledge, the first instance of data attribution on proprietary LLMs.
<div id='section'>Paperid: <span id='pid'>337, <a href='https://arxiv.org/pdf/2404.08517.pdf' target='_blank'>https://arxiv.org/pdf/2404.08517.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuan Xie, Jiayang Song, Zhehua Zhou, Yuheng Huang, Da Song, Lei Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08517">Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Large Language Models (LLMs) have seen widespread applications across numerous fields, their limited interpretability poses concerns regarding their safe operations from multiple aspects, e.g., truthfulness, robustness, and fairness. Recent research has started developing quality assurance methods for LLMs, introducing techniques such as offline detector-based or uncertainty estimation methods. However, these approaches predominantly concentrate on post-generation analysis, leaving the online safety analysis for LLMs during the generation phase an unexplored area. To bridge this gap, we conduct in this work a comprehensive evaluation of the effectiveness of existing online safety analysis methods on LLMs. We begin with a pilot study that validates the feasibility of detecting unsafe outputs in the early generation process. Following this, we establish the first publicly available benchmark of online safety analysis for LLMs, including a broad spectrum of methods, models, tasks, datasets, and evaluation metrics. Utilizing this benchmark, we extensively analyze the performance of state-of-the-art online safety analysis methods on both open-source and closed-source LLMs. This analysis reveals the strengths and weaknesses of individual methods and offers valuable insights into selecting the most appropriate method based on specific application scenarios and task requirements. Furthermore, we also explore the potential of using hybridization methods, i.e., combining multiple methods to derive a collective safety conclusion, to enhance the efficacy of online safety analysis for LLMs. Our findings indicate a promising direction for the development of innovative and trustworthy quality assurance methodologies for LLMs, facilitating their reliable deployments across diverse domains.
<div id='section'>Paperid: <span id='pid'>338, <a href='https://arxiv.org/pdf/2402.18162.pdf' target='_blank'>https://arxiv.org/pdf/2402.18162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weilin Wan, Weizhong Zhang, Quan Zhou, Fan Yi, Cheng Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18162">Out-of-Distribution Detection using Neural Activation Prior</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution detection (OOD) is a crucial technique for deploying machine learning models in the real world to handle the unseen scenarios. In this paper, we first propose a simple yet effective Neural Activation Prior (NAP) for OOD detection. Our neural activation prior is based on a key observation that, for a channel before the global pooling layer of a fully trained neural network, the probability of a few neurons being activated with a large response by an in-distribution (ID) sample is significantly higher than that by an OOD sample. An intuitive explanation is that for a model fully trained on ID dataset, each channel would play a role in detecting a certain pattern in the ID dataset, and a few neurons can be activated with a large response when the pattern is detected in an input sample. Then, a new scoring function based on this prior is proposed to highlight the role of these strongly activated neurons in OOD detection. Our approach is plug-and-play and does not lead to any performance degradation on ID data classification and requires no extra training or statistics from training or external datasets. Notice that previous methods primarily rely on post-global-pooling features of the neural networks, while the within-channel distribution information we leverage would be discarded by the global pooling operator. Consequently, our method is orthogonal to existing approaches and can be effectively combined with them in various applications. Experimental results show that our method achieves the state-of-the-art performance on CIFAR benchmark and ImageNet dataset, which demonstrates the power of the proposed prior. Finally, we extend our method to Transformers and the experimental findings indicate that NAP can also significantly enhance the performance of OOD detection on Transformers, thereby demonstrating the broad applicability of this prior knowledge.
<div id='section'>Paperid: <span id='pid'>339, <a href='https://arxiv.org/pdf/2509.13464.pdf' target='_blank'>https://arxiv.org/pdf/2509.13464.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Onat Gungor, Ishaan Kale, Jiasheng Zhou, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13464">LIGHT-HIDS: A Lightweight and Effective Machine Learning-Based Framework for Robust Host Intrusion Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The expansion of edge computing has increased the attack surface, creating an urgent need for robust, real-time machine learning (ML)-based host intrusion detection systems (HIDS) that balance accuracy and efficiency. In such settings, inference latency poses a critical security risk, as delays may provide exploitable opportunities for attackers. However, many state-of-the-art ML-based HIDS solutions rely on computationally intensive architectures with high inference costs, limiting their practical deployment. This paper proposes LIGHT-HIDS, a lightweight machine learning framework that combines a compressed neural network feature extractor trained via Deep Support Vector Data Description (DeepSVDD) with an efficient novelty detection model. This hybrid approach enables the learning of compact, meaningful representations of normal system call behavior for accurate anomaly detection. Experimental results on multiple datasets demonstrate that LIGHT-HIDS consistently enhances detection accuracy while reducing inference time by up to 75x compared to state-of-the-art methods. These findings highlight its effectiveness and scalability as a machine learning-based solution for real-time host intrusion detection.
<div id='section'>Paperid: <span id='pid'>340, <a href='https://arxiv.org/pdf/2508.19450.pdf' target='_blank'>https://arxiv.org/pdf/2508.19450.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elvin Li, Onat Gungor, Zhengli Shang, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19450">CITADEL: Continual Anomaly Detection for Enhanced Learning in IoT Intrusion Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Internet of Things (IoT), with its high degree of interconnectivity and limited computational resources, is particularly vulnerable to a wide range of cyber threats. Intrusion detection systems (IDS) have been extensively studied to enhance IoT security, and machine learning-based IDS (ML-IDS) show considerable promise for detecting malicious activity. However, their effectiveness is often constrained by poor adaptability to emerging threats and the issue of catastrophic forgetting during continuous learning. To address these challenges, we propose CITADEL, a self-supervised continual learning framework designed to extract robust representations from benign data while preserving long-term knowledge through optimized memory consolidation mechanisms. CITADEL integrates a tabular-to-image transformation module, a memory-aware masked autoencoder for self-supervised representation learning, and a novelty detection component capable of identifying anomalies without dependence on labeled attack data. Our design enables the system to incrementally adapt to emerging behaviors while retaining its ability to detect previously observed threats. Experiments on multiple intrusion datasets demonstrate that CITADEL achieves up to a 72.9% improvement over the VAE-based lifelong anomaly detector (VLAD) in key detection and retention metrics, highlighting its effectiveness in dynamic IoT environments.
<div id='section'>Paperid: <span id='pid'>341, <a href='https://arxiv.org/pdf/2507.09209.pdf' target='_blank'>https://arxiv.org/pdf/2507.09209.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Liang, Di Wang, Zhicheng Jiao, Ronghan Li, Pengfei Yang, Quan Wang, Tat-Seng Chua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09209">Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid advancements in Vision Language Models (VLMs) have prompted the development of multi-modal medical assistant systems. Despite this progress, current models still have inherent probabilistic uncertainties, often producing erroneous or unverified responses-an issue with serious implications in medical applications. Existing methods aim to enhance the performance of Medical Vision Language Model (MedVLM) by adjusting model structure, fine-tuning with high-quality data, or through preference fine-tuning. However, these training-dependent strategies are costly and still lack sufficient alignment with clinical expertise. To address these issues, we propose an expert-in-the-loop framework named Expert-Controlled Classifier-Free Guidance (Expert-CFG) to align MedVLM with clinical expertise without additional training. This framework introduces an uncertainty estimation strategy to identify unreliable outputs. It then retrieves relevant references to assist experts in highlighting key terms and applies classifier-free guidance to refine the token embeddings of MedVLM, ensuring that the adjusted outputs are correct and align with expert highlights. Evaluations across three medical visual question answering benchmarks demonstrate that the proposed Expert-CFG, with 4.2B parameters and limited expert annotations, outperforms state-of-the-art models with 13B parameters. The results demonstrate the feasibility of deploying such a system in resource-limited settings for clinical use.
<div id='section'>Paperid: <span id='pid'>342, <a href='https://arxiv.org/pdf/2505.14064.pdf' target='_blank'>https://arxiv.org/pdf/2505.14064.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cosmin I. Bercea, Jun Li, Philipp Raffler, Evamaria O. Riedel, Lena Schmitzer, Angela Kurz, Felix Bitzer, Paula RoÃmÃ¼ller, Julian Canisius, Mirjam L. Beyrle, Che Liu, Wenjia Bai, Bernhard Kainz, Julia A. Schnabel, Benedikt Wiestler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14064">NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many real-world applications, deployed models encounter inputs that differ from the data seen during training. Out-of-distribution detection identifies whether an input stems from an unseen distribution, while open-world recognition flags such inputs to ensure the system remains robust as ever-emerging, previously $unknown$ categories appear and must be addressed without retraining. Foundation and vision-language models are pre-trained on large and diverse datasets with the expectation of broad generalization across domains, including medical imaging. However, benchmarking these models on test sets with only a few common outlier types silently collapses the evaluation back to a closed-set problem, masking failures on rare or truly novel conditions encountered in clinical use.
  We therefore present $NOVA$, a challenging, real-life $evaluation-only$ benchmark of $\sim$900 brain MRI scans that span 281 rare pathologies and heterogeneous acquisition protocols. Each case includes rich clinical narratives and double-blinded expert bounding-box annotations. Together, these enable joint assessment of anomaly localisation, visual captioning, and diagnostic reasoning. Because NOVA is never used for training, it serves as an $extreme$ stress-test of out-of-distribution generalisation: models must bridge a distribution gap both in sample appearance and in semantic space. Baseline results with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B) reveal substantial performance drops across all tasks, establishing NOVA as a rigorous testbed for advancing models that can detect, localize, and reason about truly unknown anomalies.
<div id='section'>Paperid: <span id='pid'>343, <a href='https://arxiv.org/pdf/2502.15901.pdf' target='_blank'>https://arxiv.org/pdf/2502.15901.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Onat Gungor, Amanda Sofie Rios, Nilesh Ahuja, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15901">TS-OOD: Evaluating Time-Series Out-of-Distribution Detection and Prospective Directions for Progress</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) data is a fundamental challenge in the deployment of machine learning models. From a security standpoint, this is particularly important because OOD test data can result in misleadingly confident yet erroneous predictions, which undermine the reliability of the deployed model. Although numerous models for OOD detection have been developed in computer vision and language, their adaptability to the time-series data domain remains limited and under-explored. Yet, time-series data is ubiquitous across manufacturing and security applications for which OOD is essential. This paper seeks to address this research gap by conducting a comprehensive analysis of modality-agnostic OOD detection algorithms. We evaluate over several multivariate time-series datasets, deep learning architectures, time-series specific data augmentations, and loss functions. Our results demonstrate that: 1) the majority of state-of-the-art OOD methods exhibit limited performance on time-series data, and 2) OOD methods based on deep feature modeling may offer greater advantages for time-series OOD detection, highlighting a promising direction for future time-series OOD detection algorithm development.
<div id='section'>Paperid: <span id='pid'>344, <a href='https://arxiv.org/pdf/2502.14094.pdf' target='_blank'>https://arxiv.org/pdf/2502.14094.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sean Fuhrman, Onat Gungor, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14094">CND-IDS: Continual Novelty Detection for Intrusion Detection Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intrusion detection systems (IDS) play a crucial role in IoT and network security by monitoring system data and alerting to suspicious activities. Machine learning (ML) has emerged as a promising solution for IDS, offering highly accurate intrusion detection. However, ML-IDS solutions often overlook two critical aspects needed to build reliable systems: continually changing data streams and a lack of attack labels. Streaming network traffic and associated cyber attacks are continually changing, which can degrade the performance of deployed ML models. Labeling attack data, such as zero-day attacks, in real-world intrusion scenarios may not be feasible, making the use of ML solutions that do not rely on attack labels necessary. To address both these challenges, we propose CND-IDS, a continual novelty detection IDS framework which consists of (i) a learning-based feature extractor that continuously updates new feature representations of the system data, and (ii) a novelty detector that identifies new cyber attacks by leveraging principal component analysis (PCA) reconstruction. Our results on realistic intrusion datasets show that CND-IDS achieves up to 6.1x F-score improvement, and up to 6.5x improved forward transfer over the SOTA unsupervised continual learning algorithm. Our code will be released upon acceptance.
<div id='section'>Paperid: <span id='pid'>345, <a href='https://arxiv.org/pdf/2412.09333.pdf' target='_blank'>https://arxiv.org/pdf/2412.09333.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan-Lucas Uslu, Alexey Nekrasov, Alexander Hermans, Bernd Beschoten, Bastian Leibe, Lutz Waldecker, Christoph Stampfer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09333">MaskTerial: A Foundation Model for Automated 2D Material Flake Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection and classification of exfoliated two-dimensional (2D) material flakes from optical microscope images can be automated using computer vision algorithms. This has the potential to increase the accuracy and objectivity of classification and the efficiency of sample fabrication, and it allows for large-scale data collection. Existing algorithms often exhibit challenges in identifying low-contrast materials and typically require large amounts of training data. Here, we present a deep learning model, called MaskTerial, that uses an instance segmentation network to reliably identify 2D material flakes. The model is extensively pre-trained using a synthetic data generator, that generates realistic microscopy images from unlabeled data. This results in a model that can to quickly adapt to new materials with as little as 5 to 10 images. Furthermore, an uncertainty estimation model is used to finally classify the predictions based on optical contrast. We evaluate our method on eight different datasets comprising five different 2D materials and demonstrate significant improvements over existing techniques in the detection of low-contrast materials such as hexagonal boron nitride.
<div id='section'>Paperid: <span id='pid'>346, <a href='https://arxiv.org/pdf/2407.09658.pdf' target='_blank'>https://arxiv.org/pdf/2407.09658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ning Wang, Shanghao Shi, Yang Xiao, Yimin Chen, Y. Thomas Hou, Wenjing Lou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09658">BoBa: Boosting Backdoor Detection through Data Distribution Inference in Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning, while being a promising approach for collaborative model training, is susceptible to poisoning attacks due to its decentralized nature. Backdoor attacks, in particular, have shown remarkable stealthiness, as they selectively compromise predictions for inputs containing triggers. Previous endeavors to detect and mitigate such attacks are based on the Independent and Identically Distributed (IID) data assumption where benign model updates exhibit high-level similarity in multiple feature spaces due to IID data. Thus, outliers are detected as backdoor attacks. Nevertheless, non-IID data presents substantial challenges in backdoor attack detection, as the data variety introduces variance among benign models, making outlier detection-based mechanisms less effective.
  We propose a novel distribution-aware anomaly detection mechanism, BoBa, to address this problem. In order to differentiate outliers arising from data variety versus backdoor attack, we propose to break down the problem into two steps: clustering clients utilizing their data distribution followed by a voting-based detection. Based on the intuition that clustering and subsequent backdoor detection can drastically benefit from knowing client data distributions, we propose a novel data distribution inference mechanism. To improve detection robustness, we introduce an overlapping clustering method, where each client is associated with multiple clusters, ensuring that the trustworthiness of a model update is assessed collectively by multiple clusters rather than a single cluster. Through extensive evaluations, we demonstrate that BoBa can reduce the attack success rate to lower than 0.001 while maintaining high main task accuracy across various attack strategies and experimental settings.
<div id='section'>Paperid: <span id='pid'>347, <a href='https://arxiv.org/pdf/2510.13464.pdf' target='_blank'>https://arxiv.org/pdf/2510.13464.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emily Miller, Michael Milford, Muhammad Burhan Hafez, SD Ramchurn, Shoaib Ehsan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.13464">Through the Lens of Doubt: Robust and Efficient Uncertainty Estimation for Visual Place Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual Place Recognition (VPR) enables robots and autonomous vehicles to identify previously visited locations by matching current observations against a database of known places. However, VPR systems face significant challenges when deployed across varying visual environments, lighting conditions, seasonal changes, and viewpoints changes. Failure-critical VPR applications, such as loop closure detection in simultaneous localization and mapping (SLAM) pipelines, require robust estimation of place matching uncertainty. We propose three training-free uncertainty metrics that estimate prediction confidence by analyzing inherent statistical patterns in similarity scores from any existing VPR method. Similarity Distribution (SD) quantifies match distinctiveness by measuring score separation between candidates; Ratio Spread (RS) evaluates competitive ambiguity among top-scoring locations; and Statistical Uncertainty (SU) is a combination of SD and RS that provides a unified metric that generalizes across datasets and VPR methods without requiring validation data to select the optimal metric. All three metrics operate without additional model training, architectural modifications, or computationally expensive geometric verification. Comprehensive evaluation across nine state-of-the-art VPR methods and six benchmark datasets confirms that our metrics excel at discriminating between correct and incorrect VPR matches, and consistently outperform existing approaches while maintaining negligible computational overhead, making it deployable for real-time robotic applications across varied environmental conditions with improved precision-recall performance.
<div id='section'>Paperid: <span id='pid'>348, <a href='https://arxiv.org/pdf/2506.09024.pdf' target='_blank'>https://arxiv.org/pdf/2506.09024.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Wagner, Pramit Saha, Harry Anthony, J. Alison Noble, Konstantinos Kamnitsas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09024">DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safe deployment of machine learning (ML) models in safety-critical domains such as medical imaging requires detecting inputs with characteristics not seen during training, known as out-of-distribution (OOD) detection, to prevent unreliable predictions. Effective OOD detection after deployment could benefit from access to the training data, enabling direct comparison between test samples and the training data distribution to identify differences. State-of-the-art OOD detection methods, however, either discard training data after deployment or assume that test samples and training data are centrally stored together, an assumption that rarely holds in real-world settings. This is because shipping training data with the deployed model is usually impossible due to the size of training databases, as well as proprietary or privacy constraints. We introduce the Isolation Network, an OOD detection framework that quantifies the difficulty of separating a target test sample from the training data by solving a binary classification task. We then propose Decentralized Isolation Networks (DIsoN), which enables the comparison of training and test data when data-sharing is impossible, by exchanging only model parameters between the remote computational nodes of training and deployment. We further extend DIsoN with class-conditioning, comparing a target sample solely with training data of its predicted class. We evaluate DIsoN on four medical imaging datasets (dermatology, chest X-ray, breast ultrasound, histopathology) across 12 OOD detection tasks. DIsoN performs favorably against existing methods while respecting data-privacy. This decentralized OOD detection framework opens the way for a new type of service that ML developers could provide along with their models: providing remote, secure utilization of their training data for OOD detection services. Code will be available upon acceptance at: *****
<div id='section'>Paperid: <span id='pid'>349, <a href='https://arxiv.org/pdf/2411.09553.pdf' target='_blank'>https://arxiv.org/pdf/2411.09553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junwen Wang, Zhonghao Wang, Oscar MacCormac, Jonathan Shapey, Tom Vercauteren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09553">OOD-SEG: Exploiting out-of-distribution detection techniques for learning image segmentation from sparse multi-class positive-only annotations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite significant advancements, segmentation based on deep neural networks in medical and surgical imaging faces several challenges, two of which we aim to address in this work. First, acquiring complete pixel-level segmentation labels for medical images is time-consuming and requires domain expertise. Second, typical segmentation pipelines cannot detect out-of-distribution (OOD) pixels, leaving them prone to spurious outputs during deployment. In this work, we propose a novel segmentation approach which broadly falls within the positive-unlabelled (PU) learning paradigm and exploits tools from OOD detection techniques. Our framework learns only from sparsely annotated pixels from multiple positive-only classes and does not use any annotation for the background class. These multi-class positive annotations naturally fall within the in-distribution (ID) set. Unlabelled pixels may contain positive classes but also negative ones, including what is typically referred to as \emph{background} in standard segmentation formulations. Here, we forgo the need for background annotation and consider these together with any other unseen classes as part of the OOD set. Our framework can integrate, at a pixel-level, any OOD detection approaches designed for classification tasks. To address the lack of existing OOD datasets and established evaluation metric for medical image segmentation, we propose a cross-validation strategy that treats held-out labelled classes as OOD. Extensive experiments on both multi-class hyperspectral and RGB surgical imaging datasets demonstrate the robustness and generalisation capability of our proposed framework.
<div id='section'>Paperid: <span id='pid'>350, <a href='https://arxiv.org/pdf/2411.08227.pdf' target='_blank'>https://arxiv.org/pdf/2411.08227.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shawn Li, Huixian Gong, Hao Dong, Tiankai Yang, Zhengzhong Tu, Yue Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08227">DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for ensuring the robustness of machine learning models by identifying samples that deviate from the training distribution. While traditional OOD detection has primarily focused on single-modality inputs, such as images, recent advances in multimodal models have demonstrated the potential of leveraging multiple modalities (e.g., video, optical flow, audio) to enhance detection performance. However, existing methods often overlook intra-class variability within in-distribution (ID) data, assuming that samples of the same class are perfectly cohesive and consistent. This assumption can lead to performance degradation, especially when prediction discrepancies are uniformly amplified across all samples. To address this issue, we propose Dynamic Prototype Updating (DPU), a novel plug-and-play framework for multimodal OOD detection that accounts for intra-class variations. Our method dynamically updates class center representations for each class by measuring the variance of similar samples within each batch, enabling adaptive adjustments. This approach allows us to amplify prediction discrepancies based on the updated class centers, thereby improving the model's robustness and generalization across different modalities. Extensive experiments on two tasks, five datasets, and nine base OOD algorithms demonstrate that DPU significantly improves OOD detection performance, setting a new state-of-the-art in multimodal OOD detection, with improvements of up to 80 percent in Far-OOD detection. To facilitate accessibility and reproducibility, our code is publicly available on GitHub.
<div id='section'>Paperid: <span id='pid'>351, <a href='https://arxiv.org/pdf/2402.03744.pdf' target='_blank'>https://arxiv.org/pdf/2402.03744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, Mingyuan Tao, Zhihang Fu, Jieping Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03744">INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge hallucination have raised widespread concerns for the security and reliability of deployed LLMs. Previous efforts in detecting hallucinations have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, where the semantic information is inevitably lost during the token-decoding procedure. Thus, we propose to explore the dense semantic information retained within LLMs' \textbf{IN}ternal \textbf{S}tates for halluc\textbf{I}nation \textbf{DE}tection (\textbf{INSIDE}). In particular, a simple yet effective \textbf{EigenScore} metric is proposed to better evaluate responses' self-consistency, which exploits the eigenvalues of responses' covariance matrix to measure the semantic consistency/diversity in the dense embedding space. Furthermore, from the perspective of self-consistent hallucination detection, a test time feature clipping approach is explored to truncate extreme activations in the internal states, which reduces overconfident generations and potentially benefits the detection of overconfident hallucinations. Extensive experiments and ablation studies are performed on several popular LLMs and question-answering (QA) benchmarks, showing the effectiveness of our proposal.
<div id='section'>Paperid: <span id='pid'>352, <a href='https://arxiv.org/pdf/2401.08694.pdf' target='_blank'>https://arxiv.org/pdf/2401.08694.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mauricio Rivera, Jean-FranÃ§ois Godbout, Reihaneh Rabbany, Kellin Pelrine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08694">Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models have emerged as prime candidates to tackle misinformation mitigation. However, existing approaches struggle with hallucinations and overconfident predictions. We propose an uncertainty quantification framework that leverages both direct confidence elicitation and sampled-based consistency methods to provide better calibration for NLP misinformation mitigation solutions. We first investigate the calibration of sample-based consistency methods that exploit distinct features of consistency across sample sizes and stochastic levels. Next, we evaluate the performance and distributional shift of a robust numeric verbalization prompt across single vs. two-step confidence elicitation procedure. We also compare the performance of the same prompt with different versions of GPT and different numerical scales. Finally, we combine the sample-based consistency and verbalized methods to propose a hybrid framework that yields a better uncertainty estimation for GPT models. Overall, our work proposes novel uncertainty quantification methods that will improve the reliability of Large Language Models in misinformation mitigation applications.
<div id='section'>Paperid: <span id='pid'>353, <a href='https://arxiv.org/pdf/2509.25459.pdf' target='_blank'>https://arxiv.org/pdf/2509.25459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haozhou Xu, Dongxia Wu, Matteo Chinazzi, Ruijia Niu, Rose Yu, Yi-An Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25459">SimulRAG: Simulator-based RAG for Grounding LLMs in Long-form Scientific QA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) show promise in solving scientific problems. They can help generate long-form answers for scientific questions, which are crucial for comprehensive understanding of complex phenomena that require detailed explanations spanning multiple interconnected concepts and evidence. However, LLMs often suffer from hallucination, especially in the challenging task of long-form scientific question answering. Retrieval-Augmented Generation (RAG) approaches can ground LLMs by incorporating external knowledge sources to improve trustworthiness. In this context, scientific simulators, which play a vital role in validating hypotheses, offer a particularly promising retrieval source to mitigate hallucination and enhance answer factuality. However, existing RAG approaches cannot be directly applied for scientific simulation-based retrieval due to two fundamental challenges: how to retrieve from scientific simulators, and how to efficiently verify and update long-form answers. To overcome these challenges, we propose the simulator-based RAG framework (SimulRAG) and provide a long-form scientific QA benchmark covering climate science and epidemiology with ground truth verified by both simulations and human annotators. In this framework, we propose a generalized simulator retrieval interface to transform between textual and numerical modalities. We further design a claim-level generation method that utilizes uncertainty estimation scores and simulator boundary assessment (UE+SBA) to efficiently verify and update claims. Extensive experiments demonstrate SimulRAG outperforms traditional RAG baselines by 30.4% in informativeness and 16.3% in factuality. UE+SBA further improves efficiency and quality for claim-level generation.
<div id='section'>Paperid: <span id='pid'>354, <a href='https://arxiv.org/pdf/2505.17048.pdf' target='_blank'>https://arxiv.org/pdf/2505.17048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Agam Shah, Siddhant Sukhani, Huzaifa Pardawala, Saketh Budideti, Riya Bhadani, Rudra Gopal, Siddhartha Somani, Michael Galarnyk, Soungmin Lee, Arnav Hiray, Akshar Ravichandran, Eric Kim, Pranav Aluru, Joshua Zhang, Sebastian Jaskowski, Veer Guda, Meghaj Tarte, Liqin Ye, Spencer Gosden, Rutwik Routu, Rachel Yuh, Sloka Chava, Sahasra Chava, Dylan Patrick Kelly, Aiden Chiang, Harsit Mittal, Sudheer Chava
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17048">Words That Unite The World: A Unified Framework for Deciphering Central Bank Communications Globally</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Central banks around the world play a crucial role in maintaining economic stability. Deciphering policy implications in their communications is essential, especially as misinterpretations can disproportionately impact vulnerable populations. To address this, we introduce the World Central Banks (WCB) dataset, the most comprehensive monetary policy corpus to date, comprising over 380k sentences from 25 central banks across diverse geographic regions, spanning 28 years of historical data. After uniformly sampling 1k sentences per bank (25k total) across all available years, we annotate and review each sentence using dual annotators, disagreement resolutions, and secondary expert reviews. We define three tasks: Stance Detection, Temporal Classification, and Uncertainty Estimation, with each sentence annotated for all three. We benchmark seven Pretrained Language Models (PLMs) and nine Large Language Models (LLMs) (Zero-Shot, Few-Shot, and with annotation guide) on these tasks, running 15,075 benchmarking experiments. We find that a model trained on aggregated data across banks significantly surpasses a model trained on an individual bank's data, confirming the principle "the whole is greater than the sum of its parts." Additionally, rigorous human evaluations, error analyses, and predictive tasks validate our framework's economic utility. Our artifacts are accessible through the HuggingFace and GitHub under the CC-BY-NC-SA 4.0 license.
<div id='section'>Paperid: <span id='pid'>355, <a href='https://arxiv.org/pdf/2502.08445.pdf' target='_blank'>https://arxiv.org/pdf/2502.08445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yining Jiao, Sreekalyani Bhamidi, Huaizhi Qu, Carlton Zdanski, Julia Kimbell, Andrew Prince, Cameron Worden, Samuel Kirse, Christopher Rutter, Benjamin Shields, William Dunn, Jisan Mahmud, Tianlong Chen, Marc Niethammer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08445">LucidAtlas$: Learning Uncertainty-Aware, Covariate-Disentangled, Individualized Atlas Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of this work is to develop principled techniques to extract information from high dimensional data sets with complex dependencies in areas such as medicine that can provide insight into individual as well as population level variation. We develop $\texttt{LucidAtlas}$, an approach that can represent spatially varying information, and can capture the influence of covariates as well as population uncertainty. As a versatile atlas representation, $\texttt{LucidAtlas}$ offers robust capabilities for covariate interpretation, individualized prediction, population trend analysis, and uncertainty estimation, with the flexibility to incorporate prior knowledge. Additionally, we discuss the trustworthiness and potential risks of neural additive models for analyzing dependent covariates and then introduce a marginalization approach to explain the dependence of an individual predictor on the models' response (the atlas). To validate our method, we demonstrate its generalizability on two medical datasets. Our findings underscore the critical role of by-construction interpretable models in advancing scientific discovery. Our code will be publicly available upon acceptance.
<div id='section'>Paperid: <span id='pid'>356, <a href='https://arxiv.org/pdf/2408.12970.pdf' target='_blank'>https://arxiv.org/pdf/2408.12970.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongjian Qiao, Jiafei Lyu, Kechen Jiao, Qi Liu, Xiu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12970">SUMO: Search-Based Uncertainty Estimation for Model-Based Offline Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The performance of offline reinforcement learning (RL) suffers from the limited size and quality of static datasets. Model-based offline RL addresses this issue by generating synthetic samples through a dynamics model to enhance overall performance. To evaluate the reliability of the generated samples, uncertainty estimation methods are often employed. However, model ensemble, the most commonly used uncertainty estimation method, is not always the best choice. In this paper, we propose a \textbf{S}earch-based \textbf{U}ncertainty estimation method for \textbf{M}odel-based \textbf{O}ffline RL (SUMO) as an alternative. SUMO characterizes the uncertainty of synthetic samples by measuring their cross entropy against the in-distribution dataset samples, and uses an efficient search-based method for implementation. In this way, SUMO can achieve trustworthy uncertainty estimation. We integrate SUMO into several model-based offline RL algorithms including MOPO and Adapted MOReL (AMOReL), and provide theoretical analysis for them. Extensive experimental results on D4RL datasets demonstrate that SUMO can provide more accurate uncertainty estimation and boost the performance of base algorithms. These indicate that SUMO could be a better uncertainty estimator for model-based offline RL when used in either reward penalty or trajectory truncation. Our code is available and will be open-source for further research and development.
<div id='section'>Paperid: <span id='pid'>357, <a href='https://arxiv.org/pdf/2408.10885.pdf' target='_blank'>https://arxiv.org/pdf/2408.10885.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomoyasu Nanaumi, Kazuhiko Kawamoto, Hiroshi Kera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10885">Low-Quality Image Detection by Hierarchical VAE</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To make an employee roster, photo album, or training dataset of generative models, one needs to collect high-quality images while dismissing low-quality ones. This study addresses a new task of unsupervised detection of low-quality images. We propose a method that not only detects low-quality images with various types of degradation but also provides visual clues of them based on an observation that partial reconstruction by hierarchical variational autoencoders fails for low-quality images. The experiments show that our method outperforms several unsupervised out-of-distribution detection methods and also gives visual clues for low-quality images that help humans recognize them even in thumbnail view.
<div id='section'>Paperid: <span id='pid'>358, <a href='https://arxiv.org/pdf/2407.05382.pdf' target='_blank'>https://arxiv.org/pdf/2407.05382.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhonghang Liu, Panzhong Lu, Guoyang Xie, Zhichao Lu, Wen-Yan Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.05382">Rethinking Unsupervised Outlier Detection via Multiple Thresholding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the realm of unsupervised image outlier detection, assigning outlier scores holds greater significance than its subsequent task: thresholding for predicting labels. This is because determining the optimal threshold on non-separable outlier score functions is an ill-posed problem. However, the lack of predicted labels not only hiders some real applications of current outlier detectors but also causes these methods not to be enhanced by leveraging the dataset's self-supervision. To advance existing scoring methods, we propose a multiple thresholding (Multi-T) module. It generates two thresholds that isolate inliers and outliers from the unlabelled target dataset, whereas outliers are employed to obtain better feature representation while inliers provide an uncontaminated manifold. Extensive experiments verify that Multi-T can significantly improve proposed outlier scoring methods. Moreover, Multi-T contributes to a naive distance-based method being state-of-the-art.
<div id='section'>Paperid: <span id='pid'>359, <a href='https://arxiv.org/pdf/2404.04865.pdf' target='_blank'>https://arxiv.org/pdf/2404.04865.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Fang, Yixuan Li, Feng Liu, Bo Han, Jie Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04865">On the Learnability of Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms, and corresponding learning theory is still an open problem. To study the generalization of OOD detection, this paper investigates the probably approximately correct (PAC) learning theory of OOD detection that fits the commonly used evaluation metrics in the literature. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we offer theoretical support for representative OOD detection works based on our OOD theory.
<div id='section'>Paperid: <span id='pid'>360, <a href='https://arxiv.org/pdf/2510.00524.pdf' target='_blank'>https://arxiv.org/pdf/2510.00524.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Baoshan Song, Penggao Yan, Xiao Xia, Yihan Zhong, Weisong Wen, Li-Ta Hsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00524">Two stage GNSS outlier detection for factor graph optimization based GNSS-RTK/INS/odometer fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable GNSS positioning in complex environments remains a critical challenge due to non-line-of-sight (NLOS) propagation, multipath effects, and frequent signal blockages. These effects can easily introduce large outliers into the raw pseudo-range measurements, which significantly degrade the performance of global navigation satellite system (GNSS) real-time kinematic (RTK) positioning and limit the effectiveness of tightly coupled GNSS-based integrated navigation system. To address this issue, we propose a two-stage outlier detection method and apply the method in a tightly coupled GNSS-RTK, inertial navigation system (INS), and odometer integration based on factor graph optimization (FGO). In the first stage, Doppler measurements are employed to detect pseudo-range outliers in a GNSS-only manner, since Doppler is less sensitive to multipath and NLOS effects compared with pseudo-range, making it a more stable reference for detecting sudden inconsistencies. In the second stage, pre-integrated inertial measurement units (IMU) and odometer constraints are used to generate predicted double-difference pseudo-range measurements, which enable a more refined identification and rejection of remaining outliers. By combining these two complementary stages, the system achieves improved robustness against both gross pseudo-range errors and degraded satellite measuring quality. The experimental results demonstrate that the two-stage detection framework significantly reduces the impact of pseudo-range outliers, and leads to improved positioning accuracy and consistency compared with representative baseline approaches. In the deep urban canyon test, the outlier mitigation method has limits the RMSE of GNSS-RTK/INS/odometer fusion from 0.52 m to 0.30 m, with 42.3% improvement.
<div id='section'>Paperid: <span id='pid'>361, <a href='https://arxiv.org/pdf/2509.15934.pdf' target='_blank'>https://arxiv.org/pdf/2509.15934.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingdong Wu, Long Yang, Jin Liu, Weiyao Huang, Lehong Wu, Zelin Chen, Daolin Ma, Hao Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15934">UniTac2Pose: A Unified Approach Learned in Simulation for Category-level Visuotactile In-hand Pose Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate estimation of the in-hand pose of an object based on its CAD model is crucial in both industrial applications and everyday tasks, ranging from positioning workpieces and assembling components to seamlessly inserting devices like USB connectors. While existing methods often rely on regression, feature matching, or registration techniques, achieving high precision and generalizability to unseen CAD models remains a significant challenge. In this paper, we propose a novel three-stage framework for in-hand pose estimation. The first stage involves sampling and pre-ranking pose candidates, followed by iterative refinement of these candidates in the second stage. In the final stage, post-ranking is applied to identify the most likely pose candidates. These stages are governed by a unified energy-based diffusion model, which is trained solely on simulated data. This energy model simultaneously generates gradients to refine pose estimates and produces an energy scalar that quantifies the quality of the pose estimates. Additionally, borrowing the idea from the computer vision domain, we incorporate a render-compare architecture within the energy-based score network to significantly enhance sim-to-real performance, as demonstrated by our ablation studies. We conduct comprehensive experiments to show that our method outperforms conventional baselines based on regression, matching, and registration techniques, while also exhibiting strong intra-category generalization to previously unseen CAD models. Moreover, our approach integrates tactile object pose estimation, pose tracking, and uncertainty estimation into a unified framework, enabling robust performance across a variety of real-world conditions.
<div id='section'>Paperid: <span id='pid'>362, <a href='https://arxiv.org/pdf/2505.20236.pdf' target='_blank'>https://arxiv.org/pdf/2505.20236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weihao Xuan, Qingcheng Zeng, Heli Qi, Junjue Wang, Naoto Yokoya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20236">Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is essential for assessing the reliability and trustworthiness of modern AI systems. Among existing approaches, verbalized uncertainty, where models express their confidence through natural language, has emerged as a lightweight and interpretable solution in large language models (LLMs). However, its effectiveness in vision-language models (VLMs) remains insufficiently studied. In this work, we conduct a comprehensive evaluation of verbalized confidence in VLMs, spanning three model categories, four task domains, and three evaluation scenarios. Our results show that current VLMs often display notable miscalibration across diverse tasks and settings. Notably, visual reasoning models (i.e., thinking with images) consistently exhibit better calibration, suggesting that modality-specific reasoning is critical for reliable uncertainty estimation. To further address calibration challenges, we introduce Visual Confidence-Aware Prompting, a two-stage prompting strategy that improves confidence alignment in multimodal settings. Overall, our study highlights the inherent miscalibration in VLMs across modalities. More broadly, our findings underscore the fundamental importance of modality alignment and model faithfulness in advancing reliable multimodal systems.
<div id='section'>Paperid: <span id='pid'>363, <a href='https://arxiv.org/pdf/2501.08005.pdf' target='_blank'>https://arxiv.org/pdf/2501.08005.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francisco Caetano, Christiaan Viviers, Luis A. Zavala-MondragÃ³n, Peter H. N. de With, Fons van der Sommen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08005">DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code is publicly available.
<div id='section'>Paperid: <span id='pid'>364, <a href='https://arxiv.org/pdf/2411.13163.pdf' target='_blank'>https://arxiv.org/pdf/2411.13163.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nabeel Seedat, Caterina Tozzi, Andrea Hita Ardiaca, Mihaela van der Schaar, James Weatherall, Adam Taylor
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13163">Unlocking Historical Clinical Trial Data with ALIGN: A Compositional Large Language Model System for Medical Coding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The reuse of historical clinical trial data has significant potential to accelerate medical research and drug development. However, interoperability challenges, particularly with missing medical codes, hinders effective data integration across studies. While Large Language Models (LLMs) offer a promising solution for automated coding without labeled data, current approaches face challenges on complex coding tasks. We introduce ALIGN, a novel compositional LLM-based system for automated, zero-shot medical coding. ALIGN follows a three-step process: (1) diverse candidate code generation; (2) self-evaluation of codes and (3) confidence scoring and uncertainty estimation enabling human deferral to ensure reliability. We evaluate ALIGN on harmonizing medication terms into Anatomical Therapeutic Chemical (ATC) and medical history terms into Medical Dictionary for Regulatory Activities (MedDRA) codes extracted from 22 immunology trials. ALIGN outperformed the LLM baselines, while also providing capabilities for trustworthy deployment. For MedDRA coding, ALIGN achieved high accuracy across all levels, matching RAG and excelling at the most specific levels (87-90% for HLGT). For ATC coding, ALIGN demonstrated superior performance, particularly at lower hierarchy levels (ATC Level 4), with 72-73% overall accuracy and 86-89% accuracy for common medications, outperforming baselines by 7-22%. ALIGN's uncertainty-based deferral improved accuracy by 17% to 90% accuracy with 30% deferral, notably enhancing performance on uncommon medications. ALIGN achieves this cost-efficiently at \$0.0007 and \$0.02 per code for GPT-4o-mini and GPT-4o, reducing barriers to clinical adoption. ALIGN advances automated medical coding for clinical trial data, contributing to enhanced data interoperability and reusability, positioning it as a promising tool to improve clinical research and accelerate drug development.
<div id='section'>Paperid: <span id='pid'>365, <a href='https://arxiv.org/pdf/2410.08985.pdf' target='_blank'>https://arxiv.org/pdf/2410.08985.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Ni, Yu Wang, Lu Cheng, Erik Blasch, Tyler Derr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08985">Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, Knowledge Graphs (KGs) have been successfully coupled with Large Language Models (LLMs) to mitigate their hallucinations and enhance their reasoning capability, such as in KG-based retrieval-augmented frameworks. However, current KG-LLM frameworks lack rigorous uncertainty estimation, limiting their reliable deployment in high-stakes applications. Directly incorporating uncertainty quantification into KG-LLM frameworks presents challenges due to their complex architectures and the intricate interactions between the knowledge graph and language model components. To address this gap, we propose a new trustworthy KG-LLM framework, Uncertainty Aware Knowledge-Graph Reasoning (UAG), which incorporates uncertainty quantification into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning framework that leverages conformal prediction to provide a theoretical guarantee on the prediction set. To manage the error rate of the multi-step process, we additionally introduce an error rate control module to adjust the error rate within the individual components. Extensive experiments show that our proposed UAG can achieve any pre-defined coverage rate while reducing the prediction set/interval size by 40% on average over the baselines.
<div id='section'>Paperid: <span id='pid'>366, <a href='https://arxiv.org/pdf/2408.15580.pdf' target='_blank'>https://arxiv.org/pdf/2408.15580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinglun Li, Xinyu Zhou, Pinxue Guo, Yixuan Sun, Yiwen Huang, Weifeng Ge, Wenqiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15580">Hierarchical Visual Categories Modeling: A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution inputs for visual recognition models has become critical in safe deep learning. This paper proposes a novel hierarchical visual category modeling scheme to separate out-of-distribution data from in-distribution data through joint representation learning and statistical modeling. We learn a mixture of Gaussian models for each in-distribution category. There are many Gaussian mixture models to model different visual categories. With these Gaussian models, we design an in-distribution score function by aggregating multiple Mahalanobis-based metrics. We don't use any auxiliary outlier data as training samples, which may hurt the generalization ability of out-of-distribution detection algorithms. We split the ImageNet-1k dataset into ten folds randomly. We use one fold as the in-distribution dataset and the others as out-of-distribution datasets to evaluate the proposed method. We also conduct experiments on seven popular benchmarks, including CIFAR, iNaturalist, SUN, Places, Textures, ImageNet-O, and OpenImage-O. Extensive experiments indicate that the proposed method outperforms state-of-the-art algorithms clearly. Meanwhile, we find that our visual representation has a competitive performance when compared with features learned by classical methods. These results demonstrate that the proposed method hasn't weakened the discriminative ability of visual recognition models and keeps high efficiency in detecting out-of-distribution samples.
<div id='section'>Paperid: <span id='pid'>367, <a href='https://arxiv.org/pdf/2408.03746.pdf' target='_blank'>https://arxiv.org/pdf/2408.03746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Xu, Zhiqi Lin, Shigui Li, Min Chen, Junmei Yang, Delu Zeng, John Paisley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.03746">Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Last Layer (BLL) models focus solely on uncertainty in the output layer of neural networks, demonstrating comparable performance to more complex Bayesian models. However, the use of Gaussian priors for last layer weights in Bayesian Last Layer (BLL) models limits their expressive capacity when faced with non-Gaussian, outlier-rich, or high-dimensional datasets. To address this shortfall, we introduce a novel approach that combines diffusion techniques and implicit priors for variational learning of Bayesian last layer weights. This method leverages implicit distributions for modeling weight priors in BLL, coupled with diffusion samplers for approximating true posterior predictions, thereby establishing a comprehensive Bayesian prior and posterior estimation strategy. By delivering an explicit and computationally efficient variational lower bound, our method aims to augment the expressive abilities of BLL models, enhancing model accuracy, calibration, and out-of-distribution detection proficiency. Through detailed exploration and experimental validation, We showcase the method's potential for improving predictive accuracy and uncertainty quantification while ensuring computational efficiency.
<div id='section'>Paperid: <span id='pid'>368, <a href='https://arxiv.org/pdf/2406.08391.pdf' target='_blank'>https://arxiv.org/pdf/2406.08391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanyam Kapoor, Nate Gruver, Manley Roberts, Katherine Collins, Arka Pal, Umang Bhatt, Adrian Weller, Samuel Dooley, Micah Goldblum, Andrew Gordon Wilson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08391">Large Language Models Must Be Taught to Know What They Don't Know</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When using large language models (LLMs) in high-stakes applications, we need to know when we can trust their predictions. Some works argue that prompting high-performance LLMs is sufficient to produce calibrated uncertainties, while others introduce sampling methods that can be prohibitively expensive. In this work, we first argue that prompting on its own is insufficient to achieve good calibration and then show that fine-tuning on a small dataset of correct and incorrect answers can create an uncertainty estimate with good generalization and small computational overhead. We show that a thousand graded examples are sufficient to outperform baseline methods and that training through the features of a model is necessary for good performance and tractable for large open-source models when using LoRA. We also investigate the mechanisms that enable reliable LLM uncertainty estimation, finding that many models can be used as general-purpose uncertainty estimators, applicable not just to their own uncertainties but also the uncertainty of other models. Lastly, we show that uncertainty estimates inform human use of LLMs in human-AI collaborative settings through a user study.
<div id='section'>Paperid: <span id='pid'>369, <a href='https://arxiv.org/pdf/2405.11337.pdf' target='_blank'>https://arxiv.org/pdf/2405.11337.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Schmidt, Leonard Schenk, Leo Schwinn, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11337">A Unified Approach Towards Active Learning and Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When applying deep learning models in open-world scenarios, active learning (AL) strategies are crucial for identifying label candidates from a nearly infinite amount of unlabeled data. In this context, robust out-of-distribution (OOD) detection mechanisms are essential for handling data outside the target distribution of the application. However, current works investigate both problems separately. In this work, we introduce SISOM as the first unified solution for both AL and OOD detection. By leveraging feature space distance metrics SISOM combines the strengths of the currently independent tasks to solve both effectively. We conduct extensive experiments showing the problems arising when migrating between both tasks. In these evaluations SISOM underlined its effectiveness by achieving first place in two of the widely used OpenOOD benchmarks and second place in the remaining one. In AL, SISOM outperforms others and delivers top-1 performance in three benchmarks
<div id='section'>Paperid: <span id='pid'>370, <a href='https://arxiv.org/pdf/2403.10403.pdf' target='_blank'>https://arxiv.org/pdf/2403.10403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marc Lafon, ClÃ©ment Rambour, Nicolas Thome
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10403">Energy Correction Model in the Feature Space for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we study the out-of-distribution (OOD) detection problem through the use of the feature space of a pre-trained deep classifier. We show that learning the density of in-distribution (ID) features with an energy-based models (EBM) leads to competitive detection results. However, we found that the non-mixing of MCMC sampling during the EBM's training undermines its detection performance. To overcome this an energy-based correction of a mixture of class-conditional Gaussian distributions. We obtains favorable results when compared to a strong baseline like the KNN detector on the CIFAR-10/CIFAR-100 OOD detection benchmarks.
<div id='section'>Paperid: <span id='pid'>371, <a href='https://arxiv.org/pdf/2510.02279.pdf' target='_blank'>https://arxiv.org/pdf/2510.02279.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mykyta Ielanskyi, Kajetan Schweighofer, Lukas Aichberger, Sepp Hochreiter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02279">Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hallucinations are a common issue that undermine the reliability of large language models (LLMs). Recent studies have identified a specific subset of hallucinations, known as confabulations, which arise due to predictive uncertainty of LLMs. To detect confabulations, various methods for estimating predictive uncertainty in natural language generation (NLG) have been developed. These methods are typically evaluated by correlating uncertainty estimates with the correctness of generated text, with question-answering (QA) datasets serving as the standard benchmark. However, commonly used approximate correctness functions have substantial disagreement between each other and, consequently, in the ranking of the uncertainty estimation methods. This allows one to inflate the apparent performance of uncertainty estimation methods. We propose using several alternative risk indicators for risk correlation experiments that improve robustness of empirical assessment of UE algorithms for NLG. For QA tasks, we show that marginalizing over multiple LLM-as-a-judge variants leads to reducing the evaluation biases. Furthermore, we explore structured tasks as well as out of distribution and perturbation detection tasks which provide robust and controllable risk indicators. Finally, we propose to use an Elo rating of uncertainty estimation methods to give an objective summarization over extensive evaluation settings.
<div id='section'>Paperid: <span id='pid'>372, <a href='https://arxiv.org/pdf/2506.16590.pdf' target='_blank'>https://arxiv.org/pdf/2506.16590.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeyun Deng, Jasorsi Ghosh, Fiona Xie, Yuzhe Lu, Katia Sycara, Joseph Campbell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16590">Energy-Based Transfer for Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning algorithms often suffer from poor sample efficiency, making them challenging to apply in multi-task or continual learning settings. Efficiency can be improved by transferring knowledge from a previously trained teacher policy to guide exploration in new but related tasks. However, if the new task sufficiently differs from the teacher's training task, the transferred guidance may be sub-optimal and bias exploration toward low-reward behaviors. We propose an energy-based transfer learning method that uses out-of-distribution detection to selectively issue guidance, enabling the teacher to intervene only in states within its training distribution. We theoretically show that energy scores reflect the teacher's state-visitation density and empirically demonstrate improved sample efficiency and performance across both single-task and multi-task settings.
<div id='section'>Paperid: <span id='pid'>373, <a href='https://arxiv.org/pdf/2503.10468.pdf' target='_blank'>https://arxiv.org/pdf/2503.10468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifeng Yang, Lin Zhu, Zewen Sun, Hengyu Liu, Qinying Gu, Nanyang Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10468">OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection remains challenging for deep learning models, particularly when test-time OOD samples differ significantly from training outliers. We propose OODD, a novel test-time OOD detection method that dynamically maintains and updates an OOD dictionary without fine-tuning. Our approach leverages a priority queue-based dictionary that accumulates representative OOD features during testing, combined with an informative inlier sampling strategy for in-distribution (ID) samples. To ensure stable performance during early testing, we propose a dual OOD stabilization mechanism that leverages strategically generated outliers derived from ID data. To our best knowledge, extensive experiments on the OpenOOD benchmark demonstrate that OODD significantly outperforms existing methods, achieving a 26.0% improvement in FPR95 on CIFAR-100 Far OOD detection compared to the state-of-the-art approach. Furthermore, we present an optimized variant of the KNN-based OOD detection framework that achieves a 3x speedup while maintaining detection performance.
<div id='section'>Paperid: <span id='pid'>374, <a href='https://arxiv.org/pdf/2501.03932.pdf' target='_blank'>https://arxiv.org/pdf/2501.03932.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fusang Wang, Hala Djeghim, Nathan Piasco, Moussab Bennehar, Luis RoldÃ£o, Dzmitry Tsishkou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03932">CoStruction: Conjoint radiance field optimization for urban scene reconStruction with limited image overlap</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing the surrounding surface geometry from recorded driving sequences poses a significant challenge due to the limited image overlap and complex topology of urban environments. SoTA neural implicit surface reconstruction methods often struggle in such setting, either failing due to small vision overlap or exhibiting suboptimal performance in accurately reconstructing both the surface and fine structures. To address these limitations, we introduce CoStruction, a novel hybrid implicit surface reconstruction method tailored for large driving sequences with limited camera overlap. CoStruction leverages cross-representation uncertainty estimation to filter out ambiguous geometry caused by limited observations. Our method performs joint optimization of both radiance fields in addition to guided sampling achieving accurate reconstruction of large areas along with fine structures in complex urban scenarios. Extensive evaluation on major driving datasets demonstrates the superiority of our approach in reconstructing large driving sequences with limited image overlap, outperforming concurrent SoTA methods.
<div id='section'>Paperid: <span id='pid'>375, <a href='https://arxiv.org/pdf/2412.15176.pdf' target='_blank'>https://arxiv.org/pdf/2412.15176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Aichberger, Kajetan Schweighofer, Sepp Hochreiter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15176">Rethinking Uncertainty Estimation in Natural Language Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are increasingly employed in real-world applications, driving the need to evaluate the trustworthiness of their generated text. To this end, reliable uncertainty estimation is essential. Since current LLMs generate text autoregressively through a stochastic process, the same prompt can lead to varying outputs. Consequently, leading uncertainty estimation methods generate and analyze multiple output sequences to determine the LLM's uncertainty. However, generating output sequences is computationally expensive, making these methods impractical at scale. In this work, we inspect the theoretical foundations of the leading methods and explore new directions to enhance their computational efficiency. Building on the framework of proper scoring rules, we find that the negative log-likelihood of the most likely output sequence constitutes a theoretically grounded uncertainty measure. To approximate this alternative measure, we propose G-NLL, which has the advantage of being obtained using only a single output sequence generated by greedy decoding. This makes uncertainty estimation more efficient and straightforward, while preserving theoretical rigor. Empirical results demonstrate that G-NLL achieves state-of-the-art performance across various LLMs and tasks. Our work lays the foundation for efficient and reliable uncertainty estimation in natural language generation, challenging the necessity of more computationally involved methods currently leading the field.
<div id='section'>Paperid: <span id='pid'>376, <a href='https://arxiv.org/pdf/2411.08537.pdf' target='_blank'>https://arxiv.org/pdf/2411.08537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabian Bongratz, Markus Karmann, Adrian Holz, Moritz Bonhoeffer, Viktor Neumaier, Sarah Deli, Benita Schmitz-Koep, Claus Zimmer, Christian Sorg, Melissa Thalhammer, Dennis M Hedderich, Christian Wachinger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08537">MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal Lymphatic Vessel Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste products from the human brain. An impairment in their functionality has been associated with aging as well as brain disorders like multiple sclerosis and Alzheimer's disease. However, MLVs have only recently been described for the first time in magnetic resonance imaging (MRI), and their ramified structure renders manual segmentation particularly difficult. Further, as there is no consistent notion of their appearance, human-annotated MLV structures contain a high inter-rater variability that most automatic segmentation methods cannot take into account. In this work, we propose a new rater-aware training scheme for the popular nnU-Net model, and we explore rater-based ensembling strategies for accurate and consistent segmentation of MLVs. This enables us to boost nnU-Net's performance while obtaining explicit predictions in different annotation styles and a rater-based uncertainty estimation. Our final model, MLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to the human reference standard. The model further matches the human inter-rater reliability and replicates age-related associations with MLV volume.
<div id='section'>Paperid: <span id='pid'>377, <a href='https://arxiv.org/pdf/2406.04306.pdf' target='_blank'>https://arxiv.org/pdf/2406.04306.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Aichberger, Kajetan Schweighofer, Mykyta Ielanskyi, Sepp Hochreiter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04306">Semantically Diverse Language Generation for Uncertainty Estimation in Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) can suffer from hallucinations when generating text. These hallucinations impede various applications in society and industry by making LLMs untrustworthy. Current LLMs generate text in an autoregressive fashion by predicting and appending text tokens. When an LLM is uncertain about the semantic meaning of the next tokens to generate, it is likely to start hallucinating. Thus, it has been suggested that hallucinations stem from predictive uncertainty. We introduce Semantically Diverse Language Generation (SDLG) to quantify predictive uncertainty in LLMs. SDLG steers the LLM to generate semantically diverse yet likely alternatives for an initially generated text. This approach provides a precise measure of aleatoric semantic uncertainty, detecting whether the initial text is likely to be hallucinated. Experiments on question-answering tasks demonstrate that SDLG consistently outperforms existing methods while being the most computationally efficient, setting a new standard for uncertainty estimation in LLMs.
<div id='section'>Paperid: <span id='pid'>378, <a href='https://arxiv.org/pdf/2405.16460.pdf' target='_blank'>https://arxiv.org/pdf/2405.16460.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongwei Bran Li, Cheng Ouyang, Tamaz Amiranashvili, Matthew S. Rosen, Bjoern Menze, Juan Eugenio Iglesias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16460">Probabilistic Contrastive Learning with Explicit Concentration on the Hypersphere</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised contrastive learning has predominantly adopted deterministic methods, which are not suited for environments characterized by uncertainty and noise. This paper introduces a new perspective on incorporating uncertainty into contrastive learning by embedding representations within a spherical space, inspired by the von Mises-Fisher distribution (vMF). We introduce an unnormalized form of vMF and leverage the concentration parameter, kappa, as a direct, interpretable measure to quantify uncertainty explicitly. This approach not only provides a probabilistic interpretation of the embedding space but also offers a method to calibrate model confidence against varying levels of data corruption and characteristics. Our empirical results demonstrate that the estimated concentration parameter correlates strongly with the degree of unforeseen data corruption encountered at test time, enables failure analysis, and enhances existing out-of-distribution detection methods.
<div id='section'>Paperid: <span id='pid'>379, <a href='https://arxiv.org/pdf/2405.10757.pdf' target='_blank'>https://arxiv.org/pdf/2405.10757.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Zhang, Minhua Lin, Enyan Dai, Suhang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.10757">Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) have shown remarkable performance in various tasks. However, recent works reveal that GNNs are vulnerable to backdoor attacks. Generally, backdoor attack poisons the graph by attaching backdoor triggers and the target class label to a set of nodes in the training graph. A GNN trained on the poisoned graph will then be misled to predict test nodes attached with trigger to the target class. Despite their effectiveness, our empirical analysis shows that triggers generated by existing methods tend to be out-of-distribution (OOD), which significantly differ from the clean data. Hence, these injected triggers can be easily detected and pruned with widely used outlier detection methods in real-world applications. Therefore, in this paper, we study a novel problem of unnoticeable graph backdoor attacks with in-distribution (ID) triggers. To generate ID triggers, we introduce an OOD detector in conjunction with an adversarial learning strategy to generate the attributes of the triggers within distribution. To ensure a high attack success rate with ID triggers, we introduce novel modules designed to enhance trigger memorization by the victim model trained on poisoned graph. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed method in generating in distribution triggers that can by-pass various defense strategies while maintaining a high attack success rate.
<div id='section'>Paperid: <span id='pid'>380, <a href='https://arxiv.org/pdf/2403.15260.pdf' target='_blank'>https://arxiv.org/pdf/2403.15260.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alvaro Gonzalez-Jimenez, Simone Lionetti, Dena Bazazian, Philippe Gottfrois, Fabian GrÃ¶ger, Marc Pouly, Alexander Navarini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15260">Hyperbolic Metric Learning for Visual Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-Of-Distribution (OOD) detection is critical to deploy deep learning models in safety-critical applications. However, the inherent hierarchical concept structure of visual data, which is instrumental to OOD detection, is often poorly captured by conventional methods based on Euclidean geometry. This work proposes a metric framework that leverages the strengths of Hyperbolic geometry for OOD detection. Inspired by previous works that refine the decision boundary for OOD data with synthetic outliers, we extend this method to Hyperbolic space. Interestingly, we find that synthetic outliers do not benefit OOD detection in Hyperbolic space as they do in Euclidean space. Furthermore we explore the relationship between OOD detection performance and Hyperbolic embedding dimension, addressing practical concerns in resource-constrained environments. Extensive experiments show that our framework improves the FPR95 for OOD detection from 22\% to 15\% and from 49% to 28% on CIFAR-10 and CIFAR-100 respectively compared to Euclidean methods.
<div id='section'>Paperid: <span id='pid'>381, <a href='https://arxiv.org/pdf/2402.17653.pdf' target='_blank'>https://arxiv.org/pdf/2402.17653.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David S. W. Williams, Daniele De Martini, Matthew Gadd, Paul Newman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17653">Mitigating Distributional Shift in Semantic Segmentation via Uncertainty Estimation from Unlabelled Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowing when a trained segmentation model is encountering data that is different to its training data is important. Understanding and mitigating the effects of this play an important part in their application from a performance and assurance perspective - this being a safety concern in applications such as autonomous vehicles (AVs). This work presents a segmentation network that can detect errors caused by challenging test domains without any additional annotation in a single forward pass. As annotation costs limit the diversity of labelled datasets, we use easy-to-obtain, uncurated and unlabelled data to learn to perform uncertainty estimation by selectively enforcing consistency over data augmentation. To this end, a novel segmentation benchmark based on the SAX Dataset is used, which includes labelled test data spanning three autonomous-driving domains, ranging in appearance from dense urban to off-road. The proposed method, named Gamma-SSL, consistently outperforms uncertainty estimation and Out-of-Distribution (OoD) techniques on this difficult benchmark - by up to 10.7% in area under the receiver operating characteristic (ROC) curve and 19.2% in area under the precision-recall (PR) curve in the most challenging of the three scenarios.
<div id='section'>Paperid: <span id='pid'>382, <a href='https://arxiv.org/pdf/2402.17622.pdf' target='_blank'>https://arxiv.org/pdf/2402.17622.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David S. W. Williams, Matthew Gadd, Paul Newman, Daniele De Martini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17622">Masked Gamma-SSL: Learning Uncertainty Estimation via Masked Image Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work proposes a semantic segmentation network that produces high-quality uncertainty estimates in a single forward pass. We exploit general representations from foundation models and unlabelled datasets through a Masked Image Modeling (MIM) approach, which is robust to augmentation hyper-parameters and simpler than previous techniques. For neural networks used in safety-critical applications, bias in the training data can lead to errors; therefore it is crucial to understand a network's limitations at run time and act accordingly. To this end, we test our proposed method on a number of test domains including the SAX Segmentation benchmark, which includes labelled test data from dense urban, rural and off-road driving domains. The proposed method consistently outperforms uncertainty estimation and Out-of-Distribution (OoD) techniques on this difficult benchmark.
<div id='section'>Paperid: <span id='pid'>383, <a href='https://arxiv.org/pdf/2402.07320.pdf' target='_blank'>https://arxiv.org/pdf/2402.07320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ross Greer, Mohan Trivedi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07320">Towards Explainable, Safe Autonomous Driving with Language Embeddings for Novelty Identification and Active Learning: Framework and Experimental Analysis with Real-World Data Sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research explores the integration of language embeddings for active learning in autonomous driving datasets, with a focus on novelty detection. Novelty arises from unexpected scenarios that autonomous vehicles struggle to navigate, necessitating higher-level reasoning abilities. Our proposed method employs language-based representations to identify novel scenes, emphasizing the dual purpose of safety takeover responses and active learning. The research presents a clustering experiment using Contrastive Language-Image Pretrained (CLIP) embeddings to organize datasets and detect novelties. We find that the proposed algorithm effectively isolates novel scenes from a collection of subsets derived from two real-world driving datasets, one vehicle-mounted and one infrastructure-mounted. From the generated clusters, we further present methods for generating textual explanations of elements which differentiate scenes classified as novel from other scenes in the data pool, presenting qualitative examples from the clustered results. Our results demonstrate the effectiveness of language-driven embeddings in identifying novel elements and generating explanations of data, and we further discuss potential applications in safe takeovers, data curation, and multi-task active learning.
<div id='section'>Paperid: <span id='pid'>384, <a href='https://arxiv.org/pdf/2510.22437.pdf' target='_blank'>https://arxiv.org/pdf/2510.22437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>G M Shahariar, Ali Nazari, Erfan Shayegani, Nael Abu-Ghazaleh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.22437">Modeling Hierarchical Thinking in Large Reasoning Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have demonstrated remarkable reasoning abilities when they generate step-by-step solutions, known as chain-of-thought (CoT) reasoning. When trained to using chain-of-thought reasoning examples, the resulting models (called Large Reasoning Models, or LRMs) appear to learn hierarchical thinking strategies similar to those used by humans. However, understanding LRMs emerging reasoning capabilities remains a difficult open problem, with many potential important applications including improving training and understanding robustness. In this paper, we adopt a memoryless Finite State Machine formulation to approximate LRM's emerging hierarchical reasoning dynamics as a structured, interpretable abstraction. We identify a small set of discrete reasoning states including - initialization, deduction, augmentation-strategy, uncertainty-estimation, backtracking, and final-conclusion that capture the high-level states present in the model's reasoning process. By annotating each step of a model's CoT with these states, we can represent the reasoning trajectory as a transition sequence through the state graph. This FSM formulation provides a systematic way to analyze, interpret and visualize how different models approach problems. We describe the FSM model, provide examples of CoT annotations under this scheme, and discuss how it can shed light on differences between available models in their approach to reasoning. Our results demonstrate that this FSM-based analysis reveals distinct reasoning patterns and potential shortcomings, offering a new lens to evaluate and improve LLM reasoning.
<div id='section'>Paperid: <span id='pid'>385, <a href='https://arxiv.org/pdf/2510.05949.pdf' target='_blank'>https://arxiv.org/pdf/2510.05949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Randall Balestriero, Nicolas Ballas, Mike Rabbat, Yann LeCun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05949">Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Joint Embedding Predictive Architectures (JEPAs) learn representations able to solve numerous downstream tasks out-of-the-box. JEPAs combine two objectives: (i) a latent-space prediction term, i.e., the representation of a slightly perturbed sample must be predictable from the original sample's representation, and (ii) an anti-collapse term, i.e., not all samples should have the same representation. While (ii) is often considered as an obvious remedy to representation collapse, we uncover that JEPAs' anti-collapse term does much more--it provably estimates the data density. In short, any successfully trained JEPA can be used to get sample probabilities, e.g., for data curation, outlier detection, or simply for density estimation. Our theoretical finding is agnostic of the dataset and architecture used--in any case one can compute the learned probabilities of sample $x$ efficiently and in closed-form using the model's Jacobian matrix at $x$. Our findings are empirically validated across datasets (synthetic, controlled, and Imagenet) and across different Self Supervised Learning methods falling under the JEPA family (I-JEPA and DINOv2) and on multimodal models, such as MetaCLIP. We denote the method extracting the JEPA learned density as {\bf JEPA-SCORE}.
<div id='section'>Paperid: <span id='pid'>386, <a href='https://arxiv.org/pdf/2508.05732.pdf' target='_blank'>https://arxiv.org/pdf/2508.05732.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pinxuan Li, Bing Cao, Changqing Zhang, Qinghua Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05732">Generalized Few-Shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Few-shot Out-of-Distribution (OOD) detection has emerged as a critical research direction in machine learning for practical deployment. Most existing Few-shot OOD detection methods suffer from insufficient generalization capability for the open world. Due to the few-shot learning paradigm, the OOD detection ability is often overfit to the limited training data itself, thus degrading the performance on generalized data and performing inconsistently across different scenarios. To address this challenge, we proposed a Generalized Few-shot OOD Detection (GOOD) framework, which empowers the general knowledge of the OOD detection model with an auxiliary General Knowledge Model (GKM), instead of directly learning from few-shot data. We proceed to reveal the few-shot OOD detection from a generalization perspective and theoretically derive the Generality-Specificity balance (GS-balance) for OOD detection, which provably reduces the upper bound of generalization error with a general knowledge model. Accordingly, we propose a Knowledge Dynamic Embedding (KDE) mechanism to adaptively modulate the guidance of general knowledge. KDE dynamically aligns the output distributions of the OOD detection model to the general knowledge model based on the Generalized Belief (G-Belief) of GKM, thereby boosting the GS-balance. Experiments on real-world OOD benchmarks demonstrate our superiority. Codes will be available.
<div id='section'>Paperid: <span id='pid'>387, <a href='https://arxiv.org/pdf/2507.23411.pdf' target='_blank'>https://arxiv.org/pdf/2507.23411.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lemar Abdi, Francisco Caetano, Amaan Valiuddin, Christiaan Viviers, Hamdi Joudeh, Fons van der Sommen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.23411">Out-of-Distribution Detection in Medical Imaging via Diffusion Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In medical imaging, unsupervised out-of-distribution (OOD) detection offers an attractive approach for identifying pathological cases with extremely low incidence rates. In contrast to supervised methods, OOD-based approaches function without labels and are inherently robust to data imbalances. Current generative approaches often rely on likelihood estimation or reconstruction error, but these methods can be computationally expensive, unreliable, and require retraining if the inlier data changes. These limitations hinder their ability to distinguish nominal from anomalous inputs efficiently, consistently, and robustly. We propose a reconstruction-free OOD detection method that leverages the forward diffusion trajectories of a Stein score-based denoising diffusion model (SBDDM). By capturing trajectory curvature via the estimated Stein score, our approach enables accurate anomaly scoring with only five diffusion steps. A single SBDDM pre-trained on a large, semantically aligned medical dataset generalizes effectively across multiple Near-OOD and Far-OOD benchmarks, achieving state-of-the-art performance while drastically reducing computational cost during inference. Compared to existing methods, SBDDM achieves a relative improvement of up to 10.43% and 18.10% for Near-OOD and Far-OOD detection, making it a practical building block for real-time, reliable computer-aided diagnosis.
<div id='section'>Paperid: <span id='pid'>388, <a href='https://arxiv.org/pdf/2506.13265.pdf' target='_blank'>https://arxiv.org/pdf/2506.13265.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohit Mohan, Julia Hindel, Florian Drews, Claudius GlÃ¤ser, Daniele Cattaneo, Abhinav Valada
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13265">Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous vehicles that navigate in open-world environments may encounter previously unseen object classes. However, most existing LiDAR panoptic segmentation models rely on closed-set assumptions, failing to detect unknown object instances. In this work, we propose ULOPS, an uncertainty-guided open-set panoptic segmentation framework that leverages Dirichlet-based evidential learning to model predictive uncertainty. Our architecture incorporates separate decoders for semantic segmentation with uncertainty estimation, embedding with prototype association, and instance center prediction. During inference, we leverage uncertainty estimates to identify and segment unknown instances. To strengthen the model's ability to differentiate between known and unknown objects, we introduce three uncertainty-driven loss functions. Uniform Evidence Loss to encourage high uncertainty in unknown regions. Adaptive Uncertainty Separation Loss ensures a consistent difference in uncertainty estimates between known and unknown objects at a global scale. Contrastive Uncertainty Loss refines this separation at the fine-grained level. To evaluate open-set performance, we extend benchmark settings on KITTI-360 and introduce a new open-set evaluation for nuScenes. Extensive experiments demonstrate that ULOPS consistently outperforms existing open-set LiDAR panoptic segmentation methods.
<div id='section'>Paperid: <span id='pid'>389, <a href='https://arxiv.org/pdf/2505.19073.pdf' target='_blank'>https://arxiv.org/pdf/2505.19073.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Li, Jing Long, Muge Qi, Heming Xia, Lei Sha, Peiyi Wang, Zhifang Sui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19073">Towards Harmonized Uncertainty Estimation for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To facilitate robust and trustworthy deployment of large language models (LLMs), it is essential to quantify the reliability of their generations through uncertainty estimation. While recent efforts have made significant advancements by leveraging the internal logic and linguistic features of LLMs to estimate uncertainty scores, our empirical analysis highlights the pitfalls of these methods to strike a harmonized estimation between indication, balance, and calibration, which hinders their broader capability for accurate uncertainty estimation. To address this challenge, we propose CUE (Corrector for Uncertainty Estimation): A straightforward yet effective method that employs a lightweight model trained on data aligned with the target LLM's performance to adjust uncertainty scores. Comprehensive experiments across diverse models and tasks demonstrate its effectiveness, which achieves consistent improvements of up to 60% over existing methods.
<div id='section'>Paperid: <span id='pid'>390, <a href='https://arxiv.org/pdf/2411.04962.pdf' target='_blank'>https://arxiv.org/pdf/2411.04962.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Guanhua Chen, Anoop Mayampurath, Matthew Churpek, Majid Afshar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04962">Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) are being explored for diagnostic decision support, yet their ability to estimate pre-test probabilities, vital for clinical decision-making, remains limited. This study evaluates two LLMs, Mistral-7B and Llama3-70B, using structured electronic health record data on three diagnosis tasks. We examined three current methods of extracting LLM probability estimations and revealed their limitations. We aim to highlight the need for improved techniques in LLM confidence estimation.
<div id='section'>Paperid: <span id='pid'>391, <a href='https://arxiv.org/pdf/2404.12862.pdf' target='_blank'>https://arxiv.org/pdf/2404.12862.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fiona Katharina Ewald, Ludwig Bothmann, Marvin N. Wright, Bernd Bischl, Giuseppe Casalicchio, Gunnar KÃ¶nig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12862">A Guide to Feature Importance Methods for Scientific Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While machine learning (ML) models are increasingly used due to their high predictive power, their use in understanding the data-generating process (DGP) is limited. Understanding the DGP requires insights into feature-target associations, which many ML models cannot directly provide due to their opaque internal mechanisms. Feature importance (FI) methods provide useful insights into the DGP under certain conditions. Since the results of different FI methods have different interpretations, selecting the correct FI method for a concrete use case is crucial and still requires expert knowledge. This paper serves as a comprehensive guide to help understand the different interpretations of global FI methods. Through an extensive review of FI methods and providing new proofs regarding their interpretation, we facilitate a thorough understanding of these methods and formulate concrete recommendations for scientific inference. We conclude by discussing options for FI uncertainty estimation and point to directions for future research aiming at full statistical inference from black-box ML models.
<div id='section'>Paperid: <span id='pid'>392, <a href='https://arxiv.org/pdf/2401.03341.pdf' target='_blank'>https://arxiv.org/pdf/2401.03341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangkai Wu, Longbing Cao, Qi Zhang, Junxian Zhou, Hui Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03341">Weakly Augmented Variational Autoencoder in Time Series Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to their unsupervised training and uncertainty estimation, deep Variational Autoencoders (VAEs) have become powerful tools for reconstruction-based Time Series Anomaly Detection (TSAD). Existing VAE-based TSAD methods, either statistical or deep, tune meta-priors to estimate the likelihood probability for effectively capturing spatiotemporal dependencies in the data. However, these methods confront the challenge of inherent data scarcity, which is often the case in anomaly detection tasks. Such scarcity easily leads to latent holes, discontinuous regions in latent space, resulting in non-robust reconstructions on these discontinuous spaces. We propose a novel generative framework that combines VAEs with self-supervised learning (SSL) to address this issue.
<div id='section'>Paperid: <span id='pid'>393, <a href='https://arxiv.org/pdf/2511.16015.pdf' target='_blank'>https://arxiv.org/pdf/2511.16015.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nimeshika Udayangani, Hadi M. Dolatabadi, Sarah Erfani, Christopher Leckie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.16015">Exploiting Inter-Sample Information for Long-tailed Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) data is essential for safe deployment of deep neural networks (DNNs). This problem becomes particularly challenging in the presence of long-tailed in-distribution (ID) datasets, often leading to high false positive rates (FPR) and low tail-class ID classification accuracy. In this paper, we demonstrate that exploiting inter-sample relationships using a graph-based representation can significantly improve OOD detection in long-tailed recognition of vision datasets. To this end, we use the feature space of a pre-trained model to initialize our graph structure. We account for the differences between the activation layer distribution of the pre-training vs. training data, and actively introduce Gaussianization to alleviate any deviations from a standard normal distribution in the activation layers of the pre-trained model. We then refine this initial graph representation using graph convolutional networks (GCNs) to arrive at a feature space suitable for long-tailed OOD detection. This leads us to address the inferior performance observed in ID tail-classes within existing OOD detection methods. Experiments over three benchmarks CIFAR10-LT, CIFAR100-LT, and ImageNet-LT demonstrate that our method outperforms the state-of-the-art approaches by a large margin in terms of FPR and tail-class ID classification accuracy.
<div id='section'>Paperid: <span id='pid'>394, <a href='https://arxiv.org/pdf/2511.10923.pdf' target='_blank'>https://arxiv.org/pdf/2511.10923.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhixia He, Chen Zhao, Minglai Shao, Xintao Wu, Xujiang Zhao, Dong Li, Qin Tian, Linlin Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.10923">Out-of-Distribution Detection with Positive and Negative Prompt Supervision Using Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is committed to delineating the classification boundaries between in-distribution (ID) and OOD images. Recent advances in vision-language models (VLMs) have demonstrated remarkable OOD detection performance by integrating both visual and textual modalities. In this context, negative prompts are introduced to emphasize the dissimilarity between image features and prompt content. However, these prompts often include a broad range of non-ID features, which may result in suboptimal outcomes due to the capture of overlapping or misleading information. To address this issue, we propose Positive and Negative Prompt Supervision, which encourages negative prompts to capture inter-class features and transfers this semantic knowledge to the visual modality to enhance OOD detection performance. Our method begins with class-specific positive and negative prompts initialized by large language models (LLMs). These prompts are subsequently optimized, with positive prompts focusing on features within each class, while negative prompts highlight features around category boundaries. Additionally, a graph-based architecture is employed to aggregate semantic-aware supervision from the optimized prompt representations and propagate it to the visual branch, thereby enhancing the performance of the energy-based OOD detector. Extensive experiments on two benchmarks, CIFAR-100 and ImageNet-1K, across eight OOD datasets and five different LLMs, demonstrate that our method outperforms state-of-the-art baselines.
<div id='section'>Paperid: <span id='pid'>395, <a href='https://arxiv.org/pdf/2509.05993.pdf' target='_blank'>https://arxiv.org/pdf/2509.05993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junjie Li, Kong Aik Lee, Duc-Tuan Truong, Tianchi Liu, Man-Wai Mak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05993">Xi+: Uncertainty Supervision for Robust Speaker Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There are various factors that can influence the performance of speaker recognition systems, such as emotion, language and other speaker-related or context-related variations. Since individual speech frames do not contribute equally to the utterance-level representation, it is essential to estimate the importance or reliability of each frame. The xi-vector model addresses this by assigning different weights to frames based on uncertainty estimation. However, its uncertainty estimation model is implicitly trained through classification loss alone and does not consider the temporal relationships between frames, which may lead to suboptimal supervision. In this paper, we propose an improved architecture, xi+. Compared to xi-vector, xi+ incorporates a temporal attention module to capture frame-level uncertainty in a context-aware manner. In addition, we introduce a novel loss function, Stochastic Variance Loss, which explicitly supervises the learning of uncertainty. Results demonstrate consistent performance improvements of about 10\% on the VoxCeleb1-O set and 11\% on the NIST SRE 2024 evaluation set.
<div id='section'>Paperid: <span id='pid'>396, <a href='https://arxiv.org/pdf/2508.17690.pdf' target='_blank'>https://arxiv.org/pdf/2508.17690.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danny Wang, Ruihong Qiu, Guangdong Bai, Zi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17690">Text Meets Topology: Rethinking Out-of-distribution Detection in Text-Rich Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection remains challenging in text-rich networks, where textual features intertwine with topological structures. Existing methods primarily address label shifts or rudimentary domain-based splits, overlooking the intricate textual-structural diversity. For example, in social networks, where users represent nodes with textual features (name, bio) while edges indicate friendship status, OOD may stem from the distinct language patterns between bot and normal users. To address this gap, we introduce the TextTopoOOD framework for evaluating detection across diverse OOD scenarios: (1) attribute-level shifts via text augmentations and embedding perturbations; (2) structural shifts through edge rewiring and semantic connections; (3) thematically-guided label shifts; and (4) domain-based divisions. Furthermore, we propose TNT-OOD to model the complex interplay between Text aNd Topology using: 1) a novel cross-attention module to fuse local structure into node-level text representations, and 2) a HyperNetwork to generate node-specific transformation parameters. This aligns topological and semantic features of ID nodes, enhancing ID/OOD distinction across structural and textual shifts. Experiments on 11 datasets across four OOD scenarios demonstrate the nuanced challenge of TextTopoOOD for evaluating OOD detection in text-rich networks.
<div id='section'>Paperid: <span id='pid'>397, <a href='https://arxiv.org/pdf/2508.07625.pdf' target='_blank'>https://arxiv.org/pdf/2508.07625.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junxiao Xue, Xiaozhen Liu, Jie Wang, Xuecheng Wu, Bin Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07625">A Trustworthy Method for Multimodal Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing emotion recognition methods mainly focus on enhancing performance by employing complex deep models, typically resulting in significantly higher model complexity. Although effective, it is also crucial to ensure the reliability of the final decision, especially for noisy, corrupted and out-of-distribution data. To this end, we propose a novel emotion recognition method called trusted emotion recognition (TER), which utilizes uncertainty estimation to calculate the confidence value of predictions. TER combines the results from multiple modalities based on their confidence values to output the trusted predictions. We also provide a new evaluation criterion to assess the reliability of predictions. Specifically, we incorporate trusted precision and trusted recall to determine the trusted threshold and formulate the trusted Acc. and trusted F1 score to evaluate the model's trusted performance. The proposed framework combines the confidence module that accordingly endows the model with reliability and robustness against possible noise or corruption. The extensive experimental results validate the effectiveness of our proposed model. The TER achieves state-of-the-art performance on the Music-video, achieving 82.40% Acc. In terms of trusted performance, TER outperforms other methods on the IEMOCAP and Music-video, achieving trusted F1 scores of 0.7511 and 0.9035, respectively.
<div id='section'>Paperid: <span id='pid'>398, <a href='https://arxiv.org/pdf/2507.08711.pdf' target='_blank'>https://arxiv.org/pdf/2507.08711.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andreas Lolos, Stergios Christodoulidis, Maria Vakalopoulou, Jose Dolz, Aris Moustakas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08711">SGPMIL: Sparse Gaussian Process Multiple Instance Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiple Instance Learning (MIL) offers a natural solution for settings where only coarse, bag-level labels are available, without having access to instance-level annotations. This is usually the case in digital pathology, which consists of gigapixel sized images. While deterministic attention-based MIL approaches achieve strong bag-level performance, they often overlook the uncertainty inherent in instance relevance. In this paper, we address the lack of uncertainty quantification in instance-level attention scores by introducing \textbf{SGPMIL}, a new probabilistic attention-based MIL framework grounded in Sparse Gaussian Processes (SGP). By learning a posterior distribution over attention scores, SGPMIL enables principled uncertainty estimation, resulting in more reliable and calibrated instance relevance maps. Our approach not only preserves competitive bag-level performance but also significantly improves the quality and interpretability of instance-level predictions under uncertainty. SGPMIL extends prior work by introducing feature scaling in the SGP predictive mean function, leading to faster training, improved efficiency, and enhanced instance-level performance. Extensive experiments on multiple well-established digital pathology datasets highlight the effectiveness of our approach across both bag- and instance-level evaluations. Our code will be made publicly available.
<div id='section'>Paperid: <span id='pid'>399, <a href='https://arxiv.org/pdf/2506.13474.pdf' target='_blank'>https://arxiv.org/pdf/2506.13474.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Bani-Harouni, Chantal Pellegrini, Ege Ãzsoy, Matthias Keicher, Nassir Navab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13474">Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clinical decision-making is a dynamic, interactive, and cyclic process where doctors have to repeatedly decide on which clinical action to perform and consider newly uncovered information for diagnosis and treatment. Large Language Models (LLMs) have the potential to support clinicians in this process, however, most applications of LLMs in clinical decision support suffer from one of two limitations: Either they assume the unrealistic scenario of immediate availability of all patient information and do not model the interactive and iterative investigation process, or they restrict themselves to the limited "out-of-the-box" capabilities of large pre-trained models without performing task-specific training. In contrast to this, we propose to model clinical decision-making for diagnosis with a hypothesis-driven uncertainty-aware language agent, LA-CDM, that converges towards a diagnosis via repeatedly requesting and interpreting relevant tests. Using a hybrid training paradigm combining supervised and reinforcement learning, we train LA-CDM with three objectives targeting critical aspects of clinical decision-making: accurate hypothesis generation, hypothesis uncertainty estimation, and efficient decision-making. We evaluate our methodology on MIMIC-CDM, a real-world dataset covering four abdominal diseases containing various clinical tests and show the benefit of explicitly training clinical decision-making for increasing diagnostic performance and efficiency.
<div id='section'>Paperid: <span id='pid'>400, <a href='https://arxiv.org/pdf/2505.22152.pdf' target='_blank'>https://arxiv.org/pdf/2505.22152.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dominik Fuchsgruber, Tom WollschlÃ¤ger, Johannes Bordne, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22152">Uncertainty Estimation for Heterophilic Graphs Through the Lens of Information Theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While uncertainty estimation for graphs recently gained traction, most methods rely on homophily and deteriorate in heterophilic settings. We address this by analyzing message passing neural networks from an information-theoretic perspective and developing a suitable analog to data processing inequality to quantify information throughout the model's layers. In contrast to non-graph domains, information about the node-level prediction target can increase with model depth if a node's features are semantically different from its neighbors. Therefore, on heterophilic graphs, the latent embeddings of an MPNN each provide different information about the data distribution - different from homophilic settings. This reveals that considering all node representations simultaneously is a key design principle for epistemic uncertainty estimation on graphs beyond homophily. We empirically confirm this with a simple post-hoc density estimator on the joint node embedding space that provides state-of-the-art uncertainty on heterophilic graphs. At the same time, it matches prior work on homophilic graphs without explicitly exploiting homophily through post-processing.
<div id='section'>Paperid: <span id='pid'>401, <a href='https://arxiv.org/pdf/2505.11737.pdf' target='_blank'>https://arxiv.org/pdf/2505.11737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tunyu Zhang, Haizhou Shi, Yibin Wang, Hengyi Wang, Xiaoxiao He, Zhuowei Li, Haoxian Chen, Ligong Han, Kai Xu, Huan Zhang, Dimitris Metaxas, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11737">TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Large Language Models (LLMs) have demonstrated impressive capabilities, their output quality remains inconsistent across various application scenarios, making it difficult to identify trustworthy responses, especially in complex tasks requiring multi-step reasoning. In this paper, we propose a Token-level Uncertainty estimation framework for Reasoning (TokUR) that enables LLMs to self-assess and self-improve their responses in mathematical reasoning. Specifically, we introduce low-rank random weight perturbation during LLM decoding to generate predictive distributions for token-level uncertainty estimation, and we aggregate these uncertainty quantities to capture the semantic uncertainty of generated responses. Experiments on mathematical reasoning datasets of varying difficulty demonstrate that TokUR exhibits a strong correlation with answer correctness and model robustness, and the uncertainty signals produced by TokUR can be leveraged to enhance the model's reasoning performance at test time. These results highlight the effectiveness of TokUR as a principled and scalable approach for improving the reliability and interpretability of LLMs in challenging reasoning tasks.
<div id='section'>Paperid: <span id='pid'>402, <a href='https://arxiv.org/pdf/2502.05780.pdf' target='_blank'>https://arxiv.org/pdf/2502.05780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danny Wang, Ruihong Qiu, Guangdong Bai, Zi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05780">GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite graph neural networks' (GNNs) great success in modelling graph-structured data, out-of-distribution (OOD) test instances still pose a great challenge for current GNNs. One of the most effective techniques to detect OOD nodes is to expose the detector model with an additional OOD node-set, yet the extra OOD instances are often difficult to obtain in practice. Recent methods for image data address this problem using OOD data synthesis, typically relying on pre-trained generative models like Stable Diffusion. However, these approaches require vast amounts of additional data, as well as one-for-all pre-trained generative models, which are not available for graph data. Therefore, we propose the GOLD framework for graph OOD detection, an implicit adversarial learning pipeline with synthetic OOD exposure without pre-trained models. The implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model to regularly imitate the in-distribution (ID) embeddings from an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately classify ID data while increasing the energy divergence between the ID embeddings and the generative model's synthetic embeddings. This novel approach implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, effectively simulating exposure to OOD scenarios without auxiliary data. Extensive OOD detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of GOLD without using real OOD data compared with the state-of-the-art OOD exposure and non-exposure baselines.
<div id='section'>Paperid: <span id='pid'>403, <a href='https://arxiv.org/pdf/2412.09718.pdf' target='_blank'>https://arxiv.org/pdf/2412.09718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Morales-Ãlvarez, Stergios Christodoulidis, Maria Vakalopoulou, Pablo Piantanida, Jose Dolz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09718">BayesAdapter: enhanced uncertainty estimation in CLIP few-shot adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The emergence of large pre-trained vision-language models (VLMs) represents a paradigm shift in machine learning, with unprecedented results in a broad span of visual recognition tasks. CLIP, one of the most popular VLMs, has exhibited remarkable zero-shot and transfer learning capabilities in classification. To transfer CLIP to downstream tasks, adapters constitute a parameter-efficient approach that avoids backpropagation through the large model (unlike related prompt learning methods). However, CLIP adapters have been developed to target discriminative performance, and the quality of their uncertainty estimates has been overlooked. In this work we show that the discriminative performance of state-of-the-art CLIP adapters does not always correlate with their uncertainty estimation capabilities, which are essential for a safe deployment in real-world scenarios. We also demonstrate that one of such adapters is obtained through MAP inference from a more general probabilistic framework. Based on this observation we introduce BayesAdapter, which leverages Bayesian inference to estimate a full probability distribution instead of a single point, better capturing the variability inherent in the parameter space. In a comprehensive empirical evaluation we show that our approach obtains high quality uncertainty estimates in the predictions, standing out in calibration and selective classification. Our code will be publicly available upon acceptance of the paper.
<div id='section'>Paperid: <span id='pid'>404, <a href='https://arxiv.org/pdf/2411.14049.pdf' target='_blank'>https://arxiv.org/pdf/2411.14049.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haiyun Yao, Zongbo Han, Huazhu Fu, Xi Peng, Qinghua Hu, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14049">Out-Of-Distribution Detection with Diversification (Provably)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring reliable deployment of machine learning models. Recent advancements focus on utilizing easily accessible auxiliary outliers (e.g., data from the web or other datasets) in training. However, we experimentally reveal that these methods still struggle to generalize their detection capabilities to unknown OOD data, due to the limited diversity of the auxiliary outliers collected. Therefore, we thoroughly examine this problem from the generalization perspective and demonstrate that a more diverse set of auxiliary outliers is essential for enhancing the detection capabilities. However, in practice, it is difficult and costly to collect sufficiently diverse auxiliary outlier data. Therefore, we propose a simple yet practical approach with a theoretical guarantee, termed Diversity-induced Mixup for OOD detection (diverseMix), which enhances the diversity of auxiliary outlier set for training in an efficient way. Extensive experiments show that diverseMix achieves superior performance on commonly used and recent challenging large-scale benchmarks, which further confirm the importance of the diversity of auxiliary outliers.
<div id='section'>Paperid: <span id='pid'>405, <a href='https://arxiv.org/pdf/2408.06742.pdf' target='_blank'>https://arxiv.org/pdf/2408.06742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yina He, Lei Peng, Yongcun Zhang, Juanjuan Weng, Zhiming Luo, Shaozi Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06742">Long-Tailed Out-of-Distribution Detection: Prioritizing Attention to Tail</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current out-of-distribution (OOD) detection methods typically assume balanced in-distribution (ID) data, while most real-world data follow a long-tailed distribution. Previous approaches to long-tailed OOD detection often involve balancing the ID data by reducing the semantics of head classes. However, this reduction can severely affect the classification accuracy of ID data. The main challenge of this task lies in the severe lack of features for tail classes, leading to confusion with OOD data. To tackle this issue, we introduce a novel Prioritizing Attention to Tail (PATT) method using augmentation instead of reduction. Our main intuition involves using a mixture of von Mises-Fisher (vMF) distributions to model the ID data and a temperature scaling module to boost the confidence of ID data. This enables us to generate infinite contrastive pairs, implicitly enhancing the semantics of ID classes while promoting differentiation between ID and OOD data. To further strengthen the detection of OOD data without compromising the classification performance of ID data, we propose feature calibration during the inference phase. By extracting an attention weight from the training set that prioritizes the tail classes and reduces the confidence in OOD data, we improve the OOD detection capability. Extensive experiments verified that our method outperforms the current state-of-the-art methods on various benchmarks.
<div id='section'>Paperid: <span id='pid'>406, <a href='https://arxiv.org/pdf/2406.11675.pdf' target='_blank'>https://arxiv.org/pdf/2406.11675.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yibin Wang, Haizhou Shi, Ligong Han, Dimitris Metaxas, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11675">BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) often suffer from overconfidence during inference, particularly when adapted to downstream domain-specific tasks with limited data. Previous work addresses this issue by employing approximate Bayesian estimation after the LLMs are trained, enabling them to quantify uncertainty. However, such post-training approaches' performance is severely limited by the parameters learned during training. In this paper, we go beyond post-training Bayesianization and propose Bayesian Low-Rank Adaptation by Backpropagation (BLoB), an algorithm that continuously and jointly adjusts both the mean and covariance of LLM parameters throughout the whole fine-tuning process. Our empirical results verify the effectiveness of BLoB in terms of generalization and uncertainty estimation, when evaluated on both in-distribution and out-of-distribution data.
<div id='section'>Paperid: <span id='pid'>407, <a href='https://arxiv.org/pdf/2405.13377.pdf' target='_blank'>https://arxiv.org/pdf/2405.13377.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mostafa Jamshidian, Adam Wittek, Saeideh Sekhavat, Karol Miller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13377">Kinematics of Abdominal Aortic Aneurysms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A search in Scopus within "Article title, Abstract, Keywords" unveils 2,444 documents focused on the biomechanics of Abdominal Aortic Aneurysm (AAA), mostly on AAA wall stress. Only 24 documents investigated AAA kinematics, an important topic that could potentially offer significant insights into the biomechanics of AAA. In this paper, we present an image-based approach for patient-specific, in vivo, and non-invasive AAA kinematic analysis using patient's time-resolved 3D computed tomography angiography (4D-CTA) images, with an objective to measure wall displacement and strain during the cardiac cycle. Our approach relies on regularized deformable image registration for estimating wall displacement, estimation of the local wall strain as the ratio of its normal displacement to its local radius of curvature, and local surface fitting with non-deterministic outlier detection for estimating the wall radius of curvature. We verified our approach against synthetic ground truth image data created by warping a 3D-CTA image of AAA using a realistic displacement field obtained from a finite element biomechanical model. We applied our approach to assess AAA wall displacements and strains in ten patients. Our kinematic analysis results indicated that the 99th percentile of circumferential wall strain, among all patients, ranged from 2.62% to 5.54%, with an average of 4.45% and a standard deviation of 0.87%. We also observed that AAA wall strains are significantly lower than those of a healthy aorta. Our work demonstrates that the registration-based measurement of AAA wall displacements in the direction normal to the wall is sufficiently accurate to reliably estimate strain from these displacements.
<div id='section'>Paperid: <span id='pid'>408, <a href='https://arxiv.org/pdf/2405.01462.pdf' target='_blank'>https://arxiv.org/pdf/2405.01462.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dominik Fuchsgruber, Tom WollschlÃ¤ger, Bertrand Charpentier, Antonio Oroz, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01462">Uncertainty for Active Learning on Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty Sampling is an Active Learning strategy that aims to improve the data efficiency of machine learning models by iteratively acquiring labels of data points with the highest uncertainty. While it has proven effective for independent data its applicability to graphs remains under-explored. We propose the first extensive study of Uncertainty Sampling for node classification: (1) We benchmark Uncertainty Sampling beyond predictive uncertainty and highlight a significant performance gap to other Active Learning strategies. (2) We develop ground-truth Bayesian uncertainty estimates in terms of the data generating process and prove their effectiveness in guiding Uncertainty Sampling toward optimal queries. We confirm our results on synthetic data and design an approximate approach that consistently outperforms other uncertainty estimators on real datasets. (3) Based on this analysis, we relate pitfalls in modeling uncertainty to existing methods. Our analysis enables and informs the development of principled uncertainty estimation on graphs.
<div id='section'>Paperid: <span id='pid'>409, <a href='https://arxiv.org/pdf/2510.07569.pdf' target='_blank'>https://arxiv.org/pdf/2510.07569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prabhant Singh, Pieter Gijsbers, Elif Ceren Gok Yildirim, Murat Onur Yildirim, Joaquin Vanschoren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.07569">Automated Machine Learning for Unsupervised Tabular Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present LOTUS (Learning to Learn with Optimal Transport for Unsupervised Scenarios), a simple yet effective method to perform model selection for multiple unsupervised machine learning(ML) tasks such as outlier detection and clustering. Our intuition behind this work is that a machine learning pipeline will perform well in a new dataset if it previously worked well on datasets with a similar underlying data distribution. We use Optimal Transport distances to find this similarity between unlabeled tabular datasets and recommend machine learning pipelines with one unified single method on two downstream unsupervised tasks: outlier detection and clustering. We present the effectiveness of our approach with experiments against strong baselines and show that LOTUS is a very promising first step toward model selection for multiple unsupervised ML tasks.
<div id='section'>Paperid: <span id='pid'>410, <a href='https://arxiv.org/pdf/2509.15141.pdf' target='_blank'>https://arxiv.org/pdf/2509.15141.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yigit E. Yildirim, Samet Demir, Zafer Dogan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15141">Benefits of Online Tilted Empirical Risk Minimization: A Case Study of Outlier Detection and Robust Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Empirical Risk Minimization (ERM) is a foundational framework for supervised learning but primarily optimizes average-case performance, often neglecting fairness and robustness considerations. Tilted Empirical Risk Minimization (TERM) extends ERM by introducing an exponential tilt hyperparameter $t$ to balance average-case accuracy with worst-case fairness and robustness. However, in online or streaming settings where data arrive one sample at a time, the classical TERM objective degenerates to standard ERM, losing tilt sensitivity. We address this limitation by proposing an online TERM formulation that removes the logarithm from the classical objective, preserving tilt effects without additional computational or memory overhead. This formulation enables a continuous trade-off controlled by $t$, smoothly interpolating between ERM ($t \to 0$), fairness emphasis ($t > 0$), and robustness to outliers ($t < 0$). We empirically validate online TERM on two representative streaming tasks: robust linear regression with adversarial outliers and minority-class detection in binary classification. Our results demonstrate that negative tilting effectively suppresses outlier influence, while positive tilting improves recall with minimal impact on precision, all at per-sample computational cost equivalent to ERM. Online TERM thus recovers the full robustness-fairness spectrum of classical TERM in an efficient single-sample learning regime.
<div id='section'>Paperid: <span id='pid'>411, <a href='https://arxiv.org/pdf/2508.17174.pdf' target='_blank'>https://arxiv.org/pdf/2508.17174.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeng-Lin Li, Ming-Ching Chang, Wei-Chao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17174">Sharpness-Aware Geometric Defense for Robust Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection ensures safe and reliable model deployment. Contemporary OOD algorithms using geometry projection can detect OOD or adversarial samples from clean in-distribution (ID) samples. However, this setting regards adversarial ID samples as OOD, leading to incorrect OOD predictions. Existing efforts on OOD detection with ID and OOD data under attacks are minimal. In this paper, we develop a robust OOD detection method that distinguishes adversarial ID samples from OOD ones. The sharp loss landscape created by adversarial training hinders model convergence, impacting the latent embedding quality for OOD score calculation. Therefore, we introduce a {\bf Sharpness-aware Geometric Defense (SaGD)} framework to smooth out the rugged adversarial loss landscape in the projected latent geometry. Enhanced geometric embedding convergence enables accurate ID data characterization, benefiting OOD detection against adversarial attacks. We use Jitter-based perturbation in adversarial training to extend the defense ability against unseen attacks. Our SaGD framework significantly improves FPR and AUC over the state-of-the-art defense approaches in differentiating CIFAR-100 from six other OOD datasets under various attacks. We further examine the effects of perturbations at various adversarial training levels, revealing the relationship between the sharp loss landscape and adversarial OOD detection.
<div id='section'>Paperid: <span id='pid'>412, <a href='https://arxiv.org/pdf/2506.21892.pdf' target='_blank'>https://arxiv.org/pdf/2506.21892.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Goodge, Xun Xu, Bryan Hooi, Wee Siong Ng, Jingyi Liao, Yongyi Su, Xulei Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21892">SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As point cloud data increases in prevalence in a variety of applications, the ability to detect out-of-distribution (OOD) point cloud objects becomes critical for ensuring model safety and reliability. However, this problem remains under-explored in existing research. Inspired by success in the image domain, we propose to exploit advances in 3D vision-language models (3D VLMs) for OOD detection in point cloud objects. However, a major challenge is that point cloud datasets used to pre-train 3D VLMs are drastically smaller in size and object diversity than their image-based counterparts. Critically, they often contain exclusively computer-designed synthetic objects. This leads to a substantial domain shift when the model is transferred to practical tasks involving real objects scanned from the physical environment. In this paper, our empirical experiments show that synthetic-to-real domain shift significantly degrades the alignment of point cloud with their associated text embeddings in the 3D VLM latent space, hindering downstream performance. To address this, we propose a novel methodology called SODA which improves the detection of OOD point clouds through a neighborhood-based score propagation scheme. SODA is inference-based, requires no additional model training, and achieves state-of-the-art performance over existing approaches across datasets and problem settings.
<div id='section'>Paperid: <span id='pid'>413, <a href='https://arxiv.org/pdf/2504.11944.pdf' target='_blank'>https://arxiv.org/pdf/2504.11944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuyang Chen, Guojian Wang, Keyu Yan, Lin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11944">VIPO: Value Function Inconsistency Penalized Offline Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline reinforcement learning (RL) learns effective policies from pre-collected datasets, offering a practical solution for applications where online interactions are risky or costly. Model-based approaches are particularly advantageous for offline RL, owing to their data efficiency and generalizability. However, due to inherent model errors, model-based methods often artificially introduce conservatism guided by heuristic uncertainty estimation, which can be unreliable. In this paper, we introduce VIPO, a novel model-based offline RL algorithm that incorporates self-supervised feedback from value estimation to enhance model training. Specifically, the model is learned by additionally minimizing the inconsistency between the value learned directly from the offline data and the one estimated from the model. We perform comprehensive evaluations from multiple perspectives to show that VIPO can learn a highly accurate model efficiently and consistently outperform existing methods. It offers a general framework that can be readily integrated into existing model-based offline RL algorithms to systematically enhance model accuracy. As a result, VIPO achieves state-of-the-art performance on almost all tasks in both D4RL and NeoRL benchmarks.
<div id='section'>Paperid: <span id='pid'>414, <a href='https://arxiv.org/pdf/2503.23775.pdf' target='_blank'>https://arxiv.org/pdf/2503.23775.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Heublein, Nisha L. Raichur, Tobias Feigl, Tobias Brieger, Fin Heuer, Lennart Asbach, Alexander RÃ¼gamer, Felix Ott
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23775">Evaluation of (Un-)Supervised Machine Learning Methods for GNSS Interference Classification with Real-World Data Discrepancies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The accuracy and reliability of vehicle localization on roads are crucial for applications such as self-driving cars, toll systems, and digital tachographs. To achieve accurate positioning, vehicles typically use global navigation satellite system (GNSS) receivers to validate their absolute positions. However, GNSS-based positioning can be compromised by interference signals, necessitating the identification, classification, determination of purpose, and localization of such interference to mitigate or eliminate it. Recent approaches based on machine learning (ML) have shown superior performance in monitoring interference. However, their feasibility in real-world applications and environments has yet to be assessed. Effective implementation of ML techniques requires training datasets that incorporate realistic interference signals, including real-world noise and potential multipath effects that may occur between transmitter, receiver, and satellite in the operational area. Additionally, these datasets require reference labels. Creating such datasets is often challenging due to legal restrictions, as causing interference to GNSS sources is strictly prohibited. Consequently, the performance of ML-based methods in practical applications remains unclear. To address this gap, we describe a series of large-scale measurement campaigns conducted in real-world settings at two highway locations in Germany and the Seetal Alps in Austria, and in large-scale controlled indoor environments. We evaluate the latest supervised ML-based methods to report on their performance in real-world settings and present the applicability of pseudo-labeling for unsupervised learning. We demonstrate the challenges of combining datasets due to data discrepancies and evaluate outlier detection, domain adaptation, and data augmentation techniques to present the models' capabilities to adapt to changes in the datasets.
<div id='section'>Paperid: <span id='pid'>415, <a href='https://arxiv.org/pdf/2503.12847.pdf' target='_blank'>https://arxiv.org/pdf/2503.12847.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Liu, Peike Li, Liying Yang, Dadong Wang, Lincheng Li, Xin Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.12847">Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately localizing audible objects based on audio-visual cues is the core objective of audio-visual segmentation. Most previous methods emphasize spatial or temporal multi-modal modeling, yet overlook challenges from ambiguous audio-visual correspondences such as nearby visually similar but acoustically different objects and frequent shifts in objects' sounding status. Consequently, they may struggle to reliably correlate audio and visual cues, leading to over- or under-segmentation. To address these limitations, we propose a novel framework with two primary components: an audio-guided modality alignment (AMA) module and an uncertainty estimation (UE) module. Instead of indiscriminately correlating audio-visual cues through a global attention mechanism, AMA performs audio-visual interactions within multiple groups and consolidates group features into compact representations based on their responsiveness to audio cues, effectively directing the model's attention to audio-relevant areas. Leveraging contrastive learning, AMA further distinguishes sounding regions from silent areas by treating features with strong audio responses as positive samples and weaker responses as negatives. Additionally, UE integrates spatial and temporal information to identify high-uncertainty regions caused by frequent changes in sound state, reducing prediction errors by lowering confidence in these areas. Experimental results demonstrate that our approach achieves superior accuracy compared to existing state-of-the-art methods, particularly in challenging scenarios where traditional approaches struggle to maintain reliable segmentation.
<div id='section'>Paperid: <span id='pid'>416, <a href='https://arxiv.org/pdf/2502.14429.pdf' target='_blank'>https://arxiv.org/pdf/2502.14429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>VilÃ©m Zouhar, Maike ZÃ¼fle, Beni Egressy, Julius Cheng, Mrinmaya Sachan, Jan Niehues
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14429">Early-Exit and Instant Confidence Translation Quality Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quality estimation is omnipresent in machine translation, for both evaluation and generation. Unfortunately, quality estimation models are often opaque and computationally expensive, making them impractical to be part of large-scale pipelines. In this work, we tackle two connected challenges: (1) reducing the cost of quality estimation at scale, and (2) developing an inexpensive uncertainty estimation method for quality estimation. To address the latter, we introduce Instant Confidence COMET, an uncertainty-aware quality estimation model that matches the performance of previous approaches at a fraction of their costs. We extend this to Early-Exit COMET, a quality estimation model that can compute quality scores and associated confidences already at early model layers, allowing us to early-exit computations and reduce evaluation costs. We also apply our model to machine translation reranking. We combine Early-Exit COMET with an upper confidence bound bandit algorithm to find the best candidate from a large pool without having to run the full evaluation model on all candidates. In both cases (evaluation and reranking) our methods reduce the required compute by 50% with very little degradation in performance. Finally, we show how Instant Confidence COMET can be used to decide which translations a human evaluator should score rather than relying on the COMET score.
<div id='section'>Paperid: <span id='pid'>417, <a href='https://arxiv.org/pdf/2410.15326.pdf' target='_blank'>https://arxiv.org/pdf/2410.15326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hsiu-Yuan Huang, Yutong Yang, Zhaoxi Zhang, Sanwoo Lee, Yunfang Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15326">A Survey of Uncertainty Estimation in LLMs: Theory Meets Practice</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As large language models (LLMs) continue to evolve, understanding and quantifying the uncertainty in their predictions is critical for enhancing application credibility. However, the existing literature relevant to LLM uncertainty estimation often relies on heuristic approaches, lacking systematic classification of the methods. In this survey, we clarify the definitions of uncertainty and confidence, highlighting their distinctions and implications for model predictions. On this basis, we integrate theoretical perspectives, including Bayesian inference, information theory, and ensemble strategies, to categorize various classes of uncertainty estimation methods derived from heuristic approaches. Additionally, we address challenges that arise when applying these methods to LLMs. We also explore techniques for incorporating uncertainty into diverse applications, including out-of-distribution detection, data annotation, and question clarification. Our review provides insights into uncertainty estimation from both definitional and theoretical angles, contributing to a comprehensive understanding of this critical aspect in LLMs. We aim to inspire the development of more reliable and effective uncertainty estimation approaches for LLMs in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>418, <a href='https://arxiv.org/pdf/2410.07617.pdf' target='_blank'>https://arxiv.org/pdf/2410.07617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ao Ke, Wenlong Chen, Chuanwen Feng, Yukun Cao, Xike Xie, S. Kevin Zhou, Lei Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07617">Prototype-based Optimal Transport for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting Out-of-Distribution (OOD) inputs is crucial for improving the reliability of deep neural networks in the real-world deployment. In this paper, inspired by the inherent distribution shift between ID and OOD data, we propose a novel method that leverages optimal transport to measure the distribution discrepancy between test inputs and ID prototypes. The resulting transport costs are used to quantify the individual contribution of each test input to the overall discrepancy, serving as a desirable measure for OOD detection. To address the issue that solely relying on the transport costs to ID prototypes is inadequate for identifying OOD inputs closer to ID data, we generate virtual outliers to approximate the OOD region via linear extrapolation. By combining the transport costs to ID prototypes with the costs to virtual outliers, the detection of OOD data near ID data is emphasized, thereby enhancing the distinction between ID and OOD inputs. Experiments demonstrate the superiority of our method over state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>419, <a href='https://arxiv.org/pdf/2410.01534.pdf' target='_blank'>https://arxiv.org/pdf/2410.01534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Tu, Weijian Deng, Tom Gedeon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01534">Toward a Holistic Evaluation of Robustness in CLIP Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contrastive Language-Image Pre-training (CLIP) models have shown significant potential, particularly in zero-shot classification across diverse distribution shifts. Building on existing evaluations of overall classification robustness, this work aims to provide a more comprehensive assessment of CLIP by introducing several new perspectives. First, we investigate their robustness to variations in specific visual factors. Second, we assess two critical safety objectives--confidence uncertainty and out-of-distribution detection--beyond mere classification accuracy. Third, we evaluate the finesse with which CLIP models bridge the image and text modalities. Fourth, we extend our examination to 3D awareness in CLIP models, moving beyond traditional 2D image understanding. Finally, we explore the interaction between vision and language encoders within modern large multimodal models (LMMs) that utilize CLIP as the visual backbone, focusing on how this interaction impacts classification robustness. In each aspect, we consider the impact of six factors on CLIP models: model architecture, training distribution, training set size, fine-tuning, contrastive loss, and test-time prompts. Our study uncovers several previously unknown insights into CLIP. For instance, the architecture of the visual encoder in CLIP plays a significant role in their robustness against 3D corruption. CLIP models tend to exhibit a bias towards shape when making predictions. Moreover, this bias tends to diminish after fine-tuning on ImageNet. Vision-language models like LLaVA, leveraging the CLIP vision encoder, could exhibit benefits in classification performance for challenging categories over CLIP alone. Our findings are poised to offer valuable guidance for enhancing the robustness and reliability of CLIP models.
<div id='section'>Paperid: <span id='pid'>420, <a href='https://arxiv.org/pdf/2409.12479.pdf' target='_blank'>https://arxiv.org/pdf/2409.12479.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeng-Lin Li, Ming-Ching Chang, Wei-Chao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.12479">Learning Multi-Manifold Embedding for Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is crucial for trustworthy AI in real-world applications. Leveraging recent advances in representation learning and latent embeddings, Various scoring algorithms estimate distributions beyond the training data. However, a single embedding space falls short in characterizing in-distribution data and defending against diverse OOD conditions. This paper introduces a novel Multi-Manifold Embedding Learning (MMEL) framework, optimizing hypersphere and hyperbolic spaces jointly for enhanced OOD detection. MMEL generates representative embeddings and employs a prototype-aware scoring function to differentiate OOD samples. It operates with very few OOD samples and requires no model retraining. Experiments on six open datasets demonstrate MMEL's significant reduction in FPR while maintaining a high AUC compared to state-of-the-art distance-based OOD detection methods. We analyze the effects of learning multiple manifolds and visualize OOD score distributions across datasets. Notably, enrolling ten OOD samples without retraining achieves comparable FPR and AUC to modern outlier exposure methods using 80 million outlier samples for model training.
<div id='section'>Paperid: <span id='pid'>421, <a href='https://arxiv.org/pdf/2402.07417.pdf' target='_blank'>https://arxiv.org/pdf/2402.07417.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Tu, Weijian Deng, Dylan Campbell, Stephen Gould, Tom Gedeon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07417">An Empirical Study Into What Matters for Calibrating Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) have emerged as the dominant approach for zero-shot recognition, adept at handling diverse scenarios and significant distribution changes. However, their deployment in risk-sensitive areas requires a deeper understanding of their uncertainty estimation capabilities, a relatively uncharted area. In this study, we explore the calibration properties of VLMs across different architectures, datasets, and training strategies. In particular, we analyze the uncertainty estimation performance of VLMs when calibrated in one domain, label set or hierarchy level, and tested in a different one. Our findings reveal that while VLMs are not inherently calibrated for uncertainty, temperature scaling significantly and consistently improves calibration, even across shifts in distribution and changes in label set. Moreover, VLMs can be calibrated with a very small set of examples. Through detailed experimentation, we highlight the potential applications and importance of our insights, aiming for more reliable and effective use of VLMs in critical, real-world scenarios.
<div id='section'>Paperid: <span id='pid'>422, <a href='https://arxiv.org/pdf/2509.02273.pdf' target='_blank'>https://arxiv.org/pdf/2509.02273.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhao Wang, Yingrui Ji, Yu Meng, Yunjian Zhang, Yao Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02273">RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection represents a critical challenge in remote sensing applications, where reliable identification of novel or anomalous patterns is essential for autonomous monitoring, disaster response, and environmental assessment. Despite remarkable progress in OOD detection for natural images, existing methods and benchmarks remain poorly suited to remote sensing imagery due to data scarcity, complex multi-scale scene structures, and pronounced distribution shifts. To this end, we propose RS-OOD, a novel framework that leverages remote sensing-specific vision-language modeling to enable robust few-shot OOD detection. Our approach introduces three key innovations: spatial feature enhancement that improved scene discrimination, a dual-prompt alignment mechanism that cross-verifies scene context against fine-grained semantics for spatial-semantic consistency, and a confidence-guided self-training loop that dynamically mines pseudo-labels to expand training data without manual annotation. RS-OOD consistently outperforms existing methods across multiple remote sensing benchmarks and enables efficient adaptation with minimal labeled data, demonstrating the critical value of spatial-semantic integration.
<div id='section'>Paperid: <span id='pid'>423, <a href='https://arxiv.org/pdf/2508.16832.pdf' target='_blank'>https://arxiv.org/pdf/2508.16832.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yannik Hahn, Jan Voets, Antonin Koenigsfeld, Hasan Tercan, Tobias Meisen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16832">Out of Distribution Detection for Efficient Continual Learning in Quality Prediction for Arc Welding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern manufacturing relies heavily on fusion welding processes, including gas metal arc welding (GMAW). Despite significant advances in machine learning-based quality prediction, current models exhibit critical limitations when confronted with the inherent distribution shifts that occur in dynamic manufacturing environments. In this work, we extend the VQ-VAE Transformer architecture - previously demonstrating state-of-the-art performance in weld quality prediction - by leveraging its autoregressive loss as a reliable out-of-distribution (OOD) detection mechanism. Our approach exhibits superior performance compared to conventional reconstruction methods, embedding error-based techniques, and other established baselines. By integrating OOD detection with continual learning strategies, we optimize model adaptation, triggering updates only when necessary and thereby minimizing costly labeling requirements. We introduce a novel quantitative metric that simultaneously evaluates OOD detection capability while interpreting in-distribution performance. Experimental validation in real-world welding scenarios demonstrates that our framework effectively maintains robust quality prediction capabilities across significant distribution shifts, addressing critical challenges in dynamic manufacturing environments where process parameters frequently change. This research makes a substantial contribution to applied artificial intelligence by providing an explainable and at the same time adaptive solution for quality assurance in dynamic manufacturing processes - a crucial step towards robust, practical AI systems in the industrial environment.
<div id='section'>Paperid: <span id='pid'>424, <a href='https://arxiv.org/pdf/2507.14180.pdf' target='_blank'>https://arxiv.org/pdf/2507.14180.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14180">Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In line with the AI-native 6G vision, explainability and robustness are crucial for building trust and ensuring reliable performance in millimeter-wave (mmWave) systems. Efficient beam alignment is essential for initial access, but deep learning (DL) solutions face challenges, including high data collection overhead, hardware constraints, lack of explainability, and susceptibility to adversarial attacks. This paper proposes a robust and explainable DL-based beam alignment engine (BAE) for mmWave multiple-input multiple output (MIMO) systems. The BAE uses received signal strength indicator (RSSI) measurements from wide beams to predict the best narrow beam, reducing the overhead of exhaustive beam sweeping. To overcome the challenge of real-world data collection, this work leverages a site-specific digital twin (DT) to generate synthetic channel data closely resembling real-world environments. A model refinement via transfer learning is proposed to fine-tune the pre-trained model residing in the DT with minimal real-world data, effectively bridging mismatches between the digital replica and real-world environments. To reduce beam training overhead and enhance transparency, the framework uses deep Shapley additive explanations (SHAP) to rank input features by importance, prioritizing key spatial directions and minimizing beam sweeping. It also incorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a credibility metric for detecting out-of-distribution inputs and ensuring robust, transparent decision-making. Experimental results show that the proposed framework reduces real-world data needs by 70%, beam training overhead by 62%, and improves outlier detection robustness by up to 8.5x, achieving near-optimal spectral efficiency and transparent decision making compared to traditional softmax based DL models.
<div id='section'>Paperid: <span id='pid'>425, <a href='https://arxiv.org/pdf/2507.04385.pdf' target='_blank'>https://arxiv.org/pdf/2507.04385.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steven Braun, Sahil Sidheekh, Antonio Vergari, Martin Mundt, Sriraam Natarajan, Kristian Kersting
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04385">Tractable Representation Learning with Probabilistic Circuits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Probabilistic circuits (PCs) are powerful probabilistic models that enable exact and tractable inference, making them highly suitable for probabilistic reasoning and inference tasks. While dominant in neural networks, representation learning with PCs remains underexplored, with prior approaches relying on external neural embeddings or activation-based encodings. To address this gap, we introduce autoencoding probabilistic circuits (APCs), a novel framework leveraging the tractability of PCs to model probabilistic embeddings explicitly. APCs extend PCs by jointly modeling data and embeddings, obtaining embedding representations through tractable probabilistic inference. The PC encoder allows the framework to natively handle arbitrary missing data and is seamlessly integrated with a neural decoder in a hybrid, end-to-end trainable architecture enabled by differentiable sampling. Our empirical evaluation demonstrates that APCs outperform existing PC-based autoencoding methods in reconstruction quality, generate embeddings competitive with, and exhibit superior robustness in handling missing data compared to neural autoencoders. These results highlight APCs as a powerful and flexible representation learning method that exploits the probabilistic inference capabilities of PCs, showing promising directions for robust inference, out-of-distribution detection, and knowledge distillation.
<div id='section'>Paperid: <span id='pid'>426, <a href='https://arxiv.org/pdf/2505.03774.pdf' target='_blank'>https://arxiv.org/pdf/2505.03774.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Yin, Chen Zhao, Xiaoyan Liu, Minglai Shao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03774">Out-of-Distribution Detection in Heterogeneous Graphs via Energy Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph neural networks (GNNs) are proven effective in extracting complex node and structural information from graph data. While current GNNs perform well in node classification tasks within in-distribution (ID) settings, real-world scenarios often present distribution shifts, leading to the presence of out-of-distribution (OOD) nodes. OOD detection in graphs is a crucial and challenging task. Most existing research focuses on homogeneous graphs, but real-world graphs are often heterogeneous, consisting of diverse node and edge types. This heterogeneity adds complexity and enriches the informational content. To the best of our knowledge, OOD detection in heterogeneous graphs remains an underexplored area. In this context, we propose a novel methodology for OOD detection in heterogeneous graphs (OODHG) that aims to achieve two main objectives: 1) detecting OOD nodes and 2) classifying all ID nodes based on the first task's results. Specifically, we learn representations for each node in the heterogeneous graph, calculate energy values to determine whether nodes are OOD, and then classify ID nodes. To leverage the structural information of heterogeneous graphs, we introduce a meta-path-based energy propagation mechanism and an energy constraint to enhance the distinction between ID and OOD nodes. Extensive experimental findings substantiate the simplicity and effectiveness of OODHG, demonstrating its superiority over baseline models in OOD detection tasks and its accuracy in ID node classification.
<div id='section'>Paperid: <span id='pid'>427, <a href='https://arxiv.org/pdf/2504.16680.pdf' target='_blank'>https://arxiv.org/pdf/2504.16680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhao Li, Andreas Krause, Marco Hutter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16680">Offline Robotic World Model: Learning Robotic Policies without a Physics Simulator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement Learning (RL) has demonstrated impressive capabilities in robotic control but remains challenging due to high sample complexity, safety concerns, and the sim-to-real gap. While offline RL eliminates the need for risky real-world exploration by learning from pre-collected data, it suffers from distributional shift, limiting policy generalization. Model-Based RL (MBRL) addresses this by leveraging predictive models for synthetic rollouts, yet existing approaches often lack robust uncertainty estimation, leading to compounding errors in offline settings. We introduce Offline Robotic World Model (RWM-O), a model-based approach that explicitly estimates epistemic uncertainty to improve policy learning without reliance on a physics simulator. By integrating these uncertainty estimates into policy optimization, our approach penalizes unreliable transitions, reducing overfitting to model errors and enhancing stability. Experimental results show that RWM-O improves generalization and safety, enabling policy learning purely from real-world data and advancing scalable, data-efficient RL for robotics.
<div id='section'>Paperid: <span id='pid'>428, <a href='https://arxiv.org/pdf/2502.18285.pdf' target='_blank'>https://arxiv.org/pdf/2502.18285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Morteza Rohanian, Roya M. HÃ¼ppi, Farhad Nooralahzadeh, Noemi Dannecker, Yves Pauli, Werner Surbeck, Iris Sommer, Wolfram Hinzen, Nicolas Langer, Michael Krauthammer, Philipp Homan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18285">Uncertainty Modeling in Multimodal Speech Analysis Across the Psychosis Spectrum</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Capturing subtle speech disruptions across the psychosis spectrum is challenging because of the inherent variability in speech patterns. This variability reflects individual differences and the fluctuating nature of symptoms in both clinical and non-clinical populations. Accounting for uncertainty in speech data is essential for predicting symptom severity and improving diagnostic precision. Speech disruptions characteristic of psychosis appear across the spectrum, including in non-clinical individuals. We develop an uncertainty-aware model integrating acoustic and linguistic features to predict symptom severity and psychosis-related traits. Quantifying uncertainty in specific modalities allows the model to address speech variability, improving prediction accuracy. We analyzed speech data from 114 participants, including 32 individuals with early psychosis and 82 with low or high schizotypy, collected through structured interviews, semi-structured autobiographical tasks, and narrative-driven interactions in German. The model improved prediction accuracy, reducing RMSE and achieving an F1-score of 83% with ECE = 4.5e-2, showing robust performance across different interaction contexts. Uncertainty estimation improved model interpretability by identifying reliability differences in speech markers such as pitch variability, fluency disruptions, and spectral instability. The model dynamically adjusted to task structures, weighting acoustic features more in structured settings and linguistic features in unstructured contexts. This approach strengthens early detection, personalized assessment, and clinical decision-making in psychosis-spectrum research.
<div id='section'>Paperid: <span id='pid'>429, <a href='https://arxiv.org/pdf/2501.17883.pdf' target='_blank'>https://arxiv.org/pdf/2501.17883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17883">Explainable and Robust Millimeter Wave Beam Alignment for AI-Native 6G Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Integrated artificial intelligence (AI) and communication has been recognized as a key pillar of 6G and beyond networks. In line with AI-native 6G vision, explainability and robustness in AI-driven systems are critical for establishing trust and ensuring reliable performance in diverse and evolving environments. This paper addresses these challenges by developing a robust and explainable deep learning (DL)-based beam alignment engine (BAE) for millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems. The proposed convolutional neural network (CNN)-based BAE utilizes received signal strength indicator (RSSI) measurements over a set of wide beams to accurately predict the best narrow beam for each UE, significantly reducing the overhead associated with exhaustive codebook-based narrow beam sweeping for initial access (IA) and data transmission. To ensure transparency and resilience, the Deep k-Nearest Neighbors (DkNN) algorithm is employed to assess the internal representations of the network via nearest neighbor approach, providing human-interpretable explanations and confidence metrics for detecting out-of-distribution inputs. Experimental results demonstrate that the proposed DL-based BAE exhibits robustness to measurement noise, reduces beam training overhead by 75% compared to the exhaustive search while maintaining near-optimal performance in terms of spectral efficiency. Moreover, the proposed framework improves outlier detection robustness by up to 5x and offers clearer insights into beam prediction decisions compared to traditional softmax-based classifiers.
<div id='section'>Paperid: <span id='pid'>430, <a href='https://arxiv.org/pdf/2410.10894.pdf' target='_blank'>https://arxiv.org/pdf/2410.10894.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingyang Zhang, Yatao Bian, Xinke Kong, Peilin Zhao, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10894">COME: Test-time adaption by Conservatively Minimizing Entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models must continuously self-adjust themselves for novel data distribution in the open world. As the predominant principle, entropy minimization (EM) has been proven to be a simple yet effective cornerstone in existing test-time adaption (TTA) methods. While unfortunately its fatal limitation (i.e., overconfidence) tends to result in model collapse. For this issue, we propose to Conservatively Minimize the Entropy (COME), which is a simple drop-in replacement of traditional EM to elegantly address the limitation. In essence, COME explicitly models the uncertainty by characterizing a Dirichlet prior distribution over model predictions during TTA. By doing so, COME naturally regularizes the model to favor conservative confidence on unreliable samples. Theoretically, we provide a preliminary analysis to reveal the ability of COME in enhancing the optimization stability by introducing a data-adaptive lower bound on the entropy. Empirically, our method achieves state-of-the-art performance on commonly used benchmarks, showing significant improvements in terms of classification accuracy and uncertainty estimation under various settings including standard, life-long and open-world TTA, i.e., up to $34.5\%$ improvement on accuracy and $15.1\%$ on false positive rate.
<div id='section'>Paperid: <span id='pid'>431, <a href='https://arxiv.org/pdf/2410.00054.pdf' target='_blank'>https://arxiv.org/pdf/2410.00054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheng Zhang, Hossein Amiri, Dazhou Yu, Yuntong Hu, Liang Zhao, Andreas Zufle
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00054">Transferable Unsupervised Outlier Detection Framework for Human Semantic Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic trajectories, which enrich spatial-temporal data with textual information such as trip purposes or location activities, are key for identifying outlier behaviors critical to healthcare, social security, and urban planning. Traditional outlier detection relies on heuristic rules, which requires domain knowledge and limits its ability to identify unseen outliers. Besides, there lacks a comprehensive approach that can jointly consider multi-modal data across spatial, temporal, and textual dimensions. Addressing the need for a domain-agnostic model, we propose the Transferable Outlier Detection for Human Semantic Trajectories (TOD4Traj) framework.TOD4Traj first introduces a modality feature unification module to align diverse data feature representations, enabling the integration of multi-modal information and enhancing transferability across different datasets. A contrastive learning module is further pro-posed for identifying regular mobility patterns both temporally and across populations, allowing for a joint detection of outliers based on individual consistency and group majority patterns. Our experimental results have shown TOD4Traj's superior performance over existing models, demonstrating its effectiveness and adaptability in detecting human trajectory outliers across various datasets.
<div id='section'>Paperid: <span id='pid'>432, <a href='https://arxiv.org/pdf/2409.09249.pdf' target='_blank'>https://arxiv.org/pdf/2409.09249.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Ai, Ziwei Gong, Harshsaiprasad Deshpande, Alexander Johnson, Emmy Phung, Ahmad Emami, Julia Hirschberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09249">NovAScore: A New Automated Metric for Evaluating Document Level Novelty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid expansion of online content has intensified the issue of information redundancy, underscoring the need for solutions that can identify genuinely new information. Despite this challenge, the research community has seen a decline in focus on novelty detection, particularly with the rise of large language models (LLMs). Additionally, previous approaches have relied heavily on human annotation, which is time-consuming, costly, and particularly challenging when annotators must compare a target document against a vast number of historical documents. In this work, we introduce NovAScore (Novelty Evaluation in Atomicity Score), an automated metric for evaluating document-level novelty. NovAScore aggregates the novelty and salience scores of atomic information, providing high interpretability and a detailed analysis of a document's novelty. With its dynamic weight adjustment scheme, NovAScore offers enhanced flexibility and an additional dimension to assess both the novelty level and the importance of information within a document. Our experiments show that NovAScore strongly correlates with human judgments of novelty, achieving a 0.626 Point-Biserial correlation on the TAP-DLND 1.0 dataset and a 0.920 Pearson correlation on an internal human-annotated dataset.
<div id='section'>Paperid: <span id='pid'>433, <a href='https://arxiv.org/pdf/2409.03021.pdf' target='_blank'>https://arxiv.org/pdf/2409.03021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu-Hsiang Wang, Andrew Bai, Che-Ping Tsai, Cho-Jui Hsieh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03021">CLUE: Concept-Level Uncertainty Estimation for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have demonstrated remarkable proficiency in various natural language generation (NLG) tasks. Previous studies suggest that LLMs' generation process involves uncertainty. However, existing approaches to uncertainty estimation mainly focus on sequence-level uncertainty, overlooking individual pieces of information within sequences. These methods fall short in separately assessing the uncertainty of each component in a sequence. In response, we propose a novel framework for Concept-Level Uncertainty Estimation (CLUE) for LLMs. We leverage LLMs to convert output sequences into concept-level representations, breaking down sequences into individual concepts and measuring the uncertainty of each concept separately. We conduct experiments to demonstrate that CLUE can provide more interpretable uncertainty estimation results compared with sentence-level uncertainty, and could be a useful tool for various tasks such as hallucination detection and story generation.
<div id='section'>Paperid: <span id='pid'>434, <a href='https://arxiv.org/pdf/2409.01713.pdf' target='_blank'>https://arxiv.org/pdf/2409.01713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Patrick Knab, Sascha Marton, Christian Bartelt, Robert Fuder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01713">Interpreting Outliers in Time Series Data through Decoding Autoencoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection is a crucial analytical tool in various fields. In critical systems like manufacturing, malfunctioning outlier detection can be costly and safety-critical. Therefore, there is a significant need for explainable artificial intelligence (XAI) when deploying opaque models in such environments. This study focuses on manufacturing time series data from a German automotive supply industry. We utilize autoencoders to compress the entire time series and then apply anomaly detection techniques to its latent features. For outlier interpretation, we (i) adopt widely used XAI techniques to the autoencoder's encoder. Additionally, (ii) we propose AEE, Aggregated Explanatory Ensemble, a novel approach that fuses explanations of multiple XAI techniques into a single, more expressive interpretation. For evaluation of explanations, (iii) we propose a technique to measure the quality of encoder explanations quantitatively. Furthermore, we qualitatively assess the effectiveness of outlier explanations with domain expertise.
<div id='section'>Paperid: <span id='pid'>435, <a href='https://arxiv.org/pdf/2406.11278.pdf' target='_blank'>https://arxiv.org/pdf/2406.11278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Duygu Nur Yaldiz, Yavuz Faruk Bakman, Baturalp Buyukates, Chenyang Tao, Anil Ramakrishna, Dimitrios Dimitriadis, Jieyu Zhao, Salman Avestimehr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11278">Do Not Design, Learn: A Trainable Scoring Function for Uncertainty Estimation in Generative LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation (UE) of generative large language models (LLMs) is crucial for evaluating the reliability of generated sequences. A significant subset of UE methods utilize token probabilities to assess uncertainty, aggregating multiple token probabilities into a single UE score using a scoring function. Existing scoring functions for probability-based UE, such as length-normalized scoring and semantic contribution-based weighting, are designed to solve certain aspects of the problem but exhibit limitations, including the inability to handle biased probabilities and complex semantic dependencies between tokens. To address these issues, in this work, we propose Learnable Response Scoring (LARS) function, a novel scoring function that leverages supervised data to capture complex dependencies between tokens and probabilities, thereby producing more reliable and calibrated response scores in computing the uncertainty of LLM generations. Our comprehensive experiments across question-answering and arithmetical reasoning tasks with various datasets demonstrate that LARS significantly outperforms existing scoring functions, achieving improvements of up to 16\% AUROC score.
<div id='section'>Paperid: <span id='pid'>436, <a href='https://arxiv.org/pdf/2404.08476.pdf' target='_blank'>https://arxiv.org/pdf/2404.08476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hai-Vy Nguyen, Fabrice Gamboa, Reda Chhaibi, Sixin Zhang, Serge Gratton, Thierry Giaccone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08476">Combining Statistical Depth and Fermat Distance for Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We measure the Out-of-domain uncertainty in the prediction of Neural Networks using a statistical notion called ``Lens Depth'' (LD) combined with Fermat Distance, which is able to capture precisely the ``depth'' of a point with respect to a distribution in feature space, without any assumption about the form of distribution. Our method has no trainable parameter. The method is applicable to any classification model as it is applied directly in feature space at test time and does not intervene in training process. As such, it does not impact the performance of the original model. The proposed method gives excellent qualitative result on toy datasets and can give competitive or better uncertainty estimation on standard deep learning datasets compared to strong baseline methods.
<div id='section'>Paperid: <span id='pid'>437, <a href='https://arxiv.org/pdf/2403.18514.pdf' target='_blank'>https://arxiv.org/pdf/2403.18514.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aissam Djahnine, Alexandre Popoff, Emilien Jupin-Delevaux, Vincent Cottin, Olivier Nempont, Loic Boussel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18514">CT-3DFlow : Leveraging 3D Normalizing Flows for Unsupervised Detection of Pathological Pulmonary CT scans</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised pathology detection can be implemented by training a model on healthy data only and measuring the deviation from the training set upon inference, for example with CNN-based feature extraction and one-class classifiers, or reconstruction-score-based methods such as AEs, GANs and Diffusion models. Normalizing Flows (NF) have the ability to directly learn the probability distribution of training examples through an invertible architecture. We leverage this property in a novel 3D NF-based model named CT-3DFlow, specifically tailored for patient-level pulmonary pathology detection in chest CT data. Our model is trained unsupervised on healthy 3D pulmonary CT patches, and detects deviations from its log-likelihood distribution as anomalies. We aggregate patches-level likelihood values from a patient's CT scan to provide a patient-level 'normal'/'abnormal' prediction. Out-of-distribution detection performance is evaluated using expert annotations on a separate chest CT test dataset, outperforming other state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>438, <a href='https://arxiv.org/pdf/2402.05939.pdf' target='_blank'>https://arxiv.org/pdf/2402.05939.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufei Li, Simin Chen, Yanghong Guo, Wei Yang, Yue Dong, Cong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05939">Uncertainty Awareness of Large Language Models Under Code Distribution Shifts: A Benchmark Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have been widely employed in programming language analysis to enhance human productivity. Yet, their reliability can be compromised by various code distribution shifts, leading to inconsistent outputs. While probabilistic methods are known to mitigate such impact through uncertainty calibration and estimation, their efficacy in the language domain remains underexplored compared to their application in image-based tasks. In this work, we first introduce a large-scale benchmark dataset, incorporating three realistic patterns of code distribution shifts at varying intensities. Then we thoroughly investigate state-of-the-art probabilistic methods applied to CodeLlama using these shifted code snippets. We observe that these methods generally improve the uncertainty awareness of CodeLlama, with increased calibration quality and higher uncertainty estimation~(UE) precision. However, our study further reveals varied performance dynamics across different criteria (e.g., calibration error vs misclassification detection) and trade-off between efficacy and efficiency, highlighting necessary methodological selection tailored to specific contexts.
<div id='section'>Paperid: <span id='pid'>439, <a href='https://arxiv.org/pdf/2401.01881.pdf' target='_blank'>https://arxiv.org/pdf/2401.01881.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ersin Das, Joel W. Burdick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01881">Robust Control Barrier Functions using Uncertainty Estimation with Application to Mobile Robots</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a safety-critical control design approach for nonlinear control affine systems in the presence of matched and unmatched uncertainties. Our constructive framework couples control barrier function (CBF) theory with a new uncertainty estimator to ensure robust safety. We use the estimated uncertainty, along with a derived upper bound on the estimation error, for synthesizing CBFs and safety-critical controllers via a quadratic program-based feedback control law that rigorously ensures robust safety while improving disturbance rejection performance. We extend the method to higher-order CBFs (HOCBFs) to achieve safety under unmatched uncertainty, which may cause relative degree differences with respect to control input and disturbances. We assume the relative degree difference is at most one, resulting in a second-order cone constraint. We demonstrate the proposed robust HOCBF method through a simulation of an uncertain elastic actuator control problem and experimentally validate the efficacy of our robust CBF framework on a tracked robot with slope-induced matched and unmatched perturbations.
<div id='section'>Paperid: <span id='pid'>440, <a href='https://arxiv.org/pdf/2512.05927.pdf' target='_blank'>https://arxiv.org/pdf/2512.05927.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiting Mei, Tenny Yin, Micah Baker, Ola Shorinwa, Anirudha Majumdar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.05927">World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in generative video models have led to significant breakthroughs in high-fidelity video synthesis, specifically in controllable video generation where the generated video is conditioned on text and action inputs, e.g., in instruction-guided video editing and world modeling in robotics. Despite these exceptional capabilities, controllable video models often hallucinate - generating future video frames that are misaligned with physical reality - which raises serious concerns in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack the ability to assess and express their confidence, impeding hallucination mitigation. To rigorously address this challenge, we propose C3, an uncertainty quantification (UQ) method for training continuous-scale calibrated controllable video models for dense confidence estimation at the subpatch level, precisely localizing the uncertainty in each generated video frame. Our UQ method introduces three core innovations to empower video models to estimate their uncertainty. First, our method develops a novel framework that trains video models for correctness and calibration via strictly proper scoring rules. Second, we estimate the video model's uncertainty in latent space, avoiding training instability and prohibitive training costs associated with pixel-space approaches. Third, we map the dense latent-space uncertainty to interpretable pixel-level uncertainty in the RGB space for intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy regions. Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world evaluations, we demonstrate that our method not only provides calibrated uncertainty estimates within the training distribution, but also enables effective out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>441, <a href='https://arxiv.org/pdf/2511.04219.pdf' target='_blank'>https://arxiv.org/pdf/2511.04219.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingzhi Lin, Teng Huang, Han Ding, Cui Zhao, Fei Wang, Ge Wang, Wei Xi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.04219">Active Domain Adaptation for mmWave-based HAR via Renyi Entropy-based Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human Activity Recognition (HAR) using mmWave radar provides a non-invasive alternative to traditional sensor-based methods but suffers from domain shift, where model performance declines in new users, positions, or environments. To address this, we propose mmADA, an Active Domain Adaptation (ADA) framework that efficiently adapts mmWave-based HAR models with minimal labeled data. mmADA enhances adaptation by introducing Renyi Entropy-based uncertainty estimation to identify and label the most informative target samples. Additionally, it leverages contrastive learning and pseudo-labeling to refine feature alignment using unlabeled data. Evaluations with a TI IWR1443BOOST radar across multiple users, positions, and environments show that mmADA achieves over 90% accuracy in various cross-domain settings. Comparisons with five baselines confirm its superior adaptation performance, while further tests on unseen users, environments, and two additional open-source datasets validate its robustness and generalization.
<div id='section'>Paperid: <span id='pid'>442, <a href='https://arxiv.org/pdf/2510.08747.pdf' target='_blank'>https://arxiv.org/pdf/2510.08747.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihao Ang, Peicheng Yao, Yifan Bao, Yushuo Feng, Qiang Huang, Anthony K. H. Tung, Zhiyong Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.08747">RFOD: Random Forest-based Outlier Detection for Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection in tabular data is crucial for safeguarding data integrity in high-stakes domains such as cybersecurity, financial fraud detection, and healthcare, where anomalies can cause serious operational and economic impacts. Despite advances in both data mining and deep learning, many existing methods struggle with mixed-type tabular data, often relying on encoding schemes that lose important semantic information. Moreover, they frequently lack interpretability, offering little insight into which specific values cause anomalies. To overcome these challenges, we introduce \textsf{\textbf{RFOD}}, a novel \textsf{\textbf{R}}andom \textsf{\textbf{F}}orest-based \textsf{\textbf{O}}utlier \textsf{\textbf{D}}etection framework tailored for tabular data. Rather than modeling a global joint distribution, \textsf{RFOD} reframes anomaly detection as a feature-wise conditional reconstruction problem, training dedicated random forests for each feature conditioned on the others. This design robustly handles heterogeneous data types while preserving the semantic integrity of categorical features. To further enable precise and interpretable detection, \textsf{RFOD} combines Adjusted Gower's Distance (AGD) for cell-level scoring, which adapts to skewed numerical data and accounts for categorical confidence, with Uncertainty-Weighted Averaging (UWA) to aggregate cell-level scores into robust row-level anomaly scores. Extensive experiments on 15 real-world datasets demonstrate that \textsf{RFOD} consistently outperforms state-of-the-art baselines in detection accuracy while offering superior robustness, scalability, and interpretability for mixed-type tabular data.
<div id='section'>Paperid: <span id='pid'>443, <a href='https://arxiv.org/pdf/2509.25646.pdf' target='_blank'>https://arxiv.org/pdf/2509.25646.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Ma, Ling Guo, Hao Wu, Tao Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25646">Deep set based operator learning with uncertainty quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning operators from data is central to scientific machine learning. While DeepONets are widely used for their ability to handle complex domains, they require fixed sensor numbers and locations, lack mechanisms for uncertainty quantification (UQ), and are thus limited in practical applicability. Recent permutationinvariant extensions, such as the Variable-Input Deep Operator Network (VIDON), relax these sensor constraints but still rely on sufficiently dense observations and cannot capture uncertainties arising from incomplete measurements or from operators with inherent randomness. To address these challenges, we propose UQ-SONet, a permutation-invariant operator learning framework with built-in UQ. Our model integrates a set transformer embedding to handle sparse and variable sensor locations, and employs a conditional variational autoencoder (cVAE) to approximate the conditional distribution of the solution operator. By minimizing the negative ELBO, UQ-SONet provides principled uncertainty estimation while maintaining predictive accuracy. Numerical experiments on deterministic and stochastic PDEs, including the Navier-Stokes equation, demonstrate the robustness and effectiveness of the proposed framework.
<div id='section'>Paperid: <span id='pid'>444, <a href='https://arxiv.org/pdf/2505.24615.pdf' target='_blank'>https://arxiv.org/pdf/2505.24615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Liu, Zonglin Yang, Soujanya Poria, Thanh-Son Nguyen, Erik Cambria
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.24615">Harnessing Large Language Models for Scientific Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In an era of exponential scientific growth, identifying novel research ideas is crucial and challenging in academia. Despite potential, the lack of an appropriate benchmark dataset hinders the research of novelty detection. More importantly, simply adopting existing NLP technologies, e.g., retrieving and then cross-checking, is not a one-size-fits-all solution due to the gap between textual similarity and idea conception. In this paper, we propose to harness large language models (LLMs) for scientific novelty detection (ND), associated with two new datasets in marketing and NLP domains. To construct the considerate datasets for ND, we propose to extract closure sets of papers based on their relationship, and then summarize their main ideas based on LLMs. To capture idea conception, we propose to train a lightweight retriever by distilling the idea-level knowledge from LLMs to align ideas with similar conception, enabling efficient and accurate idea retrieval for LLM novelty detection. Experiments show our method consistently outperforms others on the proposed benchmark datasets for idea retrieval and ND tasks. Codes and data are available at https://anonymous.4open.science/r/NoveltyDetection-10FB/.
<div id='section'>Paperid: <span id='pid'>445, <a href='https://arxiv.org/pdf/2505.11731.pdf' target='_blank'>https://arxiv.org/pdf/2505.11731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harshil Vejendla, Haizhou Shi, Yibin Wang, Tunyu Zhang, Huan Zhang, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11731">Efficient Uncertainty Estimation via Distillation of Bayesian Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in uncertainty estimation for Large Language Models (LLMs) during downstream adaptation have addressed key challenges of reliability and simplicity. However, existing Bayesian methods typically require multiple sampling iterations during inference, creating significant efficiency issues that limit practical deployment. In this paper, we investigate the possibility of eliminating the need for test-time sampling for LLM uncertainty estimation. Specifically, when given an off-the-shelf Bayesian LLM, we distill its aligned confidence into a non-Bayesian student LLM by minimizing the divergence between their predictive distributions. Unlike typical calibration methods, our distillation is carried out solely on the training dataset without the need of an additional validation dataset. This simple yet effective approach achieves N-times more efficient uncertainty estimation during testing, where N is the number of samples traditionally required by Bayesian LLMs. Our extensive experiments demonstrate that uncertainty estimation capabilities on training data can successfully generalize to unseen test data through our distillation technique, consistently producing results comparable to (or even better than) state-of-the-art Bayesian LLMs.
<div id='section'>Paperid: <span id='pid'>446, <a href='https://arxiv.org/pdf/2504.13429.pdf' target='_blank'>https://arxiv.org/pdf/2504.13429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shenzhi Yang, Bin Liang, An Liu, Lin Gui, Xingkai Yao, Xiaofang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13429">Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).
<div id='section'>Paperid: <span id='pid'>447, <a href='https://arxiv.org/pdf/2503.22097.pdf' target='_blank'>https://arxiv.org/pdf/2503.22097.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoyan Xu, Zhengtao Yao, Yushun Dong, Ziyi Wang, Ryan A. Rossi, Mengyuan Li, Yue Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22097">Few-Shot Graph Out-of-Distribution Detection with LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing methods for graph out-of-distribution (OOD) detection typically depend on training graph neural network (GNN) classifiers using a substantial amount of labeled in-distribution (ID) data. However, acquiring high-quality labeled nodes in text-attributed graphs (TAGs) is challenging and costly due to their complex textual and structural characteristics. Large language models (LLMs), known for their powerful zero-shot capabilities in textual tasks, show promise but struggle to naturally capture the critical structural information inherent to TAGs, limiting their direct effectiveness.
  To address these challenges, we propose LLM-GOOD, a general framework that effectively combines the strengths of LLMs and GNNs to enhance data efficiency in graph OOD detection. Specifically, we first leverage LLMs' strong zero-shot capabilities to filter out likely OOD nodes, significantly reducing the human annotation burden. To minimize the usage and cost of the LLM, we employ it only to annotate a small subset of unlabeled nodes. We then train a lightweight GNN filter using these noisy labels, enabling efficient predictions of ID status for all other unlabeled nodes by leveraging both textual and structural information. After obtaining node embeddings from the GNN filter, we can apply informativeness-based methods to select the most valuable nodes for precise human annotation. Finally, we train the target ID classifier using these accurately annotated ID nodes. Extensive experiments on four real-world TAG datasets demonstrate that LLM-GOOD significantly reduces human annotation costs and outperforms state-of-the-art baselines in terms of both ID classification accuracy and OOD detection performance.
<div id='section'>Paperid: <span id='pid'>448, <a href='https://arxiv.org/pdf/2503.10959.pdf' target='_blank'>https://arxiv.org/pdf/2503.10959.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshat Ramachandran, Mingyu Lee, Huan Xu, Souvik Kundu, Tushar Krishna
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10959">OuroMamba: A Data-Free Quantization Framework for Vision Mamba Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present OuroMamba, the first data-free post-training quantization (DFQ) method for vision Mamba-based models (VMMs). We identify two key challenges in enabling DFQ for VMMs, (1) VMM's recurrent state transitions restricts capturing of long-range interactions and leads to semantically weak synthetic data, (2) VMM activations exhibit dynamic outlier variations across time-steps, rendering existing static PTQ techniques ineffective. To address these challenges, OuroMamba presents a two-stage framework: (1) OuroMamba-Gen to generate semantically rich and meaningful synthetic data. It applies contrastive learning on patch level VMM features generated through neighborhood interactions in the latent state space, (2) OuroMamba-Quant to employ mixed-precision quantization with lightweight dynamic outlier detection during inference. In specific, we present a thresholding based outlier channel selection strategy for activations that gets updated every time-step. Extensive experiments across vision and generative tasks show that our data-free OuroMamba surpasses existing data-driven PTQ techniques, achieving state-of-the-art performance across diverse quantization settings. Additionally, we implement efficient GPU kernels to achieve practical latency speedup of up to 2.36x. Code will be released soon.
<div id='section'>Paperid: <span id='pid'>449, <a href='https://arxiv.org/pdf/2412.07255.pdf' target='_blank'>https://arxiv.org/pdf/2412.07255.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinhong Lin, Linna Zhou, Zhongliang Yang, Yuang Cai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07255">Label-Confidence-Aware Uncertainty Estimation in Natural Language Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) display formidable capabilities in generative tasks but also pose potential risks due to their tendency to generate hallucinatory responses. Uncertainty Quantification (UQ), the evaluation of model output reliability, is crucial for ensuring the safety and robustness of AI systems. Recent studies have concentrated on model uncertainty by analyzing the relationship between output entropy under various sampling conditions and the corresponding labels. However, these methods primarily focus on measuring model entropy with precision to capture response characteristics, often neglecting the uncertainties associated with greedy decoding results-the sources of model labels, which can lead to biased classification outcomes. In this paper, we explore the biases introduced by greedy decoding and propose a label-confidence-aware (LCA) uncertainty estimation based on Kullback-Leibler (KL) divergence bridging between samples and label source, thus enhancing the reliability and stability of uncertainty assessments. Our empirical evaluations across a range of popular LLMs and NLP datasets reveal that different label sources can indeed affect classification, and that our approach can effectively capture differences in sampling results and label sources, demonstrating more effective uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>450, <a href='https://arxiv.org/pdf/2412.03792.pdf' target='_blank'>https://arxiv.org/pdf/2412.03792.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Li, Anouck Girard, Ilya Kolmanovsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03792">Safe Adaptive Cruise Control Under Perception Uncertainty: A Deep Ensemble and Conformal Tube Model Predictive Control Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving heavily relies on perception systems to interpret the environment for decision-making. To enhance robustness in these safety critical applications, this paper considers a Deep Ensemble of Deep Neural Network regressors integrated with Conformal Prediction to predict and quantify uncertainties. In the Adaptive Cruise Control setting, the proposed method performs state and uncertainty estimation from RGB images, informing the downstream controller of the DNN perception uncertainties. An adaptive cruise controller using Conformal Tube Model Predictive Control is designed to ensure probabilistic safety. Evaluations with a high-fidelity simulator demonstrate the algorithm's effectiveness in speed tracking and safe distance maintaining, including in Out-Of-Distribution scenarios.
<div id='section'>Paperid: <span id='pid'>451, <a href='https://arxiv.org/pdf/2411.02444.pdf' target='_blank'>https://arxiv.org/pdf/2411.02444.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoliang Wang, Chen Zhao, Feng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02444">MADOD: Generalizing OOD Detection to Unseen Domains via G-Invariance Meta-Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world machine learning applications often face simultaneous covariate and semantic shifts, challenging traditional domain generalization and out-of-distribution (OOD) detection methods. We introduce Meta-learned Across Domain Out-of-distribution Detection (MADOD), a novel framework designed to address both shifts concurrently. MADOD leverages meta-learning and G-invariance to enhance model generalizability and OOD detection in unseen domains. Our key innovation lies in task construction: we randomly designate in-distribution classes as pseudo-OODs within each meta-learning task, simulating OOD scenarios using existing data. This approach, combined with energy-based regularization, enables the learning of robust, domain-invariant features while calibrating decision boundaries for effective OOD detection. Operating in a test domain-agnostic setting, MADOD eliminates the need for adaptation during inference, making it suitable for scenarios where test data is unavailable. Extensive experiments on real-world and synthetic datasets demonstrate MADOD's superior performance in semantic OOD detection across unseen domains, achieving an AUPR improvement of 8.48% to 20.81%, while maintaining competitive in-distribution classification accuracy, representing a significant advancement in handling both covariate and semantic shifts.
<div id='section'>Paperid: <span id='pid'>452, <a href='https://arxiv.org/pdf/2409.09130.pdf' target='_blank'>https://arxiv.org/pdf/2409.09130.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jialuo Chen, Jingyi Wang, Xiyue Zhang, Youcheng Sun, Marta Kwiatkowska, Jiming Chen, Peng Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09130">FAST: Boosting Uncertainty-based Test Prioritization Methods for Neural Networks via Feature Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the vast testing space, the increasing demand for effective and efficient testing of deep neural networks (DNNs) has led to the development of various DNN test case prioritization techniques. However, the fact that DNNs can deliver high-confidence predictions for incorrectly predicted examples, known as the over-confidence problem, causes these methods to fail to reveal high-confidence errors. To address this limitation, in this work, we propose FAST, a method that boosts existing prioritization methods through guided FeAture SelecTion. FAST is based on the insight that certain features may introduce noise that affects the model's output confidence, thereby contributing to high-confidence errors. It quantifies the importance of each feature for the model's correct predictions, and then dynamically prunes the information from the noisy features during inference to derive a new probability vector for the uncertainty estimation. With the help of FAST, the high-confidence errors and correctly classified examples become more distinguishable, resulting in higher APFD (Average Percentage of Fault Detection) values for test prioritization, and higher generalization ability for model enhancement. We conduct extensive experiments to evaluate FAST across a diverse set of model structures on multiple benchmark datasets to validate the effectiveness, efficiency, and scalability of FAST compared to the state-of-the-art prioritization techniques.
<div id='section'>Paperid: <span id='pid'>453, <a href='https://arxiv.org/pdf/2409.03060.pdf' target='_blank'>https://arxiv.org/pdf/2409.03060.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Min Wu, Xiaofu Li, Haoze Wu, Clark Barrett
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03060">Better Verified Explanations with Applications to Incorrectness and Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Building on VeriX (Verified eXplainability, arXiv:2212.01051), a system for producing optimal verified explanations for machine learning model outputs, we present VeriX+, which significantly improves both the size and the generation time of verified explanations. We introduce a bound propagation-based sensitivity technique to improve the size, and a binary search-based traversal with confidence ranking for improving time -- the two techniques are orthogonal and can be used independently or together. We also show how to adapt the QuickXplain (Junker 2004) algorithm to our setting to provide a trade-off between size and time. Experimental evaluations on standard benchmarks demonstrate significant improvements on both metrics, e.g., a size reduction of 38% on the GTSRB dataset and a time reduction of 90% on MNIST. We also explore applications of our verified explanations and show that explanation size is a useful proxy for both incorrectness detection and out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>454, <a href='https://arxiv.org/pdf/2405.16766.pdf' target='_blank'>https://arxiv.org/pdf/2405.16766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxiao Lee, Xiaofeng Cao, Jingcai Guo, Wei Ye, Qing Guo, Yi Chang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16766">Concept Matching with Agent for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The remarkable achievements of Large Language Models (LLMs) have captivated the attention of both academia and industry, transcending their initial role in dialogue generation. To expand the usage scenarios of LLM, some works enhance the effectiveness and capabilities of the model by introducing more external information, which is called the agent paradigm. Based on this idea, we propose a new method that integrates the agent paradigm into out-of-distribution (OOD) detection task, aiming to improve its robustness and adaptability. Our proposed method, Concept Matching with Agent (CMA), employs neutral prompts as agents to augment the CLIP-based OOD detection process. These agents function as dynamic observers and communication hubs, interacting with both In-distribution (ID) labels and data inputs to form vector triangle relationships. This triangular framework offers a more nuanced approach than the traditional binary relationship, allowing for better separation and identification of ID and OOD inputs. Our extensive experimental results showcase the superior performance of CMA over both zero-shot and training-required methods in a diverse array of real-world scenarios.
<div id='section'>Paperid: <span id='pid'>455, <a href='https://arxiv.org/pdf/2402.07403.pdf' target='_blank'>https://arxiv.org/pdf/2402.07403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiyi Wang, Yang Nan, Felder Federico N, Sheng Zhang, Walsh Simon L F, Guang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07403">Make it more specific: A novel uncertainty based airway segmentation application on 3D U-Net and its variants</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Each medical segmentation task should be considered with a specific AI algorithm based on its scenario so that the most accurate prediction model can be obtained. The most popular algorithms in medical segmentation, 3D U-Net and its variants, can directly implement the task of lung trachea segmentation, but its failure to consider the special tree-like structure of the trachea suggests that there is much room for improvement in its segmentation accuracy. Therefore, a research gap exists because a great amount of state-of-the-art DL algorithms are vanilla 3D U-Net structures, which do not introduce the various performance-enhancing modules that come with special natural image modality in lung airway segmentation. In this paper, we proposed two different network structures Branch-Level U-Net (B-UNet) and Branch-Level CE-UNet (B-CE-UNet) which are based on U-Net structure and compared the prediction results with the same dataset. Specially, both of the two networks add branch loss and central line loss to learn the feature of fine branch endings of the airways. Uncertainty estimation algorithms are also included to attain confident predictions and thereby, increase the overall trustworthiness of our whole model. In addition, predictions of the lung trachea based on the maximum connectivity rate were calculated and extracted during post-processing for segmentation refinement and pruning.
<div id='section'>Paperid: <span id='pid'>456, <a href='https://arxiv.org/pdf/2511.19466.pdf' target='_blank'>https://arxiv.org/pdf/2511.19466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Penghao Rao, Runmin Jiang, Min Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.19466">SG-OIF: A Stability-Guided Online Influence Framework for Reliable Vision Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Approximating training-point influence on test predictions is critical for deploying deep-learning vision models, essential for locating noisy data. Though the influence function was proposed for attributing how infinitesimal up-weighting or removal of individual training examples affects model outputs, its implementation is still challenging in deep-learning vision models: inverse-curvature computations are expensive, and training non-stationarity invalidates static approximations. Prior works use iterative solvers and low-rank surrogates to reduce cost, but offline computation lags behind training dynamics, and missing confidence calibration yields fragile rankings that misidentify critical examples. To address these challenges, we introduce a Stability-Guided Online Influence Framework (SG-OIF), the first framework that treats algorithmic stability as a real-time controller, which (i) maintains lightweight anchor IHVPs via stochastic Richardson and preconditioned Neumann; (ii) proposes modular curvature backends to modulate per-example influence scores using stability-guided residual thresholds, anomaly gating, and confidence. Experimental results show that SG-OIF achieves SOTA (State-Of-The-Art) on noise-label and out-of-distribution detection tasks across multiple datasets with various corruption. Notably, our approach achieves 91.1\% accuracy in the top 1\% prediction samples on the CIFAR-10 (20\% asym), and gets 99.8\% AUPR score on MNIST, effectively demonstrating that this framework is a practical controller for online influence estimation.
<div id='section'>Paperid: <span id='pid'>457, <a href='https://arxiv.org/pdf/2511.03095.pdf' target='_blank'>https://arxiv.org/pdf/2511.03095.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gaia Grosso, Sai Sumedh R. Hindupur, Thomas Fel, Samuel Bright-Thonney, Philip Harris, Demba Ba
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.03095">Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern artificial intelligence has revolutionized our ability to extract rich and versatile data representations across scientific disciplines. Yet, the statistical properties of these representations remain poorly controlled, causing misspecified anomaly detection (AD) methods to falter. Weak or rare signals can remain hidden within the apparent regularity of normal data, creating a gap in our ability to detect and interpret anomalies. We examine this gap and identify a set of structural desiderata for detection methods operating under minimal prior information: sparsity, to enforce parsimony; locality, to preserve geometric sensitivity; and competition, to promote efficient allocation of model capacity. These principles define a class of self-organizing local kernels that adaptively partition the representation space around regions of statistical imbalance. As an instantiation of these principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained within a semi-supervised Neyman--Pearson framework to locally model the likelihood ratio between a sample that may contain anomalies and a nominal, anomaly-free reference. We provide theoretical insights into the mechanisms that drive detection and self-organization in the proposed model, and demonstrate the effectiveness of this approach on realistic high-dimensional problems of scientific discovery, open-world novelty detection, intrusion detection, and generative-model validation. Our applications span both the natural- and computer-science domains. We demonstrate that ensembles containing only a handful of kernels can identify statistically significant anomalous locations within representation spaces of thousands of dimensions, underscoring both the interpretability, efficiency and scalability of the proposed approach.
<div id='section'>Paperid: <span id='pid'>458, <a href='https://arxiv.org/pdf/2510.10584.pdf' target='_blank'>https://arxiv.org/pdf/2510.10584.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shizhen Zhao, Jiahui Liu, Xin Wen, Haoru Tan, Xiaojuan Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.10584">Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision foundation models have transformed many computer vision tasks. Despite their strong ability to learn discriminative and generalizable features crucial for out-of-distribution (OOD) detection, their impact on this task remains underexplored. Motivated by this gap, we systematically investigate representative vision foundation models for OOD detection. Our findings reveal that a pre-trained DINOv2 model, even without fine-tuning on in-domain (ID) data, naturally provides a highly discriminative feature space for OOD detection, achieving performance comparable to existing state-of-the-art methods without requiring complex designs. Beyond this, we explore how fine-tuning foundation models on in-domain (ID) data can enhance OOD detection. However, we observe that the performance of vision foundation models remains unsatisfactory in scenarios with a large semantic space. This is due to the increased complexity of decision boundaries as the number of categories grows, which complicates the optimization process. To mitigate this, we propose the Mixture of Feature Experts (MoFE) module, which partitions features into subspaces, effectively capturing complex data distributions and refining decision boundaries. Further, we introduce a Dynamic-$β$ Mixup strategy, which samples interpolation weights from a dynamic beta distribution. This adapts to varying levels of learning difficulty across categories, improving feature learning for more challenging categories. Extensive experiments demonstrate the effectiveness of our approach, significantly outperforming baseline methods.
<div id='section'>Paperid: <span id='pid'>459, <a href='https://arxiv.org/pdf/2510.03181.pdf' target='_blank'>https://arxiv.org/pdf/2510.03181.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ha Manh Bui, Felix Parker, Kimia Ghobadi, Anqi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03181">Q-Learning with Shift-Aware Upper Confidence Bound in Non-Stationary Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the Non-Stationary Reinforcement Learning (RL) under distribution shifts in both finite-horizon episodic and infinite-horizon discounted Markov Decision Processes (MDPs). In the finite-horizon case, the transition functions may suddenly change at a particular episode. In the infinite-horizon setting, such changes can occur at an arbitrary time step during the agent's interaction with the environment. While the Q-learning Upper Confidence Bound algorithm (QUCB) can discover a proper policy during learning, due to the distribution shifts, this policy can exploit sub-optimal rewards after the shift happens. To address this issue, we propose Density-QUCB (DQUCB), a shift-aware Q-learning~UCB algorithm, which uses a transition density function to detect distribution shifts, then leverages its likelihood to enhance the uncertainty estimation quality of Q-learning~UCB, resulting in a balance between exploration and exploitation. Theoretically, we prove that our oracle DQUCB achieves a better regret guarantee than QUCB. Empirically, our DQUCB enjoys the computational efficiency of model-free RL and outperforms QUCB baselines by having a lower regret across RL tasks, as well as a real-world COVID-19 patient hospital allocation task using a Deep-Q-learning architecture.
<div id='section'>Paperid: <span id='pid'>460, <a href='https://arxiv.org/pdf/2509.11467.pdf' target='_blank'>https://arxiv.org/pdf/2509.11467.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yalei Yu, Matthew Coombes, Wen-Hua Chen, Cong Sun, Myles Flanagan, Jingjing Jiang, Pramod Pashupathy, Masoud Sotoodeh-Bahraini, Peter Kinnell, Niels Lohse
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11467">A Goal-Oriented Approach for Active Object Detection with Exploration-Exploitation Balance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active object detection, which aims to identify objects of interest through controlled camera movements, plays a pivotal role in real-world visual perception for autonomous robotic applications, such as manufacturing tasks (e.g., assembly operations) performed in unknown environments. A dual control for exploration and exploitation (DCEE) algorithm is presented within goal-oriented control systems to achieve efficient active object detection, leveraging active learning by incorporating variance-based uncertainty estimation in the cost function. This novel method employs an exploration-exploitation balanced cost function to actively guide the selection of the next viewpoint. Specifically, active object detection is achieved through the development of a reward function that encodes knowledge about the confidence variation of objects as a function of viewpoint position within a given domain. By identifying the unknown parameters of this function, the system generates an optimal viewpoint planning strategy. DCEE integrates parameter estimation of the reward function and view planning, ensuring a balanced trade-off between the exploitation of learned knowledge and active exploration during the planning process. Moreover, it demonstrates remarkable adaptability across diverse scenarios, effectively handling LEGO brick detection at varying locations. Importantly, the algorithm maintains consistent configuration settings and a fixed number of parameters across various scenarios, underscoring its efficiency and robustness. To validate the proposed approach, extensive numerical studies, high-fidelity virtual simulations, and real-world experiments under various scenarios were conducted. The results confirm the effectiveness of DCEE in active object detection, showcasing superior performance compared to existing methods, including model predictive control (MPC) and entropy approaches.
<div id='section'>Paperid: <span id='pid'>461, <a href='https://arxiv.org/pdf/2507.18944.pdf' target='_blank'>https://arxiv.org/pdf/2507.18944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guanyi Qin, Ziyue Wang, Daiyun Shen, Haofeng Liu, Hantao Zhou, Junde Wu, Runze Hu, Yueming Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18944">Structure Matters: Revisiting Boundary Refinement in Video Object Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given an object mask, Semi-supervised Video Object Segmentation (SVOS) technique aims to track and segment the object across video frames, serving as a fundamental task in computer vision. Although recent memory-based methods demonstrate potential, they often struggle with scenes involving occlusion, particularly in handling object interactions and high feature similarity. To address these issues and meet the real-time processing requirements of downstream applications, in this paper, we propose a novel bOundary Amendment video object Segmentation method with Inherent Structure refinement, hereby named OASIS. Specifically, a lightweight structure refinement module is proposed to enhance segmentation accuracy. With the fusion of rough edge priors captured by the Canny filter and stored object features, the module can generate an object-level structure map and refine the representations by highlighting boundary features. Evidential learning for uncertainty estimation is introduced to further address challenges in occluded regions. The proposed method, OASIS, maintains an efficient design, yet extensive experiments on challenging benchmarks demonstrate its superior performance and competitive inference speed compared to other state-of-the-art methods, i.e., achieving the F values of 91.6 (vs. 89.7 on DAVIS-17 validation set) and G values of 86.6 (vs. 86.2 on YouTubeVOS 2019 validation set) while maintaining a competitive speed of 48 FPS on DAVIS.
<div id='section'>Paperid: <span id='pid'>462, <a href='https://arxiv.org/pdf/2505.17773.pdf' target='_blank'>https://arxiv.org/pdf/2505.17773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amir Hossein Rahmati, Sanket Jantre, Weifeng Zhang, Yucheng Wang, Byung-Jun Yoon, Nathan M. Urban, Xiaoning Qian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17773">C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Low-Rank Adaptation (LoRA) offers a cost-effective solution for fine-tuning large language models (LLMs), but it often produces overconfident predictions in data-scarce few-shot settings. To address this issue, several classical statistical learning approaches have been repurposed for scalable uncertainty-aware LoRA fine-tuning. However, these approaches neglect how input characteristics affect the predictive uncertainty estimates. To address this limitation, we propose Contextual Low-Rank Adaptation (\textbf{C-LoRA}) as a novel uncertainty-aware and parameter efficient fine-tuning approach, by developing new lightweight LoRA modules contextualized to each input data sample to dynamically adapt uncertainty estimates. Incorporating data-driven contexts into the parameter posteriors, C-LoRA mitigates overfitting, achieves well-calibrated uncertainties, and yields robust predictions. Extensive experiments demonstrate that C-LoRA consistently outperforms the state-of-the-art uncertainty-aware LoRA methods in both uncertainty quantification and model generalization. Ablation studies further confirm the critical role of our contextual modules in capturing sample-specific uncertainties. C-LoRA sets a new standard for robust, uncertainty-aware LLM fine-tuning in few-shot regimes.
<div id='section'>Paperid: <span id='pid'>463, <a href='https://arxiv.org/pdf/2505.07309.pdf' target='_blank'>https://arxiv.org/pdf/2505.07309.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07309">Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) often generate fluent but factually incorrect outputs, known as hallucinations, which undermine their reliability in real-world applications. While uncertainty estimation has emerged as a promising strategy for detecting such errors, current metrics offer limited interpretability and lack clarity about the types of uncertainty they capture. In this paper, we present a systematic framework for decomposing LLM uncertainty into four distinct sources, inspired by previous research. We develop a source-specific estimation pipeline to quantify these uncertainty types and evaluate how existing metrics relate to each source across tasks and models. Our results show that metrics, task, and model exhibit systematic variation in uncertainty characteristic. Building on this, we propose a method for task specific metric/model selection guided by the alignment or divergence between their uncertainty characteristics and that of a given task. Our experiments across datasets and models demonstrate that our uncertainty-aware selection strategy consistently outperforms baseline strategies, helping us select appropriate models or uncertainty metrics, and contributing to more reliable and efficient deployment in uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>464, <a href='https://arxiv.org/pdf/2504.03342.pdf' target='_blank'>https://arxiv.org/pdf/2504.03342.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guide Yang, Chao Hou, Weilong Peng, Xiang Fang, Yongwei Nie, Peican Zhu, Keke Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03342">EOOD: Entropy-based Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) often exhibit overconfidence when encountering out-of-distribution (OOD) samples, posing significant challenges for deployment. Since DNNs are trained on in-distribution (ID) datasets, the information flow of ID samples through DNNs inevitably differs from that of OOD samples. In this paper, we propose an Entropy-based Out-Of-distribution Detection (EOOD) framework. EOOD first identifies specific block where the information flow differences between ID and OOD samples are more pronounced, using both ID and pseudo-OOD samples. It then calculates the conditional entropy on the selected block as the OOD confidence score. Comprehensive experiments conducted across various ID and OOD settings demonstrate the effectiveness of EOOD in OOD detection and its superiority over state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>465, <a href='https://arxiv.org/pdf/2502.02657.pdf' target='_blank'>https://arxiv.org/pdf/2502.02657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifu Tao, Maurice Fallon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.02657">SiLVR: Scalable Lidar-Visual Radiance Field Reconstruction with Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a neural radiance field (NeRF) based large-scale reconstruction system that fuses lidar and vision data to generate high-quality reconstructions that are geometrically accurate and capture photorealistic texture. Our system adopts the state-of-the-art NeRF representation to incorporate lidar. Adding lidar data adds strong geometric constraints on the depth and surface normals, which is particularly useful when modelling uniform texture surfaces which contain ambiguous visual reconstruction cues. A key contribution of this work is a novel method to quantify the epistemic uncertainty of the lidar-visual NeRF reconstruction by estimating the spatial variance of each point location in the radiance field given the sensor observations from the cameras and lidar. This provides a principled approach to evaluate the contribution of each sensor modality to the final reconstruction. In this way, reconstructions that are uncertain (due to e.g. uniform visual texture, limited observation viewpoints, or little lidar coverage) can be identified and removed. Our system is integrated with a real-time lidar SLAM system which is used to bootstrap a Structure-from-Motion (SfM) reconstruction procedure. It also helps to properly constrain the overall metric scale which is essential for the lidar depth loss. The refined SLAM trajectory can then be divided into submaps using Spectral Clustering to group sets of co-visible images together. This submapping approach is more suitable for visual reconstruction than distance-based partitioning. Our uncertainty estimation is particularly effective when merging submaps as their boundaries often contain artefacts due to limited observations. We demonstrate the reconstruction system using a multi-camera, lidar sensor suite in experiments involving both robot-mounted and handheld scanning. Our test datasets cover a total area of more than 20,000 square metres.
<div id='section'>Paperid: <span id='pid'>466, <a href='https://arxiv.org/pdf/2410.09861.pdf' target='_blank'>https://arxiv.org/pdf/2410.09861.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shizuka Akahori, Satoshi Iizuka, Ken Mawatari, Kazuhiro Fukui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09861">Point Cloud Novelty Detection Based on Latent Representations of a General Feature Extractor</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an effective unsupervised 3D point cloud novelty detection approach, leveraging a general point cloud feature extractor and a one-class classifier. The general feature extractor consists of a graph-based autoencoder and is trained once on a point cloud dataset such as a mathematically generated fractal 3D point cloud dataset that is independent of normal/abnormal categories. The input point clouds are first converted into latent vectors by the general feature extractor, and then one-class classification is performed on the latent vectors. Compared to existing methods measuring the reconstruction error in 3D coordinate space, our approach utilizes latent representations where the shape information is condensed, which allows more direct and effective novelty detection. We confirm that our general feature extractor can extract shape features of unseen categories, eliminating the need for autoencoder re-training and reducing the computational burden. We validate the performance of our method through experiments on several subsets of the ShapeNet dataset and demonstrate that our latent-based approach outperforms the existing methods.
<div id='section'>Paperid: <span id='pid'>467, <a href='https://arxiv.org/pdf/2409.04766.pdf' target='_blank'>https://arxiv.org/pdf/2409.04766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shijing Wang, Yaping Huang, Jun Xie, Yi Tian, Feng Chen, Zhepeng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04766">Cross-Dataset Gaze Estimation by Evidential Inter-intra Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Achieving accurate and reliable gaze predictions in complex and diverse environments remains challenging. Fortunately, it is straightforward to access diverse gaze datasets in real-world applications. We discover that training these datasets jointly can significantly improve the generalization of gaze estimation, which is overlooked in previous works. However, due to the inherent distribution shift across different datasets, simply mixing multiple dataset decreases the performance in the original domain despite gaining better generalization abilities. To address the problem of ``cross-dataset gaze estimation'', we propose a novel Evidential Inter-intra Fusion EIF framework, for training a cross-dataset model that performs well across all source and unseen domains. Specifically, we build independent single-dataset branches for various datasets where the data space is partitioned into overlapping subspaces within each dataset for local regression, and further create a cross-dataset branch to integrate the generalizable features from single-dataset branches. Furthermore, evidential regressors based on the Normal and Inverse-Gamma (NIG) distribution are designed to additionally provide uncertainty estimation apart from predicting gaze. Building upon this foundation, our proposed framework achieves both intra-evidential fusion among multiple local regressors within each dataset and inter-evidential fusion among multiple branches by Mixture \textbfof Normal Inverse-Gamma (MoNIG distribution. Experiments demonstrate that our method consistently achieves notable improvements in both source domains and unseen domains.
<div id='section'>Paperid: <span id='pid'>468, <a href='https://arxiv.org/pdf/2406.18902.pdf' target='_blank'>https://arxiv.org/pdf/2406.18902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomohiro Shiraishi, Tatsuya Matsukawa, Shuichi Nishino, Ichiro Takeuchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18902">Statistical Test for Feature Selection Pipelines by Selective Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A data analysis pipeline is a structured sequence of steps that transforms raw data into meaningful insights by integrating various analysis algorithms. In this paper, we propose a novel statistical test to assess the significance of data analysis pipelines in feature selection problems. Our approach enables the systematic development of valid statistical tests applicable to any feature selection pipeline composed of predefined components. We develop this framework based on selective inference, a statistical technique that has recently gained attention for data-driven hypotheses. As a proof of concept, we consider feature selection pipelines for linear models, composed of three missing value imputation algorithms, three outlier detection algorithms, and three feature selection algorithms. We theoretically prove that our statistical test can control the probability of false positive feature selection at any desired level, and demonstrate its validity and effectiveness through experiments on synthetic and real data. Additionally, we present an implementation framework that facilitates testing across any configuration of these feature selection pipelines without extra implementation costs.
<div id='section'>Paperid: <span id='pid'>469, <a href='https://arxiv.org/pdf/2406.14301.pdf' target='_blank'>https://arxiv.org/pdf/2406.14301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rasika Vijithasena, Rafaela Scaciota, Mehdi Bennis, Sumudu Samarakoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14301">Resource Optimization for Tail-Based Control in Wireless Networked Control Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Achieving control stability is one of the key design challenges of scalable Wireless Networked Control Systems (WNCS) under limited communication and computing resources. This paper explores the use of an alternative control concept defined as tail-based control, which extends the classical Linear Quadratic Regulator (LQR) cost function for multiple dynamic control systems over a shared wireless network. We cast the control of multiple control systems as a network-wide optimization problem and decouple it in terms of sensor scheduling, plant state prediction, and control policies. Toward this, we propose a solution consisting of a scheduling algorithm based on Lyapunov optimization for sensing, a mechanism based on Gaussian Process Regression (GPR) for state prediction and uncertainty estimation, and a control policy based on Reinforcement Learning (RL) to ensure tail-based control stability. A set of discrete time-invariant mountain car control systems is used to evaluate the proposed solution and is compared against four variants that use state-of-the-art scheduling, prediction, and control methods. The experimental results indicate that the proposed method yields 22% reduction in overall cost in terms of communication and control resource utilization compared to state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>470, <a href='https://arxiv.org/pdf/2406.10107.pdf' target='_blank'>https://arxiv.org/pdf/2406.10107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Genc Hoxha, Gencer Sumbul, Julia Henkel, Lars MÃ¶llenbrok, BegÃ¼m Demir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10107">Annotation Cost-Efficient Active Learning for Deep Metric Learning Driven Remote Sensing Image Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep metric learning (DML) has shown to be effective for content-based image retrieval (CBIR) in remote sensing (RS). Most of DML methods for CBIR rely on a high number of annotated images to accurately learn model parameters of deep neural networks (DNNs). However, gathering such data is time-consuming and costly. To address this, we propose an annotation cost-efficient active learning (ANNEAL) method tailored to DML-driven CBIR in RS. ANNEAL aims to create a small but informative training set made up of similar and dissimilar image pairs to be utilized for accurately learning a metric space. The informativeness of image pairs is evaluated by combining uncertainty and diversity criteria. To assess the uncertainty of image pairs, we introduce two algorithms: 1) metric-guided uncertainty estimation (MGUE); and 2) binary classifier guided uncertainty estimation (BCGUE). MGUE algorithm automatically estimates a threshold value that acts as a boundary between similar and dissimilar image pairs based on the distances in the metric space. The closer the similarity between image pairs is to the estimated threshold value the higher their uncertainty. BCGUE algorithm estimates the uncertainty of the image pairs based on the confidence of the classifier in assigning correct similarity labels. The diversity criterion is assessed through a clustering-based strategy. ANNEAL combines either MGUE or BCGUE algorithm with the clustering-based strategy to select the most informative image pairs, which are then labelled by expert annotators as similar or dissimilar. This way of annotating images significantly reduces the annotation cost compared to annotating images with land-use land-cover class labels. Experimental results on two RS benchmark datasets demonstrate the effectiveness of our method. The code of this work is publicly available at \url{https://git.tu-berlin.de/rsim/anneal_tgrs}.
<div id='section'>Paperid: <span id='pid'>471, <a href='https://arxiv.org/pdf/2405.20003.pdf' target='_blank'>https://arxiv.org/pdf/2405.20003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Nikitin, Jannik Kossen, Yarin Gal, Pekka Marttinen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.20003">Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification in Large Language Models (LLMs) is crucial for applications where safety and reliability are important. In particular, uncertainty can be used to improve the trustworthiness of LLMs by detecting factually incorrect model responses, commonly called hallucinations. Critically, one should seek to capture the model's semantic uncertainty, i.e., the uncertainty over the meanings of LLM outputs, rather than uncertainty over lexical or syntactic variations that do not affect answer correctness. To address this problem, we propose Kernel Language Entropy (KLE), a novel method for uncertainty estimation in white- and black-box LLMs. KLE defines positive semidefinite unit trace kernels to encode the semantic similarities of LLM outputs and quantifies uncertainty using the von Neumann entropy. It considers pairwise semantic dependencies between answers (or semantic clusters), providing more fine-grained uncertainty estimates than previous methods based on hard clustering of answers. We theoretically prove that KLE generalizes the previous state-of-the-art method called semantic entropy and empirically demonstrate that it improves uncertainty quantification performance across multiple natural language generation datasets and LLM architectures.
<div id='section'>Paperid: <span id='pid'>472, <a href='https://arxiv.org/pdf/2403.11233.pdf' target='_blank'>https://arxiv.org/pdf/2403.11233.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liren Jin, Haofei Kuang, Yue Pan, Cyrill Stachniss, Marija PopoviÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11233">STAIR: Semantic-Targeted Active Implicit Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many autonomous robotic applications require object-level understanding when deployed. Actively reconstructing objects of interest, i.e. objects with specific semantic meanings, is therefore relevant for a robot to perform downstream tasks in an initially unknown environment. In this work, we propose a novel framework for semantic-targeted active reconstruction using posed RGB-D measurements and 2D semantic labels as input. The key components of our framework are a semantic implicit neural representation and a compatible planning utility function based on semantic rendering and uncertainty estimation, enabling adaptive view planning to target objects of interest. Our planning approach achieves better reconstruction performance in terms of mesh and novel view rendering quality compared to implicit reconstruction baselines that do not consider semantics for view planning. Our framework further outperforms a state-of-the-art semantic-targeted active reconstruction pipeline based on explicit maps, justifying our choice of utilising implicit neural representations to tackle semantic-targeted active reconstruction problems.
<div id='section'>Paperid: <span id='pid'>473, <a href='https://arxiv.org/pdf/2403.02311.pdf' target='_blank'>https://arxiv.org/pdf/2403.02311.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yidong Zhao, Joao Tourais, Iain Pierce, Christian Nitsche, Thomas A. Treibel, Sebastian WeingÃ¤rtner, Artur M. Schweidtmann, Qian Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.02311">Bayesian Uncertainty Estimation by Hamiltonian Monte Carlo: Applications to Cardiac MRI Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL)-based methods have achieved state-of-the-art performance for many medical image segmentation tasks. Nevertheless, recent studies show that deep neural networks (DNNs) can be miscalibrated and overconfident, leading to "silent failures" that are risky for clinical applications. Bayesian DL provides an intuitive approach to DL failure detection, based on posterior probability estimation. However, the posterior is intractable for large medical image segmentation DNNs. To tackle this challenge, we propose a Bayesian learning framework using Hamiltonian Monte Carlo (HMC), tempered by cold posterior (CP) to accommodate medical data augmentation, named HMC-CP. For HMC computation, we further propose a cyclical annealing strategy, capturing both local and global geometries of the posterior distribution, enabling highly efficient Bayesian DNN training with the same computational budget as training a single DNN. The resulting Bayesian DNN outputs an ensemble segmentation along with the segmentation uncertainty. We evaluate the proposed HMC-CP extensively on cardiac magnetic resonance image (MRI) segmentation, using in-domain steady-state free precession (SSFP) cine images as well as out-of-domain datasets of quantitative T1 and T2 mapping. Our results show that the proposed method improves both segmentation accuracy and uncertainty estimation for in- and out-of-domain data, compared with well-established baseline methods such as Monte Carlo Dropout and Deep Ensembles. Additionally, we establish a conceptual link between HMC and the commonly known stochastic gradient descent (SGD) and provide general insight into the uncertainty of DL. This uncertainty is implicitly encoded in the training dynamics but often overlooked. With reliable uncertainty estimation, our method provides a promising direction toward trustworthy DL in clinical applications.
<div id='section'>Paperid: <span id='pid'>474, <a href='https://arxiv.org/pdf/2510.22171.pdf' target='_blank'>https://arxiv.org/pdf/2510.22171.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erum Mushtaq, Zalan Fabian, Yavuz Faruk Bakman, Anil Ramakrishna, Mahdi Soltanolkotabi, Salman Avestimehr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.22171">HARMONY: Hidden Activation Representations and Model Output-Aware Uncertainty Estimation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing deployment of Vision-Language Models (VLMs) in high-stakes applications such as autonomous driving and assistive technologies for visually impaired individuals necessitates reliable mechanisms to assess the trustworthiness of their generation. Uncertainty Estimation (UE) plays a central role in quantifying the reliability of model outputs and reducing unsafe generations via selective prediction. In this regard, most existing probability-based UE approaches rely on output probability distributions, aggregating token probabilities into a single uncertainty score using predefined functions such as length-normalization. Another line of research leverages model hidden representations and trains MLP-based models to predict uncertainty. However, these methods often fail to capture the complex multimodal relationships between semantic and textual tokens and struggle to identify biased probabilities often influenced by language priors. Motivated by these observations, we propose a novel UE framework, HARMONY, that jointly leverages fused multimodal information in model activations and the output distribution of the VLM to determine the reliability of responses. The key hypothesis of our work is that both the model's internal belief in its visual understanding, captured by its hidden representations, and the produced token probabilities carry valuable reliability signals that can be jointly leveraged to improve UE performance, surpassing approaches that rely on only one of these components. Experimental results on three open-ended VQA benchmarks, A-OKVQA, VizWiz, and PathVQA, and three state-of-the-art VLMs, LLaVa-7b, LLaVA-13b and InstructBLIP demonstrate that our method consistently performs on par with or better than existing approaches, achieving up to 4\% improvement in AUROC, and 6\% in PRR, establishing new state of the art in uncertainty estimation for VLMs.
<div id='section'>Paperid: <span id='pid'>475, <a href='https://arxiv.org/pdf/2510.06754.pdf' target='_blank'>https://arxiv.org/pdf/2510.06754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christian Maurer, Snehal Jauhri, Sophie Lueth, Georgia Chalvatzaki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06754">UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Comprehensive visual, geometric, and semantic understanding of a 3D scene is crucial for successful execution of robotic tasks, especially in unstructured and complex environments. Additionally, to make robust decisions, it is necessary for the robot to evaluate the reliability of perceived information. While recent advances in 3D neural feature fields have enabled robots to leverage features from pretrained foundation models for tasks such as language-guided manipulation and navigation, existing methods suffer from two critical limitations: (i) they are typically scene-specific, and (ii) they lack the ability to model uncertainty in their predictions. We present UniFField, a unified uncertainty-aware neural feature field that combines visual, semantic, and geometric features in a single generalizable representation while also predicting uncertainty in each modality. Our approach, which can be applied zero shot to any new environment, incrementally integrates RGB-D images into our voxel-based feature representation as the robot explores the scene, simultaneously updating uncertainty estimation. We evaluate our uncertainty estimations to accurately describe the model prediction errors in scene reconstruction and semantic feature prediction. Furthermore, we successfully leverage our feature predictions and their respective uncertainty for an active object search task using a mobile manipulator robot, demonstrating the capability for robust decision-making.
<div id='section'>Paperid: <span id='pid'>476, <a href='https://arxiv.org/pdf/2509.25437.pdf' target='_blank'>https://arxiv.org/pdf/2509.25437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mabel Heffring, Lincoln Linlin Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25437">Bayesian Transformer for Pan-Arctic Sea Ice Concentration Mapping and Uncertainty Estimation using Sentinel-1, RCM, and AMSR2 Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although high-resolution mapping of Pan-Arctic sea ice with reliable corresponding uncertainty is essential for operational sea ice concentration (SIC) charting, it is a difficult task due to some key challenges, e.g., the subtle nature of ice signature features, model uncertainty, and data heterogeneity. This letter presents a novel Bayesian Transformer approach for Pan-Arctic SIC mapping and uncertainty quantification using Sentinel-1, RADARSAT Constellation Mission (RCM), and Advanced Microwave Scanning Radiometer 2 (AMSR2) data. First, to improve feature extraction, we design a novel high-resolution Transformer model with both global and local modules that can better discern the subtle differences in sea ice patterns. Second, to improve uncertainty quantification, we design a Bayesian extension of the proposed Transformer model, treating its parameters as random variables to more effectively capture uncertainties. Third, to address data heterogeneity, we fuse three different data types (Sentinel-1, RCM, and AMSR2) at decision-level to improve both SIC mapping and uncertainty quantification. The proposed approach is tested on Pan-Arctic datasets from September 2021, and the results demonstrate that the proposed model can achieve both high-resolution SIC maps and robust uncertainty maps compared to other uncertainty quantification approaches.
<div id='section'>Paperid: <span id='pid'>477, <a href='https://arxiv.org/pdf/2509.18934.pdf' target='_blank'>https://arxiv.org/pdf/2509.18934.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yating Liu, Xing Su, Hao Wu, Sijin Li, Yuxi Cheng, Fengyuan Xu, Sheng Zhong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18934">Revealing Adversarial Smart Contracts through Semantic Interpretation and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adversarial smart contracts, mostly on EVM-compatible chains like Ethereum and BSC, are deployed as EVM bytecode to exploit vulnerable smart contracts for financial gain. Detecting such malicious contracts at the time of deployment is an important proactive strategy to prevent losses from victim contracts. It offers a better cost-benefit ratio than detecting vulnerabilities on diverse potential victims. However, existing works are not generic with limited detection types and effectiveness due to imbalanced samples, while the emerging LLM technologies, which show their potential in generalization, have two key problems impeding its application in this task: hard digestion of compiled-code inputs, especially those with task-specific logic, and hard assessment of LLM's certainty in its binary (yes-or-no) answers. Therefore, we propose a generic adversarial smart contracts detection framework FinDet, which leverages LLM with two enhancements addressing the above two problems. FinDet takes as input only the EVM bytecode contracts and identifies adversarial ones among them with high balanced accuracy. The first enhancement extracts concise semantic intentions and high-level behavioral logic from the low-level bytecode inputs, unleashing the LLM reasoning capability restricted by the task input. The second enhancement probes and measures the LLM uncertainty to its multi-round answering to the same query, improving the LLM answering robustness for binary classifications required by the task output. Our comprehensive evaluation shows that FinDet achieves a BAC of 0.9374 and a TPR of 0.9231, significantly outperforming existing baselines. It remains robust under challenging conditions including unseen attack patterns, low-data settings, and feature obfuscation. FinDet detects all 5 public and 20+ unreported adversarial contracts in a 10-day real-world test, confirmed manually.
<div id='section'>Paperid: <span id='pid'>478, <a href='https://arxiv.org/pdf/2509.05778.pdf' target='_blank'>https://arxiv.org/pdf/2509.05778.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arantxa Urrea-CastaÃ±o, NicolÃ¡s Segura-Kunsagi, Juan Luis SuÃ¡rez-DÃ­az, Rosana Montes, Francisco Herrera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05778">DCV-ROOD Evaluation Framework: Dual Cross-Validation for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection plays a key role in enhancing the robustness of artificial intelligence systems by identifying inputs that differ significantly from the training distribution, thereby preventing unreliable predictions and enabling appropriate fallback mechanisms. Developing reliable OOD detection methods is a significant challenge, and rigorous evaluation of these techniques is essential for ensuring their effectiveness, as it allows researchers to assess their performance under diverse conditions and to identify potential limitations or failure modes. Cross-validation (CV) has proven to be a highly effective tool for providing a reasonable estimate of the performance of a learning algorithm. Although OOD scenarios exhibit particular characteristics, an appropriate adaptation of CV can lead to a suitable evaluation framework for this setting. This work proposes a dual CV framework for robust evaluation of OOD detection models, aimed at improving the reliability of their assessment. The proposed evaluation framework aims to effectively integrate in-distribution (ID) and OOD data while accounting for their differing characteristics. To achieve this, ID data are partitioned using a conventional approach, whereas OOD data are divided by grouping samples based on their classes. Furthermore, we analyze the context of data with class hierarchy to propose a data splitting that considers the entire class hierarchy to obtain fair ID-OOD partitions to apply the proposed evaluation framework. This framework is called Dual Cross-Validation for Robust Out-of-Distribution Detection (DCV-ROOD). To test the validity of the evaluation framework, we selected a set of state-of-the-art OOD detection methods, both with and without outlier exposure. The results show that the method achieves very fast convergence to the true performance.
<div id='section'>Paperid: <span id='pid'>479, <a href='https://arxiv.org/pdf/2507.01831.pdf' target='_blank'>https://arxiv.org/pdf/2507.01831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yucen Lily Li, Daohan Lu, Polina Kirichenko, Shikai Qiu, Tim G. J. Rudner, C. Bayan Bruss, Andrew Gordon Wilson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01831">Out-of-Distribution Detection Methods Answer the Wrong Questions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To detect distribution shifts and improve model safety, many out-of-distribution (OOD) detection methods rely on the predictive uncertainty or features of supervised models trained on in-distribution data. In this paper, we critically re-examine this popular family of OOD detection procedures, and we argue that these methods are fundamentally answering the wrong questions for OOD detection. There is no simple fix to this misalignment, since a classifier trained only on in-distribution classes cannot be expected to identify OOD points; for instance, a cat-dog classifier may confidently misclassify an airplane if it contains features that distinguish cats from dogs, despite generally appearing nothing alike. We find that uncertainty-based methods incorrectly conflate high uncertainty with being OOD, while feature-based methods incorrectly conflate far feature-space distance with being OOD. We show how these pathologies manifest as irreducible errors in OOD detection and identify common settings where these methods are ineffective. Additionally, interventions to improve OOD detection such as feature-logit hybrid methods, scaling of model and data size, epistemic uncertainty representation, and outlier exposure also fail to address this fundamental misalignment in objectives. We additionally consider unsupervised density estimation and generative models for OOD detection, which we show have their own fundamental limitations.
<div id='section'>Paperid: <span id='pid'>480, <a href='https://arxiv.org/pdf/2505.06898.pdf' target='_blank'>https://arxiv.org/pdf/2505.06898.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honglong Yang, Shanshan Song, Yi Qin, Lehan Wang, Haonan Wang, Xinpeng Ding, Qixiang Zhang, Bodong Du, Xiaomeng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06898">Multi-Modal Explainable Medical AI Assistant for Trustworthy Human-AI Collaboration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generalist Medical AI (GMAI) systems have demonstrated expert-level performance in biomedical perception tasks, yet their clinical utility remains limited by inadequate multi-modal explainability and suboptimal prognostic capabilities. Here, we present XMedGPT, a clinician-centric, multi-modal AI assistant that integrates textual and visual interpretability to support transparent and trustworthy medical decision-making. XMedGPT not only produces accurate diagnostic and descriptive outputs, but also grounds referenced anatomical sites within medical images, bridging critical gaps in interpretability and enhancing clinician usability. To support real-world deployment, we introduce a reliability indexing mechanism that quantifies uncertainty through consistency-based assessment via interactive question-answering. We validate XMedGPT across four pillars: multi-modal interpretability, uncertainty quantification, and prognostic modeling, and rigorous benchmarking. The model achieves an IoU of 0.703 across 141 anatomical regions, and a Kendall's tau-b of 0.479, demonstrating strong alignment between visual rationales and clinical outcomes. For uncertainty estimation, it attains an AUC of 0.862 on visual question answering and 0.764 on radiology report generation. In survival and recurrence prediction for lung and glioma cancers, it surpasses prior leading models by 26.9%, and outperforms GPT-4o by 25.0%. Rigorous benchmarking across 347 datasets covers 40 imaging modalities and external validation spans 4 anatomical systems confirming exceptional generalizability, with performance gains surpassing existing GMAI by 20.7% for in-domain evaluation and 16.7% on 11,530 in-house data evaluation. Together, XMedGPT represents a significant leap forward in clinician-centric AI integration, offering trustworthy and scalable support for diverse healthcare applications.
<div id='section'>Paperid: <span id='pid'>481, <a href='https://arxiv.org/pdf/2502.01035.pdf' target='_blank'>https://arxiv.org/pdf/2502.01035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiuhong Xiao, Giuseppe Loianno
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01035">UASTHN: Uncertainty-Aware Deep Homography Estimation for UAV Satellite-Thermal Geo-localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geo-localization is an essential component of Unmanned Aerial Vehicle (UAV) navigation systems to ensure precise absolute self-localization in outdoor environments. To address the challenges of GPS signal interruptions or low illumination, Thermal Geo-localization (TG) employs aerial thermal imagery to align with reference satellite maps to accurately determine the UAV's location. However, existing TG methods lack uncertainty measurement in their outputs, compromising system robustness in the presence of textureless or corrupted thermal images, self-similar or outdated satellite maps, geometric noises, or thermal images exceeding satellite maps. To overcome these limitations, this paper presents UASTHN, a novel approach for Uncertainty Estimation (UE) in Deep Homography Estimation (DHE) tasks for TG applications. Specifically, we introduce a novel Crop-based Test-Time Augmentation (CropTTA) strategy, which leverages the homography consensus of cropped image views to effectively measure data uncertainty. This approach is complemented by Deep Ensembles (DE) employed for model uncertainty, offering comparable performance with improved efficiency and seamless integration with any DHE model. Extensive experiments across multiple DHE models demonstrate the effectiveness and efficiency of CropTTA in TG applications. Analysis of detected failure cases underscores the improved reliability of CropTTA under challenging conditions. Finally, we demonstrate the capability of combining CropTTA and DE for a comprehensive assessment of both data and model uncertainty. Our research provides profound insights into the broader intersection of localization and uncertainty estimation. The code and models are publicly available.
<div id='section'>Paperid: <span id='pid'>482, <a href='https://arxiv.org/pdf/2501.17906.pdf' target='_blank'>https://arxiv.org/pdf/2501.17906.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingkun Chen, Guang Yang, Xiao Zhang, Jingchao Peng, Tianlu Zhang, Jianguo Zhang, Jungong Han, Vicente Grau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17906">Unsupervised Patch-GAN with Targeted Patch Ranking for Fine-Grained Novelty Detection in Medical Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting novel anomalies in medical imaging is challenging due to the limited availability of labeled data for rare abnormalities, which often display high variability and subtlety. This challenge is further compounded when small abnormal regions are embedded within larger normal areas, as whole-image predictions frequently overlook these subtle deviations. To address these issues, we propose an unsupervised Patch-GAN framework designed to detect and localize anomalies by capturing both local detail and global structure. Our framework first reconstructs masked images to learn fine-grained, normal-specific features, allowing for enhanced sensitivity to minor deviations from normality. By dividing these reconstructed images into patches and assessing the authenticity of each patch, our approach identifies anomalies at a more granular level, overcoming the limitations of whole-image evaluation. Additionally, a patch-ranking mechanism prioritizes regions with higher abnormal scores, reinforcing the alignment between local patch discrepancies and the global image context. Experimental results on the ISIC 2016 skin lesion and BraTS 2019 brain tumor datasets validate our framework's effectiveness, achieving AUCs of 95.79% and 96.05%, respectively, and outperforming three state-of-the-art baselines.
<div id='section'>Paperid: <span id='pid'>483, <a href='https://arxiv.org/pdf/2405.12223.pdf' target='_blank'>https://arxiv.org/pdf/2405.12223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinchi Zhou, Tianqi Chen, Jun Hou, Huidong Xie, Nicha C. Dvornek, S. Kevin Zhou, David L. Wilson, James S. Duncan, Chi Liu, Bo Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12223">Cascaded Multi-path Shortcut Diffusion Model for Medical Image Translation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image-to-image translation is a vital component in medical imaging processing, with many uses in a wide range of imaging modalities and clinical scenarios. Previous methods include Generative Adversarial Networks (GANs) and Diffusion Models (DMs), which offer realism but suffer from instability and lack uncertainty estimation. Even though both GAN and DM methods have individually exhibited their capability in medical image translation tasks, the potential of combining a GAN and DM to further improve translation performance and to enable uncertainty estimation remains largely unexplored. In this work, we address these challenges by proposing a Cascade Multi-path Shortcut Diffusion Model (CMDM) for high-quality medical image translation and uncertainty estimation. To reduce the required number of iterations and ensure robust performance, our method first obtains a conditional GAN-generated prior image that will be used for the efficient reverse translation with a DM in the subsequent step. Additionally, a multi-path shortcut diffusion strategy is employed to refine translation results and estimate uncertainty. A cascaded pipeline further enhances translation quality, incorporating residual averaging between cascades. We collected three different medical image datasets with two sub-tasks for each dataset to test the generalizability of our approach. Our experimental results found that CMDM can produce high-quality translations comparable to state-of-the-art methods while providing reasonable uncertainty estimations that correlate well with the translation error.
<div id='section'>Paperid: <span id='pid'>484, <a href='https://arxiv.org/pdf/2404.14933.pdf' target='_blank'>https://arxiv.org/pdf/2404.14933.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dayananda Herurkar, Sebastian Palacio, Ahmed Anwar, Joern Hees, Andreas Dengel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14933">Fin-Fed-OD: Federated Outlier Detection on Financial Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection in real-world scenarios poses challenges due to dynamic and often unknown anomaly distributions, requiring robust methods that operate under an open-world assumption. This challenge is exacerbated in practical settings, where models are employed by private organizations, precluding data sharing due to privacy and competitive concerns. Despite potential benefits, the sharing of anomaly information across organizations is restricted. This paper addresses the question of enhancing outlier detection within individual organizations without compromising data confidentiality. We propose a novel method leveraging representation learning and federated learning techniques to improve the detection of unknown anomalies. Specifically, our approach utilizes latent representations obtained from client-owned autoencoders to refine the decision boundary of inliers. Notably, only model parameters are shared between organizations, preserving data privacy. The efficacy of our proposed method is evaluated on two standard financial tabular datasets and an image dataset for anomaly detection in a distributed setting. The results demonstrate a strong improvement in the classification of unknown outliers during the inference phase for each organization's model.
<div id='section'>Paperid: <span id='pid'>485, <a href='https://arxiv.org/pdf/2402.10062.pdf' target='_blank'>https://arxiv.org/pdf/2402.10062.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Chen, Zhihang Fu, Kai Liu, Ze Chen, Mingyuan Tao, Jieping Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10062">Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For a machine learning model deployed in real world scenarios, the ability of detecting out-of-distribution (OOD) samples is indispensable and challenging. Most existing OOD detection methods focused on exploring advanced training skills or training-free tricks to prevent the model from yielding overconfident confidence score for unknown samples. The training-based methods require expensive training cost and rely on OOD samples which are not always available, while most training-free methods can not efficiently utilize the prior information from the training data. In this work, we propose an \textbf{O}ptimal \textbf{P}arameter and \textbf{N}euron \textbf{P}runing (\textbf{OPNP}) approach, which aims to identify and remove those parameters and neurons that lead to over-fitting. The main method is divided into two steps. In the first step, we evaluate the sensitivity of the model parameters and neurons by averaging gradients over all training samples. In the second step, the parameters and neurons with exceptionally large or close to zero sensitivities are removed for prediction. Our proposal is training-free, compatible with other post-hoc methods, and exploring the information from all training data. Extensive experiments are performed on multiple OOD detection tasks and model architectures, showing that our proposed OPNP consistently outperforms the existing methods by a large margin.
<div id='section'>Paperid: <span id='pid'>486, <a href='https://arxiv.org/pdf/2512.04351.pdf' target='_blank'>https://arxiv.org/pdf/2512.04351.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manh Nguyen, Sunil Gupta, Hung Le
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.04351">Distance Is All You Need: Radial Dispersion for Uncertainty Estimation in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting when large language models (LLMs) are uncertain is critical for building reliable systems, yet existing methods are overly complicated, relying on brittle semantic clustering or internal states. We introduce \textbf{Radial Dispersion Score (RDS)}, a simple, parameter-free, fully model-agnostic uncertainty metric that measures the radial dispersion of sampled generations in embedding space. A lightweight probability-weighted variant further incorporates the model's own token probabilities when available, outperforming different nine strong baselines. Moroever, RDS naturally extends to per-sample scoring, enabling applications such as best-of-$N$ selection and confidence-based filtering. Across four challenging free-form QA datasets and multiple LLMs, our metrics achieve state-of-the-art hallucination detection and answer selection performance, while remaining robust and scalable with respect to sample size and embedding choice.
<div id='section'>Paperid: <span id='pid'>487, <a href='https://arxiv.org/pdf/2511.13541.pdf' target='_blank'>https://arxiv.org/pdf/2511.13541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Hou, Ruomei Liu, Yingke Su, Junran Wu, Ke Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.13541">Graph Out-of-Distribution Detection via Test-Time Calibration with Dual Dynamic Dictionaries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A key challenge in graph out-of-distribution (OOD) detection lies in the absence of ground-truth OOD samples during training. Existing methods are typically optimized to capture features within the in-distribution (ID) data and calculate OOD scores, which often limits pre-trained models from representing distributional boundaries, leading to unreliable OOD detection. Moreover, the latent structure of graph data is often governed by multiple underlying factors, which remains less explored. To address these challenges, we propose a novel test-time graph OOD detection method, termed BaCa, that calibrates OOD scores using dual dynamically updated dictionaries without requiring fine-tuning the pre-trained model. Specifically, BaCa estimates graphons and applies a mix-up strategy solely with test samples to generate diverse boundary-aware discriminative topologies, eliminating the need for exposing auxiliary datasets as outliers. We construct dual dynamic dictionaries via priority queues and attention mechanisms to adaptively capture latent ID and OOD representations, which are then utilized for boundary-aware OOD score calibration. To the best of our knowledge, extensive experiments on real-world datasets show that BaCa significantly outperforms existing state-of-the-art methods in OOD detection.
<div id='section'>Paperid: <span id='pid'>488, <a href='https://arxiv.org/pdf/2511.07694.pdf' target='_blank'>https://arxiv.org/pdf/2511.07694.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manh Nguyen, Sunil Gupta, Hung Le
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.07694">Probabilities Are All You Need: A Probability-Only Approach to Uncertainty Estimation in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) exhibit strong performance across various natural language processing (NLP) tasks but remain vulnerable to hallucinations, generating factually incorrect or misleading outputs. Uncertainty estimation, often using predictive entropy estimation, is key to addressing this issue. However, existing methods often require multiple samples or extra computation to assess semantic entropy. This paper proposes an efficient, training-free uncertainty estimation method that approximates predictive entropy using the responses' top-$K$ probabilities. Moreover, we employ an adaptive mechanism to determine $K$ to enhance flexibility and filter out low-confidence probabilities. Experimental results on three free-form question-answering datasets across several LLMs demonstrate that our method outperforms expensive state-of-the-art baselines, contributing to the broader goal of enhancing LLM trustworthiness.
<div id='section'>Paperid: <span id='pid'>489, <a href='https://arxiv.org/pdf/2510.14562.pdf' target='_blank'>https://arxiv.org/pdf/2510.14562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Hou, He Zhu, Ruomei Liu, Yingke Su, Junran Wu, Ke Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.14562">Redundancy-Aware Test-Time Graph Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distributional discrepancy between training and test data can lead models to make inaccurate predictions when encountering out-of-distribution (OOD) samples in real-world applications. Although existing graph OOD detection methods leverage data-centric techniques to extract effective representations, their performance remains compromised by structural redundancy that induces semantic shifts. To address this dilemma, we propose RedOUT, an unsupervised framework that integrates structural entropy into test-time OOD detection for graph classification. Concretely, we introduce the Redundancy-aware Graph Information Bottleneck (ReGIB) and decompose the objective into essential information and irrelevant redundancy. By minimizing structural entropy, the decoupled redundancy is reduced, and theoretically grounded upper and lower bounds are proposed for optimization. Extensive experiments on real-world datasets demonstrate the superior performance of RedOUT on OOD detection. Specifically, our method achieves an average improvement of 6.7%, significantly surpassing the best competitor by 17.3% on the ClinTox/LIPO dataset pair.
<div id='section'>Paperid: <span id='pid'>490, <a href='https://arxiv.org/pdf/2509.11800.pdf' target='_blank'>https://arxiv.org/pdf/2509.11800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ang Nan Gu, Michael Tsang, Hooman Vaseli, Purang Abolmaesumi, Teresa Tsang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11800">Pseudo-D: Informing Multi-View Uncertainty Estimation with Calibrated Neural Training Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computer-aided diagnosis systems must make critical decisions from medical images that are often noisy, ambiguous, or conflicting, yet today's models are trained on overly simplistic labels that ignore diagnostic uncertainty. One-hot labels erase inter-rater variability and force models to make overconfident predictions, especially when faced with incomplete or artifact-laden inputs. We address this gap by introducing a novel framework that brings uncertainty back into the label space. Our method leverages neural network training dynamics (NNTD) to assess the inherent difficulty of each training sample. By aggregating and calibrating model predictions during training, we generate uncertainty-aware pseudo-labels that reflect the ambiguity encountered during learning. This label augmentation approach is architecture-agnostic and can be applied to any supervised learning pipeline to enhance uncertainty estimation and robustness. We validate our approach on a challenging echocardiography classification benchmark, demonstrating superior performance over specialized baselines in calibration, selective classification, and multi-view fusion.
<div id='section'>Paperid: <span id='pid'>491, <a href='https://arxiv.org/pdf/2507.17796.pdf' target='_blank'>https://arxiv.org/pdf/2507.17796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicholas A. Pearson, Francesca Zanello, Davide Russo, Luca Bortolussi, Francesca Cairoli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.17796">CoCAI: Copula-based Conformal Anomaly Identification for Multivariate Time-Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel framework that harnesses the power of generative artificial intelligence and copula-based modeling to address two critical challenges in multivariate time-series analysis: delivering accurate predictions and enabling robust anomaly detection. Our method, Copula-based Conformal Anomaly Identification for Multivariate Time-Series (CoCAI), leverages a diffusion-based model to capture complex dependencies within the data, enabling high quality forecasting. The model's outputs are further calibrated using a conformal prediction technique, yielding predictive regions which are statistically valid, i.e., cover the true target values with a desired confidence level. Starting from these calibrated forecasts, robust outlier detection is performed by combining dimensionality reduction techniques with copula-based modeling, providing a statistically grounded anomaly score. CoCAI benefits from an offline calibration phase that allows for minimal overhead during deployment and delivers actionable results rooted in established theoretical foundations. Empirical tests conducted on real operational data derived from water distribution and sewerage systems confirm CoCAI's effectiveness in accurately forecasting target sequences of data and in identifying anomalous segments within them.
<div id='section'>Paperid: <span id='pid'>492, <a href='https://arxiv.org/pdf/2506.15404.pdf' target='_blank'>https://arxiv.org/pdf/2506.15404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anju Chhetri, Jari Korhonen, Prashnna Gyawali, Binod Bhattarai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15404">NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensuring reliability is paramount in deep learning, particularly within the domain of medical imaging, where diagnostic decisions often hinge on model outputs. The capacity to separate out-of-distribution (OOD) samples has proven to be a valuable indicator of a model's reliability in research. In medical imaging, this is especially critical, as identifying OOD inputs can help flag potential anomalies that might otherwise go undetected. While many OOD detection methods rely on feature or logit space representations, recent works suggest these approaches may not fully capture OOD diversity. To address this, we propose a novel OOD scoring mechanism, called NERO, that leverages neuron-level relevance at the feature layer. Specifically, we cluster neuron-level relevance for each in-distribution (ID) class to form representative centroids and introduce a relevance distance metric to quantify a new sample's deviation from these centroids, enhancing OOD separability. Additionally, we refine performance by incorporating scaled relevance in the bias term and combining feature norms. Our framework also enables explainable OOD detection. We validate its effectiveness across multiple deep learning architectures on the gastrointestinal imaging benchmarks Kvasir and GastroVision, achieving improvements over state-of-the-art OOD detection methods.
<div id='section'>Paperid: <span id='pid'>493, <a href='https://arxiv.org/pdf/2505.22538.pdf' target='_blank'>https://arxiv.org/pdf/2505.22538.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Hofman, Yusuf Sale, Eyke HÃ¼llermeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22538">Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to Prediction Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We address the problem of uncertainty quantification and propose measures of total, aleatoric, and epistemic uncertainty based on a known decomposition of (strictly) proper scoring rules, a specific type of loss function, into a divergence and an entropy component. This leads to a flexible framework for uncertainty quantification that can be instantiated with different losses (scoring rules), which makes it possible to tailor uncertainty quantification to the use case at hand. We show that this flexibility is indeed advantageous. In particular, we analyze the task of selective prediction and show that the scoring rule should ideally match the task loss. In addition, we perform experiments on two other common tasks. For out-of-distribution detection, our results confirm that a widely used measure of epistemic uncertainty, mutual information, performs best. Moreover, in the setting of active learning, our measure of epistemic uncertainty based on the zero-one-loss consistently outperforms other uncertainty measures.
<div id='section'>Paperid: <span id='pid'>494, <a href='https://arxiv.org/pdf/2505.15284.pdf' target='_blank'>https://arxiv.org/pdf/2505.15284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Fang, Qinghua Tao, Mingzhen He, Kexin Lv, Runze Yang, Haibo Hu, Xiaolin Huang, Jie Yang, Longbin Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15284">Kernel PCA for Out-of-Distribution Detection: Non-Linear Kernel Selections and Approximations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OoD) detection is vital for the reliability of deep neural networks, the key of which lies in effectively characterizing the disparities between OoD and In-Distribution (InD) data. In this work, such disparities are exploited through a fresh perspective of non-linear feature subspace. That is, a discriminative non-linear subspace is learned from InD features to capture representative patterns of InD, while informative patterns of OoD features cannot be well captured in such a subspace due to their different distribution. Grounded on this perspective, we exploit the deviations of InD and OoD features in such a non-linear subspace for effective OoD detection. To be specific, we leverage the framework of Kernel Principal Component Analysis (KPCA) to attain the discriminative non-linear subspace and deploy the reconstruction error on such subspace to distinguish InD and OoD data. Two challenges emerge: (i) the learning of an effective non-linear subspace, i.e., the selection of kernel function in KPCA, and (ii) the computation of the kernel matrix with large-scale InD data. For the former, we reveal two vital non-linear patterns that closely relate to the InD-OoD disparity, leading to the establishment of a Cosine-Gaussian kernel for constructing the subspace. For the latter, we introduce two techniques to approximate the Cosine-Gaussian kernel with significantly cheap computations. In particular, our approximation is further tailored by incorporating the InD data confidence, which is demonstrated to promote the learning of discriminative subspaces for OoD data. Our study presents new insights into the non-linear feature subspace for OoD detection and contributes practical explorations on the associated kernel design and efficient computations, yielding a KPCA detection method with distinctively improved efficacy and efficiency.
<div id='section'>Paperid: <span id='pid'>495, <a href='https://arxiv.org/pdf/2504.04841.pdf' target='_blank'>https://arxiv.org/pdf/2504.04841.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Schmidt, Julius KÃ¶rner, Dominik Fuchsgruber, Stefano Gasperini, Federico Tombari, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04841">Prior2Former -- Evidential Modeling of Mask Transformers for Assumption-Free Open-World Panoptic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In panoptic segmentation, individual instances must be separated within semantic classes. As state-of-the-art methods rely on a pre-defined set of classes, they struggle with novel categories and out-of-distribution (OOD) data. This is particularly problematic in safety-critical applications, such as autonomous driving, where reliability in unseen scenarios is essential. We address the gap between outstanding benchmark performance and reliability by proposing Prior2Former (P2F), the first approach for segmentation vision transformers rooted in evidential learning. P2F extends the mask vision transformer architecture by incorporating a Beta prior for computing model uncertainty in pixel-wise binary mask assignments. This design enables high-quality uncertainty estimation that effectively detects novel and OOD objects enabling state-of-the-art anomaly instance segmentation and open-world panoptic segmentation. Unlike most segmentation models addressing unknown classes, P2F operates without access to OOD data samples or contrastive training on void (i.e., unlabeled) classes, making it highly applicable in real-world scenarios where such prior information is unavailable. Additionally, P2F can be flexibly applied to anomaly instance and panoptic segmentation. Through comprehensive experiments on the Cityscapes, COCO, SegmentMeIfYouCan, and OoDIS datasets, P2F demonstrates state-of-the-art performance across the board.
<div id='section'>Paperid: <span id='pid'>496, <a href='https://arxiv.org/pdf/2503.18562.pdf' target='_blank'>https://arxiv.org/pdf/2503.18562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nariman Naderi, Seyed Amir Ahmad Safavi-Naini, Thomas Savage, Zahra Atf, Peter Lewis, Girish Nadkarni, Ali Soroush
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18562">Self-Reported Confidence of Large Language Models in Gastroenterology: Analysis of Commercial, Open-Source, and Quantized Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study evaluated self-reported response certainty across several large language models (GPT, Claude, Llama, Phi, Mistral, Gemini, Gemma, and Qwen) using 300 gastroenterology board-style questions. The highest-performing models (GPT-o1 preview, GPT-4o, and Claude-3.5-Sonnet) achieved Brier scores of 0.15-0.2 and AUROC of 0.6. Although newer models demonstrated improved performance, all exhibited a consistent tendency towards overconfidence. Uncertainty estimation presents a significant challenge to the safe use of LLMs in healthcare. Keywords: Large Language Models; Confidence Elicitation; Artificial Intelligence; Gastroenterology; Uncertainty Quantification
<div id='section'>Paperid: <span id='pid'>497, <a href='https://arxiv.org/pdf/2503.16978.pdf' target='_blank'>https://arxiv.org/pdf/2503.16978.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruoqi Zhang, Ziwei Luo, Jens SjÃ¶lund, Per Mattsson, Linus GisslÃ©n, Alessandro Sestini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16978">Real-Time Diffusion Policies for Games: Enhancing Consistency Policies with Q-Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have shown impressive performance in capturing complex and multi-modal action distributions for game agents, but their slow inference speed prevents practical deployment in real-time game environments. While consistency models offer a promising approach for one-step generation, they often suffer from training instability and performance degradation when applied to policy learning. In this paper, we present CPQE (Consistency Policy with Q-Ensembles), which combines consistency models with Q-ensembles to address these challenges.CPQE leverages uncertainty estimation through Q-ensembles to provide more reliable value function approximations, resulting in better training stability and improved performance compared to classic double Q-network methods. Our extensive experiments across multiple game scenarios demonstrate that CPQE achieves inference speeds of up to 60 Hz -- a significant improvement over state-of-the-art diffusion policies that operate at only 20 Hz -- while maintaining comparable performance to multi-step diffusion approaches. CPQE consistently outperforms state-of-the-art consistency model approaches, showing both higher rewards and enhanced training stability throughout the learning process. These results indicate that CPQE offers a practical solution for deploying diffusion-based policies in games and other real-time applications where both multi-modal behavior modeling and rapid inference are critical requirements.
<div id='section'>Paperid: <span id='pid'>498, <a href='https://arxiv.org/pdf/2503.07330.pdf' target='_blank'>https://arxiv.org/pdf/2503.07330.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changshun Wu, Weicheng He, Chih-Hong Cheng, Xiaowei Huang, Saddek Bensalem
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07330">Revisiting Out-of-Distribution Detection in Real-time Object Detection: From Benchmark Pitfalls to a New Mitigation Paradigm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OoD) inputs pose a persistent challenge to deep learning models, often triggering overconfident predictions on non-target objects. While prior work has primarily focused on refining scoring functions and adjusting test-time thresholds, such algorithmic improvements offer only incremental gains. We argue that a rethinking of the entire development lifecycle is needed to mitigate these risks effectively. This work addresses two overlooked dimensions of OoD detection in object detection. First, we reveal fundamental flaws in widely used evaluation benchmarks: contrary to their design intent, up to 13% of objects in the OoD test sets actually belong to in-distribution classes, and vice versa. These quality issues severely distort the reported performance of existing methods and contribute to their high false positive rates. Second, we introduce a novel training-time mitigation paradigm that operates independently of external OoD detectors. Instead of relying solely on post-hoc scoring, we fine-tune the detector using a carefully synthesized OoD dataset that semantically resembles in-distribution objects. This process shapes a defensive decision boundary by suppressing objectness on OoD objects, leading to a 91% reduction in hallucination error of a YOLO model on BDD-100K. Our methodology generalizes across detection paradigms such as YOLO, Faster R-CNN, and RT-DETR, and supports few-shot adaptation. Together, these contributions offer a principled and effective way to reduce OoD-induced hallucination in object detectors. Code and data are available at: https://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood.
<div id='section'>Paperid: <span id='pid'>499, <a href='https://arxiv.org/pdf/2503.03241.pdf' target='_blank'>https://arxiv.org/pdf/2503.03241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Hou, He Zhu, Ruomei Liu, Yingke Su, Jinxiang Xia, Junran Wu, Ke Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.03241">Structural Entropy Guided Unsupervised Graph Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the emerging of huge amount of unlabeled data, unsupervised out-of-distribution (OOD) detection is vital for ensuring the reliability of graph neural networks (GNNs) by identifying OOD samples from in-distribution (ID) ones during testing, where encountering novel or unknown data is inevitable. Existing methods often suffer from compromised performance due to redundant information in graph structures, which impairs their ability to effectively differentiate between ID and OOD data. To address this challenge, we propose SEGO, an unsupervised framework that integrates structural entropy into OOD detection regarding graph classification. Specifically, within the architecture of contrastive learning, SEGO introduces an anchor view in the form of coding tree by minimizing structural entropy. The obtained coding tree effectively removes redundant information from graphs while preserving essential structural information, enabling the capture of distinct graph patterns between ID and OOD samples. Furthermore, we present a multi-grained contrastive learning scheme at local, global, and tree levels using triplet views, where coding trees with essential information serve as the anchor view. Extensive experiments on real-world datasets validate the effectiveness of SEGO, demonstrating superior performance over state-of-the-art baselines in OOD detection. Specifically, our method achieves the best performance on 9 out of 10 dataset pairs, with an average improvement of 3.7\% on OOD detection datasets, significantly surpassing the best competitor by 10.8\% on the FreeSolv/ToxCast dataset pair.
<div id='section'>Paperid: <span id='pid'>500, <a href='https://arxiv.org/pdf/2501.08286.pdf' target='_blank'>https://arxiv.org/pdf/2501.08286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ke Wu, Zicheng Zhang, Muer Tie, Ziqing Ai, Zhongxue Gan, Wenchao Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08286">VINGS-Mono: Visual-Inertial Gaussian Splatting Monocular SLAM in Large Scenes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>VINGS-Mono is a monocular (inertial) Gaussian Splatting (GS) SLAM framework designed for large scenes. The framework comprises four main components: VIO Front End, 2D Gaussian Map, NVS Loop Closure, and Dynamic Eraser. In the VIO Front End, RGB frames are processed through dense bundle adjustment and uncertainty estimation to extract scene geometry and poses. Based on this output, the mapping module incrementally constructs and maintains a 2D Gaussian map. Key components of the 2D Gaussian Map include a Sample-based Rasterizer, Score Manager, and Pose Refinement, which collectively improve mapping speed and localization accuracy. This enables the SLAM system to handle large-scale urban environments with up to 50 million Gaussian ellipsoids. To ensure global consistency in large-scale scenes, we design a Loop Closure module, which innovatively leverages the Novel View Synthesis (NVS) capabilities of Gaussian Splatting for loop closure detection and correction of the Gaussian map. Additionally, we propose a Dynamic Eraser to address the inevitable presence of dynamic objects in real-world outdoor scenes. Extensive evaluations in indoor and outdoor environments demonstrate that our approach achieves localization performance on par with Visual-Inertial Odometry while surpassing recent GS/NeRF SLAM methods. It also significantly outperforms all existing methods in terms of mapping and rendering quality. Furthermore, we developed a mobile app and verified that our framework can generate high-quality Gaussian maps in real time using only a smartphone camera and a low-frequency IMU sensor. To the best of our knowledge, VINGS-Mono is the first monocular Gaussian SLAM method capable of operating in outdoor environments and supporting kilometer-scale large scenes.
<div id='section'>Paperid: <span id='pid'>501, <a href='https://arxiv.org/pdf/2411.00826.pdf' target='_blank'>https://arxiv.org/pdf/2411.00826.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Zhang, Ming Li, Chun Li, Zhaoxia Liu, Ye Zhang, Fei Richard Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00826">Uncertainty Quantification via HÃ¶lder Divergence for Multi-View Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evidence-based deep learning represents a burgeoning paradigm for uncertainty estimation, offering reliable predictions with negligible extra computational overheads. Existing methods usually adopt Kullback-Leibler divergence to estimate the uncertainty of network predictions, ignoring domain gaps among various modalities. To tackle this issue, this paper introduces a novel algorithm based on HÃ¶lder Divergence (HD) to enhance the reliability of multi-view learning by addressing inherent uncertainty challenges from incomplete or noisy data. Generally, our method extracts the representations of multiple modalities through parallel network branches, and then employs HD to estimate the prediction uncertainties. Through the Dempster-Shafer theory, integration of uncertainty from different modalities, thereby generating a comprehensive result that considers all available representations. Mathematically, HD proves to better measure the ``distance'' between real data distribution and predictive distribution of the model and improve the performances of multi-class recognition tasks.
  Specifically, our method surpass the existing state-of-the-art counterparts on all evaluating benchmarks.
  We further conduct extensive experiments on different backbones to verify our superior robustness. It is demonstrated that our method successfully pushes the corresponding performance boundaries. Finally, we perform experiments on more challenging scenarios, \textit{i.e.}, learning with incomplete or noisy data, revealing that our method exhibits a high tolerance to such corrupted data.
<div id='section'>Paperid: <span id='pid'>502, <a href='https://arxiv.org/pdf/2409.08756.pdf' target='_blank'>https://arxiv.org/pdf/2409.08756.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin Bubel, Jochen Schmid, Maximilian Carmesin, Volodymyr Kozachynskyi, Erik Esche, Michael Bortz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08756">Cubature-based uncertainty estimation for nonlinear regression models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Calibrating model parameters to measured data by minimizing loss functions is an important step in obtaining realistic predictions from model-based approaches, e.g., for process optimization. This is applicable to both knowledge-driven and data-driven model setups. Due to measurement errors, the calibrated model parameters also carry uncertainty. In this contribution, we use cubature formulas based on sparse grids to calculate the variance of the regression results. The number of cubature points is close to the theoretical minimum required for a given level of exactness. We present exact benchmark results, which we also compare to other cubatures. This scheme is then applied to estimate the prediction uncertainty of the NRTL model, calibrated to observations from different experimental designs.
<div id='section'>Paperid: <span id='pid'>503, <a href='https://arxiv.org/pdf/2407.14024.pdf' target='_blank'>https://arxiv.org/pdf/2407.14024.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sandesh Pokhrel, Sanjay Bhandari, Eduard Vazquez, Tryphon Lambrou, Prashnna Gyawali, Binod Bhattarai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14024">TTA-OOD: Test-time Augmentation for Improving Out-of-Distribution Detection in Gastrointestinal Vision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has significantly advanced the field of gastrointestinal vision, enhancing disease diagnosis capabilities. One major challenge in automating diagnosis within gastrointestinal settings is the detection of abnormal cases in endoscopic images. Due to the sparsity of data, this process of distinguishing normal from abnormal cases has faced significant challenges, particularly with rare and unseen conditions. To address this issue, we frame abnormality detection as an out-of-distribution (OOD) detection problem. In this setup, a model trained on In-Distribution (ID) data, which represents a healthy GI tract, can accurately identify healthy cases, while abnormalities are detected as OOD, regardless of their class. We introduce a test-time augmentation segment into the OOD detection pipeline, which enhances the distinction between ID and OOD examples, thereby improving the effectiveness of existing OOD methods with the same model. This augmentation shifts the pixel space, which translates into a more distinct semantic representation for OOD examples compared to ID examples. We evaluated our method against existing state-of-the-art OOD scores, showing improvements with test-time augmentation over the baseline approach.
<div id='section'>Paperid: <span id='pid'>504, <a href='https://arxiv.org/pdf/2407.08662.pdf' target='_blank'>https://arxiv.org/pdf/2407.08662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08662">Uncertainty Estimation of Large Language Models in Medical Question Answering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) show promise for natural language generation in healthcare, but risk hallucinating factually incorrect information. Deploying LLMs for medical question answering necessitates reliable uncertainty estimation (UE) methods to detect hallucinations. In this work, we benchmark popular UE methods with different model sizes on medical question-answering datasets. Our results show that current approaches generally perform poorly in this domain, highlighting the challenge of UE for medical applications. We also observe that larger models tend to yield better results, suggesting a correlation between model size and the reliability of UE. To address these challenges, we propose Two-phase Verification, a probability-free Uncertainty Estimation approach. First, an LLM generates a step-by-step explanation alongside its initial answer, followed by formulating verification questions to check the factual claims in the explanation. The model then answers these questions twice: first independently, and then referencing the explanation. Inconsistencies between the two sets of answers measure the uncertainty in the original response. We evaluate our approach on three biomedical question-answering datasets using Llama 2 Chat models and compare it against the benchmarked baseline methods. The results show that our Two-phase Verification method achieves the best overall accuracy and stability across various datasets and model sizes, and its performance scales as the model size increases.
<div id='section'>Paperid: <span id='pid'>505, <a href='https://arxiv.org/pdf/2405.01691.pdf' target='_blank'>https://arxiv.org/pdf/2405.01691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenjiang Mao, Dong-You Jhong, Ao Wang, Ivan Ruchkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01691">Language-Enhanced Latent Representations for Out-of-Distribution Detection in Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential in autonomous driving, to determine when learning-based components encounter unexpected inputs. Traditional detectors typically use encoder models with fixed settings, thus lacking effective human interaction capabilities. With the rise of large foundation models, multimodal inputs offer the possibility of taking human language as a latent representation, thus enabling language-defined OOD detection. In this paper, we use the cosine similarity of image and text representations encoded by the multimodal model CLIP as a new representation to improve the transparency and controllability of latent encodings used for visual anomaly detection. We compare our approach with existing pre-trained encoders that can only produce latent representations that are meaningless from the user's standpoint. Our experiments on realistic driving data show that the language-based latent representation performs better than the traditional representation of the vision encoder and helps improve the detection performance when combined with standard representations.
<div id='section'>Paperid: <span id='pid'>506, <a href='https://arxiv.org/pdf/2404.06144.pdf' target='_blank'>https://arxiv.org/pdf/2404.06144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fatima Ezzeddine, Mirna Saad, Omran Ayoub, Davide Andreoletti, Martin Gjoreski, Ihab Sbeity, Marc Langheinrich, Silvia Giordano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06144">Differential Privacy for Anomaly Detection: Analyzing the Trade-off Between Privacy and Explainability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection (AD), also referred to as outlier detection, is a statistical process aimed at identifying observations within a dataset that significantly deviate from the expected pattern of the majority of the data. Such a process finds wide application in various fields, such as finance and healthcare. While the primary objective of AD is to yield high detection accuracy, the requirements of explainability and privacy are also paramount. The first ensures the transparency of the AD process, while the second guarantees that no sensitive information is leaked to untrusted parties. In this work, we exploit the trade-off of applying Explainable AI (XAI) through SHapley Additive exPlanations (SHAP) and differential privacy (DP). We perform AD with different models and on various datasets, and we thoroughly evaluate the cost of privacy in terms of decreased accuracy and explainability. Our results show that the enforcement of privacy through DP has a significant impact on detection accuracy and explainability, which depends on both the dataset and the considered AD model. We further show that the visual interpretation of explanations is also influenced by the choice of the AD algorithm.
<div id='section'>Paperid: <span id='pid'>507, <a href='https://arxiv.org/pdf/2402.12664.pdf' target='_blank'>https://arxiv.org/pdf/2402.12664.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Zhang, Kamalika Das, Sricharan Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12664">Discriminant Distance-Aware Representation on Deterministic Uncertainty Quantification Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a crucial aspect of deploying dependable deep learning models in safety-critical systems. In this study, we introduce a novel and efficient method for deterministic uncertainty estimation called Discriminant Distance-Awareness Representation (DDAR). Our approach involves constructing a DNN model that incorporates a set of prototypes in its latent representations, enabling us to analyze valuable feature information from the input data. By leveraging a distinction maximization layer over optimal trainable prototypes, DDAR can learn a discriminant distance-awareness representation. We demonstrate that DDAR overcomes feature collapse by relaxing the Lipschitz constraint that hinders the practicality of deterministic uncertainty methods (DUMs) architectures. Our experiments show that DDAR is a flexible and architecture-agnostic method that can be easily integrated as a pluggable layer with distance-sensitive metrics, outperforming state-of-the-art uncertainty estimation methods on multiple benchmark problems.
<div id='section'>Paperid: <span id='pid'>508, <a href='https://arxiv.org/pdf/2402.07452.pdf' target='_blank'>https://arxiv.org/pdf/2402.07452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinyu Ye, Shijing Chen, Dong Ni, Ruobing Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07452">TriAug: Out-of-Distribution Detection for Imbalanced Breast Lesion in Ultrasound</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Different diseases, such as histological subtypes of breast lesions, have severely varying incidence rates. Even trained with substantial amount of in-distribution (ID) data, models often encounter out-of-distribution (OOD) samples belonging to unseen classes in clinical reality. To address this, we propose a novel framework built upon a long-tailed OOD detection task for breast ultrasound images. It is equipped with a triplet state augmentation (TriAug) which improves ID classification accuracy while maintaining a promising OOD detection performance. Meanwhile, we designed a balanced sphere loss to handle the class imbalanced problem. Experimental results show that the model outperforms state-of-art OOD approaches both in ID classification (F1-score=42.12%) and OOD detection (AUROC=78.06%).
<div id='section'>Paperid: <span id='pid'>509, <a href='https://arxiv.org/pdf/2402.02949.pdf' target='_blank'>https://arxiv.org/pdf/2402.02949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Fang, Qinghua Tao, Kexin Lv, Mingzhen He, Xiaolin Huang, Jie Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.02949">Kernel PCA for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper non-linear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, and seek suitable non-linear kernels that advocate the separability between InD and OoD data in the subspace spanned by the principal components. Besides, explicit feature mappings induced from the devoted task-specific kernels are adopted so that the KPCA reconstruction error for new test samples can be efficiently obtained with large-scale data. Extensive theoretical and empirical results on multiple OoD data sets and network structures verify the superiority of our KPCA detector in efficiency and efficacy with state-of-the-art detection performance.
<div id='section'>Paperid: <span id='pid'>510, <a href='https://arxiv.org/pdf/2512.12906.pdf' target='_blank'>https://arxiv.org/pdf/2512.12906.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhimao Peng, Enguang Wang, Xialei Liu, Ming-Ming Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.12906">Predictive Sample Assignment for Semantically Coherent Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantically coherent out-of-distribution detection (SCOOD) is a recently proposed realistic OOD detection setting: given labeled in-distribution (ID) data and mixed in-distribution and out-of-distribution unlabeled data as the training data, SCOOD aims to enable the trained model to accurately identify OOD samples in the testing data. Current SCOOD methods mainly adopt various clustering-based in-distribution sample filtering (IDF) strategies to select clean ID samples from unlabeled data, and take the remaining samples as auxiliary OOD data, which inevitably introduces a large number of noisy samples in training. To address the above issue, we propose a concise SCOOD framework based on predictive sample assignment (PSA). PSA includes a dual-threshold ternary sample assignment strategy based on the predictive energy score that can significantly improve the purity of the selected ID and OOD sample sets by assigning unconfident unlabeled data to an additional discard sample set, and a concept contrastive representation learning loss to further expand the distance between ID and OOD samples in the representation space to assist ID/OOD discrimination. In addition, we also introduce a retraining strategy to help the model fully fit the selected auxiliary ID/OOD samples. Experiments on two standard SCOOD benchmarks demonstrate that our approach outperforms the state-of-the-art methods by a significant margin.
<div id='section'>Paperid: <span id='pid'>511, <a href='https://arxiv.org/pdf/2512.10659.pdf' target='_blank'>https://arxiv.org/pdf/2512.10659.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tommaso Amico, Pernille Matthews, Lena Krieger, Arthur Zimek, Ira Assent
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.10659">DCFO: Density-Based Counterfactuals for Outliers - Additional Material</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection identifies data points that significantly deviate from the majority of the data distribution. Explaining outliers is crucial for understanding the underlying factors that contribute to their detection, validating their significance, and identifying potential biases or errors. Effective explanations provide actionable insights, facilitating preventive measures to avoid similar outliers in the future. Counterfactual explanations clarify why specific data points are classified as outliers by identifying minimal changes required to alter their prediction. Although valuable, most existing counterfactual explanation methods overlook the unique challenges posed by outlier detection, and fail to target classical, widely adopted outlier detection algorithms. Local Outlier Factor (LOF) is one the most popular unsupervised outlier detection methods, quantifying outlierness through relative local density. Despite LOF's widespread use across diverse applications, it lacks interpretability. To address this limitation, we introduce Density-based Counterfactuals for Outliers (DCFO), a novel method specifically designed to generate counterfactual explanations for LOF. DCFO partitions the data space into regions where LOF behaves smoothly, enabling efficient gradient-based optimisation. Extensive experimental validation on 50 OpenML datasets demonstrates that DCFO consistently outperforms benchmarked competitors, offering superior proximity and validity of generated counterfactuals.
<div id='section'>Paperid: <span id='pid'>512, <a href='https://arxiv.org/pdf/2512.08216.pdf' target='_blank'>https://arxiv.org/pdf/2512.08216.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aneesh Rangnekar, Harini Veeraraghavan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.08216">Tumor-anchored deep feature random forests for out-of-distribution detection in lung cancer segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate segmentation of cancerous lesions from 3D computed tomography (CT) scans is essential for automated treatment planning and response assessment. However, even state-of-the-art models combining self-supervised learning (SSL) pretrained transformers with convolutional decoders are susceptible to out-of-distribution (OOD) inputs, generating confidently incorrect tumor segmentations, posing risks for safe clinical deployment. Existing logit-based methods suffer from task-specific model biases, while architectural enhancements to explicitly detect OOD increase parameters and computational costs. Hence, we introduce a plug-and-play and lightweight post-hoc random forests-based OOD detection framework called RF-Deep that leverages deep features with limited outlier exposure. RF-Deep enhances generalization to imaging variations by repurposing the hierarchical features from the pretrained-then-finetuned backbone encoder, providing task-relevant OOD detection by extracting the features from multiple regions of interest anchored to the predicted tumor segmentations. Hence, it scales to images of varying fields-of-view. We compared RF-Deep against existing OOD detection methods using 1,916 CT scans across near-OOD (pulmonary embolism, negative COVID-19) and far-OOD (kidney cancer, healthy pancreas) datasets. RF-Deep achieved AUROC > 93.50 for the challenging near-OOD datasets and near-perfect detection (AUROC > 99.00) for the far-OOD datasets, substantially outperforming logit-based and radiomics approaches. RF-Deep maintained similar performance consistency across networks of different depths and pretraining strategies, demonstrating its effectiveness as a lightweight, architecture-agnostic approach to enhance the reliability of tumor segmentation from CT volumes.
<div id='section'>Paperid: <span id='pid'>513, <a href='https://arxiv.org/pdf/2512.08129.pdf' target='_blank'>https://arxiv.org/pdf/2512.08129.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guangmingmei Yang, David J. Miller, George Kesidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.08129">Improving the Sensitivity of Backdoor Detectors via Class Subspace Orthogonalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most post-training backdoor detection methods rely on attacked models exhibiting extreme outlier detection statistics for the target class of an attack, compared to non-target classes. However, these approaches may fail: (1) when some (non-target) classes are easily discriminable from all others, in which case they may naturally achieve extreme detection statistics (e.g., decision confidence); and (2) when the backdoor is subtle, i.e., with its features weak relative to intrinsic class-discriminative features. A key observation is that the backdoor target class has contributions to its detection statistic from both the backdoor trigger and from its intrinsic features, whereas non-target classes only have contributions from their intrinsic features. To achieve more sensitive detectors, we thus propose to suppress intrinsic features while optimizing the detection statistic for a given class. For non-target classes, such suppression will drastically reduce the achievable statistic, whereas for the target class the (significant) contribution from the backdoor trigger remains. In practice, we formulate a constrained optimization problem, leveraging a small set of clean examples from a given class, and optimizing the detection statistic while orthogonalizing with respect to the class's intrinsic features. We dub this plug-and-play approach Class Subspace Orthogonalization (CSO) and assess it against challenging mixed-label and adaptive attacks.
<div id='section'>Paperid: <span id='pid'>514, <a href='https://arxiv.org/pdf/2512.07400.pdf' target='_blank'>https://arxiv.org/pdf/2512.07400.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giulia Lanzillotta, Damiano Meier, Thomas Hofmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.07400">Asymptotic analysis of shallow and deep forgetting in replay with Neural Collapse</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A persistent paradox in continual learning (CL) is that neural networks often retain linearly separable representations of past tasks even when their output predictions fail. We formalize this distinction as the gap between deep feature-space and shallow classifier-level forgetting. We reveal a critical asymmetry in Experience Replay: while minimal buffers successfully anchor feature geometry and prevent deep forgetting, mitigating shallow forgetting typically requires substantially larger buffer capacities. To explain this, we extend the Neural Collapse framework to the sequential setting. We characterize deep forgetting as a geometric drift toward out-of-distribution subspaces and prove that any non-zero replay fraction asymptotically guarantees the retention of linear separability. Conversely, we identify that the "strong collapse" induced by small buffers leads to rank-deficient covariances and inflated class means, effectively blinding the classifier to true population boundaries. By unifying CL with out-of-distribution detection, our work challenges the prevailing reliance on large buffers, suggesting that explicitly correcting these statistical artifacts could unlock robust performance with minimal replay.
<div id='section'>Paperid: <span id='pid'>515, <a href='https://arxiv.org/pdf/2510.06505.pdf' target='_blank'>https://arxiv.org/pdf/2510.06505.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Momin Abbas, Ali Falahati, Hossein Goli, Mohammad Mohammadi Amiri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06505">A Median Perspective on Unlabeled Data for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection plays a crucial role in ensuring the robustness and reliability of machine learning systems deployed in real-world applications. Recent approaches have explored the use of unlabeled data, showing potential for enhancing OOD detection capabilities. However, effectively utilizing unlabeled in-the-wild data remains challenging due to the mixed nature of both in-distribution (InD) and OOD samples. The lack of a distinct set of OOD samples complicates the task of training an optimal OOD classifier. In this work, we introduce Medix, a novel framework designed to identify potential outliers from unlabeled data using the median operation. We use the median because it provides a stable estimate of the central tendency, as an OOD detection mechanism, due to its robustness against noise and outliers. Using these identified outliers, along with labeled InD data, we train a robust OOD classifier. From a theoretical perspective, we derive error bounds that demonstrate Medix achieves a low error rate. Empirical results further substantiate our claims, as Medix outperforms existing methods across the board in open-world settings, confirming the validity of our theoretical insights.
<div id='section'>Paperid: <span id='pid'>516, <a href='https://arxiv.org/pdf/2509.23480.pdf' target='_blank'>https://arxiv.org/pdf/2509.23480.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shourya Verma, Mengbo Wang, Nadia Atallah Lanman, Ananth Grama
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.23480">RestoRect: Degraded Image Restoration via Latent Rectified Flow & Feature Distillation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current approaches for restoration of degraded images face a critical trade-off: high-performance models are too slow for practical use, while fast models produce poor results. Knowledge distillation transfers teacher knowledge to students, but existing static feature matching methods cannot capture how modern transformer architectures dynamically generate features. We propose 'RestoRect', a novel Latent Rectified Flow Feature Distillation method for restoring degraded images. We apply rectified flow to reformulate feature distillation as a generative process where students learn to synthesize teacher-quality features through learnable trajectories in latent space. Our framework combines Retinex theory for physics-based decomposition with learnable anisotropic diffusion constraints, and trigonometric color space polarization. We introduce a Feature Layer Extraction loss for robust knowledge transfer between different network architectures through cross-normalized transformer feature alignment with percentile-based outlier detection. RestoRect achieves better training stability, and faster convergence and inference while preserving restoration quality. We demonstrate superior results across 15 image restoration datasets, covering 4 tasks, on 8 metrics.
<div id='section'>Paperid: <span id='pid'>517, <a href='https://arxiv.org/pdf/2509.03551.pdf' target='_blank'>https://arxiv.org/pdf/2509.03551.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shubham Mishra, The Anh Han, Bruno Silvester Lopes, Shatha Ghareeb, Zia Ush Shamszaman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03551">Predicting Antimicrobial Resistance (AMR) in Campylobacter, a Foodborne Pathogen, and Cost Burden Analysis Using Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antimicrobial resistance (AMR) poses a significant public health and economic challenge, increasing treatment costs and reducing antibiotic effectiveness. This study employs machine learning to analyze genomic and epidemiological data from the public databases for molecular typing and microbial genome diversity (PubMLST), incorporating data from UK government-supported AMR surveillance by the Food Standards Agency and Food Standards Scotland. We identify AMR patterns in Campylobacter jejuni and Campylobacter coli isolates collected in the UK from 2001 to 2017. The research integrates whole-genome sequencing (WGS) data, epidemiological metadata, and economic projections to identify key resistance determinants and forecast future resistance trends and healthcare costs. We investigate gyrA mutations for fluoroquinolone resistance and the tet(O) gene for tetracycline resistance, training a Random Forest model validated with bootstrap resampling (1,000 samples, 95% confidence intervals), achieving 74% accuracy in predicting AMR phenotypes. Time-series forecasting models (SARIMA, SIR, and Prophet) predict a rise in campylobacteriosis cases, potentially exceeding 130 cases per 100,000 people by 2050, with an economic burden projected to surpass 1.9 billion GBP annually if left unchecked. An enhanced Random Forest system, analyzing 6,683 isolates, refines predictions by incorporating temporal patterns, uncertainty estimation, and resistance trend modeling, indicating sustained high beta-lactam resistance, increasing fluoroquinolone resistance, and fluctuating tetracycline resistance.
<div id='section'>Paperid: <span id='pid'>518, <a href='https://arxiv.org/pdf/2508.19112.pdf' target='_blank'>https://arxiv.org/pdf/2508.19112.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aneesh Rangnekar, Harini Veeraraghavan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19112">Random forest-based out-of-distribution detection for robust lung cancer segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate detection and segmentation of cancerous lesions from computed tomography (CT) scans is essential for automated treatment planning and cancer treatment response assessment. Transformer-based models with self-supervised pretraining can produce reliably accurate segmentation from in-distribution (ID) data but degrade when applied to out-of-distribution (OOD) datasets. We address this challenge with RF-Deep, a random forest classifier that utilizes deep features from a pretrained transformer encoder of the segmentation model to detect OOD scans and enhance segmentation reliability. The segmentation model comprises a Swin Transformer encoder, pretrained with masked image modeling (SimMIM) on 10,432 unlabeled 3D CT scans covering cancerous and non-cancerous conditions, with a convolution decoder, trained to segment lung cancers in 317 3D scans. Independent testing was performed on 603 3D CT public datasets that included one ID dataset and four OOD datasets comprising chest CTs with pulmonary embolism (PE) and COVID-19, and abdominal CTs with kidney cancers and healthy volunteers. RF-Deep detected OOD cases with a FPR95 of 18.26%, 27.66%, and less than 0.1% on PE, COVID-19, and abdominal CTs, consistently outperforming established OOD approaches. The RF-Deep classifier provides a simple and effective approach to enhance reliability of cancer segmentation in ID and OOD scenarios.
<div id='section'>Paperid: <span id='pid'>519, <a href='https://arxiv.org/pdf/2505.18280.pdf' target='_blank'>https://arxiv.org/pdf/2505.18280.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tsai Hor Chan, Dora Yan Zhang, Guosheng Yin, Lequan Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18280">Feature Preserving Shrinkage on Bayesian Neural Networks via the R2D2 Prior</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian neural networks (BNNs) treat neural network weights as random variables, which aim to provide posterior uncertainty estimates and avoid overfitting by performing inference on the posterior weights. However, the selection of appropriate prior distributions remains a challenging task, and BNNs may suffer from catastrophic inflated variance or poor predictive performance when poor choices are made for the priors. Existing BNN designs apply different priors to weights, while the behaviours of these priors make it difficult to sufficiently shrink noisy signals or they are prone to overshrinking important signals in the weights. To alleviate this problem, we propose a novel R2D2-Net, which imposes the R^2-induced Dirichlet Decomposition (R2D2) prior to the BNN weights. The R2D2-Net can effectively shrink irrelevant coefficients towards zero, while preventing key features from over-shrinkage. To approximate the posterior distribution of weights more accurately, we further propose a variational Gibbs inference algorithm that combines the Gibbs updating procedure and gradient-based optimization. This strategy enhances stability and consistency in estimation when the variational objective involving the shrinkage parameters is non-convex. We also analyze the evidence lower bound (ELBO) and the posterior concentration rates from a theoretical perspective. Experiments on both natural and medical image classification and uncertainty estimation tasks demonstrate satisfactory performance of our method.
<div id='section'>Paperid: <span id='pid'>520, <a href='https://arxiv.org/pdf/2504.19820.pdf' target='_blank'>https://arxiv.org/pdf/2504.19820.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yoonhyuk Choi, Jiho Choi, Taewook Ko, Chong-Kwon Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19820">Hierarchical Uncertainty-Aware Graph Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent research on graph neural networks (GNNs) has explored mechanisms for capturing local uncertainty and exploiting graph hierarchies to mitigate data sparsity and leverage structural properties. However, the synergistic integration of these two approaches remains underexplored. This work introduces a novel architecture, the Hierarchical Uncertainty-Aware Graph Neural Network (HU-GNN), which unifies multi-scale representation learning, principled uncertainty estimation, and self-supervised embedding diversity within a single end-to-end framework. Specifically, HU-GNN adaptively forms node clusters and estimates uncertainty at multiple structural scales from individual nodes to higher levels. These uncertainty estimates guide a robust message-passing mechanism and attention weighting, effectively mitigating noise and adversarial perturbations while preserving predictive accuracy on semi-supervised classification tasks. We also offer key theoretical contributions, including a probabilistic formulation, rigorous uncertainty-calibration guarantees, and formal robustness bounds. Extensive experiments on standard benchmarks demonstrate that our model achieves state-of-the-art robustness and interpretability.
<div id='section'>Paperid: <span id='pid'>521, <a href='https://arxiv.org/pdf/2504.01508.pdf' target='_blank'>https://arxiv.org/pdf/2504.01508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pu Wang, Yu Zhang, Zhuoran Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01508">UAKNN: Label Distribution Learning via Uncertainty-Aware KNN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Label Distribution Learning (LDL) aims to characterize the polysemy of an instance by building a set of descriptive degrees corresponding to the instance. In recent years, researchers seek to model to obtain an accurate label distribution by using low-rank, label relations, expert experiences, and label uncertainty estimation. In general, these methods are based on algorithms with parameter learning in a linear (including kernel functions) or deep learning framework. However, these methods are difficult to deploy and update online due to high training costs, limited scalability, and outlier sensitivity. To address this problem, we design a novel LDL method called UAKNN, which has the advantages of the KNN algorithm with the benefits of uncertainty modeling. In addition, we provide solutions to the dilemma of existing work on extremely label distribution spaces. Extensive experiments demonstrate that our method is significantly competitive on 12 benchmarks and that the inference speed of the model is well-suited for industrial-level applications.
<div id='section'>Paperid: <span id='pid'>522, <a href='https://arxiv.org/pdf/2503.05274.pdf' target='_blank'>https://arxiv.org/pdf/2503.05274.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sajad Marvi, Christoph Rist, Julian Schmidt, Julian Jordan, Abhinav Valada
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05274">Evidential Uncertainty Estimation for Multi-Modal Trajectory Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate trajectory prediction is crucial for autonomous driving, yet uncertainty in agent behavior and perception noise makes it inherently challenging. While multi-modal trajectory prediction models generate multiple plausible future paths with associated probabilities, effectively quantifying uncertainty remains an open problem. In this work, we propose a novel multi-modal trajectory prediction approach based on evidential deep learning that estimates both positional and mode probability uncertainty in real time. Our approach leverages a Normal Inverse Gamma distribution for positional uncertainty and a Dirichlet distribution for mode uncertainty. Unlike sampling-based methods, it infers both types of uncertainty in a single forward pass, significantly improving efficiency. Additionally, we experimented with uncertainty-driven importance sampling to improve training efficiency by prioritizing underrepresented high-uncertainty samples over redundant ones. We perform extensive evaluations of our method on the Argoverse 1 and Argoverse 2 datasets, demonstrating that it provides reliable uncertainty estimates while maintaining high trajectory prediction accuracy.
<div id='section'>Paperid: <span id='pid'>523, <a href='https://arxiv.org/pdf/2503.00699.pdf' target='_blank'>https://arxiv.org/pdf/2503.00699.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunsu Kim, Giung Nam, Chulhee Yun, Hongseok Yang, Juho Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00699">Parameter Expanded Stochastic Gradient Markov Chain Monte Carlo</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Neural Networks (BNNs) provide a promising framework for modeling predictive uncertainty and enhancing out-of-distribution robustness (OOD) by estimating the posterior distribution of network parameters. Stochastic Gradient Markov Chain Monte Carlo (SGMCMC) is one of the most powerful methods for scalable posterior sampling in BNNs, achieving efficiency by combining stochastic gradient descent with second-order Langevin dynamics. However, SGMCMC often suffers from limited sample diversity in practice, which affects uncertainty estimation and model performance. We propose a simple yet effective approach to enhance sample diversity in SGMCMC without the need for tempering or running multiple chains. Our approach reparameterizes the neural network by decomposing each of its weight matrices into a product of matrices, resulting in a sampling trajectory that better explores the target parameter space. This approach produces a more diverse set of samples, allowing faster mixing within the same computational budget. Notably, our sampler achieves these improvements without increasing the inference cost compared to the standard SGMCMC. Extensive experiments on image classification tasks, including OOD robustness, diversity, loss surface analyses, and a comparative study with Hamiltonian Monte Carlo, demonstrate the superiority of the proposed approach.
<div id='section'>Paperid: <span id='pid'>524, <a href='https://arxiv.org/pdf/2502.19977.pdf' target='_blank'>https://arxiv.org/pdf/2502.19977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Song, Andrea Iannelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19977">Convergence Guarantees of Model-free Policy Gradient Methods for LQR with Stochastic Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Policy gradient (PG) methods are the backbone of many reinforcement learning algorithms due to their good performance in policy optimization problems. As a gradient-based approach, PG methods typically rely on knowledge of the system dynamics. If this is not available, trajectory data can be utilized to approximate first-order information. When the data are noisy, gradient estimates become inaccurate and a study that investigates uncertainty estimation and the analysis of its propagation through the algorithm is currently missing. To address this, our work focuses on the Linear Quadratic Regulator (LQR) problem for systems subject to additive stochastic noise. After briefly summarizing the state of the art for cases with a known model, we focus on scenarios where the system dynamics are unknown, and approximate gradient information is obtained using zeroth-order optimization techniques. We analyze the theoretical properties by computing the error in the estimated gradient and examining how this error affects the convergence of PG algorithms. Additionally, we provide global convergence guarantees for various versions of PG methods, including those employing adaptive step sizes and variance reduction techniques, which help increase the convergence rate and reduce sample complexity. This study contributed to characterizing robustness of the study of the robustness of model-free PG methods, aiming to identify their limitations in the presence of stochastic noise and proposing improvements to enhance their applicability.
<div id='section'>Paperid: <span id='pid'>525, <a href='https://arxiv.org/pdf/2502.15833.pdf' target='_blank'>https://arxiv.org/pdf/2502.15833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alessandro Canevaro, Julian Schmidt, Mohammad Sajad Marvi, Hang Yu, Georg Martius, Julian Jordan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15833">Advancing Out-of-Distribution Detection via Local Neuroplasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the domain of machine learning, the assumption that training and test data share the same distribution is often violated in real-world scenarios, requiring effective out-of-distribution (OOD) detection. This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs). Unlike traditional multilayer perceptrons, KANs exhibit local plasticity, allowing them to preserve learned information while adapting to new tasks. Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples. We validate our approach on benchmarks from image and medical domains, demonstrating superior performance and robustness compared to state-of-the-art techniques. These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.
<div id='section'>Paperid: <span id='pid'>526, <a href='https://arxiv.org/pdf/2502.11021.pdf' target='_blank'>https://arxiv.org/pdf/2502.11021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tuo Zhang, Asal Mehradfar, Dimitrios Dimitriadis, Salman Avestimehr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11021">Leveraging Uncertainty Estimation for Efficient LLM Routing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying large language models (LLMs) in edge-cloud environments requires an efficient routing strategy to balance cost and response quality. Traditional approaches prioritize either human-preference data or accuracy metrics from benchmark datasets as routing criteria, but these methods suffer from rigidity and subjectivity. Moreover, existing routing frameworks primarily focus on accuracy and cost, neglecting response quality from a human preference perspective. In this work, we propose the Confidence-Driven LLM Router, a novel framework that leverages uncertainty estimation to optimize routing decisions. To comprehensively assess routing performance, we evaluate both system cost efficiency and response quality. In particular, we introduce the novel use of LLM-as-a-Judge to simulate human rating preferences, providing the first systematic assessment of response quality across different routing strategies. Extensive experiments on MT-Bench, GSM8K, and MMLU demonstrate that our approach outperforms state-of-the-art routing methods, achieving superior response quality while maintaining cost efficiency.
<div id='section'>Paperid: <span id='pid'>527, <a href='https://arxiv.org/pdf/2502.05049.pdf' target='_blank'>https://arxiv.org/pdf/2502.05049.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Federico Cinus, Corrado Monti, Paolo Bajardi, Gianmarco De Francisci Morales
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05049">Uncovering the Sociodemographic Fabric of Reddit</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the sociodemographic composition of online platforms is essential for accurately interpreting digital behavior and its societal implications. Yet, current methods often lack the transparency and reliability required, risking misrepresenting social identities and distorting our understanding of digital society. Here, we introduce a principled framework for sociodemographic inference on Reddit that leverages over 850,000 user self-declarations of age, gender, and partisan affiliation. By training models on sparse user activity signals from this extensive, self-disclosed dataset, we demonstrate that simple probabilistic models, such as Naive Bayes, outperform more complex embedding-based alternatives. Our approach improves classification performance over the state of the art by up to 19% in ROC AUC and maintains quantification error below 15%. The models produce well-calibrated and interpretable outputs, enabling uncertainty estimation and subreddit-level feature importance analysis. More broadly, this work advocates for a shift toward more ethical and transparent computational social science by grounding sociodemographic analysis in user-provided data rather than researcher assumptions.
<div id='section'>Paperid: <span id='pid'>528, <a href='https://arxiv.org/pdf/2502.00662.pdf' target='_blank'>https://arxiv.org/pdf/2502.00662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yimu Wang, Evelien Riddell, Adrian Chow, Sean Sedwards, Krzysztof Czarnecki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00662">Mitigating the Modality Gap: Few-Shot Out-of-Distribution Detection with Multi-modal Prototypes and Image Bias Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing vision-language model (VLM)-based methods for out-of-distribution (OOD) detection typically rely on similarity scores between input images and in-distribution (ID) text prototypes. However, the modality gap between image and text often results in high false positive rates, as OOD samples can exhibit high similarity to ID text prototypes. To mitigate the impact of this modality gap, we propose incorporating ID image prototypes along with ID text prototypes. We present theoretical analysis and empirical evidence indicating that this approach enhances VLM-based OOD detection performance without any additional training. To further reduce the gap between image and text, we introduce a novel few-shot tuning framework, SUPREME, comprising biased prompts generation (BPG) and image-text consistency (ITC) modules. BPG enhances image-text fusion and improves generalization by conditioning ID text prototypes on the Gaussian-based estimated image domain bias; ITC reduces the modality gap by minimizing intra- and inter-modal distances. Moreover, inspired by our theoretical and empirical findings, we introduce a novel OOD score $S_{\textit{GMP}}$, leveraging uni- and cross-modal similarities. Finally, we present extensive experiments to demonstrate that SUPREME consistently outperforms existing VLM-based OOD detection methods.
<div id='section'>Paperid: <span id='pid'>529, <a href='https://arxiv.org/pdf/2501.14894.pdf' target='_blank'>https://arxiv.org/pdf/2501.14894.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiaojie Zheng, Jiucai Zhang, Xiaoli Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14894">Enhancing accuracy of uncertainty estimation in appearance-based gaze tracking with probabilistic evaluation and calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately knowing uncertainties in appearance-based gaze tracking is critical for ensuring reliable downstream applications. Due to the lack of individual uncertainty labels, current uncertainty-aware approaches adopt probabilistic models to acquire uncertainties by following distributions in the training dataset. Without regulations, this approach lets the uncertainty model build biases and overfits the training data, leading to poor performance when deployed. We first presented a strict proper evaluation metric from the probabilistic perspective based on comparing the coverage probability between prediction and observation to provide quantitative evaluation for better assessment on the inferred uncertainties. We then proposed a correction strategy based on probability calibration to mitigate biases in the estimated uncertainties of the trained models. Finally, we demonstrated the effectiveness of the correction strategy with experiments performed on two popular gaze estimation datasets with distinctive image characteristics caused by data collection settings.
<div id='section'>Paperid: <span id='pid'>530, <a href='https://arxiv.org/pdf/2412.09572.pdf' target='_blank'>https://arxiv.org/pdf/2412.09572.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Feng, Phu Mon Htut, Zheng Qi, Wei Xiao, Manuel Mager, Nikolaos Pappas, Kishaloy Halder, Yang Li, Yassine Benajiba, Dan Roth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09572">Rethinking LLM Uncertainty: A Multi-Agent Approach to Estimating Black-Box Model Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantifying uncertainty in black-box LLMs is vital for reliable responses and scalable oversight. Existing methods, which gauge a model's uncertainty through evaluating self-consistency in responses to the target query, can be misleading: an LLM may confidently provide an incorrect answer to a target query, yet give a confident and accurate answer to that same target query when answering a knowledge-preserving perturbation of the query. We systematically analyze the model behaviors and demonstrate that this discrepancy stems from suboptimal retrieval of parametric knowledge, often due to contextual biases that prevent consistent access to stored knowledge. We then introduce DiverseAgentEntropy, a novel, theoretically-grounded method employing multi-agent interaction across diverse query variations for uncertainty estimation of black-box LLMs. This approach more accurately assesses an LLM's true uncertainty and improves hallucination detection, outperforming existing self-consistency based techniques.
<div id='section'>Paperid: <span id='pid'>531, <a href='https://arxiv.org/pdf/2410.19356.pdf' target='_blank'>https://arxiv.org/pdf/2410.19356.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Li, Zhicheng Xu, Bo Wen, Ruibin Mao, Can Li, Thomas KÃ¤mpfe, Kai Ni, Xunzhao Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19356">FeBiM: Efficient and Compact Bayesian Inference Engine Empowered with Ferroelectric In-Memory Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In scenarios with limited training data or where explainability is crucial, conventional neural network-based machine learning models often face challenges. In contrast, Bayesian inference-based algorithms excel in providing interpretable predictions and reliable uncertainty estimation in these scenarios. While many state-of-the-art in-memory computing (IMC) architectures leverage emerging non-volatile memory (NVM) technologies to offer unparalleled computing capacity and energy efficiency for neural network workloads, their application in Bayesian inference is limited. This is because the core operations in Bayesian inference differ significantly from the multiplication-accumulation (MAC) operations common in neural networks, rendering them generally unsuitable for direct implementation in most existing IMC designs. In this paper, we propose FeBiM, an efficient and compact Bayesian inference engine powered by multi-bit ferroelectric field-effect transistor (FeFET)-based IMC. FeBiM effectively encodes the trained probabilities of a Bayesian inference model within a compact FeFET-based crossbar. It maps quantized logarithmic probabilities to discrete FeFET states. As a result, the accumulated outputs of the crossbar naturally represent the posterior probabilities, i.e., the Bayesian inference model's output given a set of observations. This approach enables efficient in-memory Bayesian inference without the need for additional calculation circuitry. As the first FeFET-based in-memory Bayesian inference engine, FeBiM achieves an impressive storage density of 26.32 Mb/mm$^{2}$ and a computing efficiency of 581.40 TOPS/W in a representative Bayesian classification task. These results demonstrate 10.7$\times$/43.4$\times$ improvement in compactness/efficiency compared to the state-of-the-art hardware implementation of Bayesian inference.
<div id='section'>Paperid: <span id='pid'>532, <a href='https://arxiv.org/pdf/2410.19288.pdf' target='_blank'>https://arxiv.org/pdf/2410.19288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyuan Dong, Zhuotong Cai, Gilbert Hangel, Wolfgang Bogner, Georg Widhalm, Yaqing Huang, Qinghao Liang, Chenyu You, Chathura Kumaragamage, Robert K. Fulbright, Amit Mahajan, Amin Karbasi, John A. Onofrey, Robin A. de Graaf, James S. Duncan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19288">A Flow-based Truncated Denoising Diffusion Model for Super-resolution Magnetic Resonance Spectroscopic Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic Resonance Spectroscopic Imaging (MRSI) is a non-invasive imaging technique for studying metabolism and has become a crucial tool for understanding neurological diseases, cancers and diabetes. High spatial resolution MRSI is needed to characterize lesions, but in practice MRSI is acquired at low resolution due to time and sensitivity restrictions caused by the low metabolite concentrations. Therefore, there is an imperative need for a post-processing approach to generate high-resolution MRSI from low-resolution data that can be acquired fast and with high sensitivity. Deep learning-based super-resolution methods provided promising results for improving the spatial resolution of MRSI, but they still have limited capability to generate accurate and high-quality images. Recently, diffusion models have demonstrated superior learning capability than other generative models in various tasks, but sampling from diffusion models requires iterating through a large number of diffusion steps, which is time-consuming. This work introduces a Flow-based Truncated Denoising Diffusion Model (FTDDM) for super-resolution MRSI, which shortens the diffusion process by truncating the diffusion chain, and the truncated steps are estimated using a normalizing flow-based network. The network is conditioned on upscaling factors to enable multi-scale super-resolution. To train and evaluate the deep learning models, we developed a 1H-MRSI dataset acquired from 25 high-grade glioma patients. We demonstrate that FTDDM outperforms existing generative models while speeding up the sampling process by over 9-fold compared to the baseline diffusion model. Neuroradiologists' evaluations confirmed the clinical advantages of our method, which also supports uncertainty estimation and sharpness adjustment, extending its potential clinical applications.
<div id='section'>Paperid: <span id='pid'>533, <a href='https://arxiv.org/pdf/2410.14868.pdf' target='_blank'>https://arxiv.org/pdf/2410.14868.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sung-Wook Lee, Xuhui Kang, Yen-Ling Kuo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14868">Diff-DAgger: Uncertainty Estimation with Diffusion Policy for Robotic Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, diffusion policy has shown impressive results in handling multi-modal tasks in robotic manipulation. However, it has fundamental limitations in out-of-distribution failures that persist due to compounding errors and its limited capability to extrapolate. One way to address these limitations is robot-gated DAgger, an interactive imitation learning with a robot query system to actively seek expert help during policy rollout. While robot-gated DAgger has high potential for learning at scale, existing methods like Ensemble-DAgger struggle with highly expressive policies: They often misinterpret policy disagreements as uncertainty at multi-modal decision points. To address this problem, we introduce Diff-DAgger, an efficient robot-gated DAgger algorithm that leverages the training objective of diffusion policy. We evaluate Diff-DAgger across different robot tasks including stacking, pushing, and plugging, and show that Diff-DAgger improves the task failure prediction by 39.0%, the task completion rate by 20.6%, and reduces the wall-clock time by a factor of 7.8. We hope that this work opens up a path for efficiently incorporating expressive yet data-hungry policies into interactive robot learning settings. The project website is available at: https://diffdagger.github.io.
<div id='section'>Paperid: <span id='pid'>534, <a href='https://arxiv.org/pdf/2409.17725.pdf' target='_blank'>https://arxiv.org/pdf/2409.17725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linfeng Li, Gang Yang, Lin Shao, David Hsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17725">Differentiable Contact Dynamics for Stable Object Placement Under Geometric Uncertainties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>From serving a cup of coffee to positioning mechanical parts during assembly, stable object placement is a crucial skill for future robots. It becomes particularly challenging under geometric uncertainties, e.g., when the object pose or shape is not known accurately. This work leverages a differentiable simulation model of contact dynamics to tackle this challenge. We derive a novel gradient that relates force-torque sensor readings to geometric uncertainties, thus enabling uncertainty estimation by minimizing discrepancies between sensor data and model predictions via gradient descent. Gradient-based methods are sensitive to initialization. To mitigate this effect, we maintain a belief over multiple estimates and choose the robot action based on the current belief at each timestep. In experiments on a Franka robot arm, our method achieved promising results on multiple objects under various geometric uncertainties, including the in-hand pose uncertainty of a grasped object, the object shape uncertainty, and the environment uncertainty.
<div id='section'>Paperid: <span id='pid'>535, <a href='https://arxiv.org/pdf/2407.04022.pdf' target='_blank'>https://arxiv.org/pdf/2407.04022.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Doorenbos, Raphael Sznitman, Pablo MÃ¡rquez-Neila
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04022">Learning Non-Linear Invariants for Unsupervised Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The inability of deep learning models to handle data drawn from unseen distributions has sparked much interest in unsupervised out-of-distribution (U-OOD) detection, as it is crucial for reliable deep learning models. Despite considerable attention, theoretically-motivated approaches are few and far between, with most methods building on top of some form of heuristic. Recently, U-OOD was formalized in the context of data invariants, allowing a clearer understanding of how to characterize U-OOD, and methods leveraging affine invariants have attained state-of-the-art results on large-scale benchmarks. Nevertheless, the restriction to affine invariants hinders the expressiveness of the approach. In this work, we broaden the affine invariants formulation to a more general case and propose a framework consisting of a normalizing flow-like architecture capable of learning non-linear invariants. Our novel approach achieves state-of-the-art results on an extensive U-OOD benchmark, and we demonstrate its further applicability to tabular data. Finally, we show our method has the same desirable properties as those based on affine invariants.
<div id='section'>Paperid: <span id='pid'>536, <a href='https://arxiv.org/pdf/2406.20042.pdf' target='_blank'>https://arxiv.org/pdf/2406.20042.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haykel Snoussi, Davood Karimi, Onur Afacan, Mustafa Utkur, Ali Gholipour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.20042">HAITCH: A Framework for Distortion and Motion Correction in Fetal Multi-Shell Diffusion-Weighted MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion magnetic resonance imaging (dMRI) is pivotal for probing the microstructure of the rapidly-developing fetal brain. However, fetal motion during scans and its interaction with magnetic field inhomogeneities result in artifacts and data scattering across spatial and angular domains. The effects of those artifacts are more pronounced in high-angular resolution fetal dMRI, where signal-to-noise ratio is very low. Those effects lead to biased estimates and compromise the consistency and reliability of dMRI analysis. This work presents HAITCH, the first and the only publicly available tool to correct and reconstruct multi-shell high-angular resolution fetal dMRI data. HAITCH offers several technical advances that include a blip-reversed dual-echo acquisition for dynamic distortion correction, advanced motion correction for model-free and robust reconstruction, optimized multi-shell design for enhanced information capture and increased tolerance to motion, and outlier detection for improved reconstruction fidelity. The framework is open-source, flexible, and can be used to process any type of fetal dMRI data including single-echo or single-shell acquisitions, but is most effective when used with multi-shell multi-echo fetal dMRI data that cannot be processed with any of the existing tools. Validation experiments on real fetal dMRI scans demonstrate significant improvements and accurate correction across diverse fetal ages and motion levels. HAITCH successfully removes artifacts and reconstructs high-fidelity fetal dMRI data suitable for advanced diffusion modeling, including fiber orientation distribution function estimation. These advancements pave the way for more reliable analysis of the fetal brain microstructure and tractography under challenging imaging conditions.
<div id='section'>Paperid: <span id='pid'>537, <a href='https://arxiv.org/pdf/2406.10023.pdf' target='_blank'>https://arxiv.org/pdf/2406.10023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luckeciano C. Melo, Panagiotis Tigas, Alessandro Abate, Yarin Gal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10023">Deep Bayesian Active Learning for Preference Modeling in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Leveraging human preferences for steering the behavior of Large Language Models (LLMs) has demonstrated notable success in recent years. Nonetheless, data selection and labeling are still a bottleneck for these systems, particularly at large scale. Hence, selecting the most informative points for acquiring human feedback may considerably reduce the cost of preference labeling and unleash the further development of LLMs. Bayesian Active Learning provides a principled framework for addressing this challenge and has demonstrated remarkable success in diverse settings. However, previous attempts to employ it for Preference Modeling did not meet such expectations. In this work, we identify that naive epistemic uncertainty estimation leads to the acquisition of redundant samples. We address this by proposing the Bayesian Active Learner for Preference Modeling (BAL-PM), a novel stochastic acquisition policy that not only targets points of high epistemic uncertainty according to the preference model but also seeks to maximize the entropy of the acquired prompt distribution in the feature space spanned by the employed LLM. Notably, our experiments demonstrate that BAL-PM requires 33% to 68% fewer preference labels in two popular human preference datasets and exceeds previous stochastic Bayesian acquisition policies.
<div id='section'>Paperid: <span id='pid'>538, <a href='https://arxiv.org/pdf/2406.02327.pdf' target='_blank'>https://arxiv.org/pdf/2406.02327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Doorenbos, Raphael Sznitman, Pablo MÃ¡rquez-Neila
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02327">Iterative Deployment Exposure for Unsupervised Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models are vulnerable to performance degradation when encountering out-of-distribution (OOD) images, potentially leading to misdiagnoses and compromised patient care. These shortcomings have led to great interest in the field of OOD detection. Existing unsupervised OOD (U-OOD) detection methods typically assume that OOD samples originate from an unconcentrated distribution complementary to the training distribution, neglecting the reality that deployed models passively accumulate task-specific OOD samples over time. To better reflect this real-world scenario, we introduce Iterative Deployment Exposure (IDE), a novel and more realistic setting for U-OOD detection. We propose CSO, a method for IDE that starts from a U-OOD detector that is agnostic to the OOD distribution and slowly refines it during deployment using observed unlabeled data. CSO uses a new U-OOD scoring function that combines the Mahalanobis distance with a nearest-neighbor approach, along with a novel confidence-scaled few-shot OOD detector to effectively learn from limited OOD examples. We validate our approach on a dedicated benchmark, showing that our method greatly improves upon strong baselines on three medical imaging modalities.
<div id='section'>Paperid: <span id='pid'>539, <a href='https://arxiv.org/pdf/2405.11533.pdf' target='_blank'>https://arxiv.org/pdf/2405.11533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shani Goren, Ido Galil, Ran El-Yaniv
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11533">Hierarchical Selective Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying deep neural networks for risk-sensitive tasks necessitates an uncertainty estimation mechanism. This paper introduces hierarchical selective classification, extending selective classification to a hierarchical setting. Our approach leverages the inherent structure of class relationships, enabling models to reduce the specificity of their predictions when faced with uncertainty. In this paper, we first formalize hierarchical risk and coverage, and introduce hierarchical risk-coverage curves. Next, we develop algorithms for hierarchical selective classification (which we refer to as "inference rules"), and propose an efficient algorithm that guarantees a target accuracy constraint with high probability. Lastly, we conduct extensive empirical studies on over a thousand ImageNet classifiers, revealing that training regimes such as CLIP, pretraining on ImageNet21k and knowledge distillation boost hierarchical selective performance.
<div id='section'>Paperid: <span id='pid'>540, <a href='https://arxiv.org/pdf/2405.03953.pdf' target='_blank'>https://arxiv.org/pdf/2405.03953.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixing Zhang, Tao Pang, Jing Han, BjÃ¶rn W. Schuller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.03953">Intelligent Cardiac Auscultation for Murmur Detection via Parallel-Attentive Models with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Heart murmurs are a common manifestation of cardiovascular diseases and can provide crucial clues to early cardiac abnormalities. While most current research methods primarily focus on the accuracy of models, they often overlook other important aspects such as the interpretability of machine learning algorithms and the uncertainty of predictions. This paper introduces a heart murmur detection method based on a parallel-attentive model, which consists of two branches: One is based on a self-attention module and the other one is based on a convolutional network. Unlike traditional approaches, this structure is better equipped to handle long-term dependencies in sequential data, and thus effectively captures the local and global features of heart murmurs. Additionally, we acknowledge the significance of understanding the uncertainty of model predictions in the medical field for clinical decision-making. Therefore, we have incorporated an effective uncertainty estimation method based on Monte Carlo Dropout into our model. Furthermore, we have employed temperature scaling to calibrate the predictions of our probabilistic model, enhancing its reliability. In experiments conducted on the CirCor Digiscope dataset for heart murmur detection, our proposed method achieves a weighted accuracy of 79.8% and an F1 of 65.1%, representing state-of-the-art results.
<div id='section'>Paperid: <span id='pid'>541, <a href='https://arxiv.org/pdf/2404.15993.pdf' target='_blank'>https://arxiv.org/pdf/2404.15993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linyu Liu, Yu Pan, Xiaocheng Li, Guanting Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15993">Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we study the problem of uncertainty estimation and calibration for LLMs. We begin by formulating the uncertainty estimation problem, a relevant yet underexplored area in existing literature. We then propose a supervised approach that leverages labeled datasets to estimate the uncertainty in LLMs' responses. Based on the formulation, we illustrate the difference between the uncertainty estimation for LLMs and that for standard ML models and explain why the hidden neurons of the LLMs may contain uncertainty information. Our designed approach demonstrates the benefits of utilizing hidden activations to enhance uncertainty estimation across various tasks and shows robust transferability in out-of-distribution settings. We distinguish the uncertainty estimation task from the uncertainty calibration task and show that better uncertainty estimation leads to better calibration performance. Furthermore, our method is easy to implement and adaptable to different levels of model accessibility including black box, grey box, and white box.
<div id='section'>Paperid: <span id='pid'>542, <a href='https://arxiv.org/pdf/2403.01165.pdf' target='_blank'>https://arxiv.org/pdf/2403.01165.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linhai Zhang, Jialong Wu, Deyu Zhou, Guoqiang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01165">STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the uncertainty gap, we introduce a dynamic uncertainty measurement that combines the uncertainty of the base model and the uncertainty of the full model during the iteration of active learning. For poor model calibration, we incorporate the regularization method during LoRA training to keep the model from being over-confident, and the Monte-Carlo dropout mechanism is employed to enhance the uncertainty estimation. Experimental results show that the proposed approach outperforms existing baseline models on three complex reasoning tasks.
<div id='section'>Paperid: <span id='pid'>543, <a href='https://arxiv.org/pdf/2401.08777.pdf' target='_blank'>https://arxiv.org/pdf/2401.08777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhijith Gandrakota, Lily Zhang, Aahlad Puli, Kyle Cranmer, Jennifer Ngadiuba, Rajesh Ranganath, Nhan Tran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08777">Robust Anomaly Detection for Particle Physics Using Multi-Background Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly, or out-of-distribution, detection is a promising tool for aiding discoveries of new particles or processes in particle physics. In this work, we identify and address two overlooked opportunities to improve anomaly detection for high-energy physics. First, rather than train a generative model on the single most dominant background process, we build detection algorithms using representation learning from multiple background types, thus taking advantage of more information to improve estimation of what is relevant for detection. Second, we generalize decorrelation to the multi-background setting, thus directly enforcing a more complete definition of robustness for anomaly detection. We demonstrate the benefit of the proposed robust multi-background anomaly detection algorithms on a high-dimensional dataset of particle decays at the Large Hadron Collider.
<div id='section'>Paperid: <span id='pid'>544, <a href='https://arxiv.org/pdf/2511.07734.pdf' target='_blank'>https://arxiv.org/pdf/2511.07734.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shu Hong, Yongsheng Mei, Mahdi Imani, Tian Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.07734">Global Optimization on Graph-Structured Data via Gaussian Processes with Spectral Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian optimization (BO) is a powerful framework for optimizing expensive black-box objectives, yet extending it to graph-structured domains remains challenging due to the discrete and combinatorial nature of graphs. Existing approaches often rely on either full graph topology-impractical for large or partially observed graphs-or incremental exploration, which can lead to slow convergence. We introduce a scalable framework for global optimization over graphs that employs low-rank spectral representations to build Gaussian process (GP) surrogates from sparse structural observations. The method jointly infers graph structure and node representations through learnable embeddings, enabling efficient global search and principled uncertainty estimation even with limited data. We also provide theoretical analysis establishing conditions for accurate recovery of underlying graph structure under different sampling regimes. Experiments on synthetic and real-world datasets demonstrate that our approach achieves faster convergence and improved optimization performance compared to prior methods.
<div id='section'>Paperid: <span id='pid'>545, <a href='https://arxiv.org/pdf/2511.06720.pdf' target='_blank'>https://arxiv.org/pdf/2511.06720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zizhao Li, Zhengkang Xiang, Jiayang Ao, Joseph West, Kourosh Khoshelham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.06720">Relative Energy Learning for LiDAR Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical requirement for reliable autonomous driving, where safety depends on recognizing road obstacles and unexpected objects beyond the training distribution. Despite extensive research on OOD detection in 2D images, direct transfer to 3D LiDAR point clouds has been proven ineffective. Current LiDAR OOD methods struggle to distinguish rare anomalies from common classes, leading to high false-positive rates and overconfident errors in safety-critical settings. We propose Relative Energy Learning (REL), a simple yet effective framework for OOD detection in LiDAR point clouds. REL leverages the energy gap between positive (in-distribution) and negative logits as a relative scoring function, mitigating calibration issues in raw energy values and improving robustness across various scenes. To address the absence of OOD samples during training, we propose a lightweight data synthesis strategy called Point Raise, which perturbs existing point clouds to generate auxiliary anomalies without altering the inlier semantics. Evaluated on SemanticKITTI and the Spotting the Unexpected (STU) benchmark, REL consistently outperforms existing methods by a large margin. Our results highlight that modeling relative energy, combined with simple synthetic outliers, provides a principled and scalable solution for reliable OOD detection in open-world autonomous driving.
<div id='section'>Paperid: <span id='pid'>546, <a href='https://arxiv.org/pdf/2510.11832.pdf' target='_blank'>https://arxiv.org/pdf/2510.11832.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Narine Kokhlikyan, Kamalika Chaudhuri, Saeed Mahloujifar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.11832">Z0-Inf: Zeroth Order Approximation for Data Influence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A critical aspect of analyzing and improving modern machine learning systems lies in understanding how individual training examples influence a model's predictive behavior. Estimating this influence enables critical applications, including data selection and model debugging; in particular, self-influence, which quantifies the influence of a training point on itself, has found many uses in data quality assessment and outlier detection. Existing methods for measuring data influence, however, are often impractical for large models due to low accuracy or prohibitive computational costs: most approaches either provide poor approximations or rely on gradients and inverse-Hessian computations that remain challenging to scale. In this work, we introduce a highly efficient zeroth-order approximation for estimating the influence of training data that requires only a fraction of the time and memory footprint of prior methods. Notably, our method relies solely on loss values of intermediate checkpoints on the training and test data, along with the checkpoints themselves, making it broadly applicable even when the loss function of interest is non-differentiable. Beyond its computational efficiency, our approach achieves superior accuracy in estimating self-influence and comparable or improved accuracy in estimating train-test influence for fine-tuned large language models, enabling scalable and practical analysis of how training data shapes model behavior.
<div id='section'>Paperid: <span id='pid'>547, <a href='https://arxiv.org/pdf/2509.24492.pdf' target='_blank'>https://arxiv.org/pdf/2509.24492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charmaine Barker, Daniel Bethell, Simos Gerasimou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24492">Guided Uncertainty Learning Using a Post-Hoc Evidential Meta-Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty quantification remains a major obstacle to the deployment of deep learning models under distributional shift. Existing post-hoc approaches that retrofit pretrained models either inherit misplaced confidence or merely reshape predictions, without teaching the model when to be uncertain. We introduce GUIDE, a lightweight evidential learning meta-model approach that attaches to a frozen deep learning model and explicitly learns how and when to be uncertain. GUIDE identifies salient internal features via a calibration stage, and then employs these features to construct a noise-driven curriculum that teaches the model how and when to express uncertainty. GUIDE requires no retraining, no architectural modifications, and no manual intermediate-layer selection to the base deep learning model, thus ensuring broad applicability and minimal user intervention. The resulting model avoids distilling overconfidence from the base model, improves out-of-distribution detection by ~77% and adversarial attack detection by ~80%, while preserving in-distribution performance. Across diverse benchmarks, GUIDE consistently outperforms state-of-the-art approaches, evidencing the need for actively guiding uncertainty to close the gap between predictive confidence and reliability.
<div id='section'>Paperid: <span id='pid'>548, <a href='https://arxiv.org/pdf/2509.13681.pdf' target='_blank'>https://arxiv.org/pdf/2509.13681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Li, Dianmo Sheng, Qiankun Dong, Zichun Wang, Zhiwei Xu, Tao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13681">FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a cornerstone technique for autonomous driving, Bird's Eye View (BEV) segmentation has recently achieved remarkable progress with pinhole cameras. However, it is non-trivial to extend the existing methods to fisheye cameras with severe geometric distortion, ambiguous multi-view correspondences and unstable temporal dynamics, all of which significantly degrade BEV performance. To address these challenges, we propose FishBEV, a novel BEV segmentation framework specifically tailored for fisheye cameras. This framework introduces three complementary innovations, including a Distortion-Resilient Multi-scale Extraction (DRME) backbone that learns robust features under distortion while preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention (U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that adaptively balances near field details and far field context to ensure temporal coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that FishBEV consistently outperforms SOTA baselines, regarding the performance evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.
<div id='section'>Paperid: <span id='pid'>549, <a href='https://arxiv.org/pdf/2509.08280.pdf' target='_blank'>https://arxiv.org/pdf/2509.08280.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyeonseok Kim, Byeongkeun Kang, Yeejin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08280">Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generalized zero-shot semantic segmentation of 3D point clouds aims to classify each point into both seen and unseen classes. A significant challenge with these models is their tendency to make biased predictions, often favoring the classes encountered during training. This problem is more pronounced in 3D applications, where the scale of the training data is typically smaller than in image-based tasks. To address this problem, we propose a novel method called E3DPC-GZSL, which reduces overconfident predictions towards seen classes without relying on separate classifiers for seen and unseen data. E3DPC-GZSL tackles the overconfidence problem by integrating an evidence-based uncertainty estimator into a classifier. This estimator is then used to adjust prediction probabilities using a dynamic calibrated stacking factor that accounts for pointwise prediction uncertainty. In addition, E3DPC-GZSL introduces a novel training strategy that improves uncertainty estimation by refining the semantic space. This is achieved by merging learnable parameters with text-derived features, thereby improving model optimization for unseen data. Extensive experiments demonstrate that the proposed approach achieves state-of-the-art performance on generalized zero-shot semantic segmentation datasets, including ScanNet v2 and S3DIS.
<div id='section'>Paperid: <span id='pid'>550, <a href='https://arxiv.org/pdf/2508.20812.pdf' target='_blank'>https://arxiv.org/pdf/2508.20812.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lorenzo Busellato, Federico Cunico, Diego Dall'Alba, Marco Emporio, Andrea Giachetti, Riccardo Muradore, Marco Cristani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20812">Uncertainty Aware-Predictive Control Barrier Functions: Safer Human Robot Interaction through Probabilistic Motion Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To enable flexible, high-throughput automation in settings where people and robots share workspaces, collaborative robotic cells must reconcile stringent safety guarantees with the need for responsive and effective behavior. A dynamic obstacle is the stochastic, task-dependent variability of human motion: when robots fall back on purely reactive or worst-case envelopes, they brake unnecessarily, stall task progress, and tamper with the fluidity that true Human-Robot Interaction demands. In recent years, learning-based human-motion prediction has rapidly advanced, although most approaches produce worst-case scenario forecasts that often do not treat prediction uncertainty in a well-structured way, resulting in over-conservative planning algorithms, limiting their flexibility. We introduce Uncertainty-Aware Predictive Control Barrier Functions (UA-PCBFs), a unified framework that fuses probabilistic human hand motion forecasting with the formal safety guarantees of Control Barrier Functions. In contrast to other variants, our framework allows for dynamic adjustment of the safety margin thanks to the human motion uncertainty estimation provided by a forecasting module. Thanks to uncertainty estimation, UA-PCBFs empower collaborative robots with a deeper understanding of future human states, facilitating more fluid and intelligent interactions through informed motion planning. We validate UA-PCBFs through comprehensive real-world experiments with an increasing level of realism, including automated setups (to perform exactly repeatable motions) with a robotic hand and direct human-robot interactions (to validate promptness, usability, and human confidence). Relative to state-of-the-art HRI architectures, UA-PCBFs show better performance in task-critical metrics, significantly reducing the number of violations of the robot's safe space during interaction with respect to the state-of-the-art.
<div id='section'>Paperid: <span id='pid'>551, <a href='https://arxiv.org/pdf/2508.18630.pdf' target='_blank'>https://arxiv.org/pdf/2508.18630.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weide Liu, Xiaoyang Zhong, Lu Wang, Jingwen Hou, Yuemei Luo, Jiebin Yan, Yuming Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18630">Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised domain adaptation methods seek to generalize effectively on unlabeled test data, especially when encountering the common challenge in time series data that distribution shifts occur between training and testing datasets. In this paper, we propose incorporating multi-scale feature extraction and uncertainty estimation to improve the model's generalization and robustness across domains. Our approach begins with a multi-scale mixed input architecture that captures features at different scales, increasing training diversity and reducing feature discrepancies between the training and testing domains. Based on the mixed input architecture, we further introduce an uncertainty awareness mechanism based on evidential learning by imposing a Dirichlet prior on the labels to facilitate both target prediction and uncertainty estimation. The uncertainty awareness mechanism enhances domain adaptation by aligning features with the same labels across different domains, which leads to significant performance improvements in the target domain. Additionally, our uncertainty-aware model demonstrates a much lower Expected Calibration Error (ECE), indicating better-calibrated prediction confidence. Our experimental results show that this combined approach of mixed input architecture with the uncertainty awareness mechanism achieves state-of-the-art performance across multiple benchmark datasets, underscoring its effectiveness in unsupervised domain adaptation for time series data.
<div id='section'>Paperid: <span id='pid'>552, <a href='https://arxiv.org/pdf/2508.06452.pdf' target='_blank'>https://arxiv.org/pdf/2508.06452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mattia Litrico, Mario Valerio Giuffrida, Sebastiano Battiato, Devis Tuia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06452">TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent unsupervised domain adaptation (UDA) methods have shown great success in addressing classical domain shifts (e.g., synthetic-to-real), but they still suffer under complex shifts (e.g. geographical shift), where both the background and object appearances differ significantly across domains. Prior works showed that the language modality can help in the adaptation process, exhibiting more robustness to such complex shifts. In this paper, we introduce TRUST, a novel UDA approach that exploits the robustness of the language modality to guide the adaptation of a vision model. TRUST generates pseudo-labels for target samples from their captions and introduces a novel uncertainty estimation strategy that uses normalised CLIP similarity scores to estimate the uncertainty of the generated pseudo-labels. Such estimated uncertainty is then used to reweight the classification loss, mitigating the adverse effects of wrong pseudo-labels obtained from low-quality captions. To further increase the robustness of the vision model, we propose a multimodal soft-contrastive learning loss that aligns the vision and language feature spaces, by leveraging captions to guide the contrastive training of the vision model on target images. In our contrastive loss, each pair of images acts as both a positive and a negative pair and their feature representations are attracted and repulsed with a strength proportional to the similarity of their captions. This solution avoids the need for hardly determining positive and negative pairs, which is critical in the UDA setting. Our approach outperforms previous methods, setting the new state-of-the-art on classical (DomainNet) and complex (GeoNet) domain shifts. The code will be available upon acceptance.
<div id='section'>Paperid: <span id='pid'>553, <a href='https://arxiv.org/pdf/2508.06101.pdf' target='_blank'>https://arxiv.org/pdf/2508.06101.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yachun Mi, Xingyang He, Shixin Sun, Yu Li, Yanting Li, Zhixuan Li, Jian Jin, Chen Hui, Shaohui Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06101">UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the digital age, advanced image editing tools pose a serious threat to the integrity of visual content, making image forgery detection and localization a key research focus. Most existing Image Manipulation Localization (IML) methods rely on discriminative learning and require large, high-quality annotated datasets. However, current datasets lack sufficient scale and diversity, limiting model performance in real-world scenarios. To overcome this, recent studies have explored Constrained IML (CIML), which generates pixel-level annotations through algorithmic supervision. However, existing CIML approaches often depend on complex multi-stage pipelines, making the annotation process inefficient. In this work, we propose a novel generative framework based on diffusion models, named UGD-IML, which for the first time unifies both IML and CIML tasks within a single framework. By learning the underlying data distribution, generative diffusion models inherently reduce the reliance on large-scale labeled datasets, allowing our approach to perform effectively even under limited data conditions. In addition, by leveraging a class embedding mechanism and a parameter-sharing design, our model seamlessly switches between IML and CIML modes without extra components or training overhead. Furthermore, the end-to-end design enables our model to avoid cumbersome steps in the data annotation process. Extensive experimental results on multiple datasets demonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and 4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the proposed method also excels in uncertainty estimation, visualization and robustness.
<div id='section'>Paperid: <span id='pid'>554, <a href='https://arxiv.org/pdf/2507.16219.pdf' target='_blank'>https://arxiv.org/pdf/2507.16219.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Da Fan, David John Gagne, Steven J. Greybush, Eugene E. Clothiaux, John S. Schreck, Chaopeng Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16219">Bayesian Deep Learning for Convective Initiation Nowcasting Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study evaluated the probability and uncertainty forecasts of five recently proposed Bayesian deep learning methods relative to a deterministic residual neural network (ResNet) baseline for 0-1 h convective initiation (CI) nowcasting using GOES-16 satellite infrared observations. Uncertainty was assessed by how well probabilistic forecasts were calibrated and how well uncertainty separated forecasts with large and small errors. Most of the Bayesian deep learning methods produced probabilistic forecasts that outperformed the deterministic ResNet, with one, the initial-weights ensemble + Monte Carlo (MC) dropout, an ensemble of deterministic ResNets with different initial weights to start training and dropout activated during inference, producing the most skillful and well-calibrated forecasts. The initial-weights ensemble + MC dropout benefited from generating multiple solutions that more thoroughly sampled the hypothesis space. The Bayesian ResNet ensemble was the only one that performed worse than the deterministic ResNet at longer lead times, likely due to the challenge of optimizing a larger number of parameters. To address this issue, the Bayesian-MOPED (MOdel Priors with Empirical Bayes using Deep neural network) ResNet ensemble was adopted, and it enhanced forecast skill by constraining the hypothesis search near the deterministic ResNet hypothesis. All Bayesian methods demonstrated well-calibrated uncertainty and effectively separated cases with large and small errors. In case studies, the initial-weights ensemble + MC dropout demonstrated better forecast skill than the Bayesian-MOPED ensemble and the deterministic ResNet on selected CI events in clear-sky regions. However, the initial-weights ensemble + MC dropout exhibited poorer generalization in clear-sky and anvil cloud regions without CI occurrence compared to the deterministic ResNet and Bayesian-MOPED ensemble.
<div id='section'>Paperid: <span id='pid'>555, <a href='https://arxiv.org/pdf/2505.08604.pdf' target='_blank'>https://arxiv.org/pdf/2505.08604.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu-Jen Chen, Xueyang Li, Yiyu Shi, Tsung-Yi Ho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08604">Unsupervised Out-of-Distribution Detection in Medical Imaging Using Multi-Exit Class Activation Maps and Feature Masking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for ensuring the reliability of deep learning models in medical imaging applications. This work is motivated by the observation that class activation maps (CAMs) for in-distribution (ID) data typically emphasize regions that are highly relevant to the model's predictions, whereas OOD data often lacks such focused activations. By masking input images with inverted CAMs, the feature representations of ID data undergo more substantial changes compared to those of OOD data, offering a robust criterion for differentiation. In this paper, we introduce a novel unsupervised OOD detection framework, Multi-Exit Class Activation Map (MECAM), which leverages multi-exit CAMs and feature masking. By utilizing mult-exit networks that combine CAMs from varying resolutions and depths, our method captures both global and local feature representations, thereby enhancing the robustness of OOD detection. We evaluate MECAM on multiple ID datasets, including ISIC19 and PathMNIST, and test its performance against three medical OOD datasets, RSNA Pneumonia, COVID-19, and HeadCT, and one natural image OOD dataset, iSUN. Comprehensive comparisons with state-of-the-art OOD detection methods validate the effectiveness of our approach. Our findings emphasize the potential of multi-exit networks and feature masking for advancing unsupervised OOD detection in medical imaging, paving the way for more reliable and interpretable models in clinical practice.
<div id='section'>Paperid: <span id='pid'>556, <a href='https://arxiv.org/pdf/2505.07863.pdf' target='_blank'>https://arxiv.org/pdf/2505.07863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziliang Wang, Xiaohong Zhang, Ze Shi Li, Meng Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07863">QoSBERT: An Uncertainty-Aware Approach based on Pre-trained Language Models for Service Quality Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of Quality of Service (QoS) metrics is fundamental for selecting and managing cloud based services. Traditional QoS models rely on manual feature engineering and yield only point estimates, offering no insight into the confidence of their predictions. In this paper, we propose QoSBERT, the first framework that reformulates QoS prediction as a semantic regression task based on pre trained language models. Unlike previous approaches relying on sparse numerical features, QoSBERT automatically encodes user service metadata into natural language descriptions, enabling deep semantic understanding. Furthermore, we integrate a Monte Carlo Dropout based uncertainty estimation module, allowing for trustworthy and risk-aware service quality prediction, which is crucial yet underexplored in existing QoS models. QoSBERT applies attentive pooling over contextualized embeddings and a lightweight multilayer perceptron regressor, fine tuned jointly to minimize absolute error. We further exploit the resulting uncertainty estimates to select high quality training samples, improving robustness in low resource settings. On standard QoS benchmark datasets, QoSBERT achieves an average reduction of 11.7% in MAE and 6.7% in RMSE for response time prediction, and 6.9% in MAE for throughput prediction compared to the strongest baselines, while providing well calibrated confidence intervals for robust and trustworthy service quality estimation. Our approach not only advances the accuracy of service quality prediction but also delivers reliable uncertainty quantification, paving the way for more trustworthy, data driven service selection and optimization.
<div id='section'>Paperid: <span id='pid'>557, <a href='https://arxiv.org/pdf/2505.04253.pdf' target='_blank'>https://arxiv.org/pdf/2505.04253.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maria Marina, Nikolay Ivanov, Sergey Pletenev, Mikhail Salnikov, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04253">LLM-Independent Adaptive RAG: Let the Question Speak for Itself</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models~(LLMs) are prone to hallucinations, and Retrieval-Augmented Generation (RAG) helps mitigate this, but at a high computational cost while risking misinformation. Adaptive retrieval aims to retrieve only when necessary, but existing approaches rely on LLM-based uncertainty estimation, which remain inefficient and impractical. In this study, we introduce lightweight LLM-independent adaptive retrieval methods based on external information. We investigated 27 features, organized into 7 groups, and their hybrid combinations. We evaluated these methods on 6 QA datasets, assessing the QA performance and efficiency. The results show that our approach matches the performance of complex LLM-based methods while achieving significant efficiency gains, demonstrating the potential of external information for adaptive retrieval.
<div id='section'>Paperid: <span id='pid'>558, <a href='https://arxiv.org/pdf/2505.03567.pdf' target='_blank'>https://arxiv.org/pdf/2505.03567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zengli Luo, Canlong Zhang, Zhixin Li, Zhiwen Wang, Chunrong Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03567">Uncertainty-Aware Prototype Semantic Decoupling for Text-Based Person Search in Full Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Text-based pedestrian search (TBPS) in full images aims to locate a target pedestrian in untrimmed images using natural language descriptions. However, in complex scenes with multiple pedestrians, existing methods are limited by uncertainties in detection and matching, leading to degraded performance. To address this, we propose UPD-TBPS, a novel framework comprising three modules: Multi-granularity Uncertainty Estimation (MUE), Prototype-based Uncertainty Decoupling (PUD), and Cross-modal Re-identification (ReID). MUE conducts multi-granularity queries to identify potential targets and assigns confidence scores to reduce early-stage uncertainty. PUD leverages visual context decoupling and prototype mining to extract features of the target pedestrian described in the query. It separates and learns pedestrian prototype representations at both the coarse-grained cluster level and the fine-grained individual level, thereby reducing matching uncertainty. ReID evaluates candidates with varying confidence levels, improving detection and retrieval accuracy. Experiments on CUHK-SYSU-TBPS and PRW-TBPS datasets validate the effectiveness of our framework.
<div id='section'>Paperid: <span id='pid'>559, <a href='https://arxiv.org/pdf/2504.16262.pdf' target='_blank'>https://arxiv.org/pdf/2504.16262.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junn Yong Loo, Michelle Adeline, Julia Kaiwen Lau, Fang Yu Leong, Hwa Hui Tew, Arghya Pal, Vishnu Monn Baskaran, Chee-Ming Ting, RaphaÃ«l C. -W. Phan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16262">Learning Energy-Based Generative Models via Potential Flow: A Variational Principle Approach to Probability Density Homotopy Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Energy-based models (EBMs) are a powerful class of probabilistic generative models due to their flexibility and interpretability. However, relationships between potential flows and explicit EBMs remain underexplored, while contrastive divergence training via implicit Markov chain Monte Carlo (MCMC) sampling is often unstable and expensive in high-dimensional settings. In this paper, we propose Variational Potential Flow Bayes (VPFB), a new energy-based generative framework that eliminates the need for implicit MCMC sampling and does not rely on auxiliary networks or cooperative training. VPFB learns an energy-parameterized potential flow by constructing a flow-driven density homotopy that is matched to the data distribution through a variational loss minimizing the Kullback-Leibler divergence between the flow-driven and marginal homotopies. This principled formulation enables robust and efficient generative modeling while preserving the interpretability of EBMs. Experimental results on image generation, interpolation, out-of-distribution detection, and compositional generation confirm the effectiveness of VPFB, showing that our method performs competitively with existing approaches in terms of sample quality and versatility across diverse generative modeling tasks.
<div id='section'>Paperid: <span id='pid'>560, <a href='https://arxiv.org/pdf/2503.06442.pdf' target='_blank'>https://arxiv.org/pdf/2503.06442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Liu, Hao Tang, Haiqi Zhang, Jing Qin, Zechao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06442">OT-DETECTOR: Delving into Optimal Transport for Zero-shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring the reliability and safety of machine learning models in real-world applications. While zero-shot OOD detection, which requires no training on in-distribution (ID) data, has become feasible with the emergence of vision-language models like CLIP, existing methods primarily focus on semantic matching and fail to fully capture distributional discrepancies. To address these limitations, we propose OT-DETECTOR, a novel framework that employs Optimal Transport (OT) to quantify both semantic and distributional discrepancies between test samples and ID labels. Specifically, we introduce cross-modal transport mass and transport cost as semantic-wise and distribution-wise OOD scores, respectively, enabling more robust detection of OOD samples. Additionally, we present a semantic-aware content refinement (SaCR) module, which utilizes semantic cues from ID labels to amplify the distributional discrepancy between ID and hard OOD samples. Extensive experiments on several benchmarks demonstrate that OT-DETECTOR achieves state-of-the-art performance across various OOD detection tasks, particularly in challenging hard-OOD scenarios.
<div id='section'>Paperid: <span id='pid'>561, <a href='https://arxiv.org/pdf/2502.14115.pdf' target='_blank'>https://arxiv.org/pdf/2502.14115.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shailik Sarkar, Raquib Bin Yousuf, Linhan Wang, Brian Mayer, Thomas Mortier, Victor Deklerck, Jakub Truszkowski, John C. Simeone, Marigold Norman, Jade Saunders, Chang-Tien Lu, Naren Ramakrishnan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14115">Chasing the Timber Trail: Machine Learning to Reveal Harvest Location Misrepresentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Illegal logging poses a significant threat to global biodiversity, climate stability, and depresses international prices for legal wood harvesting and responsible forest products trade, affecting livelihoods and communities across the globe. Stable isotope ratio analysis (SIRA) is rapidly becoming an important tool for determining the harvest location of traded, organic, products. The spatial pattern in stable isotope ratio values depends on factors such as atmospheric and environmental conditions and can thus be used for geographic origin identification. We present here the results of a deployed machine learning pipeline where we leverage both isotope values and atmospheric variables to determine timber harvest location. Additionally, the pipeline incorporates uncertainty estimation to facilitate the interpretation of harvest location determination for analysts. We present our experiments on a collection of oak (Quercus spp.) tree samples from its global range. Our pipeline outperforms comparable state-of-the-art models determining geographic harvest origin of commercially traded wood products, and has been used by European enforcement agencies to identify harvest location misrepresentation. We also identify opportunities for further advancement of our framework and how it can be generalized to help identify the origin of falsely labeled organic products throughout the supply chain.
<div id='section'>Paperid: <span id='pid'>562, <a href='https://arxiv.org/pdf/2502.09780.pdf' target='_blank'>https://arxiv.org/pdf/2502.09780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Yang, Bo Dai, Lin Xiao, Yuejie Chi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09780">Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-agent reinforcement learning (MARL) lies at the heart of a plethora of applications involving the interaction of a group of agents in a shared unknown environment. A prominent framework for studying MARL is Markov games, with the goal of finding various notions of equilibria in a sample-efficient manner, such as the Nash equilibrium (NE) and the coarse correlated equilibrium (CCE). However, existing sample-efficient approaches either require tailored uncertainty estimation under function approximation, or careful coordination of the players. In this paper, we propose a novel model-based algorithm, called VMG, that incentivizes exploration via biasing the empirical estimate of the model parameters towards those with a higher collective best-response values of all the players when fixing the other players' policies, thus encouraging the policy to deviate from its current equilibrium for more exploration. VMG is oblivious to different forms of function approximation, and permits simultaneous and uncoupled policy updates of all players. Theoretically, we also establish that VMG achieves a near-optimal regret for finding both the NEs of two-player zero-sum Markov games and CCEs of multi-player general-sum Markov games under linear function approximation in an online environment, which nearly match their counterparts with sophisticated uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>563, <a href='https://arxiv.org/pdf/2501.04899.pdf' target='_blank'>https://arxiv.org/pdf/2501.04899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanna Zubkova, Ji-Hoon Park, Seong-Whan Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04899">SUGAR: Leveraging Contextual Confidence for Smarter Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bearing in mind the limited parametric knowledge of Large Language Models (LLMs), retrieval-augmented generation (RAG) which supplies them with the relevant external knowledge has served as an approach to mitigate the issue of hallucinations to a certain extent. However, uniformly retrieving supporting context makes response generation source-inefficient, as triggering the retriever is not always necessary, or even inaccurate, when a model gets distracted by noisy retrieved content and produces an unhelpful answer. Motivated by these issues, we introduce Semantic Uncertainty Guided Adaptive Retrieval (SUGAR), where we leverage context-based entropy to actively decide whether to retrieve and to further determine between single-step and multi-step retrieval. Our empirical results show that selective retrieval guided by semantic uncertainty estimation improves the performance across diverse question answering tasks, as well as achieves a more efficient inference.
<div id='section'>Paperid: <span id='pid'>564, <a href='https://arxiv.org/pdf/2412.03058.pdf' target='_blank'>https://arxiv.org/pdf/2412.03058.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Wu, Xichen Ye, Songmin Dai, Dengye Pan, Xiaoqiang Li, Weizhong Zhang, Yifan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03058">Revisiting Energy-Based Model for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is an essential approach to robustifying deep learning models, enabling them to identify inputs that fall outside of their trained distribution. Existing OOD detection methods usually depend on crafted data, such as specific outlier datasets or elaborate data augmentations. While this is reasonable, the frequent mismatch between crafted data and OOD data limits model robustness and generalizability. In response to this issue, we introduce Outlier Exposure by Simple Transformations (OEST), a framework that enhances OOD detection by leveraging "peripheral-distribution" (PD) data. Specifically, PD data are samples generated through simple data transformations, thus providing an efficient alternative to manually curated outliers.
  We adopt energy-based models (EBMs) to study PD data. We recognize the "energy barrier" in OOD detection, which characterizes the energy difference between in-distribution (ID) and OOD samples and eases detection. PD data are introduced to establish the energy barrier during training. Furthermore, this energy barrier concept motivates a theoretically grounded energy-barrier loss to replace the classical energy-bounded loss, leading to an improved paradigm, OEST*, which achieves a more effective and theoretically sound separation between ID and OOD samples. We perform empirical validation of our proposal, and extensive experiments across various benchmarks demonstrate that OEST* achieves better or similar accuracy compared with state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>565, <a href='https://arxiv.org/pdf/2411.16189.pdf' target='_blank'>https://arxiv.org/pdf/2411.16189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihua Duan, Jialin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16189">Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) still face challenges when dealing with complex reasoning tasks, often resulting in hallucinations, which limit the practical application of LLMs. To alleviate this issue, this paper proposes a new method that integrates different LLMs to expand the knowledge boundary, reduce dependence on a single model, and promote in-depth debate among agents. The main contributions include: 1) Introducing third-party LLMs to adjust the attention weights of agents through uncertainty estimation and confidence analysis, optimizing consensus formation in multi-agent systems; 2) Experiments on arithmetic datasets have validated the effectiveness of the method, surpassing traditional multi-agent baselines. This research provides a new perspective for large models to alleviate hallucination phenomena when dealing with complex tasks.
<div id='section'>Paperid: <span id='pid'>566, <a href='https://arxiv.org/pdf/2409.10094.pdf' target='_blank'>https://arxiv.org/pdf/2409.10094.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Fang, Qinghua Tao, Zuopeng Yang, Xiaolin Huang, Jie Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10094">Beyond Perceptual Distances: Rethinking Disparity Assessment for Out-of-Distribution Detection with Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OoD) detection aims to justify whether a given sample is from the training distribution of the classifier-under-protection, i.e., In-Distribution (InD), or from OoD. Diffusion Models (DMs) are recently utilized in OoD detection by using the perceptual distances between the given image and its DM generation. DM-based methods bring fresh insights to the field, yet remain under-explored.
  In this work, we point out two main limitations in DM-based OoD detection methods: (i) the perceptual metrics on the disparities between the given sample and its generation are devised only at human-perceived levels, ignoring the abstract or high-level patterns that help better reflect the intrinsic disparities in distribution; (ii) only the raw image contents are taken to measure the disparities, while other representations, i.e., the features and probabilities from the classifier-under-protection, are easy to access at hand but are ignored. To this end, our proposed detection framework goes beyond the perceptual distances and looks into the deep representations from the classifier-under-protection with our novel metrics devised correspondingly, leading to more informative disparity assessments between InD and OoD. An anomaly-removal strategy is integrated to remove the abnormal OoD information in the generation, further enhancing the distinctiveness of disparities. Our work has demonstrated state-of-the-art detection performances among DM-based methods in extensive experiments.
<div id='section'>Paperid: <span id='pid'>567, <a href='https://arxiv.org/pdf/2407.01623.pdf' target='_blank'>https://arxiv.org/pdf/2407.01623.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgia Papacharalampous, Hristos Tyralis, Nikolaos Doulamis, Anastasios Doulamis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01623">Combinations of distributional regression algorithms with application in uncertainty estimation of corrected satellite precipitation products</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To facilitate effective decision-making, precipitation datasets should include uncertainty estimates. Quantile regression with machine learning has been proposed for issuing such estimates. Distributional regression offers distinct advantages over quantile regression, including the ability to model intermittency as well as a stronger ability to extrapolate beyond the training data, which is critical for predicting extreme precipitation. Therefore, here, we introduce the concept of distributional regression in precipitation dataset creation, specifically for the spatial prediction task of correcting satellite precipitation products. Building upon this concept, we formulated new ensemble learning methods that can be valuable not only for spatial prediction but also for other prediction problems. These methods exploit conditional zero-adjusted probability distributions estimated with generalized additive models for location, scale and shape (GAMLSS), spline-based GAMLSS and distributional regression forests as well as their ensembles (stacking based on quantile regression and equal-weight averaging). To identify the most effective methods for our specific problem, we compared them to benchmarks using a large, multi-source precipitation dataset. Stacking was shown to be superior to individual methods at most quantile levels when evaluated with the quantile loss function. Moreover, while the relative ranking of the methods varied across different quantile levels, stacking methods, and to a lesser extent mean combiners, exhibited lower variance in their performance across different quantiles compared to individual methods that occasionally ranked extremely low. Overall, a task-specific combination of multiple distributional regression algorithms could yield significant benefits in terms of stability.
<div id='section'>Paperid: <span id='pid'>568, <a href='https://arxiv.org/pdf/2404.08195.pdf' target='_blank'>https://arxiv.org/pdf/2404.08195.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Yang, Yucong Meng, Kexue Fu, Shuo Wang, Zhijian Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08195">Tackling Ambiguity from Perspective of Uncertainty Inference and Affinity Diversification for Weakly Supervised Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Weakly supervised semantic segmentation (WSSS) with image-level labels intends to achieve dense tasks without laborious annotations. However, due to the ambiguous contexts and fuzzy regions, the performance of WSSS, especially the stages of generating Class Activation Maps (CAMs) and refining pseudo masks, widely suffers from ambiguity while being barely noticed by previous literature. In this work, we propose UniA, a unified single-staged WSSS framework, to efficiently tackle this issue from the perspective of uncertainty inference and affinity diversification, respectively. When activating class objects, we argue that the false activation stems from the bias to the ambiguous regions during the feature extraction. Therefore, we design a more robust feature representation with a probabilistic Gaussian distribution and introduce the uncertainty estimation to avoid the bias. A distribution loss is particularly proposed to supervise the process, which effectively captures the ambiguity and models the complex dependencies among features. When refining pseudo labels, we observe that the affinity from the prevailing refinement methods intends to be similar among ambiguities. To this end, an affinity diversification module is proposed to promote diversity among semantics. A mutual complementing refinement is proposed to initially rectify the ambiguous affinity with multiple inferred pseudo labels. More importantly, a contrastive affinity loss is further designed to diversify the relations among unrelated semantics, which reliably propagates the diversity into the whole feature representations and helps generate better pseudo masks. Extensive experiments are conducted on PASCAL VOC, MS COCO, and medical ACDC datasets, which validate the efficiency of UniA tackling ambiguity and the superiority over recent single-staged or even most multi-staged competitors.
<div id='section'>Paperid: <span id='pid'>569, <a href='https://arxiv.org/pdf/2404.04663.pdf' target='_blank'>https://arxiv.org/pdf/2404.04663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arne Schmidt, Pablo Morales-Ãlvarez, Lee A. D. Cooper, Lee A. Newberg, Andinet Enquobahrie, Aggelos K. Katsaggelos, Rafael Molina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04663">Focused Active Learning for Histopathological Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active Learning (AL) has the potential to solve a major problem of digital pathology: the efficient acquisition of labeled data for machine learning algorithms. However, existing AL methods often struggle in realistic settings with artifacts, ambiguities, and class imbalances, as commonly seen in the medical field. The lack of precise uncertainty estimations leads to the acquisition of images with a low informative value. To address these challenges, we propose Focused Active Learning (FocAL), which combines a Bayesian Neural Network with Out-of-Distribution detection to estimate different uncertainties for the acquisition function. Specifically, the weighted epistemic uncertainty accounts for the class imbalance, aleatoric uncertainty for ambiguous images, and an OoD score for artifacts. We perform extensive experiments to validate our method on MNIST and the real-world Panda dataset for the classification of prostate cancer. The results confirm that other AL methods are 'distracted' by ambiguities and artifacts which harm the performance. FocAL effectively focuses on the most informative images, avoiding ambiguities and artifacts during acquisition. For both experiments, FocAL outperforms existing AL approaches, reaching a Cohen's kappa of 0.764 with only 0.69% of the labeled Panda data.
<div id='section'>Paperid: <span id='pid'>570, <a href='https://arxiv.org/pdf/2403.18476.pdf' target='_blank'>https://arxiv.org/pdf/2403.18476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luca Savant, Diego Valsesia, Enrico Magli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18476">Modeling uncertainty for Gaussian Splatting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Stochastic Gaussian Splatting (SGS): the first framework for uncertainty estimation using Gaussian Splatting (GS). GS recently advanced the novel-view synthesis field by achieving impressive reconstruction quality at a fraction of the computational cost of Neural Radiance Fields (NeRF). However, contrary to the latter, it still lacks the ability to provide information about the confidence associated with their outputs. To address this limitation, in this paper, we introduce a Variational Inference-based approach that seamlessly integrates uncertainty prediction into the common rendering pipeline of GS. Additionally, we introduce the Area Under Sparsification Error (AUSE) as a new term in the loss function, enabling optimization of uncertainty estimation alongside image reconstruction. Experimental results on the LLFF dataset demonstrate that our method outperforms existing approaches in terms of both image rendering quality and uncertainty estimation accuracy. Overall, our framework equips practitioners with valuable insights into the reliability of synthesized views, facilitating safer decision-making in real-world applications.
<div id='section'>Paperid: <span id='pid'>571, <a href='https://arxiv.org/pdf/2403.16260.pdf' target='_blank'>https://arxiv.org/pdf/2403.16260.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhui Xu, Fuxun Yu, Zirui Xu, Nathan Inkawhich, Xiang Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.16260">Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity.
  However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation.
  To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into distinct supervision tasks. This innovative approach, termed Multi-Comprehension (MC) Ensemble, leverages diverse training tasks to generate distinct comprehensions of the data and labels, thereby extending the feature representation field.
  Our experimental results demonstrate the superior performance of the MC Ensemble strategy in OOD detection compared to both the naive Deep Ensemble method and a standalone model of comparable size. This underscores the effectiveness of our proposed approach in enhancing the model's capability to detect instances outside its training distribution.
<div id='section'>Paperid: <span id='pid'>572, <a href='https://arxiv.org/pdf/2403.10567.pdf' target='_blank'>https://arxiv.org/pdf/2403.10567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgia Papacharalampous, Hristos Tyralis, Nikolaos Doulamis, Anastasios Doulamis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10567">Ensemble learning for uncertainty estimation with application to the correction of satellite precipitation products</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictions in the form of probability distributions are crucial for effective decision-making. Quantile regression enables such predictions within spatial prediction settings that aim to create improved precipitation datasets by merging remote sensing and gauge data. However, ensemble learning of quantile regression algorithms remains unexplored in this context and, at the same time, it has not been substantially developed so far in the broader machine learning research landscape. Here, we introduce nine quantile-based ensemble learners and address the aforementioned gap in precipitation dataset creation by presenting the first application of these learners to large precipitation datasets. We employed a novel feature engineering strategy, which reduces the number of predictors by using distance-weighted satellite precipitation at relevant locations, combined with location elevation. Our ensemble learners include six that are based on stacking ideas and three simple methods (mean, median, best combiner). Each of them combines the following six individual algorithms: quantile regression (QR), quantile regression forests (QRF), generalized random forests (GRF), gradient boosting machines (GBM), light gradient boosting machines (LightGBM), and quantile regression neural networks (QRNN). These algorithms serve as both base learners and combiners within different ensemble learning methods. We evaluated performance against a reference method (i.e., QR) using quantile scoring functions and a large dataset. The latter comprises 15 years of monthly gauge-measured and satellite precipitation in the contiguous United States (CONUS). Ensemble learning with QR and QRNN yielded the best results across the various investigated quantile levels, which range from 0.025 to 0.975, outperforming the reference method by 3.91% to 8.95%...
<div id='section'>Paperid: <span id='pid'>573, <a href='https://arxiv.org/pdf/2403.05600.pdf' target='_blank'>https://arxiv.org/pdf/2403.05600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ha Manh Bui, Anqi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.05600">Density-Regression: Efficient and Distance-Aware Deep Regressor for Uncertainty Estimation under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Morden deep ensembles technique achieves strong uncertainty estimation performance by going through multiple forward passes with different models. This is at the price of a high storage space and a slow speed in the inference (test) time. To address this issue, we propose Density-Regression, a method that leverages the density function in uncertainty estimation and achieves fast inference by a single forward pass. We prove it is distance aware on the feature space, which is a necessary condition for a neural network to produce high-quality uncertainty estimation under distribution shifts. Empirically, we conduct experiments on regression tasks with the cubic toy dataset, benchmark UCI, weather forecast with time series, and depth estimation under real-world shifted applications. We show that Density-Regression has competitive uncertainty estimation performance under distribution shifts with modern deep regressors while using a lower model size and a faster inference speed.
<div id='section'>Paperid: <span id='pid'>574, <a href='https://arxiv.org/pdf/2402.17888.pdf' target='_blank'>https://arxiv.org/pdf/2402.17888.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Peng, Yadan Luo, Yonggang Zhang, Yixuan Li, Zhen Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17888">ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Post-hoc out-of-distribution (OOD) detection has garnered intensive attention in reliable machine learning. Many efforts have been dedicated to deriving score functions based on logits, distances, or rigorous data distribution assumptions to identify low-scoring OOD samples. Nevertheless, these estimate scores may fail to accurately reflect the true data density or impose impractical constraints. To provide a unified perspective on density-based score design, we propose a novel theoretical framework grounded in Bregman divergence, which extends distribution considerations to encompass an exponential family of distributions. Leveraging the conjugation constraint revealed in our theorem, we introduce a \textsc{ConjNorm} method, reframing density function design as a search for the optimal norm coefficient $p$ against the given dataset. In light of the computational challenges of normalization, we devise an unbiased and analytically tractable estimator of the partition function using the Monte Carlo-based importance sampling technique. Extensive experiments across OOD detection benchmarks empirically demonstrate that our proposed \textsc{ConjNorm} has established a new state-of-the-art in a variety of OOD detection setups, outperforming the current best method by up to 13.25$\%$ and 28.19$\%$ (FPR95) on CIFAR-100 and ImageNet-1K, respectively.
<div id='section'>Paperid: <span id='pid'>575, <a href='https://arxiv.org/pdf/2402.11406.pdf' target='_blank'>https://arxiv.org/pdf/2402.11406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Min Zhang, Jianfeng He, Taoran Ji, Chang-Tien Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11406">Don't Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The fairness and trustworthiness of Large Language Models (LLMs) are receiving increasing attention. Implicit hate speech, which employs indirect language to convey hateful intentions, occupies a significant portion of practice. However, the extent to which LLMs effectively address this issue remains insufficiently examined. This paper delves into the capability of LLMs to detect implicit hate speech (Classification Task) and express confidence in their responses (Calibration Task). Our evaluation meticulously considers various prompt patterns and mainstream uncertainty estimation methods. Our findings highlight that LLMs exhibit two extremes: (1) LLMs display excessive sensitivity towards groups or topics that may cause fairness issues, resulting in misclassifying benign statements as hate speech. (2) LLMs' confidence scores for each method excessively concentrate on a fixed range, remaining unchanged regardless of the dataset's complexity. Consequently, the calibration performance is heavily reliant on primary classification accuracy. These discoveries unveil new limitations of LLMs, underscoring the need for caution when optimizing models to ensure they do not veer towards extremes. This serves as a reminder to carefully consider sensitivity and confidence in the pursuit of model fairness.
<div id='section'>Paperid: <span id='pid'>576, <a href='https://arxiv.org/pdf/2512.10715.pdf' target='_blank'>https://arxiv.org/pdf/2512.10715.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matias Cosarinsky, Nicolas Gaggion, Rodrigo Echeveste, Enzo Ferrante
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.10715">CheXmask-U: Quantifying uncertainty in landmark-based anatomical segmentation for X-ray images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is essential for the safe clinical deployment of medical image segmentation systems, enabling the identification of unreliable predictions and supporting human oversight. While prior work has largely focused on pixel-level uncertainty, landmark-based segmentation offers inherent topological guarantees yet remains underexplored from an uncertainty perspective. In this work, we study uncertainty estimation for anatomical landmark-based segmentation on chest X-rays. Inspired by hybrid neural network architectures that combine standard image convolutional encoders with graph-based generative decoders, and leveraging their variational latent space, we derive two complementary measures: (i) latent uncertainty, captured directly from the learned distribution parameters, and (ii) predictive uncertainty, obtained by generating multiple stochastic output predictions from latent samples. Through controlled corruption experiments we show that both uncertainty measures increase with perturbation severity, reflecting both global and local degradation. We demonstrate that these uncertainty signals can identify unreliable predictions by comparing with manual ground-truth, and support out-of-distribution detection on the CheXmask dataset. More importantly, we release CheXmask-U (huggingface.co/datasets/mcosarinsky/CheXmask-U), a large scale dataset of 657,566 chest X-ray landmark segmentations with per-node uncertainty estimates, enabling researchers to account for spatial variations in segmentation quality when using these anatomical masks. Our findings establish uncertainty estimation as a promising direction to enhance robustness and safe deployment of landmark-based anatomical segmentation methods in chest X-ray. A fully working interactive demo of the method is available at huggingface.co/spaces/matiasky/CheXmask-U and the source code at github.com/mcosarinsky/CheXmask-U.
<div id='section'>Paperid: <span id='pid'>577, <a href='https://arxiv.org/pdf/2512.04331.pdf' target='_blank'>https://arxiv.org/pdf/2512.04331.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongyi Cai, Bryce Gernon, Wentao Bao, Yifan Li, Matthew Wright, Yu Kong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.04331">Open Set Face Forgery Detection via Dual-Level Evidence Collection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The proliferation of face forgeries has increasingly undermined confidence in the authenticity of online content. Given the rapid development of face forgery generation algorithms, new fake categories are likely to keep appearing, posing a major challenge to existing face forgery detection methods. Despite recent advances in face forgery detection, existing methods are typically limited to binary Real-vs-Fake classification or the identification of known fake categories, and are incapable of detecting the emergence of novel types of forgeries. In this work, we study the Open Set Face Forgery Detection (OSFFD) problem, which demands that the detection model recognize novel fake categories. We reformulate the OSFFD problem and address it through uncertainty estimation, enhancing its applicability to real-world scenarios. Specifically, we propose the Dual-Level Evidential face forgery Detection (DLED) approach, which collects and fuses category-specific evidence on the spatial and frequency levels to estimate prediction uncertainty. Extensive evaluations conducted across diverse experimental settings demonstrate that the proposed DLED method achieves state-of-the-art performance, outperforming various baseline models by an average of 20% in detecting forgeries from novel fake categories. Moreover, on the traditional Real-versus-Fake face forgery detection task, our DLED method concurrently exhibits competitive performance.
<div id='section'>Paperid: <span id='pid'>578, <a href='https://arxiv.org/pdf/2511.08968.pdf' target='_blank'>https://arxiv.org/pdf/2511.08968.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maryam Dialameh, Hossein Rajabzadeh, Weiwei Zhang, Walid Ahmed, Hyock Ju Kwon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.08968">Bayesian Mixture of Experts For Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Bayesian Mixture of Experts (Bayesian-MoE), a post-hoc uncertainty estimation framework for fine-tuned large language models (LLMs) based on Mixture-of-Experts architectures. Our method applies a structured Laplace approximation to the second linear layer of each expert, enabling calibrated uncertainty estimation without modifying the original training procedure or introducing new parameters. Unlike prior approaches, which apply Bayesian inference to added adapter modules, Bayesian-MoE directly targets the expert pathways already present in MoE models, leveraging their modular design for tractable block-wise posterior estimation. We use Kronecker-factored low-rank approximations to model curvature and derive scalable estimates of predictive uncertainty and marginal likelihood. Experiments on common-sense reasoning benchmarks with Qwen1.5-MoE and DeepSeek-MoE demonstrate that Bayesian-MoE improves both expected calibration error (ECE) and negative log-likelihood (NLL) over baselines, confirming its effectiveness for reliable downstream decision-making.
<div id='section'>Paperid: <span id='pid'>579, <a href='https://arxiv.org/pdf/2510.23136.pdf' target='_blank'>https://arxiv.org/pdf/2510.23136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan A. Lara, David Lizcano, Víctor Rampérez, Javier Soriano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.23136">A method for outlier detection based on cluster analysis and visual expert criteria</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection is an important problem occurring in a wide range of areas. Outliers are the outcome of fraudulent behaviour, mechanical faults, human error, or simply natural deviations. Many data mining applications perform outlier detection, often as a preliminary step in order to filter out outliers and build more representative models. In this paper, we propose an outlier detection method based on a clustering process. The aim behind the proposal outlined in this paper is to overcome the specificity of many existing outlier detection techniques that fail to take into account the inherent dispersion of domain objects. The outlier detection method is based on four criteria designed to represent how human beings (experts in each domain) visually identify outliers within a set of objects after analysing the clusters. This has an advantage over other clustering-based outlier detection techniques that are founded on a purely numerical analysis of clusters. Our proposal has been evaluated, with satisfactory results, on data (particularly time series) from two different domains: stabilometry, a branch of medicine studying balance-related functions in human beings and electroencephalography (EEG), a neurological exploration used to diagnose nervous system disorders. To validate the proposed method, we studied method outlier detection and efficiency in terms of runtime. The results of regression analyses confirm that our proposal is useful for detecting outlier data in different domains, with a false positive rate of less than 2% and a reliability greater than 99%.
<div id='section'>Paperid: <span id='pid'>580, <a href='https://arxiv.org/pdf/2510.18322.pdf' target='_blank'>https://arxiv.org/pdf/2510.18322.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeseong Yoon, Heeyoung Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.18322">Uncertainty Estimation by Flexible Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification (UQ) is crucial for deploying machine learning models in high-stakes applications, where overconfident predictions can lead to serious consequences. An effective UQ method must balance computational efficiency with the ability to generalize across diverse scenarios. Evidential deep learning (EDL) achieves efficiency by modeling uncertainty through the prediction of a Dirichlet distribution over class probabilities. However, the restrictive assumption of Dirichlet-distributed class probabilities limits EDL's robustness, particularly in complex or unforeseen situations. To address this, we propose \textit{flexible evidential deep learning} ($\mathcal{F}$-EDL), which extends EDL by predicting a flexible Dirichlet distribution -- a generalization of the Dirichlet distribution -- over class probabilities. This approach provides a more expressive and adaptive representation of uncertainty, significantly enhancing UQ generalization and reliability under challenging scenarios. We theoretically establish several advantages of $\mathcal{F}$-EDL and empirically demonstrate its state-of-the-art UQ performance across diverse evaluation settings, including classical, long-tailed, and noisy in-distribution scenarios.
<div id='section'>Paperid: <span id='pid'>581, <a href='https://arxiv.org/pdf/2510.01456.pdf' target='_blank'>https://arxiv.org/pdf/2510.01456.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brett Barkley, Preston Culbertson, David Fridovich-Keil
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01456">SCOPED: Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for reliable deployment of machine learning systems in vision, robotics, reinforcement learning, and beyond. We introduce Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion (SCOPED), a fast and general-purpose OOD detection method for diffusion models that reduces the number of forward passes on the trained model by an order of magnitude compared to prior methods, outperforming most diffusion-based baselines and closely approaching the accuracy of the strongest ones. SCOPED is computed from a single diffusion model trained once on a diverse dataset, and combines the Jacobian trace and squared norm of the model's score function into a single test statistic. Rather than thresholding on a fixed value, we estimate the in-distribution density of SCOPED scores using kernel density estimation, enabling a flexible, unsupervised test that, in the simplest case, only requires a single forward pass and one Jacobian-vector product (JVP), made efficient by Hutchinson's trace estimator. On four vision benchmarks, SCOPED achieves competitive or state-of-the-art precision-recall scores despite its low computational cost. The same method generalizes to robotic control tasks with shared state and action spaces, identifying distribution shifts across reward functions and training regimes. These results position SCOPED as a practical foundation for fast and reliable OOD detection in real-world domains, including perceptual artifacts in vision, outlier detection in autoregressive models, exploration in reinforcement learning, and dataset curation for unsupervised training.
<div id='section'>Paperid: <span id='pid'>582, <a href='https://arxiv.org/pdf/2509.23355.pdf' target='_blank'>https://arxiv.org/pdf/2509.23355.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Tian, Xiaoling Hu, Juan Eugenio Iglesias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.23355">Test-time Uncertainty Estimation for Medical Image Registration via Transformation Equivariance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate image registration is essential for downstream applications, yet current deep registration networks provide limited indications of whether and when their predictions are reliable. Existing uncertainty estimation strategies, such as Bayesian methods, ensembles, or MC dropout, require architectural changes or retraining, limiting their applicability to pretrained registration networks. Instead, we propose a test-time uncertainty estimation framework that is compatible with any pretrained networks. Our framework is grounded in the transformation equivariance property of registration, which states that the true mapping between two images should remain consistent under spatial perturbations of the input. By analyzing the variance of network predictions under such perturbations, we derive a theoretical decomposition of perturbation-based uncertainty in registration. This decomposition separates into two terms: (i) an intrinsic spread, reflecting epistemic noise, and (ii) a bias jitter, capturing how systematic error drifts under perturbations. Across four anatomical structures (brain, cardiac, abdominal, and lung) and multiple registration models (uniGradICON, SynthMorph), the uncertainty maps correlate consistently with registration errors and highlight regions requiring caution. Our framework turns any pretrained registration network into a risk-aware tool at test time, placing medical image registration one step closer to safe deployment in clinical and large-scale research settings.
<div id='section'>Paperid: <span id='pid'>583, <a href='https://arxiv.org/pdf/2508.21695.pdf' target='_blank'>https://arxiv.org/pdf/2508.21695.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>BarÄ±Å ZÃ¶ngÃ¼r, Robin Hesse, Stefan Roth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21695">Activation Subspaces for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To ensure the reliability of deep models in real-world applications, out-of-distribution (OOD) detection methods aim to distinguish samples close to the training distribution (in-distribution, ID) from those farther away (OOD). In this work, we propose a novel OOD detection method that utilizes singular value decomposition of the weight matrix of the classification head to decompose the model's activations into decisive and insignificant components, which contribute maximally, respectively minimally, to the final classifier output. We find that the subspace of insignificant components more effectively distinguishes ID from OOD data than raw activations in regimes of large distribution shifts (Far-OOD). This occurs because the classification objective leaves the insignificant subspace largely unaffected, yielding features that are ''untainted'' by the target classification task. Conversely, in regimes of smaller distribution shifts (Near-OOD), we find that activation shaping methods profit from only considering the decisive subspace, as the insignificant component can cause interference in the activation space. By combining two findings into a single approach, termed ActSub, we achieve state-of-the-art results in various standard OOD benchmarks.
<div id='section'>Paperid: <span id='pid'>584, <a href='https://arxiv.org/pdf/2508.17667.pdf' target='_blank'>https://arxiv.org/pdf/2508.17667.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Runhe Lai, Xinhua Lu, Kanghao Chen, Qichao Chen, Wei-Shi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17667">Hierarchical Vision-Language Learning for Medical Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In trustworthy medical diagnosis systems, integrating out-of-distribution (OOD) detection aims to identify unknown diseases in samples, thereby mitigating the risk of misdiagnosis. In this study, we propose a novel OOD detection framework based on vision-language models (VLMs), which integrates hierarchical visual information to cope with challenging unknown diseases that resemble known diseases. Specifically, a cross-scale visual fusion strategy is proposed to couple visual embeddings from multiple scales. This enriches the detailed representation of medical images and thus improves the discrimination of unknown diseases. Moreover, a cross-scale hard pseudo-OOD sample generation strategy is proposed to benefit OOD detection maximally. Experimental evaluations on three public medical datasets support that the proposed framework achieves superior OOD detection performance compared to existing methods. The source code is available at https://openi.pcl.ac.cn/OpenMedIA/HVL.
<div id='section'>Paperid: <span id='pid'>585, <a href='https://arxiv.org/pdf/2508.12776.pdf' target='_blank'>https://arxiv.org/pdf/2508.12776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Rajabinasab, Farhad Pakdaman, Moncef Gabbouj, Peter Schneider-Kamp, Arthur Zimek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12776">Randomized PCA Forest for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel unsupervised outlier detection method based on Randomized Principal Component Analysis (PCA). Inspired by the performance of Randomized PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a novel unsupervised outlier detection method that utilizes RPCA Forest for outlier detection. Experimental results showcase the superiority of the proposed approach compared to the classical and state-of-the-art methods in performing the outlier detection task on several datasets while performing competitively on the rest. The extensive analysis of the proposed method reflects it high generalization power and its computational efficiency, highlighting it as a good choice for unsupervised outlier detection.
<div id='section'>Paperid: <span id='pid'>586, <a href='https://arxiv.org/pdf/2508.03890.pdf' target='_blank'>https://arxiv.org/pdf/2508.03890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanghun Jung, Daehoon Gwak, Byron Boots, James Hays
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03890">Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Terrain elevation modeling for off-road navigation aims to accurately estimate changes in terrain geometry in real-time and quantify the corresponding uncertainties. Having precise estimations and uncertainties plays a crucial role in planning and control algorithms to explore safe and reliable maneuver strategies. However, existing approaches, such as Gaussian Processes (GPs) and neural network-based methods, often fail to meet these needs. They are either unable to perform in real-time due to high computational demands, underestimating sharp geometry changes, or harming elevation accuracy when learned with uncertainties. Recently, Neural Processes (NPs) have emerged as a promising approach that integrates the Bayesian uncertainty estimation of GPs with the efficiency and flexibility of neural networks. Inspired by NPs, we propose an effective NP-based method that precisely estimates sharp elevation changes and quantifies the corresponding predictive uncertainty without losing elevation accuracy. Our method leverages semantic features from LiDAR and camera sensors to improve interpolation and extrapolation accuracy in unobserved regions. Also, we introduce a local ball-query attention mechanism to effectively reduce the computational complexity of global attention by 17\% while preserving crucial local and spatial information. We evaluate our method on off-road datasets having interesting geometric features, collected from trails, deserts, and hills. Our results demonstrate superior performance over baselines and showcase the potential of neural processes for effective and expressive terrain modeling in complex off-road environments.
<div id='section'>Paperid: <span id='pid'>587, <a href='https://arxiv.org/pdf/2508.02443.pdf' target='_blank'>https://arxiv.org/pdf/2508.02443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Gottwald, Edgar Heinert, Matthias Rottmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02443">Uncertainty Estimation for Novel Views in Gaussian Splatting from Primitive-Based Representations of Error and Visibility</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present a novel method for uncertainty estimation (UE) in Gaussian Splatting. UE is crucial for using Gaussian Splatting in critical applications such as robotics and medicine. Previous methods typically estimate the variance of Gaussian primitives and use the rendering process to obtain pixel-wise uncertainties. Our method establishes primitive representations of error and visibility of trainings views, which carries meaningful uncertainty information. This representation is obtained by projection of training error and visibility onto the primitives. Uncertainties of novel views are obtained by rendering the primitive representations of uncertainty for those novel views, yielding uncertainty feature maps. To aggregate these uncertainty feature maps of novel views, we perform a pixel-wise regression on holdout data. In our experiments, we analyze the different components of our method, investigating various combinations of uncertainty feature maps and regression models. Furthermore, we considered the effect of separating splatting into foreground and background. Our UEs show high correlations to true errors, outperforming state-of-the-art methods, especially on foreground objects. The trained regression models show generalization capabilities to new scenes, allowing uncertainty estimation without the need for holdout data.
<div id='section'>Paperid: <span id='pid'>588, <a href='https://arxiv.org/pdf/2507.14178.pdf' target='_blank'>https://arxiv.org/pdf/2507.14178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhang Liu, Yuefei Wu, Bin Shi, Bo Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14178">Feature Bank Enhancement for Distance-based Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical to ensuring the reliability of deep learning applications and has attracted significant attention in recent years. A rich body of literature has emerged to develop efficient score functions that assign high scores to in-distribution (ID) samples and low scores to OOD samples, thereby helping distinguish OOD samples. Among these methods, distance-based score functions are widely used because of their efficiency and ease of use. However, deep learning often leads to a biased distribution of data features, and extreme features are inevitable. These extreme features make the distance-based methods tend to assign too low scores to ID samples. This limits the OOD detection capabilities of such methods. To address this issue, we propose a simple yet effective method, Feature Bank Enhancement (FBE), that uses statistical characteristics from dataset to identify and constrain extreme features to the separation boundaries, therapy making the distance between samples inside and outside the distribution farther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10 respectively, and the results show that our method achieves state-of-the-art performance on both benchmark. Additionally, theoretical analysis and supplementary experiments are conducted to provide more insights into our method.
<div id='section'>Paperid: <span id='pid'>589, <a href='https://arxiv.org/pdf/2507.09980.pdf' target='_blank'>https://arxiv.org/pdf/2507.09980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhipeng Xue, Yan Zhang, Ming Li, Chun Li, Yue Liu, Fei Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09980">Uncertainty Quantification for Incomplete Multi-View Data Using Divergence Measures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing multi-view classification and clustering methods typically improve task accuracy by leveraging and fusing information from different views. However, ensuring the reliability of multi-view integration and final decisions is crucial, particularly when dealing with noisy or corrupted data. Current methods often rely on Kullback-Leibler (KL) divergence to estimate uncertainty of network predictions, ignoring domain gaps between different modalities. To address this issue, KPHD-Net, based on HÃ¶lder divergence, is proposed for multi-view classification and clustering tasks. Generally, our KPHD-Net employs a variational Dirichlet distribution to represent class probability distributions, models evidences from different views, and then integrates it with Dempster-Shafer evidence theory (DST) to improve uncertainty estimation effects. Our theoretical analysis demonstrates that Proper HÃ¶lder divergence offers a more effective measure of distribution discrepancies, ensuring enhanced performance in multi-view learning. Moreover, Dempster-Shafer evidence theory, recognized for its superior performance in multi-view fusion tasks, is introduced and combined with the Kalman filter to provide future state estimations. This integration further enhances the reliability of the final fusion results. Extensive experiments show that the proposed KPHD-Net outperforms the current state-of-the-art methods in both classification and clustering tasks regarding accuracy, robustness, and reliability, with theoretical guarantees.
<div id='section'>Paperid: <span id='pid'>590, <a href='https://arxiv.org/pdf/2507.04529.pdf' target='_blank'>https://arxiv.org/pdf/2507.04529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philipp Reis, Joshua Ransiek, David Petri, Jacob Langner, Eric Sax
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04529">A Data-Driven Novelty Score for Diverse In-Vehicle Data Recording</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-quality datasets are essential for training robust perception systems in autonomous driving. However, real-world data collection is often biased toward common scenes and objects, leaving novel cases underrepresented. This imbalance hinders model generalization and compromises safety. The core issue is the curse of rarity. Over time, novel events occur infrequently, and standard logging methods fail to capture them effectively. As a result, large volumes of redundant data are stored, while critical novel cases are diluted, leading to biased datasets. This work presents a real-time data selection method focused on object-level novelty detection to build more balanced and diverse datasets. The method assigns a data-driven novelty score to image frames using a novel dynamic Mean Shift algorithm. It models normal content based on mean and covariance statistics to identify frames with novel objects, discarding those with redundant elements. The main findings show that reducing the training dataset size with this method can improve model performance, whereas higher redundancy tends to degrade it. Moreover, as data redundancy increases, more aggressive filtering becomes both possible and beneficial. While random sampling can offer some gains, it often leads to overfitting and unpredictability in outcomes. The proposed method supports real-time deployment with 32 frames per second and is constant over time. By continuously updating the definition of normal content, it enables efficient detection of novelties in a continuous data stream.
<div id='section'>Paperid: <span id='pid'>591, <a href='https://arxiv.org/pdf/2506.16724.pdf' target='_blank'>https://arxiv.org/pdf/2506.16724.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyi Liu, Weiguang Wang, Hangfeng He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16724">The Role of Model Confidence on Bias Effects in Measured Uncertainties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases induce greater changes in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence leads to greater underestimation of epistemic uncertainty (i.e. overconfidence) due to bias, whereas it has no significant effect on the direction of changes in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.
<div id='section'>Paperid: <span id='pid'>592, <a href='https://arxiv.org/pdf/2504.03440.pdf' target='_blank'>https://arxiv.org/pdf/2504.03440.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mirko Borszukovszki, Ivo Pascal de Jong, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03440">Know What You do Not Know: Verbalized Uncertainty Estimation Robustness on Corrupted Images in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To leverage the full potential of Large Language Models (LLMs) it is crucial to have some information on their answers' uncertainty. This means that the model has to be able to quantify how certain it is in the correctness of a given response. Bad uncertainty estimates can lead to overconfident wrong answers undermining trust in these models. Quite a lot of research has been done on language models that work with text inputs and provide text outputs. Still, since the visual capabilities have been added to these models recently, there has not been much progress on the uncertainty of Visual Language Models (VLMs). We tested three state-of-the-art VLMs on corrupted image data. We found that the severity of the corruption negatively impacted the models' ability to estimate their uncertainty and the models also showed overconfidence in most of the experiments.
<div id='section'>Paperid: <span id='pid'>593, <a href='https://arxiv.org/pdf/2502.03323.pdf' target='_blank'>https://arxiv.org/pdf/2502.03323.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Momin Abbas, Muneeza Azmat, Raya Horesh, Mikhail Yurochkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03323">Out-of-Distribution Detection using Synthetic Data Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distinguishing in- and out-of-distribution (OOD) inputs is crucial for reliable deployment of classification systems. However, OOD data is typically unavailable or difficult to collect, posing a significant challenge for accurate OOD detection. In this work, we present a method that harnesses the generative capabilities of Large Language Models (LLMs) to create high-quality synthetic OOD proxies, eliminating the dependency on any external OOD data source. We study the efficacy of our method on classical text classification tasks such as toxicity detection and sentiment classification as well as classification tasks arising in LLM development and deployment, such as training a reward model for RLHF and detecting misaligned generations. Extensive experiments on nine InD-OOD dataset pairs and various model sizes show that our approach dramatically lowers false positive rates (achieving a perfect zero in some cases) while maintaining high accuracy on in-distribution tasks, outperforming baseline methods by a significant margin.
<div id='section'>Paperid: <span id='pid'>594, <a href='https://arxiv.org/pdf/2501.02616.pdf' target='_blank'>https://arxiv.org/pdf/2501.02616.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amol Khanna, Chenyi Ling, Derek Everett, Edward Raff, Nathan Inkawhich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02616">Multi-layer Radial Basis Function Networks for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing methods for out-of-distribution (OOD) detection use various techniques to produce a score, separate from classification, that determines how ``OOD'' an input is. Our insight is that OOD detection can be simplified by using a neural network architecture which can effectively merge classification and OOD detection into a single step. Radial basis function networks (RBFNs) inherently link classification confidence and OOD detection; however, these networks have lost popularity due to the difficult of training them in a multi-layer fashion. In this work, we develop a multi-layer radial basis function network (MLRBFN) which can be easily trained. To ensure that these networks are also effective for OOD detection, we develop a novel depression mechanism. We apply MLRBFNs as standalone classifiers and as heads on top of pretrained feature extractors, and find that they are competitive with commonly used methods for OOD detection. Our MLRBFN architecture demonstrates a promising new direction for OOD detection methods.
<div id='section'>Paperid: <span id='pid'>595, <a href='https://arxiv.org/pdf/2412.19017.pdf' target='_blank'>https://arxiv.org/pdf/2412.19017.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saadat Behzadi, Danial Sharifrazi, Roohallah Alizadehsani, Mojtaba Lotfaliany, Mohammadreza Mohebbi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19017">Brain Ageing Prediction using Isolation Forest Technique and Residual Neural Network (ResNet)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Brain aging is a complex and dynamic process, leading to functional and structural changes in the brain. These changes could lead to the increased risk of neurodegenerative diseases and cognitive decline. Accurate brain-age estimation utilizing neuroimaging data has become necessary for detecting initial signs of neurodegeneration. Here, we propose a novel deep learning approach using the Residual Neural Network 101 Version 2 (ResNet101V2) model to predict brain age from MRI scans. To train, validate and test our proposed model, we used a large dataset of 2102 images which were selected randomly from the International Consortium for Brain Mapping (ICBM). Next, we applied data preprocessing techniques, including normalizing the images and using outlier detection via Isolation Forest method. Then, we evaluated various pre-trained approaches (namely: MobileNetV2, ResNet50V2, ResNet101V2, Xception). The results demonstrated that the ResNet101V2 model has higher performance compared with the other models, attaining MAEs of 0.9136 and 0.8242 years for before and after using Isolation Forest process. Our method achieved a high accuracy in brain age estimation in ICBM dataset and it provides a reliable brain age prediction.
<div id='section'>Paperid: <span id='pid'>596, <a href='https://arxiv.org/pdf/2411.10254.pdf' target='_blank'>https://arxiv.org/pdf/2411.10254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdullah Abdullah, Fannya Ratana Sandjaja, Ayesha Abdul Majeed, Gyan Wickremasinghe, Karen Rafferty, Vishal Sharma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10254">Uncertainty in Supply Chain Digital Twins: A Quantum-Classical Hybrid Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates uncertainty quantification (UQ) using quantum-classical hybrid machine learning (ML) models for applications in complex and dynamic fields, such as attaining resiliency in supply chain digital twins and financial risk assessment. Although quantum feature transformations have been integrated into ML models for complex data tasks, a gap exists in determining their impact on UQ within their hybrid architectures (quantum-classical approach). This work applies existing UQ techniques for different models within a hybrid framework, examining how quantum feature transformation affects uncertainty propagation. Increasing qubits from 4 to 16 shows varied model responsiveness to outlier detection (OD) samples, which is a critical factor for resilient decision-making in dynamic environments. This work shows how quantum computing techniques can transform data features for UQ, particularly when combined with classical methods.
<div id='section'>Paperid: <span id='pid'>597, <a href='https://arxiv.org/pdf/2411.05619.pdf' target='_blank'>https://arxiv.org/pdf/2411.05619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhilong Zhang, Ruifeng Chen, Junyin Ye, Yihao Sun, Pengyuan Wang, Jingcheng Pang, Kaiyuan Li, Tianshuo Liu, Haoxin Lin, Yang Yu, Zhi-Hua Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05619">WHALE: Towards Generalizable and Scalable World Models for Embodied Decision-making</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>World models play a crucial role in decision-making within embodied environments, enabling cost-free explorations that would otherwise be expensive in the real world. To facilitate effective decision-making, world models must be equipped with strong generalizability to support faithful imagination in out-of-distribution (OOD) regions and provide reliable uncertainty estimation to assess the credibility of the simulated experiences, both of which present significant challenges for prior scalable approaches. This paper introduces WHALE, a framework for learning generalizable world models, consisting of two key techniques: behavior-conditioning and retracing-rollout. Behavior-conditioning addresses the policy distribution shift, one of the primary sources of the world model generalization error, while retracing-rollout enables efficient uncertainty estimation without the necessity of model ensembles. These techniques are universal and can be combined with any neural network architecture for world model learning. Incorporating these two techniques, we present Whale-ST, a scalable spatial-temporal transformer-based world model with enhanced generalizability. We demonstrate the superiority of Whale-ST in simulation tasks by evaluating both value estimation accuracy and video generation fidelity. Additionally, we examine the effectiveness of our uncertainty estimation technique, which enhances model-based policy optimization in fully offline scenarios. Furthermore, we propose Whale-X, a 414M parameter world model trained on 970K trajectories from Open X-Embodiment datasets. We show that Whale-X exhibits promising scalability and strong generalizability in real-world manipulation scenarios using minimal demonstrations.
<div id='section'>Paperid: <span id='pid'>598, <a href='https://arxiv.org/pdf/2409.08754.pdf' target='_blank'>https://arxiv.org/pdf/2409.08754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeseong Yoon, Heeyoung Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08754">Uncertainty Estimation by Density Aware Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evidential deep learning (EDL) has shown remarkable success in uncertainty estimation. However, there is still room for improvement, particularly in out-of-distribution (OOD) detection and classification tasks. The limited OOD detection performance of EDL arises from its inability to reflect the distance between the testing example and training data when quantifying uncertainty, while its limited classification performance stems from its parameterization of the concentration parameters. To address these limitations, we propose a novel method called Density Aware Evidential Deep Learning (DAEDL). DAEDL integrates the feature space density of the testing example with the output of EDL during the prediction stage, while using a novel parameterization that resolves the issues in the conventional parameterization. We prove that DAEDL enjoys a number of favorable theoretical properties. DAEDL demonstrates state-of-the-art performance across diverse downstream tasks related to uncertainty estimation and classification
<div id='section'>Paperid: <span id='pid'>599, <a href='https://arxiv.org/pdf/2409.02149.pdf' target='_blank'>https://arxiv.org/pdf/2409.02149.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thanh Tung Khuat, Robert Bassett, Ellen Otte, Bogdan Gabrys
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02149">Uncertainty Quantification Using Ensemble Learning and Monte Carlo Sampling for Performance Prediction and Monitoring in Cell Culture Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biopharmaceutical products, particularly monoclonal antibodies (mAbs), have gained prominence in the pharmaceutical market due to their high specificity and efficacy. As these products are projected to constitute a substantial portion of global pharmaceutical sales, the application of machine learning models in mAb development and manufacturing is gaining momentum. This paper addresses the critical need for uncertainty quantification in machine learning predictions, particularly in scenarios with limited training data. Leveraging ensemble learning and Monte Carlo simulations, our proposed method generates additional input samples to enhance the robustness of the model in small training datasets. We evaluate the efficacy of our approach through two case studies: predicting antibody concentrations in advance and real-time monitoring of glucose concentrations during bioreactor runs using Raman spectra data. Our findings demonstrate the effectiveness of the proposed method in estimating the uncertainty levels associated with process performance predictions and facilitating real-time decision-making in biopharmaceutical manufacturing. This contribution not only introduces a novel approach for uncertainty quantification but also provides insights into overcoming challenges posed by small training datasets in bioprocess development. The evaluation demonstrates the effectiveness of our method in addressing key challenges related to uncertainty estimation within upstream cell cultivation, illustrating its potential impact on enhancing process control and product quality in the dynamic field of biopharmaceuticals.
<div id='section'>Paperid: <span id='pid'>600, <a href='https://arxiv.org/pdf/2408.16469.pdf' target='_blank'>https://arxiv.org/pdf/2408.16469.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Jiang, Sicheng Zhao, Jiankun Zhu, Wenbo Tang, Zhaopan Xu, Jidong Yang, Guoping Liu, Tengfei Xing, Pengfei Xu, Hongxun Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16469">Multi-source Domain Adaptation for Panoramic Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised domain adaptation methods for panoramic semantic segmentation utilize real pinhole images or low-cost synthetic panoramic images to transfer segmentation models to real panoramic images. However, these methods struggle to understand the panoramic structure using only real pinhole images and lack real-world scene perception with only synthetic panoramic images. Therefore, in this paper, we propose a new task, Multi-source Domain Adaptation for Panoramic Semantic Segmentation (MSDA4PASS), which leverages both real pinhole and synthetic panoramic images to improve segmentation on unlabeled real panoramic images. There are two key issues in the MSDA4PASS task: (1) distortion gaps between the pinhole and panoramic domains -- panoramic images exhibit global and local distortions absent in pinhole images; (2) texture gaps between the source and target domains -- scenes and styles differ across domains. To address these two issues, we propose a novel framework, Deformation Transform Aligner for Panoramic Semantic Segmentation (DTA4PASS), which converts all pinhole images in the source domains into distorted images and aligns the source distorted and panoramic images with the target panoramic images. Specifically, DTA4PASS consists of two main components: Unpaired Semantic Morphing (USM) and Distortion Gating Alignment (DGA). First, in USM, the Dual-view Discriminator (DvD) assists in training the diffeomorphic deformation network at the image and pixel level, enabling the effective deformation transformation of pinhole images without paired panoramic views, alleviating distortion gaps. Second, DGA assigns pinhole-like (pin-like) and panoramic-like (pan-like) features to each image by gating, and aligns these two features through uncertainty estimation, reducing texture gaps.
<div id='section'>Paperid: <span id='pid'>601, <a href='https://arxiv.org/pdf/2406.08839.pdf' target='_blank'>https://arxiv.org/pdf/2406.08839.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenhui Xiao, Rodrigo Santa Cruz, David Ahmedt-Aristizabal, Olivier Salvado, Clinton Fookes, Leo Lebrat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08839">NeRF Director: Revisiting View Selection in Neural Volume Rendering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Rendering representations have significantly contributed to the field of 3D computer vision. Given their potential, considerable efforts have been invested to improve their performance. Nonetheless, the essential question of selecting training views is yet to be thoroughly investigated. This key aspect plays a vital role in achieving high-quality results and aligns with the well-known tenet of deep learning: "garbage in, garbage out". In this paper, we first illustrate the importance of view selection by demonstrating how a simple rotation of the test views within the most pervasive NeRF dataset can lead to consequential shifts in the performance rankings of state-of-the-art techniques. To address this challenge, we introduce a unified framework for view selection methods and devise a thorough benchmark to assess its impact. Significant improvements can be achieved without leveraging error or uncertainty estimation but focusing on uniform view coverage of the reconstructed object, resulting in a training-free approach. Using this technique, we show that high-quality renderings can be achieved faster by using fewer views. We conduct extensive experiments on both synthetic datasets and realistic data to demonstrate the effectiveness of our proposed method compared with random, conventional error-based, and uncertainty-guided view selection.
<div id='section'>Paperid: <span id='pid'>602, <a href='https://arxiv.org/pdf/2406.06999.pdf' target='_blank'>https://arxiv.org/pdf/2406.06999.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junfei Yi, Jianxu Mao, Tengfei Liu, Mingjie Li, Hanyu Gu, Hui Zhang, Xiaojun Chang, Yaonan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06999">Teaching with Uncertainty: Unleashing the Potential of Knowledge Distillation in Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge distillation (KD) is a widely adopted and effective method for compressing models in object detection tasks. Particularly, feature-based distillation methods have shown remarkable performance. Existing approaches often ignore the uncertainty in the teacher model's knowledge, which stems from data noise and imperfect training. This limits the student model's ability to learn latent knowledge, as it may overly rely on the teacher's imperfect guidance. In this paper, we propose a novel feature-based distillation paradigm with knowledge uncertainty for object detection, termed "Uncertainty Estimation-Discriminative Knowledge Extraction-Knowledge Transfer (UET)", which can seamlessly integrate with existing distillation methods. By leveraging the Monte Carlo dropout technique, we introduce knowledge uncertainty into the training process of the student model, facilitating deeper exploration of latent knowledge. Our method performs effectively during the KD process without requiring intricate structures or extensive computational resources. Extensive experiments validate the effectiveness of our proposed approach across various distillation strategies, detectors, and backbone architectures. Specifically, following our proposed paradigm, the existing FGD method achieves state-of-the-art (SoTA) performance, with ResNet50-based GFL achieving 44.1% mAP on the COCO dataset, surpassing the baselines by 3.9%.
<div id='section'>Paperid: <span id='pid'>603, <a href='https://arxiv.org/pdf/2405.03060.pdf' target='_blank'>https://arxiv.org/pdf/2405.03060.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhaiming Shen, Menglun Wang, Guang Cheng, Ming-Jun Lai, Lin Mu, Ruihao Huang, Qi Liu, Hao Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.03060">Tree-based Ensemble Learning for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Being able to successfully determine whether the testing samples has similar distribution as the training samples is a fundamental question to address before we can safely deploy most of the machine learning models into practice. In this paper, we propose TOOD detection, a simple yet effective tree-based out-of-distribution (TOOD) detection mechanism to determine if a set of unseen samples will have similar distribution as of the training samples. The TOOD detection mechanism is based on computing pairwise hamming distance of testing samples' tree embeddings, which are obtained by fitting a tree-based ensemble model through in-distribution training samples. Our approach is interpretable and robust for its tree-based nature. Furthermore, our approach is efficient, flexible to various machine learning tasks, and can be easily generalized to unsupervised setting. Extensive experiments are conducted to show the proposed method outperforms other state-of-the-art out-of-distribution detection methods in distinguishing the in-distribution from out-of-distribution on various tabular, image, and text data.
<div id='section'>Paperid: <span id='pid'>604, <a href='https://arxiv.org/pdf/2404.15390.pdf' target='_blank'>https://arxiv.org/pdf/2404.15390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Josefina Catoni, Domonkos Martos, Ferenc Csikor, Enzo Ferrante, Diego H. Milone, BalÃ¡zs MeszÃ©na, GergÅ OrbÃ¡n, Rodrigo Echeveste
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15390">Uncertainty in latent representations of variational autoencoders optimized for visual tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Generative Models (DGMs) can learn flexible latent variable representations of images while avoiding intractable computations, common in Bayesian inference. However, investigating the properties of inference in Variational Autoencoders (VAEs), a major class of DGMs, reveals severe problems in their uncertainty representations. Here we draw inspiration from classical computer vision to introduce an inductive bias into the VAE by incorporating a global explaining-away latent variable, which remedies defective inference in VAEs. Unlike standard VAEs, the Explaing-Away VAE (EA-VAE) provides uncertainty estimates that align with normative requirements across a wide spectrum of perceptual tasks, including image corruption, interpolation, and out-of-distribution detection. We find that restored inference capabilities are delivered by developing a motif in the inference network (the encoder) which is widespread in biological neural networks: divisive normalization. Our results establish EA-VAEs as reliable tools to perform inference under deep generative models with appropriate estimates of uncertainty.
<div id='section'>Paperid: <span id='pid'>605, <a href='https://arxiv.org/pdf/2402.16865.pdf' target='_blank'>https://arxiv.org/pdf/2402.16865.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anirudh Prabhakaran, YeKun Xiao, Ching-Yu Cheng, Dianbo Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16865">Enhance Eye Disease Detection using Learnable Probabilistic Discrete Latents in Machine Learning Architectures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ocular diseases, including diabetic retinopathy and glaucoma, present a significant public health challenge due to their high prevalence and potential for causing vision impairment. Early and accurate diagnosis is crucial for effective treatment and management. In recent years, deep learning models have emerged as powerful tools for analysing medical images, such as retina imaging. However, challenges persist in model relibability and uncertainty estimation, which are critical for clinical decision-making. This study leverages the probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over latent discrete dropout masks for the classification and analysis of ocular diseases using fundus images. We develop a robust and generalizable method that utilizes GFlowOut integrated with ResNet18 and ViT models as the backbone in identifying various ocular conditions. This study employs a unique set of dropout masks - none, random, bottomup, and topdown - to enhance model performance in analyzing these fundus images. Our results demonstrate that our learnable probablistic latents significantly improves accuracy, outperforming the traditional dropout approach. We utilize a gradient map calculation method, Grad-CAM, to assess model explainability, observing that the model accurately focuses on critical image regions for predictions. The integration of GFlowOut in neural networks presents a promising advancement in the automated diagnosis of ocular diseases, with implications for improving clinical workflows and patient outcomes.
<div id='section'>Paperid: <span id='pid'>606, <a href='https://arxiv.org/pdf/2402.15374.pdf' target='_blank'>https://arxiv.org/pdf/2402.15374.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anja DeliÄ, Matej GrciÄ, SiniÅ¡a Å egviÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.15374">Outlier detection by ensembling uncertainty with negative objectness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection is an essential capability in safety-critical applications of supervised visual recognition. Most of the existing methods deliver best results by encouraging standard closed-set models to produce low-confidence predictions in negative training data. However, that approach conflates prediction uncertainty with recognition of the negative class. We therefore reconsider direct prediction of K+1 logits that correspond to K groundtruth classes and one outlier class. This setup allows us to formulate a novel anomaly score as an ensemble of in-distribution uncertainty and the posterior of the outlier class which we term negative objectness. Now outliers can be independently detected due to i) high prediction uncertainty or ii) similarity with negative data. We embed our method into a dense prediction architecture with mask-level recognition over K+2 classes. The training procedure encourages the novel K+2-th class to learn negative objectness at pasted negative instances. Our models outperform the current state-of-the art on standard benchmarks for image-wide and pixel-level outlier detection with and without training on real negative data.
<div id='section'>Paperid: <span id='pid'>607, <a href='https://arxiv.org/pdf/2402.06509.pdf' target='_blank'>https://arxiv.org/pdf/2402.06509.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alberto Testoni, Raquel FernÃ¡ndez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06509">Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importance of equipping dialogue systems with the ability to assess their own uncertainty and exploit in interaction.
<div id='section'>Paperid: <span id='pid'>608, <a href='https://arxiv.org/pdf/2402.06160.pdf' target='_blank'>https://arxiv.org/pdf/2402.06160.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maohao Shen, J. Jon Ryu, Soumya Ghosh, Yuheng Bu, Prasanna Sattigeri, Subhro Das, Gregory W. Wornell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06160">Are Uncertainty Quantification Capabilities of Evidential Deep Learning a Mirage?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called \emph{evidential deep learning} (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.
<div id='section'>Paperid: <span id='pid'>609, <a href='https://arxiv.org/pdf/2402.01476.pdf' target='_blank'>https://arxiv.org/pdf/2402.01476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingyi Chen, Qinghua Tao, Francesco Tonin, Johan A. K. Suykens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01476">Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While the great capability of Transformers significantly boosts prediction accuracy, it could also yield overconfident predictions and require calibrated uncertainty estimation, which can be commonly tackled by Gaussian processes (GPs). Existing works apply GPs with symmetric kernels under variational inference to the attention kernel; however, omitting the fact that attention kernels are in essence asymmetric. Moreover, the complexity of deriving the GP posteriors remains high for large-scale data. In this work, we propose Kernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for building uncertainty-aware self-attention where the asymmetry of attention kernels is tackled by Kernel SVD (KSVD) and a reduced complexity is acquired. Through KEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors from KSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) using only a small set of adjoint eigenfunctions from KSVD, the derivation of SVGP posteriors can be based on the inversion of a diagonal matrix containing singular values, contributing to a reduction in time complexity; iii) an evidence lower bound is derived so that variational parameters and network weights can be optimized with it. Experiments verify our excellent performances and efficiency on in-distribution, distribution-shift and out-of-distribution benchmarks.
<div id='section'>Paperid: <span id='pid'>610, <a href='https://arxiv.org/pdf/2401.07271.pdf' target='_blank'>https://arxiv.org/pdf/2401.07271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sheng Zhang, Minheng Chen, Junxian Wu, Ziyue Zhang, Tonglong Li, Cheng Xue, Youyong Kong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.07271">SpineCLUE: Automatic Vertebrae Identification Using Contrastive Learning and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vertebrae identification in arbitrary fields-of-view plays a crucial role in diagnosing spine disease. Most spine CT contain only local regions, such as the neck, chest, and abdomen. Therefore, identification should not depend on specific vertebrae or a particular number of vertebrae being visible. Existing methods at the spine-level are unable to meet this challenge. In this paper, we propose a three-stage method to address the challenges in 3D CT vertebrae identification at vertebrae-level. By sequentially performing the tasks of vertebrae localization, segmentation, and identification, the anatomical prior information of the vertebrae is effectively utilized throughout the process. Specifically, we introduce a dual-factor density clustering algorithm to acquire localization information for individual vertebra, thereby facilitating subsequent segmentation and identification processes. In addition, to tackle the issue of interclass similarity and intra-class variability, we pre-train our identification network by using a supervised contrastive learning method. To further optimize the identification results, we estimated the uncertainty of the classification network and utilized the message fusion module to combine the uncertainty scores, while aggregating global information about the spine. Our method achieves state-of-the-art results on the VerSe19 and VerSe20 challenge benchmarks. Additionally, our approach demonstrates outstanding generalization performance on an collected dataset containing a wide range of abnormal cases.
<div id='section'>Paperid: <span id='pid'>611, <a href='https://arxiv.org/pdf/2512.14177.pdf' target='_blank'>https://arxiv.org/pdf/2512.14177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joseph Hoche, Andrei Bursuc, David Brellmann, Gilles Louppe, Pavel Izmailov, Angela Yao, Gianni Franchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.14177">Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Vision-Language Models (LVLMs) often produce plausible but unreliable outputs, making robust uncertainty estimation essential. Recent work on semantic uncertainty estimates relies on external models to cluster multiple sampled responses and measure their semantic consistency. However, these clustering methods are often fragile, highly sensitive to minor phrasing variations, and can incorrectly group or separate semantically similar answers, leading to unreliable uncertainty estimates. We propose Semantic Gaussian Process Uncertainty (SGPU), a Bayesian framework that quantifies semantic uncertainty by analyzing the geometric structure of answer embeddings, avoiding brittle clustering. SGPU maps generated answers into a dense semantic space, computes the Gram matrix of their embeddings, and summarizes their semantic configuration via the eigenspectrum. This spectral representation is then fed into a Gaussian Process Classifier that learns to map patterns of semantic consistency to predictive uncertainty, and that can be applied in both black-box and white-box settings. Across six LLMs and LVLMs on eight datasets spanning VQA, image classification, and textual QA, SGPU consistently achieves state-of-the-art calibration (ECE) and discriminative (AUROC, AUARC) performance. We further show that SGPU transfers across models and modalities, indicating that its spectral representation captures general patterns of semantic uncertainty.
<div id='section'>Paperid: <span id='pid'>612, <a href='https://arxiv.org/pdf/2511.07884.pdf' target='_blank'>https://arxiv.org/pdf/2511.07884.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Si-Hyun Kim, Heon-Gyu Kwak, Byoung-Hee Kwon, Seong-Whan Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.07884">Meta-cognitive Multi-scale Hierarchical Reasoning for Motor Imagery Decoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Brain-computer interface (BCI) aims to decode motor intent from noninvasive neural signals to enable control of external devices, but practical deployment remains limited by noise and variability in motor imagery (MI)-based electroencephalogram (EEG) signals. This work investigates a hierarchical and meta-cognitive decoding framework for four-class MI classification. We introduce a multi-scale hierarchical signal processing module that reorganizes backbone features into temporal multi-scale representations, together with an introspective uncertainty estimation module that assigns per-cycle reliability scores and guides iterative refinement. We instantiate this framework on three standard EEG backbones (EEGNet, ShallowConvNet, and DeepConvNet) and evaluate four-class MI decoding using the BCI Competition IV-2a dataset under a subject-independent setting. Across all backbones, the proposed components improve average classification accuracy and reduce inter-subject variance compared to the corresponding baselines, indicating increased robustness to subject heterogeneity and noisy trials. These results suggest that combining hierarchical multi-scale processing with introspective confidence estimation can enhance the reliability of MI-based BCI systems.
<div id='section'>Paperid: <span id='pid'>613, <a href='https://arxiv.org/pdf/2511.02092.pdf' target='_blank'>https://arxiv.org/pdf/2511.02092.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kishansingh Rajput, Malachi Schram, Brian Sammuli, Sen Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.02092">Uncertainty Guided Online Ensemble for Non-stationary Data Streams in Fusion Science</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine Learning (ML) is poised to play a pivotal role in the development and operation of next-generation fusion devices. Fusion data shows non-stationary behavior with distribution drifts, resulted by both experimental evolution and machine wear-and-tear. ML models assume stationary distribution and fail to maintain performance when encountered with such non-stationary data streams. Online learning techniques have been leveraged in other domains, however it has been largely unexplored for fusion applications. In this paper, we present an application of online learning to continuously adapt to drifting data stream for prediction of Toroidal Field (TF) coils deflection at the DIII-D fusion facility. The results demonstrate that online learning is critical to maintain ML model performance and reduces error by 80% compared to a static model. Moreover, traditional online learning can suffer from short-term performance degradation as ground truth is not available before making the predictions. As such, we propose an uncertainty guided online ensemble method to further improve the performance. The Deep Gaussian Process Approximation (DGPA) technique is leveraged for calibrated uncertainty estimation and the uncertainty values are then used to guide a meta-algorithm that produces predictions based on an ensemble of learners trained on different horizon of historical data. The DGPA also provides uncertainty estimation along with the predictions for decision makers. The online ensemble and the proposed uncertainty guided online ensemble reduces predictions error by about 6%, and 10% respectively over standard single model based online learning.
<div id='section'>Paperid: <span id='pid'>614, <a href='https://arxiv.org/pdf/2510.17381.pdf' target='_blank'>https://arxiv.org/pdf/2510.17381.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Achref Jaziri, Martin Rogmann, Martin Mundt, Visvanathan Ramesh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.17381">Beyond Binary Out-of-Distribution Detection: Characterizing Distributional Shifts with Multi-Statistic Diffusion Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) data is critical for machine learning, be it for safety reasons or to enable open-ended learning. However, beyond mere detection, choosing an appropriate course of action typically hinges on the type of OOD data encountered. Unfortunately, the latter is generally not distinguished in practice, as modern OOD detection methods collapse distributional shifts into single scalar outlier scores. This work argues that scalar-based methods are thus insufficient for OOD data to be properly contextualized and prospectively exploited, a limitation we overcome with the introduction of DISC: Diffusion-based Statistical Characterization. DISC leverages the iterative denoising process of diffusion models to extract a rich, multi-dimensional feature vector that captures statistical discrepancies across multiple noise levels. Extensive experiments on image and tabular benchmarks show that DISC matches or surpasses state-of-the-art detectors for OOD detection and, crucially, also classifies OOD type, a capability largely absent from prior work. As such, our work enables a shift from simple binary OOD detection to a more granular detection.
<div id='section'>Paperid: <span id='pid'>615, <a href='https://arxiv.org/pdf/2510.10653.pdf' target='_blank'>https://arxiv.org/pdf/2510.10653.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Schmidt, Julius Körner, Stephan Günnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.10653">A Machine Learning Perspective on Automated Driving Corner Cases</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For high-stakes applications, like autonomous driving, a safe operation is necessary to prevent harm, accidents, and failures. Traditionally, difficult scenarios have been categorized into corner cases and addressed individually. However, this example-based categorization is not scalable and lacks a data coverage perspective, neglecting the generalization to training data of machine learning models. In our work, we propose a novel machine learning approach that takes the underlying data distribution into account. Based on our novel perspective, we present a framework for effective corner case recognition for perception on individual samples. In our evaluation, we show that our approach (i) unifies existing scenario-based corner case taxonomies under a distributional perspective, (ii) achieves strong performance on corner case detection tasks across standard benchmarks for which we extend established out-of-distribution detection benchmarks, and (iii) enables analysis of combined corner cases via a newly introduced fog-augmented Lost & Found dataset. These results provide a principled basis for corner case recognition, underlining our manual specification-free definition.
<div id='section'>Paperid: <span id='pid'>616, <a href='https://arxiv.org/pdf/2510.01251.pdf' target='_blank'>https://arxiv.org/pdf/2510.01251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlo Bono, Federico Belotti, Matteo Palmonari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01251">Efficient Uncertainty Estimation for LLM-based Entity Linking in Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Linking textual values in tabular data to their corresponding entities in a Knowledge Base is a core task across a variety of data integration and enrichment applications. Although Large Language Models (LLMs) have shown State-of-The-Art performance in Entity Linking (EL) tasks, their deployment in real-world scenarios requires not only accurate predictions but also reliable uncertainty estimates, which require resource-demanding multi-shot inference, posing serious limits to their actual applicability. As a more efficient alternative, we investigate a self-supervised approach for estimating uncertainty from single-shot LLM outputs using token-level features, reducing the need for multiple generations. Evaluation is performed on an EL task on tabular data across multiple LLMs, showing that the resulting uncertainty estimates are highly effective in detecting low-accuracy outputs. This is achieved at a fraction of the computational cost, ultimately supporting a cost-effective integration of uncertainty measures into LLM-based EL workflows. The method offers a practical way to incorporate uncertainty estimation into EL workflows with limited computational overhead.
<div id='section'>Paperid: <span id='pid'>617, <a href='https://arxiv.org/pdf/2510.00463.pdf' target='_blank'>https://arxiv.org/pdf/2510.00463.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daofu Zhang, Mehrdad Pournaderi, Hanne M. Clifford, Yu Xiang, Pramod K. Varshney
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00463">On the Adversarial Robustness of Learning-based Conformal Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper studies the adversarial robustness of conformal novelty detection. In particular, we focus on AdaDetect, a powerful learning-based framework for novelty detection with finite-sample false discovery rate (FDR) control. While AdaDetect provides rigorous statistical guarantees under benign conditions, its behavior under adversarial perturbations remains unexplored. We first formulate an oracle attack setting that quantifies the worst-case degradation of FDR, deriving an upper bound that characterizes the statistical cost of attacks. This idealized formulation directly motivates a practical and effective attack scheme that only requires query access to AdaDetect's output labels. Coupling these formulations with two popular and complementary black-box adversarial algorithms, we systematically evaluate the vulnerability of AdaDetect on synthetic and real-world datasets. Our results show that adversarial perturbations can significantly increase the FDR while maintaining high detection power, exposing fundamental limitations of current error-controlled novelty detection methods and motivating the development of more robust alternatives.
<div id='section'>Paperid: <span id='pid'>618, <a href='https://arxiv.org/pdf/2509.18111.pdf' target='_blank'>https://arxiv.org/pdf/2509.18111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Faizul Rakib Sayem, Shahana Ibrahim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18111">Prompt Optimization Meets Subspace Representation Learning for Few-shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The reliability of artificial intelligence (AI) systems in open-world settings depends heavily on their ability to flag out-of-distribution (OOD) inputs unseen during training. Recent advances in large-scale vision-language models (VLMs) have enabled promising few-shot OOD detection frameworks using only a handful of in-distribution (ID) samples. However, existing prompt learning-based OOD methods rely solely on softmax probabilities, overlooking the rich discriminative potential of the feature embeddings learned by VLMs trained on millions of samples. To address this limitation, we propose a novel context optimization (CoOp)-based framework that integrates subspace representation learning with prompt tuning. Our approach improves ID-OOD separability by projecting the ID features into a subspace spanned by prompt vectors, while projecting ID-irrelevant features into an orthogonal null space. To train such OOD detection framework, we design an easy-to-handle end-to-end learning criterion that ensures strong OOD detection performance as well as high ID classification accuracy. Experiments on real-world datasets showcase the effectiveness of our approach.
<div id='section'>Paperid: <span id='pid'>619, <a href='https://arxiv.org/pdf/2509.17445.pdf' target='_blank'>https://arxiv.org/pdf/2509.17445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaodong Tong, Qi Zhang, Lei Jiang, Yanbing Liu, Nannan Sun, Wei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17445">Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable question answering with large language models (LLMs) is challenged by hallucinations, fluent but factually incorrect outputs arising from epistemic uncertainty. Existing entropy-based semantic-level uncertainty estimation methods are limited by sampling noise and unstable clustering of variable-length answers. We propose Semantic Reformulation Entropy (SRE), which improves uncertainty estimation in two ways. First, input-side semantic reformulations produce faithful paraphrases, expand the estimation space, and reduce biases from superficial decoder tendencies. Second, progressive, energy-based hybrid clustering stabilizes semantic grouping. Experiments on SQuAD and TriviaQA show that SRE outperforms strong baselines, providing more robust and generalizable hallucination detection. These results demonstrate that combining input diversification with multi-signal clustering substantially enhances semantic-level uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>620, <a href='https://arxiv.org/pdf/2509.17034.pdf' target='_blank'>https://arxiv.org/pdf/2509.17034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuai Feng, Yuxin Ge, Yuntao Du, Mingcai Chen, Chongjun Wang, Lei Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17034">Long-Tailed Out-of-Distribution Detection with Refined Separate Class Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for deploying robust machine learning models. However, when training data follows a long-tailed distribution, the model's ability to accurately detect OOD samples is significantly compromised, due to the confusion between OOD samples and head/tail classes. To distinguish OOD samples from both head and tail classes, the separate class learning (SCL) approach has emerged as a promising solution, which separately conduct head-specific and tail-specific class learning. To this end, we examine the limitations of existing works of SCL and reveal that the OOD detection performance is notably influenced by the use of static scaling temperature value and the presence of uninformative outliers. To mitigate these limitations, we propose a novel approach termed Refined Separate Class Learning (RSCL), which leverages dynamic class-wise temperature adjustment to modulate the temperature parameter for each in-distribution class and informative outlier mining to identify diverse types of outliers based on their affinity with head and tail classes. Extensive experiments demonstrate that RSCL achieves superior OOD detection performance while improving the classification accuracy on in-distribution data.
<div id='section'>Paperid: <span id='pid'>621, <a href='https://arxiv.org/pdf/2509.14622.pdf' target='_blank'>https://arxiv.org/pdf/2509.14622.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihao Guo, Haocheng Bian, Liutong Zhou, Ze Wang, Zhaoyi Zhang, Francois Kawala, Milan Dean, Ian Fischer, Yuantao Peng, Noyan Tokgozoglu, Ivan Barrientos, Riyaaz Shaik, Rachel Li, Chandru Venkataraman, Reza Shifteh Far, Moses Pawar, Venkat Sundaranatha, Michael Xu, Frank Chu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14622">Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the deployment of Large Language Models (LLMs) in interactive applications, online malicious intent detection has become increasingly critical. However, existing approaches fall short of handling diverse and complex user queries in real time. To address these challenges, we introduce ADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework for robust and efficient online malicious intent detection. In the training stage, a high-capacity teacher model is trained on adversarially perturbed, retrieval-augmented inputs to learn robust decision boundaries over diverse and complex user queries. In the inference stage, a distillation scheduler transfers the teacher's knowledge into a compact student model, with a continually updated knowledge base collected online. At deployment, the compact student model leverages top-K similar safety exemplars retrieved from the online-updated knowledge base to enable both online and real-time malicious query detection. Evaluations across ten safety benchmarks demonstrate that ADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's performance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on out-of-distribution detection, while simultaneously delivering up to 5.6x lower latency at 300 queries per second (QPS) in real-time applications.
<div id='section'>Paperid: <span id='pid'>622, <a href='https://arxiv.org/pdf/2509.08846.pdf' target='_blank'>https://arxiv.org/pdf/2509.08846.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>H. Martin Gillis, Isaac Xu, Thomas Trappenberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08846">Uncertainty Estimation using Variance-Gated Distributions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evaluation of per-sample uncertainty quantification from neural networks is essential for decision-making involving high-risk applications. A common approach is to use the predictive distribution from Bayesian or approximation models and decompose the corresponding predictive uncertainty into epistemic (model-related) and aleatoric (data-related) components. However, additive decomposition has recently been questioned. In this work, we propose an intuitive framework for uncertainty estimation and decomposition based on the signal-to-noise ratio of class probability distributions across different model predictions. We introduce a variance-gated measure that scales predictions by a confidence factor derived from ensembles. We use this measure to discuss the existence of a collapse in the diversity of committee machines.
<div id='section'>Paperid: <span id='pid'>623, <a href='https://arxiv.org/pdf/2508.13099.pdf' target='_blank'>https://arxiv.org/pdf/2508.13099.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingyu Kim, Daniel Stilwell, Jorge Jimenez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13099">Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a framework for classifying and detecting spatial commission outliers in maritime environments using seabed acoustic sensor networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as a mixture of normal and outlier processes, we estimate the probability that a newly observed event is an outlier. We propose a second-order approximation of this probability that incorporates both the mean and variance of the normal intensity function, providing improved classification accuracy compared to mean-only approaches. We analytically show that our method yields a tighter bound to the true probability using Jensen's inequality. To enhance detection, we integrate a real-time, near-optimal sensor placement strategy that dynamically adjusts sensor locations based on the evolving outlier intensity. The proposed framework is validated using real ship traffic data near Norfolk, Virginia, where numerical results demonstrate the effectiveness of our approach in improving both classification performance and outlier detection through sensor deployment.
<div id='section'>Paperid: <span id='pid'>624, <a href='https://arxiv.org/pdf/2508.03108.pdf' target='_blank'>https://arxiv.org/pdf/2508.03108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tarhib Al Azad, Faizul Rakib Sayem, Shahana Ibrahim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03108">Pseudo-label Induced Subspace Representation Learning for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection lies at the heart of robust artificial intelligence (AI), aiming to identify samples from novel distributions beyond the training set. Recent approaches have exploited feature representations as distinguishing signatures for OOD detection. However, most existing methods rely on restrictive assumptions on the feature space that limit the separability between in-distribution (ID) and OOD samples. In this work, we propose a novel OOD detection framework based on a pseudo-label-induced subspace representation, that works under more relaxed and natural assumptions compared to existing feature-based techniques. In addition, we introduce a simple yet effective learning criterion that integrates a cross-entropy-based ID classification loss with a subspace distance-based regularization loss to enhance ID-OOD separability. Extensive experiments validate the effectiveness of our framework.
<div id='section'>Paperid: <span id='pid'>625, <a href='https://arxiv.org/pdf/2506.17564.pdf' target='_blank'>https://arxiv.org/pdf/2506.17564.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lakshita Dodeja, Karl Schmeckpeper, Shivam Vats, Thomas Weng, Mingxi Jia, George Konidaris, Stefanie Tellex
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17564">Accelerating Residual Reinforcement Learning with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Residual Reinforcement Learning (RL) is a popular approach for adapting pretrained policies by learning a lightweight residual policy that provides corrective actions. While Residual RL is more sample-efficient than finetuning the entire base policy, existing methods struggle with sparse rewards and are designed for deterministic base policies. We propose two improvements to Residual RL that further enhance its sample efficiency and make it suitable for stochastic base policies. First, we leverage uncertainty estimates of the base policy to focus exploration on regions in which the base policy is not confident. Second, we propose a simple modification to off-policy residual learning that allows it to observe base actions and better handle stochastic base policies. We evaluate our method with both Gaussian-based and Diffusion-based stochastic base policies on tasks from Robosuite and D4RL, and compare against state-of-the-art finetuning methods, demo-augmented RL methods, and other residual RL methods. Our algorithm significantly outperforms existing baselines in a variety of simulation benchmark environments. We also deploy our learned polices in the real world to demonstrate their robustness with zero-shot sim-to-real transfer.
<div id='section'>Paperid: <span id='pid'>626, <a href='https://arxiv.org/pdf/2505.13273.pdf' target='_blank'>https://arxiv.org/pdf/2505.13273.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Berry, Axel Brando, Wei-Di Chang, Juan Camilo Gamboa Higuera, David Meger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13273">Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating uncertainty in text-to-image diffusion models is challenging because of their large parameter counts (often exceeding 100 million) and operation in complex, high-dimensional spaces with virtually infinite input possibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a novel framework for efficiently estimating epistemic uncertainty in diffusion models. EMoE leverages pre-trained networks without requiring additional training, enabling direct uncertainty estimation from a prompt. We leverage a latent space within the diffusion process that captures epistemic uncertainty better than existing methods. Experimental results on the COCO dataset demonstrate EMoE's effectiveness, showing a strong correlation between uncertainty and image quality. Additionally, EMoE identifies under-sampled languages and regions with higher uncertainty, revealing hidden biases in the training set. This capability demonstrates the relevance of EMoE as a tool for addressing fairness and accountability in AI-generated content.
<div id='section'>Paperid: <span id='pid'>627, <a href='https://arxiv.org/pdf/2505.04986.pdf' target='_blank'>https://arxiv.org/pdf/2505.04986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qian Peng, Yajie Bao, Haojie Ren, Zhaojun Wang, Changliang Zou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04986">Conformal Prediction with Cellwise Outliers: A Detect-then-Impute Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformal prediction is a powerful tool for constructing prediction intervals for black-box models, providing a finite sample coverage guarantee for exchangeable data. However, this exchangeability is compromised when some entries of the test feature are contaminated, such as in the case of cellwise outliers. To address this issue, this paper introduces a novel framework called detect-then-impute conformal prediction. This framework first employs an outlier detection procedure on the test feature and then utilizes an imputation method to fill in those cells identified as outliers. To quantify the uncertainty in the processed test feature, we adaptively apply the detection and imputation procedures to the calibration set, thereby constructing exchangeable features for the conformal prediction interval of the test label. We develop two practical algorithms, PDI-CP and JDI-CP, and provide a distribution-free coverage analysis under some commonly used detection and imputation procedures. Notably, JDI-CP achieves a finite sample $1-2Î±$ coverage guarantee. Numerical experiments on both synthetic and real datasets demonstrate that our proposed algorithms exhibit robust coverage properties and comparable efficiency to the oracle baseline.
<div id='section'>Paperid: <span id='pid'>628, <a href='https://arxiv.org/pdf/2505.02448.pdf' target='_blank'>https://arxiv.org/pdf/2505.02448.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaohua Li, Enhao Zhang, Chuanxing Geng, Songcan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02448">Recent Advances in Out-of-Distribution Detection with CLIP-Like Models: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution detection (OOD) is a pivotal task for real-world applications that trains models to identify samples that are distributionally different from the in-distribution (ID) data during testing. Recent advances in AI, particularly Vision-Language Models (VLMs) like CLIP, have revolutionized OOD detection by shifting from traditional unimodal image detectors to multimodal image-text detectors. This shift has inspired extensive research; however, existing categorization schemes (e.g., few- or zero-shot types) still rely solely on the availability of ID images, adhering to a unimodal paradigm. To better align with CLIP's cross-modal nature, we propose a new categorization framework rooted in both image and text modalities. Specifically, we categorize existing methods based on how visual and textual information of OOD data is utilized within image + text modalities, and further divide them into four groups: OOD Images (i.e., outliers) Seen or Unseen, and OOD Texts (i.e., learnable vectors or class names) Known or Unknown, across two training strategies (i.e., train-free or training-required). More importantly, we discuss open problems in CLIP-like OOD detection and highlight promising directions for future research, including cross-domain integration, practical applications, and theoretical understanding.
<div id='section'>Paperid: <span id='pid'>629, <a href='https://arxiv.org/pdf/2504.15663.pdf' target='_blank'>https://arxiv.org/pdf/2504.15663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ju Yeon Kang, Ji Won Yoon, Semin Kim, Min Hyun Han, Nam Soo Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15663">FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, fake audio detection has gained significant attention, as advancements in speech synthesis and voice conversion have increased the vulnerability of automatic speaker verification (ASV) systems to spoofing attacks. A key challenge in this task is generalizing models to detect unseen, out-of-distribution (OOD) attacks. Although existing approaches have shown promising results, they inherently suffer from overconfidence issues due to the usage of softmax for classification, which can produce unreliable predictions when encountering unpredictable spoofing attempts. To deal with this limitation, we propose a novel framework called fake audio detection with evidential learning (FADEL). By modeling class probabilities with a Dirichlet distribution, FADEL incorporates model uncertainty into its predictions, thereby leading to more robust performance in OOD scenarios. Experimental results on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets indicate that the proposed method significantly improves the performance of baseline models. Furthermore, we demonstrate the validity of uncertainty estimation by analyzing a strong correlation between average uncertainty and equal error rate (EER) across different spoofing algorithms.
<div id='section'>Paperid: <span id='pid'>630, <a href='https://arxiv.org/pdf/2504.02214.pdf' target='_blank'>https://arxiv.org/pdf/2504.02214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunho Lee, Wenwen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02214">Geospatial Artificial Intelligence for Satellite-Based Flood Extent Mapping: Concepts, Advances, and Future Perspectives</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geospatial Artificial Intelligence (GeoAI) for satellite-based flood extent mapping systematically integrates artificial intelligence techniques with satellite data to identify flood events and assess their impacts, for disaster management and spatial decision-making. The primary output often includes flood extent maps, which delineate the affected areas, along with additional analytical outputs such as uncertainty estimation and change detection.
<div id='section'>Paperid: <span id='pid'>631, <a href='https://arxiv.org/pdf/2503.14665.pdf' target='_blank'>https://arxiv.org/pdf/2503.14665.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Parker Ewen, Hao Chen, Seth Isaacson, Joey Wilson, Katherine A. Skinner, Ram Vasudevan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14665">These Magic Moments: Differentiable Uncertainty Quantification of Radiance Field Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel approach to uncertainty quantification for radiance fields by leveraging higher-order moments of the rendering equation. Uncertainty quantification is crucial for downstream tasks including view planning and scene understanding, where safety and robustness are paramount. However, the high dimensionality and complexity of radiance fields pose significant challenges for uncertainty quantification, limiting the use of these uncertainty quantification methods in high-speed decision-making. We demonstrate that the probabilistic nature of the rendering process enables efficient and differentiable computation of higher-order moments for radiance field outputs, including color, depth, and semantic predictions. Our method outperforms existing radiance field uncertainty estimation techniques while offering a more direct, computationally efficient, and differentiable formulation without the need for post-processing. Beyond uncertainty quantification, we also illustrate the utility of our approach in downstream applications such as next-best-view (NBV) selection and active ray sampling for neural radiance field training. Extensive experiments on synthetic and real-world scenes confirm the efficacy of our approach, which achieves state-of-the-art performance while maintaining simplicity.
<div id='section'>Paperid: <span id='pid'>632, <a href='https://arxiv.org/pdf/2503.09626.pdf' target='_blank'>https://arxiv.org/pdf/2503.09626.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Wu, Yingguang Yang, hao liu, Hao Peng, Buyun He, Yutong Xia, Yong Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.09626">Certainly Bot Or Not? Trustworthy Social Bot Detection via Robust Multi-Modal Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Social bot detection is crucial for mitigating misinformation, online manipulation, and coordinated inauthentic behavior. While existing neural network-based detectors perform well on benchmarks, they struggle with generalization due to distribution shifts across datasets and frequently produce overconfident predictions for out-of-distribution accounts beyond the training data. To address this, we introduce a novel Uncertainty Estimation for Social Bot Detection (UESBD) framework, which quantifies the predictive uncertainty of detectors beyond mere classification. For this task, we propose Robust Multi-modal Neural Processes (RMNP), which aims to enhance the robustness of multi-modal neural processes to modality inconsistencies caused by social bot camouflage. RMNP first learns unimodal representations through modality-specific encoders. Then, unimodal attentive neural processes are employed to encode the Gaussian distribution of unimodal latent variables. Furthermore, to avoid social bots stealing human features to camouflage themselves thus causing certain modalities to provide conflictive information, we introduce an evidential gating network to explicitly model the reliability of modalities. The joint latent distribution is learned through the generalized product of experts, which takes the reliability of each modality into consideration during fusion. The final prediction is obtained through Monte Carlo sampling of the joint latent distribution followed by a decoder. Experiments on three real-world benchmarks show the effectiveness of RMNP in classification and uncertainty estimation, as well as its robustness to modality conflicts.
<div id='section'>Paperid: <span id='pid'>633, <a href='https://arxiv.org/pdf/2503.07435.pdf' target='_blank'>https://arxiv.org/pdf/2503.07435.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Riccardo Mazzieri, Jacopo Pegoraro, Michele Rossi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07435">Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The adoption of Millimeter-Wave (mmWave) radar devices for human sensing, particularly gait recognition, has recently gathered significant attention due to their efficiency, resilience to environmental conditions, and privacy-preserving nature. In this work, we tackle the challenging problem of Open-set Gait Recognition (OSGR) from sparse mmWave radar point clouds. Unlike most existing research, which assumes a closed-set scenario, our work considers the more realistic open-set case, where unknown subjects might be present at inference time, and should be correctly recognized by the system. Point clouds are well-suited for edge computing applications with resource constraints, but are more significantly affected by noise and random fluctuations than other representations, like the more common micro-Doppler signature. This is the first work addressing open-set gait recognition with sparse point cloud data. To do so, we propose a novel neural network architecture that combines supervised classification with unsupervised reconstruction of the point clouds, creating a robust, rich, and highly regularized latent space of gait features. To detect unknown subjects at inference time, we introduce a probabilistic novelty detection algorithm that leverages the structured latent space and offers a tunable trade-off between inference speed and prediction accuracy. Along with this paper, we release mmGait10, an original human gait dataset featuring over five hours of measurements from ten subjects, under varied walking modalities. Extensive experimental results show that our solution attains F1-Score improvements by 24% over state-of-the-art methods adapted for point clouds, on average, and across multiple openness levels.
<div id='section'>Paperid: <span id='pid'>634, <a href='https://arxiv.org/pdf/2503.05088.pdf' target='_blank'>https://arxiv.org/pdf/2503.05088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changhong Lin, Jiarong Lin, Zhiqiang Sui, XiaoZhi Qu, Rui Wang, Kehua Sheng, Bo Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05088">An End-to-End Learning-Based Multi-Sensor Fusion for Autonomous Vehicle Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-sensor fusion is essential for autonomous vehicle localization, as it is capable of integrating data from various sources for enhanced accuracy and reliability. The accuracy of the integrated location and orientation depends on the precision of the uncertainty modeling. Traditional methods of uncertainty modeling typically assume a Gaussian distribution and involve manual heuristic parameter tuning. However, these methods struggle to scale effectively and address long-tail scenarios. To address these challenges, we propose a learning-based method that encodes sensor information using higher-order neural network features, thereby eliminating the need for uncertainty estimation. This method significantly eliminates the need for parameter fine-tuning by developing an end-to-end neural network that is specifically designed for multi-sensor fusion. In our experiments, we demonstrate the effectiveness of our approach in real-world autonomous driving scenarios. Results show that the proposed method outperforms existing multi-sensor fusion methods in terms of both accuracy and robustness. A video of the results can be viewed at https://youtu.be/q4iuobMbjME.
<div id='section'>Paperid: <span id='pid'>635, <a href='https://arxiv.org/pdf/2503.00136.pdf' target='_blank'>https://arxiv.org/pdf/2503.00136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacopo Teneggi, J Webster Stayman, Jeremias Sulam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00136">Conformal Risk Control for Semantic Uncertainty Quantification in Computed Tomography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is necessary for developers, physicians, and regulatory agencies to build trust in machine learning predictors and improve patient care. Beyond measuring uncertainty, it is crucial to express it in clinically meaningful terms that provide actionable insights. This work introduces a conformal risk control (CRC) procedure for organ-dependent uncertainty estimation, ensuring high-probability coverage of the ground-truth image. We first present a high-dimensional CRC procedure that leverages recent ideas of length minimization. We make this procedure semantically adaptive to each patient's anatomy and positioning of organs. Our method, sem-CRC, provides tighter uncertainty intervals with valid coverage on real-world computed tomography (CT) data while communicating uncertainty with clinically relevant features.
<div id='section'>Paperid: <span id='pid'>636, <a href='https://arxiv.org/pdf/2502.19700.pdf' target='_blank'>https://arxiv.org/pdf/2502.19700.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yimin Zhu, Lincoln Linlin Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19700">Language-Informed Hyperspectral Image Synthesis for Imbalanced-Small Sample Classification via Semi-Supervised Conditional Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data augmentation effectively addresses the imbalanced-small sample data (ISSD) problem in hyperspectral image classification (HSIC). While most methodologies extend features in the latent space, few leverage text-driven generation to create realistic and diverse samples. Recently, text-guided diffusion models have gained significant attention due to their ability to generate highly diverse and high-quality images based on text prompts in natural image synthesis. Motivated by this, this paper proposes Txt2HSI-LDM(VAE), a novel language-informed hyperspectral image synthesis method to address the ISSD in HSIC. The proposed approach uses a denoising diffusion model, which iteratively removes Gaussian noise to generate hyperspectral samples conditioned on textual descriptions. First, to address the high-dimensionality of hyperspectral data, a universal variational autoencoder (VAE) is designed to map the data into a low-dimensional latent space, which provides stable features and reduces the inference complexity of diffusion model. Second, a semi-supervised diffusion model is designed to fully take advantage of unlabeled data. Random polygon spatial clipping (RPSC) and uncertainty estimation of latent feature (LF-UE) are used to simulate the varying degrees of mixing. Third, the VAE decodes HSI from latent space generated by the diffusion model with the language conditions as input. In our experiments, we fully evaluate synthetic samples' effectiveness from statistical characteristics and data distribution in 2D-PCA space. Additionally, visual-linguistic cross-attention is visualized on the pixel level to prove that our proposed model can capture the spatial layout and geometry of the generated data. Experiments demonstrate that the performance of the proposed Txt2HSI-LDM(VAE) surpasses the classical backbone models, state-of-the-art CNNs, and semi-supervised methods.
<div id='section'>Paperid: <span id='pid'>637, <a href='https://arxiv.org/pdf/2502.00290.pdf' target='_blank'>https://arxiv.org/pdf/2502.00290.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huan Ma, Jingdong Chen, Joey Tianyi Zhou, Guangyu Wang, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00290">Estimating LLM Uncertainty with Evidence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the past few years, Large Language Models (LLMs) have developed rapidly and are widely applied in various domains. However, LLMs face the issue of hallucinations, generating responses that may be unreliable when the models lack relevant knowledge. To be aware of potential hallucinations, uncertainty estimation methods have been introduced, and most of them have confirmed that reliability lies in critical tokens. However, probability-based methods perform poorly in identifying token reliability, limiting their practical utility. In this paper, we reveal that the probability-based method fails to estimate token reliability due to the loss of evidence strength information which is accumulated in the training stage. Therefore, we present Logits-induced token uncertainty (LogTokU), a framework for estimating decoupled token uncertainty in LLMs, enabling real-time uncertainty estimation without requiring multiple sampling processes. We employ evidence modeling to implement LogTokU and use the estimated uncertainty to guide downstream tasks. The experimental results demonstrate that LogTokU has significant effectiveness and promise.
<div id='section'>Paperid: <span id='pid'>638, <a href='https://arxiv.org/pdf/2501.10209.pdf' target='_blank'>https://arxiv.org/pdf/2501.10209.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Annita Vapsi, AndrÃ©s MuÃ±oz, Nancy Thomas, Keshav Ramani, Daniel Borrajo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.10209">Hypercone Assisted Contour Generation for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in the field of out-of-distribution (OOD) detection have placed great emphasis on learning better representations suited to this task. While there are distance-based approaches, distributional awareness has seldom been exploited for better performance. We present HAC$_k$-OOD, a novel OOD detection method that makes no distributional assumption about the data, but automatically adapts to its distribution. Specifically, HAC$_k$-OOD constructs a set of hypercones by maximizing the angular distance to neighbors in a given data-point's vicinity to approximate the contour within which in-distribution (ID) data-points lie. Experimental results show state-of-the-art FPR@95 and AUROC performance on Near-OOD detection and on Far-OOD detection on the challenging CIFAR-100 benchmark without explicitly training for OOD performance.
<div id='section'>Paperid: <span id='pid'>639, <a href='https://arxiv.org/pdf/2501.08285.pdf' target='_blank'>https://arxiv.org/pdf/2501.08285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matias Valdenegro-Toro, Marco Zullich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08285">Can Bayesian Neural Networks Explicitly Model Input Uncertainty?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inputs to machine learning models can have associated noise or uncertainties, but they are often ignored and not modelled. It is unknown if Bayesian Neural Networks and their approximations are able to consider uncertainty in their inputs. In this paper we build a two input Bayesian Neural Network (mean and standard deviation) and evaluate its capabilities for input uncertainty estimation across different methods like Ensembles, MC-Dropout, and Flipout. Our results indicate that only some uncertainty estimation methods for approximate Bayesian NNs can model input uncertainty, in particular Ensembles and Flipout.
<div id='section'>Paperid: <span id='pid'>640, <a href='https://arxiv.org/pdf/2412.15758.pdf' target='_blank'>https://arxiv.org/pdf/2412.15758.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sophie Steger, Christian Knoll, Bernhard Klein, Holger FrÃ¶ning, Franz Pernkopf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15758">Function Space Diversity for Uncertainty Prediction via Repulsive Last-Layer Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian inference in function space has gained attention due to its robustness against overparameterization in neural networks. However, approximating the infinite-dimensional function space introduces several challenges. In this work, we discuss function space inference via particle optimization and present practical modifications that improve uncertainty estimation and, most importantly, make it applicable for large and pretrained networks. First, we demonstrate that the input samples, where particle predictions are enforced to be diverse, are detrimental to the model performance. While diversity on training data itself can lead to underfitting, the use of label-destroying data augmentation, or unlabeled out-of-distribution data can improve prediction diversity and uncertainty estimates. Furthermore, we take advantage of the function space formulation, which imposes no restrictions on network parameterization other than sufficient flexibility. Instead of using full deep ensembles to represent particles, we propose a single multi-headed network that introduces a minimal increase in parameters and computation. This allows seamless integration to pretrained networks, where this repulsive last-layer ensemble can be used for uncertainty aware fine-tuning at minimal additional cost. We achieve competitive results in disentangling aleatoric and epistemic uncertainty for active learning, detecting out-of-domain data, and providing calibrated uncertainty estimates under distribution shifts with minimal compute and memory.
<div id='section'>Paperid: <span id='pid'>641, <a href='https://arxiv.org/pdf/2412.15439.pdf' target='_blank'>https://arxiv.org/pdf/2412.15439.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maniraj Sai Adapa, Marco Zullich, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15439">Uncertainty Estimation for Super-Resolution using ESRGAN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Learning-based image super-resolution (SR) has been gaining traction with the aid of Generative Adversarial Networks. Models like SRGAN and ESRGAN are constantly ranked between the best image SR tools. However, they lack principled ways for estimating predictive uncertainty. In the present work, we enhance these models using Monte Carlo-Dropout and Deep Ensemble, allowing the computation of predictive uncertainty. When coupled with a prediction, uncertainty estimates can provide more information to the model users, highlighting pixels where the SR output might be uncertain, hence potentially inaccurate, if these estimates were to be reliable. Our findings suggest that these uncertainty estimates are decently calibrated and can hence fulfill this goal, while providing no performance drop with respect to the corresponding models without uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>642, <a href='https://arxiv.org/pdf/2412.13738.pdf' target='_blank'>https://arxiv.org/pdf/2412.13738.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Navid Ansari, Hans-Peter Seidel, Vahid Babaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13738">Uncertainty separation via ensemble quantile regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel and scalable framework for uncertainty estimation and separation with applications in data driven modeling in science and engineering tasks where reliable uncertainty quantification is critical. Leveraging an ensemble of quantile regression (E-QR) models, our approach enhances aleatoric uncertainty estimation while preserving the quality of epistemic uncertainty, surpassing competing methods, such as Deep Ensembles (DE) and Monte Carlo (MC) dropout. To address challenges in separating uncertainty types, we propose an algorithm that iteratively improves separation through progressive sampling in regions of high uncertainty. Our framework is scalable to large datasets and demonstrates superior performance on synthetic benchmarks, offering a robust tool for uncertainty quantification in data-driven applications.
<div id='section'>Paperid: <span id='pid'>643, <a href='https://arxiv.org/pdf/2411.11919.pdf' target='_blank'>https://arxiv.org/pdf/2411.11919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiyang Zhang, Hu Zhang, Zhedong Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11919">VL-Uncertainty: Detecting Hallucination in Large Vision-Language Model via Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the higher information load processed by large vision-language models (LVLMs) compared to single-modal LLMs, detecting LVLM hallucinations requires more human and time expense, and thus rise a wider safety concerns. In this paper, we introduce VL-Uncertainty, the first uncertainty-based framework for detecting hallucinations in LVLMs. Different from most existing methods that require ground-truth or pseudo annotations, VL-Uncertainty utilizes uncertainty as an intrinsic metric. We measure uncertainty by analyzing the prediction variance across semantically equivalent but perturbed prompts, including visual and textual data. When LVLMs are highly confident, they provide consistent responses to semantically equivalent queries. However, when uncertain, the responses of the target LVLM become more random. Considering semantically similar answers with different wordings, we cluster LVLM responses based on their semantic content and then calculate the cluster distribution entropy as the uncertainty measure to detect hallucination. Our extensive experiments on 10 LVLMs across four benchmarks, covering both free-form and multi-choice tasks, show that VL-Uncertainty significantly outperforms strong baseline methods in hallucination detection.
<div id='section'>Paperid: <span id='pid'>644, <a href='https://arxiv.org/pdf/2411.08488.pdf' target='_blank'>https://arxiv.org/pdf/2411.08488.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Wan, Lin Liu, Haoran Wang, Liangwei Li, Wei Li, Shuheng Kou, Runtian Li, Jiayi Tang, Juanxiu Liu, Jing Zhang, Xiaohui Du, Ruqian Hao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08488">UNSCT-HRNet: Modeling Anatomical Uncertainty for Landmark Detection in Total Hip Arthroplasty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Total hip arthroplasty (THA) relies on accurate landmark detection from radiographic images, but unstructured data caused by irregular patient postures or occluded anatomical markers pose significant challenges for existing methods. To address this, we propose UNSCT-HRNet (Unstructured CT - High-Resolution Net), a deep learning-based framework that integrates a Spatial Relationship Fusion (SRF) module and an Uncertainty Estimation (UE) module. The SRF module, utilizing coordinate convolution and polarized attention, enhances the model's ability to capture complex spatial relationships. Meanwhile, the UE module which based on entropy ensures predictions are anatomically relevant. For unstructured data, the proposed method can predict landmarks without relying on the fixed number of points, which shows higher accuracy and better robustness comparing with the existing methods. Our UNSCT-HRNet demonstrates over a 60% improvement across multiple metrics in unstructured data. The experimental results also reveal that our approach maintains good performance on the structured dataset. Overall, the proposed UNSCT-HRNet has the potential to be used as a new reliable, automated solution for THA surgical planning and postoperative monitoring.
<div id='section'>Paperid: <span id='pid'>645, <a href='https://arxiv.org/pdf/2410.20783.pdf' target='_blank'>https://arxiv.org/pdf/2410.20783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20783">Graph-based Uncertainty Metrics for Long-form Language Model Outputs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in Large Language Models (LLMs) have significantly improved text generation capabilities, but these systems are still known to hallucinate, and granular uncertainty estimation for long-form LLM generations remains challenging. In this work, we propose Graph Uncertainty -- which represents the relationship between LLM generations and claims within them as a bipartite graph and estimates the claim-level uncertainty with a family of graph centrality metrics. Under this view, existing uncertainty estimation methods based on the concept of self-consistency can be viewed as using degree centrality as an uncertainty measure, and we show that more sophisticated alternatives such as closeness centrality provide consistent gains at claim-level uncertainty estimation. Moreover, we present uncertainty-aware decoding techniques that leverage both the graph structure and uncertainty estimates to improve the factuality of LLM generations by preserving only the most reliable claims. Compared to existing methods, our graph-based uncertainty metrics lead to an average of 6.8% relative gains on AUPRC across various long-form generation settings, and our end-to-end system provides consistent 2-4% gains in factuality over existing decoding techniques while significantly improving the informativeness of generated responses.
<div id='section'>Paperid: <span id='pid'>646, <a href='https://arxiv.org/pdf/2410.06422.pdf' target='_blank'>https://arxiv.org/pdf/2410.06422.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael J. Kenney, Katerina G. Malollari, Sergei V. Kalinin, Maxim Ziatdinov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06422">Predicting Battery Capacity Fade Using Probabilistic Machine Learning Models With and Without Pre-Trained Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lithium-ion batteries are a key energy storage technology driving revolutions in mobile electronics, electric vehicles and renewable energy storage. Capacity retention is a vital performance measure that is frequently utilized to assess whether these batteries have approached their end-of-life. Machine learning (ML) offers a powerful tool for predicting capacity degradation based on past data, and, potentially, prior physical knowledge, but the degree to which an ML prediction can be trusted is of significant practical importance in situations where consequential decisions must be made based on battery state of health. This study explores the efficacy of fully Bayesian machine learning in forecasting battery health with the quantification of uncertainty in its predictions. Specifically, we implemented three probabilistic ML approaches and evaluated the accuracy of their predictions and uncertainty estimates: a standard Gaussian process (GP), a structured Gaussian process (sGP), and a fully Bayesian neural network (BNN). In typical applications of GP and sGP, their hyperparameters are learned from a single sample while, in contrast, BNNs are typically pre-trained on an existing dataset to learn the weight distributions before being used for inference. This difference in methodology gives the BNN an advantage in learning global trends in a dataset and makes BNNs a good choice when training data is available. However, we show that pre-training can also be leveraged for GP and sGP approaches to learn the prior distributions of the hyperparameters and that in the case of the pre-trained sGP, similar accuracy and improved uncertainty estimation compared to the BNN can be achieved. This approach offers a framework for a broad range of probabilistic machine learning scenarios where past data is available and can be used to learn priors for (hyper)parameters of probabilistic ML models.
<div id='section'>Paperid: <span id='pid'>647, <a href='https://arxiv.org/pdf/2409.07942.pdf' target='_blank'>https://arxiv.org/pdf/2409.07942.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guangxuan Song, Dongmei Fu, Zhongwei Qiu, Jintao Meng, Dawei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07942">Taylor-Sensus Network: Embracing Noise to Enlighten Uncertainty for Scientific Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial in scientific data for machine learning. Current uncertainty estimation methods mainly focus on the model's inherent uncertainty, while neglecting the explicit modeling of noise in the data. Furthermore, noise estimation methods typically rely on temporal or spatial dependencies, which can pose a significant challenge in structured scientific data where such dependencies among samples are often absent. To address these challenges in scientific research, we propose the Taylor-Sensus Network (TSNet). TSNet innovatively uses a Taylor series expansion to model complex, heteroscedastic noise and proposes a deep Taylor block for aware noise distribution. TSNet includes a noise-aware contrastive learning module and a data density perception module for aleatoric and epistemic uncertainty. Additionally, an uncertainty combination operator is used to integrate these uncertainties, and the network is trained using a novel heteroscedastic mean square error loss. TSNet demonstrates superior performance over mainstream and state-of-the-art methods in experiments, highlighting its potential in scientific research and noise resistance. It will be open-source to facilitate the community of "AI for Science".
<div id='section'>Paperid: <span id='pid'>648, <a href='https://arxiv.org/pdf/2408.00619.pdf' target='_blank'>https://arxiv.org/pdf/2408.00619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiyang Zhang, Hu Zhang, Hang Yu, Zhedong Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00619">Harnessing Uncertainty-aware Bounding Boxes for Unsupervised 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised 3D object detection aims to identify objects of interest from unlabeled raw data, such as LiDAR points. Recent approaches usually adopt pseudo 3D bounding boxes (3D bboxes) from clustering algorithm to initialize the model training. However, pseudo bboxes inevitably contain noise, and such inaccuracies accumulate to the final model, compromising the performance. Therefore, in an attempt to mitigate the negative impact of inaccurate pseudo bboxes, we introduce a new uncertainty-aware framework for unsupervised 3D object detection, dubbed UA3D. In particular, our method consists of two phases: uncertainty estimation and uncertainty regularization. (1) In the uncertainty estimation phase, we incorporate an extra auxiliary detection branch alongside the original primary detector. The prediction disparity between the primary and auxiliary detectors could reflect fine-grained uncertainty at the box coordinate level. (2) Based on the assessed uncertainty, we adaptively adjust the weight of every 3D bbox coordinate via uncertainty regularization, refining the training process on pseudo bboxes. For pseudo bbox coordinate with high uncertainty, we assign a relatively low loss weight. Extensive experiments verify that the proposed method is robust against the noisy pseudo bboxes, yielding substantial improvements on nuScenes and Lyft compared to existing approaches, with increases of +6.9% AP$_{BEV}$ and +2.5% AP$_{3D}$ on nuScenes, and +4.1% AP$_{BEV}$ and +2.0% AP$_{3D}$ on Lyft.
<div id='section'>Paperid: <span id='pid'>649, <a href='https://arxiv.org/pdf/2406.18580.pdf' target='_blank'>https://arxiv.org/pdf/2406.18580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Berry, Axel Brando, David Meger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18580">Shedding Light on Large Generative Networks: Estimating Epistemic Uncertainty in Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative diffusion models, notable for their large parameter count (exceeding 100 million) and operation within high-dimensional image spaces, pose significant challenges for traditional uncertainty estimation methods due to computational demands. In this work, we introduce an innovative framework, Diffusion Ensembles for Capturing Uncertainty (DECU), designed for estimating epistemic uncertainty for diffusion models. The DECU framework introduces a novel method that efficiently trains ensembles of conditional diffusion models by incorporating a static set of pre-trained parameters, drastically reducing the computational burden and the number of parameters that require training. Additionally, DECU employs Pairwise-Distance Estimators (PaiDEs) to accurately measure epistemic uncertainty by evaluating the mutual information between model outputs and weights in high-dimensional spaces. The effectiveness of this framework is demonstrated through experiments on the ImageNet dataset, highlighting its capability to capture epistemic uncertainty, specifically in under-sampled image classes.
<div id='section'>Paperid: <span id='pid'>650, <a href='https://arxiv.org/pdf/2406.12815.pdf' target='_blank'>https://arxiv.org/pdf/2406.12815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikolas Koutsoubis, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12815">Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable advancements, particularly in healthcare. Within medical imaging, ML models hold the promise of improving disease diagnoses, treatment planning, and post-treatment monitoring. Various computer vision tasks like image classification, object detection, and image segmentation are poised to become routine in clinical analysis. However, privacy concerns surrounding patient data hinder the assembly of large training datasets needed for developing and training accurate, robust, and generalizable models. Federated Learning (FL) emerges as a compelling solution, enabling organizations to collaborate on ML model training by sharing model training information (gradients) rather than data (e.g., medical images). FL's distributed learning framework facilitates inter-institutional collaboration while preserving patient privacy. However, FL, while robust in privacy preservation, faces several challenges. Sensitive information can still be gleaned from shared gradients that are passed on between organizations during model training. Additionally, in medical imaging, quantifying model confidence\uncertainty accurately is crucial due to the noise and artifacts present in the data. Uncertainty estimation in FL encounters unique hurdles due to data heterogeneity across organizations. This paper offers a comprehensive review of FL, privacy preservation, and uncertainty estimation, with a focus on medical imaging. Alongside a survey of current research, we identify gaps in the field and suggest future directions for FL research to enhance privacy and address noisy medical imaging data challenges.
<div id='section'>Paperid: <span id='pid'>651, <a href='https://arxiv.org/pdf/2406.02566.pdf' target='_blank'>https://arxiv.org/pdf/2406.02566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ognjen Kundacina, Vladimir Vincan, Dragisa Miskovic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02566">Combining X-Vectors and Bayesian Batch Active Learning: Two-Stage Active Learning Pipeline for Speech Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel two-stage active learning (AL) pipeline for automatic speech recognition (ASR), combining unsupervised and supervised AL methods. The first stage utilizes unsupervised AL by using x-vectors clustering for diverse sample selection from unlabeled speech data, thus establishing a robust initial dataset for the subsequent supervised AL. The second stage incorporates a supervised AL strategy, with a batch AL method specifically developed for ASR, aimed at selecting diverse and informative batches of samples. Here, sample diversity is also achieved using x-vectors clustering, while the most informative samples are identified using a Bayesian AL method tailored for ASR with an adaptation of Monte Carlo dropout to approximate Bayesian inference. This approach enables precise uncertainty estimation, thereby enhancing ASR model training with significantly reduced data requirements. Our method has shown superior performance compared to competing methods on homogeneous, heterogeneous, and OOD test sets, demonstrating that strategic sample selection and innovative Bayesian modeling can substantially optimize both labeling effort and data utilization in deep learning-based ASR applications.
<div id='section'>Paperid: <span id='pid'>652, <a href='https://arxiv.org/pdf/2406.00529.pdf' target='_blank'>https://arxiv.org/pdf/2406.00529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vivek Narayanaswamy, Kowshik Thopalli, Rushil Anirudh, Yamen Mubarka, Wesam Sakla, Jayaraman J. Thiagarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00529">On the Use of Anchoring for Training Vision Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anchoring is a recent, architecture-agnostic principle for training deep neural networks that has been shown to significantly improve uncertainty estimation, calibration, and extrapolation capabilities. In this paper, we systematically explore anchoring as a general protocol for training vision models, providing fundamental insights into its training and inference processes and their implications for generalization and safety. Despite its promise, we identify a critical problem in anchored training that can lead to an increased risk of learning undesirable shortcuts, thereby limiting its generalization capabilities. To address this, we introduce a new anchored training protocol that employs a simple regularizer to mitigate this issue and significantly enhances generalization. We empirically evaluate our proposed approach across datasets and architectures of varying scales and complexities, demonstrating substantial performance gains in generalization and safety metrics compared to the standard training protocol.
<div id='section'>Paperid: <span id='pid'>653, <a href='https://arxiv.org/pdf/2405.16146.pdf' target='_blank'>https://arxiv.org/pdf/2405.16146.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyi Chen, Yaohui Li, Haoxing Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16146">Dual-Adapter: Training-free Dual Adaptation for Few-shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the problem of few-shot out-of-distribution (OOD) detection, which aims to detect OOD samples from unseen categories during inference time with only a few labeled in-domain (ID) samples. Existing methods mainly focus on training task-aware prompts for OOD detection. However, training on few-shot data may cause severe overfitting and textual prompts alone may not be enough for effective detection. To tackle these problems, we propose a prior-based Training-free Dual Adaptation method (Dual-Adapter) to detect OOD samples from both textual and visual perspectives. Specifically, Dual-Adapter first extracts the most significant channels as positive features and designates the remaining less relevant channels as negative features. Then, it constructs both a positive adapter and a negative adapter from a dual perspective, thereby better leveraging previously outlooked or interfering features in the training dataset. In this way, Dual-Adapter can inherit the advantages of CLIP not having to train, but also excels in distinguishing between ID and OOD samples. Extensive experimental results on four benchmark datasets demonstrate the superiority of Dual-Adapter.
<div id='section'>Paperid: <span id='pid'>654, <a href='https://arxiv.org/pdf/2405.14563.pdf' target='_blank'>https://arxiv.org/pdf/2405.14563.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Loris Giulivi, Giacomo Boracchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14563">Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in multi-modal embeddings, and in particular CLIP, have recently driven several breakthroughs in Computer Vision (CV). CLIP has shown impressive performance on a variety of tasks, yet, its inherently opaque architecture may hinder the application of models employing CLIP as backbone, especially in fields where trust and model explainability are imperative, such as in the medical domain. Current explanation methodologies for CV models rely on Saliency Maps computed through gradient analysis or input perturbation. However, these Saliency Maps can only be computed to explain classes relevant to the end task, often smaller in scope than the backbone training classes. In the context of models implementing CLIP as their vision backbone, a substantial portion of the information embedded within the learned representations is thus left unexplained.
  In this work, we propose Concept Visualization (ConVis), a novel saliency methodology that explains the CLIP embedding of an image by exploiting the multi-modal nature of the embeddings. ConVis makes use of lexical information from WordNet to compute task-agnostic Saliency Maps for any concept, not limited to concepts the end model was trained on. We validate our use of WordNet via an out of distribution detection experiment, and test ConVis on an object localization benchmark, showing that Concept Visualizations correctly identify and localize the image's semantic content. Additionally, we perform a user study demonstrating that our methodology can give users insight on the model's functioning.
<div id='section'>Paperid: <span id='pid'>655, <a href='https://arxiv.org/pdf/2405.02140.pdf' target='_blank'>https://arxiv.org/pdf/2405.02140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alvaro H. C. Correia, Fabio Valerio Massoli, Christos Louizos, Arash Behboodi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02140">An Information Theoretic Perspective on Conformal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformal Prediction (CP) is a distribution-free uncertainty estimation framework that constructs prediction sets guaranteed to contain the true answer with a user-specified probability. Intuitively, the size of the prediction set encodes a general notion of uncertainty, with larger sets associated with higher degrees of uncertainty. In this work, we leverage information theory to connect conformal prediction to other notions of uncertainty. More precisely, we prove three different ways to upper bound the intrinsic uncertainty, as described by the conditional entropy of the target variable given the inputs, by combining CP with information theoretical inequalities. Moreover, we demonstrate two direct and useful applications of such connection between conformal prediction and information theory: (i) more principled and effective conformal training objectives that generalize previous approaches and enable end-to-end training of machine learning models from scratch, and (ii) a natural mechanism to incorporate side information into conformal prediction. We empirically validate both applications in centralized and federated learning settings, showing our theoretical results translate to lower inefficiency (average prediction set size) for popular CP methods.
<div id='section'>Paperid: <span id='pid'>656, <a href='https://arxiv.org/pdf/2404.18279.pdf' target='_blank'>https://arxiv.org/pdf/2404.18279.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zesheng Hong, Yubiao Yue, Yubin Chen, Lele Cong, Huanjie Lin, Yuanmei Luo, Mini Han Wang, Weidong Wang, Jialong Xu, Xiaoqi Yang, Hechang Chen, Zhenzhang Li, Sihong Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.18279">Out-of-distribution Detection in Medical Image Analysis: A survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computer-aided diagnostics has benefited from the development of deep learning-based computer vision techniques in these years. Traditional supervised deep learning methods assume that the test sample is drawn from the identical distribution as the training data. However, it is possible to encounter out-of-distribution samples in real-world clinical scenarios, which may cause silent failure in deep learning-based medical image analysis tasks. Recently, research has explored various out-of-distribution (OOD) detection situations and techniques to enable a trustworthy medical AI system. In this survey, we systematically review the recent advances in OOD detection in medical image analysis. We first explore several factors that may cause a distributional shift when using a deep-learning-based model in clinic scenarios, with three different types of distributional shift well defined on top of these factors. Then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy. Our discussion also includes evaluation protocols and metrics, as well as the challenge and a research direction lack of exploration.
<div id='section'>Paperid: <span id='pid'>657, <a href='https://arxiv.org/pdf/2404.09127.pdf' target='_blank'>https://arxiv.org/pdf/2404.09127.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruixin Yang, Dheeraj Rajagopal, Shirley Anugrah Hayati, Bin Hu, Dongyeop Kang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.09127">Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a significant issue for current large language models (LLMs) that are generally poorly calibrated and over-confident, especially with reinforcement learning from human feedback (RLHF). Unlike humans, whose decisions and confidences not only stem from intrinsic beliefs but can also be adjusted through daily observations, existing calibration methods for LLMs focus on estimating or eliciting individual confidence without taking full advantage of the "Collective Wisdom": the interaction among multiple LLMs that can collectively improve both accuracy and calibration. In this work, we propose Collaborative Calibration, a post-hoc training-free calibration strategy that leverages the collaborative and expressive capabilities of multiple tool-augmented LLM agents in a simulated group deliberation process. We demonstrate the effectiveness of Collaborative Calibration on generative QA tasks across various domains, showing its potential in harnessing the rationalization of collectively calibrated confidence assessments and improving the reliability of model predictions.
<div id='section'>Paperid: <span id='pid'>658, <a href='https://arxiv.org/pdf/2404.07099.pdf' target='_blank'>https://arxiv.org/pdf/2404.07099.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linas Nasvytis, Kai Sandbrink, Jakob Foerster, Tim Franzmeyer, Christian Schroeder de Witt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07099">Rethinking Out-of-Distribution Detection for Reinforcement Learning: Advancing Methods for Evaluation and Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While reinforcement learning (RL) algorithms have been successfully applied across numerous sequential decision-making problems, their generalization to unforeseen testing environments remains a significant concern. In this paper, we study the problem of out-of-distribution (OOD) detection in RL, which focuses on identifying situations at test time that RL agents have not encountered in their training environments. We first propose a clarification of terminology for OOD detection in RL, which aligns it with the literature from other machine learning domains. We then present new benchmark scenarios for OOD detection, which introduce anomalies with temporal autocorrelation into different components of the agent-environment loop. We argue that such scenarios have been understudied in the current literature, despite their relevance to real-world situations. Confirming our theoretical predictions, our experimental results suggest that state-of-the-art OOD detectors are not able to identify such anomalies. To address this problem, we propose a novel method for OOD detection, which we call DEXTER (Detection via Extraction of Time Series Representations). By treating environment observations as time series data, DEXTER extracts salient time series features, and then leverages an ensemble of isolation forest algorithms to detect anomalies. We find that DEXTER can reliably identify anomalies across benchmark scenarios, exhibiting superior performance compared to both state-of-the-art OOD detectors and high-dimensional changepoint detectors adopted from statistics.
<div id='section'>Paperid: <span id='pid'>659, <a href='https://arxiv.org/pdf/2404.03495.pdf' target='_blank'>https://arxiv.org/pdf/2404.03495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon KlÃ¼ttermann, Emmanuel MÃ¼ller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.03495">Deep Transductive Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) is one of the core challenges in machine learning. Transductive learning, which leverages test data during training, has shown promise in related machine learning tasks, yet remains largely unexplored for modern OD. We present Doust, the first end-to-end transductive deep learning algorithm for outlier detection, which explicitly leverages unlabeled test data to boost accuracy. On the comprehensive ADBench benchmark, Doust achieves an average ROC-AUC of $89%$, outperforming all 21 competitors by roughly $10%$. Our analysis identifies both the potential and a limitation of transductive OD: while performance gains can be substantial in favorable conditions, very low contamination rates can hinder improvements unless the dataset is sufficiently large.
<div id='section'>Paperid: <span id='pid'>660, <a href='https://arxiv.org/pdf/2403.15011.pdf' target='_blank'>https://arxiv.org/pdf/2403.15011.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Timo Kaiser, Maximilian Schier, Bodo Rosenhahn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15011">Cell Tracking according to Biological Needs -- Strong Mitosis-aware Multi-Hypothesis Tracker with Aleatoric Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cell tracking and segmentation assist biologists in extracting insights from large-scale microscopy time-lapse data. Driven by local accuracy metrics, current tracking approaches often suffer from a lack of long-term consistency and the ability to reconstruct lineage trees correctly. To address this issue, we introduce an uncertainty estimation technique for motion estimation frameworks and extend the multi-hypothesis tracking framework. Our uncertainty estimation lifts motion representations into probabilistic spatial densities using problem-specific test-time augmentations. Moreover, we introduce a novel mitosis-aware assignment problem formulation that allows multi-hypothesis trackers to model cell splits and to resolve false associations and mitosis detections based on long-term conflicts. In our framework, explicit biological knowledge is modeled in assignment costs. We evaluate our approach on nine competitive datasets and demonstrate that we outperform the current state-of-the-art on biologically inspired metrics substantially, achieving improvements by a factor of approximately 6 and uncover new insights into the behavior of motion estimation uncertainty.
<div id='section'>Paperid: <span id='pid'>661, <a href='https://arxiv.org/pdf/2403.05171.pdf' target='_blank'>https://arxiv.org/pdf/2403.05171.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoying Zhang, Jean-Francois Ton, Wei Shen, Hongning Wang, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.05171">Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Adversarial Policy Optimization (AdvPO), a novel solution to the pervasive issue of reward over-optimization in Reinforcement Learning from Human Feedback (RLHF) for Large Language Models (LLMs). Over-optimization occurs when a reward model serves as an imperfect proxy for human preference, and RL-driven policy optimization erroneously exploits reward inaccuracies. In this paper, we begin by introducing a lightweight way to quantify uncertainties in rewards, relying solely on the last layer embeddings of the reward model, without the need for computationally expensive reward ensembles. AdvPO then addresses a distributionally robust optimization problem centred around the confidence interval of the reward model's predictions for policy improvement. Through comprehensive experiments on the Anthropic HH and TL;DR summarization datasets, we illustrate the efficacy of AdvPO in mitigating the overoptimization issue, consequently resulting in enhanced performance as evaluated through human-assisted evaluation.
<div id='section'>Paperid: <span id='pid'>662, <a href='https://arxiv.org/pdf/2403.03412.pdf' target='_blank'>https://arxiv.org/pdf/2403.03412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingrui Ji, Yao Zhu, Zhigang Li, Jiansheng Chen, Yunlong Kong, Jingbo Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.03412">Advancing Out-of-Distribution Detection through Data Purification and Dynamic Activation Function Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the dynamic realms of machine learning and deep learning, the robustness and reliability of models are paramount, especially in critical real-world applications. A fundamental challenge in this sphere is managing Out-of-Distribution (OOD) samples, significantly increasing the risks of model misclassification and uncertainty. Our work addresses this challenge by enhancing the detection and management of OOD samples in neural networks. We introduce OOD-R (Out-of-Distribution-Rectified), a meticulously curated collection of open-source datasets with enhanced noise reduction properties. In-Distribution (ID) noise in existing OOD datasets can lead to inaccurate evaluation of detection algorithms. Recognizing this, OOD-R incorporates noise filtering technologies to refine the datasets, ensuring a more accurate and reliable evaluation of OOD detection algorithms. This approach not only improves the overall quality of data but also aids in better distinguishing between OOD and ID samples, resulting in up to a 2.5\% improvement in model accuracy and a minimum 3.2\% reduction in false positives. Furthermore, we present ActFun, an innovative method that fine-tunes the model's response to diverse inputs, thereby improving the stability of feature extraction and minimizing specificity issues. ActFun addresses the common problem of model overconfidence in OOD detection by strategically reducing the influence of hidden units, which enhances the model's capability to estimate OOD uncertainty more accurately. Implementing ActFun in the OOD-R dataset has led to significant performance enhancements, including an 18.42\% increase in AUROC of the GradNorm method and a 16.93\% decrease in FPR95 of the Energy method. Overall, our research not only advances the methodologies in OOD detection but also emphasizes the importance of dataset integrity for accurate algorithm evaluation.
<div id='section'>Paperid: <span id='pid'>663, <a href='https://arxiv.org/pdf/2512.12341.pdf' target='_blank'>https://arxiv.org/pdf/2512.12341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Hofman, Yusuf Sale, Eyke Hüllermeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.12341">Uncertainty Quantification for Machine Learning: One Size Does Not Fit All</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proper quantification of predictive uncertainty is essential for the use of machine learning in safety-critical applications. Various uncertainty measures have been proposed for this purpose, typically claiming superiority over other measures. In this paper, we argue that there is no single best measure. Instead, uncertainty quantification should be tailored to the specific application. To this end, we use a flexible family of uncertainty measures that distinguishes between total, aleatoric, and epistemic uncertainty of second-order distributions. These measures can be instantiated with specific loss functions, so-called proper scoring rules, to control their characteristics, and we show that different characteristics are useful for different tasks. In particular, we show that, for the task of selective prediction, the scoring rule should ideally match the task loss. On the other hand, for out-of-distribution detection, our results confirm that mutual information, a widely used measure of epistemic uncertainty, performs best. Furthermore, in an active learning setting, epistemic uncertainty based on zero-one loss is shown to consistently outperform other uncertainty measures.
<div id='section'>Paperid: <span id='pid'>664, <a href='https://arxiv.org/pdf/2512.10602.pdf' target='_blank'>https://arxiv.org/pdf/2512.10602.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hendrik Borras, Yong Wu, Bernhard Klein, Holger Fröning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.10602">Uncertainty-Preserving QBNNs: Multi-Level Quantization of SVI-Based Bayesian Neural Networks for Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Neural Networks (BNNs) provide principled uncertainty quantification but suffer from substantial computational and memory overhead compared to deterministic networks. While quantization techniques have successfully reduced resource requirements in standard deep learning models, their application to probabilistic models remains largely unexplored. We introduce a systematic multi-level quantization framework for Stochastic Variational Inference based BNNs that distinguishes between three quantization strategies: Variational Parameter Quantization (VPQ), Sampled Parameter Quantization (SPQ), and Joint Quantization (JQ). Our logarithmic quantization for variance parameters, and specialized activation functions to preserve the distributional structure are essential for calibrated uncertainty estimation. Through comprehensive experiments on Dirty-MNIST, we demonstrate that BNNs can be quantized down to 4-bit precision while maintaining both classification accuracy and uncertainty disentanglement. At 4 bits, Joint Quantization achieves up to 8x memory reduction compared to floating-point implementations with minimal degradation in epistemic and aleatoric uncertainty estimation. These results enable deployment of BNNs on resource-constrained edge devices and provide design guidelines for future analog "Bayesian Machines" operating at inherently low precision.
<div id='section'>Paperid: <span id='pid'>665, <a href='https://arxiv.org/pdf/2512.02981.pdf' target='_blank'>https://arxiv.org/pdf/2512.02981.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongyu Yang, Yingfang Yuan, Xuanming Jiang, Baoyi An, Wei Pang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.02981">InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hallucination remains a critical challenge in large language models (LLMs), hindering the development of reliable multimodal LLMs (MLLMs). Existing solutions often rely on human intervention or underutilize the agent's ability to autonomously mitigate hallucination. To address these limitations, we draw inspiration from how humans make reliable decisions in the real world. They begin with introspective reasoning to reduce uncertainty and form an initial judgment, then rely on external verification from diverse perspectives to reach a final decision. Motivated by this cognitive paradigm, we propose InEx, a training-free, multi-agent framework designed to autonomously mitigate hallucination. InEx introduces internal introspective reasoning, guided by entropy-based uncertainty estimation, to improve the reliability of the decision agent's reasoning process. The agent first generates a response, which is then iteratively verified and refined through external cross-modal multi-agent collaboration with the editing agent and self-reflection agents, further enhancing reliability and mitigating hallucination. Extensive experiments show that InEx consistently outperforms existing methods, achieving 4%-27% gains on general and hallucination benchmarks, and demonstrating strong robustness.
<div id='section'>Paperid: <span id='pid'>666, <a href='https://arxiv.org/pdf/2511.23440.pdf' target='_blank'>https://arxiv.org/pdf/2511.23440.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bernhard Klein, Falk Selker, Hendrik Borras, Sophie Steger, Franz Pernkopf, Holger Fröning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.23440">Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models perform well across domains such as diagnostics, weather forecasting, NLP, and autonomous driving, but their limited uncertainty handling restricts use in safety-critical settings. Traditional neural networks often fail to detect out-of-domain (OOD) data and may output confident yet incorrect predictions. Bayesian neural networks (BNNs) address this by providing probabilistic estimates, but incur high computational cost because predictions require sampling weight distributions and multiple forward passes. The Probabilistic Forward Pass (PFP) offers a highly efficient approximation to Stochastic Variational Inference (SVI) by assuming Gaussian-distributed weights and activations, enabling fully analytic uncertainty propagation and replacing sampling with a single deterministic forward pass. We present an end-to-end pipeline for training, compiling, optimizing, and deploying PFP-based BNNs on embedded ARM CPUs. Using the TVM deep learning compiler, we implement a dedicated library of Gaussian-propagating operators for multilayer perceptrons and convolutional neural networks, combined with manual and automated tuning strategies. Ablation studies show that PFP consistently outperforms SVI in computational efficiency, achieving speedups of up to 4200x for small mini-batches. PFP-BNNs match SVI-BNNs on Dirty-MNIST in accuracy, uncertainty estimation, and OOD detection while greatly reducing compute cost. These results highlight the potential of combining Bayesian approximations with code generation to enable efficient BNN deployment on resource-constrained systems.
<div id='section'>Paperid: <span id='pid'>667, <a href='https://arxiv.org/pdf/2511.04461.pdf' target='_blank'>https://arxiv.org/pdf/2511.04461.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giorgio Palma, Andrea Serani, Matteo Diez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.04461">Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we present and validate an ensemble-based Hankel Dynamic Mode Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions of a high-speed catamaran, namely the Delft 372 model. Experimental measurements (time histories) of wave elevation at the longitudinal center of gravity, heave, pitch, notional flight-deck velocity, notional bridge acceleration, and total resistance were collected from irregular wave basin tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5 conditions at Fr = 0.425, and organized into training, validation, and test sets. The HDMDc algorithm constructs an equation-free linear reduced-order model of the seakeeping vessel by augmenting states and inputs with their time-lagged copies to capture nonlinear and memory effects. Two ensembling strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters considered stochastic variables with prior distribution to produce posterior mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which aggregates multiple model obtained over data subsets, are compared in providing seakeeping prediction and uncertainty quantification. The FHDMDc approach is found to improve the accuracy of the predictions compared to the deterministic counterpart, also providing robust uncertainty estimation; whereas the application of BHDMDc to the present test case is not found beneficial in comparison to the deterministic model. FHDMDc-derived probability density functions for the motions closely match both experimental data and URANS results, demonstrating reliable and computationally efficient seakeeping prediction for design and operational support.
<div id='section'>Paperid: <span id='pid'>668, <a href='https://arxiv.org/pdf/2510.27443.pdf' target='_blank'>https://arxiv.org/pdf/2510.27443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meenu Ravi, Shailik Sarkar, Yanshen Sun, Vaishnavi Singh, Chang-Tien Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.27443">MVeLMA: Multimodal Vegetation Loss Modeling Architecture for Predicting Post-fire Vegetation Loss</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding post-wildfire vegetation loss is critical for developing effective ecological recovery strategies and is often challenging due to the extended time and effort required to capture the evolving ecosystem features. Recent works in this area have not fully explored all the contributing factors, their modalities, and interactions with each other. Furthermore, most research in this domain is limited by a lack of interpretability in predictive modeling, making it less useful in real-world settings. In this work, we propose a novel end-to-end ML pipeline called MVeLMA (\textbf{M}ultimodal \textbf{Ve}getation \textbf{L}oss \textbf{M}odeling \textbf{A}rchitecture) to predict county-wise vegetation loss from fire events. MVeLMA uses a multimodal feature integration pipeline and a stacked ensemble-based architecture to capture different modalities while also incorporating uncertainty estimation through probabilistic modeling. Through comprehensive experiments, we show that our model outperforms several state-of-the-art (SOTA) and baseline models in predicting post-wildfire vegetation loss. Furthermore, we generate vegetation loss confidence maps to identify high-risk counties, thereby helping targeted recovery efforts. The findings of this work have the potential to inform future disaster relief planning, ecological policy development, and wildlife recovery management.
<div id='section'>Paperid: <span id='pid'>669, <a href='https://arxiv.org/pdf/2510.13093.pdf' target='_blank'>https://arxiv.org/pdf/2510.13093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ningkang Peng, Yuzhe Mao, Yuhao Zhang, Linjin Qian, Qianfeng Yu, Yanhui Gu, Yi Chen, Li Kong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.13093">A Multi-dimensional Semantic Surprise Framework Based on Low-Entropy Semantic Manifolds for Fine-Grained Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is a cornerstone for the safe deployment of AI systems in the open world. However, existing methods treat OOD detection as a binary classification problem, a cognitive flattening that fails to distinguish between semantically close (Near-OOD) and distant (Far-OOD) unknown risks. This limitation poses a significant safety bottleneck in applications requiring fine-grained risk stratification. To address this, we propose a paradigm shift from a conventional probabilistic view to a principled information-theoretic framework. We formalize the core task as quantifying the Semantic Surprise of a new sample and introduce a novel ternary classification challenge: In-Distribution (ID) vs. Near-OOD vs. Far-OOD. The theoretical foundation of our work is the concept of Low-Entropy Semantic Manifolds, which are explicitly structured to reflect the data's intrinsic semantic hierarchy. To construct these manifolds, we design a Hierarchical Prototypical Network. We then introduce the Semantic Surprise Vector (SSV), a universal probe that decomposes a sample's total surprise into three complementary and interpretable dimensions: conformity, novelty, and ambiguity. To evaluate performance on this new task, we propose the Normalized Semantic Risk (nSR), a cost-sensitive metric. Experiments demonstrate that our framework not only establishes a new state-of-the-art (sota) on the challenging ternary task, but its robust representations also achieve top results on conventional binary benchmarks, reducing the False Positive Rate by over 60% on datasets like LSUN.
<div id='section'>Paperid: <span id='pid'>670, <a href='https://arxiv.org/pdf/2509.15403.pdf' target='_blank'>https://arxiv.org/pdf/2509.15403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangyi Li, Mengdi Huai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15403">Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have shown strong capabilities, enabling concise, context-aware answers in question answering (QA) tasks. The lack of transparency in complex LLMs has inspired extensive research aimed at developing methods to explain large language behaviors. Among existing explanation methods, natural language explanations stand out due to their ability to explain LLMs in a self-explanatory manner and enable the understanding of model behaviors even when the models are closed-source. However, despite these promising advancements, there is no existing work studying how to provide valid uncertainty guarantees for these generated natural language explanations. Such uncertainty quantification is critical in understanding the confidence behind these explanations. Notably, generating valid uncertainty estimates for natural language explanations is particularly challenging due to the auto-regressive generation process of LLMs and the presence of noise in medical inquiries. To bridge this gap, in this work, we first propose a novel uncertainty estimation framework for these generated natural language explanations, which provides valid uncertainty guarantees in a post-hoc and model-agnostic manner. Additionally, we also design a novel robust uncertainty estimation method that maintains valid uncertainty guarantees even under noise. Extensive experiments on QA tasks demonstrate the desired performance of our methods.
<div id='section'>Paperid: <span id='pid'>671, <a href='https://arxiv.org/pdf/2509.15256.pdf' target='_blank'>https://arxiv.org/pdf/2509.15256.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zimo Yan, Jie Zhang, Zheng Xie, Yiping Song, Hao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15256">A Multi-Scale Graph Neural Process with Cross-Drug Co-Attention for Drug-Drug Interactions Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of drug-drug interactions (DDI) is crucial for medication safety and effective drug development. However, existing methods often struggle to capture structural information across different scales, from local functional groups to global molecular topology, and typically lack mechanisms to quantify prediction confidence. To address these limitations, we propose MPNP-DDI, a novel Multi-scale Graph Neural Process framework. The core of MPNP-DDI is a unique message-passing scheme that, by being iteratively applied, learns a hierarchy of graph representations at multiple scales. Crucially, a cross-drug co-attention mechanism then dynamically fuses these multi-scale representations to generate context-aware embeddings for interacting drug pairs, while an integrated neural process module provides principled uncertainty estimation. Extensive experiments demonstrate that MPNP-DDI significantly outperforms state-of-the-art baselines on benchmark datasets. By providing accurate, generalizable, and uncertainty-aware predictions built upon multi-scale structural features, MPNP-DDI represents a powerful computational tool for pharmacovigilance, polypharmacy risk assessment, and precision medicine.
<div id='section'>Paperid: <span id='pid'>672, <a href='https://arxiv.org/pdf/2509.08926.pdf' target='_blank'>https://arxiv.org/pdf/2509.08926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Waqar Ahmad, Evan Murphy, Vladimir A. Krylov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08926">Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Object re-identification (Re-ID) methods are highly sensitive to label noise, which typically leads to significant performance degradation. We address this challenge by reframing Re-ID as a supervised image similarity task and adopting a Siamese network architecture trained to capture discriminative pairwise relationships. Central to our approach is a novel statistical outlier detection (OD) framework, termed Beta-SOD (Beta mixture Similarity-based Outlier Detection), which models the distribution of cosine similarities between embedding pairs using a two-component Beta distribution mixture model. We establish a novel identifiability result for mixtures of two Beta distributions, ensuring that our learning task is well-posed. The proposed OD step complements the Re-ID architecture combining binary cross-entropy, contrastive, and cosine embedding losses that jointly optimize feature-level similarity learning. We demonstrate the effectiveness of Beta-SOD in de-noising and Re-ID tasks for person Re-ID, on CUHK03 and Market-1501 datasets, and vehicle Re-ID, on VeRi-776 dataset. Our method shows superior performance compared to the state-of-the-art methods across various noise levels (10-30\%), demonstrating both robustness and broad applicability in noisy Re-ID scenarios. The implementation of Beta-SOD is available at: github.com/waqar3411/Beta-SOD
<div id='section'>Paperid: <span id='pid'>673, <a href='https://arxiv.org/pdf/2509.08069.pdf' target='_blank'>https://arxiv.org/pdf/2509.08069.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiping Ma, Haoming Zhang, Marc Toussaint
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08069">SVN-ICP: Uncertainty Estimation of ICP-based LiDAR Odometry using Stein Variational Newton</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This letter introduces SVN-ICP, a novel Iterative Closest Point (ICP) algorithm with uncertainty estimation that leverages Stein Variational Newton (SVN) on manifold. Designed specifically for fusing LiDAR odometry in multisensor systems, the proposed method ensures accurate pose estimation and consistent noise parameter inference, even in LiDAR-degraded environments. By approximating the posterior distribution using particles within the Stein Variational Inference framework, SVN-ICP eliminates the need for explicit noise modeling or manual parameter tuning. To evaluate its effectiveness, we integrate SVN-ICP into a simple error-state Kalman filter alongside an IMU and test it across multiple datasets spanning diverse environments and robot types. Extensive experimental results demonstrate that our approach outperforms best-in-class methods on challenging scenarios while providing reliable uncertainty estimates.
<div id='section'>Paperid: <span id='pid'>674, <a href='https://arxiv.org/pdf/2507.22429.pdf' target='_blank'>https://arxiv.org/pdf/2507.22429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erwin de Gelder, Maren Buermann, Olaf Op den Camp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22429">Comparing Normalizing Flows with Kernel Density Estimation in Estimating Risk of Automated Driving Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of safety validation methods is essential for the safe deployment and operation of Automated Driving Systems (ADSs). One of the goals of safety validation is to prospectively evaluate the risk of an ADS dealing with real-world traffic. Scenario-based assessment is a widely-used approach, where test cases are derived from real-world driving data. To allow for a quantitative analysis of the system performance, the exposure of the scenarios must be accurately estimated. The exposure of scenarios at parameter level is expressed using a Probability Density Function (PDF). However, assumptions about the PDF, such as parameter independence, can introduce errors, while avoiding assumptions often leads to oversimplified models with limited parameters to mitigate the curse of dimensionality.
  This paper considers the use of Normalizing Flows (NF) for estimating the PDF of the parameters. NF are a class of generative models that transform a simple base distribution into a complex one using a sequence of invertible and differentiable mappings, enabling flexible, high-dimensional density estimation without restrictive assumptions on the PDF's shape. We demonstrate the effectiveness of NF in quantifying risk and risk uncertainty of an ADS, comparing its performance with Kernel Density Estimation (KDE), a traditional method for non-parametric PDF estimation. While NF require more computational resources compared to KDE, NF is less sensitive to the curse of dimensionality. As a result, NF can improve risk uncertainty estimation, offering a more precise assessment of an ADS's safety.
  This work illustrates the potential of NF in scenario-based safety. Future work involves experimenting more with using NF for scenario generation and optimizing the NF architecture, transformation types, and training hyperparameters to further enhance their applicability.
<div id='section'>Paperid: <span id='pid'>675, <a href='https://arxiv.org/pdf/2507.21423.pdf' target='_blank'>https://arxiv.org/pdf/2507.21423.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Monninger, Zihan Zhang, Zhipeng Mo, Md Zafar Anwar, Steffen Staab, Sihao Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21423">MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving requires an understanding of the static environment from sensor data. Learned Bird's-Eye View (BEV) encoders are commonly used to fuse multiple inputs, and a vector decoder predicts a vectorized map representation from the latent BEV grid. However, traditional map construction models provide deterministic point estimates, failing to capture uncertainty and the inherent ambiguities of real-world environments, such as occlusions and missing lane markings. We propose MapDiffusion, a novel generative approach that leverages the diffusion paradigm to learn the full distribution of possible vectorized maps. Instead of predicting a single deterministic output from learned queries, MapDiffusion iteratively refines randomly initialized queries, conditioned on a BEV latent grid, to generate multiple plausible map samples. This allows aggregating samples to improve prediction accuracy and deriving uncertainty estimates that directly correlate with scene ambiguity. Extensive experiments on the nuScenes dataset demonstrate that MapDiffusion achieves state-of-the-art performance in online map construction, surpassing the baseline by 5% in single-sample performance. We further show that aggregating multiple samples consistently improves performance along the ROC curve, validating the benefit of distribution modeling. Additionally, our uncertainty estimates are significantly higher in occluded areas, reinforcing their value in identifying regions with ambiguous sensor input. By modeling the full map distribution, MapDiffusion enhances the robustness and reliability of online vectorized HD map construction, enabling uncertainty-aware decision-making for autonomous vehicles in complex environments.
<div id='section'>Paperid: <span id='pid'>676, <a href='https://arxiv.org/pdf/2507.19418.pdf' target='_blank'>https://arxiv.org/pdf/2507.19418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiwei Lou, Yuanpeng He, Rongchao Zhang, Yongzhi Cao, Hanpin Wang, Yu Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19418">DEFNet: Multitasks-based Deep Evidential Fusion Network for Blind Image Quality Assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Blind image quality assessment (BIQA) methods often incorporate auxiliary tasks to improve performance. However, existing approaches face limitations due to insufficient integration and a lack of flexible uncertainty estimation, leading to suboptimal performance. To address these challenges, we propose a multitasks-based Deep Evidential Fusion Network (DEFNet) for BIQA, which performs multitask optimization with the assistance of scene and distortion type classification tasks. To achieve a more robust and reliable representation, we design a novel trustworthy information fusion strategy. It first combines diverse features and patterns across sub-regions to enhance information richness, and then performs local-global information fusion by balancing fine-grained details with coarse-grained context. Moreover, DEFNet exploits advanced uncertainty estimation technique inspired by evidential learning with the help of normal-inverse gamma distribution mixture. Extensive experiments on both synthetic and authentic distortion datasets demonstrate the effectiveness and robustness of the proposed framework. Additional evaluation and analysis are carried out to highlight its strong generalization capability and adaptability to previously unseen scenarios.
<div id='section'>Paperid: <span id='pid'>677, <a href='https://arxiv.org/pdf/2507.11960.pdf' target='_blank'>https://arxiv.org/pdf/2507.11960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyein Hong, Sangbong Yoo, SeokHwan Choi, Jisue Kim, Seongbum Seo, Haneol Cho, Chansoo Kim, Yun Jang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11960">d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Approaches to enhancing data quality (DQ) are classified into two main categories: data- and process-driven. However, prior research has predominantly utilized batch data preprocessing within the data-driven framework, which often proves insufficient for optimizing machine learning (ML) model performance and frequently leads to distortions in data characteristics. Existing studies have primarily focused on data preprocessing rather than genuine data quality improvement (DQI). In this paper, we introduce d-DQIVAR, a novel visual analytics system designed to facilitate DQI strategies aimed at improving ML model performance. Our system integrates visual analytics techniques that leverage both data-driven and process-driven approaches. Data-driven techniques tackle DQ issues such as imputation, outlier detection, deletion, format standardization, removal of duplicate records, and feature selection. Process-driven strategies encompass evaluating DQ and DQI procedures by considering DQ dimensions and ML model performance and applying the Kolmogorov-Smirnov test. We illustrate how our system empowers users to harness expert and domain knowledge effectively within a practical workflow through case studies, evaluations, and user studies.
<div id='section'>Paperid: <span id='pid'>678, <a href='https://arxiv.org/pdf/2507.05698.pdf' target='_blank'>https://arxiv.org/pdf/2507.05698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohsi Jawaid, Marcus MÃ¤rtens, Tat-Jun Chin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05698">Event-RGB Fusion for Spacecraft Pose Estimation Under Harsh Lighting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spacecraft pose estimation is crucial for autonomous in-space operations, such as rendezvous, docking and on-orbit servicing. Vision-based pose estimation methods, which typically employ RGB imaging sensors, is a compelling solution for spacecraft pose estimation, but are challenged by harsh lighting conditions, which produce imaging artifacts such as glare, over-exposure, blooming and lens flare. Due to their much higher dynamic range, neuromorphic or event sensors are more resilient to extreme lighting conditions. However, event sensors generally have lower spatial resolution and suffer from reduced signal-to-noise ratio during periods of low relative motion. This work addresses these individual sensor limitations by introducing a sensor fusion approach combining RGB and event sensors. A beam-splitter prism was employed to achieve precise optical and temporal alignment. Then, a RANSAC-based technique was developed to fuse the information from the RGB and event channels to achieve pose estimation that leveraged the strengths of the two modalities. The pipeline was complemented by dropout uncertainty estimation to detect extreme conditions that affect either channel. To benchmark the performance of the proposed event-RGB fusion method, we collected a comprehensive real dataset of RGB and event data for satellite pose estimation in a laboratory setting under a variety of challenging illumination conditions. Encouraging results on the dataset demonstrate the efficacy of our event-RGB fusion approach and further supports the usage of event sensors for spacecraft pose estimation. To support community research on this topic, our dataset will be released publicly.
<div id='section'>Paperid: <span id='pid'>679, <a href='https://arxiv.org/pdf/2507.00570.pdf' target='_blank'>https://arxiv.org/pdf/2507.00570.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zizhao Li, Xueyang Kang, Joseph West, Kourosh Khoshelham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00570">Out-of-distribution detection in 3D applications: a review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to detect objects that are not prevalent in the training set is a critical capability in many 3D applications, including autonomous driving. Machine learning methods for object recognition often assume that all object categories encountered during inference belong to a closed set of classes present in the training data. This assumption limits generalization to the real world, as objects not seen during training may be misclassified or entirely ignored. As part of reliable AI, OOD detection identifies inputs that deviate significantly from the training distribution. This paper provides a comprehensive overview of OOD detection within the broader scope of trustworthy and uncertain AI. We begin with key use cases across diverse domains, introduce benchmark datasets spanning multiple modalities, and discuss evaluation metrics. Next, we present a comparative analysis of OOD detection methodologies, exploring model structures, uncertainty indicators, and distributional distance taxonomies, alongside uncertainty calibration techniques. Finally, we highlight promising research directions, including adversarially robust OOD detection and failure identification, particularly relevant to 3D applications. The paper offers both theoretical and practical insights into OOD detection, showcasing emerging research opportunities such as 3D vision integration. These insights help new researchers navigate the field more effectively, contributing to the development of reliable, safe, and robust AI systems.
<div id='section'>Paperid: <span id='pid'>680, <a href='https://arxiv.org/pdf/2506.24034.pdf' target='_blank'>https://arxiv.org/pdf/2506.24034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>George Webber, Alexander Hammers, Andrew P King, Andrew J Reader
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.24034">Supervised Diffusion-Model-Based PET Image Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models (DMs) have recently been introduced as a regularizing prior for PET image reconstruction, integrating DMs trained on high-quality PET images with unsupervised schemes that condition on measured data. While these approaches have potential generalization advantages due to their independence from the scanner geometry and the injected activity level, they forgo the opportunity to explicitly model the interaction between the DM prior and noisy measurement data, potentially limiting reconstruction accuracy. To address this, we propose a supervised DM-based algorithm for PET reconstruction. Our method enforces the non-negativity of PET's Poisson likelihood model and accommodates the wide intensity range of PET images. Through experiments on realistic brain PET phantoms, we demonstrate that our approach outperforms or matches state-of-the-art deep learning-based methods quantitatively across a range of dose levels. We further conduct ablation studies to demonstrate the benefits of the proposed components in our model, as well as its dependence on training data, parameter count, and number of diffusion steps. Additionally, we show that our approach enables more accurate posterior sampling than unsupervised DM-based methods, suggesting improved uncertainty estimation. Finally, we extend our methodology to a practical approach for fully 3D PET and present example results from real [$^{18}$F]FDG brain PET data.
<div id='section'>Paperid: <span id='pid'>681, <a href='https://arxiv.org/pdf/2506.17633.pdf' target='_blank'>https://arxiv.org/pdf/2506.17633.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Fang, Arvind Easwaran, Blaise Genest
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17633">Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection attempts to distinguish outlier samples to prevent models trained on the in-distribution (ID) dataset from producing unavailable outputs. Most OOD detection methods require many IID samples for training, which seriously limits their real-world applications. To this end, we target a challenging setting: few-shot OOD detection, where {Only a few {\em labeled ID} samples are available.} Therefore, few-shot OOD detection is much more challenging than the traditional OOD detection setting. Previous few-shot OOD detection works ignore the distinct diversity between different classes. In this paper, we propose a novel network: Adaptive Multi-prompt Contrastive Network (AMCN), which adapts the ID-OOD separation boundary by learning inter- and intra-class distribution. To compensate for the absence of OOD and scarcity of ID {\em image samples}, we leverage CLIP, connecting text with images, engineering learnable ID and OOD {\em textual prompts}. Specifically, we first generate adaptive prompts (learnable ID prompts, label-fixed OOD prompts and label-adaptive OOD prompts). Then, we generate an adaptive class boundary for each class by introducing a class-wise threshold. Finally, we propose a prompt-guided ID-OOD separation module to control the margin between ID and OOD prompts. Experimental results show that AMCN outperforms other state-of-the-art works.
<div id='section'>Paperid: <span id='pid'>682, <a href='https://arxiv.org/pdf/2506.10718.pdf' target='_blank'>https://arxiv.org/pdf/2506.10718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefan Roth, Aydin Sezgin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10718">Anomaly Detection for Sensing Security</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Various approaches in the field of physical layer security involve anomaly detection, such as physical layer authentication, sensing attacks, and anti-tampering solutions. Depending on the context in which these approaches are applied, anomaly detection needs to be computationally lightweight, resilient to changes in temperature and environment, and robust against phase noise. We adapt moving average filters, autoregression filters and Kalman filters to provide predictions of feature vectors that fulfill the above criteria. Different hypothesis test designs are employed that allow omnidirectional and unidirectional outlier detection. In a case study, a sensing attack is investigated that employs the described algorithms with various channel features based on commodity WiFi devices. Thereby, various combinations of algorithms and channel features show effectiveness for motion detection by an attacker. Countermeasures only utilizing transmit power randomization are shown insufficient to mitigate such attacks if the attacker has access to channel state information (CSI) measurements, suggesting that mitigation solutions might require frequency-variant randomization.
<div id='section'>Paperid: <span id='pid'>683, <a href='https://arxiv.org/pdf/2505.22199.pdf' target='_blank'>https://arxiv.org/pdf/2505.22199.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyue Hu, Zhibin Duan, Bo Chen, Mingyuan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22199">Enhancing Uncertainty Estimation and Interpretability via Bayesian Non-negative Decision Layer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although deep neural networks have demonstrated significant success due to their powerful expressiveness, most models struggle to meet practical requirements for uncertainty estimation. Concurrently, the entangled nature of deep neural networks leads to a multifaceted problem, where various localized explanation techniques reveal that multiple unrelated features influence the decisions, thereby undermining interpretability. To address these challenges, we develop a Bayesian Non-negative Decision Layer (BNDL), which reformulates deep neural networks as a conditional Bayesian non-negative factor analysis. By leveraging stochastic latent variables, the BNDL can model complex dependencies and provide robust uncertainty estimation. Moreover, the sparsity and non-negativity of the latent variables encourage the model to learn disentangled representations and decision layers, thereby improving interpretability. We also offer theoretical guarantees that BNDL can achieve effective disentangled learning. In addition, we developed a corresponding variational inference method utilizing a Weibull variational inference network to approximate the posterior distribution of the latent variables. Our experimental results demonstrate that with enhanced disentanglement capabilities, BNDL not only improves the model's accuracy but also provides reliable uncertainty estimation and improved interpretability.
<div id='section'>Paperid: <span id='pid'>684, <a href='https://arxiv.org/pdf/2505.07459.pdf' target='_blank'>https://arxiv.org/pdf/2505.07459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07459">Why Uncertainty Estimation Methods Fall Short in RAG: An Axiomatic Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are valued for their strong performance across various tasks, but they also produce inaccurate or misleading outputs. Uncertainty Estimation (UE) quantifies the model's confidence and helps users assess response reliability. However, existing UE methods have not been thoroughly examined in scenarios like Retrieval-Augmented Generation (RAG), where the input prompt includes non-parametric knowledge. This paper shows that current UE methods cannot reliably assess correctness in the RAG setting. We further propose an axiomatic framework to identify deficiencies in existing methods and guide the development of improved approaches. Our framework introduces five constraints that an effective UE method should meet after incorporating retrieved documents into the LLM's prompt. Experimental results reveal that no existing UE method fully satisfies all the axioms, explaining their suboptimal performance in RAG. We further introduce a simple yet effective calibration function based on our framework, which not only satisfies more axioms than baseline methods but also improves the correlation between uncertainty estimates and correctness.
<div id='section'>Paperid: <span id='pid'>685, <a href='https://arxiv.org/pdf/2505.02277.pdf' target='_blank'>https://arxiv.org/pdf/2505.02277.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maryam Sultana, Neil Yorke-Smith, Kaizheng Wang, Shireen Kudukkil Manchingal, Muhammad Mubashar, Fabio Cuzzolin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02277">Epistemic Wrapping for Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is pivotal in machine learning, especially for classification tasks, as it improves the robustness and reliability of models. We introduce a novel `Epistemic Wrapping' methodology aimed at improving uncertainty estimation in classification. Our approach uses Bayesian Neural Networks (BNNs) as a baseline and transforms their outputs into belief function posteriors, effectively capturing epistemic uncertainty and offering an efficient and general methodology for uncertainty quantification. Comprehensive experiments employing a Bayesian Neural Network (BNN) baseline and an Interval Neural Network for inference on the MNIST, Fashion-MNIST, CIFAR-10 and CIFAR-100 datasets demonstrate that our Epistemic Wrapper significantly enhances generalisation and uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>686, <a href='https://arxiv.org/pdf/2504.18421.pdf' target='_blank'>https://arxiv.org/pdf/2504.18421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Ullrich, Zurab Mujirishvili, Knut Graichen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18421">Enhancing System Self-Awareness and Trust of AI: A Case Study in Trajectory Prediction and Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the trajectory planning of automated driving, data-driven statistical artificial intelligence (AI) methods are increasingly established for predicting the emergent behavior of other road users. While these methods achieve exceptional performance in defined datasets, they usually rely on the independent and identically distributed (i.i.d.) assumption and thus tend to be vulnerable to distribution shifts that occur in the real world. In addition, these methods lack explainability due to their black box nature, which poses further challenges in terms of the approval process and social trustworthiness. Therefore, in order to use the capabilities of data-driven statistical AI methods in a reliable and trustworthy manner, the concept of TrustMHE is introduced and investigated in this paper. TrustMHE represents a complementary approach, independent of the underlying AI systems, that combines AI-driven out-of-distribution detection with control-driven moving horizon estimation (MHE) to enable not only detection and monitoring, but also intervention. The effectiveness of the proposed TrustMHE is evaluated and proven in three simulation scenarios.
<div id='section'>Paperid: <span id='pid'>687, <a href='https://arxiv.org/pdf/2504.13569.pdf' target='_blank'>https://arxiv.org/pdf/2504.13569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Djohan Bonnet, Kellian Cottart, Tifenn Hirtzlin, Tarcisius Januel, Thomas Dalgaty, Elisa Vianello, Damien Querlioz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13569">Bayesian continual learning and forgetting in neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological synapses effortlessly balance memory retention and flexibility, yet artificial neural networks still struggle with the extremes of catastrophic forgetting and catastrophic remembering. Here, we introduce Metaplasticity from Synaptic Uncertainty (MESU), a Bayesian framework that updates network parameters according their uncertainty. This approach allows a principled combination of learning and forgetting that ensures that critical knowledge is preserved while unused or outdated information is gradually released. Unlike standard Bayesian approaches -- which risk becoming overly constrained, and popular continual-learning methods that rely on explicit task boundaries, MESU seamlessly adapts to streaming data. It further provides reliable epistemic uncertainty estimates, allowing out-of-distribution detection, the only computational cost being to sample the weights multiple times to provide proper output statistics. Experiments on image-classification benchmarks demonstrate that MESU mitigates catastrophic forgetting, while maintaining plasticity for new tasks. When training 200 sequential permuted MNIST tasks, MESU outperforms established continual learning techniques in terms of accuracy, capability to learn additional tasks, and out-of-distribution data detection. Additionally, due to its non-reliance on task boundaries, MESU outperforms conventional learning techniques on the incremental training of CIFAR-100 tasks consistently in a wide range of scenarios. Our results unify ideas from metaplasticity, Bayesian inference, and Hessian-based regularization, offering a biologically-inspired pathway to robust, perpetual learning.
<div id='section'>Paperid: <span id='pid'>688, <a href='https://arxiv.org/pdf/2504.08768.pdf' target='_blank'>https://arxiv.org/pdf/2504.08768.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaofan Zhou, Liangjie Huang, Pinyang Cheng, Wenpen Yin, Rui Zhang, Wenrui Hao, Lu Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08768">Accelerating Causal Network Discovery of Alzheimer Disease Biomarkers via Scientific Literature-based Retrieval Augmented Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The causal relationships between biomarkers are essential for disease diagnosis and medical treatment planning. One notable application is Alzheimer's disease (AD) diagnosis, where certain biomarkers may influence the presence of others, enabling early detection, precise disease staging, targeted treatments, and improved monitoring of disease progression. However, understanding these causal relationships is complex and requires extensive research. Constructing a comprehensive causal network of biomarkers demands significant effort from human experts, who must analyze a vast number of research papers, and have bias in understanding diseases' biomarkers and their relation. This raises an important question: Can advanced large language models (LLMs), such as those utilizing retrieval-augmented generation (RAG), assist in building causal networks of biomarkers for further medical analysis? To explore this, we collected 200 AD-related research papers published over the past 25 years and then integrated scientific literature with RAG to extract AD biomarkers and generate causal relations among them. Given the high-risk nature of the medical diagnosis, we applied uncertainty estimation to assess the reliability of the generated causal edges and examined the faithfulness and scientificness of LLM reasoning using both automatic and human evaluation. We find that RAG enhances the ability of LLMs to generate more accurate causal networks from scientific papers. However, the overall performance of LLMs in identifying causal relations of AD biomarkers is still limited. We hope this study will inspire further foundational research on AI-driven analysis of AD biomarkers causal network discovery.
<div id='section'>Paperid: <span id='pid'>689, <a href='https://arxiv.org/pdf/2503.18784.pdf' target='_blank'>https://arxiv.org/pdf/2503.18784.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenxi Chen, Raymond A. Yeh, Shaoshuai Mou, Yan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18784">Leveraging Perturbation Robustness to Enhance Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is the task of identifying inputs that deviate from the training data distribution. This capability is essential for safely deploying deep computer vision models in open-world environments. In this work, we propose a post-hoc method, Perturbation-Rectified OOD detection (PRO), based on the insight that prediction confidence for OOD inputs is more susceptible to reduction under perturbation than in-distribution (IND) inputs. Based on the observation, we propose an adversarial score function that searches for the local minimum scores near the original inputs by applying gradient descent. This procedure enhances the separability between IND and OOD samples. Importantly, the approach improves OOD detection performance without complex modifications to the underlying model architectures. We conduct extensive experiments using the OpenOOD benchmark~\cite{yang2022openood}. Our approach further pushes the limit of softmax-based OOD detection and is the leading post-hoc method for small-scale models. On a CIFAR-10 model with adversarial training, PRO effectively detects near-OOD inputs, achieving a reduction of more than 10\% on FPR@95 compared to state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>690, <a href='https://arxiv.org/pdf/2503.18589.pdf' target='_blank'>https://arxiv.org/pdf/2503.18589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guillem Capellera, Antonio Rubio, Luis Ferraz, Antonio Agudo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18589">Unified Uncertainty-Aware Diffusion for Multi-Agent Trajectory Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-agent trajectory modeling has primarily focused on forecasting future states, often overlooking broader tasks like trajectory completion, which are crucial for real-world applications such as correcting tracking data. Existing methods also generally predict agents' states without offering any state-wise measure of uncertainty. Moreover, popular multi-modal sampling methods lack any error probability estimates for each generated scene under the same prior observations, making it difficult to rank the predictions during inference time. We introduce U2Diff, a \textbf{unified} diffusion model designed to handle trajectory completion while providing state-wise \textbf{uncertainty} estimates jointly. This uncertainty estimation is achieved by augmenting the simple denoising loss with the negative log-likelihood of the predicted noise and propagating latent space uncertainty to the real state space. Additionally, we incorporate a Rank Neural Network in post-processing to enable \textbf{error probability} estimation for each generated mode, demonstrating a strong correlation with the error relative to ground truth. Our method outperforms the state-of-the-art solutions in trajectory completion and forecasting across four challenging sports datasets (NBA, Basketball-U, Football-U, Soccer-U), highlighting the effectiveness of uncertainty and error probability estimation. Video at https://youtu.be/ngw4D4eJToE
<div id='section'>Paperid: <span id='pid'>691, <a href='https://arxiv.org/pdf/2503.14106.pdf' target='_blank'>https://arxiv.org/pdf/2503.14106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jef Jonkers, Frank Coopman, Luc Duchateau, Glenn Van Wallendael, Sofie Van Hoecke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14106">Reliable uncertainty quantification for 2D/3D anatomical landmark localization using multi-output conformal prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic anatomical landmark localization in medical imaging requires not just accurate predictions but reliable uncertainty quantification for effective clinical decision support. Current uncertainty quantification approaches often fall short, particularly when combined with normality assumptions, systematically underestimating total predictive uncertainty. This paper introduces conformal prediction as a framework for reliable uncertainty quantification in anatomical landmark localization, addressing a critical gap in automatic landmark localization. We present two novel approaches guaranteeing finite-sample validity for multi-output prediction: Multi-output Regression-as-Classification Conformal Prediction (M-R2CCP) and its variant Multi-output Regression to Classification Conformal Prediction set to Region (M-R2C2R). Unlike conventional methods that produce axis-aligned hyperrectangular or ellipsoidal regions, our approaches generate flexible, non-convex prediction regions that better capture the underlying uncertainty structure of landmark predictions. Through extensive empirical evaluation across multiple 2D and 3D datasets, we demonstrate that our methods consistently outperform existing multi-output conformal prediction approaches in both validity and efficiency. This work represents a significant advancement in reliable uncertainty estimation for anatomical landmark localization, providing clinicians with trustworthy confidence measures for their diagnoses. While developed for medical imaging, these methods show promise for broader applications in multi-output regression problems.
<div id='section'>Paperid: <span id='pid'>692, <a href='https://arxiv.org/pdf/2503.13317.pdf' target='_blank'>https://arxiv.org/pdf/2503.13317.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Enrico Foglia, Benjamin Bobbia, Nikita Durasov, Michael Bauerheim, Pascal Fua, Stephane Moreau, Thierry Jardin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13317">Do you understand epistemic uncertainty? Think again! Rigorous frequentist epistemic uncertainty estimation in regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantifying model uncertainty is critical for understanding prediction reliability, yet distinguishing between aleatoric and epistemic uncertainty remains challenging. We extend recent work from classification to regression to provide a novel frequentist approach to epistemic and aleatoric uncertainty estimation. We train models to generate conditional predictions by feeding their initial output back as an additional input. This method allows for a rigorous measurement of model uncertainty by observing how prediction responses change when conditioned on the model's previous answer. We provide a complete theoretical framework to analyze epistemic uncertainty in regression in a frequentist way, and explain how it can be exploited in practice to gauge a model's uncertainty, with minimal changes to the original architecture.
<div id='section'>Paperid: <span id='pid'>693, <a href='https://arxiv.org/pdf/2503.11339.pdf' target='_blank'>https://arxiv.org/pdf/2503.11339.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moritz A. Zanger, Pascal R. Van der Vaart, Wendelin BÃ¶hmer, Matthijs T. J. Spaan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.11339">Contextual Similarity Distillation: Ensemble Uncertainties with a Single Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is a critical aspect of reinforcement learning and deep learning, with numerous applications ranging from efficient exploration and stable offline reinforcement learning to outlier detection in medical diagnostics. The scale of modern neural networks, however, complicates the use of many theoretically well-motivated approaches such as full Bayesian inference. Approximate methods like deep ensembles can provide reliable uncertainty estimates but still remain computationally expensive. In this work, we propose contextual similarity distillation, a novel approach that explicitly estimates the variance of an ensemble of deep neural networks with a single model, without ever learning or evaluating such an ensemble in the first place. Our method builds on the predictable learning dynamics of wide neural networks, governed by the neural tangent kernel, to derive an efficient approximation of the predictive variance of an infinite ensemble. Specifically, we reinterpret the computation of ensemble variance as a supervised regression problem with kernel similarities as regression targets. The resulting model can estimate predictive variance at inference time with a single forward pass, and can make use of unlabeled target-domain data or data augmentations to refine its uncertainty estimates. We empirically validate our method across a variety of out-of-distribution detection benchmarks and sparse-reward reinforcement learning environments. We find that our single-model method performs competitively and sometimes superior to ensemble-based baselines and serves as a reliable signal for efficient exploration. These results, we believe, position contextual similarity distillation as a principled and scalable alternative for uncertainty quantification in reinforcement learning and general deep learning.
<div id='section'>Paperid: <span id='pid'>694, <a href='https://arxiv.org/pdf/2503.01688.pdf' target='_blank'>https://arxiv.org/pdf/2503.01688.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Petr Sychev, Andrey Goncharov, Daniil Vyazhev, Edvard Khalafyan, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.01688">When an LLM is apprehensive about its answers -- and when its uncertainty is justified</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial for evaluating Large Language Models (LLMs), particularly in high-stakes domains where incorrect answers result in significant consequences. Numerous approaches consider this problem, while focusing on a specific type of uncertainty, ignoring others. We investigate what estimates, specifically token-wise entropy and model-as-judge (MASJ), would work for multiple-choice question-answering tasks for different question topics. Our experiments consider three LLMs: Phi-4, Mistral, and Qwen of different sizes from 1.5B to 72B and $14$ topics. While MASJ performs similarly to a random error predictor, the response entropy predicts model error in knowledge-dependent domains and serves as an effective indicator of question difficulty: for biology ROC AUC is $0.73$. This correlation vanishes for the reasoning-dependent domain: for math questions ROC-AUC is $0.55$. More principally, we found out that the entropy measure required a reasoning amount. Thus, data-uncertainty related entropy should be integrated within uncertainty estimates frameworks, while MASJ requires refinement. Moreover, existing MMLU-Pro samples are biased, and should balance required amount of reasoning for different subdomains to provide a more fair assessment of LLMs performance.
<div id='section'>Paperid: <span id='pid'>695, <a href='https://arxiv.org/pdf/2503.00476.pdf' target='_blank'>https://arxiv.org/pdf/2503.00476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yicong Dong, Rundong He, Guangyao Chen, Wentao Zhang, Zhongyi Han, Jieming Shi, Yilong Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00476">G-OSR: A Comprehensive Benchmark for Graph Open-Set Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) have achieved significant success in machine learning, with wide applications in social networks, bioinformatics, knowledge graphs, and other fields. Most research assumes ideal closed-set environments. However, in real-world open-set environments, graph learning models face challenges in robustness and reliability due to unseen classes. This highlights the need for Graph Open-Set Recognition (GOSR) methods to address these issues and ensure effective GNN application in practical scenarios. Research in GOSR is in its early stages, with a lack of a comprehensive benchmark spanning diverse tasks and datasets to evaluate methods. Moreover, traditional methods, Graph Out-of-Distribution Detection (GOODD), GOSR, and Graph Anomaly Detection (GAD) have mostly evolved in isolation, with little exploration of their interconnections or potential applications to GOSR. To fill these gaps, we introduce \textbf{G-OSR}, a comprehensive benchmark for evaluating GOSR methods at both the node and graph levels, using datasets from multiple domains to ensure fair and standardized comparisons of effectiveness and efficiency across traditional, GOODD, GOSR, and GAD methods. The results offer critical insights into the generalizability and limitations of current GOSR methods and provide valuable resources for advancing research in this field through systematic analysis of diverse approaches.
<div id='section'>Paperid: <span id='pid'>696, <a href='https://arxiv.org/pdf/2502.01800.pdf' target='_blank'>https://arxiv.org/pdf/2502.01800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aidan Curtis, Eric Li, Michael Noseworthy, Nishad Gothoskar, Sachin Chitta, Hui Li, Leslie Pack Kaelbling, Nicole Carey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01800">Flow-based Domain Randomization for Learning and Sequencing Robotic Skills</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain randomization in reinforcement learning is an established technique for increasing the robustness of control policies trained in simulation. By randomizing environment properties during training, the learned policy can become robust to uncertainties along the randomized dimensions. While the environment distribution is typically specified by hand, in this paper we investigate automatically discovering a sampling distribution via entropy-regularized reward maximization of a normalizing-flow-based neural sampling distribution. We show that this architecture is more flexible and provides greater robustness than existing approaches that learn simpler, parameterized sampling distributions, as demonstrated in six simulated and one real-world robotics domain. Lastly, we explore how these learned sampling distributions, combined with a privileged value function, can be used for out-of-distribution detection in an uncertainty-aware multi-step manipulation planner.
<div id='section'>Paperid: <span id='pid'>697, <a href='https://arxiv.org/pdf/2501.08440.pdf' target='_blank'>https://arxiv.org/pdf/2501.08440.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabri Mustafa Kahya, Boran Hamdi Sivrikaya, Muhammet Sami Yavuz, Eckehard Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08440">FARE: A Deep Learning-Based Framework for Radar-based Face Recognition and Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose a novel pipeline for face recognition and out-of-distribution (OOD) detection using short-range FMCW radar. The proposed system utilizes Range-Doppler and micro Range-Doppler Images. The architecture features a primary path (PP) responsible for the classification of in-distribution (ID) faces, complemented by intermediate paths (IPs) dedicated to OOD detection. The network is trained in two stages: first, the PP is trained using triplet loss to optimize ID face classification. In the second stage, the PP is frozen, and the IPs-comprising simple linear autoencoder networks-are trained specifically for OOD detection. Using our dataset generated with a 60 GHz FMCW radar, our method achieves an ID classification accuracy of 99.30% and an OOD detection AUROC of 96.91%.
<div id='section'>Paperid: <span id='pid'>698, <a href='https://arxiv.org/pdf/2501.06308.pdf' target='_blank'>https://arxiv.org/pdf/2501.06308.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexis Bose, Jonathan Ethier, Ryan G. Dempsey, Yifeng Qiu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06308">Uncertainty Estimation for Path Loss and Radio Metric Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research leverages Conformal Prediction (CP) in the form of Conformal Predictive Systems (CPS) to accurately estimate uncertainty in a suite of machine learning (ML)-based radio metric models [1] as well as in a 2-D map-based ML path loss model [2]. Utilizing diverse difficulty estimators, we construct 95% confidence prediction intervals (PIs) that are statistically robust. Our experiments demonstrate that CPS models, trained on Toronto datasets, generalize effectively to other cities such as Vancouver and Montreal, maintaining high coverage and reliability. Furthermore, the employed difficulty estimators identify challenging samples, leading to measurable reductions in RMSE as dataset difficulty decreases. These findings highlight the effectiveness of scalable and reliable uncertainty estimation through CPS in wireless network modeling, offering important potential insights for network planning, operations, and spectrum management.
<div id='section'>Paperid: <span id='pid'>699, <a href='https://arxiv.org/pdf/2412.15668.pdf' target='_blank'>https://arxiv.org/pdf/2412.15668.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Fang, Arvind Easwaran, Blaise Genest, Ponnuthurai Nagaratnam Suganthan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15668">Adaptive Hierarchical Graph Cut for Multi-granularity Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper focuses on a significant yet challenging task: out-of-distribution detection (OOD detection), which aims to distinguish and reject test samples with semantic shifts, so as to prevent models trained on in-distribution (ID) data from producing unreliable predictions. Although previous works have made decent success, they are ineffective for real-world challenging applications since these methods simply regard all unlabeled data as OOD data and ignore the case that different datasets have different label granularity. For example, "cat" on CIFAR-10 and "tabby cat" on Tiny-ImageNet share the same semantics but have different labels due to various label granularity. To this end, in this paper, we propose a novel Adaptive Hierarchical Graph Cut network (AHGC) to deeply explore the semantic relationship between different images. Specifically, we construct a hierarchical KNN graph to evaluate the similarities between different images based on the cosine similarity. Based on the linkage and density information of the graph, we cut the graph into multiple subgraphs to integrate these semantics-similar samples. If the labeled percentage in a subgraph is larger than a threshold, we will assign the label with the highest percentage to unlabeled images. To further improve the model generalization, we augment each image into two augmentation versions, and maximize the similarity between the two versions. Finally, we leverage the similarity score for OOD detection. Extensive experiments on two challenging benchmarks (CIFAR- 10 and CIFAR-100) illustrate that in representative cases, AHGC outperforms state-of-the-art OOD detection methods by 81.24% on CIFAR-100 and by 40.47% on CIFAR-10 in terms of "FPR95", which shows the effectiveness of our AHGC.
<div id='section'>Paperid: <span id='pid'>700, <a href='https://arxiv.org/pdf/2412.06284.pdf' target='_blank'>https://arxiv.org/pdf/2412.06284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Fang, Arvind Easwaran, Blaise Genest, Ponnuthurai Nagaratnam Suganthan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06284">Your Data Is Not Perfect: Towards Cross-Domain Out-of-Distribution Detection in Class-Imbalanced Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Previous OOD detection systems only focus on the semantic gap between ID and OOD samples. Besides the semantic gap, we are faced with two additional gaps: the domain gap between source and target domains, and the class-imbalance gap between different classes. In fact, similar objects from different domains should belong to the same class. In this paper, we introduce a realistic yet challenging setting: class-imbalanced cross-domain OOD detection (CCOD), which contains a well-labeled (but usually small) source set for training and conducts OOD detection on an unlabeled (but usually larger) target set for testing. We do not assume that the target domain contains only OOD classes or that it is class-balanced: the distribution among classes of the target dataset need not be the same as the source dataset. To tackle this challenging setting with an OOD detection system, we propose a novel uncertainty-aware adaptive semantic alignment (UASA) network based on a prototype-based alignment strategy. Specifically, we first build label-driven prototypes in the source domain and utilize these prototypes for target classification to close the domain gap. Rather than utilizing fixed thresholds for OOD detection, we generate adaptive sample-wise thresholds to handle the semantic gap. Finally, we conduct uncertainty-aware clustering to group semantically similar target samples to relieve the class-imbalance gap. Extensive experiments on three challenging benchmarks demonstrate that our proposed UASA outperforms state-of-the-art methods by a large margin.
<div id='section'>Paperid: <span id='pid'>701, <a href='https://arxiv.org/pdf/2410.23910.pdf' target='_blank'>https://arxiv.org/pdf/2410.23910.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Durasov, Rafid Mahmood, Jiwoong Choi, Marc T. Law, James Lucas, Pascal Fua, Jose M. Alvarez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.23910">Uncertainty Estimation for 3D Object Detection via Evidential Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>3D object detection is an essential task for computer vision applications in autonomous vehicles and robotics. However, models often struggle to quantify detection reliability, leading to poor performance on unfamiliar scenes. We introduce a framework for quantifying uncertainty in 3D object detection by leveraging an evidential learning loss on Bird's Eye View representations in the 3D detector. These uncertainty estimates require minimal computational overhead and are generalizable across different architectures. We demonstrate both the efficacy and importance of these uncertainty estimates on identifying out-of-distribution scenes, poorly localized objects, and missing (false negative) detections; our framework consistently improves over baselines by 10-20% on average. Finally, we integrate this suite of tasks into a system where a 3D object detector auto-labels driving scenes and our uncertainty estimates verify label correctness before the labels are used to train a second model. Here, our uncertainty-driven verification results in a 1% improvement in mAP and a 1-2% improvement in NDS.
<div id='section'>Paperid: <span id='pid'>702, <a href='https://arxiv.org/pdf/2410.19996.pdf' target='_blank'>https://arxiv.org/pdf/2410.19996.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxin Chen, Zijian Wu, Adam Schmidt, Septimiu E. Salcudean
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19996">A-MFST: Adaptive Multi-Flow Sparse Tracker for Real-Time Tissue Tracking Under Occlusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose: Tissue tracking is critical for downstream tasks in robot-assisted surgery. The Sparse Efficient Neural Depth and Deformation (SENDD) model has previously demonstrated accurate and real-time sparse point tracking, but struggled with occlusion handling. This work extends SENDD to enhance occlusion detection and tracking consistency while maintaining real-time performance. Methods: We use the Segment Anything Model2 (SAM2) to detect and mask occlusions by surgical tools, and we develop and integrate into SENDD an Adaptive Multi-Flow Sparse Tracker (A-MFST) with forward-backward consistency metrics, to enhance occlusion and uncertainty estimation. A-MFST is an unsupervised variant of the Multi-Flow Dense Tracker (MFT). Results: We evaluate our approach on the STIR dataset and demonstrate a significant improvement in tracking accuracy under occlusion, reducing average tracking errors by 12 percent in Mean Endpoint Error (MEE) and showing a 6 percent improvement in the averaged accuracy over thresholds of 4, 8, 16, 32, and 64 pixels. The incorporation of forward-backward consistency further improves the selection of optimal tracking paths, reducing drift and enhancing robustness. Notably, these improvements were achieved without compromising the model's real-time capabilities. Conclusions: Using A-MFST and SAM2, we enhance SENDD's ability to track tissue in real time under instrument and tissue occlusions.
<div id='section'>Paperid: <span id='pid'>703, <a href='https://arxiv.org/pdf/2409.02770.pdf' target='_blank'>https://arxiv.org/pdf/2409.02770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mazen Soufi, Yoshito Otake, Makoto Iwasa, Keisuke Uemura, Tomoki Hakotani, Masahiro Hashimoto, Yoshitake Yamada, Minoru Yamada, Yoichi Yokoyama, Masahiro Jinzaki, Suzushi Kusano, Masaki Takao, Seiji Okada, Nobuhiko Sugano, Yoshinobu Sato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02770">Validation of musculoskeletal segmentation model with uncertainty estimation for bone and muscle assessment in hip-to-knee clinical CT images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based image segmentation has allowed for the fully automated, accurate, and rapid analysis of musculoskeletal (MSK) structures from medical images. However, current approaches were either applied only to 2D cross-sectional images, addressed few structures, or were validated on small datasets, which limit the application in large-scale databases. This study aimed to validate an improved deep learning model for volumetric MSK segmentation of the hip and thigh with uncertainty estimation from clinical computed tomography (CT) images. Databases of CT images from multiple manufacturers/scanners, disease status, and patient positioning were used. The segmentation accuracy, and accuracy in estimating the structures volume and density, i.e., mean HU, were evaluated. An approach for segmentation failure detection based on predictive uncertainty was also investigated. The model has shown an overall improvement with respect to all segmentation accuracy and structure volume/density evaluation metrics. The predictive uncertainty yielded large areas under the receiver operating characteristic (AUROC) curves (AUROCs>=.95) in detecting inaccurate and failed segmentations. The high segmentation and muscle volume/density estimation accuracy, along with the high accuracy in failure detection based on the predictive uncertainty, exhibited the model's reliability for analyzing individual MSK structures in large-scale CT databases.
<div id='section'>Paperid: <span id='pid'>704, <a href='https://arxiv.org/pdf/2407.21740.pdf' target='_blank'>https://arxiv.org/pdf/2407.21740.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhibin Duan, Tiansheng Wen, Yifei Wang, Chen Zhu, Bo Chen, Mingyuan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21740">Contrastive Factor Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Factor analysis, often regarded as a Bayesian variant of matrix factorization, offers superior capabilities in capturing uncertainty, modeling complex dependencies, and ensuring robustness. As the deep learning era arrives, factor analysis is receiving less and less attention due to their limited expressive ability. On the contrary, contrastive learning has emerged as a potent technique with demonstrated efficacy in unsupervised representational learning. While the two methods are different paradigms, recent theoretical analysis has revealed the mathematical equivalence between contrastive learning and matrix factorization, providing a potential possibility for factor analysis combined with contrastive learning. Motivated by the interconnectedness of contrastive learning, matrix factorization, and factor analysis, this paper introduces a novel Contrastive Factor Analysis framework, aiming to leverage factor analysis's advantageous properties within the realm of contrastive learning. To further leverage the interpretability properties of non-negative factor analysis, which can learn disentangled representations, contrastive factor analysis is extended to a non-negative version. Finally, extensive experimental validation showcases the efficacy of the proposed contrastive (non-negative) factor analysis methodology across multiple key properties, including expressiveness, robustness, interpretability, and accurate uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>705, <a href='https://arxiv.org/pdf/2406.05143.pdf' target='_blank'>https://arxiv.org/pdf/2406.05143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lane E. Schultz, Yiqi Wang, Ryan Jacobs, Dane Morgan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05143">A General Approach for Determining Applicability Domain of Machine Learning Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge of the domain of applicability of a machine learning model is essential to ensuring accurate and reliable model predictions. In this work, we develop a new and general approach of assessing model domain and demonstrate that our approach provides accurate and meaningful domain designation across multiple model types and material property data sets. Our approach assesses the distance between data in feature space using kernel density estimation, where this distance provides an effective tool for domain determination. We show that chemical groups considered unrelated based on chemical knowledge exhibit significant dissimilarities by our measure. We also show that high measures of dissimilarity are associated with poor model performance (i.e., high residual magnitudes) and poor estimates of model uncertainty (i.e., unreliable uncertainty estimation). Automated tools are provided to enable researchers to establish acceptable dissimilarity thresholds to identify whether new predictions of their own machine learning models are in-domain versus out-of-domain.
<div id='section'>Paperid: <span id='pid'>706, <a href='https://arxiv.org/pdf/2406.04546.pdf' target='_blank'>https://arxiv.org/pdf/2406.04546.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabri Mustafa Kahya, Boran Hamdi Sivrikaya, Muhammet Sami Yavuz, Eckehard Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04546">FOOD: Facial Authentication and Out-of-Distribution Detection with Short-Range FMCW Radar</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a short-range FMCW radar-based facial authentication and out-of-distribution (OOD) detection framework. Our pipeline jointly estimates the correct classes for the in-distribution (ID) samples and detects the OOD samples to prevent their inaccurate prediction. Our reconstruction-based architecture consists of a main convolutional block with one encoder and multi-decoder configuration, and intermediate linear encoder-decoder parts. Together, these elements form an accurate human face classifier and a robust OOD detector. For our dataset, gathered using a 60 GHz short-range FMCW radar, our network achieves an average classification accuracy of 98.07% in identifying in-distribution human faces. As an OOD detector, it achieves an average Area Under the Receiver Operating Characteristic (AUROC) curve of 98.50% and an average False Positive Rate at 95% True Positive Rate (FPR95) of 6.20%. Also, our extensive experiments show that the proposed approach outperforms previous OOD detectors in terms of common OOD detection metrics.
<div id='section'>Paperid: <span id='pid'>707, <a href='https://arxiv.org/pdf/2404.00546.pdf' target='_blank'>https://arxiv.org/pdf/2404.00546.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mubariz Zaffar, Liangliang Nan, Julian F. P. Kooij
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00546">On the Estimation of Image-matching Uncertainty in Visual Place Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In Visual Place Recognition (VPR) the pose of a query image is estimated by comparing the image to a map of reference images with known reference poses. As is typical for image retrieval problems, a feature extractor maps the query and reference images to a feature space, where a nearest neighbor search is then performed. However, till recently little attention has been given to quantifying the confidence that a retrieved reference image is a correct match. Highly certain but incorrect retrieval can lead to catastrophic failure of VPR-based localization pipelines. This work compares for the first time the main approaches for estimating the image-matching uncertainty, including the traditional retrieval-based uncertainty estimation, more recent data-driven aleatoric uncertainty estimation, and the compute-intensive geometric verification. We further formulate a simple baseline method, ``SUE'', which unlike the other methods considers the freely-available poses of the reference images in the map. Our experiments reveal that a simple L2-distance between the query and reference descriptors is already a better estimate of image-matching uncertainty than current data-driven approaches. SUE outperforms the other efficient uncertainty estimation methods, and its uncertainty estimates complement the computationally expensive geometric verification approach. Future works for uncertainty estimation in VPR should consider the baselines discussed in this work.
<div id='section'>Paperid: <span id='pid'>708, <a href='https://arxiv.org/pdf/2403.07514.pdf' target='_blank'>https://arxiv.org/pdf/2403.07514.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anastasios Arsenos, Dimitrios Kollias, Evangelos Petrongonas, Christos Skliros, Stefanos Kollias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07514">Uncertainty-guided Contrastive Learning for Single Source Domain Generalisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the context of single domain generalisation, the objective is for models that have been exclusively trained on data from a single domain to demonstrate strong performance when confronted with various unfamiliar domains. In this paper, we introduce a novel model referred to as Contrastive Uncertainty Domain Generalisation Network (CUDGNet). The key idea is to augment the source capacity in both input and label spaces through the fictitious domain generator and jointly learn the domain invariant representation of each class through contrastive learning. Extensive experiments on two Single Source Domain Generalisation (SSDG) datasets demonstrate the effectiveness of our approach, which surpasses the state-of-the-art single-DG methods by up to $7.08\%$. Our method also provides efficient uncertainty estimation at inference time from a single forward pass through the generator subnetwork.
<div id='section'>Paperid: <span id='pid'>709, <a href='https://arxiv.org/pdf/2402.16875.pdf' target='_blank'>https://arxiv.org/pdf/2402.16875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adrian-Gabriel Chifu, SÃ©bastien DÃ©jean, Moncef Garouani, Josiane Mothe, DiÃ©go Ortiz, Md Zia Ullah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16875">Can we predict QPP? An approach based on multivariate outliers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Query performance prediction (QPP) aims to forecast the effectiveness of a search engine across a range of queries and documents. While state-of-the-art predictors offer a certain level of precision, their accuracy is not flawless. Prior research has recognized the challenges inherent in QPP but often lacks a thorough qualitative analysis. In this paper, we delve into QPP by examining the factors that influence the predictability of query performance accuracy. We propose the working hypothesis that while some queries are readily predictable, others present significant challenges. By focusing on outliers, we aim to identify the queries that are particularly challenging to predict. To this end, we employ multivariate outlier detection method. Our results demonstrate the effectiveness of this approach in identifying queries on which QPP do not perform well, yielding less reliable predictions. Moreover, we provide evidence that excluding these hard-to-predict queries from the analysis significantly enhances the overall accuracy of QPP.
<div id='section'>Paperid: <span id='pid'>710, <a href='https://arxiv.org/pdf/2402.03985.pdf' target='_blank'>https://arxiv.org/pdf/2402.03985.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ossi RÃ¤isÃ¤, Antti Honkela
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03985">A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets, including differentially private synthetic data. Our theory yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice with several real datasets, downstream predictors and error metrics. As our theory predicts, multiple synthetic datasets often improve accuracy, while a single large synthetic dataset gives at best minimal improvement, showing that our insights are practically relevant.
<div id='section'>Paperid: <span id='pid'>711, <a href='https://arxiv.org/pdf/2401.05043.pdf' target='_blank'>https://arxiv.org/pdf/2401.05043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaizheng Wang, Keivan Shariatmadar, Shireen Kudukkil Manchingal, Fabio Cuzzolin, David Moens, Hans Hallez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05043">CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective uncertainty estimation is becoming increasingly attractive for enhancing the reliability of neural networks. This work presents a novel approach, termed Credal-Set Interval Neural Networks (CreINNs), for classification. CreINNs retain the fundamental structure of traditional Interval Neural Networks, capturing weight uncertainty through deterministic intervals. CreINNs are designed to predict an upper and a lower probability bound for each class, rather than a single probability value. The probability intervals can define a credal set, facilitating estimating different types of uncertainties associated with predictions. Experiments on standard multiclass and binary classification tasks demonstrate that the proposed CreINNs can achieve superior or comparable quality of uncertainty estimation compared to variational Bayesian Neural Networks (BNNs) and Deep Ensembles. Furthermore, CreINNs significantly reduce the computational complexity of variational BNNs during inference. Moreover, the effective uncertainty quantification of CreINNs is also verified when the input data are intervals.
<div id='section'>Paperid: <span id='pid'>712, <a href='https://arxiv.org/pdf/2401.00159.pdf' target='_blank'>https://arxiv.org/pdf/2401.00159.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masachika Masuda, Mazen Soufi, Yoshito Otake, Keisuke Uemura, Sotaro Kono, Kazuma Takashima, Hidetoshi Hamada, Yi Gu, Masaki Takao, Seiji Okada, Nobuhiko Sugano, Yoshinobu Sato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00159">Automatic hip osteoarthritis grading with uncertainty estimation from computed tomography using digitally-reconstructed radiographs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Progression of hip osteoarthritis (hip OA) leads to pain and disability, likely leading to surgical treatment such as hip arthroplasty at the terminal stage. The severity of hip OA is often classified using the Crowe and Kellgren-Lawrence (KL) classifications. However, as the classification is subjective, we aimed to develop an automated approach to classify the disease severity based on the two grades using digitally-reconstructed radiographs (DRRs) from CT images. Automatic grading of the hip OA severity was performed using deep learning-based models. The models were trained to predict the disease grade using two grading schemes, i.e., predicting the Crowe and KL grades separately, and predicting a new ordinal label combining both grades and representing the disease progression of hip OA. The models were trained in classification and regression settings. In addition, the model uncertainty was estimated and validated as a predictor of classification accuracy. The models were trained and validated on a database of 197 hip OA patients, and externally validated on 52 patients. The model accuracy was evaluated using exact class accuracy (ECA), one-neighbor class accuracy (ONCA), and balanced accuracy.The deep learning models produced a comparable accuracy of approximately 0.65 (ECA) and 0.95 (ONCA) in the classification and regression settings. The model uncertainty was significantly larger in cases with large classification errors (P<6e-3). In this study, an automatic approach for grading hip OA severity from CT images was developed. The models have shown comparable performance with high ONCA, which facilitates automated grading in large-scale CT databases and indicates the potential for further disease progression analysis. Classification accuracy was correlated with the model uncertainty, which would allow for the prediction of classification errors.
<div id='section'>Paperid: <span id='pid'>713, <a href='https://arxiv.org/pdf/2512.14770.pdf' target='_blank'>https://arxiv.org/pdf/2512.14770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xixian Wu, Yang Ou, Pengchao Tian, Zian Yang, Jielei Zhang, Peiyi Li, Longwen Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.14770">Improving VQA Reliability: A Dual-Assessment Approach with Self-Reflection and Cross-Model Verification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) have demonstrated significant potential in Visual Question Answering (VQA). However, the susceptibility of VLMs to hallucinations can lead to overconfident yet incorrect answers, severely undermining answer reliability. To address this, we propose Dual-Assessment for VLM Reliability (DAVR), a novel framework that integrates Self-Reflection and Cross-Model Verification for comprehensive uncertainty estimation. The DAVR framework features a dual-pathway architecture: one pathway leverages dual selector modules to assess response reliability by fusing VLM latent features with QA embeddings, while the other deploys external reference models for factual cross-checking to mitigate hallucinations. Evaluated in the Reliable VQA Challenge at ICCV-CLVL 2025, DAVR achieves a leading $Φ_{100}$ score of 39.64 and a 100-AUC of 97.22, securing first place and demonstrating its effectiveness in enhancing the trustworthiness of VLM responses.
<div id='section'>Paperid: <span id='pid'>714, <a href='https://arxiv.org/pdf/2512.07390.pdf' target='_blank'>https://arxiv.org/pdf/2512.07390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gilhyun Nam, Taewon Kim, Joonhyun Jeong, Eunho Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.07390">Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty - a critical issue in high-stakes domains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed models or static distributions, resulting in degraded performance under real-world, dynamic test conditions. To address these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL estimates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requiring only the model's forward pass. This makes it a plug-and-play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenarios with three model architecture demonstrate that SICL reduces calibration error by an average of 13 percentage points compared to conventional calibration approaches.
<div id='section'>Paperid: <span id='pid'>715, <a href='https://arxiv.org/pdf/2512.03243.pdf' target='_blank'>https://arxiv.org/pdf/2512.03243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ioannis Gasteratos, Antoine Jacquier, Maud Lemercier, Terry Lyons, Cristopher Salvi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.03243">Novelty detection on path space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We frame novelty detection on path space as a hypothesis testing problem with signature-based test statistics. Using transportation-cost inequalities of Gasteratos and Jacquier (2023), we obtain tail bounds for false positive rates that extend beyond Gaussian measures to laws of RDE solutions with smooth bounded vector fields, yielding estimates of quantiles and p-values. Exploiting the shuffle product, we derive exact formulae for smooth surrogates of conditional value-at-risk (CVaR) in terms of expected signatures, leading to new one-class SVM algorithms optimising smooth CVaR objectives. We then establish lower bounds on type-$\mathrm{II}$ error for alternatives with finite first moment, giving general power bounds when the reference measure and the alternative are absolutely continuous with respect to each other. Finally, we evaluate numerically the type-$\mathrm{I}$ error and statistical power of signature-based test statistic, using synthetic anomalous diffusion data and real-world molecular biology data.
<div id='section'>Paperid: <span id='pid'>716, <a href='https://arxiv.org/pdf/2511.10200.pdf' target='_blank'>https://arxiv.org/pdf/2511.10200.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jieting Wang, Huimei Shi, Feijiang Li, Xiaolei Shang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.10200">Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time series forecasting is an important task that involves analyzing temporal dependencies and underlying patterns (such as trends, cyclicality, and seasonality) in historical data to predict future values or trends. Current deep learning-based forecasting models primarily employ Mean Squared Error (MSE) loss functions for regression modeling. Despite enabling direct value prediction, this method offers no uncertainty estimation and exhibits poor outlier robustness. To address these limitations, we propose OCE-TS, a novel ordinal classification approach for time series forecasting that replaces MSE with Ordinal Cross-Entropy (OCE) loss, preserving prediction order while quantifying uncertainty through probability output. Specifically, OCE-TS begins by discretizing observed values into ordered intervals and deriving their probabilities via a parametric distribution as supervision signals. Using a simple linear model, we then predict probability distributions for each timestep. The OCE loss is computed between the cumulative distributions of predicted and ground-truth probabilities, explicitly preserving ordinal relationships among forecasted values. Through theoretical analysis using influence functions, we establish that cross-entropy (CE) loss exhibits superior stability and outlier robustness compared to MSE loss. Empirically, we compared OCE-TS with five baseline models-Autoformer, DLinear, iTransformer, TimeXer, and TimeBridge-on seven public time series datasets. Using MSE and Mean Absolute Error (MAE) as evaluation metrics, the results demonstrate that OCE-TS consistently outperforms benchmark models. The code will be published.
<div id='section'>Paperid: <span id='pid'>717, <a href='https://arxiv.org/pdf/2510.27054.pdf' target='_blank'>https://arxiv.org/pdf/2510.27054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaofan Guo, Yaxuan Luan, Yue Kang, Xiangchen Song, Jinxu Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.27054">LLM-Centric RAG with Multi-Granular Indexing and Confidence Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the issues of insufficient coverage, unstable results, and limited reliability in retrieval-augmented generation under complex knowledge environments, and proposes a confidence control method that integrates multi-granularity memory indexing with uncertainty estimation. The method builds a hierarchical memory structure that divides knowledge representations into different levels of granularity, enabling dynamic indexing and retrieval from local details to global context, and thus establishing closer semantic connections between retrieval and generation. On this basis, an uncertainty estimation mechanism is introduced to explicitly constrain and filter low-confidence paths during the generation process, allowing the model to maintain information coverage while effectively suppressing noise and false content. The overall optimization objective consists of generation loss, entropy constraints, and variance regularization, forming a unified confidence control framework. In the experiments, comprehensive sensitivity tests and comparative analyses were designed, covering hyperparameters, environmental conditions, and data structures, to verify the stability and robustness of the proposed method across different scenarios. The results show that the method achieves superior performance over existing models in QA accuracy, retrieval recall, ranking quality, and factual consistency, demonstrating the effectiveness of combining multi-granularity indexing with confidence control. This study not only provides a new technical pathway for retrieval-augmented generation but also offers practical evidence for improving the reliability and controllability of large models in complex contexts.
<div id='section'>Paperid: <span id='pid'>718, <a href='https://arxiv.org/pdf/2510.25599.pdf' target='_blank'>https://arxiv.org/pdf/2510.25599.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christopher Bülte, Yusuf Sale, Gitta Kutyniok, Eyke Hüllermeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.25599">Uncertainty Quantification for Regression: A Unified Framework based on kernel scores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Regression tasks, notably in safety-critical domains, require proper uncertainty quantification, yet the literature remains largely classification-focused. In this light, we introduce a family of measures for total, aleatoric, and epistemic uncertainty based on proper scoring rules, with a particular emphasis on kernel scores. The framework unifies several well-known measures and provides a principled recipe for designing new ones whose behavior, such as tail sensitivity, robustness, and out-of-distribution responsiveness, is governed by the choice of kernel. We prove explicit correspondences between kernel-score characteristics and downstream behavior, yielding concrete design guidelines for task-specific measures. Extensive experiments demonstrate that these measures are effective in downstream tasks and reveal clear trade-offs among instantiations, including robustness and out-of-distribution detection performance.
<div id='section'>Paperid: <span id='pid'>719, <a href='https://arxiv.org/pdf/2510.21310.pdf' target='_blank'>https://arxiv.org/pdf/2510.21310.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ji Won Park, Kyunghyun Cho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.21310">Efficient semantic uncertainty quantification in language models via diversity-steered sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately estimating semantic aleatoric and epistemic uncertainties in large language models (LLMs) is particularly challenging in free-form question answering (QA), where obtaining stable estimates often requires many expensive generations. We introduce a diversity-steered sampler that discourages semantically redundant outputs during decoding, covers both autoregressive and masked diffusion paradigms, and yields substantial sample-efficiency gains. The key idea is to inject a continuous semantic-similarity penalty into the model's proposal distribution using a natural language inference (NLI) model lightly finetuned on partial prefixes or intermediate diffusion states. We debias downstream uncertainty estimates with importance reweighting and shrink their variance with control variates. Across four QA benchmarks, our method matches or surpasses baselines while covering more semantic clusters with the same number of samples. Being modular and requiring no gradient access to the base LLM, the framework promises to serve as a drop-in enhancement for uncertainty estimation in risk-sensitive model deployments.
<div id='section'>Paperid: <span id='pid'>720, <a href='https://arxiv.org/pdf/2510.15666.pdf' target='_blank'>https://arxiv.org/pdf/2510.15666.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Shi, Gang Li, Junxing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.15666">Uncertainty-Aware Extreme Point Tracing for Weakly Supervised Ultrasound Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic medical image segmentation is a fundamental step in computer-aided diagnosis, yet fully supervised approaches demand extensive pixel-level annotations that are costly and time-consuming. To alleviate this burden, we propose a weakly supervised segmentation framework that leverages only four extreme points as annotation. Specifically, bounding boxes derived from the extreme points are used as prompts for the Segment Anything Model 2 (SAM2) to generate reliable initial pseudo labels. These pseudo labels are progressively refined by an enhanced Feature-Guided Extreme Point Masking (FGEPM) algorithm, which incorporates Monte Carlo dropout-based uncertainty estimation to construct a unified gradient uncertainty cost map for boundary tracing. Furthermore, a dual-branch Uncertainty-aware Scale Consistency (USC) loss and a box alignment loss are introduced to ensure spatial consistency and precise boundary alignment during training. Extensive experiments on two public ultrasound datasets, BUSI and UNS, demonstrate that our method achieves performance comparable to, and even surpassing fully supervised counterparts while significantly reducing annotation cost. These results validate the effectiveness and practicality of the proposed weakly supervised framework for ultrasound image segmentation.
<div id='section'>Paperid: <span id='pid'>721, <a href='https://arxiv.org/pdf/2510.05782.pdf' target='_blank'>https://arxiv.org/pdf/2510.05782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>I. M. De la Jara, C. Rodriguez-Opazo, D. Teney, D. Ranasinghe, E. Abbasnejad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05782">Mysteries of the Deep: Role of Intermediate Representations in Out of Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for reliably deploying machine learning models in the wild. Yet, most methods treat large pre-trained models as monolithic encoders and rely solely on their final-layer representations for detection. We challenge this wisdom. We reveal the \textit{intermediate layers} of pre-trained models, shaped by residual connections that subtly transform input projections, \textit{can} encode \textit{surprisingly rich and diverse signals} for detecting distributional shifts. Importantly, to exploit latent representation diversity across layers, we introduce an entropy-based criterion to \textit{automatically} identify layers offering the most complementary information in a training-free setting -- \textit{without access to OOD data}. We show that selectively incorporating these intermediate representations can increase the accuracy of OOD detection by up to \textbf{$10\%$} in far-OOD and over \textbf{$7\%$} in near-OOD benchmarks compared to state-of-the-art training-free methods across various model architectures and training objectives. Our findings reveal a new avenue for OOD detection research and uncover the impact of various training objectives and model architectures on confidence-based OOD detection methods.
<div id='section'>Paperid: <span id='pid'>722, <a href='https://arxiv.org/pdf/2509.21750.pdf' target='_blank'>https://arxiv.org/pdf/2509.21750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Li, Da Chang, Xi Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21750">KG-SAM: Injecting Anatomical Knowledge into Segment Anything Models via Conditional Random Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While the Segment Anything Model (SAM) has achieved remarkable success in image segmentation, its direct application to medical imaging remains hindered by fundamental challenges, including ambiguous boundaries, insufficient modeling of anatomical relationships, and the absence of uncertainty quantification. To address these limitations, we introduce KG-SAM, a knowledge-guided framework that synergistically integrates anatomical priors with boundary refinement and uncertainty estimation. Specifically, KG-SAM incorporates (i) a medical knowledge graph to encode fine-grained anatomical relationships, (ii) an energy-based Conditional Random Field (CRF) to enforce anatomically consistent predictions, and (iii) an uncertainty-aware fusion module to enhance reliability in high-stakes clinical scenarios. Extensive experiments across multi-center medical datasets demonstrate the effectiveness of our approach: KG-SAM achieves an average Dice score of 82.69% on prostate segmentation and delivers substantial gains in abdominal segmentation, reaching 78.05% on MRI and 79.68% on CT. These results establish KG-SAM as a robust and generalizable framework for advancing medical image segmentation.
<div id='section'>Paperid: <span id='pid'>723, <a href='https://arxiv.org/pdf/2509.21593.pdf' target='_blank'>https://arxiv.org/pdf/2509.21593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peng Luo, Xiayin Lou, Yu Zheng, Zhuo Zheng, Stefano Ermon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21593">GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geospatial modeling provides critical solutions for pressing global challenges such as sustainability and climate change. Existing large language model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at evolving generic code but lack the domain knowledge and multi-step reasoning required for complex geospatial problems. We introduce GeoEvolve, a multi-agent LLM framework that couples evolutionary search with geospatial domain knowledge to automatically design and refine geospatial algorithms. GeoEvolve operates in two nested loops: an inner loop leverages a code evolver to generate and mutate candidate solutions, while an outer agentic controller evaluates global elites and queries a GeoKnowRAG module -- a structured geospatial knowledge base that injects theoretical priors from geography. This knowledge-guided evolution steers the search toward theoretically meaningful and computationally efficient algorithms. We evaluate GeoEvolve on two fundamental and classical tasks: spatial interpolation (kriging) and spatial uncertainty quantification (geospatial conformal prediction). Across these benchmarks, GeoEvolve automatically improves and discovers new algorithms, incorporating geospatial theory on top of classical models. It reduces spatial interpolation error (RMSE) by 13-21% and enhances uncertainty estimation performance by 17\%. Ablation studies confirm that domain-guided retrieval is essential for stable, high-quality evolution. These results demonstrate that GeoEvolve provides a scalable path toward automated, knowledge-driven geospatial modeling, opening new opportunities for trustworthy and efficient AI-for-Science discovery.
<div id='section'>Paperid: <span id='pid'>724, <a href='https://arxiv.org/pdf/2509.17153.pdf' target='_blank'>https://arxiv.org/pdf/2509.17153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moule Lin, Andrea Patane, Weipeng Jing, Shuhao Guan, Goetz Botterweck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17153">Flow-Induced Diagonal Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Flow-Induced Diagonal Gaussian Processes (FiD-GP), a compression framework that incorporates a compact inducing weight matrix to project a neural network's weight uncertainty into a lower-dimensional subspace. Critically, FiD-GP relies on normalising-flow priors and spectral regularisations to augment its expressiveness and align the inducing subspace with feature-gradient geometry through a numerically stable projection mechanism objective. Furthermore, we demonstrate how the prediction framework in FiD-GP can help to design a single-pass projection for Out-of-Distribution (OoD) detection. Our analysis shows that FiD-GP improves uncertainty estimation ability on various tasks compared with SVGP-based baselines, satisfies tight spectral residual bounds with theoretically guaranteed OoD detection, and significantly compresses the neural network's storage requirements at the cost of increased inference computation dependent on the number of inducing weights employed. Specifically, in a comprehensive empirical study spanning regression, image classification, semantic segmentation, and out-of-distribution detection benchmarks, it cuts Bayesian training cost by several orders of magnitude, compresses parameters by roughly 51%, reduces model size by about 75%, and matches state-of-the-art accuracy and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>725, <a href='https://arxiv.org/pdf/2509.12772.pdf' target='_blank'>https://arxiv.org/pdf/2509.12772.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Damola Agbelese, Krishna Chaitanya, Pushpak Pati, Chaitanya Parmar, Pooya Mobadersany, Shreyas Fadnavis, Lindsey Surace, Shadi Yarandi, Louis R. Ghanem, Molly Lucas, Tommaso Mansi, Oana Gabriela Cula, Pablo F. Damasceno, Kristopher Standish
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12772">MEGAN: Mixture of Experts for Robust Uncertainty Estimation in Endoscopy Videos</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty quantification (UQ) is essential in medical AI. Evidential Deep Learning (EDL) offers a computationally efficient way to quantify model uncertainty alongside predictions, unlike traditional methods such as Monte Carlo (MC) Dropout and Deep Ensembles (DE). However, all these methods often rely on a single expert's annotations as ground truth for model training, overlooking the inter-rater variability in healthcare. To address this issue, we propose MEGAN, a Multi-Expert Gating Network that aggregates uncertainty estimates and predictions from multiple AI experts via EDL models trained with diverse ground truths and modeling strategies. MEGAN's gating network optimally combines predictions and uncertainties from each EDL model, enhancing overall prediction confidence and calibration. We extensively benchmark MEGAN on endoscopy videos for Ulcerative colitis (UC) disease severity estimation, assessed by visual labeling of Mayo Endoscopic Subscore (MES), where inter-rater variability is prevalent. In large-scale prospective UC clinical trial, MEGAN achieved a 3.5% improvement in F1-score and a 30.5% reduction in Expected Calibration Error (ECE) compared to existing methods. Furthermore, MEGAN facilitated uncertainty-guided sample stratification, reducing the annotation burden and potentially increasing efficiency and consistency in UC trials.
<div id='section'>Paperid: <span id='pid'>726, <a href='https://arxiv.org/pdf/2509.12329.pdf' target='_blank'>https://arxiv.org/pdf/2509.12329.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengjie Kris Liu, Siqin Wang, Lu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12329">Uncertainty-Aware Hourly Air Temperature Mapping at 2 km Resolution via Physics-Guided Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Near-surface air temperature is a key physical property of the Earth's surface. Although weather stations offer continuous monitoring and satellites provide broad spatial coverage, no single data source offers seamless data in a spatiotemporal fashion. Here, we propose a data-driven, physics-guided deep learning approach to generate hourly air temperature data at 2 km resolution over the contiguous United States. The approach, called Amplifier Air-Transformer, first reconstructs GOES-16 surface temperature data obscured by clouds. It does so through a neural network encoded with the annual temperature cycle, incorporating a linear term to amplify ERA5 temperature values at finer scales and convolutional layers to capture spatiotemporal variations. Then, another neural network transforms the reconstructed surface temperature into air temperature by leveraging its latent relationship with key Earth surface properties. The approach is further enhanced with predictive uncertainty estimation through deep ensemble learning to improve reliability. The proposed approach is built and tested on 77.7 billion surface temperature pixels and 155 million air temperature records from weather stations across the contiguous United States (2018-2024), achieving hourly air temperature mapping accuracy of 1.93 C in station-based validation. The proposed approach streamlines surface temperature reconstruction and air temperature prediction, and it can be extended to other satellite sources for seamless air temperature monitoring at high spatiotemporal resolution. The generated data of this study can be downloaded at https://doi.org/10.5281/zenodo.15252812, and the project webpage can be found at https://skrisliu.com/HourlyAirTemp2kmUSA/.
<div id='section'>Paperid: <span id='pid'>727, <a href='https://arxiv.org/pdf/2509.10914.pdf' target='_blank'>https://arxiv.org/pdf/2509.10914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Somayeh Kianpisheh, Tarik Taleb, Jari Iinatti, JaeSeung Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10914">Deep Learning based Moving Target Defence for Federated Learning against Poisoning Attack in MEC Systems with a 6G Wireless Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Collaboration opportunities for devices are facilitated with Federated Learning (FL). Edge computing facilitates aggregation at edge and reduces latency. To deal with model poisoning attacks, model-based outlier detection mechanisms may not operate efficiently with hetereogenous models or in recognition of complex attacks. This paper fosters the defense line against model poisoning attack by exploiting device-level traffic analysis to anticipate the reliability of participants. FL is empowered with a topology mutation strategy, as a Moving Target Defence (MTD) strategy to dynamically change the participants in learning. Based on the adoption of recurrent neural networks for time-series analysis of traffic and a 6G wireless model, optimization framework for MTD strategy is given. A deep reinforcement mechanism is provided to optimize topology mutation in adaption with the anticipated Byzantine status of devices and the communication channel capabilities at devices. For a DDoS attack detection application and under Botnet attack at devices level, results illustrate acceptable malicious models exclusion and improvement in recognition time and accuracy.
<div id='section'>Paperid: <span id='pid'>728, <a href='https://arxiv.org/pdf/2509.01476.pdf' target='_blank'>https://arxiv.org/pdf/2509.01476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youchao Zhou, Heyan Huang, Yicheng Liu, Rui Dai, Xinglin Wang, Xingchen Zhang, Shumin Shi, Yang Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01476">Do Retrieval Augmented Language Models Know When They Don't Know?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing large language models (LLMs) occasionally generate plausible yet factually incorrect responses, known as hallucinations. Two main approaches have been proposed to mitigate hallucinations: retrieval-augmented language models (RALMs) and refusal post-training. However, current research predominantly focuses on their individual effectiveness while overlooking the evaluation of the refusal capability of RALMs. Ideally, if RALMs know when they do not know, they should refuse to answer.In this study, we ask the fundamental question: Do RALMs know when they don't know? Specifically, we investigate three questions. First, are RALMs well calibrated with respect to different internal and external knowledge states? We examine the influence of various factors. Contrary to expectations, when all retrieved documents are irrelevant, RALMs still tend to refuse questions they could have answered correctly. Next, given the model's pronounced \textbf{over-refusal} behavior, we raise a second question: How does a RALM's refusal ability align with its calibration quality? Our results show that the over-refusal problem can be mitigated through in-context fine-tuning. However, we observe that improved refusal behavior does not necessarily imply better calibration or higher overall accuracy. Finally, we ask: Can we combine refusal-aware RALMs with uncertainty-based answer abstention to mitigate over-refusal? We develop a simple yet effective refusal mechanism for refusal-post-trained RALMs that improves their overall answer quality by balancing refusal and correct answers. Our study provides a more comprehensive understanding of the factors influencing RALM behavior. Meanwhile, we emphasize that uncertainty estimation for RALMs remains an open problem deserving deeper investigation.
<div id='section'>Paperid: <span id='pid'>729, <a href='https://arxiv.org/pdf/2506.15850.pdf' target='_blank'>https://arxiv.org/pdf/2506.15850.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Mendes, Paolo Romano, David Garlan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15850">Uncertainty Estimation by Human Perception versus Neural Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern neural networks (NNs) often achieve high predictive accuracy but are poorly calibrated, producing overconfident predictions even when wrong. This miscalibration poses serious challenges in applications where reliable uncertainty estimates are critical. In this work, we investigate how human perceptual uncertainty compares to uncertainty estimated by NNs. Using three vision benchmarks annotated with both human disagreement and crowdsourced confidence, we assess the correlation between model-predicted uncertainty and human-perceived uncertainty. Our results show that current methods only weakly align with human intuition, with correlations varying significantly across tasks and uncertainty metrics. Notably, we find that incorporating human-derived soft labels into the training process can improve calibration without compromising accuracy. These findings reveal a persistent gap between model and human uncertainty and highlight the potential of leveraging human insights to guide the development of more trustworthy AI systems.
<div id='section'>Paperid: <span id='pid'>730, <a href='https://arxiv.org/pdf/2506.15518.pdf' target='_blank'>https://arxiv.org/pdf/2506.15518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giulio Delama, Igor Borowski, Roland Jung, Stephan Weiss
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15518">Real-Time Initialization of Unknown Anchors for UWB-aided Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a framework for the real-time initialization of unknown Ultra-Wideband (UWB) anchors in UWB-aided navigation systems. The method is designed for localization solutions where UWB modules act as supplementary sensors. Our approach enables the automatic detection and calibration of previously unknown anchors during operation, removing the need for manual setup. By combining an online Positional Dilution of Precision (PDOP) estimation, a lightweight outlier detection method, and an adaptive robust kernel for non-linear optimization, our approach significantly improves robustness and suitability for real-world applications compared to state-of-the-art. In particular, we show that our metric which triggers an initialization decision is more conservative than current ones commonly based on initial linear or non-linear initialization guesses. This allows for better initialization geometry and subsequently lower initialization errors. We demonstrate the proposed approach on two different mobile robots: an autonomous forklift and a quadcopter equipped with a UWB-aided Visual-Inertial Odometry (VIO) framework. The results highlight the effectiveness of the proposed method with robust initialization and low positioning error. We open-source our code in a C++ library including a ROS wrapper.
<div id='section'>Paperid: <span id='pid'>731, <a href='https://arxiv.org/pdf/2506.10770.pdf' target='_blank'>https://arxiv.org/pdf/2506.10770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joran Leest, Claudia Raibulet, Patricia Lago, Ilias Gerostathopoulos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10770">From Tea Leaves to System Maps: A Survey and Framework on Context-aware Machine Learning Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) models in production fail when their broader systems -- from data pipelines to deployment environments -- deviate from training assumptions, not merely due to statistical anomalies in input data. Despite extensive work on data drift, data validation, and out-of-distribution detection, ML monitoring research remains largely model-centric while neglecting contextual information: auxiliary signals about the system around the model (external factors, data pipelines, downstream applications). Incorporating this context turns statistical anomalies into actionable alerts and structured root-cause analysis. Drawing on a systematic review of 94 primary studies, we identify three dimensions of contextual information for ML monitoring: the system element concerned (natural environment or technical infrastructure); the aspect of that element (runtime states, structural relationships, prescriptive properties); and the representation used (formal constructs or informal formats). This forms the Contextual System-Aspect-Representation (C-SAR) framework, a descriptive model synthesizing our findings. We identify 20 recurring triplets across these dimensions and map them to the monitoring activities they support. This study provides a holistic perspective on ML monitoring: from interpreting "tea leaves" (i.e., isolated data and performance statistics) to constructing and managing "system maps" (i.e., end-to-end views that connect data, models, and operating context).
<div id='section'>Paperid: <span id='pid'>732, <a href='https://arxiv.org/pdf/2505.22803.pdf' target='_blank'>https://arxiv.org/pdf/2505.22803.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Mendes, Paolo Romano, David Garlan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22803">CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation is critical for deploying neural networks (NNs) in real-world applications. While existing calibration techniques often rely on post-hoc adjustments or coarse-grained binning methods, they remain limited in scalability, differentiability, and generalization across domains. In this work, we introduce CLUE (Calibration via Learning Uncertainty-Error Alignment), a novel approach that explicitly aligns predicted uncertainty with observed error during training, grounded in the principle that well-calibrated models should produce uncertainty estimates that match their empirical loss. CLUE adopts a novel loss function that jointly optimizes predictive performance and calibration, using summary statistics of uncertainty and loss as proxies. The proposed method is fully differentiable, domain-agnostic, and compatible with standard training pipelines. Through extensive experiments on vision, regression, and language modeling tasks, including out-of-distribution and domain-shift scenarios, we demonstrate that CLUE achieves superior calibration quality and competitive predictive performance with respect to state-of-the-art approaches without imposing significant computational overhead.
<div id='section'>Paperid: <span id='pid'>733, <a href='https://arxiv.org/pdf/2504.07522.pdf' target='_blank'>https://arxiv.org/pdf/2504.07522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Cribeiro-Ramallo, Federico Matteucci, Paul Enciu, Alexander Jenke, Vadim Arzamasov, Thorsten Strufe, Klemens BÃ¶hm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07522">Adversarial Subspace Generation for Outlier Detection in High-Dimensional Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection in high-dimensional tabular data is challenging since data is often distributed across multiple lower-dimensional subspaces -- a phenomenon known as the Multiple Views effect (MV). This effect led to a large body of research focused on mining such subspaces, known as subspace selection. However, as the precise nature of the MV effect was not well understood, traditional methods had to rely on heuristic-driven search schemes that struggle to accurately capture the true structure of the data. Properly identifying these subspaces is critical for unsupervised tasks such as outlier detection or clustering, where misrepresenting the underlying data structure can hinder the performance. We introduce Myopic Subspace Theory (MST), a new theoretical framework that mathematically formulates the Multiple Views effect and writes subspace selection as a stochastic optimization problem. Based on MST, we introduce V-GAN, a generative method trained to solve such an optimization problem. This approach avoids any exhaustive search over the feature space while ensuring that the intrinsic data structure is preserved. Experiments on 42 real-world datasets show that using V-GAN subspaces to build ensemble methods leads to a significant increase in one-class classification performance -- compared to existing subspace selection, feature selection, and embedding methods. Further experiments on synthetic data show that V-GAN identifies subspaces more accurately while scaling better than other relevant subspace selection methods. These results confirm the theoretical guarantees of our approach and also highlight its practical viability in high-dimensional settings.
<div id='section'>Paperid: <span id='pid'>734, <a href='https://arxiv.org/pdf/2504.02606.pdf' target='_blank'>https://arxiv.org/pdf/2504.02606.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas Teufel, Annika Leinweber, Pascal Friederich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02606">Improving Counterfactual Truthfulness for Molecular Property Prediction through Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explainable AI (xAI) interventions aim to improve interpretability for complex black-box models, not only to improve user trust but also as a means to extract scientific insights from high-performing predictive systems. In molecular property prediction, counterfactual explanations offer a way to understand predictive behavior by highlighting which minimal perturbations in the input molecular structure cause the greatest deviation in the predicted property. However, such explanations only allow for meaningful scientific insights if they reflect the distribution of the true underlying property -- a feature we define as counterfactual truthfulness. To increase this truthfulness, we propose the integration of uncertainty estimation techniques to filter counterfactual candidates with high predicted uncertainty. Through computational experiments with synthetic and real-world datasets, we demonstrate that traditional uncertainty estimation methods, such as ensembles and mean-variance estimation, can already substantially reduce the average prediction error and increase counterfactual truthfulness, especially for out-of-distribution settings. Our results highlight the importance and potential impact of incorporating uncertainty estimation into explainability methods, especially considering the relatively high effectiveness of low-effort interventions like model ensembles.
<div id='section'>Paperid: <span id='pid'>735, <a href='https://arxiv.org/pdf/2504.00429.pdf' target='_blank'>https://arxiv.org/pdf/2504.00429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinghe Zhang, Chi Liu, Shuai Zhou, Sheng Shen, Peng Gui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.00429">Unleashing the Power of Pre-trained Encoders for Universal Adversarial Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adversarial attacks pose a critical security threat to real-world AI systems by injecting human-imperceptible perturbations into benign samples to induce misclassification in deep learning models. While existing detection methods, such as Bayesian uncertainty estimation and activation pattern analysis, have achieved progress through feature engineering, their reliance on handcrafted feature design and prior knowledge of attack patterns limits generalization capabilities and incurs high engineering costs. To address these limitations, this paper proposes a lightweight adversarial detection framework based on the large-scale pre-trained vision-language model CLIP. Departing from conventional adversarial feature characterization paradigms, we innovatively adopt an anomaly detection perspective. By jointly fine-tuning CLIP's dual visual-text encoders with trainable adapter networks and learnable prompts, we construct a compact representation space tailored for natural images. Notably, our detection architecture achieves substantial improvements in generalization capability across both known and unknown attack patterns compared to traditional methods, while significantly reducing training overhead. This study provides a novel technical pathway for establishing a parameter-efficient and attack-agnostic defense paradigm, markedly enhancing the robustness of vision systems against evolving adversarial threats.
<div id='section'>Paperid: <span id='pid'>736, <a href='https://arxiv.org/pdf/2503.14002.pdf' target='_blank'>https://arxiv.org/pdf/2503.14002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Damian Boborzi, Phillip Mueller, Jonas Emrich, Dominik Schmid, Sebastian Mueller, Lars Mikelsons
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14002">MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models have recently made remarkable progress in the field of 3D objects. However, their practical application in fields like engineering remains limited since they fail to deliver the accuracy, quality, and controllability needed for domain-specific tasks. Fine-tuning large generative models is a promising perspective for making these models available in these fields. Creating high-quality, domain-specific 3D datasets is crucial for fine-tuning large generative models, yet the data filtering and annotation process remains a significant bottleneck. We present MeshFleet, a filtered and annotated 3D vehicle dataset extracted from Objaverse-XL, the most extensive publicly available collection of 3D objects. Our approach proposes a pipeline for automated data filtering based on a quality classifier. This classifier is trained on a manually labeled subset of Objaverse, incorporating DINOv2 and SigLIP embeddings, refined through caption-based analysis and uncertainty estimation. We demonstrate the efficacy of our filtering method through a comparative analysis against caption and image aesthetic score-based techniques and fine-tuning experiments with SV3D, highlighting the importance of targeted data selection for domain-specific 3D generative modeling.
<div id='section'>Paperid: <span id='pid'>737, <a href='https://arxiv.org/pdf/2503.05238.pdf' target='_blank'>https://arxiv.org/pdf/2503.05238.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohit Prashant, Arvind Easwaran, Suman Das, Michael Yuhas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05238">Guaranteeing Out-Of-Distribution Detection in Deep RL via Transition Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An issue concerning the use of deep reinforcement learning (RL) agents is whether they can be trusted to perform reliably when deployed, as training environments may not reflect real-life environments. Anticipating instances outside their training scope, learning-enabled systems are often equipped with out-of-distribution (OOD) detectors that alert when a trained system encounters a state it does not recognize or in which it exhibits uncertainty. There exists limited work conducted on the problem of OOD detection within RL, with prior studies being unable to achieve a consensus on the definition of OOD execution within the context of RL. By framing our problem using a Markov Decision Process, we assume there is a transition distribution mapping each state-action pair to another state with some probability. Based on this, we consider the following definition of OOD execution within RL: A transition is OOD if its probability during real-life deployment differs from the transition distribution encountered during training. As such, we utilize conditional variational autoencoders (CVAE) to approximate the transition dynamics of the training environment and implement a conformity-based detector using reconstruction loss that is able to guarantee OOD detection with a pre-determined confidence level. We evaluate our detector by adapting existing benchmarks and compare it with existing OOD detection models for RL.
<div id='section'>Paperid: <span id='pid'>738, <a href='https://arxiv.org/pdf/2503.00172.pdf' target='_blank'>https://arxiv.org/pdf/2503.00172.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiqiu Xia, Jinxuan Xu, Yuqian Zhang, Hang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00172">A Survey of Uncertainty Estimation Methods on Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have demonstrated remarkable capabilities across various tasks. However, these models could offer biased, hallucinated, or non-factual responses camouflaged by their fluency and realistic appearance. Uncertainty estimation is the key method to address this challenge. While research efforts in uncertainty estimation are ramping up, there is a lack of comprehensive and dedicated surveys on LLM uncertainty estimation. This survey presents four major avenues of LLM uncertainty estimation. Furthermore, we perform extensive experimental evaluations across multiple methods and datasets. At last, we provide critical and promising future directions for LLM uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>739, <a href='https://arxiv.org/pdf/2502.11864.pdf' target='_blank'>https://arxiv.org/pdf/2502.11864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Natalie Grabowsky, Annika MÃ¼tze, Joshua Wendland, Nils Jansen, Matthias Rottmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11864">Does Knowledge About Perceptual Uncertainty Help an Agent in Automated Driving?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Agents in real-world scenarios like automated driving deal with uncertainty in their environment, in particular due to perceptual uncertainty. Although, reinforcement learning is dedicated to autonomous decision-making under uncertainty these algorithms are typically not informed about the uncertainty currently contained in their environment. On the other hand, uncertainty estimation for perception itself is typically directly evaluated in the perception domain, e.g., in terms of false positive detection rates or calibration errors based on camera images. Its use for deciding on goal-oriented actions remains largely unstudied. In this paper, we investigate how an agent's behavior is influenced by an uncertain perception and how this behavior changes if information about this uncertainty is available. Therefore, we consider a proxy task, where the agent is rewarded for driving a route as fast as possible without colliding with other road users. For controlled experiments, we introduce uncertainty in the observation space by perturbing the perception of the given agent while informing the latter. Our experiments show that an unreliable observation space modeled by a perturbed perception leads to a defensive driving behavior of the agent. Furthermore, when adding the information about the current uncertainty directly to the observation space, the agent adapts to the specific situation and in general accomplishes its task faster while, at the same time, accounting for risks.
<div id='section'>Paperid: <span id='pid'>740, <a href='https://arxiv.org/pdf/2502.04807.pdf' target='_blank'>https://arxiv.org/pdf/2502.04807.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meshi Bashari, Matteo Sesia, Yaniv Romano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04807">Robust Conformal Outlier Detection under Contaminated Reference Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformal prediction is a flexible framework for calibrating machine learning predictions, providing distribution-free statistical guarantees. In outlier detection, this calibration relies on a reference set of labeled inlier data to control the type-I error rate. However, obtaining a perfectly labeled inlier reference set is often unrealistic, and a more practical scenario involves access to a contaminated reference set containing a small fraction of outliers. This paper analyzes the impact of such contamination on the validity of conformal methods. We prove that under realistic, non-adversarial settings, calibration on contaminated data yields conservative type-I error control, shedding light on the inherent robustness of conformal methods. This conservativeness, however, typically results in a loss of power. To alleviate this limitation, we propose a novel, active data-cleaning framework that leverages a limited labeling budget and an outlier detection model to selectively annotate data points in the contaminated reference set that are suspected as outliers. By removing only the annotated outliers in this ``suspicious'' subset, we can effectively enhance power while mitigating the risk of inflating the type-I error rate, as supported by our theoretical analysis. Experiments on real datasets validate the conservative behavior of conformal methods under contamination and show that the proposed data-cleaning strategy improves power without sacrificing validity.
<div id='section'>Paperid: <span id='pid'>741, <a href='https://arxiv.org/pdf/2502.04126.pdf' target='_blank'>https://arxiv.org/pdf/2502.04126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alejandro AntÃ³n Ruiz, John Kvarnstrand, Klas Arvidsson, AndrÃ©s AlayÃ³n Glazunov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04126">RC Measurement Uncertainty Estimation Method for Directive Antennas and Turntable Stirring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates measurement uncertainty in a Reverberation Chamber (RC) within the lower FR2 bands (24.25-29.5 GHz). The study focuses on the impact of several factors contributing to RC measurement uncertainty, including finite sample size, polarization imbalance, and spatial non-uniformity. A series of 24 measurements were conducted using a horn antenna, known for its directivity in mmWave frequencies, varying antenna parameters such as height, orientation, position on the turntable, and polarization within a predefined chamber volume. The measurement uncertainty was evaluated by a method based on the standardized 3GPP and CTIA approaches, incorporating uncorrelated measurements and analyzing Pearson correlation coefficients between measurement pairs. An analysis of variance (ANOVA) was performed on the frequency-averaged power transfer function to identify the significance and impact of each variable on measurement variability. Additionally, the K-factor was estimated for each measurement set as part of the RC characterization, using an alternative approach to account for the turntable stirring effect. The findings highlight which variables most significantly influence measurement uncertainty, where the antenna orientation emerges as the most significant factor for the mmWave directive antenna setup.
<div id='section'>Paperid: <span id='pid'>742, <a href='https://arxiv.org/pdf/2412.16409.pdf' target='_blank'>https://arxiv.org/pdf/2412.16409.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda S. Rios, Ibrahima J. Ndiour, Parual Datta, Jaroslaw Sydir, Omesh Tickoo, Nilesh Ahuja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16409">Uncertainty Quantification in Continual Open-World Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI deployed in the real-world should be capable of autonomously adapting to novelties encountered after deployment. Yet, in the field of continual learning, the reliance on novelty and labeling oracles is commonplace albeit unrealistic. This paper addresses a challenging and under-explored problem: a deployed AI agent that continuously encounters unlabeled data - which may include both unseen samples of known classes and samples from novel (unknown) classes - and must adapt to it continuously. To tackle this challenge, we propose our method COUQ "Continual Open-world Uncertainty Quantification", an iterative uncertainty estimation algorithm tailored for learning in generalized continual open-world multi-class settings. We rigorously apply and evaluate COUQ on key sub-tasks in the Continual Open-World: continual novelty detection, uncertainty guided active learning, and uncertainty guided pseudo-labeling for semi-supervised CL. We demonstrate the effectiveness of our method across multiple datasets, ablations, backbones and performance superior to state-of-the-art.
<div id='section'>Paperid: <span id='pid'>743, <a href='https://arxiv.org/pdf/2412.10473.pdf' target='_blank'>https://arxiv.org/pdf/2412.10473.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda Rios, Ibrahima Ndiour, Parual Datta, Omesh Tickoo, Nilesh Ahuja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.10473">CONCLAD: COntinuous Novel CLAss Detector</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of continual learning, relying on so-called oracles for novelty detection is commonplace albeit unrealistic. This paper introduces CONCLAD ("COntinuous Novel CLAss Detector"), a comprehensive solution to the under-explored problem of continual novel class detection in post-deployment data. At each new task, our approach employs an iterative uncertainty estimation algorithm to differentiate between known and novel class(es) samples, and to further discriminate between the different novel classes themselves. Samples predicted to be from a novel class with high-confidence are automatically pseudo-labeled and used to update our model. Simultaneously, a tiny supervision budget is used to iteratively query ambiguous novel class predictions, which are also used during update. Evaluation across multiple datasets, ablations and experimental settings demonstrate our method's effectiveness at separating novel and old class samples continuously. We will release our code upon acceptance.
<div id='section'>Paperid: <span id='pid'>744, <a href='https://arxiv.org/pdf/2412.09701.pdf' target='_blank'>https://arxiv.org/pdf/2412.09701.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda Rios, Ibrahima Ndiour, Parual Datta, Jerry Sydir, Omesh Tickoo, Nilesh Ahuja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09701">CUAL: Continual Uncertainty-aware Active Learner</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI deployed in many real-world use cases should be capable of adapting to novelties encountered after deployment. Here, we consider a challenging, under-explored and realistic continual adaptation problem: a deployed AI agent is continuously provided with unlabeled data that may contain not only unseen samples of known classes but also samples from novel (unknown) classes. In such a challenging setting, it has only a tiny labeling budget to query the most informative samples to help it continuously learn. We present a comprehensive solution to this complex problem with our model "CUAL" (Continual Uncertainty-aware Active Learner). CUAL leverages an uncertainty estimation algorithm to prioritize active labeling of ambiguous (uncertain) predicted novel class samples while also simultaneously pseudo-labeling the most certain predictions of each class. Evaluations across multiple datasets, ablations, settings and backbones (e.g. ViT foundation model) demonstrate our method's effectiveness. We will release our code upon acceptance.
<div id='section'>Paperid: <span id='pid'>745, <a href='https://arxiv.org/pdf/2412.01705.pdf' target='_blank'>https://arxiv.org/pdf/2412.01705.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anuja Vats, Ivar Farup, Marius Pedersen, Kiran Raja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01705">Uncertainty-Aware Regularization for Image-to-Image Translation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The importance of quantifying uncertainty in deep networks has become paramount for reliable real-world applications. In this paper, we propose a method to improve uncertainty estimation in medical Image-to-Image (I2I) translation. Our model integrates aleatoric uncertainty and employs Uncertainty-Aware Regularization (UAR) inspired by simple priors to refine uncertainty estimates and enhance reconstruction quality. We show that by leveraging simple priors on parameters, our approach captures more robust uncertainty maps, effectively refining them to indicate precisely where the network encounters difficulties, while being less affected by noise. Our experiments demonstrate that UAR not only improves translation performance, but also provides better uncertainty estimations, particularly in the presence of noise and artifacts. We validate our approach using two medical imaging datasets, showcasing its effectiveness in maintaining high confidence in familiar regions while accurately identifying areas of uncertainty in novel/ambiguous scenarios.
<div id='section'>Paperid: <span id='pid'>746, <a href='https://arxiv.org/pdf/2411.04562.pdf' target='_blank'>https://arxiv.org/pdf/2411.04562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marvin Alles, Philip Becker-Ehmck, Patrick van der Smagt, Maximilian Karl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04562">Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In offline reinforcement learning, a policy is learned using a static dataset in the absence of costly feedback from the environment. In contrast to the online setting, only using static datasets poses additional challenges, such as policies generating out-of-distribution samples. Model-based offline reinforcement learning methods try to overcome these by learning a model of the underlying dynamics of the environment and using it to guide policy search. It is beneficial but, with limited datasets, errors in the model and the issue of value overestimation among out-of-distribution states can worsen performance. Current model-based methods apply some notion of conservatism to the Bellman update, often implemented using uncertainty estimation derived from model ensembles. In this paper, we propose Constrained Latent Action Policies (C-LAP) which learns a generative model of the joint distribution of observations and actions. We cast policy learning as a constrained objective to always stay within the support of the latent action distribution, and use the generative capabilities of the model to impose an implicit constraint on the generated actions. Thereby eliminating the need to use additional uncertainty penalties on the Bellman update and significantly decreasing the number of gradient steps required to learn a policy. We empirically evaluate C-LAP on the D4RL and V-D4RL benchmark, and show that C-LAP is competitive to state-of-the-art methods, especially outperforming on datasets with visual observations.
<div id='section'>Paperid: <span id='pid'>747, <a href='https://arxiv.org/pdf/2411.01487.pdf' target='_blank'>https://arxiv.org/pdf/2411.01487.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyao Geng, Yuan Zhang, Jiaqi Huang, Feng Xue, Falong Tan, Chuanlong Xie, Shumei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01487">DSDE: Using Proportion Estimation to Improve Model Selection for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model library is an effective tool for improving the performance of single-model Out-of-Distribution (OoD) detector, mainly through model selection and detector fusion. However, existing methods in the literature do not provide uncertainty quantification for model selection results. Additionally, the model ensemble process primarily focuses on controlling the True Positive Rate (TPR) while neglecting the False Positive Rate (FPR). In this paper, we emphasize the significance of the proportion of models in the library that identify the test sample as an OoD sample. This proportion holds crucial information and directly influences the error rate of OoD detection.To address this, we propose inverting the commonly-used sequential p-value strategies. We define the rejection region initially and then estimate the error rate. Furthermore, we introduce a novel perspective from change-point detection and propose an approach for proportion estimation with automatic hyperparameter selection. We name the proposed approach as DOS-Storey-based Detector Ensemble (DSDE). Experimental results on CIFAR10 and CIFAR100 demonstrate the effectiveness of our approach in tackling OoD detection challenges. Specifically, the CIFAR10 experiments show that DSDE reduces the FPR from 11.07% to 3.31% compared to the top-performing single-model detector.
<div id='section'>Paperid: <span id='pid'>748, <a href='https://arxiv.org/pdf/2410.23272.pdf' target='_blank'>https://arxiv.org/pdf/2410.23272.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qidong Yang, Weicheng Zhu, Joseph Keslin, Laure Zanna, Tim G. J. Rudner, Carlos Fernandez-Granda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.23272">A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Probabilistic prediction of sequences from images and other high-dimensional data is a key challenge, particularly in risk-sensitive applications. In these settings, it is often desirable to quantify the uncertainty associated with the prediction (instead of just determining the most likely sequence, as in language modeling). In this paper, we propose a Monte Carlo framework to estimate probabilities and confidence intervals associated with the distribution of a discrete sequence. Our framework uses a Monte Carlo simulator, implemented as an autoregressively trained neural network, to sample sequences conditioned on an image input. We then use these samples to estimate the probabilities and confidence intervals. Experiments on synthetic and real data show that the framework produces accurate discriminative predictions, but can suffer from miscalibration. In order to address this shortcoming, we propose a time-dependent regularization method, which is shown to produce calibrated predictions.
<div id='section'>Paperid: <span id='pid'>749, <a href='https://arxiv.org/pdf/2409.17758.pdf' target='_blank'>https://arxiv.org/pdf/2409.17758.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Thel, Lars Greve, Maximilian Karl, Patrick van der Smagt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17758">Adapting Deep Variational Bayes Filter for Enhanced Confidence Estimation in Finite Element Method Integrated Networks (FEMIN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Finite Element Method (FEM) is a widely used technique for simulating crash scenarios with high accuracy and reliability. To reduce the significant computational costs associated with FEM, the Finite Element Method Integrated Networks (FEMIN) framework integrates neural networks (NNs) with FEM solvers. However, this integration can introduce errors and deviations from full-FEM simulations, highlighting the need for an additional metric to assess prediction confidence, especially when no ground truth data is available. In this study, we adapt the Deep Variational Bayes Filter (DVBF) to the FEMIN framework, incorporating a probabilistic approach to provide qualitative insights into prediction confidence during FEMIN simulations. The adaptation involves using the learned transition model for a predictive decoding step, generating a preliminary force prediction. This predictive force is used alongside the displacement and the velocity data from the FEM solver as input for the encoder model. The decoder reconstructs the likelihood distribution based on the posterior. The mean force of this distribution is applied to the FEM solver, while the predicted standard deviation can be used for uncertainty estimation. Our findings demonstrate that the DVBF outperforms deterministic NN architectures in terms of accuracy. Furthermore, the standard deviation derived from the decoder serves as a valuable qualitative metric for assessing the confidence in FEMIN simulations. This approach enhances the robustness of FEMIN by providing a measure of reliability alongside the simulation results.
<div id='section'>Paperid: <span id='pid'>750, <a href='https://arxiv.org/pdf/2409.12426.pdf' target='_blank'>https://arxiv.org/pdf/2409.12426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Liu, Jiaqi Zhu, Guirong Zhuo, Wufei Fu, Zonglin Meng, Yishi Lu, Min Hua, Feng Qiao, You Li, Yi He, Lu Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.12426">UniMSF: A Unified Multi-Sensor Fusion Framework for Intelligent Transportation System Global Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intelligent transportation systems (ITS) localization is of significant importance as it provides fundamental position and orientation for autonomous operations like intelligent vehicles. Integrating diverse and complementary sensors such as global navigation satellite system (GNSS) and 4D-radar can provide scalable and reliable global localization. Nevertheless, multi-sensor fusion encounters challenges including heterogeneity and time-varying uncertainty in measurements. Consequently, developing a reliable and unified multi-sensor framework remains challenging. In this paper, we introduce UniMSF, a comprehensive multi-sensor fusion localization framework for ITS, utilizing factor graphs. By integrating a multi-sensor fusion front-end, alongside outlier detection\&noise model estimation, and a factor graph optimization back-end, this framework accomplishes efficient fusion and ensures accurate localization for ITS. Specifically, in the multi-sensor fusion front-end module, we tackle the measurement heterogeneity among different modality sensors and establish effective measurement models. Reliable outlier detection and data-driven online noise estimation methods ensure that back-end optimization is immune to interference from outlier measurements. In addition, integrating multi-sensor observations via factor graph optimization offers the advantage of \enquote{plug and play}. Notably, our framework features high modularity and is seamlessly adapted to various sensor configurations. We demonstrate the effectiveness of the proposed framework through real vehicle tests by tightly integrating GNSS pseudorange and carrier phase information with IMU, and 4D-radar.
<div id='section'>Paperid: <span id='pid'>751, <a href='https://arxiv.org/pdf/2409.04720.pdf' target='_blank'>https://arxiv.org/pdf/2409.04720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyu Gao, Mengyuan Chen, Liangyu Xiang, Changsheng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04720">A Comprehensive Survey on Evidential Deep Learning and Its Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation has become a crucial requirement for the industrial deployment of deep learning algorithms, particularly in high-risk applications such as autonomous driving and medical diagnosis. However, mainstream uncertainty estimation methods, based on deep ensembling or Bayesian neural networks, generally impose substantial computational overhead. To address this challenge, a novel paradigm called Evidential Deep Learning (EDL) has emerged, providing reliable uncertainty estimation with minimal additional computation in a single forward pass. This survey provides a comprehensive overview of the current research on EDL, designed to offer readers a broad introduction to the field without assuming prior knowledge. Specifically, we first delve into the theoretical foundation of EDL, the subjective logic theory, and discuss its distinctions from other uncertainty estimation frameworks. We further present existing theoretical advancements in EDL from four perspectives: reformulating the evidence collection process, improving uncertainty estimation via OOD samples, delving into various training strategies, and evidential regression networks. Thereafter, we elaborate on its extensive applications across various machine learning paradigms and downstream tasks. In the end, an outlook on future directions for better performances and broader adoption of EDL is provided, highlighting potential research avenues.
<div id='section'>Paperid: <span id='pid'>752, <a href='https://arxiv.org/pdf/2408.14841.pdf' target='_blank'>https://arxiv.org/pdf/2408.14841.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Suhee Yoon, Sanghyu Yoon, Ye Seul Sim, Sungik Choi, Kyungeun Lee, Hye-Seung Cho, Hankook Lee, Woohyung Lim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14841">Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection, which determines whether a given sample is part of the in-distribution (ID), has recently shown promising results through training with synthetic OOD datasets. Nonetheless, existing methods often produce outliers that are considerably distant from the ID, showing limited efficacy for capturing subtle distinctions between ID and OOD. To address these issues, we propose a novel framework, Semantic Outlier generation via Nuisance Awareness (SONA), which notably produces challenging outliers by directly leveraging pixel-space ID samples through diffusion models. Our approach incorporates SONA guidance, providing separate control over semantic and nuisance regions of ID samples. Thereby, the generated outliers achieve two crucial properties: (i) they present explicit semantic-discrepant information, while (ii) maintaining various levels of nuisance resemblance with ID. Furthermore, the improved OOD detector training with SONA outliers facilitates learning with a focus on semantic distinctions. Extensive experiments demonstrate the effectiveness of our framework, achieving an impressive AUROC of 88% on near-OOD datasets, which surpasses the performance of baseline methods by a significant margin of approximately 6%.
<div id='section'>Paperid: <span id='pid'>753, <a href='https://arxiv.org/pdf/2407.16871.pdf' target='_blank'>https://arxiv.org/pdf/2407.16871.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ratanond Koonchanok, Michael E. Papka, Khairi Reda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16871">Trust Your Gut: Comparing Human and Machine Inference from Noisy Visualizations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>People commonly utilize visualizations not only to examine a given dataset, but also to draw generalizable conclusions about the underlying models or phenomena. Prior research has compared human visual inference to that of an optimal Bayesian agent, with deviations from rational analysis viewed as problematic. However, human reliance on non-normative heuristics may prove advantageous in certain circumstances. We investigate scenarios where human intuition might surpass idealized statistical rationality. In two experiments, we examine individuals' accuracy in characterizing the parameters of known data-generating models from bivariate visualizations. Our findings indicate that, although participants generally exhibited lower accuracy compared to statistical models, they frequently outperformed Bayesian agents, particularly when faced with extreme samples. Participants appeared to rely on their internal models to filter out noisy visualizations, thus improving their resilience against spurious data. However, participants displayed overconfidence and struggled with uncertainty estimation. They also exhibited higher variance than statistical machines. Our findings suggest that analyst gut reactions to visualizations may provide an advantage, even when departing from rationality. These results carry implications for designing visual analytics tools, offering new perspectives on how to integrate statistical models and analyst intuition for improved inference and decision-making. The data and materials for this paper are available at https://osf.io/qmfv6
<div id='section'>Paperid: <span id='pid'>754, <a href='https://arxiv.org/pdf/2407.13553.pdf' target='_blank'>https://arxiv.org/pdf/2407.13553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyue Zhao, Peiqi Li, Xiangde Luo, Meng Yang, Shi Chang, Zhongyu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13553">SAM-Driven Weakly Supervised Nodule Segmentation with Uncertainty-Aware Cross Teaching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated nodule segmentation is essential for computer-assisted diagnosis in ultrasound images. Nevertheless, most existing methods depend on precise pixel-level annotations by medical professionals, a process that is both costly and labor-intensive. Recently, segmentation foundation models like SAM have shown impressive generalizability on natural images, suggesting their potential as pseudo-labelers. However, accurate prompts remain crucial for their success in medical images. In this work, we devise a novel weakly supervised framework that effectively utilizes the segmentation foundation model to generate pseudo-labels from aspect ration annotations for automatic nodule segmentation. Specifically, we develop three types of bounding box prompts based on scalable shape priors, followed by an adaptive pseudo-label selection module to fully exploit the prediction capabilities of the foundation model for nodules. We also present a SAM-driven uncertainty-aware cross-teaching strategy. This approach integrates SAM-based uncertainty estimation and label-space perturbations into cross-teaching to mitigate the impact of pseudo-label inaccuracies on model training. Extensive experiments on two clinically collected ultrasound datasets demonstrate the superior performance of our proposed method.
<div id='section'>Paperid: <span id='pid'>755, <a href='https://arxiv.org/pdf/2407.13307.pdf' target='_blank'>https://arxiv.org/pdf/2407.13307.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anna M. Wundram, Paul Fischer, Michael Muehlebach, Lisa M. Koch, Christian F. Baumgartner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13307">Conformal Performance Range Prediction for Segmentation Output Quality Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent works have introduced methods to estimate segmentation performance without ground truth, relying solely on neural network softmax outputs. These techniques hold potential for intuitive output quality control. However, such performance estimates rely on calibrated softmax outputs, which is often not the case in modern neural networks. Moreover, the estimates do not take into account inherent uncertainty in segmentation tasks. These limitations may render precise performance predictions unattainable, restricting the practical applicability of performance estimation methods. To address these challenges, we develop a novel approach for predicting performance ranges with statistical guarantees of containing the ground truth with a user specified probability. Our method leverages sampling-based segmentation uncertainty estimation to derive heuristic performance ranges, and applies split conformal prediction to transform these estimates into rigorous prediction ranges that meet the desired guarantees. We demonstrate our approach on the FIVES retinal vessel segmentation dataset and compare five commonly used sampling-based uncertainty estimation techniques. Our results show that it is possible to achieve the desired coverage with small prediction ranges, highlighting the potential of performance range prediction as a valuable tool for output quality control.
<div id='section'>Paperid: <span id='pid'>756, <a href='https://arxiv.org/pdf/2407.04248.pdf' target='_blank'>https://arxiv.org/pdf/2407.04248.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhikun Zhang, Yiting Duan, Xiangjun Wang, Mingyuan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04248">Machine Learning for Complex Systems with Abnormal Pattern by Exception Maximization Outlier Detection Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a novel fast online methodology for outlier detection called the exception maximization outlier detection method(EMODM), which employs probabilistic models and statistical algorithms to detect abnormal patterns from the outputs of complex systems. The EMODM is based on a two-state Gaussian mixture model and demonstrates strong performance in probability anomaly detection working on real-time raw data rather than using special prior distribution information. We confirm this using the synthetic data from two numerical cases. For the real-world data, we have detected the short circuit pattern of the circuit system using EMODM by the current and voltage output of a three-phase inverter. The EMODM also found an abnormal period due to COVID-19 in the insured unemployment data of 53 regions in the United States from 2000 to 2024. The application of EMODM to these two real-life datasets demonstrated the effectiveness and accuracy of our algorithm.
<div id='section'>Paperid: <span id='pid'>757, <a href='https://arxiv.org/pdf/2405.19247.pdf' target='_blank'>https://arxiv.org/pdf/2405.19247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuang Qi, Junlin Zhang, Xiaming Chen, Xin Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19247">Comparative Study of Neighbor-based Methods for Local Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The neighbor-based method has become a powerful tool to handle the outlier detection problem, which aims to infer the abnormal degree of the sample based on the compactness of the sample and its neighbors. However, the existing methods commonly focus on designing different processes to locate outliers in the dataset, while the contributions of different types neighbors to outlier detection has not been well discussed. To this end, this paper studies the neighbor in the existing outlier detection algorithms and a taxonomy is introduced, which uses the three-level components of information, neighbor and methodology to define hybrid methods. This taxonomy can serve as a paradigm where a novel neighbor-based outlier detection method can be proposed by combining different components in this taxonomy. A large number of comparative experiments were conducted on synthetic and real-world datasets in terms of performance comparison and case study, and the results show that reverse K-nearest neighbor based methods achieve promising performance and dynamic selection method is suitable for working in high-dimensional space. Notably, it is verified that rationally selecting components from this taxonomy may create an algorithms superior to existing methods.
<div id='section'>Paperid: <span id='pid'>758, <a href='https://arxiv.org/pdf/2405.08766.pdf' target='_blank'>https://arxiv.org/pdf/2405.08766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Claus Hofmann, Simon Schmid, Bernhard Lehner, Daniel Klotz, Sepp Hochreiter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08766">Energy-based Hopfield Boosting for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical when deploying machine learning models in the real world. Outlier exposure methods, which incorporate auxiliary outlier data in the training process, can drastically improve OOD detection performance compared to approaches without advanced training strategies. We introduce Hopfield Boosting, a boosting approach, which leverages modern Hopfield energy (MHE) to sharpen the decision boundary between the in-distribution and OOD data. Hopfield Boosting encourages the model to concentrate on hard-to-distinguish auxiliary outlier examples that lie close to the decision boundary between in-distribution and auxiliary outlier data. Our method achieves a new state-of-the-art in OOD detection with outlier exposure, improving the FPR95 metric from 2.28 to 0.92 on CIFAR-10 and from 11.76 to 7.94 on CIFAR-100.
<div id='section'>Paperid: <span id='pid'>759, <a href='https://arxiv.org/pdf/2405.05286.pdf' target='_blank'>https://arxiv.org/pdf/2405.05286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soyed Tuhin Ahmed, Michael Hefenbrock, Mehdi B. Tahoori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.05286">Tiny Deep Ensemble: Uncertainty Estimation in Edge AI Accelerators via Ensembling Normalization Layers with Shared Weights</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The applications of artificial intelligence (AI) are rapidly evolving, and they are also commonly used in safety-critical domains, such as autonomous driving and medical diagnosis, where functional safety is paramount. In AI-driven systems, uncertainty estimation allows the user to avoid overconfidence predictions and achieve functional safety. Therefore, the robustness and reliability of model predictions can be improved. However, conventional uncertainty estimation methods, such as the deep ensemble method, impose high computation and, accordingly, hardware (latency and energy) overhead because they require the storage and processing of multiple models. Alternatively, Monte Carlo dropout (MC-dropout) methods, although having low memory overhead, necessitate numerous ($\sim 100$) forward passes, leading to high computational overhead and latency. Thus, these approaches are not suitable for battery-powered edge devices with limited computing and memory resources. In this paper, we propose the Tiny-Deep Ensemble approach, a low-cost approach for uncertainty estimation on edge devices. In our approach, only normalization layers are ensembled $M$ times, with all ensemble members sharing common weights and biases, leading to a significant decrease in storage requirements and latency. Moreover, our approach requires only one forward pass in a hardware architecture that allows batch processing for inference and uncertainty estimation. Furthermore, it has approximately the same memory overhead compared to a single model. Therefore, latency and memory overhead are reduced by a factor of up to $\sim M\times$. Nevertheless, our method does not compromise accuracy, with an increase in inference accuracy of up to $\sim 1\%$ and a reduction in RMSE of $17.17\%$ in various benchmark datasets, tasks, and state-of-the-art architectures.
<div id='section'>Paperid: <span id='pid'>760, <a href='https://arxiv.org/pdf/2405.01205.pdf' target='_blank'>https://arxiv.org/pdf/2405.01205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Mendes, Paolo Romano, David Garlan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01205">Error-Driven Uncertainty Aware Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks are often overconfident about their predictions, which undermines their reliability and trustworthiness. In this work, we present a novel technique, named Error-Driven Uncertainty Aware Training (EUAT), which aims to enhance the ability of neural classifiers to estimate their uncertainty correctly, namely to be highly uncertain when they output inaccurate predictions and low uncertain when their output is accurate. The EUAT approach operates during the model's training phase by selectively employing two loss functions depending on whether the training examples are correctly or incorrectly predicted by the model. This allows for pursuing the twofold goal of i) minimizing model uncertainty for correctly predicted inputs and ii) maximizing uncertainty for mispredicted inputs, while preserving the model's misprediction rate. We evaluate EUAT using diverse neural models and datasets in the image recognition domains considering both non-adversarial and adversarial settings. The results show that EUAT outperforms existing approaches for uncertainty estimation (including other uncertainty-aware training techniques, calibration, ensembles, and DEUP) by providing uncertainty estimates that not only have higher quality when evaluated via statistical metrics (e.g., correlation with residuals) but also when employed to build binary classifiers that decide whether the model's output can be trusted or not and under distributional data shifts.
<div id='section'>Paperid: <span id='pid'>761, <a href='https://arxiv.org/pdf/2404.14451.pdf' target='_blank'>https://arxiv.org/pdf/2404.14451.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Cribeiro-Ramallo, Vadim Arzamasov, Federico Matteucci, Denis Wambold, Klemens BÃ¶hm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14451">Generative Subspace Adversarial Active Learning for Outlier Detection in Multiple Views of High-dimensional Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection in high-dimensional tabular data is an important task in data mining, essential for many downstream tasks and applications. Existing unsupervised outlier detection algorithms face one or more problems, including inlier assumption (IA), curse of dimensionality (CD), and multiple views (MV). To address these issues, we introduce Generative Subspace Adversarial Active Learning (GSAAL), a novel approach that uses a Generative Adversarial Network with multiple adversaries. These adversaries learn the marginal class probability functions over different data subspaces, while a single generator in the full space models the entire distribution of the inlier class. GSAAL is specifically designed to address the MV limitation while also handling the IA and CD, being the only method to do so. We provide a comprehensive mathematical formulation of MV, convergence guarantees for the discriminators, and scalability results for GSAAL. Our extensive experiments demonstrate the effectiveness and scalability of GSAAL, highlighting its superior performance compared to other popular OD methods, especially in MV scenarios.
<div id='section'>Paperid: <span id='pid'>762, <a href='https://arxiv.org/pdf/2404.07815.pdf' target='_blank'>https://arxiv.org/pdf/2404.07815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rishabh Ranjan, Saurabh Garg, Mrigank Raman, Carlos Guestrin, Zachary Lipton
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07815">Post-Hoc Reversal: Are We Selecting Models Prematurely?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trained models are often composed with post-hoc transforms such as temperature scaling (TS), ensembling and stochastic weight averaging (SWA) to improve performance, robustness, uncertainty estimation, etc. However, such transforms are typically applied only after the base models have already been finalized by standard means. In this paper, we challenge this practice with an extensive empirical study. In particular, we demonstrate a phenomenon that we call post-hoc reversal, where performance trends are reversed after applying post-hoc transforms. This phenomenon is especially prominent in high-noise settings. For example, while base models overfit badly early in training, both ensembling and SWA favor base models trained for more epochs. Post-hoc reversal can also prevent the appearance of double descent and mitigate mismatches between test loss and test error seen in base models. Preliminary analyses suggest that these transforms induce reversal by suppressing the influence of mislabeled examples, exploiting differences in their learning dynamics from those of clean examples. Based on our findings, we propose post-hoc selection, a simple technique whereby post-hoc metrics inform model development decisions such as early stopping, checkpointing, and broader hyperparameter choices. Our experiments span real-world vision, language, tabular and graph datasets. On an LLM instruction tuning dataset, post-hoc selection results in >1.5x MMLU improvement compared to naive selection.
<div id='section'>Paperid: <span id='pid'>763, <a href='https://arxiv.org/pdf/2404.06421.pdf' target='_blank'>https://arxiv.org/pdf/2404.06421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christian Marius Lillelund, Martin Magris, Christian Fischer Pedersen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06421">Efficient Training of Probabilistic Neural Networks for Survival Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Variational Inference (VI) is a commonly used technique for approximate Bayesian inference and uncertainty estimation in deep learning models, yet it comes at a computational cost, as it doubles the number of trainable parameters to represent uncertainty. This rapidly becomes challenging in high-dimensional settings and motivates the use of alternative techniques for inference, such as Monte Carlo Dropout (MCD) or Spectral-normalized Neural Gaussian Process (SNGP). However, such methods have seen little adoption in survival analysis, and VI remains the prevalent approach for training probabilistic neural networks. In this paper, we investigate how to train deep probabilistic survival models in large datasets without introducing additional overhead in model complexity. To achieve this, we adopt three probabilistic approaches, namely VI, MCD, and SNGP, and evaluate them in terms of their prediction performance, calibration performance, and model complexity. In the context of probabilistic survival analysis, we investigate whether non-VI techniques can offer comparable or possibly improved prediction performance and uncertainty calibration compared to VI. In the MIMIC-IV dataset, we find that MCD aligns with VI in terms of the concordance index (0.748 vs. 0.743) and mean absolute error (254.9 vs. 254.7) using hinge loss, while providing C-calibrated uncertainty estimates. Moreover, our SNGP implementation provides D-calibrated survival functions in all datasets compared to VI (4/4 vs. 2/4, respectively). Our work encourages the use of techniques alternative to VI for survival analysis in high-dimensional datasets, where computational efficiency and overhead are of concern.
<div id='section'>Paperid: <span id='pid'>764, <a href='https://arxiv.org/pdf/2404.02649.pdf' target='_blank'>https://arxiv.org/pdf/2404.02649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>NicolÃ² Felicioni, Lucas Maystre, Sina Ghiassian, Kamil Ciosek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.02649">On the Importance of Uncertainty in Decision-Making with Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate the role of uncertainty in decision-making problems with natural language as input. For such tasks, using Large Language Models as agents has become the norm. However, none of the recent approaches employ any additional phase for estimating the uncertainty the agent has about the world during the decision-making task. We focus on a fundamental decision-making framework with natural language as input, which is the one of contextual bandits, where the context information consists of text. As a representative of the approaches with no uncertainty estimation, we consider an LLM bandit with a greedy policy, which picks the action corresponding to the largest predicted reward. We compare this baseline to LLM bandits that make active use of uncertainty estimation by integrating the uncertainty in a Thompson Sampling policy. We employ different techniques for uncertainty estimation, such as Laplace Approximation, Dropout, and Epinets. We empirically show on real-world data that the greedy policy performs worse than the Thompson Sampling policies. These findings suggest that, while overlooked in the LLM literature, uncertainty plays a fundamental role in bandit tasks with LLMs.
<div id='section'>Paperid: <span id='pid'>765, <a href='https://arxiv.org/pdf/2403.13452.pdf' target='_blank'>https://arxiv.org/pdf/2403.13452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luca Mozzarelli, Luca Cattaneo, Matteo Corno, Sergio Matteo Savaresi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13452">Mobile Robot Localization: a Modular, Odometry-Improving Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the number of works published in recent years, vehicle localization remains an open, challenging problem. While map-based localization and SLAM algorithms are getting better and better, they remain a single point of failure in typical localization pipelines. This paper proposes a modular localization architecture that fuses sensor measurements with the outputs of off-the-shelf localization algorithms. The fusion filter estimates model uncertainties to improve odometry in case absolute pose measurements are lost entirely. The architecture is validated experimentally on a real robot navigating autonomously proving a reduction of the position error of more than 90% with respect to the odometrical estimate without uncertainty estimation in a two-minute navigation period without position measurements.
<div id='section'>Paperid: <span id='pid'>766, <a href='https://arxiv.org/pdf/2403.10803.pdf' target='_blank'>https://arxiv.org/pdf/2403.10803.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Li, Sitong Li, Shanshan Wang, Yicheng Zeng, Falong Tan, Chuanlong Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10803">Enhancing Out-of-Distribution Detection with Multitesting-based Layer-wise Feature Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying machine learning in open environments presents the challenge of encountering diverse test inputs that differ significantly from the training data. These out-of-distribution samples may exhibit shifts in local or global features compared to the training distribution. The machine learning (ML) community has responded with a number of methods aimed at distinguishing anomalous inputs from original training data. However, the majority of previous studies have primarily focused on the output layer or penultimate layer of pre-trained deep neural networks. In this paper, we propose a novel framework, Multitesting-based Layer-wise Out-of-Distribution (OOD) Detection (MLOD), to identify distributional shifts in test samples at different levels of features through rigorous multiple testing procedure. Our approach distinguishes itself from existing methods as it does not require modifying the structure or fine-tuning of the pre-trained classifier. Through extensive experiments, we demonstrate that our proposed framework can seamlessly integrate with any existing distance-based inspection method while efficiently utilizing feature extractors of varying depths. Our scheme effectively enhances the performance of out-of-distribution detection when compared to baseline methods. In particular, MLOD-Fisher achieves superior performance in general. When trained using KNN on CIFAR10, MLOD-Fisher significantly lowers the false positive rate (FPR) from 24.09% to 7.47% on average compared to merely utilizing the features of the last layer.
<div id='section'>Paperid: <span id='pid'>767, <a href='https://arxiv.org/pdf/2402.16255.pdf' target='_blank'>https://arxiv.org/pdf/2402.16255.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinqian Chen, Jihua Zhu, Qinghai Zheng, Zhongyu Li, Zhiqiang Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16255">Watch Your Head: Assembling Projection Heads to Save the Reliability of Federated Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning encounters substantial challenges with heterogeneous data, leading to performance degradation and convergence issues. While considerable progress has been achieved in mitigating such an impact, the reliability aspect of federated models has been largely disregarded. In this study, we conduct extensive experiments to investigate the reliability of both generic and personalized federated models. Our exploration uncovers a significant finding: \textbf{federated models exhibit unreliability when faced with heterogeneous data}, demonstrating poor calibration on in-distribution test data and low uncertainty levels on out-of-distribution data. This unreliability is primarily attributed to the presence of biased projection heads, which introduce miscalibration into the federated models. Inspired by this observation, we propose the "Assembled Projection Heads" (APH) method for enhancing the reliability of federated models. By treating the existing projection head parameters as priors, APH randomly samples multiple initialized parameters of projection heads from the prior and further performs targeted fine-tuning on locally available data under varying learning rates. Such a head ensemble introduces parameter diversity into the deterministic model, eliminating the bias and producing reliable predictions via head averaging. We evaluate the effectiveness of the proposed APH method across three prominent federated benchmarks. Experimental results validate the efficacy of APH in model calibration and uncertainty estimation. Notably, APH can be seamlessly integrated into various federated approaches but only requires less than 30\% additional computation cost for 100$\times$ inferences within large models.
<div id='section'>Paperid: <span id='pid'>768, <a href='https://arxiv.org/pdf/2402.11245.pdf' target='_blank'>https://arxiv.org/pdf/2402.11245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liming Huang, Yulei Wu, Juan Marcelo Parra-Ullauri, Reza Nejabati, Dimitra Simeonidou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11245">AI Model Placement for 6G Networks under Epistemic Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The adoption of Artificial Intelligence (AI) based Virtual Network Functions (VNFs) has witnessed significant growth, posing a critical challenge in orchestrating AI models within next-generation 6G networks. Finding optimal AI model placement is significantly more challenging than placing traditional software-based VNFs, due to the introduction of numerous uncertain factors by AI models, such as varying computing resource consumption, dynamic storage requirements, and changing model performance. To address the AI model placement problem under uncertainties, this paper presents a novel approach employing a sequence-to-sequence (S2S) neural network which considers uncertainty estimations. The S2S model, characterized by its encoding-decoding architecture, is designed to take the service chain with a number of AI models as input and produce the corresponding placement of each AI model. To address the introduced uncertainties, our methodology incorporates the orthonormal certificate module for uncertainty estimation and utilizes fuzzy logic for uncertainty representation, thereby enhancing the capabilities of the S2S model. Experiments demonstrate that the proposed method achieves competitive results across diverse AI model profiles, network environments, and service chain requests.
<div id='section'>Paperid: <span id='pid'>769, <a href='https://arxiv.org/pdf/2402.03846.pdf' target='_blank'>https://arxiv.org/pdf/2402.03846.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Cribeiro-Ramallo, Vadim Arzamasov, Klemens BÃ¶hm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03846">Efficient Generation of Hidden Outliers for Improved Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier generation is a popular technique used for solving important outlier detection tasks. Generating outliers with realistic behavior is challenging. Popular existing methods tend to disregard the 'multiple views' property of outliers in high-dimensional spaces. The only existing method accounting for this property falls short in efficiency and effectiveness. We propose BISECT, a new outlier generation method that creates realistic outliers mimicking said property. To do so, BISECT employs a novel proposition introduced in this article stating how to efficiently generate said realistic outliers. Our method has better guarantees and complexity than the current methodology for recreating 'multiple views'. We use the synthetic outliers generated by BISECT to effectively enhance outlier detection in diverse datasets, for multiple use cases. For instance, oversampling with BISECT reduced the error by up to 3 times when compared with the baselines.
<div id='section'>Paperid: <span id='pid'>770, <a href='https://arxiv.org/pdf/2401.04744.pdf' target='_blank'>https://arxiv.org/pdf/2401.04744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soyed Tuhin Ahmed, Michael Hefenbrock, Guillaume Prenat, Lorena Anghel, Mehdi B. Tahoori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04744">Testing Spintronics Implemented Monte Carlo Dropout-Based Bayesian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Neural Networks (BayNNs) can inherently estimate predictive uncertainty, facilitating informed decision-making. Dropout-based BayNNs are increasingly implemented in spintronics-based computation-in-memory architectures for resource-constrained yet high-performance safety-critical applications. Although uncertainty estimation is important, the reliability of Dropout generation and BayNN computation is equally important for target applications but is overlooked in existing works. However, testing BayNNs is significantly more challenging compared to conventional NNs, due to their stochastic nature. In this paper, we present for the first time the model of the non-idealities of the spintronics-based Dropout module and analyze their impact on uncertainty estimates and accuracy. Furthermore, we propose a testing framework based on repeatability ranking for Dropout-based BayNN with up to $100\%$ fault coverage while using only $0.2\%$ of training data as test vectors.
<div id='section'>Paperid: <span id='pid'>771, <a href='https://arxiv.org/pdf/2401.01459.pdf' target='_blank'>https://arxiv.org/pdf/2401.01459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ananya Joshi, Tina Townes, Nolan Gormley, Luke Neureiter, Roni Rosenfeld, Bryan Wilder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01459">Outlier Ranking in Large-Scale Public Health Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Disease control experts inspect public health data streams daily for outliers worth investigating, like those corresponding to data quality issues or disease outbreaks. However, they can only examine a few of the thousands of maximally-tied outliers returned by univariate outlier detection methods applied to large-scale public health data streams. To help experts distinguish the most important outliers from these thousands of tied outliers, we propose a new task for algorithms to rank the outputs of any univariate method applied to each of many streams. Our novel algorithm for this task, which leverages hierarchical networks and extreme value analysis, performed the best across traditional outlier detection metrics in a human-expert evaluation using public health data streams. Most importantly, experts have used our open-source Python implementation since April 2023 and report identifying outliers worth investigating 9.1x faster than their prior baseline. Other organizations can readily adapt this implementation to create rankings from the outputs of their tailored univariate methods across large-scale streams.
<div id='section'>Paperid: <span id='pid'>772, <a href='https://arxiv.org/pdf/2512.12997.pdf' target='_blank'>https://arxiv.org/pdf/2512.12997.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjing lu, Zerui Tao, Dongping Zhang, Yuning Qiu, Yang Yang, Qibin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.12997">Calibrating Uncertainty for Zero-Shot Adversarial CLIP</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>CLIP delivers strong zero-shot classification but remains highly vulnerable to adversarial attacks. Previous work of adversarial fine-tuning largely focuses on matching the predicted logits between clean and adversarial examples, which overlooks uncertainty calibration and may degrade the zero-shot generalization. A common expectation in reliable uncertainty estimation is that predictive uncertainty should increase as inputs become more difficult or shift away from the training distribution. However, we frequently observe the opposite in the adversarial setting: perturbations not only degrade accuracy but also suppress uncertainty, leading to severe miscalibration and unreliable over-confidence. This overlooked phenomenon highlights a critical reliability gap beyond robustness. To bridge this gap, we propose a novel adversarial fine-tuning objective for CLIP considering both prediction accuracy and uncertainty alignments. By reparameterizing the output of CLIP as the concentration parameter of a Dirichlet distribution, we propose a unified representation that captures relative semantic structure and the magnitude of predictive confidence. Our objective aligns these distributions holistically under perturbations, moving beyond single-logit anchoring and restoring calibrated uncertainty. Experiments on multiple zero-shot classification benchmarks demonstrate that our approach effectively restores calibrated uncertainty and achieves competitive adversarial robustness while maintaining clean accuracy.
<div id='section'>Paperid: <span id='pid'>773, <a href='https://arxiv.org/pdf/2512.04034.pdf' target='_blank'>https://arxiv.org/pdf/2512.04034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Yang, Devroop Kar, Qi Yu, Alex Ororbia, Travis Desell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.04034">Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.
<div id='section'>Paperid: <span id='pid'>774, <a href='https://arxiv.org/pdf/2511.17760.pdf' target='_blank'>https://arxiv.org/pdf/2511.17760.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashley S. Dale, Kangming Li, Brian DeCost, Hao Wan, Yuchen Han, Yao Fehlis, Jason Hattrick-Simpers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.17760">When Active Learning Fails, Uncalibrated Out of Distribution Uncertainty Quantification Might Be the Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficiently and meaningfully estimating prediction uncertainty is important for exploration in active learning campaigns in materials discovery, where samples with high uncertainty are interpreted as containing information missing from the model. In this work, the effect of different uncertainty estimation and calibration methods are evaluated for active learning when using ensembles of ALIGNN, eXtreme Gradient Boost, Random Forest, and Neural Network model architectures. We compare uncertainty estimates from ALIGNN deep ensembles to loss landscape uncertainty estimates obtained for solubility, bandgap, and formation energy prediction tasks. We then evaluate how the quality of the uncertainty estimate impacts an active learning campaign that seeks model generalization to out-of-distribution data. Uncertainty calibration methods were found to variably generalize from in-domain data to out-of-domain data. Furthermore, calibrated uncertainties were generally unsuccessful in reducing the amount of data required by a model to improve during an active learning campaign on out-of-distribution data when compared to random sampling and uncalibrated uncertainties. The impact of poor-quality uncertainty persists for random forest and eXtreme Gradient Boosting models trained on the same data for the same tasks, indicating that this is at least partially intrinsic to the data and not due to model capacity alone. Analysis of the target, in-distribution uncertainty, out-of-distribution uncertainty, and training residual distributions suggest that future work focus on understanding empirical uncertainties in the feature input space for cases where ensemble prediction variances do not accurately capture the missing information required for the model to generalize.
<div id='section'>Paperid: <span id='pid'>775, <a href='https://arxiv.org/pdf/2511.13766.pdf' target='_blank'>https://arxiv.org/pdf/2511.13766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaizheng Wang, Fabio Cuzzolin, David Moens, Hans Hallez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.13766">Credal Ensemble Distillation for Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep ensembles (DE) have emerged as a powerful approach for quantifying predictive uncertainty and distinguishing its aleatoric and epistemic components, thereby enhancing model robustness and reliability. However, their high computational and memory costs during inference pose significant challenges for wide practical deployment. To overcome this issue, we propose credal ensemble distillation (CED), a novel framework that compresses a DE into a single model, CREDIT, for classification tasks. Instead of a single softmax probability distribution, CREDIT predicts class-wise probability intervals that define a credal set, a convex set of probability distributions, for uncertainty quantification. Empirical results on out-of-distribution detection benchmarks demonstrate that CED achieves superior or comparable uncertainty estimation compared to several existing baselines, while substantially reducing inference overhead compared to DE.
<div id='section'>Paperid: <span id='pid'>776, <a href='https://arxiv.org/pdf/2510.21935.pdf' target='_blank'>https://arxiv.org/pdf/2510.21935.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel Bright-Thonney, Christina Reissel, Gaia Grosso, Nathaniel Woodward, Katya Govorkova, Andrzej Novak, Sang Eon Park, Eric Moreno, Philip Harris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.21935">AutoSciDACT: Automated Scientific Discovery through Contrastive Embedding and Hypothesis Testing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty detection in large scientific datasets faces two key challenges: the noisy and high-dimensional nature of experimental data, and the necessity of making statistically robust statements about any observed outliers. While there is a wealth of literature on anomaly detection via dimensionality reduction, most methods do not produce outputs compatible with quantifiable claims of scientific discovery. In this work we directly address these challenges, presenting the first step towards a unified pipeline for novelty detection adapted for the rigorous statistical demands of science. We introduce AutoSciDACT (Automated Scientific Discovery with Anomalous Contrastive Testing), a general-purpose pipeline for detecting novelty in scientific data. AutoSciDACT begins by creating expressive low-dimensional data representations using a contrastive pre-training, leveraging the abundance of high-quality simulated data in many scientific domains alongside expertise that can guide principled data augmentation strategies. These compact embeddings then enable an extremely sensitive machine learning-based two-sample test using the New Physics Learning Machine (NPLM) framework, which identifies and statistically quantifies deviations in observed data relative to a reference distribution (null hypothesis). We perform experiments across a range of astronomical, physical, biological, image, and synthetic datasets, demonstrating strong sensitivity to small injections of anomalous data across all domains.
<div id='section'>Paperid: <span id='pid'>777, <a href='https://arxiv.org/pdf/2510.20126.pdf' target='_blank'>https://arxiv.org/pdf/2510.20126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prithvi Raj Singh, Raju Gottumukkala, Anthony S. Maida, Alan B. Barhorst, Vijaya Gopu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.20126">Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While computer vision has advanced considerably for general object detection and tracking, the specific problem of fast-moving tiny objects remains underexplored. This paper addresses the significant challenge of detecting and tracking rapidly moving small objects using an RGB-D camera. Our novel system combines deep learning-based detection with physics-based tracking to overcome the limitations of existing approaches. Our contributions include: (1) a comprehensive system design for object detection and tracking of fast-moving small objects in 3D space, (2) an innovative physics-based tracking algorithm that integrates kinematics motion equations to handle outliers and missed detections, and (3) an outlier detection and correction module that significantly improves tracking performance in challenging scenarios such as occlusions and rapid direction changes. We evaluated our proposed system on a custom racquetball dataset. Our evaluation shows our system surpassing kalman filter based trackers with up to 70\% less Average Displacement Error. Our system has significant applications for improving robot perception on autonomous platforms and demonstrates the effectiveness of combining physics-based models with deep learning approaches for real-time 3D detection and tracking of challenging small objects.
<div id='section'>Paperid: <span id='pid'>778, <a href='https://arxiv.org/pdf/2510.12259.pdf' target='_blank'>https://arxiv.org/pdf/2510.12259.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinlun Ye, Zhuohao Sun, Yiqiao Qiu, Qiu Li, Zhijun Tan, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.12259">Local Background Features Matter in Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial when deploying deep neural networks in the real world to ensure the reliability and safety of their applications. One main challenge in OOD detection is that neural network models often produce overconfident predictions on OOD data. While some methods using auxiliary OOD datasets or generating fake OOD images have shown promising OOD detection performance, they are limited by the high costs of data collection and training. In this study, we propose a novel and effective OOD detection method that utilizes local background features as fake OOD features for model training. Inspired by the observation that OOD images generally share similar background regions with ID images, the background features are extracted from ID images as simulated OOD visual representations during training based on the local invariance of convolution. Through being optimized to reduce the $L_2$-norm of these background features, the neural networks are able to alleviate the overconfidence issue on OOD data. Extensive experiments on multiple standard OOD detection benchmarks confirm the effectiveness of our method and its wide combinatorial compatibility with existing post-hoc methods, with new state-of-the-art performance achieved from our method.
<div id='section'>Paperid: <span id='pid'>779, <a href='https://arxiv.org/pdf/2510.06742.pdf' target='_blank'>https://arxiv.org/pdf/2510.06742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Sarabadani, Kheirolah Rahsepar Fard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06742">MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advent of large language models (LLMs) has revolutionized the integration of knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming limitations in traditional machine learning methods for capturing intricate semantic links among genes, diseases, and cognitive processes. We introduce MultiCNKG, an innovative framework that merges three key knowledge sources: the Cognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges across 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes and 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO) comprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types. Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity computation, and graph augmentation to create a cohesive KG that interconnects genetic mechanisms, neurological disorders, and cognitive functions. The resulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes, Diseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes, Associated with, Regulates), facilitating a multi-layered view from molecular to behavioral domains. Assessments using metrics such as precision (85.20%), recall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty detection (40.28%), and expert validation (89.50%) affirm its robustness and coherence. Link prediction evaluations with models like TransE (MR: 391, MRR: 0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against benchmarks like FB15k-237 and WN18RR. This KG advances applications in personalized medicine, cognitive disorder diagnostics, and hypothesis formulation in cognitive neuroscience.
<div id='section'>Paperid: <span id='pid'>780, <a href='https://arxiv.org/pdf/2509.12358.pdf' target='_blank'>https://arxiv.org/pdf/2509.12358.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Sun, Joshua A. Vita, Amit Samanta, Vincenzo Lordi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12358">Unsupervised Atomic Data Mining via Multi-Kernel Graph Autoencoders for Machine Learning Force Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing a chemically diverse dataset while avoiding sampling bias is critical to training efficient and generalizable force fields. However, in computational chemistry and materials science, many common dataset generation techniques are prone to oversampling regions of the potential energy surface. Furthermore, these regions can be difficult to identify and isolate from each other or may not align well with human intuition, making it challenging to systematically remove bias in the dataset. While traditional clustering and pruning (down-sampling) approaches can be useful for this, they can often lead to information loss or a failure to properly identify distinct regions of the potential energy surface due to difficulties associated with the high dimensionality of atomic descriptors. In this work, we introduce the Multi-kernel Edge Attention-based Graph Autoencoder (MEAGraph) model, an unsupervised approach for analyzing atomic datasets. MEAGraph combines multiple linear kernel transformations with attention-based message passing to capture geometric sensitivity and enable effective dataset pruning without relying on labels or extensive training. Demonstrated applications on niobium, tantalum, and iron datasets show that MEAGraph efficiently groups similar atomic environments, allowing for the use of basic pruning techniques for removing sampling bias. This approach provides an effective method for representation learning and clustering that can be used for data analysis, outlier detection, and dataset optimization.
<div id='section'>Paperid: <span id='pid'>781, <a href='https://arxiv.org/pdf/2509.11892.pdf' target='_blank'>https://arxiv.org/pdf/2509.11892.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akito Shinohara, Kohei Fukuda, Hiroaki Aizawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11892">Logit Mixture Outlier Exposure for Fine-grained Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to detect out-of-distribution data is essential not only for ensuring robustness against unknown or unexpected input data but also for improving the generalization performance of the model. Among various out-of-distribution detection methods, Outlier Exposure and Mixture Outlier Exposure are promising approaches that enhance out-of-distribution detection performance by exposing the outlier data during training. However, even with these sophisticated techniques, it remains challenging for models to learn the relationships between classes effectively and to distinguish data sampling from in-distribution and out-of-distribution clearly. Therefore, we focus on the logit space, where the properties between class-wise distributions are distinctly separated from those in the input or feature spaces. Specifically, we propose a linear interpolation technique in the logit space that mixes in-distribution and out-of-distribution data to facilitate smoothing logits between classes and improve the out-of-distribution detection performance, particularly for out-of-distribution data that lie close to the in-distribution data. Additionally, we enforce consistency between the logits obtained through mixing in the logit space and those generated via mixing in the input space. Our experiments demonstrate that our logit-space mixing technique reduces the abrupt fluctuations in the model outputs near the decision boundaries, resulting in smoother and more reliable separation between in-distribution and out-of-distribution data. Furthermore, we evaluate the effectiveness of the proposed method on a fine-grained out-of-distribution detection task.
<div id='section'>Paperid: <span id='pid'>782, <a href='https://arxiv.org/pdf/2509.07523.pdf' target='_blank'>https://arxiv.org/pdf/2509.07523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jad Yehya, Mansour Benbakoura, CÃ©dric Allain, BenoÃ®t Malezieux, Matthieu Kowalski, Thomas Moreau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07523">RoseCDL: Robust and Scalable Convolutional Dictionary Learning for Rare-event Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying recurring patterns and rare events in large-scale signals is a fundamental challenge in fields such as astronomy, physical simulations, and biomedical science. Convolutional Dictionary Learning (CDL) offers a powerful framework for modeling local structures in signals, but its use for detecting rare or anomalous events remains largely unexplored. In particular, CDL faces two key challenges in this setting: high computational cost and sensitivity to artifacts and outliers. In this paper, we introduce RoseCDL, a scalable and robust CDL algorithm designed for unsupervised rare event detection in long signals. RoseCDL combines stochastic windowing for efficient training on large datasets with inline outlier detection to enhance robustness and isolate anomalous patterns. This reframes CDL as a practical tool for event discovery and characterization in real-world signals, extending its role beyond traditional tasks like compression or denoising.
<div id='section'>Paperid: <span id='pid'>783, <a href='https://arxiv.org/pdf/2507.23035.pdf' target='_blank'>https://arxiv.org/pdf/2507.23035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xueying Wu, Baijun Zhou, Zhihui Gao, Yuzhe Fu, Qilin Zheng, Yintao He, Hai Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.23035">KLLM: Fast LLM Inference with K-Means Quantization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language model (LLM) inference poses significant challenges due to its intensive memory and computation demands. Weight and activation quantization (WAQ) offers a promising solution by reducing both memory footprint and arithmetic complexity. Traditional WAQ designs rely on uniform integer quantization for hardware efficiency, but often suffer from significant model performance degradation at low precision. In contrast, K-Means quantization, a non-uniform technique, achieves higher accuracy by aligning with the Gaussian-like distributions of weights and activations in LLMs. However, two key challenges prevent the efficient deployment of K-Means-based WAQ designs for LLM inference: (1) The non-uniform structure of K-Means-quantized data precludes direct execution on low-precision compute units, necessitating dequantization and floating-point matrix multiplications (MatMuls) during inference. (2) Activation outliers hinder effective low-precision quantization. Offline thresholding methods for outlier detection degrade model performance substantially, while existing online detection techniques introduce significant runtime overhead. To address the aforementioned challenges and fully unleash the potential of K-Means-based WAQ for LLM inference, in this paper, we propose KLLM, an LLM inference accelerator for efficient execution with K-Means-quantized weights and activations. KLLM features an index-based computation scheme for efficient execution of MatMuls and nonlinear operations on K-Means-quantized data, which avoids most of the dequantization and full-precision computations. Moreover, KLLM incorporates a lightweight outlier detection engine, Orizuru, that efficiently identifies the top-$k$ largest and smallest elements in the activation data stream during online inference.
<div id='section'>Paperid: <span id='pid'>784, <a href='https://arxiv.org/pdf/2507.08905.pdf' target='_blank'>https://arxiv.org/pdf/2507.08905.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Koen Vellenga, H. Joe Steinhauer, GÃ¶ran Falkman, Jonas Andersson, Anders SjÃ¶gren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08905">Last Layer Hamiltonian Monte Carlo</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore the use of Hamiltonian Monte Carlo (HMC) sampling as a probabilistic last layer approach for deep neural networks (DNNs). While HMC is widely regarded as a gold standard for uncertainty estimation, the computational demands limit its application to large-scale datasets and large DNN architectures. Although the predictions from the sampled DNN parameters can be parallelized, the computational cost still scales linearly with the number of samples (similar to an ensemble). Last layer HMC (LL--HMC) reduces the required computations by restricting the HMC sampling to the final layer of a DNN, making it applicable to more data-intensive scenarios with limited computational resources. In this paper, we compare LL-HMC against five last layer probabilistic deep learning (LL-PDL) methods across three real-world video datasets for driver action and intention. We evaluate the in-distribution classification performance, calibration, and out-of-distribution (OOD) detection. Due to the stochastic nature of the probabilistic evaluations, we performed five grid searches for different random seeds to avoid being reliant on a single initialization for the hyperparameter configurations. The results show that LL--HMC achieves competitive in-distribution classification and OOD detection performance. Additional sampled last layer parameters do not improve the classification performance, but can improve the OOD detection. Multiple chains or starting positions did not yield consistent improvements.
<div id='section'>Paperid: <span id='pid'>785, <a href='https://arxiv.org/pdf/2507.01694.pdf' target='_blank'>https://arxiv.org/pdf/2507.01694.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanlin Cai, Haofan Dong, Houtianfu Wang, Kai Li, Ozgur B. Akan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01694">Graph Representation-based Model Poisoning on Federated Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated large language models (FedLLMs) enable powerful generative capabilities within wireless networks while preserving data privacy. Nonetheless, FedLLMs remain vulnerable to model poisoning attacks. This article first reviews recent advancements in model poisoning techniques and existing defense mechanisms for FedLLMs, underscoring critical limitations, especially when dealing with non-IID textual data distributions. Current defense strategies predominantly employ distance or similarity-based outlier detection mechanisms, relying on the assumption that malicious updates markedly differ from benign statistical patterns. However, this assumption becomes inadequate against adaptive adversaries targeting billion-parameter LLMs. The article further investigates graph representation-based model poisoning (GRMP), an emerging attack paradigm that exploits higher-order correlations among benign client gradients to craft malicious updates indistinguishable from legitimate ones. GRMP can effectively circumvent advanced defense systems, causing substantial degradation in model accuracy and overall performance. Moreover, the article outlines a forward-looking research roadmap that emphasizes the necessity of graph-aware secure aggregation methods, specialized vulnerability metrics tailored for FedLLMs, and evaluation frameworks to enhance the robustness of federated language model deployments.
<div id='section'>Paperid: <span id='pid'>786, <a href='https://arxiv.org/pdf/2506.21142.pdf' target='_blank'>https://arxiv.org/pdf/2506.21142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Deepak Kumar Panda, Weisi Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21142">Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing integration of UAVs into civilian airspace underscores the need for resilient and intelligent intrusion detection systems (IDS), as traditional anomaly detection methods often fail to identify novel threats. A common approach treats unfamiliar attacks as out-of-distribution (OOD) samples; however, this leaves systems vulnerable when mitigation is inadequate. Moreover, conventional OOD detectors struggle to distinguish stealthy adversarial attacks from genuine OOD events. This paper introduces a conditional generative adversarial network (cGAN)-based framework for crafting stealthy adversarial attacks that evade IDS mechanisms. We first design a robust multi-class IDS classifier trained on benign UAV telemetry and known cyber-attacks, including Denial of Service (DoS), false data injection (FDI), man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN perturbs known attacks to generate adversarial samples that misclassify as benign while retaining statistical resemblance to OOD distributions. These adversarial samples are iteratively refined to achieve high stealth and success rates. To detect such perturbations, we implement a conditional variational autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based regret scores significantly outperform traditional Mahalanobis distance-based detectors in identifying stealthy adversarial threats. Our findings emphasize the importance of advanced probabilistic modeling to strengthen IDS capabilities against adaptive, generative-model-based cyber intrusions.
<div id='section'>Paperid: <span id='pid'>787, <a href='https://arxiv.org/pdf/2505.16923.pdf' target='_blank'>https://arxiv.org/pdf/2505.16923.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhui Zhang, Dongshen Wu, Yuichiro Wada, Takafumi Kanamori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16923">TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A reliable uncertainty estimation method is the foundation of many modern out-of-distribution (OOD) detectors, which are critical for safe deployments of deep learning models in the open world. In this work, we propose TULiP, a theoretically-driven post-hoc uncertainty estimator for OOD detection. Our approach considers a hypothetical perturbation applied to the network before convergence. Based on linearized training dynamics, we bound the effect of such perturbation, resulting in an uncertainty score computable by perturbing model parameters. Ultimately, our approach computes uncertainty from a set of sampled predictions. We visualize our bound on synthetic regression and classification datasets. Furthermore, we demonstrate the effectiveness of TULiP using large-scale OOD detection benchmarks for image classification. Our method exhibits state-of-the-art performance, particularly for near-distribution samples.
<div id='section'>Paperid: <span id='pid'>788, <a href='https://arxiv.org/pdf/2505.02402.pdf' target='_blank'>https://arxiv.org/pdf/2505.02402.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thibault de Surrel, Florian Yger, Fabien Lotte, Sylvain Chevallier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02402">A probabilistic view on Riemannian machine learning models for SPD matrices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of this paper is to show how different machine learning tools on the Riemannian manifold $\mathcal{P}_d$ of Symmetric Positive Definite (SPD) matrices can be united under a probabilistic framework. For this, we will need several Gaussian distributions defined on $\mathcal{P}_d$. We will show how popular classifiers on $\mathcal{P}_d$ can be reinterpreted as Bayes Classifiers using these Gaussian distributions. These distributions will also be used for outlier detection and dimension reduction. By showing that those distributions are pervasive in the tools used on $\mathcal{P}_d$, we allow for other machine learning tools to be extended to $\mathcal{P}_d$.
<div id='section'>Paperid: <span id='pid'>789, <a href='https://arxiv.org/pdf/2504.15846.pdf' target='_blank'>https://arxiv.org/pdf/2504.15846.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonah Ekelund, Savvas Raptis, Vicki Toy-Edens, Wenli Mo, Drew L. Turner, Ian J. Cohen, Stefano Markidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15846">Adaptive PCA-Based Outlier Detection for Multi-Feature Time Series in Space Missions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Analyzing multi-featured time series data is critical for space missions making efficient event detection, potentially onboard, essential for automatic analysis. However, limited onboard computational resources and data downlink constraints necessitate robust methods for identifying regions of interest in real time. This work presents an adaptive outlier detection algorithm based on the reconstruction error of Principal Component Analysis (PCA) for feature reduction, designed explicitly for space mission applications. The algorithm adapts dynamically to evolving data distributions by using Incremental PCA, enabling deployment without a predefined model for all possible conditions. A pre-scaling process normalizes each feature's magnitude while preserving relative variance within feature types. We demonstrate the algorithm's effectiveness in detecting space plasma events, such as distinct space environments, dayside and nightside transients phenomena, and transition layers through NASA's MMS mission observations. Additionally, we apply the method to NASA's THEMIS data, successfully identifying a dayside transient using onboard-available measurements.
<div id='section'>Paperid: <span id='pid'>790, <a href='https://arxiv.org/pdf/2504.14704.pdf' target='_blank'>https://arxiv.org/pdf/2504.14704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Yang, Qi Yu, Travis Desel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.14704">Can We Ignore Labels In Out of Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection methods have recently become more prominent, serving as a core element in safety-critical autonomous systems. One major purpose of OOD detection is to reject invalid inputs that could lead to unpredictable errors and compromise safety. Due to the cost of labeled data, recent works have investigated the feasibility of self-supervised learning (SSL) OOD detection, unlabeled OOD detection, and zero shot OOD detection. In this work, we identify a set of conditions for a theoretical guarantee of failure in unlabeled OOD detection algorithms from an information-theoretic perspective. These conditions are present in all OOD tasks dealing with real-world data: I) we provide theoretical proof of unlabeled OOD detection failure when there exists zero mutual information between the learning objective and the in-distribution labels, a.k.a. 'label blindness', II) we define a new OOD task - Adjacent OOD detection - that tests for label blindness and accounts for a previously ignored safety gap in all OOD detection benchmarks, and III) we perform experiments demonstrating that existing unlabeled OOD methods fail under conditions suggested by our label blindness theory and analyze the implications for future research in unlabeled OOD methods.
<div id='section'>Paperid: <span id='pid'>791, <a href='https://arxiv.org/pdf/2504.13465.pdf' target='_blank'>https://arxiv.org/pdf/2504.13465.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Duy A. Nguyen, Quan Huu Do, Khoa D. Doan, Minh N. Do
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13465">Are you SURE? Enhancing Multimodal Pretraining with Missing Modalities through Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal learning has demonstrated incredible successes by integrating diverse data sources, yet it often relies on the availability of all modalities - an assumption that rarely holds in real-world applications. Pretrained multimodal models, while effective, struggle when confronted with small-scale and incomplete datasets (i.e., missing modalities), limiting their practical applicability. Previous studies on reconstructing missing modalities have overlooked the reconstruction's potential unreliability, which could compromise the quality of the final outputs. We present SURE (Scalable Uncertainty and Reconstruction Estimation), a novel framework that extends the capabilities of pretrained multimodal models by introducing latent space reconstruction and uncertainty estimation for both reconstructed modalities and downstream tasks. Our method is architecture-agnostic, reconstructs missing modalities, and delivers reliable uncertainty estimates, improving both interpretability and performance. SURE introduces a unique Pearson Correlation-based loss and applies statistical error propagation in deep networks for the first time, allowing precise quantification of uncertainties from missing data and model predictions. Extensive experiments across tasks such as sentiment analysis, genre classification, and action recognition show that SURE consistently achieves state-of-the-art performance, ensuring robust predictions even in the presence of incomplete data.
<div id='section'>Paperid: <span id='pid'>792, <a href='https://arxiv.org/pdf/2504.12931.pdf' target='_blank'>https://arxiv.org/pdf/2504.12931.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vincent Freiberger, Arthur Fleig, Erik Buchmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12931">Explainable AI in Usable Privacy and Security: Challenges and Opportunities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are increasingly being used for automated evaluations and explaining them. However, concerns about explanation quality, consistency, and hallucinations remain open research challenges, particularly in high-stakes contexts like privacy and security, where user trust and decision-making are at stake. In this paper, we investigate these issues in the context of PRISMe, an interactive privacy policy assessment tool that leverages LLMs to evaluate and explain website privacy policies. Based on a prior user study with 22 participants, we identify key concerns regarding LLM judgment transparency, consistency, and faithfulness, as well as variations in user preferences for explanation detail and engagement. We discuss potential strategies to mitigate these concerns, including structured evaluation criteria, uncertainty estimation, and retrieval-augmented generation (RAG). We identify a need for adaptive explanation strategies tailored to different user profiles for LLM-as-a-judge. Our goal is to showcase the application area of usable privacy and security to be promising for Human-Centered Explainable AI (HCXAI) to make an impact.
<div id='section'>Paperid: <span id='pid'>793, <a href='https://arxiv.org/pdf/2504.11434.pdf' target='_blank'>https://arxiv.org/pdf/2504.11434.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Ding, Xixi Liu, Jonas Unger, Gabriel Eilertsen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11434">Enhancing Out-of-Distribution Detection with Extended Logit Normalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for the safe deployment of machine learning models. Recent advances have explored improved classification losses and representation learning strategies to enhance OOD detection. However, these methods are often tailored to specific post-hoc detection techniques, limiting their generalizability. In this work, we identify a critical issue in Logit Normalization (LogitNorm), which inhibits its effectiveness in improving certain post-hoc OOD detection methods. To address this, we propose Extended Logit Normalization ($\textbf{ELogitNorm}$), a novel hyperparameter-free formulation that significantly benefits a wide range of post-hoc detection methods. By incorporating feature distance-awareness to LogitNorm, $\textbf{ELogitNorm}$ shows more robust OOD separability and in-distribution (ID) confidence calibration than its predecessor. Extensive experiments across standard benchmarks demonstrate that our approach outperforms state-of-the-art training-time methods in OOD detection while maintaining strong ID classification accuracy.
<div id='section'>Paperid: <span id='pid'>794, <a href='https://arxiv.org/pdf/2504.04471.pdf' target='_blank'>https://arxiv.org/pdf/2504.04471.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuo Zhi, Qiangqiang Wu, Minghe shen, Wenbo Li, Yinchuan Li, Kun Shao, Kaiwen Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04471">VideoAgent2: Enhancing the LLM-Based Agent System for Long-Form Video Understanding by Uncertainty-Aware CoT</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Long video understanding has emerged as an increasingly important yet challenging task in computer vision. Agent-based approaches are gaining popularity for processing long videos, as they can handle extended sequences and integrate various tools to capture fine-grained information. However, existing methods still face several challenges: (1) they often rely solely on the reasoning ability of large language models (LLMs) without dedicated mechanisms to enhance reasoning in long video scenarios; and (2) they remain vulnerable to errors or noise from external tools. To address these issues, we propose a specialized chain-of-thought (CoT) process tailored for long video analysis. Our proposed CoT with plan-adjust mode enables the LLM to incrementally plan and adapt its information-gathering strategy. We further incorporate heuristic uncertainty estimation of both the LLM and external tools to guide the CoT process. This allows the LLM to assess the reliability of newly collected information, refine its collection strategy, and make more robust decisions when synthesizing final answers. Empirical experiments show that our uncertainty-aware CoT effectively mitigates noise from external tools, leading to more reliable outputs. We implement our approach in a system called VideoAgent2, which also includes additional modules such as general context acquisition and specialized tool design. Evaluation on three dedicated long video benchmarks (and their subsets) demonstrates that VideoAgent2 outperforms the previous state-of-the-art agent-based method, VideoAgent, by an average of 13.1% and achieves leading performance among all zero-shot approaches
<div id='section'>Paperid: <span id='pid'>795, <a href='https://arxiv.org/pdf/2503.18341.pdf' target='_blank'>https://arxiv.org/pdf/2503.18341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuma Kitazawa, Takahito Aoto, Satoshi Ikehata, Tsuyoshi Takatani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18341">PS-EIP: Robust Photometric Stereo Based on Event Interval Profile</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, the energy-efficient photometric stereo method using an event camera has been proposed to recover surface normals from events triggered by changes in logarithmic Lambertian reflections under a moving directional light source. However, EventPS treats each event interval independently, making it sensitive to noise, shadows, and non-Lambertian reflections. This paper proposes Photometric Stereo based on Event Interval Profile (PS-EIP), a robust method that recovers pixelwise surface normals from a time-series profile of event intervals. By exploiting the continuity of the profile and introducing an outlier detection method based on profile shape, our approach enhances robustness against outliers from shadows and specular reflections. Experiments using real event data from 3D-printed objects demonstrate that PS-EIP significantly improves robustness to outliers compared to EventPS's deep-learning variant, EventPS-FCN, without relying on deep learning.
<div id='section'>Paperid: <span id='pid'>796, <a href='https://arxiv.org/pdf/2503.00479.pdf' target='_blank'>https://arxiv.org/pdf/2503.00479.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andy Gray, Alma Rahat, Tom Crick, Stephen Lindsay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00479">Bayesian Active Learning for Multi-Criteria Comparative Judgement in Educational Assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Comparative Judgement (CJ) provides an alternative assessment approach by evaluating work holistically rather than breaking it into discrete criteria. This method leverages human ability to make nuanced comparisons, yielding more reliable and valid assessments. CJ aligns with real-world evaluations, where overall quality emerges from the interplay of various elements. However, rubrics remain widely used in education, offering structured criteria for grading and detailed feedback. This creates a gap between CJ's holistic ranking and the need for criterion-based performance breakdowns. This paper addresses this gap using a Bayesian approach. We build on Bayesian CJ (BCJ) by Gray et al., which directly models preferences instead of using likelihoods over total scores, allowing for expected ranks with uncertainty estimation. Their entropy-based active learning method selects the most informative pairwise comparisons for assessors. We extend BCJ to handle multiple independent learning outcome (LO) components, defined by a rubric, enabling both holistic and component-wise predictive rankings with uncertainty estimates. Additionally, we propose a method to aggregate entropies and identify the most informative comparison for assessors. Experiments on synthetic and real data demonstrate our method's effectiveness. Finally, we address a key limitation of BCJ, which is the inability to quantify assessor agreement. We show how to derive agreement levels, enhancing transparency in assessment.
<div id='section'>Paperid: <span id='pid'>797, <a href='https://arxiv.org/pdf/2502.20375.pdf' target='_blank'>https://arxiv.org/pdf/2502.20375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aravind Gollakota, Parikshit Gopalan, Aayush Karan, Charlotte Peale, Udi Wieder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.20375">When does a predictor know its own loss?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given a predictor and a loss function, how well can we predict the loss that the predictor will incur on an input? This is the problem of loss prediction, a key computational task associated with uncertainty estimation for a predictor. In a classification setting, a predictor will typically predict a distribution over labels and hence have its own estimate of the loss that it will incur, given by the entropy of the predicted distribution. Should we trust this estimate? In other words, when does the predictor know what it knows and what it does not know?
  In this work we study the theoretical foundations of loss prediction. Our main contribution is to establish tight connections between nontrivial loss prediction and certain forms of multicalibration, a multigroup fairness notion that asks for calibrated predictions across computationally identifiable subgroups. Formally, we show that a loss predictor that is able to improve on the self-estimate of a predictor yields a witness to a failure of multicalibration, and vice versa. This has the implication that nontrivial loss prediction is in effect no easier or harder than auditing for multicalibration. We support our theoretical results with experiments that show a robust positive correlation between the multicalibration error of a predictor and the efficacy of training a loss predictor.
<div id='section'>Paperid: <span id='pid'>798, <a href='https://arxiv.org/pdf/2501.11570.pdf' target='_blank'>https://arxiv.org/pdf/2501.11570.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karn N. Watcharasupat, Yiwei Ding, T. Aleksandra Ma, Pavan Seshadri, Alexander Lerch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11570">Uncertainty Estimation in the Real World: A Study on Music Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Any data annotation for subjective tasks shows potential variations between individuals. This is particularly true for annotations of emotional responses to musical stimuli. While older approaches to music emotion recognition systems frequently addressed this uncertainty problem through probabilistic modeling, modern systems based on neural networks tend to ignore the variability and focus only on predicting central tendencies of human subjective responses. In this work, we explore several methods for estimating not only the central tendencies of the subjective responses to a musical stimulus, but also for estimating the uncertainty associated with these responses. In particular, we investigate probabilistic loss functions and inference-time random sampling. Experimental results indicate that while the modeling of the central tendencies is achievable, modeling of the uncertainty in subjective responses proves significantly more challenging with currently available approaches even when empirical estimates of variations in the responses are available.
<div id='section'>Paperid: <span id='pid'>799, <a href='https://arxiv.org/pdf/2412.20674.pdf' target='_blank'>https://arxiv.org/pdf/2412.20674.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ervin Moore, Ahmed Imteaj, Md Zarif Hossain, Shabnam Rezapour, M. Hadi Amini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20674">Blockchain-Empowered Cyber-Secure Federated Learning for Trustworthy Edge Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated Learning (FL) is a privacy-preserving distributed machine learning scheme, where each participant data remains on the participating devices and only the local model generated utilizing the local computational power is transmitted throughout the database. However, the distributed computational nature of FL creates the necessity to develop a mechanism that can remotely trigger any network agents, track their activities, and prevent threats to the overall process posed by malicious participants. Particularly, the FL paradigm may become vulnerable due to an active attack from the network participants, called a poisonous attack. In such an attack, the malicious participant acts as a benign agent capable of affecting the global model quality by uploading an obfuscated poisoned local model update to the server. This paper presents a cross-device FL model that ensures trustworthiness, fairness, and authenticity in the underlying FL training process. We leverage trustworthiness by constructing a reputation-based trust model based on contributions of agents toward model convergence. We ensure fairness by identifying and removing malicious agents from the training process through an outlier detection technique. Further, we establish authenticity by generating a token for each participating device through a distributed sensing mechanism and storing that unique token in a blockchain smart contract. Further, we insert the trust scores of all agents into a blockchain and validate their reputations using various consensus mechanisms that consider the computational task.
<div id='section'>Paperid: <span id='pid'>800, <a href='https://arxiv.org/pdf/2412.17586.pdf' target='_blank'>https://arxiv.org/pdf/2412.17586.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Evi M. C. Huijben, Sina Amirrajab, Josien P. W. Pluim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17586">Enhancing Reconstruction-Based Out-of-Distribution Detection in Brain MRI with Model and Metric Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for safely deploying automated medical image analysis systems, as abnormal patterns in images could hamper their performance. However, OOD detection in medical imaging remains an open challenge, and we address three gaps: the underexplored potential of a simple OOD detection model, the lack of optimization of deep learning strategies specifically for OOD detection, and the selection of appropriate reconstruction metrics. In this study, we investigated the effectiveness of a reconstruction-based autoencoder for unsupervised detection of synthetic artifacts in brain MRI. We evaluated the general reconstruction capability of the model, analyzed the impact of the selected training epoch and reconstruction metrics, assessed the potential of model and/or metric ensembles, and tested the model on a dataset containing a diverse range of artifacts. Among the metrics assessed, the contrast component of SSIM and LPIPS consistently outperformed others in detecting homogeneous circular anomalies. By combining two well-converged models and using LPIPS and contrast as reconstruction metrics, we achieved a pixel-level area under the Precision-Recall curve of 0.66. Furthermore, with the more realistic OOD dataset, we observed that the detection performance varied between artifact types; local artifacts were more difficult to detect, while global artifacts showed better detection results. These findings underscore the importance of carefully selecting metrics and model configurations, and highlight the need for tailored approaches, as standard deep learning approaches do not always align with the unique needs of OOD detection.
<div id='section'>Paperid: <span id='pid'>801, <a href='https://arxiv.org/pdf/2412.08501.pdf' target='_blank'>https://arxiv.org/pdf/2412.08501.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuang Zhang, Liping Wang, Yihong Huang, Yuanxing Zheng, Fan Zhang, Xuemin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.08501">GradStop: Exploring Training Dynamics in Unsupervised Outlier Detection through Gradient</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised Outlier Detection (UOD) is a critical task in data mining and machine learning, aiming to identify instances that significantly deviate from the majority. Without any label, deep UOD methods struggle with the misalignment between the model's direct optimization goal and the final performance goal of Outlier Detection (OD) task. Through the perspective of training dynamics, this paper proposes an early stopping algorithm to optimize the training of deep UOD models, ensuring they perform optimally in OD rather than overfitting the entire contaminated dataset.
  Inspired by UOD mechanism and inlier priority phenomenon, where intuitively models fit inliers more quickly than outliers, we propose GradStop, a sampling-based label-free algorithm to estimate model's real-time performance during training. First, a sampling method generates two sets: one likely containing more outliers and the other more inliers, then a metric based on gradient cohesion is applied to probe into current training dynamics, which reflects model's performance on OD task.
  Experimental results on 4 deep UOD algorithms and 47 real-world datasets and theoretical proofs demonstrate the effectiveness of our proposed early stopping algorithm in enhancing the performance of deep UOD models. Auto Encoder (AE) enhanced by GradStop achieves better performance than itself, other SOTA UOD methods, and even ensemble AEs. Our method provides a robust and effective solution to the problem of performance degradation during training, enabling deep UOD models to achieve better potential in anomaly detection tasks.
<div id='section'>Paperid: <span id='pid'>802, <a href='https://arxiv.org/pdf/2412.07565.pdf' target='_blank'>https://arxiv.org/pdf/2412.07565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Kristoffersson Lind, Rudolph Triebel, Volker KrÃ¼ger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07565">Making the Flow Glow -- Robot Perception under Severe Lighting Conditions using Normalizing Flow Gradients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern robotic perception is highly dependent on neural networks. It is well known that neural network-based perception can be unreliable in real-world deployment, especially in difficult imaging conditions. Out-of-distribution detection is commonly proposed as a solution for ensuring reliability in real-world deployment. Previous work has shown that normalizing flow models can be used for out-of-distribution detection to improve reliability of robotic perception tasks. Specifically, camera parameters can be optimized with respect to the likelihood output from a normalizing flow, which allows a perception system to adapt to difficult vision scenarios. With this work we propose to use the absolute gradient values from a normalizing flow, which allows the perception system to optimize local regions rather than the whole image. By setting up a table top picking experiment with exceptionally difficult lighting conditions, we show that our method achieves a 60% higher success rate for an object detection task compared to previous methods.
<div id='section'>Paperid: <span id='pid'>803, <a href='https://arxiv.org/pdf/2411.14346.pdf' target='_blank'>https://arxiv.org/pdf/2411.14346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edgar Mauricio Salazar Duque, Bart van der Holst, Pedro P. Vergara, Juan S. Giraldo, Phuong H. Nguyen, Anne Van der Molen, Han, Slootweg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14346">Lower Dimensional Spherical Representation of Medium Voltage Load Profiles for Visualization, Outlier Detection, and Generative Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents the spherical lower dimensional representation for daily medium voltage load profiles, based on principal component analysis. The objective is to unify and simplify the tasks for (i) clustering visualisation, (ii) outlier detection and (iii) generative profile modelling under one concept. The lower dimensional projection of standardised load profiles unveils a latent distribution in a three-dimensional sphere. This spherical structure allows us to detect outliers by fitting probability distribution models in the spherical coordinate system, identifying measurements that deviate from the spherical shape. The same latent distribution exhibits an arc shape, suggesting an underlying order among load profiles. We develop a principal curve technique to uncover this order based on similarity, offering new advantages over conventional clustering techniques. This finding reveals that energy consumption in a wide region can be seen as a continuously changing process. Furthermore, we combined the principal curve with a von Mises-Fisher distribution to create a model capable of generating profiles with continuous mixtures between clusters. The presence of the spherical distribution is validated with data from four municipalities in the Netherlands. The uncovered spherical structure implies the possibility of employing new mathematical tools from directional statistics and differential geometry for load profile modelling.
<div id='section'>Paperid: <span id='pid'>804, <a href='https://arxiv.org/pdf/2411.02871.pdf' target='_blank'>https://arxiv.org/pdf/2411.02871.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junhao Dong, Xinghua Qu, Z. Jane Wang, Yew-Soon Ong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02871">Enhancing Adversarial Robustness via Uncertainty-Aware Distributional Adversarial Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite remarkable achievements in deep learning across various domains, its inherent vulnerability to adversarial examples still remains a critical concern for practical deployment. Adversarial training has emerged as one of the most effective defensive techniques for improving model robustness against such malicious inputs. However, existing adversarial training schemes often lead to limited generalization ability against underlying adversaries with diversity due to their overreliance on a point-by-point augmentation strategy by mapping each clean example to its adversarial counterpart during training. In addition, adversarial examples can induce significant disruptions in the statistical information w.r.t. the target model, thereby introducing substantial uncertainty and challenges to modeling the distribution of adversarial examples. To circumvent these issues, in this paper, we propose a novel uncertainty-aware distributional adversarial training method, which enforces adversary modeling by leveraging both the statistical information of adversarial examples and its corresponding uncertainty estimation, with the goal of augmenting the diversity of adversaries. Considering the potentially negative impact induced by aligning adversaries to misclassified clean examples, we also refine the alignment reference based on the statistical proximity to clean examples during adversarial training, thereby reframing adversarial training within a distribution-to-distribution matching framework interacted between the clean and adversarial domains. Furthermore, we design an introspective gradient alignment approach via matching input gradients between these domains without introducing external models. Extensive experiments across four benchmark datasets and various network architectures demonstrate that our approach achieves state-of-the-art adversarial robustness and maintains natural performance.
<div id='section'>Paperid: <span id='pid'>805, <a href='https://arxiv.org/pdf/2411.00430.pdf' target='_blank'>https://arxiv.org/pdf/2411.00430.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuchen Xie, Yiqiao Qiu, Run Lin, Weishi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00430">Class Incremental Learning with Task-Specific Batch Normalization and Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study focuses on incremental learning for image classification, exploring how to reduce catastrophic forgetting of all learned knowledge when access to old data is restricted due to memory or privacy constraints. The challenge of incremental learning lies in achieving an optimal balance between plasticity, the ability to learn new knowledge, and stability, the ability to retain old knowledge. Based on whether the task identifier (task-ID) of an image can be obtained during the test stage, incremental learning for image classifcation is divided into two main paradigms, which are task incremental learning (TIL) and class incremental learning (CIL). The TIL paradigm has access to the task-ID, allowing it to use multiple task-specific classification heads selected based on the task-ID. Consequently, in CIL, where the task-ID is unavailable, TIL methods must predict the task-ID to extend their application to the CIL paradigm. Our previous method for TIL adds task-specific batch normalization and classification heads incrementally. This work extends the method by predicting task-ID through an "unknown" class added to each classification head. The head with the lowest "unknown" probability is selected, enabling task-ID prediction and making the method applicable to CIL. The task-specific batch normalization (BN) modules effectively adjust the distribution of output feature maps across different tasks, enhancing the model's plasticity.Moreover, since BN has much fewer parameters compared to convolutional kernels, by only modifying the BN layers as new tasks arrive, the model can effectively manage parameter growth while ensuring stability across tasks. The innovation of this study lies in the first-time introduction of task-specific BN into CIL and verifying the feasibility of extending TIL methods to CIL through task-ID prediction with state-of-the-art performance on multiple datasets.
<div id='section'>Paperid: <span id='pid'>806, <a href='https://arxiv.org/pdf/2410.01281.pdf' target='_blank'>https://arxiv.org/pdf/2410.01281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haomin Wen, Shurui Cao, Zeeshan Rasheed, Khurram Hassan Shafique, Leman Akoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01281">Uncertainty-aware Human Mobility Modeling and Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the temporal GPS coordinates from a large set of human agents, how can we model their mobility behavior toward effective anomaly (e.g. bad-actor or malicious behavior) detection without any labeled data? Human mobility and trajectory modeling have been extensively studied, showcasing varying abilities to manage complex inputs and balance performance-efficiency trade-offs. In this work, we formulate anomaly detection in complex human behavior by modeling raw GPS data as a sequence of stay-point events, each characterized by spatio-temporal features, along with trips (i.e. commute) between the stay-points. Our problem formulation allows us to leverage modern sequence models for unsupervised training and anomaly detection. Notably, we equip our proposed model USTAD (for Uncertainty-aware Spatio-Temporal Anomaly Detection) with aleatoric (i.e. data) uncertainty estimation to account for inherent stochasticity in certain individuals' behavior, as well as epistemic (i.e. model) uncertainty to handle data sparsity under a large variety of human behaviors. Together, aleatoric and epistemic uncertainties unlock a robust loss function as well as uncertainty-aware decision-making in anomaly scoring. Extensive experiments shows that USTAD improves anomaly detection AUCROC by 3\%-15\% over baselines in industry-scale data.
<div id='section'>Paperid: <span id='pid'>807, <a href='https://arxiv.org/pdf/2409.13143.pdf' target='_blank'>https://arxiv.org/pdf/2409.13143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Ling, Yiping Xie, Nils Bore, John Folkesson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13143">Score-Based Multibeam Point Cloud Denoising</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multibeam echo-sounder (MBES) is the de-facto sensor for bathymetry mapping. In recent years, cheaper MBES sensors and global mapping initiatives have led to exponential growth of available data. However, raw MBES data contains 1-25% of noise that requires semi-automatic filtering using tools such as Combined Uncertainty and Bathymetric Estimator (CUBE). In this work, we draw inspirations from the 3D point cloud community and adapted a score-based point cloud denoising network for MBES outlier detection and denoising. We trained and evaluated this network on real MBES survey data. The proposed method was found to outperform classical methods, and can be readily integrated into existing MBES standard workflow. To facilitate future research, the code and pretrained model are available online.
<div id='section'>Paperid: <span id='pid'>808, <a href='https://arxiv.org/pdf/2409.11985.pdf' target='_blank'>https://arxiv.org/pdf/2409.11985.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Viacheslav Barkov, Jonas Schmidinger, Robin Gebbers, Martin Atzmueller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11985">An Efficient Model-Agnostic Approach for Uncertainty Estimation in Data-Restricted Pedometric Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a model-agnostic approach designed to enhance uncertainty estimation in the predictive modeling of soil properties, a crucial factor for advancing pedometrics and the practice of digital soil mapping. For addressing the typical challenge of data scarcity in soil studies, we present an improved technique for uncertainty estimation. This method is based on the transformation of regression tasks into classification problems, which not only allows for the production of reliable uncertainty estimates but also enables the application of established machine learning algorithms with competitive performance that have not yet been utilized in pedometrics. Empirical results from datasets collected from two German agricultural fields showcase the practical application of the proposed methodology. Our results and findings suggest that the proposed approach has the potential to provide better uncertainty estimation than the models commonly used in pedometrics.
<div id='section'>Paperid: <span id='pid'>809, <a href='https://arxiv.org/pdf/2409.01980.pdf' target='_blank'>https://arxiv.org/pdf/2409.01980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiyao Xu, Kaize Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01980">Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting anomalies or out-of-distribution (OOD) samples is critical for maintaining the reliability and trustworthiness of machine learning systems. Recently, Large Language Models (LLMs) have demonstrated their effectiveness not only in natural language processing but also in broader applications due to their advanced comprehension and generative capabilities. The integration of LLMs into anomaly and OOD detection marks a significant shift from the traditional paradigm in the field. This survey focuses on the problem of anomaly and OOD detection under the context of LLMs. We propose a new taxonomy to categorize existing approaches into two classes based on the role played by LLMs. Following our proposed taxonomy, we further discuss the related work under each of the categories and finally discuss potential challenges and directions for future research in this field. We also provide an up-to-date reading list of relevant papers.
<div id='section'>Paperid: <span id='pid'>810, <a href='https://arxiv.org/pdf/2408.15012.pdf' target='_blank'>https://arxiv.org/pdf/2408.15012.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcel Boersma, Krishna Manoorkar, Alessandra Palmigiano, Mattia Panettiere, Apostolos Tzimoulis, Nachoem Wijnberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15012">Flexible categorization using formal concept analysis and Dempster-Shafer theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The framework developed in the present paper provides a formal ground to generate and study explainable categorizations of sets of entities, based on the epistemic attitudes of individual agents or groups thereof. Based on this framework, we discuss a machine-leaning meta-algorithm for outlier detection and classification which provides local and global explanations of its results.
<div id='section'>Paperid: <span id='pid'>811, <a href='https://arxiv.org/pdf/2408.13667.pdf' target='_blank'>https://arxiv.org/pdf/2408.13667.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xueying Ding, Rui Xi, Leman Akoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.13667">Outlier Detection Bias Busted: Understanding Sources of Algorithmic Bias through Data-centric Factors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The astonishing successes of ML have raised growing concern for the fairness of modern methods when deployed in real world settings. However, studies on fairness have mostly focused on supervised ML, while unsupervised outlier detection (OD), with numerous applications in finance, security, etc., have attracted little attention. While a few studies proposed fairness-enhanced OD algorithms, they remain agnostic to the underlying driving mechanisms or sources of unfairness. Even within the supervised ML literature, there exists debate on whether unfairness stems solely from algorithmic biases (i.e. design choices) or from the biases encoded in the data on which they are trained. To close this gap, this work aims to shed light on the possible sources of unfairness in OD by auditing detection models under different data-centric factors. By injecting various known biases into the input data -- as pertain to sample size disparity, under-representation, feature measurement noise, and group membership obfuscation -- we find that the OD algorithms under the study all exhibit fairness pitfalls, although differing in which types of data bias they are more susceptible to. Most notable of our study is to demonstrate that OD algorithm bias is not merely a data bias problem. A key realization is that the data properties that emerge from bias injection could as well be organic -- as pertain to natural group differences w.r.t. sparsity, base rate, variance, and multi-modality. Either natural or biased, such data properties can give rise to unfairness as they interact with certain algorithmic design choices.
<div id='section'>Paperid: <span id='pid'>812, <a href='https://arxiv.org/pdf/2407.15739.pdf' target='_blank'>https://arxiv.org/pdf/2407.15739.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Silvio Galesso, Philipp SchrÃ¶ppel, Hssan Driss, Thomas Brox
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15739">Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, research on out-of-distribution (OoD) detection for semantic segmentation has mainly focused on road scenes -- a domain with a constrained amount of semantic diversity. In this work, we challenge this constraint and extend the domain of this task to general natural images. To this end, we introduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and includes images from diverse domains with a high semantic diversity, and 2. a novel approach that uses Diffusion score matching for OoD detection (DOoD) and is robust to the increased semantic diversity. ADE-OoD features indoor and outdoor images, defines 150 semantic categories as in-distribution, and contains a variety of OoD objects. For DOoD, we train a diffusion model with an MLP architecture on semantic in-distribution embeddings and build on the score matching interpretation to compute pixel-wise OoD scores at inference time. On common road scene OoD benchmarks, DOoD performs on par or better than the state of the art, without using outliers for training or making assumptions about the data domain. On ADE-OoD, DOoD outperforms previous approaches, but leaves much room for future improvements.
<div id='section'>Paperid: <span id='pid'>813, <a href='https://arxiv.org/pdf/2407.14097.pdf' target='_blank'>https://arxiv.org/pdf/2407.14097.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erik B. Terres-Escudero, Javier Del Ser, Aitor MartÃ­nez-Seras, Pablo Garcia-Bringas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14097">Forward-Forward Learning achieves Highly Selective Latent Representations for Out-of-Distribution Detection in Fully Spiking Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, Artificial Intelligence (AI) models have achieved remarkable success across various domains, yet challenges persist in two critical areas: ensuring robustness against uncertain inputs and drastically increasing model efficiency during training and inference. Spiking Neural Networks (SNNs), inspired by biological systems, offer a promising avenue for overcoming these limitations. By operating in an event-driven manner, SNNs achieve low energy consumption and can naturally implement biological methods known for their high noise tolerance. In this work, we explore the potential of the spiking Forward-Forward Algorithm (FFA) to address these challenges, leveraging its representational properties for both Out-of-Distribution (OoD) detection and interpretability. To achieve this, we exploit the sparse and highly specialized neural latent space of FF networks to estimate the likelihood of a sample belonging to the training distribution. Additionally, we propose a novel, gradient-free attribution method to detect features that drive a sample away from class distributions, addressing the challenges posed by the lack of gradients in most visual interpretability methods for spiking models. We evaluate our OoD detection algorithm on well-known image datasets (e.g., Omniglot, Not-MNIST, CIFAR10), outperforming previous methods proposed in the recent literature for OoD detection in spiking networks. Furthermore, our attribution method precisely identifies salient OoD features, such as artifacts or missing regions, hence providing a visual explanatory interface for the user to understand why unknown inputs are identified as such by the proposed method.
<div id='section'>Paperid: <span id='pid'>814, <a href='https://arxiv.org/pdf/2407.00616.pdf' target='_blank'>https://arxiv.org/pdf/2407.00616.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masoud Ataei, Vikas Dhiman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00616">DADEE: Well-calibrated uncertainty quantification in neural networks for barriers-based robot safety</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty-aware controllers that guarantee safety are critical for safety critical applications. Among such controllers, Control Barrier Functions (CBFs) based approaches are popular because they are fast, yet safe. However, most such works depend on Gaussian Processes (GPs) or MC-Dropout for learning and uncertainty estimation, and both approaches come with drawbacks: GPs are non-parametric methods that are slow, while MC-Dropout does not capture aleatoric uncertainty. On the other hand, modern Bayesian learning algorithms have shown promise in uncertainty quantification. The application of modern Bayesian learning methods to CBF-based controllers has not yet been studied. We aim to fill this gap by surveying uncertainty quantification algorithms and evaluating them on CBF-based safe controllers. We find that model variance-based algorithms (for example, Deep ensembles, MC-dropout, etc.) and direct estimation-based algorithms (such as DEUP) have complementary strengths. Algorithms in the former category can only estimate uncertainty accurately out-of-domain, while those in the latter category can only do so in-domain. We combine the two approaches to obtain more accurate uncertainty estimates both in- and out-of-domain. As measured by the failure rate of a simulated robot, this results in a safer CBF-based robot controller.
<div id='section'>Paperid: <span id='pid'>815, <a href='https://arxiv.org/pdf/2406.03680.pdf' target='_blank'>https://arxiv.org/pdf/2406.03680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atsutoshi Kumagai, Tomoharu Iwata, Yasuhiro Fujiwara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03680">Meta-learning for Positive-unlabeled Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a meta-learning method for positive and unlabeled (PU) classification, which improves the performance of binary classifiers obtained from only PU data in unseen target tasks. PU learning is an important problem since PU data naturally arise in real-world applications such as outlier detection and information retrieval. Existing PU learning methods require many PU data, but sufficient data are often unavailable in practice. The proposed method minimizes the test classification risk after the model is adapted to PU data by using related tasks that consist of positive, negative, and unlabeled data. We formulate the adaptation as an estimation problem of the Bayes optimal classifier, which is an optimal classifier to minimize the classification risk. The proposed method embeds each instance into a task-specific space using neural networks. With the embedded PU data, the Bayes optimal classifier is estimated through density-ratio estimation of PU densities, whose solution is obtained as a closed-form solution. The closed-form solution enables us to efficiently and effectively minimize the test classification risk. We empirically show that the proposed method outperforms existing methods with one synthetic and three real-world datasets.
<div id='section'>Paperid: <span id='pid'>816, <a href='https://arxiv.org/pdf/2405.15047.pdf' target='_blank'>https://arxiv.org/pdf/2405.15047.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaizheng Wang, Fabio Cuzzolin, Keivan Shariatmadar, David Moens, Hans Hallez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15047">Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents an innovative approach, called credal wrapper, to formulating a credal set representation of model averaging for Bayesian neural networks (BNNs) and deep ensembles (DEs), capable of improving uncertainty estimation in classification tasks. Given a finite collection of single predictive distributions derived from BNNs or DEs, the proposed credal wrapper approach extracts an upper and a lower probability bound per class, acknowledging the epistemic uncertainty due to the availability of a limited amount of distributions. Such probability intervals over classes can be mapped on a convex set of probabilities (a credal set) from which, in turn, a unique prediction can be obtained using a transformation called intersection probability transformation. In this article, we conduct extensive experiments on several out-of-distribution (OOD) detection benchmarks, encompassing various dataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C, CIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network architectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base). Compared to the BNN and DE baselines, the proposed credal wrapper method exhibits superior performance in uncertainty estimation and achieves a lower expected calibration error on corrupted data.
<div id='section'>Paperid: <span id='pid'>817, <a href='https://arxiv.org/pdf/2405.12502.pdf' target='_blank'>https://arxiv.org/pdf/2405.12502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, Xuemin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12502">EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised Outlier Detection (UOD) is an important data mining task. With the advance of deep learning, deep Outlier Detection (OD) has received broad interest. Most deep UOD models are trained exclusively on clean datasets to learn the distribution of the normal data, which requires huge manual efforts to clean the real-world data if possible. Instead of relying on clean datasets, some approaches directly train and detect on unlabeled contaminated datasets, leading to the need for methods that are robust to such conditions. Ensemble methods emerged as a superior solution to enhance model robustness against contaminated training sets. However, the training time is greatly increased by the ensemble.
  In this study, we investigate the impact of outliers on the training phase, aiming to halt training on unlabeled contaminated datasets before performance degradation. Initially, we noted that blending normal and anomalous data causes AUC fluctuations, a label-dependent measure of detection accuracy. To circumvent the need for labels, we propose a zero-label entropy metric named Loss Entropy for loss distribution, enabling us to infer optimal stopping points for training without labels. Meanwhile, we theoretically demonstrate negative correlation between entropy metric and the label-based AUC. Based on this, we develop an automated early-stopping algorithm, EntropyStop, which halts training when loss entropy suggests the maximum model detection capability. We conduct extensive experiments on ADBench (including 47 real datasets), and the overall results indicate that AutoEncoder (AE) enhanced by our approach not only achieves better performance than ensemble AEs but also requires under 2\% of training time. Lastly, our proposed metric and early-stopping approach are evaluated on other deep OD models, exhibiting their broad potential applicability.
<div id='section'>Paperid: <span id='pid'>818, <a href='https://arxiv.org/pdf/2405.09697.pdf' target='_blank'>https://arxiv.org/pdf/2405.09697.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jadie Adams, Krithika Iyer, Shireen Elhabian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.09697">Weakly Supervised Bayesian Shape Modeling from Unsegmented Medical Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anatomical shape analysis plays a pivotal role in clinical research and hypothesis testing, where the relationship between form and function is paramount. Correspondence-based statistical shape modeling (SSM) facilitates population-level morphometrics but requires a cumbersome, potentially bias-inducing construction pipeline. Recent advancements in deep learning have streamlined this process in inference by providing SSM prediction directly from unsegmented medical images. However, the proposed approaches are fully supervised and require utilizing a traditional SSM construction pipeline to create training data, thus inheriting the associated burdens and limitations. To address these challenges, we introduce a weakly supervised deep learning approach to predict SSM from images using point cloud supervision. Specifically, we propose reducing the supervision associated with the state-of-the-art fully Bayesian variational information bottleneck DeepSSM (BVIB-DeepSSM) model. BVIB-DeepSSM is an effective, principled framework for predicting probabilistic anatomical shapes from images with quantification of both aleatoric and epistemic uncertainties. Whereas the original BVIB-DeepSSM method requires strong supervision in the form of ground truth correspondence points, the proposed approach utilizes weak supervision via point cloud surface representations, which are more readily obtainable. Furthermore, the proposed approach learns correspondence in a completely data-driven manner without prior assumptions about the expected variability in shape cohort. Our experiments demonstrate that this approach yields similar accuracy and uncertainty estimation to the fully supervised scenario while substantially enhancing the feasibility of model training for SSM construction.
<div id='section'>Paperid: <span id='pid'>819, <a href='https://arxiv.org/pdf/2405.06424.pdf' target='_blank'>https://arxiv.org/pdf/2405.06424.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JoonHo Lee, Jae Oh Woo, Juree Seok, Parisa Hassanzadeh, Wooseok Jang, JuYoun Son, Sima Didari, Baruch Gutow, Heng Hao, Hankyu Moon, Wenjun Hu, Yeong-Dae Kwon, Taehee Lee, Seungjai Min
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06424">Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Assessing response quality to instructions in language models is vital but challenging due to the complexity of human language across different contexts. This complexity often results in ambiguous or inconsistent interpretations, making accurate assessment difficult. To address this issue, we propose a novel Uncertainty-aware Reward Model (URM) that introduces a robust uncertainty estimation for the quality of paired responses based on Bayesian approximation. Trained with preference datasets, our uncertainty-enabled proxy not only scores rewards for responses but also evaluates their inherent uncertainty. Empirical results demonstrate significant benefits of incorporating the proposed proxy into language model training. Our method boosts the instruction following capability of language models by refining data curation for training and improving policy optimization objectives, thereby surpassing existing methods by a large margin on benchmarks such as Vicuna and MT-bench. These findings highlight that our proposed approach substantially advances language model training and paves a new way of harnessing uncertainty within language models.
<div id='section'>Paperid: <span id='pid'>820, <a href='https://arxiv.org/pdf/2402.13531.pdf' target='_blank'>https://arxiv.org/pdf/2402.13531.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gavin Brown, Krishnamurthy Dvijotham, Georgina Evans, Daogao Liu, Adam Smith, Abhradeep Thakurta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.13531">Private Gradient Descent for Linear Regression: Tighter Error Bounds and Instance-Specific Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We provide an improved analysis of standard differentially private gradient descent for linear regression under the squared error loss. Under modest assumptions on the input, we characterize the distribution of the iterate at each time step.
  Our analysis leads to new results on the algorithm's accuracy: for a proper fixed choice of hyperparameters, the sample complexity depends only linearly on the dimension of the data. This matches the dimension-dependence of the (non-private) ordinary least squares estimator as well as that of recent private algorithms that rely on sophisticated adaptive gradient-clipping schemes (Varshney et al., 2022; Liu et al., 2023).
  Our analysis of the iterates' distribution also allows us to construct confidence intervals for the empirical optimizer which adapt automatically to the variance of the algorithm on a particular data set. We validate our theorems through experiments on synthetic data.
<div id='section'>Paperid: <span id='pid'>821, <a href='https://arxiv.org/pdf/2402.07281.pdf' target='_blank'>https://arxiv.org/pdf/2402.07281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shanay Mehta, Shlok Mehendale, Nicole Fernandes, Jyotirmoy Sarkar, Santonu Sarkar, Snehanshu Saha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07281">Benchmarking Anomaly Detection Algorithms: Deep Learning and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detection of anomalous situations for complex mission-critical systems hold paramount importance when their service continuity needs to be ensured. A major challenge in detecting anomalies from the operational data arises due to the imbalanced class distribution problem since the anomalies are supposed to be rare events. This paper evaluates a diverse array of Machine Learning (ML)-based anomaly detection algorithms through a comprehensive benchmark study. The paper contributes significantly by conducting an unbiased comparison of various anomaly detection algorithms, spanning classical ML, including various tree-based approaches to Deep Learning (DL) and outlier detection methods. The inclusion of 104 publicly available enhances the diversity of the study, allowing a more realistic evaluation of algorithm performance and emphasizing the importance of adaptability to real-world scenarios.
  The paper evaluates the general notion of DL as a universal solution, showing that, while powerful, it is not always the best fit for every scenario. The findings reveal that recently proposed tree-based evolutionary algorithms match DL methods and sometimes outperform them in many instances of univariate data where the size of the data is small and number of anomalies are less than 10%. Specifically, tree-based approaches successfully detect singleton anomalies in datasets where DL falls short. To the best of the authors' knowledge, such a study on a large number of state-of-the-art algorithms using diverse data sets, with the objective of guiding researchers and practitioners in making informed algorithmic choices, has not been attempted earlier.
<div id='section'>Paperid: <span id='pid'>822, <a href='https://arxiv.org/pdf/2402.01302.pdf' target='_blank'>https://arxiv.org/pdf/2402.01302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aleksandar Armacki, Dragana BajoviÄ, DuÅ¡an JakovetiÄ, Soummya Kar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01302">A Unified Framework for Center-based Clustering of Distributed Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a family of distributed center-based clustering algorithms that work over networks of users. In the proposed scenario, users contain a local dataset and communicate only with their immediate neighbours, with the aim of finding a clustering of the full, joint data. The proposed family, termed Distributed Gradient Clustering (DGC-$\mathcal{F}_Ï$), is parametrized by $Ï\geq 1$, controling the proximity of users' center estimates, with $\mathcal{F}$ determining the clustering loss. Our framework allows for a broad class of smooth convex loss functions, including popular clustering losses like $K$-means and Huber loss. Specialized to popular clustering losses like $K$-means and Huber loss, DGC-$\mathcal{F}_Ï$ gives rise to novel distributed clustering algorithms DGC-KM$_Ï$ and DGC-HL$_Ï$, while novel clustering losses based on Logistic and Fair functions lead to DGC-LL$_Ï$ and DGC-FL$_Ï$. We provide a unified analysis and establish several strong results, under mild assumptions. First, we show that the sequence of centers generated by the methods converges to a well-defined notion of fixed point, under any center initialization and value of $Ï$. Second, we prove that, as $Ï$ increases, the family of fixed points produced by DGC-$\mathcal{F}_Ï$ converges to a notion of consensus fixed points. We show that consensus fixed points of DGC-$\mathcal{F}_Ï$ are equivalent to fixed points of gradient clustering over the full data, guaranteeing a clustering of the full data is produced. For the special case of Bregman losses, we show that our fixed points converge to the set of Lloyd points. Extensive numerical experiments on synthetic and real data confirm our theoretical findings, show strong performance of our methods and demonstrate the usefulness and wide range of potential applications of our general framework, such as outlier detection.
<div id='section'>Paperid: <span id='pid'>823, <a href='https://arxiv.org/pdf/2512.18495.pdf' target='_blank'>https://arxiv.org/pdf/2512.18495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Yumlembam, Biju Issac, Seibu Mary Jacob
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.18495">Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence techniques have achieved strong performance in classifying Windows Portable Executable (PE) malware, but their reliability often degrades under dataset shifts, leading to misclassifications with severe security consequences. To address this, we enhance an existing LightGBM (LGBM) malware detector by integrating Neural Networks (NN), PriorNet, and Neural Network Ensembles, evaluated across three benchmark datasets: EMBER, BODMAS, and UCSB. The UCSB dataset, composed mainly of packed malware, introduces a substantial distributional shift relative to EMBER and BODMAS, making it a challenging testbed for robustness. We study uncertainty-aware decision strategies, including probability thresholding, PriorNet, ensemble-derived estimates, and Inductive Conformal Evaluation (ICE). Our main contribution is the use of ensemble-based uncertainty estimates as Non-Conformity Measures within ICE, combined with a novel threshold optimisation method. On the UCSB dataset, where the shift is most severe, the state-of-the-art probability-based ICE (SOTA) yields an incorrect acceptance rate (IA%) of 22.8%. In contrast, our method reduces this to 16% a relative reduction of about 30% while maintaining competitive correct acceptance rates (CA%). These results demonstrate that integrating ensemble-based uncertainty with conformal prediction provides a more reliable safeguard against misclassifications under extreme dataset shifts, particularly in the presence of packed malware, thereby offering practical benefits for real-world security operations.
<div id='section'>Paperid: <span id='pid'>824, <a href='https://arxiv.org/pdf/2512.12289.pdf' target='_blank'>https://arxiv.org/pdf/2512.12289.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bingbing Wang, Shengyan Sun, Jiaqi Wang, Yu Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.12289">Robust Outlier Detection and Low-Latency Concept Drift Adaptation for Data Stream Regression: A Dual-Channel Architecture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection and concept drift detection represent two challenges in data analysis. Most studies address these issues separately. However, joint detection mechanisms in regression remain underexplored, where the continuous nature of output spaces makes distinguishing drifts from outliers inherently challenging. To address this, we propose a novel robust regression framework for joint outlier and concept drift detection. Specifically, we introduce a dual-channel decision process that orchestrates prediction residuals into two coupled logic flows: a rapid response channel for filtering point outliers and a deep analysis channel for diagnosing drifts. We further develop the Exponentially Weighted Moving Absolute Deviation with Distinguishable Types (EWMAD-DT) detector to autonomously differentiate between abrupt and incremental drifts via dynamic thresholding. Comprehensive experiments on both synthetic and real-world datasets demonstrate that our unified framework, enhanced by EWMAD-DT, exhibits superior detection performance even when point outliers and concept drifts coexist.
<div id='section'>Paperid: <span id='pid'>825, <a href='https://arxiv.org/pdf/2512.01294.pdf' target='_blank'>https://arxiv.org/pdf/2512.01294.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Song Zhang, Ruohan Guo, Xiaohua Ge, Perter Mahon, Weixiang Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.01294">Experimental Methods, Health Indicators, and Diagnostic Strategies for Retired Lithium-ion Batteries: A Comprehensive Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable health assessment of retired lithium-ion batteries is essential for safe and economically viable second-life deployment, yet remains difficult due to sparse measurements, incomplete historical records, heterogeneous chemistries, and limited or noisy battery health labels. Conventional laboratory diagnostics, such as full charge-discharge cycling, pulse tests, Electrochemical Impedance Spectroscopy (EIS) measurements, and thermal characterization, provide accurate degradation information but are too time-consuming, equipment-intensive, or condition-sensitive to be applied at scale during retirement-stage sorting, leaving real-world datasets fragmented and inconsistent. This review synthesizes recent advances that address these constraints through physical health indicators, experiment testing methods, data-generation and augmentation techniques, and a spectrum of learning-based modeling routes spanning supervised, semi-supervised, weakly supervised, and unsupervised paradigms. We highlight how minimal-test features, synthetic data, domain-invariant representations, and uncertainty-aware prediction enable robust inference under limited or approximate labels and across mixed chemistries and operating histories. A comparative evaluation further reveals trade-offs in accuracy, interpretability, scalability, and computational burden. Looking forward, progress toward physically constrained generative models, cross-chemistry generalization, calibrated uncertainty estimation, and standardized benchmarks will be crucial for building reliable, scalable, and deployment-ready health prediction tools tailored to the realities of retired-battery applications.
<div id='section'>Paperid: <span id='pid'>826, <a href='https://arxiv.org/pdf/2511.22118.pdf' target='_blank'>https://arxiv.org/pdf/2511.22118.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihan Dai, Dimitrios Stamatios Bouras, Haoxiang Jia, Sergey Mechtaev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.22118">Statistical Independence Aware Caching for LLM Workflows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) inference is both expensive and slow. Local caching of responses offers a practical solution to reduce the cost and latency of LLM queries. In research contexts, caching also enhances reproducibility and provides flexibility for experimentation. However, naive reuse of cached responses compromises statistical independence, a critical property for probabilistic workflows. In applications of LLM for code, it underpins performance metrics such as Pass@k and uncertainty estimation, as well as algorithms like program repair loops and retries. Existing LLM caching systems lack ways to enforce statistical independence constraints. To address this, we introduce Mnimi, a cache design pattern that supports modular LLM workflows while ensuring statistical integrity at the component level. Its core innovation lies in encapsulating statistical constraints within the type of LLM references, allowing users to manage and transform these types according to the scope and requirements of their algorithm. We implemented this design pattern in Python using a combination of decorators and iterators over infinite sequences. A case study on SpecFix, an recent automated program specification repair system, highlights how Mnimi improves reproducibility, ease of debugging, time and cost efficiency while preserving statistical correctness.
<div id='section'>Paperid: <span id='pid'>827, <a href='https://arxiv.org/pdf/2511.21057.pdf' target='_blank'>https://arxiv.org/pdf/2511.21057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin Hong, Xinze Sun, Yinhao Li, Yen-Wei Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.21057">Long-Term Alzheimers Disease Prediction: A Novel Image Generation Method Using Temporal Parameter Estimation with Normal Inverse Gamma Distribution on Uneven Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image generation can provide physicians with an imaging diagnosis basis in the prediction of Alzheimer's Disease (AD). Recent research has shown that long-term AD predictions by image generation often face difficulties maintaining disease-related characteristics when dealing with irregular time intervals in sequential data. Considering that the time-related aspects of the distribution can reflect changes in disease-related characteristics when images are distributed unevenly, this research proposes a model to estimate the temporal parameter within the Normal Inverse Gamma Distribution (T-NIG) to assist in generating images over the long term. The T-NIG model employs brain images from two different time points to create intermediate brain images, forecast future images, and predict the disease. T-NIG is designed by identifying features using coordinate neighborhoods. It incorporates a time parameter into the normal inverse gamma distribution to understand how features change in brain imaging sequences that have varying time intervals. Additionally, T-NIG utilizes uncertainty estimation to reduce both epistemic and aleatoric uncertainties in the model, which arise from insufficient temporal data. In particular, the T-NIG model demonstrates state-of-the-art performance in both short-term and long-term prediction tasks within the dataset. Experimental results indicate that T-NIG is proficient in forecasting disease progression while maintaining disease-related characteristics, even when faced with an irregular temporal data distribution.
<div id='section'>Paperid: <span id='pid'>828, <a href='https://arxiv.org/pdf/2511.19487.pdf' target='_blank'>https://arxiv.org/pdf/2511.19487.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ben Shaw, Adam Rustad, Sofia Pelagalli Maia, Jake S. Rhodes, Kevin R. Moon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.19487">The Generalized Proximity Forest</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent work has demonstrated the utility of Random Forest (RF) proximities for various supervised machine learning tasks, including outlier detection, missing data imputation, and visualization. However, the utility of the RF proximities depends upon the success of the RF model, which itself is not the ideal model in all contexts. RF proximities have recently been extended to time series by means of the distance-based Proximity Forest (PF) model, among others, affording time series analysis with the benefits of RF proximities. In this work, we introduce the generalized PF model, thereby extending RF proximities to all contexts in which supervised distance-based machine learning can occur. Additionally, we introduce a variant of the PF model for regression tasks. We also introduce the notion of using the generalized PF model as a meta-learning framework, extending supervised imputation capability to any pre-trained classifier. We experimentally demonstrate the unique advantages of the generalized PF model compared with both the RF model and the $k$-nearest neighbors model.
<div id='section'>Paperid: <span id='pid'>829, <a href='https://arxiv.org/pdf/2511.06459.pdf' target='_blank'>https://arxiv.org/pdf/2511.06459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huanbo Lyu, Daniel Herring, Shiqiao Zhou, Miqing Li, Zheming Zuo, Jelena Ninic, James Andrews, Fabian Spill, Shuo Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.06459">Uncertainty-Aware Dual-Ranking Strategy for Offline Data-Driven Multi-Objective Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline data-driven Multi-Objective Optimization Problems (MOPs) rely on limited data from simulations, experiments, or sensors. This scarcity leads to high epistemic uncertainty in surrogate predictions. Conventional surrogate methods such as Kriging assume Gaussian distributions, which can yield suboptimal results when the assumptions fail. To address these issues, we propose a simple yet novel dual-ranking strategy, working with a basic multi-objective evolutionary algorithm, NSGA-II, where the built-in non-dominated sorting is kept and the second rank is devised for uncertainty estimation. In the latter, we utilize the uncertainty estimates given by several surrogate models, including Quantile Regression (QR), Monte Carlo Dropout (MCD), and Bayesian Neural Networks (BNNs). Concretely, with this dual-ranking strategy, each solution's final rank is the average of its non-dominated sorting rank and a rank derived from the uncertainty-adjusted fitness function, thus reducing the risk of misguided optimization under data constraints. We evaluate our approach on benchmark and real-world MOPs, comparing it to state-of-the-art methods. The results show that our dual-ranking strategy significantly improves the performance of NSGA-II in offline settings, achieving competitive outcomes compared with traditional surrogate-based methods. This framework advances uncertainty-aware multi-objective evolutionary algorithms, offering a robust solution for data-limited, real-world applications.
<div id='section'>Paperid: <span id='pid'>830, <a href='https://arxiv.org/pdf/2511.05523.pdf' target='_blank'>https://arxiv.org/pdf/2511.05523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ciaran O'Connor, Mohamed Bahloul, Steven Prestwich, Andrea Visentin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.05523">The Evolution of Probabilistic Price Forecasting Techniques: A Review of the Day-Ahead, Intra-Day, and Balancing Markets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electricity price forecasting has become a critical tool for decision-making in energy markets, particularly as the increasing penetration of renewable energy introduces greater volatility and uncertainty. Historically, research in this field has been dominated by point forecasting methods, which provide single-value predictions but fail to quantify uncertainty. However, as power markets evolve due to renewable integration, smart grids, and regulatory changes, the need for probabilistic forecasting has become more pronounced, offering a more comprehensive approach to risk assessment and market participation. This paper presents a review of probabilistic forecasting methods, tracing their evolution from Bayesian and distribution based approaches, through quantile regression techniques, to recent developments in conformal prediction. Particular emphasis is placed on advancements in probabilistic forecasting, including validity-focused methods which address key limitations in uncertainty estimation. Additionally, this review extends beyond the Day-Ahead Market to include the Intra-Day and Balancing Markets, where forecasting challenges are intensified by higher temporal granularity and real-time operational constraints. We examine state of the art methodologies, key evaluation metrics, and ongoing challenges, such as forecast validity, model selection, and the absence of standardised benchmarks, providing researchers and practitioners with a comprehensive and timely resource for navigating the complexities of modern electricity markets.
<div id='section'>Paperid: <span id='pid'>831, <a href='https://arxiv.org/pdf/2510.22734.pdf' target='_blank'>https://arxiv.org/pdf/2510.22734.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanhao Lai, Pengfei Zheng, Chenpeng Ji, Yan Li, Songhan Zhang, Rutao Zhang, Zhengang Wang, Yunfei Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.22734">Centrum: Model-based Database Auto-tuning with Minimal Distributional Assumptions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gaussian-Process-based Bayesian optimization (GP-BO), is a prevailing model-based framework for DBMS auto-tuning. However, recent work shows GP-BO-based DBMS auto-tuners significantly outperformed auto-tuners based on SMAC, which features random forest surrogate models; such results motivate us to rethink and investigate the limitations of GP-BO in auto-tuner design. We find the fundamental assumptions of GP-BO are widely violated when modeling and optimizing DBMS performance, while tree-ensemble-BOs (e.g., SMAC) can avoid the assumption pitfalls and deliver improved tuning efficiency and effectiveness. Moreover, we argue that existing tree-ensemble-BOs restrict further advancement in DBMS auto-tuning. First, existing tree-ensemble-BOs can only achieve distribution-free point estimates, but still impose unrealistic distributional assumptions on uncertainty estimates, compromising surrogate modeling and distort the acquisition function. Second, recent advances in gradient boosting, which can further enhance surrogate modeling against vanilla GP and random forest counterparts, have rarely been applied in optimizing DBMS auto-tuners. To address these issues, we propose a novel model-based DBMS auto-tuner, Centrum. Centrum improves distribution-free point and interval estimation in surrogate modeling with a two-phase learning procedure of stochastic gradient boosting ensembles. Moreover, Centrum adopts a generalized SGBE-estimated locally-adaptive conformal prediction to facilitate a distribution-free uncertainty estimation and acquisition function. To our knowledge, Centrum is the first auto-tuner to realize distribution-freeness, enhancing BO's practicality in DBMS auto-tuning, and the first to seamlessly fuse gradient boosting ensembles and conformal inference in BO. Extensive physical and simulation experiments on two DBMSs and three workloads show Centrum outperforms 21 SOTA methods.
<div id='section'>Paperid: <span id='pid'>832, <a href='https://arxiv.org/pdf/2510.19364.pdf' target='_blank'>https://arxiv.org/pdf/2510.19364.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Golnaz Raja, Ruslan Agishev, Miloš Prágr, Joni Pajarinen, Karel Zimmermann, Arun Kumar Singh, Reza Ghabcheloo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.19364">ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty-aware robot motion prediction is crucial for downstream traversability estimation and safe autonomous navigation in unstructured, off-road environments, where terrain is heterogeneous and perceptual uncertainty is high. Most existing methods assume deterministic or spatially independent terrain uncertainties, ignoring the inherent local correlations of 3D spatial data and often producing unreliable predictions. In this work, we introduce an efficient probabilistic framework that explicitly models spatially correlated aleatoric uncertainty over terrain parameters as a probabilistic world model and propagates this uncertainty through a differentiable physics engine for probabilistic trajectory forecasting. By leveraging structured convolutional operators, our approach provides high-resolution multivariate predictions at manageable computational cost. Experimental evaluation on a publicly available dataset shows significantly improved uncertainty estimation and trajectory prediction accuracy over aleatoric uncertainty estimation baselines.
<div id='section'>Paperid: <span id='pid'>833, <a href='https://arxiv.org/pdf/2510.17727.pdf' target='_blank'>https://arxiv.org/pdf/2510.17727.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ege Beyazit, KL Navaneet, Prashant Mathur, Roi Blanco, Vidit Bansal, Karim Bouyarmane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.17727">Enabling Fine-Grained Operating Points for Black-Box LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Black-box Large Language Models (LLMs) provide practical and accessible alternatives to other machine learning methods, as they require minimal labeled data and machine learning expertise to develop solutions for various decision making problems. However, for applications that need operating with constraints on specific metrics (e.g., precision $\geq$ 95%), decision making with black-box LLMs remains unfavorable, due to their low numerical output cardinalities. This results in limited control over their operating points, preventing fine-grained adjustment of their decision making behavior. In this paper, we study using black-box LLMs as classifiers, focusing on efficiently improving their operational granularity without performance loss. Specifically, we first investigate the reasons behind their low-cardinality numerical outputs and show that they are biased towards generating rounded but informative verbalized probabilities. Then, we experiment with standard prompt engineering, uncertainty estimation and confidence elicitation techniques, and observe that they do not effectively improve operational granularity without sacrificing performance or increasing inference cost. Finally, we propose efficient approaches to significantly increase the number and diversity of available operating points. Our proposed approaches provide finer-grained operating points and achieve comparable to or better performance than the benchmark methods across 11 datasets and 3 LLMs.
<div id='section'>Paperid: <span id='pid'>834, <a href='https://arxiv.org/pdf/2510.08631.pdf' target='_blank'>https://arxiv.org/pdf/2510.08631.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanieh Shojaei Miandashti, Claus Brenner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.08631">Out-of-Distribution Detection in LiDAR Semantic Segmentation Using Epistemic Uncertainty from Hierarchical GMMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In addition to accurate scene understanding through precise semantic segmentation of LiDAR point clouds, detecting out-of-distribution (OOD) objects, instances not encountered during training, is essential to prevent the incorrect assignment of unknown objects to known classes. While supervised OOD detection methods depend on auxiliary OOD datasets, unsupervised methods avoid this requirement but typically rely on predictive entropy, the entropy of the predictive distribution obtained by averaging over an ensemble or multiple posterior weight samples. However, these methods often conflate epistemic (model) and aleatoric (data) uncertainties, misclassifying ambiguous in distribution regions as OOD. To address this issue, we present an unsupervised OOD detection approach that employs epistemic uncertainty derived from hierarchical Bayesian modeling of Gaussian Mixture Model (GMM) parameters in the feature space of a deep neural network. Without requiring auxiliary data or additional training stages, our approach outperforms existing uncertainty-based methods on the SemanticKITTI dataset, achieving an 18\% improvement in AUROC, 22\% increase in AUPRC, and 36\% reduction in FPR95 (from 76\% to 40\%), compared to the predictive entropy approach used in prior works.
<div id='section'>Paperid: <span id='pid'>835, <a href='https://arxiv.org/pdf/2510.06007.pdf' target='_blank'>https://arxiv.org/pdf/2510.06007.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hans Weytjens, Wouter Verbeke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06007">Uncertainty in Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This book chapter introduces the principles and practical applications of uncertainty quantification in machine learning. It explains how to identify and distinguish between different types of uncertainty and presents methods for quantifying uncertainty in predictive models, including linear regression, random forests, and neural networks. The chapter also covers conformal prediction as a framework for generating predictions with predefined confidence intervals. Finally, it explores how uncertainty estimation can be leveraged to improve business decision-making, enhance model reliability, and support risk-aware strategies.
<div id='section'>Paperid: <span id='pid'>836, <a href='https://arxiv.org/pdf/2509.21943.pdf' target='_blank'>https://arxiv.org/pdf/2509.21943.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlo Dindorf, Jonas Dully, Steven Simon, Dennis Perchthaler, Stephan Becker, Hannah Ehmann, Kjell Heitmann, Bernd Stetter, Christian Diers, Michael FrÃ¶hlich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21943">Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Plantar pressure mapping is essential in clinical diagnostics and sports science, yet large heterogeneous datasets often contain outliers from technical errors or procedural inconsistencies. Statistical Parametric Mapping (SPM) provides interpretable analyses but is sensitive to alignment and its capacity for robust outlier detection remains unclear. This study compares an SPM approach with an explainable machine learning (ML) approach to establish transparent quality-control pipelines for plantar pressure datasets. Data from multiple centers were annotated by expert consensus and enriched with synthetic anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a non-parametric, registration-dependent SPM approach and (ii) a convolutional neural network (CNN), explained using SHapley Additive exPlanations (SHAP). Performance was assessed via nested cross-validation; explanation quality via a semantic differential survey with domain experts. The ML model reached high accuracy and outperformed SPM, which misclassified clinically meaningful variations and missed true outliers. Experts perceived both SPM and SHAP explanations as clear, useful, and trustworthy, though SPM was assessed less complex. These findings highlight the complementary potential of SPM and explainable ML as approaches for automated outlier detection in plantar pressure data, and underscore the importance of explainability in translating complex model outputs into interpretable insights that can effectively inform decision-making.
<div id='section'>Paperid: <span id='pid'>837, <a href='https://arxiv.org/pdf/2509.19366.pdf' target='_blank'>https://arxiv.org/pdf/2509.19366.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Buhe Li, Berkay Kaplan, Maksym Lazirko, Aleksandr Kogan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19366">Unsupervised Outlier Detection in Audit Analytics: A Case Study Using USA Spending Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the effectiveness of unsupervised outlier detection methods in audit analytics, utilizing USA spending data from the U.S. Department of Health and Human Services (DHHS) as a case example. We employ and compare multiple outlier detection algorithms, including Histogram-based Outlier Score (HBOS), Robust Principal Component Analysis (PCA), Minimum Covariance Determinant (MCD), and K-Nearest Neighbors (KNN) to identify anomalies in federal spending patterns. The research addresses the growing need for efficient and accurate anomaly detection in large-scale governmental datasets, where traditional auditing methods may fall short. Our methodology involves data preparation, algorithm implementation, and performance evaluation using precision, recall, and F1 scores. Results indicate that a hybrid approach, combining multiple detection strategies, enhances the robustness and accuracy of outlier identification in complex financial data. This study contributes to the field of audit analytics by providing insights into the comparative effectiveness of various outlier detection models and demonstrating the potential of unsupervised learning techniques in improving audit quality and efficiency. The findings have implications for auditors, policymakers, and researchers seeking to leverage advanced analytics in governmental financial oversight and risk management.
<div id='section'>Paperid: <span id='pid'>838, <a href='https://arxiv.org/pdf/2509.11689.pdf' target='_blank'>https://arxiv.org/pdf/2509.11689.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeremiah Fadugba, Petru Manescu, Bolanle Oladejo, Delmiro Fernandez-Reyes, Philipp Berens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11689">Uncertainty-Aware Retinal Vessel Segmentation via Ensemble Distillation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is critical for reliable medical image segmentation, particularly in retinal vessel analysis, where accurate predictions are essential for diagnostic applications. Deep Ensembles, where multiple networks are trained individually, are widely used to improve medical image segmentation performance. However, training and testing costs increase with the number of ensembles. In this work, we propose Ensemble Distillation as a robust alternative to commonly used uncertainty estimation techniques by distilling the knowledge of multiple ensemble models into a single model. Through extensive experiments on the DRIVE and FIVES datasets, we demonstrate that Ensemble Distillation achieves comparable performance via calibration and segmentation metrics, while significantly reducing computational complexity. These findings suggest that Ensemble distillation provides an efficient and reliable approach for uncertainty estimation in the segmentation of the retinal vessels, making it a promising tool for medical imaging applications.
<div id='section'>Paperid: <span id='pid'>839, <a href='https://arxiv.org/pdf/2509.08947.pdf' target='_blank'>https://arxiv.org/pdf/2509.08947.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yancheng Cai, Robert Wanat, Rafal Mantiuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08947">CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via Camera and Visual Difference Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate measurement of images produced by electronic displays is critical for the evaluation of both traditional and computational displays. Traditional display measurement methods based on sparse radiometric sampling and fitting a model are inadequate for capturing spatially varying display artifacts, as they fail to capture high-frequency and pixel-level distortions. While cameras offer sufficient spatial resolution, they introduce optical, sampling, and photometric distortions. Furthermore, the physical measurement must be combined with a model of a visual system to assess whether the distortions are going to be visible. To enable perceptual assessment of displays, we propose a combination of a camera-based reconstruction pipeline with a visual difference predictor, which account for both the inaccuracy of camera measurements and visual difference prediction. The reconstruction pipeline combines HDR image stacking, MTF inversion, vignetting correction, geometric undistortion, homography transformation, and color correction, enabling cameras to function as precise display measurement instruments. By incorporating a Visual Difference Predictor (VDP), our system models the visibility of various stimuli under different viewing conditions for the human visual system. We validate the proposed CameraVDP framework through three applications: defective pixel detection, color fringing awareness, and display non-uniformity evaluation. Our uncertainty analysis framework enables the estimation of the theoretical upper bound for defect pixel detection performance and provides confidence intervals for VDP quality scores.
<div id='section'>Paperid: <span id='pid'>840, <a href='https://arxiv.org/pdf/2509.07415.pdf' target='_blank'>https://arxiv.org/pdf/2509.07415.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arslan Majal, Aamir Hussain Chughtai, Muhammad Tahir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07415">EMORF-II: Adaptive EM-based Outlier-Robust Filtering with Correlated Measurement Noise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a learning-based outlier-robust filter for a general setup where the measurement noise can be correlated. Since it is an enhanced version of EM-based outlier robust filter (EMORF), we call it as EMORF-II. As it is equipped with an additional powerful feature to learn the outlier characteristics during inference along with outlier-detection, EMORF-II has improved outlier-mitigation capability. Numerical experiments confirm performance gains as compared to the state-of-the-art methods in terms of accuracy with an increased computational overhead. However, thankfully the computational complexity order remains at par with other practical methods making it a useful choice for diverse applications.
<div id='section'>Paperid: <span id='pid'>841, <a href='https://arxiv.org/pdf/2509.06918.pdf' target='_blank'>https://arxiv.org/pdf/2509.06918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tarhib Al Azad, Shahana Ibrahim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06918">Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution Detection via Loss Correction and Low-rank Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robust out-of-distribution (OOD) detection is an indispensable component of modern artificial intelligence (AI) systems, especially in safety-critical applications where models must identify inputs from unfamiliar classes not seen during training. While OOD detection has been extensively studied in the machine learning literature--with both post hoc and training-based approaches--its effectiveness under noisy training labels remains underexplored. Recent studies suggest that label noise can significantly degrade OOD performance, yet principled solutions to this issue are lacking. In this work, we demonstrate that directly combining existing label noise-robust methods with OOD detection strategies is insufficient to address this critical challenge. To overcome this, we propose a robust OOD detection framework that integrates loss correction techniques from the noisy label learning literature with low-rank and sparse decomposition methods from signal processing. Extensive experiments on both synthetic and real-world datasets demonstrate that our method significantly outperforms the state-of-the-art OOD detection techniques, particularly under severe noisy label settings.
<div id='section'>Paperid: <span id='pid'>842, <a href='https://arxiv.org/pdf/2509.05877.pdf' target='_blank'>https://arxiv.org/pdf/2509.05877.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marzieh Ajirak, Anand Ravishankar, Petar M. Djuric
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05877">Uncertainty Quantification in Probabilistic Machine Learning Models: Theory, Methods, and Insights</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty Quantification (UQ) is essential in probabilistic machine learning models, particularly for assessing the reliability of predictions. In this paper, we present a systematic framework for estimating both epistemic and aleatoric uncertainty in probabilistic models. We focus on Gaussian Process Latent Variable Models and employ scalable Random Fourier Features-based Gaussian Processes to approximate predictive distributions efficiently. We derive a theoretical formulation for UQ, propose a Monte Carlo sampling-based estimation method, and conduct experiments to evaluate the impact of uncertainty estimation. Our results provide insights into the sources of predictive uncertainty and illustrate the effectiveness of our approach in quantifying the confidence in the predictions.
<div id='section'>Paperid: <span id='pid'>843, <a href='https://arxiv.org/pdf/2508.21773.pdf' target='_blank'>https://arxiv.org/pdf/2508.21773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nattapong Kurpukdee, Adrian G. Bors
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21773">Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a realistic scenario for the unsupervised video learning where neither task boundaries nor labels are provided when learning a succession of tasks. We also provide a non-parametric learning solution for the under-explored problem of unsupervised video continual learning. Videos represent a complex and rich spatio-temporal media information, widely used in many applications, but which have not been sufficiently explored in unsupervised continual learning. Prior studies have only focused on supervised continual learning, relying on the knowledge of labels and task boundaries, while having labeled data is costly and not practical. To address this gap, we study the unsupervised video continual learning (uVCL). uVCL raises more challenges due to the additional computational and memory requirements of processing videos when compared to images. We introduce a general benchmark experimental protocol for uVCL by considering the learning of unstructured video data categories during each task. We propose to use the Kernel Density Estimation (KDE) of deep embedded video features extracted by unsupervised video transformer networks as a non-parametric probabilistic representation of the data. We introduce a novelty detection criterion for the incoming new task data, dynamically enabling the expansion of memory clusters, aiming to capture new knowledge when learning a succession of tasks. We leverage the use of transfer learning from the previous tasks as an initial state for the knowledge transfer to the current learning task. We found that the proposed methodology substantially enhances the performance of the model when successively learning many tasks. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, without using any labels or class boundaries.
<div id='section'>Paperid: <span id='pid'>844, <a href='https://arxiv.org/pdf/2508.04457.pdf' target='_blank'>https://arxiv.org/pdf/2508.04457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Baur, Wojciech Samek, Jackie Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04457">Benchmarking Uncertainty and its Disentanglement in multi-label Chest X-Ray Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty quantification is crucial for trustworthy decision-making and the deployment of AI models in medical imaging. While prior work has explored the ability of neural networks to quantify predictive, epistemic, and aleatoric uncertainties using an information-theoretical approach in synthetic or well defined data settings like natural image classification, its applicability to real life medical diagnosis tasks remains underexplored. In this study, we provide an extensive uncertainty quantification benchmark for multi-label chest X-ray classification using the MIMIC-CXR-JPG dataset. We evaluate 13 uncertainty quantification methods for convolutional (ResNet) and transformer-based (Vision Transformer) architectures across a wide range of tasks. Additionally, we extend Evidential Deep Learning, HetClass NNs, and Deep Deterministic Uncertainty to the multi-label setting. Our analysis provides insights into uncertainty estimation effectiveness and the ability to disentangle epistemic and aleatoric uncertainties, revealing method- and architecture-specific strengths and limitations.
<div id='section'>Paperid: <span id='pid'>845, <a href='https://arxiv.org/pdf/2507.01417.pdf' target='_blank'>https://arxiv.org/pdf/2507.01417.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Gu, Ziyue Qiao, Zechao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01417">Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is critical for safely deploying deep models in open-world environments, where inputs may lie outside the training distribution. During inference on a model trained exclusively with In-Distribution (ID) data, we observe a salient gradient phenomenon: around an ID sample, the local gradient directions for "enhancing" that sample's predicted class remain relatively consistent, whereas OOD samples--unseen in training--exhibit disorganized or conflicting gradient directions in the same neighborhood. Motivated by this observation, we propose an inference-stage technique to short-circuit those feature coordinates that spurious gradients exploit to inflate OOD confidence, while leaving ID classification largely intact. To circumvent the expense of recomputing the logits after this gradient short-circuit, we further introduce a local first-order approximation that accurately captures the post-modification outputs without a second forward pass. Experiments on standard OOD benchmarks show our approach yields substantial improvements. Moreover, the method is lightweight and requires minimal changes to the standard inference pipeline, offering a practical path toward robust OOD detection in real-world applications.
<div id='section'>Paperid: <span id='pid'>846, <a href='https://arxiv.org/pdf/2505.15240.pdf' target='_blank'>https://arxiv.org/pdf/2505.15240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yassir Fathullah, Mark J. F. Gales
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15240">Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores generalised probabilistic modelling and uncertainty estimation in comparative LLM-as-a-judge frameworks. We show that existing Product-of-Experts methods are specific cases of a broader framework, enabling diverse modelling options. Furthermore, we propose improved uncertainty estimates for individual comparisons, enabling more efficient selection and achieving strong performance with fewer evaluations. We also introduce a method for estimating overall ranking uncertainty. Finally, we demonstrate that combining absolute and comparative scoring improves performance. Experiments show that the specific expert model has a limited impact on final rankings but our proposed uncertainty estimates, especially the probability of reordering, significantly improve the efficiency of systems reducing the number of needed comparisons by ~50%. Furthermore, ranking-level uncertainty metrics can be used to identify low-performing predictions, where the nature of the probabilistic model has a notable impact on the quality of the overall uncertainty.
<div id='section'>Paperid: <span id='pid'>847, <a href='https://arxiv.org/pdf/2505.15177.pdf' target='_blank'>https://arxiv.org/pdf/2505.15177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Gu, Ziyue Qiao, Zechao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15177">SpectralGap: Graph-Level Out-of-Distribution Detection via Laplacian Eigenvalue Gaps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The task of graph-level out-of-distribution (OOD) detection is crucial for deploying graph neural networks in real-world settings. In this paper, we observe a significant difference in the relationship between the largest and second-largest eigenvalues of the Laplacian matrix for in-distribution (ID) and OOD graph samples: \textit{OOD samples often exhibit anomalous spectral gaps (the difference between the largest and second-largest eigenvalues)}. This observation motivates us to propose SpecGap, an effective post-hoc approach for OOD detection on graphs. SpecGap adjusts features by subtracting the component associated with the second-largest eigenvalue, scaled by the spectral gap, from the high-level features (i.e., $\mathbf{X}-\left(Î»_n-Î»_{n-1}\right) \mathbf{u}_{n-1} \mathbf{v}_{n-1}^T$). SpecGap achieves state-of-the-art performance across multiple benchmark datasets. We present extensive ablation studies and comprehensive theoretical analyses to support our empirical results. As a parameter-free post-hoc method, SpecGap can be easily integrated into existing graph neural network models without requiring any additional training or model modification.
<div id='section'>Paperid: <span id='pid'>848, <a href='https://arxiv.org/pdf/2504.18746.pdf' target='_blank'>https://arxiv.org/pdf/2504.18746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brian K. S. Isaac-Medina, Toby P. Breckon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18746">Dream-Box: Object-wise Outlier Generation for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have demonstrated great generalization capabilities for tasks whose training and test sets are drawn from the same distribution. Nevertheless, out-of-distribution (OOD) detection remains a challenging task that has received significant attention in recent years. Specifically, OOD detection refers to the detection of instances that do not belong to the training distribution, while still having good performance on the in-distribution task (e.g., classification or object detection). Recent work has focused on generating synthetic outliers and using them to train an outlier detector, generally achieving improved OOD detection than traditional OOD methods. In this regard, outliers can be generated either in feature or pixel space. Feature space driven methods have shown strong performance on both the classification and object detection tasks, at the expense that the visualization of training outliers remains unknown, making further analysis on OOD failure modes challenging. On the other hand, pixel space outlier generation techniques enabled by diffusion models have been used for image classification using, providing improved OOD detection performance and outlier visualization, although their adaption to the object detection task is as yet unexplored. We therefore introduce Dream-Box, a method that provides a link to object-wise outlier generation in the pixel space for OOD detection. Specifically, we use diffusion models to generate object-wise outliers that are used to train an object detector for an in-distribution task and OOD detection. Our method achieves comparable performance to previous traditional methods while being the first technique to provide concrete visualization of generated OOD objects.
<div id='section'>Paperid: <span id='pid'>849, <a href='https://arxiv.org/pdf/2504.15722.pdf' target='_blank'>https://arxiv.org/pdf/2504.15722.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Huang, Simone Rossi, Rui Yuan, Thomas Hannagan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15722">From predictions to confidence intervals: an empirical study of conformal prediction methods for in-context learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformers have become a standard architecture in machine learning, demonstrating strong in-context learning (ICL) abilities that allow them to learn from the prompt at inference time. However, uncertainty quantification for ICL remains an open challenge, particularly in noisy regression tasks. This paper investigates whether ICL can be leveraged for distribution-free uncertainty estimation, proposing a method based on conformal prediction to construct prediction intervals with guaranteed coverage. While traditional conformal methods are computationally expensive due to repeated model fitting, we exploit ICL to efficiently generate confidence intervals in a single forward pass. Our empirical analysis compares this approach against ridge regression-based conformal methods, showing that conformal prediction with in-context learning (CP with ICL) achieves robust and scalable uncertainty estimates. Additionally, we evaluate its performance under distribution shifts and establish scaling laws to guide model training. These findings bridge ICL and conformal prediction, providing a theoretically grounded and new framework for uncertainty quantification in transformer-based models.
<div id='section'>Paperid: <span id='pid'>850, <a href='https://arxiv.org/pdf/2503.13246.pdf' target='_blank'>https://arxiv.org/pdf/2503.13246.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guoyou Sun, Panagiotis Karras, Qi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13246">Highly Efficient Direct Analytics on Semantic-aware Time Series Data Compression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic communication has emerged as a promising paradigm to tackle the challenges of massive growing data traffic and sustainable data communication. It shifts the focus from data fidelity to goal-oriented or task-oriented semantic transmission. While deep learning-based methods are commonly used for semantic encoding and decoding, they struggle with the sequential nature of time series data and high computation cost, particularly in resource-constrained IoT environments. Data compression plays a crucial role in reducing transmission and storage costs, yet traditional data compression methods fall short of the demands of goal-oriented communication systems. In this paper, we propose a novel method for direct analytics on time series data compressed by the SHRINK compression algorithm. Through experimentation using outlier detection as a case study, we show that our method outperforms baselines running on uncompressed data in multiple cases, with merely 1% difference in the worst case. Additionally, it achieves four times lower runtime on average and accesses approximately 10% of the data volume, which enables edge analytics with limited storage and computation power. These results demonstrate that our approach offers reliable, high-speed outlier detection analytics for diverse IoT applications while extracting semantics from time-series data, achieving high compression, and reducing data transmission.
<div id='section'>Paperid: <span id='pid'>851, <a href='https://arxiv.org/pdf/2503.01691.pdf' target='_blank'>https://arxiv.org/pdf/2503.01691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuyan Chen, Nico Lang, B. Christian Schmidt, Aditya Jain, Yves Basset, Sara Beery, Maxim LarrivÃ©e, David Rolnick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.01691">Open-Set Recognition of Novel Species in Biodiversity Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning is increasingly being applied to facilitate long-term, large-scale biodiversity monitoring. With most species on Earth still undiscovered or poorly documented, species-recognition models are expected to encounter new species during deployment. We introduce Open-Insects, a fine-grained image recognition benchmark dataset for open-set recognition and out-of-distribution detection in biodiversity monitoring. Open-Insects makes it possible to evaluate algorithms for new species detection on several geographical open-set splits with varying difficulty. Furthermore, we present a test set recently collected in the wild with 59 species that are likely new to science. We evaluate a variety of open-set recognition algorithms, including post-hoc methods, training-time regularization, and training with auxiliary data, finding that the simple post-hoc approach of utilizing softmax scores remains a strong baseline. We also demonstrate how to leverage auxiliary data to improve the detection performance when the training dataset is limited. Our results provide timely insights to guide the development of computer vision methods for biodiversity monitoring and species discovery.
<div id='section'>Paperid: <span id='pid'>852, <a href='https://arxiv.org/pdf/2502.04381.pdf' target='_blank'>https://arxiv.org/pdf/2502.04381.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Kim, Anna Podlasek, Kie Shidara, Feng Liu, Ahmed Alaa, Danilo Bernardo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04381">Limitations of Large Language Models in Clinical Problem-Solving Arising from Inflexible Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have attained human-level accuracy on medical question-answer (QA) benchmarks. However, their limitations in navigating open-ended clinical scenarios have recently been shown, raising concerns about the robustness and generalizability of LLM reasoning across diverse, real-world medical tasks. To probe potential LLM failure modes in clinical problem-solving, we present the medical abstraction and reasoning corpus (M-ARC). M-ARC assesses clinical reasoning through scenarios designed to exploit the Einstellung effect -- the fixation of thought arising from prior experience, targeting LLM inductive biases toward inflexible pattern matching from their training data rather than engaging in flexible reasoning. We find that LLMs, including current state-of-the-art o1 and Gemini models, perform poorly compared to physicians on M-ARC, often demonstrating lack of commonsense medical reasoning and a propensity to hallucinate. In addition, uncertainty estimation analyses indicate that LLMs exhibit overconfidence in their answers, despite their limited accuracy. The failure modes revealed by M-ARC in LLM medical reasoning underscore the need to exercise caution when deploying these models in clinical settings.
<div id='section'>Paperid: <span id='pid'>853, <a href='https://arxiv.org/pdf/2501.05530.pdf' target='_blank'>https://arxiv.org/pdf/2501.05530.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Shi, Nedret Billor, Elvan Ceyhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05530">Outlyingness Scores with Cluster Catch Digraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces two novel, outlyingness scores (OSs) based on Cluster Catch Digraphs (CCDs): Outbound Outlyingness Score (OOS) and Inbound Outlyingness Score (IOS). These scores enhance the interpretability of outlier detection results. Both OSs employ graph-, density-, and distribution-based techniques, tailored to high-dimensional data with varying cluster shapes and intensities. OOS evaluates the outlyingness of a point relative to its nearest neighbors, while IOS assesses the total ``influence" a point receives from others within its cluster. Both OSs effectively identify global and local outliers, invariant to data collinearity. Moreover, IOS is robust to the masking problems. With extensive Monte Carlo simulations, we compare the performance of both OSs with CCD-based, traditional, and state-of-the-art outlier detection methods. Both OSs exhibit substantial overall improvements over the CCD-based methods in both artificial and real-world data sets, particularly with IOS, which delivers the best overall performance among all the methods, especially in high-dimensional settings.
  Keywords: Outlier detection, Outlyingness score, Graph-based clustering, Cluster catch digraphs, High-dimensional data.
<div id='section'>Paperid: <span id='pid'>854, <a href='https://arxiv.org/pdf/2412.03178.pdf' target='_blank'>https://arxiv.org/pdf/2412.03178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gianni Franchi, Dat Nguyen Trong, Nacim Belkhir, Guoxuan Xia, Andrea Pilzer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03178">Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification in text-to-image (T2I) generative models is crucial for understanding model behavior and improving output reliability. In this paper, we are the first to quantify and evaluate the uncertainty of T2I models with respect to the prompt. Alongside adapting existing approaches designed to measure uncertainty in the image space, we also introduce Prompt-based UNCertainty Estimation for T2I models (PUNC), a novel method leveraging Large Vision-Language Models (LVLMs) to better address uncertainties arising from the semantics of the prompt and generated images. PUNC utilizes a LVLM to caption a generated image, and then compares the caption with the original prompt in the more semantically meaningful text space. PUNC also enables the disentanglement of both aleatoric and epistemic uncertainties via precision and recall, which image-space approaches are unable to do. Extensive experiments demonstrate that PUNC outperforms state-of-the-art uncertainty estimation techniques across various settings. Uncertainty quantification in text-to-image generation models can be used on various applications including bias detection, copyright protection, and OOD detection. We also introduce a comprehensive dataset of text prompts and generation pairs to foster further research in uncertainty quantification for generative models. Our findings illustrate that PUNC not only achieves competitive performance but also enables novel applications in evaluating and improving the trustworthiness of text-to-image models.
<div id='section'>Paperid: <span id='pid'>855, <a href='https://arxiv.org/pdf/2412.02904.pdf' target='_blank'>https://arxiv.org/pdf/2412.02904.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ranganath Krishnan, Piyush Khanna, Omesh Tickoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02904">Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have revolutionized the field of natural language processing with their impressive reasoning and question-answering capabilities. However, these models are sometimes prone to generating credible-sounding but incorrect information, a phenomenon known as LLM hallucinations. Reliable uncertainty estimation in LLMs is essential for fostering trust in their generated responses and serves as a critical tool for the detection and prevention of erroneous or hallucinated outputs. To achieve reliable and well-calibrated uncertainty quantification in open-ended and free-form natural language generation, we propose an uncertainty-aware fine-tuning approach for LLMs. This approach enhances the model's ability to provide reliable uncertainty estimates without compromising accuracy, thereby guiding them to produce more trustworthy responses. We introduce a novel uncertainty-aware causal language modeling loss function, grounded in the principles of decision theory. Through rigorous evaluation on multiple free-form question-answering datasets and models, we demonstrate that our uncertainty-aware fine-tuning approach yields better calibrated uncertainty estimates in natural language generation tasks than fine-tuning with the standard causal language modeling loss. Furthermore, the experimental results show that the proposed method significantly improves the model's ability to detect hallucinations and identify out-of-domain prompts.
<div id='section'>Paperid: <span id='pid'>856, <a href='https://arxiv.org/pdf/2412.02408.pdf' target='_blank'>https://arxiv.org/pdf/2412.02408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shabnam Fazliani, Mohammad Mowlavi Sorond, Arsalan Masoudifard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02408">Leveraging Ensemble-Based Semi-Supervised Learning for Illicit Account Detection in Ethereum DeFi Transactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advent of smart contracts has enabled the rapid rise of Decentralized Finance (DeFi) on the Ethereum blockchain, offering substantial rewards in financial innovation and inclusivity. However, this growth has also introduced significant security risks, including the proliferation of illicit accounts involved in fraudulent activities. Traditional detection methods are limited by the scarcity of labeled data and the evolving tactics of malicious actors. In this paper, we propose a novel Self-Learning Ensemble-based Illicit account Detection (SLEID) framework to address these challenges. SLEID employs an Isolation Forest for initial outlier detection and a self-training mechanism to iteratively generate pseudo-labels for unlabeled accounts, thereby enhancing detection accuracy. Extensive experiments demonstrate that SLEID significantly outperforms traditional supervised approaches and recent semi-supervised models, achieving superior precision, recall, and F1-scores, particularly in detecting illicit accounts. Compared to state-of-the-art methods, our approach achieves better detection performance while reducing reliance on labeled data. The results affirm SLEID's efficacy as a robust solution for safeguarding the DeFi ecosystem and mitigating risks posed by malicious accounts.
<div id='section'>Paperid: <span id='pid'>857, <a href='https://arxiv.org/pdf/2412.01596.pdf' target='_blank'>https://arxiv.org/pdf/2412.01596.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brian K. S. Isaac-Medina, Mauricio Che, Yona F. A. Gaus, Samet Akcay, Toby P. Breckon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01596">FEVER-OOD: Free Energy Vulnerability Elimination for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern machine learning models, that excel on computer vision tasks such as classification and object detection, are often overconfident in their predictions for Out-of-Distribution (OOD) examples, resulting in unpredictable behaviour for open-set environments. Recent works have demonstrated that the free energy score is an effective measure of uncertainty for OOD detection given its close relationship to the data distribution. However, despite free energy-based methods representing a significant empirical advance in OOD detection, our theoretical analysis reveals previously unexplored and inherent vulnerabilities within the free energy score formulation such that in-distribution and OOD instances can have distinct feature representations yet identical free energy scores. This phenomenon occurs when the vector direction representing the feature space difference between the in-distribution and OOD sample lies within the null space of the last layer of a neural-based classifier. To mitigate these issues, we explore lower-dimensional feature spaces to reduce the null space footprint and introduce novel regularisation to maximize the least singular value of the final linear layer, hence enhancing inter-sample free energy separation. We refer to these techniques as Free Energy Vulnerability Elimination for Robust Out-of-Distribution Detection (FEVER-OOD). Our experiments show that FEVER-OOD techniques achieve state of the art OOD detection in Imagenet-100, with average OOD false positive rate (at 95% true positive rate) of 35.83% when used with the baseline Dream-OOD model.
<div id='section'>Paperid: <span id='pid'>858, <a href='https://arxiv.org/pdf/2411.17917.pdf' target='_blank'>https://arxiv.org/pdf/2411.17917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Boqi Li, Haojie Zhu, Henry X. Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17917">DECODE: Domain-aware Continual Domain Expansion for Motion Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motion prediction is critical for autonomous vehicles to effectively navigate complex environments and accurately anticipate the behaviors of other traffic participants. As autonomous driving continues to evolve, the need to assimilate new and varied driving scenarios necessitates frequent model updates through retraining. To address these demands, we introduce DECODE, a novel continual learning framework that begins with a pre-trained generalized model and incrementally develops specialized models for distinct domains. Unlike existing continual learning approaches that attempt to develop a unified model capable of generalizing across diverse scenarios, DECODE uniquely balances specialization with generalization, dynamically adjusting to real-time demands. The proposed framework leverages a hypernetwork to generate model parameters, significantly reducing storage requirements, and incorporates a normalizing flow mechanism for real-time model selection based on likelihood estimation. Furthermore, DECODE merges outputs from the most relevant specialized and generalized models using deep Bayesian uncertainty estimation techniques. This integration ensures optimal performance in familiar conditions while maintaining robustness in unfamiliar scenarios. Extensive evaluations confirm the effectiveness of the framework, achieving a notably low forgetting rate of 0.044 and an average minADE of 0.584 m, significantly surpassing traditional learning strategies and demonstrating adaptability across a wide range of driving conditions.
<div id='section'>Paperid: <span id='pid'>859, <a href='https://arxiv.org/pdf/2411.11935.pdf' target='_blank'>https://arxiv.org/pdf/2411.11935.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanieh Shojaei Miandashti, Qianqian Zou, Claus Brenner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11935">Calibrated and Efficient Sampling-Free Confidence Estimation for LiDAR Scene Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable deep learning models require not only accurate predictions but also well-calibrated confidence estimates to ensure dependable uncertainty estimation. This is crucial in safety-critical applications like autonomous driving, which depend on rapid and precise semantic segmentation of LiDAR point clouds for real-time 3D scene understanding. In this work, we introduce a sampling-free approach for estimating well-calibrated confidence values for classification tasks, achieving alignment with true classification accuracy and significantly reducing inference time compared to sampling-based methods. Our evaluation using the Adaptive Calibration Error (ACE) metric for LiDAR semantic segmentation shows that our approach maintains well-calibrated confidence values while achieving increased processing speed compared to a sampling baseline. Additionally, reliability diagrams reveal that our method produces underconfidence rather than overconfident predictions, an advantage for safety-critical applications. Our sampling-free approach offers well-calibrated and time-efficient predictions for LiDAR scene semantic segmentation.
<div id='section'>Paperid: <span id='pid'>860, <a href='https://arxiv.org/pdf/2411.06308.pdf' target='_blank'>https://arxiv.org/pdf/2411.06308.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ezgi Demircan-Tureyen, Felix Lucka, Tristan van Leeuwen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06308">Exploring Out-of-distribution Detection for Sparse-view Computed Tomography with Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent works demonstrate the effectiveness of diffusion models as unsupervised solvers for inverse imaging problems. Sparse-view computed tomography (CT) has greatly benefited from these advancements, achieving improved generalization without reliance on measurement parameters. However, this comes at the cost of potential hallucinations, especially when handling out-of-distribution (OOD) data. To ensure reliability, it is essential to study OOD detection for CT reconstruction across both clinical and industrial applications. This need further extends to enabling the OOD detector to function effectively as an anomaly inspection tool. In this paper, we explore the use of a diffusion model, trained to capture the target distribution for CT reconstruction, as an in-distribution prior. Building on recent research, we employ the model to reconstruct partially diffused input images and assess OOD-ness through multiple reconstruction errors. Adapting this approach for sparse-view CT requires redefining the notions of ``input'' and ``reconstruction error''. Here, we use filtered backprojection (FBP) reconstructions as input and investigate various definitions of reconstruction error. Our proof-of-concept experiments on the MNIST dataset highlight both successes and failures, demonstrating the potential and limitations of integrating such an OOD detector into a CT reconstruction system. Our findings suggest that effective OOD detection can be achieved by comparing measurements with forward-projected reconstructions, provided that reconstructions from noisy FBP inputs are conditioned on the measurements. However, conditioning can sometimes lead the OOD detector to inadvertently reconstruct OOD images well. To counter this, we introduce a weighting approach that improves robustness against highly informative OOD measurements, albeit with a trade-off in performance in certain cases.
<div id='section'>Paperid: <span id='pid'>861, <a href='https://arxiv.org/pdf/2411.04090.pdf' target='_blank'>https://arxiv.org/pdf/2411.04090.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guillermo Villate-Castillo, Javier Del Ser, Borja Sanz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04090">A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Content moderation typically combines the efforts of human moderators and machine learning models. However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception. Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content,an insight missed when only the majority label is considered. In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement. Our approach uses multitask learning, where toxicity classification serves as the primary task and annotation disagreement is addressed as an auxiliary task. Additionally, we leverage uncertainty estimation techniques, specifically Conformal Prediction, to account for both the ambiguity in comment annotations and the model's inherent uncertainty in predicting toxicity and disagreement.The framework also allows moderators to adjust thresholds for annotation disagreement, offering flexibility in determining when ambiguity should trigger a review. We demonstrate that our joint approach enhances model performance, calibration, and uncertainty estimation, while offering greater parameter efficiency and improving the review process in comparison to single-task methods.
<div id='section'>Paperid: <span id='pid'>862, <a href='https://arxiv.org/pdf/2411.02184.pdf' target='_blank'>https://arxiv.org/pdf/2411.02184.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MouÃ¯n Ben Ammar, David Brellmann, Arturo Mendoza, Antoine Manzanera, Gianni Franchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02184">Double Descent Meets Out-of-Distribution Detection: Theoretical Insights and Empirical Analysis on the role of model complexity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for ensuring the reliability and safety of machine learning systems. In recent years, it has received increasing attention, particularly through post-hoc detection and training-based methods. In this paper, we focus on post-hoc OOD detection, which enables identifying OOD samples without altering the model's training procedure or objective. Our primary goal is to investigate the relationship between model capacity and its OOD detection performance. Specifically, we aim to answer the following question: Does the Double Descent phenomenon manifest in post-hoc OOD detection? This question is crucial, as it can reveal whether overparameterization, which is already known to benefit generalization, can also enhance OOD detection. Despite the growing interest in these topics by the classic supervised machine learning community, this intersection remains unexplored for OOD detection. We empirically demonstrate that the Double Descent effect does indeed appear in post-hoc OOD detection. Furthermore, we provide theoretical insights to explain why this phenomenon emerges in such setting. Finally, we show that the overparameterized regime does not yield superior results consistently, and we propose a method to identify the optimal regime for OOD detection based on our observations.
<div id='section'>Paperid: <span id='pid'>863, <a href='https://arxiv.org/pdf/2410.20432.pdf' target='_blank'>https://arxiv.org/pdf/2410.20432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sina DÃ¤ubener, Kira Maag, David Krueger, Asja Fischer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20432">Integrating uncertainty quantification into randomized smoothing based robustness guarantees</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have proven to be extremely powerful, however, they are also vulnerable to adversarial attacks which can cause hazardous incorrect predictions in safety-critical applications. Certified robustness via randomized smoothing gives a probabilistic guarantee that the smoothed classifier's predictions will not change within an $\ell_2$-ball around a given input. On the other hand (uncertainty) score-based rejection is a technique often applied in practice to defend models against adversarial attacks. In this work, we fuse these two approaches by integrating a classifier that abstains from predicting when uncertainty is high into the certified robustness framework. This allows us to derive two novel robustness guarantees for uncertainty aware classifiers, namely (i) the radius of an $\ell_2$-ball around the input in which the same label is predicted and uncertainty remains low and (ii) the $\ell_2$-radius of a ball in which the predictions will either not change or be uncertain. While the former provides robustness guarantees with respect to attacks aiming at increased uncertainty, the latter informs about the amount of input perturbation necessary to lead the uncertainty aware model into a wrong prediction. Notably, this is on CIFAR10 up to 20.93% larger than for models not allowing for uncertainty based rejection. We demonstrate, that the novel framework allows for a systematic robustness evaluation of different network architectures and uncertainty measures and to identify desired properties of uncertainty quantification techniques. Moreover, we show that leveraging uncertainty in a smoothed classifier helps out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>864, <a href='https://arxiv.org/pdf/2410.18864.pdf' target='_blank'>https://arxiv.org/pdf/2410.18864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>SebastiÃ¡n Espinel-RÃ­os, JosÃ© MontaÃ±o LÃ³pez, JosÃ© L. Avalos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18864">Omics-driven hybrid dynamic modeling of bioprocesses with uncertainty estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents an omics-driven modeling pipeline that integrates machine-learning tools to facilitate the dynamic modeling of multiscale biological systems. Random forests and permutation feature importance are proposed to mine omics datasets, guiding feature selection and dimensionality reduction for dynamic modeling. Continuous and differentiable machine-learning functions can be trained to link the reduced omics feature set to key components of the dynamic model, resulting in a hybrid model. As proof of concept, we apply this framework to a high-dimensional proteomics dataset of $\textit{Saccharomyces cerevisiae}$. After identifying key intracellular proteins that correlate with cell growth, targeted dynamic experiments are designed, and key model parameters are captured as functions of the selected proteins using Gaussian processes. This approach captures the dynamic behavior of yeast strains under varying proteome profiles while estimating the uncertainty in the hybrid model's predictions. The outlined modeling framework is adaptable to other scenarios, such as integrating additional layers of omics data for more advanced multiscale biological systems, or employing alternative machine-learning methods to handle larger datasets. Overall, this study outlines a strategy for leveraging omics data to inform multiscale dynamic modeling in systems biology and bioprocess engineering.
<div id='section'>Paperid: <span id='pid'>865, <a href='https://arxiv.org/pdf/2410.06134.pdf' target='_blank'>https://arxiv.org/pdf/2410.06134.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingle Xu, Jaehwan Lee, Sook Yoon, Dong Sun Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06134">Adaptive Label Smoothing for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection, which aims to distinguish unknown classes from known classes, has received increasing attention recently. A main challenge within is the unavailable of samples from the unknown classes in the training process, and an effective strategy is to improve the performance for known classes. Using beneficial strategies such as data augmentation and longer training is thus a way to improve OOD detection. However, label smoothing, an effective method for classifying known classes, degrades the performance of OOD detection, and this phenomenon is under exploration. In this paper, we first analyze that the limited and predefined learning target in label smoothing results in the smaller maximal probability and logit, which further leads to worse OOD detection performance. To mitigate this issue, we then propose a novel regularization method, called adaptive label smoothing (ALS), and the core is to push the non-true classes to have same probabilities whereas the maximal probability is neither fixed nor limited. Extensive experimental results in six datasets with two backbones suggest that ALS contributes to classifying known samples and discerning unknown samples with clear margins. Our code will be available to the public.
<div id='section'>Paperid: <span id='pid'>866, <a href='https://arxiv.org/pdf/2410.04544.pdf' target='_blank'>https://arxiv.org/pdf/2410.04544.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vinesh Sridhar, Rolf Svenning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04544">Fast Area-Weighted Peeling of Convex Hulls for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel 2D convex hull peeling algorithm for outlier detection, which repeatedly removes the point on the hull that decreases the hull's area the most. To find k outliers among n points, one simply peels k points. The algorithm is an efficient heuristic for exact methods, which find the k points whose removal together results in the smallest convex hull. Our algorithm runs in O(nlogn) time using O(n) space for any choice of k. This is a significant speedup compared to the fastest exact algorithms, which run in O(n^2logn + (n - k)^3) time using O(n\logn + (n-k)^3) space by Eppstein et al., and O(nlogn + 4k_C_2k (3k)^k n) time by Atanassov et al. Existing heuristic peeling approaches are not area-based. Instead, an approach by Harsh et al. repeatedly removes the point furthest from the mean using various distance metrics and runs in O(nlogn + kn) time. Other approaches greedily peel one convex layer at a time, which is efficient when using an O(nlogn) time algorithm by Chazelle to compute the convex layers. However, in many cases this fails to recover outliers. For most values of n and k, our approach is the fastest and first practical choice for finding outliers based on minimizing the area of the convex hull. Our algorithm also generalizes to other objectives such as perimeter.
<div id='section'>Paperid: <span id='pid'>867, <a href='https://arxiv.org/pdf/2409.11596.pdf' target='_blank'>https://arxiv.org/pdf/2409.11596.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Shi, Nedret Billor, Elvan Ceyhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11596">Outlier Detection with Cluster Catch Digraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel family of outlier detection algorithms based on Cluster Catch Digraphs (CCDs), specifically tailored to address the challenges of high dimensionality and varying cluster shapes, which deteriorate the performance of most traditional outlier detection methods. We propose the Uniformity-Based CCD with Mutual Catch Graph (U-MCCD), the Uniformity- and Neighbor-Based CCD with Mutual Catch Graph (UN-MCCD), and their shape-adaptive variants (SU-MCCD and SUN-MCCD), which are designed to detect outliers in data sets with arbitrary cluster shapes and high dimensions. We present the advantages and shortcomings of these algorithms and provide the motivation or need to define each particular algorithm. Through comprehensive Monte Carlo simulations, we assess their performance and demonstrate the robustness and effectiveness of our algorithms across various settings and contamination levels. We also illustrate the use of our algorithms on various real-life data sets. The U-MCCD algorithm efficiently identifies outliers while maintaining high true negative rates, and the SU-MCCD algorithm shows substantial improvement in handling non-uniform clusters. Additionally, the UN-MCCD and SUN-MCCD algorithms address the limitations of existing methods in high-dimensional spaces by utilizing Nearest Neighbor Distances (NND) for clustering and outlier detection. Our results indicate that these novel algorithms offer substantial advancements in the accuracy and adaptability of outlier detection, providing a valuable tool for various real-world applications.
  Keyword: Outlier detection, Graph-based clustering, Cluster catch digraphs, $k$-nearest-neighborhood, Mutual catch graphs, Nearest neighbor distance.
<div id='section'>Paperid: <span id='pid'>868, <a href='https://arxiv.org/pdf/2409.11212.pdf' target='_blank'>https://arxiv.org/pdf/2409.11212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianing Wang, Yang Zhou, Xiaocheng Zhang, Mengjiao Bao, Peng Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11212">Self-Evolutionary Large Language Models through Uncertainty-Enhanced Preference Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iterative preference optimization has recently become one of the de-facto training paradigms for large language models (LLMs), but the performance is still underwhelming due to too much noisy preference data yielded in the loop. To combat this issue, we present an \textbf{U}ncertainty-enhanced \textbf{P}reference \textbf{O}ptimization (UPO) framework to make the LLM self-evolve with reliable feedback. The key idea is mitigating the noisy preference data derived from the current policy and reward models by performing pair-wise uncertainty estimation and judiciously reliable feedback sampling. To reach this goal, we thus introduce an estimator model, which incorporates Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the preference data derived from the LLM policy. Compared to the existing methods that directly filter generated responses based on the reward score, the estimator focuses on the model uncertainty in a pair-wise manner and effectively bypasses the confirmation bias problem of the reward model. Additionally, we also propose an uncertainty-enhanced self-evolution algorithm to improve the robustness of preference optimization and encourage the LLM to generate responses with both high reward and certainty. Extensive experiments over multiple benchmarks demonstrate that our framework substantially alleviates the noisy problem and improves the performance of iterative preference optimization.
<div id='section'>Paperid: <span id='pid'>869, <a href='https://arxiv.org/pdf/2409.10972.pdf' target='_blank'>https://arxiv.org/pdf/2409.10972.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sawan Kumar, Rajdip Nayek, Souvik Chakraborty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10972">Towards Gaussian Process for operator learning: an uncertainty aware resolution independent operator learning algorithm for computational mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing demand for accurate, efficient, and scalable solutions in computational mechanics highlights the need for advanced operator learning algorithms that can efficiently handle large datasets while providing reliable uncertainty quantification. This paper introduces a novel Gaussian Process (GP) based neural operator for solving parametric differential equations. The approach proposed leverages the expressive capability of deterministic neural operators and the uncertainty awareness of conventional GP. In particular, we propose a ``neural operator-embedded kernel'' wherein the GP kernel is formulated in the latent space learned using a neural operator. Further, we exploit a stochastic dual descent (SDD) algorithm for simultaneously training the neural operator parameters and the GP hyperparameters. Our approach addresses the (a) resolution dependence and (b) cubic complexity of traditional GP models, allowing for input-resolution independence and scalability in high-dimensional and non-linear parametric systems, such as those encountered in computational mechanics. We apply our method to a range of non-linear parametric partial differential equations (PDEs) and demonstrate its superiority in both computational efficiency and accuracy compared to standard GP models and wavelet neural operators. Our experimental results highlight the efficacy of this framework in solving complex PDEs while maintaining robustness in uncertainty estimation, positioning it as a scalable and reliable operator-learning algorithm for computational mechanics.
<div id='section'>Paperid: <span id='pid'>870, <a href='https://arxiv.org/pdf/2408.11237.pdf' target='_blank'>https://arxiv.org/pdf/2408.11237.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Constantinou, Georgios Ioannides, Aman Chadha, Aaron Elkins, Edwin Simpson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11237">Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) data is crucial in machine learning applications to mitigate the risk of model overconfidence, thereby enhancing the reliability and safety of deployed systems. The majority of existing OOD detection methods predominantly address uni-modal inputs, such as images or texts. In the context of multi-modal documents, there is a notable lack of extensive research on the performance of these methods, which have primarily been developed with a focus on computer vision tasks. We propose a novel methodology termed as attention head masking (AHM) for multi-modal OOD tasks in document classification systems. Our empirical results demonstrate that the proposed AHM method outperforms all state-of-the-art approaches and significantly decreases the false positive rate (FPR) compared to existing solutions up to 7.5\%. This methodology generalizes well to multi-modal data, such as documents, where visual and textual information are modeled under the same Transformer architecture. To address the scarcity of high-quality publicly available document datasets and encourage further research on OOD detection for documents, we introduce FinanceDocs, a new document AI dataset. Our code and dataset are publicly available.
<div id='section'>Paperid: <span id='pid'>871, <a href='https://arxiv.org/pdf/2408.10021.pdf' target='_blank'>https://arxiv.org/pdf/2408.10021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kira Maag, Roman Resner, Asja Fischer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10021">Detecting Adversarial Attacks in Semantic Segmentation via Uncertainty Estimation: A Deep Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have demonstrated remarkable effectiveness across a wide range of tasks such as semantic segmentation. Nevertheless, these networks are vulnerable to adversarial attacks that add imperceptible perturbations to the input image, leading to false predictions. This vulnerability is particularly dangerous in safety-critical applications like automated driving. While adversarial examples and defense strategies are well-researched in the context of image classification, there is comparatively less research focused on semantic segmentation. Recently, we have proposed an uncertainty-based method for detecting adversarial attacks on neural networks for semantic segmentation. We observed that uncertainty, as measured by the entropy of the output distribution, behaves differently on clean versus adversely perturbed images, and we utilize this property to differentiate between the two. In this extended version of our work, we conduct a detailed analysis of uncertainty-based detection of adversarial attacks including a diverse set of adversarial attacks and various state-of-the-art neural networks. Our numerical experiments show the effectiveness of the proposed uncertainty-based detection method, which is lightweight and operates as a post-processing step, i.e., no model modifications or knowledge of the adversarial example generation process are required.
<div id='section'>Paperid: <span id='pid'>872, <a href='https://arxiv.org/pdf/2408.06018.pdf' target='_blank'>https://arxiv.org/pdf/2408.06018.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shanu Saklani, Chitwan Goel, Shrey Bansal, Zhe Wang, Soumya Dutta, Tushar M. Athawale, David Pugmire, Christopher R. Johnson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06018">Uncertainty-Informed Volume Visualization using Implicit Neural Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The increasing adoption of Deep Neural Networks (DNNs) has led to their application in many challenging scientific visualization tasks. While advanced DNNs offer impressive generalization capabilities, understanding factors such as model prediction quality, robustness, and uncertainty is crucial. These insights can enable domain scientists to make informed decisions about their data. However, DNNs inherently lack ability to estimate prediction uncertainty, necessitating new research to construct robust uncertainty-aware visualization techniques tailored for various visualization tasks. In this work, we propose uncertainty-aware implicit neural representations to model scalar field data sets effectively and comprehensively study the efficacy and benefits of estimated uncertainty information for volume visualization tasks. We evaluate the effectiveness of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout (MCDropout). These techniques enable uncertainty-informed volume visualization in scalar field data sets. Our extensive exploration across multiple data sets demonstrates that uncertainty-aware models produce informative volume visualization results. Moreover, integrating prediction uncertainty enhances the trustworthiness of our DNN model, making it suitable for robustly analyzing and visualizing real-world scientific volumetric data sets.
<div id='section'>Paperid: <span id='pid'>873, <a href='https://arxiv.org/pdf/2408.04718.pdf' target='_blank'>https://arxiv.org/pdf/2408.04718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dule Shu, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.04718">Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The success of diffusion probabilistic models in generative tasks, such as text-to-image generation, has motivated the exploration of their application to regression problems commonly encountered in scientific computing and various other domains. In this context, the use of diffusion regression models for ensemble prediction is becoming a practice with increasing popularity. Under such background, we conducted a study to quantitatively evaluate the effectiveness of ensemble methods on solving different regression problems using diffusion models. We consider the ensemble prediction of a diffusion model as a means for zero-shot uncertainty quantification, since the diffusion models in our study are not trained with a loss function containing any uncertainty estimation. Through extensive experiments on 1D and 2D data, we demonstrate that ensemble methods consistently improve model prediction accuracy across various regression tasks. Notably, we observed a larger accuracy gain in auto-regressive prediction compared with point-wise prediction, and that enhancements take place in both the mean-square error and the physics-informed loss. Additionally, we reveal a statistical correlation between ensemble prediction error and ensemble variance, offering insights into balancing computational complexity with prediction accuracy and monitoring prediction confidence in practical applications where the ground truth is unknown. Our study provides a comprehensive view of the utility of diffusion ensembles, serving as a useful reference for practitioners employing diffusion models in regression problem-solving.
<div id='section'>Paperid: <span id='pid'>874, <a href='https://arxiv.org/pdf/2408.01977.pdf' target='_blank'>https://arxiv.org/pdf/2408.01977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fatemeh Amerehi, Patrick Healy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01977">Label Augmentation for Neural Networks Robustness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution generalization can be categorized into two types: common perturbations arising from natural variations in the real world and adversarial perturbations that are intentionally crafted to deceive neural networks. While deep neural networks excel in accuracy under the assumption of identical distributions between training and test data, they often encounter out-of-distribution scenarios resulting in a significant decline in accuracy. Data augmentation methods can effectively enhance robustness against common corruptions, but they typically fall short in improving robustness against adversarial perturbations. In this study, we develop Label Augmentation (LA), which enhances robustness against both common and intentional perturbations and improves uncertainty estimation. Our findings indicate a Clean error rate improvement of up to 23.29% when employing LA in comparisons to the baseline. Additionally, it enhances robustness under common corruptions benchmark by up to 24.23%. When tested against FGSM and PGD attacks, improvements in adversarial robustness are noticeable, with enhancements of up to 53.18% for FGSM and 24.46% for PGD attacks.
<div id='section'>Paperid: <span id='pid'>875, <a href='https://arxiv.org/pdf/2407.21273.pdf' target='_blank'>https://arxiv.org/pdf/2407.21273.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohini Banerjee, Cecilia G. Morales, Artur Dubrawski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21273">Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient intravascular access in trauma and critical care significantly impacts patient outcomes. However, the availability of skilled medical personnel in austere environments is often limited. Autonomous robotic ultrasound systems can aid in needle insertion for medication delivery and support non-experts in such tasks. Despite advances in autonomous needle insertion, inaccuracies in vessel segmentation predictions pose risks. Understanding the uncertainty of predictive models in ultrasound imaging is crucial for assessing their reliability. We introduce MSU-Net, a novel multistage approach for training an ensemble of U-Nets to yield accurate ultrasound image segmentation maps. We demonstrate substantial improvements, 18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model transparency, and trustworthiness. By highlighting areas of model certainty, MSU-Net can guide safe needle insertions, empowering non-experts to accomplish such tasks.
<div id='section'>Paperid: <span id='pid'>876, <a href='https://arxiv.org/pdf/2407.21263.pdf' target='_blank'>https://arxiv.org/pdf/2407.21263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Tariqul Islam, Jason W. Fleischer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21263">Outlier Detection in Large Radiological Datasets using UMAP</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The success of machine learning algorithms heavily relies on the quality of samples and the accuracy of their corresponding labels. However, building and maintaining large, high-quality datasets is an enormous task. This is especially true for biomedical data and for meta-sets that are compiled from smaller ones, as variations in image quality, labeling, reports, and archiving can lead to errors, inconsistencies, and repeated samples. Here, we show that the uniform manifold approximation and projection (UMAP) algorithm can find these anomalies essentially by forming independent clusters that are distinct from the main (good) data but similar to other points with the same error type. As a representative example, we apply UMAP to discover outliers in the publicly available ChestX-ray14, CheXpert, and MURA datasets. While the results are archival and retrospective and focus on radiological images, the graph-based methods work for any data type and will prove equally beneficial for curation at the time of dataset creation.
<div id='section'>Paperid: <span id='pid'>877, <a href='https://arxiv.org/pdf/2406.11105.pdf' target='_blank'>https://arxiv.org/pdf/2406.11105.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Armando Zhu, Jiabei Liu, Keqin Li, Shuying Dai, Bo Hong, Peng Zhao, Changsong Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11105">Exploiting Diffusion Prior for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for deploying robust machine learning models, especially in areas where security is critical. However, traditional OOD detection methods often fail to capture complex data distributions from large scale date. In this paper, we present a novel approach for OOD detection that leverages the generative ability of diffusion models and the powerful feature extraction capabilities of CLIP. By using these features as conditional inputs to a diffusion model, we can reconstruct the images after encoding them with CLIP. The difference between the original and reconstructed images is used as a signal for OOD identification. The practicality and scalability of our method is increased by the fact that it does not require class-specific labeled ID data, as is the case with many other methods. Extensive experiments on several benchmark datasets demonstrates the robustness and effectiveness of our method, which have significantly improved the detection accuracy.
<div id='section'>Paperid: <span id='pid'>878, <a href='https://arxiv.org/pdf/2405.18176.pdf' target='_blank'>https://arxiv.org/pdf/2405.18176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ilia Azizi, Marc-Olivier Boldi, ValÃ©rie Chavez-Demoulin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18176">SEMF: Supervised Expectation-Maximization Framework for Predicting Intervals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces the Supervised Expectation-Maximization Framework (SEMF), a versatile and model-agnostic approach for generating prediction intervals with any ML model. SEMF extends the Expectation-Maximization algorithm, traditionally used in unsupervised learning, to a supervised context, leveraging latent variable modeling for uncertainty estimation. Through extensive empirical evaluation of diverse simulated distributions and 11 real-world tabular datasets, SEMF consistently produces narrower prediction intervals while maintaining the desired coverage probability, outperforming traditional quantile regression methods. Furthermore, without using the quantile (pinball) loss, SEMF allows point predictors, including gradient-boosted trees and neural networks, to be calibrated with conformal quantile regression. The results indicate that SEMF enhances uncertainty quantification under diverse data distributions and is particularly effective for models that otherwise struggle with inherent uncertainty representation.
<div id='section'>Paperid: <span id='pid'>879, <a href='https://arxiv.org/pdf/2405.15130.pdf' target='_blank'>https://arxiv.org/pdf/2405.15130.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yueyue Liu, Hongyu Zhang, Yuantian Miao, Van-Hoang Le, Zhiqiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15130">OptLLM: Optimal Assignment of Queries to Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have garnered considerable attention owing to their remarkable capabilities, leading to an increasing number of companies offering LLMs as services. Different LLMs achieve different performance at different costs. A challenge for users lies in choosing the LLMs that best fit their needs, balancing cost and performance. In this paper, we propose a framework for addressing the cost-effective query allocation problem for LLMs. Given a set of input queries and candidate LLMs, our framework, named OptLLM, provides users with a range of optimal solutions to choose from, aligning with their budget constraints and performance preferences, including options for maximizing accuracy and minimizing cost. OptLLM predicts the performance of candidate LLMs on each query using a multi-label classification model with uncertainty estimation and then iteratively generates a set of non-dominated solutions by destructing and reconstructing the current solution. To evaluate the effectiveness of OptLLM, we conduct extensive experiments on various types of tasks, including text classification, question answering, sentiment analysis, reasoning, and log parsing. Our experimental results demonstrate that OptLLM substantially reduces costs by 2.40% to 49.18% while achieving the same accuracy as the best LLM. Compared to other multi-objective optimization algorithms, OptLLM improves accuracy by 2.94% to 69.05% at the same cost or saves costs by 8.79% and 95.87% while maintaining the highest attainable accuracy.
<div id='section'>Paperid: <span id='pid'>880, <a href='https://arxiv.org/pdf/2405.07104.pdf' target='_blank'>https://arxiv.org/pdf/2405.07104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Schwarz, Arian Mehrfard, Golchehr Amirkhani, Henry Phalen, Justin H. Ma, Robert B. Grupp, Alejandro Martin-Gomez, Mehran Armand
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.07104">Uncertainty-Aware Shape Estimation of a Surgical Continuum Manipulator in Constrained Environments using Fiber Bragg Grating Sensors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continuum Dexterous Manipulators (CDMs) are well-suited tools for minimally invasive surgery due to their inherent dexterity and reachability. Nonetheless, their flexible structure and non-linear curvature pose significant challenges for shape-based feedback control. The use of Fiber Bragg Grating (FBG) sensors for shape sensing has shown great potential in estimating the CDM's tip position and subsequently reconstructing the shape using optimization algorithms. This optimization, however, is under-constrained and may be ill-posed for complex shapes, falling into local minima. In this work, we introduce a novel method capable of directly estimating a CDM's shape from FBG sensor wavelengths using a deep neural network. In addition, we propose the integration of uncertainty estimation to address the critical issue of uncertainty in neural network predictions. Neural network predictions are unreliable when the input sample is outside the training distribution or corrupted by noise. Recognizing such deviations is crucial when integrating neural networks within surgical robotics, as inaccurate estimations can pose serious risks to the patient. We present a robust method that not only improves the precision upon existing techniques for FBG-based shape estimation but also incorporates a mechanism to quantify the models' confidence through uncertainty estimation. We validate the uncertainty estimation through extensive experiments, demonstrating its effectiveness and reliability on out-of-distribution (OOD) data, adding an additional layer of safety and precision to minimally invasive surgical robotics.
<div id='section'>Paperid: <span id='pid'>881, <a href='https://arxiv.org/pdf/2404.10474.pdf' target='_blank'>https://arxiv.org/pdf/2404.10474.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pietro Recalcati, Fabio Garcea, Luca Piano, Fabrizio Lamberti, Lia Morra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10474">Toward a Realistic Benchmark for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks are increasingly used in a wide range of technologies and services, but remain highly susceptible to out-of-distribution (OOD) samples, that is, drawn from a different distribution than the original training set. A common approach to address this issue is to endow deep neural networks with the ability to detect OOD samples. Several benchmarks have been proposed to design and validate OOD detection techniques. However, many of them are based on far-OOD samples drawn from very different distributions, and thus lack the complexity needed to capture the nuances of real-world scenarios. In this work, we introduce a comprehensive benchmark for OOD detection, based on ImageNet and Places365, that assigns individual classes as in-distribution or out-of-distribution depending on the semantic similarity with the training set. Several techniques can be used to determine which classes should be considered in-distribution, yielding benchmarks with varying properties. Experimental results on different OOD detection techniques show how their measured efficacy depends on the selected benchmark and how confidence-based techniques may outperform classifier-based ones on near-OOD samples.
<div id='section'>Paperid: <span id='pid'>882, <a href='https://arxiv.org/pdf/2404.07518.pdf' target='_blank'>https://arxiv.org/pdf/2404.07518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuwei Sun, Ippei Fujisawa, Arthur Juliani, Jun Sakuma, Ryota Kanai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07518">Remembering Transformer for Continual Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks encounter the challenge of Catastrophic Forgetting (CF) in continual learning, where new task learning interferes with previously learned knowledge. Existing data fine-tuning and regularization methods necessitate task identity information during inference and cannot eliminate interference among different tasks, while soft parameter sharing approaches encounter the problem of an increasing model parameter size. To tackle these challenges, we propose the Remembering Transformer, inspired by the brain's Complementary Learning Systems (CLS). Remembering Transformer employs a mixture-of-adapters architecture and a generative model-based novelty detection mechanism in a pretrained Transformer to alleviate CF. Remembering Transformer dynamically routes task data to the most relevant adapter with enhanced parameter efficiency based on knowledge distillation. We conducted extensive experiments, including ablation studies on the novelty detection mechanism and model capacity of the mixture-of-adapters, in a broad range of class-incremental split tasks and permutation tasks. Our approach demonstrated SOTA performance surpassing the second-best method by 15.90% in the split tasks, reducing the memory footprint from 11.18M to 0.22M in the five splits CIFAR10 task.
<div id='section'>Paperid: <span id='pid'>883, <a href='https://arxiv.org/pdf/2404.06230.pdf' target='_blank'>https://arxiv.org/pdf/2404.06230.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emre Ozfatura, Kerem Ozfatura, Alptekin Kupcu, Deniz Gunduz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06230">Aggressive or Imperceptible, or Both: Network Pruning Assisted Hybrid Byzantines in Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning (FL) has been introduced to enable a large number of clients, possibly mobile devices, to collaborate on generating a generalized machine learning model thanks to utilizing a larger number of local samples without sharing to offer certain privacy to collaborating clients. However, due to the participation of a large number of clients, it is often difficult to profile and verify each client, which leads to a security threat that malicious participants may hamper the accuracy of the trained model by conveying poisoned models during the training. Hence, the aggregation framework at the parameter server also needs to minimize the detrimental effects of these malicious clients. A plethora of attack and defence strategies have been analyzed in the literature. However, often the Byzantine problem is analyzed solely from the outlier detection perspective, being oblivious to the topology of neural networks (NNs).
  In the scope of this work, we argue that by extracting certain side information specific to the NN topology, one can design stronger attacks. Hence, inspired by the sparse neural networks, we introduce a hybrid sparse Byzantine attack that is composed of two parts: one exhibiting a sparse nature and attacking only certain NN locations with higher sensitivity, and the other being more silent but accumulating over time, where each ideally targets a different type of defence mechanism, and together they form a strong but imperceptible attack. Finally, we show through extensive simulations that the proposed hybrid Byzantine attack is effective against 8 different defence methods.
<div id='section'>Paperid: <span id='pid'>884, <a href='https://arxiv.org/pdf/2403.14058.pdf' target='_blank'>https://arxiv.org/pdf/2403.14058.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yasith Jayawardana, Azeem Ahmad, Balpreet S. Ahluwalia, Rafi Ahmad, Sampath Jayarathna, Dushan N. Wadduwage
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14058">Hypothesis-Driven Deep Learning for Out of Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare. For such applications, it is crucial to assess how models handle samples beyond the domain of training data. While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use. In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD. Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses. We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothesis. We adapt our method to detect an unseen sample of bacteria to a trained deep learning model, and show that it reveals interpretable differences between InD and OoD latent responses. Our work has implications for systematic novelty detection and informed decision-making from classifiers trained on a subset of labels.
<div id='section'>Paperid: <span id='pid'>885, <a href='https://arxiv.org/pdf/2402.09264.pdf' target='_blank'>https://arxiv.org/pdf/2402.09264.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Jia, Young D. Kwon, Dong Ma, Nhat Pham, Lorena Qendro, Tam Vu, Cecilia Mascolo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.09264">UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional machine learning techniques are prone to generating inaccurate predictions when confronted with shifts in the distribution of data between the training and testing phases. This vulnerability can lead to severe consequences, especially in applications such as mobile healthcare. Uncertainty estimation has the potential to mitigate this issue by assessing the reliability of a model's output. However, existing uncertainty estimation techniques often require substantial computational resources and memory, making them impractical for implementation on microcontrollers (MCUs). This limitation hinders the feasibility of many important on-device wearable event detection (WED) applications, such as heart attack detection.
  In this paper, we present UR2M, a novel Uncertainty and Resource-aware event detection framework for MCUs. Specifically, we (i) develop an uncertainty-aware WED based on evidential theory for accurate event detection and reliable uncertainty estimation; (ii) introduce a cascade ML framework to achieve efficient model inference via early exits, by sharing shallower model layers among different event models; (iii) optimize the deployment of the model and MCU library for system efficiency. We conducted extensive experiments and compared UR2M to traditional uncertainty baselines using three wearable datasets. Our results demonstrate that UR2M achieves up to 864% faster inference speed, 857% energy-saving for uncertainty estimation, 55% memory saving on two popular MCUs, and a 22% improvement in uncertainty quantification performance.
  UR2M can be deployed on a wide range of MCUs, significantly expanding real-time and reliable WED applications.
<div id='section'>Paperid: <span id='pid'>886, <a href='https://arxiv.org/pdf/2402.00251.pdf' target='_blank'>https://arxiv.org/pdf/2402.00251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yao-Hung Hubert Tsai, Walter Talbott, Jian Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00251">Efficient Non-Parametric Uncertainty Quantification for Black-Box Large Language Models and Decision Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Step-by-step decision planning with large language models (LLMs) is gaining attention in AI agent development. This paper focuses on decision planning with uncertainty estimation to address the hallucination problem in language models. Existing approaches are either white-box or computationally demanding, limiting use of black-box proprietary LLMs within budgets. The paper's first contribution is a non-parametric uncertainty quantification method for LLMs, efficiently estimating point-wise dependencies between input-decision on the fly with a single inference, without access to token logits. This estimator informs the statistical interpretation of decision trustworthiness. The second contribution outlines a systematic design for a decision-making agent, generating actions like ``turn on the bathroom light'' based on user prompts such as ``take a bath''. Users will be asked to provide preferences when more than one action has high estimated point-wise dependencies. In conclusion, our uncertainty estimation and decision-making agent design offer a cost-efficient approach for AI agent development.
<div id='section'>Paperid: <span id='pid'>887, <a href='https://arxiv.org/pdf/2401.08140.pdf' target='_blank'>https://arxiv.org/pdf/2401.08140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kiyohiro Nakayama, Mikaela Angelina Uy, Yang You, Ke Li, Leonidas J. Guibas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08140">ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Field</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural radiance fields (NeRFs) have gained popularity with multiple works showing promising results across various applications. However, to the best of our knowledge, existing works do not explicitly model the distribution of training camera poses, or consequently the triangulation quality, a key factor affecting reconstruction quality dating back to classical vision literature. We close this gap with ProvNeRF, an approach that models the \textbf{provenance} for each point -- i.e., the locations where it is likely visible -- of NeRFs as a stochastic field. We achieve this by extending implicit maximum likelihood estimation (IMLE) to functional space with an optimizable objective. We show that modeling per-point provenance during the NeRF optimization enriches the model with information on triangulation leading to improvements in novel view synthesis and uncertainty estimation under the challenging sparse, unconstrained view setting against competitive baselines.
<div id='section'>Paperid: <span id='pid'>888, <a href='https://arxiv.org/pdf/2401.02914.pdf' target='_blank'>https://arxiv.org/pdf/2401.02914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Parvin Malekzadeh, Ming Hou, Konstantinos N. Plataniotis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02914">A unified uncertainty-aware exploration: Combining epistemic and aleatory uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Exploration is a significant challenge in practical reinforcement learning (RL), and uncertainty-aware exploration that incorporates the quantification of epistemic and aleatory uncertainty has been recognized as an effective exploration strategy. However, capturing the combined effect of aleatory and epistemic uncertainty for decision-making is difficult. Existing works estimate aleatory and epistemic uncertainty separately and consider the composite uncertainty as an additive combination of the two. Nevertheless, the additive formulation leads to excessive risk-taking behavior, causing instability. In this paper, we propose an algorithm that clarifies the theoretical connection between aleatory and epistemic uncertainty, unifies aleatory and epistemic uncertainty estimation, and quantifies the combined effect of both uncertainties for a risk-sensitive exploration. Our method builds on a novel extension of distributional RL that estimates a parameterized return distribution whose parameters are random variables encoding epistemic uncertainty. Experimental results on tasks with exploration and risk challenges show that our method outperforms alternative approaches.
<div id='section'>Paperid: <span id='pid'>889, <a href='https://arxiv.org/pdf/2401.01021.pdf' target='_blank'>https://arxiv.org/pdf/2401.01021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Butian Xiong, Liguang Zhou, Tin Lun Lam, Yangsheng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01021">Class Relevance Learning For Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image classification plays a pivotal role across diverse applications, yet challenges persist when models are deployed in real-world scenarios. Notably, these models falter in detecting unfamiliar classes that were not incorporated during classifier training, a formidable hurdle for safe and effective real-world model deployment, commonly known as out-of-distribution (OOD) detection. While existing techniques, like max logits, aim to leverage logits for OOD identification, they often disregard the intricate interclass relationships that underlie effective detection. This paper presents an innovative class relevance learning method tailored for OOD detection. Our method establishes a comprehensive class relevance learning framework, strategically harnessing interclass relationships within the OOD pipeline. This framework significantly augments OOD detection capabilities. Extensive experimentation on diverse datasets, encompassing generic image classification datasets (Near OOD and Far OOD datasets), demonstrates the superiority of our method over state-of-the-art alternatives for OOD detection.
<div id='section'>Paperid: <span id='pid'>890, <a href='https://arxiv.org/pdf/2512.22245.pdf' target='_blank'>https://arxiv.org/pdf/2512.22245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bhaktipriya Radharapu, Eshika Saxena, Kenneth Li, Chenxi Whitehouse, Adina Williams, Nicola Cancedda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.22245">Calibrating LLM Judges: Linear Probes for Fast and Reliable Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As LLM-based judges become integral to industry applications, obtaining well-calibrated uncertainty estimates efficiently has become critical for production deployment. However, existing techniques, such as verbalized confidence and multi-generation methods, are often either poorly calibrated or computationally expensive. We introduce linear probes trained with a Brier score-based loss to provide calibrated uncertainty estimates from reasoning judges' hidden states, requiring no additional model training. We evaluate our approach on both objective tasks (reasoning, mathematics, factuality, coding) and subjective human preference judgments. Our results demonstrate that probes achieve superior calibration compared to existing methods with $\approx10$x computational savings, generalize robustly to unseen evaluation domains, and deliver higher accuracy on high-confidence predictions. However, probes produce conservative estimates that underperform on easier datasets but may benefit safety-critical deployments prioritizing low false-positive rates. Overall, our work demonstrates that interpretability-based uncertainty estimation provides a practical and scalable plug-and-play solution for LLM judges in production.
<div id='section'>Paperid: <span id='pid'>891, <a href='https://arxiv.org/pdf/2512.18454.pdf' target='_blank'>https://arxiv.org/pdf/2512.18454.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Graber, Victor Armegioiu, Rebecca Buller, Siddhartha Mishra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.18454">Out-of-Distribution Detection in Molecular Complexes via Diffusion Models for Irregular Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictive machine learning models generally excel on in-distribution data, but their performance degrades on out-of-distribution (OOD) inputs. Reliable deployment therefore requires robust OOD detection, yet this is particularly challenging for irregular 3D graphs that combine continuous geometry with categorical identities and are unordered by construction. Here, we present a probabilistic OOD detection framework for complex 3D graph data built on a diffusion model that learns a density of the training distribution in a fully unsupervised manner. A key ingredient we introduce is a unified continuous diffusion over both 3D coordinates and discrete features: categorical identities are embedded in a continuous space and trained with cross-entropy, while the corresponding diffusion score is obtained analytically via posterior-mean interpolation from predicted class probabilities. This yields a single self-consistent probability-flow ODE (PF-ODE) that produces per-sample log-likelihoods, providing a principled typicality score for distribution shift. We validate the approach on protein-ligand complexes and construct strict OOD datasets by withholding entire protein families from training. PF-ODE likelihoods identify held-out families as OOD and correlate strongly with prediction errors of an independent binding-affinity model (GEMS), enabling a priori reliability estimates on new complexes. Beyond scalar likelihoods, we show that multi-scale PF-ODE trajectory statistics - including path tortuosity, flow stiffness, and vector-field instability - provide complementary OOD information. Modeling the joint distribution of these trajectory features yields a practical, high-sensitivity detector that improves separation over likelihood-only baselines, offering a label-free OOD quantification workflow for geometric deep learning.
<div id='section'>Paperid: <span id='pid'>892, <a href='https://arxiv.org/pdf/2511.13775.pdf' target='_blank'>https://arxiv.org/pdf/2511.13775.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongdong Zhao, Ranxin Fang, Changtian Song, Zhihui Liu, Jianwen Xiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.13775">Known Meets Unknown: Mitigating Overconfidence in Open Set Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open Set Recognition (OSR) requires models not only to accurately classify known classes but also to effectively reject unknown samples. However, when unknown samples are semantically similar to known classes, inter-class overlap in the feature space often causes models to assign unjustifiably high confidence to them, leading to misclassification as known classes -- a phenomenon known as overconfidence. This overconfidence undermines OSR by blurring the decision boundary between known and unknown classes. To address this issue, we propose a framework that explicitly mitigates overconfidence caused by inter-class overlap. The framework consists of two components: a perturbation-based uncertainty estimation module, which applies controllable parameter perturbations to generate diverse predictions and quantify predictive uncertainty, and an unknown detection module with distinct learning-based classifiers, implemented as a two-stage procedure, which leverages the estimated uncertainty to improve discrimination between known and unknown classes, thereby enhancing OSR performance. Experimental results on three public datasets show that the proposed framework achieves superior performance over existing OSR methods.
<div id='section'>Paperid: <span id='pid'>893, <a href='https://arxiv.org/pdf/2511.03166.pdf' target='_blank'>https://arxiv.org/pdf/2511.03166.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Wang, Subre Abdoul Moktar, Jia Li, Kangshuo Li, Feng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.03166">Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have become increasingly pervasive, finding applications across many industries and disciplines. Ensuring the trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE) plays a key role. In this work, a comprehensive empirical study is conducted to examine the robustness and effectiveness of diverse UE measures regarding aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE methods and four generation quality metrics including LLMScore from LLM criticizers to evaluate the uncertainty of LLM-generated answers in Question-Answering (QA) tasks on both in-distribution (ID) and out-of-distribution (OOD) datasets. Our analysis reveals that information-based methods, which leverage token and sequence probabilities, perform exceptionally well in ID settings due to their alignment with the model's understanding of the data. Conversely, density-based methods and the P(True) metric exhibit superior performance in OOD contexts, highlighting their effectiveness in capturing the model's epistemic uncertainty. Semantic consistency methods, which assess variability in generated answers, show reliable performance across different datasets and generation metrics. These methods generally perform well but may not be optimal for every situation.
<div id='section'>Paperid: <span id='pid'>894, <a href='https://arxiv.org/pdf/2510.21418.pdf' target='_blank'>https://arxiv.org/pdf/2510.21418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Bierling, Davide Pasero, Jan-Henrik Bertrand, Kiki Van Gerwen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.21418">DreamerV3-XP: Optimizing exploration through uncertainty estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce DreamerV3-XP, an extension of DreamerV3 that improves exploration and learning efficiency. This includes (i) a prioritized replay buffer, scoring trajectories by return, reconstruction loss, and value error and (ii) an intrinsic reward based on disagreement over predicted environment rewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset of Atari100k and DeepMind Control Visual Benchmark tasks, confirming the original DreamerV3 results and showing that our extensions lead to faster learning and lower dynamics model loss, particularly in sparse-reward settings.
<div id='section'>Paperid: <span id='pid'>895, <a href='https://arxiv.org/pdf/2510.21254.pdf' target='_blank'>https://arxiv.org/pdf/2510.21254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Victoria J. Hodge, Colin Paterson, Ibrahim Habli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.21254">Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The operational capabilities and application domains of AI-enabled autonomous systems have expanded significantly in recent years due to advances in robotics and machine learning (ML). Demonstrating the safety of autonomous systems rigorously is critical for their responsible adoption but it is challenging as it requires robust methodologies that can handle novel and uncertain situations throughout the system lifecycle, including detecting out-of-distribution (OoD) data. Thus, OOD detection is receiving increased attention from the research, development and safety engineering communities. This comprehensive review analyses OOD detection techniques within the context of safety assurance for autonomous systems, in particular in safety-critical domains. We begin by defining the relevant concepts, investigating what causes OOD and exploring the factors which make the safety assurance of autonomous systems and OOD detection challenging. Our review identifies a range of techniques which can be used throughout the ML development lifecycle and we suggest areas within the lifecycle in which they may be used to support safety assurance arguments. We discuss a number of caveats that system and safety engineers must be aware of when integrating OOD detection into system lifecycles. We conclude by outlining the challenges and future work necessary for the safe development and operation of autonomous systems across a range of domains and applications.
<div id='section'>Paperid: <span id='pid'>896, <a href='https://arxiv.org/pdf/2510.19229.pdf' target='_blank'>https://arxiv.org/pdf/2510.19229.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juntang Wang, Yihan Wang, Hao Wu, Dongmian Zou, Shixin Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.19229">Brain-Inspired Perspective on Configurations: Unsupervised Similarity and Early Cognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Infants discover categories, detect novelty, and adapt to new contexts without supervision -- a challenge for current machine learning. We present a brain-inspired perspective on configurations, a finite-resolution clustering framework that uses a single resolution parameter and attraction-repulsion dynamics to yield hierarchical organization, novelty sensitivity, and flexible adaptation. To evaluate these properties, we introduce mheatmap, which provides proportional heatmaps and a reassignment algorithm to fairly assess multi-resolution and dynamic behavior. Across datasets, configurations are competitive on standard clustering metrics, achieve 87% AUC in novelty detection, and show 35% better stability during dynamic category evolution. These results position configurations as a principled computational model of early cognitive categorization and a step toward brain-inspired AI.
<div id='section'>Paperid: <span id='pid'>897, <a href='https://arxiv.org/pdf/2510.12919.pdf' target='_blank'>https://arxiv.org/pdf/2510.12919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mouhyemen Khan, Tatsuya Ibuki, Abhijit Chatterjee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.12919">Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Level set methods underpin modern safety techniques such as control barrier functions (CBFs), while also serving as implicit surface representations for geometric shapes via distance fields. Inspired by these two paradigms, we propose a unified framework where the implicit surface itself acts as a CBF. We leverage Gaussian process (GP) implicit surface (GPIS) to represent the safety boundaries, using safety samples which are derived from sensor measurements to condition the GP. The GP posterior mean defines the implicit safety surface (safety belief), while the posterior variance provides a robust safety margin. Although GPs have favorable properties such as uncertainty estimation and analytical tractability, they scale cubically with data. To alleviate this issue, we develop a sparse solution called sparse Gaussian CBFs. To the best of our knowledge, GPIS have not been explicitly used to synthesize CBFs. We validate the approach on collision avoidance tasks in two settings: a simulated 7-DOF manipulator operating around the Stanford bunny, and a quadrotor navigating in 3D around a physical chair. In both cases, Gaussian CBFs (with and without sparsity) enable safe interaction and collision-free execution of trajectories that would otherwise intersect the objects.
<div id='section'>Paperid: <span id='pid'>898, <a href='https://arxiv.org/pdf/2510.10126.pdf' target='_blank'>https://arxiv.org/pdf/2510.10126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sehar Zehra, Hassan Jamil Syed, Ummay Faseeha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.10126">FedMon: Federated eBPF Monitoring for Distributed Anomaly Detection in Multi-Cluster Cloud Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kubernetes multi-cluster deployments demand scalable and privacy-preserving anomaly detection. Existing eBPF-based monitors provide low-overhead system and network visibility but are limited to single clusters, while centralized approaches incur bandwidth, privacy, and heterogeneity challenges. We propose FedMon, a federated eBPF framework that unifies kernel-level telemetry with federated learning (FL) for cross-cluster anomaly detection. Lightweight eBPF agents capture syscalls and network events, extract local statistical and sequence features, and share only model updates with a global server. A hybrid detection engine combining Variational Autoencoders (VAEs) with Isolation Forests enables both temporal pattern modeling and outlier detection. Deployed across three Kubernetes clusters, FedMon achieves 94% precision, 91% recall, and an F1-score of 0.92, while cutting bandwidth usage by 60% relative to centralized baselines. Results demonstrate that FedMon enhances accuracy, scalability, and privacy, providing an effective defense for large-scale, multi-tenant cloud-native environments.
<div id='section'>Paperid: <span id='pid'>899, <a href='https://arxiv.org/pdf/2510.06025.pdf' target='_blank'>https://arxiv.org/pdf/2510.06025.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Raina, Tanya Schmah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06025">Out-of-Distribution Detection from Small Training Sets using Bayesian Neural Network Classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is critical to AI reliability and safety, yet in many practical settings, only a limited amount of training data is available. Bayesian Neural Networks (BNNs) are a promising class of model on which to base OOD detection, because they explicitly represent epistemic (i.e. model) uncertainty. In the small training data regime, BNNs are especially valuable because they can incorporate prior model information. We introduce a new family of Bayesian posthoc OOD scores based on expected logit vectors, and compare 5 Bayesian and 4 deterministic posthoc OOD scores. Experiments on MNIST and CIFAR-10 In-Distributions, with 5000 training samples or less, show that the Bayesian methods outperform corresponding deterministic methods.
<div id='section'>Paperid: <span id='pid'>900, <a href='https://arxiv.org/pdf/2510.04776.pdf' target='_blank'>https://arxiv.org/pdf/2510.04776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ebenezer Awotoro, Chisom Ezekannagha, Florian Schwarz, Johannes Tauscher, Dominik Heider, Katharina Ladewig, Christel Le Bon, Karine Moncoq, Bruno Miroux, Georges Hattab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04776">MetaMP: Seamless Metadata Enrichment and AI Application Framework for Enhanced Membrane Protein Visualization and Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structural biology has made significant progress in determining membrane proteins, leading to a remarkable increase in the number of available structures in dedicated databases. The inherent complexity of membrane protein structures, coupled with challenges such as missing data, inconsistencies, and computational barriers from disparate sources, underscores the need for improved database integration. To address this gap, we present MetaMP, a framework that unifies membrane-protein databases within a web application and uses machine learning for classification. MetaMP improves data quality by enriching metadata, offering a user-friendly interface, and providing eight interactive views for streamlined exploration. MetaMP was effective across tasks of varying difficulty, demonstrating advantages across different levels without compromising speed or accuracy, according to user evaluations. Moreover, MetaMP supports essential functions such as structure classification and outlier detection. We present three practical applications of Artificial Intelligence (AI) in membrane protein research: predicting transmembrane segments, reconciling legacy databases, and classifying structures with explainable AI support. In a validation focused on statistics, MetaMP resolved 77% of data discrepancies and accurately predicted the class of newly identified membrane proteins 98% of the time and overtook expert curation. Altogether, MetaMP is a much-needed resource that harmonizes current knowledge and empowers AI-driven exploration of membrane-protein architecture.
<div id='section'>Paperid: <span id='pid'>901, <a href='https://arxiv.org/pdf/2510.03911.pdf' target='_blank'>https://arxiv.org/pdf/2510.03911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yadav Mahesh Lorik, Kaushik Sarveswaran, Nagaraj Sundaramahalingam, Aravindakumar Venugopalan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03911">THEMIS: Unlocking Pretrained Knowledge with Foundation Model Embeddings for Anomaly Detection in Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time series anomaly detection forms a very crucial area in several domains but poses substantial challenges. Due to time series data possessing seasonality, trends, noise, and evolving patterns (concept drift), it becomes very difficult to set a general notion of what constitutes normal behavior. Anomalies themselves could be varied, ranging from a single outlier to contextual or collective anomalies, and are normally very rare; hence, the dataset is largely imbalanced. Additional layers of complexities arise due to the problems of increased dimensionality of modern time series, real-time detection criteria, setting up appropriate detection thresholds, and arriving at results that are interpretable. To embrace these multifaceted challenges, very strong, flexible, and interpretable approaches are required. This paper presents THEMIS, a new framework for time series anomaly detection that exploits pretrained knowledge from foundation models. THEMIS extracts embeddings from the encoder of the Chronos time series foundation model and applies outlier detection techniques like Local Outlier Factor and Spectral Decomposition on the self-similarity matrix, to spot anomalies in the data. Our experiments show that this modular method achieves SOTA results on the MSL dataset and performs quite competitively on the SMAP and SWAT$^*$ datasets. Notably, THEMIS exceeds models trained specifically for anomaly detection, presenting hyperparameter robustness and interpretability by default. This paper advocates for pretrained representations from foundation models for performing efficient and adaptable anomaly detection for time series data.
<div id='section'>Paperid: <span id='pid'>902, <a href='https://arxiv.org/pdf/2510.01829.pdf' target='_blank'>https://arxiv.org/pdf/2510.01829.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cornelius Schröder, Marius-Raphael Schlüter, Markus Lienkamp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01829">Calibrating the Full Predictive Class Distribution of 3D Object Detectors for Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In autonomous systems, precise object detection and uncertainty estimation are critical for self-aware and safe operation. This work addresses confidence calibration for the classification task of 3D object detectors. We argue that it is necessary to regard the calibration of the full predictive confidence distribution over all classes and deduce a metric which captures the calibration of dominant and secondary class predictions. We propose two auxiliary regularizing loss terms which introduce either calibration of the dominant prediction or the full prediction vector as a training goal. We evaluate a range of post-hoc and train-time methods for CenterPoint, PillarNet and DSVT-Pillar and find that combining our loss term, which regularizes for calibration of the full class prediction, and isotonic regression lead to the best calibration of CenterPoint and PillarNet with respect to both dominant and secondary class predictions. We further find that DSVT-Pillar can not be jointly calibrated for dominant and secondary predictions using the same method.
<div id='section'>Paperid: <span id='pid'>903, <a href='https://arxiv.org/pdf/2510.00029.pdf' target='_blank'>https://arxiv.org/pdf/2510.00029.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Madhushan Ramalingam, Yaish Riaz, Priyanthi Rajamanoharan, Piyumi Dasanayaka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00029">Enhancing Safety in Diabetic Retinopathy Detection: Uncertainty-Aware Deep Learning Models with Rejection Capabilities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diabetic retinopathy (DR) is a major cause of visual impairment, and effective treatment options depend heavily on timely and accurate diagnosis. Deep learning models have demonstrated great success identifying DR from retinal images. However, relying only on predictions made by models, without any indication of model confidence, creates uncertainty and poses significant risk in clinical settings. This paper investigates an alternative in uncertainty-aware deep learning models, including a rejection mechanism to reject low-confidence predictions, contextualized by deferred decision-making in clinical practice. The results show there is a trade-off between prediction coverage and coverage reliability. The Variational Bayesian model adopted a more conservative strategy when predicting DR, subsequently rejecting the uncertain predictions. The model is evaluated by means of important performance metrics such as Accuracy on accepted predictions, the proportion of accepted cases (coverage), the rejection-ratio, and Expected Calibration Error (ECE). The findings also demonstrate a clear trade-off between accuracy and caution, establishing that the use of uncertainty estimation and selective rejection improves the model's reliability in safety-critical diagnostic use cases.
<div id='section'>Paperid: <span id='pid'>904, <a href='https://arxiv.org/pdf/2510.00001.pdf' target='_blank'>https://arxiv.org/pdf/2510.00001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Noah Broestl, Adel Nasser Abdalla, Rajprakash Bale, Hersh Gupta, Max Struever
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00001">Methodological Framework for Quantifying Semantic Test Coverage in RAG Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliably determining the performance of Retrieval-Augmented Generation (RAG) systems depends on comprehensive test questions. While a proliferation of evaluation frameworks for LLM-powered applications exists, current practices lack a systematic method to ensure these test sets adequately cover the underlying knowledge base, leaving developers with significant blind spots. To address this, we present a novel, applied methodology to quantify the semantic coverage of RAG test questions against their underlying documents. Our approach leverages existing technologies, including vector embeddings and clustering algorithms, to create a practical framework for validating test comprehensiveness. Our methodology embeds document chunks and test questions into a unified vector space, enabling the calculation of multiple coverage metrics: basic proximity, content-weighted coverage, and multi-topic question coverage. Furthermore, we incorporate outlier detection to filter irrelevant questions, allowing for the refinement of test sets. Experimental evidence from two distinct use cases demonstrates that our framework effectively quantifies test coverage, identifies specific content areas with inadequate representation, and provides concrete recommendations for generating new, high-value test questions. This work provides RAG developers with essential tools to build more robust test suites, thereby improving system reliability and extending to applications such as identifying misaligned documents.
<div id='section'>Paperid: <span id='pid'>905, <a href='https://arxiv.org/pdf/2509.22014.pdf' target='_blank'>https://arxiv.org/pdf/2509.22014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurav Jha, Stefan K. Ehrlich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22014">Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Healthcare robotics requires robust multimodal perception and reasoning to ensure safety in dynamic clinical environments. Current Vision-Language Models (VLMs) demonstrate strong general-purpose capabilities but remain limited in temporal reasoning, uncertainty estimation, and structured outputs needed for robotic planning. We present a lightweight agentic multimodal framework for video-based scene understanding. Combining the Qwen2.5-VL-3B-Instruct model with a SmolAgent-based orchestration layer, it supports chain-of-thought reasoning, speech-vision fusion, and dynamic tool invocation. The framework generates structured scene graphs and leverages a hybrid retrieval module for interpretable and adaptive reasoning. Evaluations on the Video-MME benchmark and a custom clinical dataset show competitive accuracy and improved robustness compared to state-of-the-art VLMs, demonstrating its potential for applications in robot-assisted surgery, patient monitoring, and decision support.
<div id='section'>Paperid: <span id='pid'>906, <a href='https://arxiv.org/pdf/2509.19408.pdf' target='_blank'>https://arxiv.org/pdf/2509.19408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Obu-Amoah Ampomah, Edmund Agyemang, Kofi Acheampong, Louis Agyekum
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19408">Enhancing Credit Default Prediction Using Boruta Feature Selection and DBSCAN Algorithm with Different Resampling Techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study examines credit default prediction by comparing three techniques, namely SMOTE, SMOTE-Tomek, and ADASYN, that are commonly used to address the class imbalance problem in credit default situations. Recognizing that credit default datasets are typically skewed, with defaulters comprising a much smaller proportion than non-defaulters, we began our analysis by evaluating machine learning (ML) models on the imbalanced data without any resampling to establish baseline performance. These baseline results provide a reference point for understanding the impact of subsequent balancing methods. In addition to traditional classifiers such as Naive Bayes and K-Nearest Neighbors (KNN), our study also explores the suitability of advanced ensemble boosting algorithms, including Extreme Gradient Boosting (XGBoost), AdaBoost, Gradient Boosting Machines (GBM), and Light GBM for credit default prediction using Boruta feature selection and DBSCAN-based outlier detection, both before and after resampling. A real-world credit default data set sourced from the University of Cleveland ML Repository was used to build ML classifiers, and their performances were tested. The criteria chosen to measure model performance are the area under the receiver operating characteristic curve (ROC-AUC), area under the precision-recall curve (PR-AUC), G-mean, and F1-scores. The results from this empirical study indicate that the Boruta+DBSCAN+SMOTE-Tomek+GBM classifier outperformed the other ML models (F1-score: 82.56%, G-mean: 82.98%, ROC-AUC: 90.90%, PR-AUC: 91.85%) in a credit default context. The findings establish a foundation for future progress in creating more resilient and adaptive credit default systems, which will be essential as credit-based transactions continue to rise worldwide.
<div id='section'>Paperid: <span id='pid'>907, <a href='https://arxiv.org/pdf/2509.16354.pdf' target='_blank'>https://arxiv.org/pdf/2509.16354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sivan Sarafian, Yehudit Aperstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16354">Improving Deep Tabular Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tabular data remain a dominant form of real-world information but pose persistent challenges for deep learning due to heterogeneous feature types, lack of natural structure, and limited label-preserving augmentations. As a result, ensemble models based on decision trees continue to dominate benchmark leaderboards. In this work, we introduce RuleNet, a transformer-based architecture specifically designed for deep tabular learning. RuleNet incorporates learnable rule embeddings in a decoder, a piecewise linear quantile projection for numerical features, and feature masking ensembles for robustness and uncertainty estimation. Evaluated on eight benchmark datasets, RuleNet matches or surpasses state-of-the-art tree-based methods in most cases, while remaining computationally efficient, offering a practical neural alternative for tabular prediction tasks.
<div id='section'>Paperid: <span id='pid'>908, <a href='https://arxiv.org/pdf/2509.13713.pdf' target='_blank'>https://arxiv.org/pdf/2509.13713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tae-Wook Um, Ki-Hyeon Kim, Hyun-Duck Choi, Hyo-Sung Ahn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13713">UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monocular depth estimation has been increasingly adopted in robotics and autonomous driving for its ability to infer scene geometry from a single camera. In self-supervised monocular depth estimation frameworks, the network jointly generates and exploits depth and pose estimates during training, thereby eliminating the need for depth labels. However, these methods remain challenged by uncertainty in the input data, such as low-texture or dynamic regions, which can cause reduced depth accuracy. To address this, we introduce UM-Depth, a framework that combines motion- and uncertainty-aware refinement to enhance depth accuracy at dynamic object boundaries and in textureless regions. Specifically, we develop a teacherstudent training strategy that embeds uncertainty estimation into both the training pipeline and network architecture, thereby strengthening supervision where photometric signals are weak. Unlike prior motion-aware approaches that incur inference-time overhead and rely on additional labels or auxiliary networks for real-time generation, our method uses optical flow exclusively within the teacher network during training, which eliminating extra labeling demands and any runtime cost. Extensive experiments on the KITTI and Cityscapes datasets demonstrate the effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves state-of-the-art results in both self-supervised depth and pose estimation on the KITTI datasets.
<div id='section'>Paperid: <span id='pid'>909, <a href='https://arxiv.org/pdf/2509.13577.pdf' target='_blank'>https://arxiv.org/pdf/2509.13577.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tongfei Guo, Lili Su
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13577">Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trajectory prediction is central to the safe and seamless operation of autonomous vehicles (AVs). In deployment, however, prediction models inevitably face distribution shifts between training data and real-world conditions, where rare or underrepresented traffic scenarios induce out-of-distribution (OOD) cases. While most prior OOD detection research in AVs has concentrated on computer vision tasks such as object detection and segmentation, trajectory-level OOD detection remains largely underexplored. A recent study formulated this problem as a quickest change detection (QCD) task, providing formal guarantees on the trade-off between detection delay and false alarms [1]. Building on this foundation, we propose a new framework that introduces adaptive mechanisms to achieve robust detection in complex driving environments. Empirical analysis across multiple real-world datasets reveals that prediction errors -- even on in-distribution samples -- exhibit mode-dependent distributions that evolve over time with dataset-specific dynamics. By explicitly modeling these error modes, our method achieves substantial improvements in both detection delay and false alarm rates. Comprehensive experiments on established trajectory prediction benchmarks show that our framework significantly outperforms prior UQ- and vision-based OOD approaches in both accuracy and computational efficiency, offering a practical path toward reliable, driving-aware autonomy.
<div id='section'>Paperid: <span id='pid'>910, <a href='https://arxiv.org/pdf/2509.10560.pdf' target='_blank'>https://arxiv.org/pdf/2509.10560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuechen Liang, Xiaoxing He, Shengdao Wang, Jean-Philippe Montillet, Zhengkai Huang, GaÃ«l Kermarrec, Shunqiang Hu, Yu Zhou, Jiahui Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10560">GTS_Forecaster: a novel deep learning based geodetic time series forecasting toolbox with python</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geodetic time series -- such as Global Navigation Satellite System (GNSS) positions, satellite altimetry-derived sea surface height (SSH), and tide gauge (TG) records -- is essential for monitoring surface deformation and sea level change. Accurate forecasts of these variables can enhance early warning systems and support hazard mitigation for earthquakes, landslides, coastal storm surge, and long-term sea level. However, the nonlinear, non-stationary, and incomplete nature of such variables presents significant challenges for classic models, which often fail to capture long-term dependencies and complex spatiotemporal dynamics. We introduce GTS Forecaster, an open-source Python package for geodetic time series forecasting. It integrates advanced deep learning models -- including kernel attention networks (KAN), graph neural network-based gated recurrent units (GNNGRU), and time-aware graph neural networks (TimeGNN) -- to effectively model nonlinear spatial-temporal patterns. The package also provides robust preprocessing tools, including outlier detection and a reinforcement learning-based gap-filling algorithm, the Kalman-TransFusion Interpolation Framework (KTIF). GTS Forecaster currently supports forecasting, visualization, and evaluation of GNSS, SSH, and TG datasets, and is adaptable to general time series applications. By combining cutting-edge models with an accessible interface, it facilitates the application of deep learning in geodetic forecasting tasks.
<div id='section'>Paperid: <span id='pid'>911, <a href='https://arxiv.org/pdf/2509.06554.pdf' target='_blank'>https://arxiv.org/pdf/2509.06554.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dietmar Saupe, Tim Bleile
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06554">Robustness and accuracy of mean opinion scores with hard and soft outlier detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In subjective assessment of image and video quality, observers rate or compare selected stimuli. Before calculating the mean opinion scores (MOS) for these stimuli from the ratings, it is recommended to identify and deal with outliers that may have given unreliable ratings. Several methods are available for this purpose, some of which have been standardized. These methods are typically based on statistics and sometimes tested by introducing synthetic ratings from artificial outliers, such as random clickers. However, a reliable and comprehensive approach is lacking for comparative performance analysis of outlier detection methods. To fill this gap, this work proposes and applies an empirical worst-case analysis as a general solution. Our method involves evolutionary optimization of an adversarial black-box attack on outlier detection algorithms, where the adversary maximizes the distortion of scale values with respect to ground truth. We apply our analysis to several hard and soft outlier detection methods for absolute category ratings and show their differing performance in this stress test. In addition, we propose two new outlier detection methods with low complexity and excellent worst-case performance. Software for adversarial attacks and data analysis is available.
<div id='section'>Paperid: <span id='pid'>912, <a href='https://arxiv.org/pdf/2509.05360.pdf' target='_blank'>https://arxiv.org/pdf/2509.05360.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jerry Li, Evangelos Papalexakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05360">Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have demonstrated effectiveness across a wide variety of tasks involving natural language, however, a fundamental problem of hallucinations still plagues these models, limiting their trustworthiness in generating consistent, truthful information. Detecting hallucinations has quickly become an important topic, with various methods such as uncertainty estimation, LLM Judges, retrieval augmented generation (RAG), and consistency checks showing promise. Many of these methods build upon foundational metrics, such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth necessary to detect hallucinations effectively. In this work, we propose a novel approach inspired by ROUGE that constructs an N-Gram frequency tensor from LLM-generated text. This tensor captures richer semantic structure by encoding co-occurrence patterns, enabling better differentiation between factual and hallucinated content. We demonstrate this by applying tensor decomposition methods to extract singular values from each mode and use these as input features to train a multi-layer perceptron (MLP) binary classifier for hallucinations. Our method is evaluated on the HaluEval dataset and demonstrates significant improvements over traditional baselines, as well as competitive performance against state-of-the-art LLM judges.
<div id='section'>Paperid: <span id='pid'>913, <a href='https://arxiv.org/pdf/2509.02826.pdf' target='_blank'>https://arxiv.org/pdf/2509.02826.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Towhidul Islam, Md Sumon Ali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02826">Ensemble Learning for Healthcare: A Comparative Analysis of Hybrid Voting and Ensemble Stacking in Obesity Risk Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Obesity is a critical global health issue driven by dietary, physiological, and environmental factors, and is strongly associated with chronic diseases such as diabetes, cardiovascular disorders, and cancer. Machine learning has emerged as a promising approach for early obesity risk prediction, yet a comparative evaluation of ensemble techniques -- particularly hybrid majority voting and ensemble stacking -- remains limited. This study aims to compare hybrid majority voting and ensemble stacking methods for obesity risk prediction, identifying which approach delivers higher accuracy and efficiency. The analysis seeks to highlight the complementary strengths of these ensemble techniques in guiding better predictive model selection for healthcare applications. Two datasets were utilized to evaluate three ensemble models: Majority Hard Voting, Weighted Hard Voting, and Stacking (with a Multi-Layer Perceptron as meta-classifier). A pool of nine Machine Learning (ML) algorithms, evaluated across a total of 50 hyperparameter configurations, was analyzed to identify the top three models to serve as base learners for the ensemble methods. Preprocessing steps involved dataset balancing, and outlier detection, and model performance was evaluated using Accuracy and F1-Score. On Dataset-1, weighted hard voting and stacking achieved nearly identical performance (Accuracy: 0.920304, F1: 0.920070), outperforming majority hard voting. On Dataset-2, stacking demonstrated superior results (Accuracy: 0.989837, F1: 0.989825) compared to majority hard voting (Accuracy: 0.981707, F1: 0.981675) and weighted hard voting, which showed the lowest performance. The findings confirm that ensemble stacking provides stronger predictive capability, particularly for complex data distributions, while hybrid majority voting remains a robust alternative.
<div id='section'>Paperid: <span id='pid'>914, <a href='https://arxiv.org/pdf/2508.18903.pdf' target='_blank'>https://arxiv.org/pdf/2508.18903.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aishwarya Venkataramanan, Joachim Denzler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18903">Distance-informed Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the Distance-informed Neural Process (DNP), a novel variant of Neural Processes that improves uncertainty estimation by combining global and distance-aware local latent structures. Standard Neural Processes (NPs) often rely on a global latent variable and struggle with uncertainty calibration and capturing local data dependencies. DNP addresses these limitations by introducing a global latent variable to model task-level variations and a local latent variable to capture input similarity within a distance-preserving latent space. This is achieved through bi-Lipschitz regularization, which bounds distortions in input relationships and encourages the preservation of relative distances in the latent space. This modeling approach allows DNP to produce better-calibrated uncertainty estimates and more effectively distinguish in- from out-of-distribution data. Empirical results demonstrate that DNP achieves strong predictive performance and improved uncertainty calibration across regression and classification tasks.
<div id='section'>Paperid: <span id='pid'>915, <a href='https://arxiv.org/pdf/2508.18473.pdf' target='_blank'>https://arxiv.org/pdf/2508.18473.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Li, Akshayaa Magesh, Venugopal V. Veeravalli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18473">Principled Detection of Hallucinations in Large Language Models via Multiple Testing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Large Language Models (LLMs) have emerged as powerful foundational models to solve a variety of tasks, they have also been shown to be prone to hallucinations, i.e., generating responses that sound confident but are actually incorrect or even nonsensical. In this work, we formulate the problem of detecting hallucinations as a hypothesis testing problem and draw parallels to the problem of out-of-distribution detection in machine learning models. We propose a multiple-testing-inspired method to solve the hallucination detection problem, and provide extensive experimental results to validate the robustness of our approach against state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>916, <a href='https://arxiv.org/pdf/2507.13486.pdf' target='_blank'>https://arxiv.org/pdf/2507.13486.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Debao Huang, Rongjun Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13486">Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification of the photogrammetry process is essential for providing per-point accuracy credentials of the point clouds. Unlike airborne LiDAR, which typically delivers consistent accuracy across various scenes, the accuracy of photogrammetric point clouds is highly scene-dependent, since it relies on algorithm-generated measurements (i.e., stereo or multi-view stereo). Generally, errors of the photogrammetric point clouds propagate through a two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA), followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM stage has been well studied using the first-order statistics of the reprojection error function, that in the MVS stage remains largely unsolved and non-standardized, primarily due to its non-differentiable and multi-modal nature (i.e., from pixel values to geometry). In this paper, we present an uncertainty quantification framework closing this gap by associating an error covariance matrix per point accounting for this two-step photogrammetry process. Specifically, to estimate the uncertainty in the MVS stage, we propose a novel, self-calibrating method by taking reliable n-view points (n>=6) per-view to regress the disparity uncertainty using highly relevant cues (such as matching cost values) from the MVS stage. Compared to existing approaches, our method uses self-contained, reliable 3D points extracted directly from the MVS process, with the benefit of being self-supervised and naturally adhering to error propagation path of the photogrammetry process, thereby providing a robust and certifiable uncertainty quantification across diverse scenes. We evaluate the framework using a variety of publicly available airborne and UAV imagery datasets. Results demonstrate that our method outperforms existing approaches by achieving high bounding rates without overestimating uncertainty.
<div id='section'>Paperid: <span id='pid'>917, <a href='https://arxiv.org/pdf/2507.00756.pdf' target='_blank'>https://arxiv.org/pdf/2507.00756.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Xing, Kai Zhe Boey, Gordon Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00756">Towards Open-World Human Action Segmentation Using Graph Convolutional Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human-object interaction segmentation is a fundamental task of daily activity understanding, which plays a crucial role in applications such as assistive robotics, healthcare, and autonomous systems. Most existing learning-based methods excel in closed-world action segmentation, they struggle to generalize to open-world scenarios where novel actions emerge. Collecting exhaustive action categories for training is impractical due to the dynamic diversity of human activities, necessitating models that detect and segment out-of-distribution actions without manual annotation. To address this issue, we formally define the open-world action segmentation problem and propose a structured framework for detecting and segmenting unseen actions. Our framework introduces three key innovations: 1) an Enhanced Pyramid Graph Convolutional Network (EPGCN) with a novel decoder module for robust spatiotemporal feature upsampling. 2) Mixup-based training to synthesize out-of-distribution data, eliminating reliance on manual annotations. 3) A novel Temporal Clustering loss that groups in-distribution actions while distancing out-of-distribution samples.
  We evaluate our framework on two challenging human-object interaction recognition datasets: Bimanual Actions and 2 Hands and Object (H2O) datasets. Experimental results demonstrate significant improvements over state-of-the-art action segmentation models across multiple open-set evaluation metrics, achieving 16.9% and 34.6% relative gains in open-set segmentation (F1@50) and out-of-distribution detection performances (AUROC), respectively. Additionally, we conduct an in-depth ablation study to assess the impact of each proposed component, identifying the optimal framework configuration for open-world action segmentation.
<div id='section'>Paperid: <span id='pid'>918, <a href='https://arxiv.org/pdf/2506.22994.pdf' target='_blank'>https://arxiv.org/pdf/2506.22994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Hakan DaÄÄ±dÄ±r, Mia Hubert, Peter J. Rousseeuw
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22994">Kernel Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A new anomaly detection method called kernel outlier detection (KOD) is proposed. It is designed to address challenges of outlier detection in high-dimensional settings. The aim is to overcome limitations of existing methods, such as dependence on distributional assumptions or on hyperparameters that are hard to tune. KOD starts with a kernel transformation, followed by a projection pursuit approach. Its novelties include a new ensemble of directions to search over, and a new way to combine results of different direction types. This provides a flexible and lightweight approach for outlier detection. Our empirical evaluations illustrate the effectiveness of KOD on three small datasets with challenging structures, and on four large benchmark datasets.
<div id='section'>Paperid: <span id='pid'>919, <a href='https://arxiv.org/pdf/2506.18283.pdf' target='_blank'>https://arxiv.org/pdf/2506.18283.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuli Slavutsky, David M. Blei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18283">Quantifying Uncertainty in the Presence of Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks make accurate predictions but often fail to provide reliable uncertainty estimates, especially under covariate distribution shifts between training and testing. To address this problem, we propose a Bayesian framework for uncertainty estimation that explicitly accounts for covariate shifts. While conventional approaches rely on fixed priors, the key idea of our method is an adaptive prior, conditioned on both training and new covariates. This prior naturally increases uncertainty for inputs that lie far from the training distribution in regions where predictive performance is likely to degrade. To efficiently approximate the resulting posterior predictive distribution, we employ amortized variational inference. Finally, we construct synthetic environments by drawing small bootstrap samples from the training data, simulating a range of plausible covariate shift using only the original dataset. We evaluate our method on both synthetic and real-world data. It yields substantially improved uncertainty estimates under distribution shifts.
<div id='section'>Paperid: <span id='pid'>920, <a href='https://arxiv.org/pdf/2506.16416.pdf' target='_blank'>https://arxiv.org/pdf/2506.16416.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Timans, Rajeev Verma, Eric Nalisnick, Christian A. Naesseth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16416">On Continuous Monitoring of Risk Violations under Unknown Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning systems deployed in the real world must operate under dynamic and often unpredictable distribution shifts. This challenges the validity of statistical safety assurances on the system's risk established beforehand. Common risk control frameworks rely on fixed assumptions and lack mechanisms to continuously monitor deployment reliability. In this work, we propose a general framework for the real-time monitoring of risk violations in evolving data streams. Leveraging the 'testing by betting' paradigm, we propose a sequential hypothesis testing procedure to detect violations of bounded risks associated with the model's decision-making mechanism, while ensuring control on the false alarm rate. Our method operates under minimal assumptions on the nature of encountered shifts, rendering it broadly applicable. We illustrate the effectiveness of our approach by monitoring risks in outlier detection and set prediction under a variety of shifts.
<div id='section'>Paperid: <span id='pid'>921, <a href='https://arxiv.org/pdf/2506.13508.pdf' target='_blank'>https://arxiv.org/pdf/2506.13508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jungeon Kim, Geonsoo Park, Seungyong Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13508">Multiview Geometric Regularization of Gaussian Splatting for Accurate Radiance Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent methods, such as 2D Gaussian Splatting and Gaussian Opacity Fields, have aimed to address the geometric inaccuracies of 3D Gaussian Splatting while retaining its superior rendering quality. However, these approaches still struggle to reconstruct smooth and reliable geometry, particularly in scenes with significant color variation across viewpoints, due to their per-point appearance modeling and single-view optimization constraints. In this paper, we propose an effective multiview geometric regularization strategy that integrates multiview stereo (MVS) depth, RGB, and normal constraints into Gaussian Splatting initialization and optimization. Our key insight is the complementary relationship between MVS-derived depth points and Gaussian Splatting-optimized positions: MVS robustly estimates geometry in regions of high color variation through local patch-based matching and epipolar constraints, whereas Gaussian Splatting provides more reliable and less noisy depth estimates near object boundaries and regions with lower color variation. To leverage this insight, we introduce a median depth-based multiview relative depth loss with uncertainty estimation, effectively integrating MVS depth information into Gaussian Splatting optimization. We also propose an MVS-guided Gaussian Splatting initialization to avoid Gaussians falling into suboptimal positions. Extensive experiments validate that our approach successfully combines these strengths, enhancing both geometric accuracy and rendering quality across diverse indoor and outdoor scenes.
<div id='section'>Paperid: <span id='pid'>922, <a href='https://arxiv.org/pdf/2506.06907.pdf' target='_blank'>https://arxiv.org/pdf/2506.06907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fred Xu, Thomas Markovich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06907">Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks have achieved impressive results across diverse network modeling tasks, but accurately estimating uncertainty on graphs remains difficult, especially under distributional shifts. Unlike traditional uncertainty estimation, graph-based uncertainty must account for randomness arising from both the graph's structure and its label distribution, which adds complexity. In this paper, making an analogy between the evolution of a stochastic partial differential equation (SPDE) driven by Matern Gaussian Process and message passing using GNN layers, we present a principled way to design a novel message passing scheme that incorporates spatial-temporal noises motivated by the Gaussian Process approach to SPDE. Our method simultaneously captures uncertainty across space and time and allows explicit control over the covariance kernel smoothness, thereby enhancing uncertainty estimates on graphs with both low and high label informativeness. Our extensive experiments on Out-of-Distribution (OOD) detection on graph datasets with varying label informativeness demonstrate the soundness and superiority of our model to existing approaches.
<div id='section'>Paperid: <span id='pid'>923, <a href='https://arxiv.org/pdf/2506.06048.pdf' target='_blank'>https://arxiv.org/pdf/2506.06048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haripriya Harikumar, Santu Rana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06048">TRUST: Test-time Resource Utilization for Superior Trustworthiness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard uncertainty estimation techniques, such as dropout, often struggle to clearly distinguish reliable predictions from unreliable ones. We attribute this limitation to noisy classifier weights, which, while not impairing overall class-level predictions, render finer-level statistics less informative. To address this, we propose a novel test-time optimization method that accounts for the impact of such noise to produce more reliable confidence estimates. This score defines a monotonic subset-selection function, where population accuracy consistently increases as samples with lower scores are removed, and it demonstrates superior performance in standard risk-based metrics such as AUSE and AURC. Additionally, our method effectively identifies discrepancies between training and test distributions, reliably differentiates in-distribution from out-of-distribution samples, and elucidates key differences between CNN and ViT classifiers across various vision datasets.
<div id='section'>Paperid: <span id='pid'>924, <a href='https://arxiv.org/pdf/2505.16320.pdf' target='_blank'>https://arxiv.org/pdf/2505.16320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>P. Huijse, J. De Ridder, L. Eyer, L. Rimoldini, B. Holl, N. Chornay, J. Roquette, K. Nienartowicz, G. Jevardat de Fombelle, D. J. Fritzewski, A. Kemp, V. Vanlaer, M. Vanrespaille, H. Wang, M. I. Carnerero, C. M. Raiteri, G. Marton, M. MadarÃ¡sz, G. Clementini, P. Gavras, C. Aerts
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16320">Learning novel representations of variable sources from multi-modal $\textit{Gaia}$ data via autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gaia Data Release 3 (DR3) published for the first time epoch photometry, BP/RP (XP) low-resolution mean spectra, and supervised classification results for millions of variable sources. This extensive dataset offers a unique opportunity to study their variability by combining multiple Gaia data products. In preparation for DR4, we propose and evaluate a machine learning methodology capable of ingesting multiple Gaia data products to achieve an unsupervised classification of stellar and quasar variability. A dataset of 4 million Gaia DR3 sources is used to train three variational autoencoders (VAE), which are artificial neural networks (ANNs) designed for data compression and generation. One VAE is trained on Gaia XP low-resolution spectra, another on a novel approach based on the distribution of magnitude differences in the Gaia G band, and the third on folded Gaia G band light curves. Each Gaia source is compressed into 15 numbers, representing the coordinates in a 15-dimensional latent space generated by combining the outputs of these three models. The learned latent representation produced by the ANN effectively distinguishes between the main variability classes present in Gaia DR3, as demonstrated through both supervised and unsupervised classification analysis of the latent space. The results highlight a strong synergy between light curves and low-resolution spectral data, emphasising the benefits of combining the different Gaia data products. A two-dimensional projection of the latent variables reveals numerous overdensities, most of which strongly correlate with astrophysical properties, showing the potential of this latent space for astrophysical discovery. We show that the properties of our novel latent representation make it highly valuable for variability analysis tasks, including classification, clustering and outlier detection.
<div id='section'>Paperid: <span id='pid'>925, <a href='https://arxiv.org/pdf/2505.16017.pdf' target='_blank'>https://arxiv.org/pdf/2505.16017.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mariia Seleznova, Hung-Hsu Chou, Claudio Mayrink Verdun, Gitta Kutyniok
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16017">GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce GradPCA, an Out-of-Distribution (OOD) detection method that exploits the low-rank structure of neural network gradients induced by Neural Tangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis (PCA) to gradient class-means, achieving more consistent performance than existing methods across standard image classification benchmarks. We provide a theoretical perspective on spectral OOD detection in neural networks to support GradPCA, highlighting feature-space properties that enable effective detection and naturally emerge from NTK alignment. Our analysis further reveals that feature quality -- particularly the use of pretrained versus non-pretrained representations -- plays a crucial role in determining which detectors will succeed. Extensive experiments validate the strong performance of GradPCA, and our theoretical framework offers guidance for designing more principled spectral OOD detectors.
<div id='section'>Paperid: <span id='pid'>926, <a href='https://arxiv.org/pdf/2505.13585.pdf' target='_blank'>https://arxiv.org/pdf/2505.13585.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinzhu Liang, Joseph M. Lukens, Sanjaya Lohani, Brian T. Kirby, Thomas A. Searles, Xin Qiu, Kody J. H. Law
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13585">Scalable Bayesian Monte Carlo: fast uncertainty estimation beyond deep ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces a new method designed for Bayesian deep learning called scalable Bayesian Monte Carlo (SBMC). The method is comprised of a model and an algorithm. The model interpolates between a point estimator and the posterior. The algorithm is a parallel implementation of sequential Monte Carlo sampler (SMC$_\parallel$) or Markov chain Monte Carlo (MCMC$_\parallel$). We collectively refer to these consistent (asymptotically unbiased) algorithms as Bayesian Monte Carlo (BMC), and any such algorithm can be used in our SBMC method. The utility of the method is demonstrated on practical examples: MNIST, CIFAR, IMDb. A systematic numerical study reveals that for the same wall-clock time as state-of-the-art (SOTA) methods like deep ensembles (DE), SBMC achieves comparable or better accuracy and substantially improved uncertainty quantification (UQ)--in particular, epistemic UQ. This is demonstrated on the downstream task of estimating the confidence in predictions, which can be used for reliability assessment or abstention decisions.
<div id='section'>Paperid: <span id='pid'>927, <a href='https://arxiv.org/pdf/2505.02299.pdf' target='_blank'>https://arxiv.org/pdf/2505.02299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daisuke Yamada, Harit Vishwakarma, Ramya Korlakai Vinayak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02299">Adaptive Scoring and Thresholding with Human Feedback for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine Learning (ML) models are trained on in-distribution (ID) data but often encounter out-of-distribution (OOD) inputs during deployment -- posing serious risks in safety-critical domains. Recent works have focused on designing scoring functions to quantify OOD uncertainty, with score thresholds typically set based solely on ID data to achieve a target true positive rate (TPR), since OOD data is limited before deployment. However, these TPR-based thresholds leave false positive rates (FPR) uncontrolled, often resulting in high FPRs where OOD points are misclassified as ID. Moreover, fixed scoring functions and thresholds lack the adaptivity needed to handle newly observed, evolving OOD inputs, leading to sub-optimal performance. To address these challenges, we propose a human-in-the-loop framework that \emph{safely updates both scoring functions and thresholds on the fly} based on real-world OOD inputs. Our method maximizes TPR while strictly controlling FPR at all times, even as the system adapts over time. We provide theoretical guarantees for FPR control under stationary conditions and present extensive empirical evaluations on OpenOOD benchmarks to demonstrate that our approach outperforms existing methods by achieving higher TPRs while maintaining FPR control.
<div id='section'>Paperid: <span id='pid'>928, <a href='https://arxiv.org/pdf/2504.20863.pdf' target='_blank'>https://arxiv.org/pdf/2504.20863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sven Goblirsch, Benedikt Ruhland, Johannes Betz, Markus Lienkamp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20863">Bayesian Optimization-based Tire Parameter and Uncertainty Estimation for Real-World Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents a methodology to estimate tire parameters and their uncertainty using a Bayesian optimization approach. The literature mainly considers the estimation of tire parameters but lacks an evaluation of the parameter identification quality and the required slip ratios for an adequate model fit. Therefore, we examine the use of Stochastical Variational Inference as a methodology to estimate both - the parameters and their uncertainties. We evaluate the method compared to a state-of-the-art Nelder-Mead algorithm for theoretical and real-world application. The theoretical study considers parameter fitting at different slip ratios to evaluate the required excitation for an adequate fitting of each parameter. The results are compared to a sensitivity analysis for a Pacejka Magic Formula tire model. We show the application of the algorithm on real-world data acquired during the Abu Dhabi Autonomous Racing League and highlight the uncertainties in identifying the curvature and shape parameters due to insufficient excitation. The gathered insights can help assess the acquired data's limitations and instead utilize standardized parameters until higher slip ratios are captured. We show that our proposed method can be used to assess the mean values and the uncertainties of tire model parameters in real-world conditions and derive actions for the tire modeling based on our simulative study.
<div id='section'>Paperid: <span id='pid'>929, <a href='https://arxiv.org/pdf/2504.20862.pdf' target='_blank'>https://arxiv.org/pdf/2504.20862.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dayananda Herurkar, JÃ¶rn Hees, Vesselin Tzvetkov, Andreas Dengel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20862">Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The remarkable success of Deep Learning approaches is often based and demonstrated on large public datasets. However, when applying such approaches to internal, private datasets, one frequently faces challenges arising from structural differences in the datasets, domain shift, and the lack of labels. In this work, we introduce Tabular Data Adapters (TDA), a novel method for generating soft labels for unlabeled tabular data in outlier detection tasks. By identifying statistically similar public datasets and transforming private data (based on a shared autoencoder) into a format compatible with state-of-the-art public models, our approach enables the generation of weak labels. It thereby can help to mitigate the cold start problem of labeling by basing on existing outlier detection models for public datasets. In experiments on 50 tabular datasets across different domains, we demonstrate that our method is able to provide more accurate annotations than baseline approaches while reducing computational time. Our approach offers a scalable, efficient, and cost-effective solution, to bridge the gap between public research models and real-world industrial applications.
<div id='section'>Paperid: <span id='pid'>930, <a href='https://arxiv.org/pdf/2504.08452.pdf' target='_blank'>https://arxiv.org/pdf/2504.08452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jyri MaanpÃ¤Ã¤, Julius Pesonen, Iaroslav Melekhov, Heikki Hyyti, Juha HyyppÃ¤
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08452">Road Grip Uncertainty Estimation Through Surface State Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Slippery road conditions pose significant challenges for autonomous driving. Beyond predicting road grip, it is crucial to estimate its uncertainty reliably to ensure safe vehicle control. In this work, we benchmark several uncertainty prediction methods to assess their effectiveness for grip uncertainty estimation. Additionally, we propose a novel approach that leverages road surface state segmentation to predict grip uncertainty. Our method estimates a pixel-wise grip probability distribution based on inferred road surface conditions. Experimental results indicate that the proposed approach enhances the robustness of grip uncertainty prediction.
<div id='section'>Paperid: <span id='pid'>931, <a href='https://arxiv.org/pdf/2503.22271.pdf' target='_blank'>https://arxiv.org/pdf/2503.22271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Omini Rathore, Richard Paul, Abigail Morrison, Hanno Scharr, Elisabeth Pfaehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22271">Efficient Epistemic Uncertainty Estimation in Cerebrovascular Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Brain vessel segmentation of MR scans is a critical step in the diagnosis of cerebrovascular diseases. Due to the fine vessel structure, manual vessel segmentation is time consuming. Therefore, automatic deep learning (DL) based segmentation techniques are intensively investigated. As conventional DL models yield a high complexity and lack an indication of decision reliability, they are often considered as not trustworthy. This work aims to increase trust in DL based models by incorporating epistemic uncertainty quantification into cerebrovascular segmentation models for the first time. By implementing an efficient ensemble model combining the advantages of Bayesian Approximation and Deep Ensembles, we aim to overcome the high computational costs of conventional probabilistic networks. Areas of high model uncertainty and erroneous predictions are aligned which demonstrates the effectiveness and reliability of the approach. We perform extensive experiments applying the ensemble model on out-of-distribution (OOD) data. We demonstrate that for OOD-images, the estimated uncertainty increases. Additionally, omitting highly uncertain areas improves the segmentation quality, both for in- and out-of-distribution data. The ensemble model explains its limitations in a reliable manner and can maintain trustworthiness also for OOD data and could be considered in clinical applications
<div id='section'>Paperid: <span id='pid'>932, <a href='https://arxiv.org/pdf/2503.22197.pdf' target='_blank'>https://arxiv.org/pdf/2503.22197.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Liu, Xun Zhang, Jiale Du, Xinbo Gao, Jungong Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22197">Extremely Simple Out-of-distribution Detection for Audio-visual Generalized Zero-shot Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Zero-shot Learning(ZSL) attains knowledge transfer from seen classes to unseen classes by exploring auxiliary category information, which is a promising yet difficult research topic. In this field, Audio-Visual Generalized Zero-Shot Learning~(AV-GZSL) has aroused researchers' great interest in which intricate relations within triple modalities~(audio, video, and natural language) render this task quite challenging but highly research-worthy. However, both existing embedding-based and generative-based AV-GZSL methods tend to suffer from domain shift problem a lot and we propose an extremely simple Out-of-distribution~(OOD) detection based AV-GZSL method~(EZ-AVOOD) to further mitigate bias problem by differentiating seen and unseen samples at the initial beginning. EZ-AVOOD accomplishes effective seen-unseen separation by exploiting the intrinsic discriminative information held in class-specific logits and class-agnostic feature subspace without training an extra OOD detector network. Followed by seen-unseen binary classification, we employ two expert models to classify seen samples and unseen samples separately. Compared to existing state-of-the-art methods, our model achieves superior ZSL and GZSL performances on three audio-visual datasets and becomes the new SOTA, which comprehensively demonstrates the effectiveness of the proposed EZ-AVOOD.
<div id='section'>Paperid: <span id='pid'>933, <a href='https://arxiv.org/pdf/2503.18836.pdf' target='_blank'>https://arxiv.org/pdf/2503.18836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxuan Zhang, Jinkui Hao, Bo Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18836">Dual-domain Multi-path Self-supervised Diffusion Model for Accelerated MRI Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic resonance imaging (MRI) is a vital diagnostic tool, but its inherently long acquisition times reduce clinical efficiency and patient comfort. Recent advancements in deep learning, particularly diffusion models, have improved accelerated MRI reconstruction. However, existing diffusion models' training often relies on fully sampled data, models incur high computational costs, and often lack uncertainty estimation, limiting their clinical applicability. To overcome these challenges, we propose a novel framework, called Dual-domain Multi-path Self-supervised Diffusion Model (DMSM), that integrates a self-supervised dual-domain diffusion model training scheme, a lightweight hybrid attention network for the reconstruction diffusion model, and a multi-path inference strategy, to enhance reconstruction accuracy, efficiency, and explainability. Unlike traditional diffusion-based models, DMSM eliminates the dependency on training from fully sampled data, making it more practical for real-world clinical settings. We evaluated DMSM on two human MRI datasets, demonstrating that it achieves favorable performance over several supervised and self-supervised baselines, particularly in preserving fine anatomical structures and suppressing artifacts under high acceleration factors. Additionally, our model generates uncertainty maps that correlate reasonably well with reconstruction errors, offering valuable clinically interpretable guidance and potentially enhancing diagnostic confidence.
<div id='section'>Paperid: <span id='pid'>934, <a href='https://arxiv.org/pdf/2503.18599.pdf' target='_blank'>https://arxiv.org/pdf/2503.18599.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minsu Kim, Seongmin Hong, RyeoWook Ko, Soongyu Choi, Hunjong Lee, Junsoo Kim, Joo-Young Kim, Jongse Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18599">Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern Large Language Model serving system batches multiple requests to achieve high throughput, while batching attention operations is challenging, rendering memory bandwidth a critical bottleneck. The community relies on high-end GPUs with multiple high-bandwidth memory channels. Unfortunately, HBM's high bandwidth often comes at the expense of limited memory capacity, which reduces core utilization and increases costs. Recent advancements enabling longer contexts for LLMs have substantially increased the key-value cache size, further intensifying the pressures on memory capacity. The literature has explored KV cache quantization techniques, which commonly use low bitwidth for most values, selectively using higher bitwidth for outlier values. While this approach helps achieve high accuracy and low bitwidth simultaneously, it comes with the limitation that cost for online outlier detection is excessively high, negating the advantages. We propose Oaken, an acceleration solution that achieves high accuracy and high performance simultaneously through co-designing algorithm and hardware. To effectively find a sweet spot in the accuracy-performance trade-off space of KV cache quantization, Oaken employs an online-offline hybrid approach, setting outlier thresholds offline, which are then used to determine the quantization scale online. To translate the proposed algorithmic technique into tangible performance gains, Oaken also comes with custom quantization engines and memory management units that can be integrated with any LLM accelerators. We built an Oaken accelerator on top of an LLM accelerator, LPU, and conducted a comprehensive evaluation. Our experiments show that for a batch size of 256, Oaken achieves up to 1.58x throughput improvement over NVIDIA A100 GPU, incurring a minimal accuracy loss of only 0.54\% on average, compared to state-of-the-art KV cache quantization techniques.
<div id='section'>Paperid: <span id='pid'>935, <a href='https://arxiv.org/pdf/2503.14983.pdf' target='_blank'>https://arxiv.org/pdf/2503.14983.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zanting Ye, Xiaolong Niu, Xuanbin Wu, Wenxiang Yi, Yuan Chang, Lijun Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14983">Semi-KAN: KAN Provides an Effective Representation for Semi-Supervised Learning in Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based medical image segmentation has shown remarkable success; however, it typically requires extensive pixel-level annotations, which are both expensive and time-intensive. Semi-supervised medical image segmentation (SSMIS) offers a viable alternative, driven by advancements in CNNs and ViTs. However, these networks often rely on single fixed activation functions and linear modeling patterns, limiting their ability to effectively learn robust representations. Given the limited availability of labeled date, achieving robust representation learning becomes crucial. Inspired by Kolmogorov-Arnold Networks (KANs), we propose Semi-KAN, which leverages the untapped potential of KANs to enhance backbone architectures for representation learning in SSMIS. Our findings indicate that: (1) compared to networks with fixed activation functions, KANs exhibit superior representation learning capabilities with fewer parameters, and (2) KANs excel in high-semantic feature spaces. Building on these insights, we integrate KANs into tokenized intermediate representations, applying them selectively at the encoder's bottleneck and the decoder's top layers within a U-Net pipeline to extract high-level semantic features. Although learnable activation functions improve feature expansion, they introduce significant computational overhead with only marginal performance gains. To mitigate this, we reduce the feature dimensions and employ horizontal scaling to capture multiple pattern representations. Furthermore, we design a multi-branch U-Net architecture with uncertainty estimation to effectively learn diverse pattern representations. Extensive experiments on four public datasets demonstrate that Semi-KAN surpasses baseline networks, utilizing fewer KAN layers and lower computational cost, thereby underscoring the potential of KANs as a promising approach for SSMIS.
<div id='section'>Paperid: <span id='pid'>936, <a href='https://arxiv.org/pdf/2503.04191.pdf' target='_blank'>https://arxiv.org/pdf/2503.04191.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sara Sangalli, Gary Sarwin, Ertunc Erdil, Alessandro Carretta, Victor Staartjes, Carlo Serra, Ender Konukoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04191">Conformal forecasting for surgical instrument trajectory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Forecasting surgical instrument trajectories and predicting the next surgical action recently started to attract attention from the research community. Both these tasks are crucial for automation and assistance in endoscopy surgery. Given the safety-critical nature of these tasks, reliable uncertainty quantification is essential. Conformal prediction is a fast-growing and widely recognized framework for uncertainty estimation in machine learning and computer vision, offering distribution-free, theoretically valid prediction intervals. In this work, we explore the application of standard conformal prediction and conformalized quantile regression to estimate uncertainty in forecasting surgical instrument motion, i.e., predicting direction and magnitude of surgical instruments' future motion. We analyze and compare their coverage and interval sizes, assessing the impact of multiple hypothesis testing and correction methods. Additionally, we show how these techniques can be employed to produce useful uncertainty heatmaps. To the best of our knowledge, this is the first study applying conformal prediction to surgical guidance, marking an initial step toward constructing principled prediction intervals with formal coverage guarantees in this domain.
<div id='section'>Paperid: <span id='pid'>937, <a href='https://arxiv.org/pdf/2502.18883.pdf' target='_blank'>https://arxiv.org/pdf/2502.18883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanfu Yan, Viet Duong, Huajie Shao, Denys Poshyvanyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18883">Towards More Trustworthy Deep Code Models by Enabling Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerous machine learning (ML) models have been developed, including those for software engineering (SE) tasks, under the assumption that training and testing data come from the same distribution. However, training and testing distributions often differ, as training datasets rarely encompass the entire distribution, while testing distribution tends to shift over time. Hence, when confronted with out-of-distribution (OOD) instances that differ from the training data, a reliable and trustworthy SE ML model must be capable of detecting them to either abstain from making predictions, or potentially forward these OODs to appropriate models handling other categories or tasks.
  In this paper, we develop two types of SE-specific OOD detection models, unsupervised and weakly-supervised OOD detection for code. The unsupervised OOD detection approach is trained solely on in-distribution samples while the weakly-supervised approach utilizes a tiny number of OOD samples to further enhance the detection performance in various OOD scenarios. Extensive experimental results demonstrate that our proposed methods significantly outperform the baselines in detecting OOD samples from four different scenarios simultaneously and also positively impact a main code understanding task.
<div id='section'>Paperid: <span id='pid'>938, <a href='https://arxiv.org/pdf/2502.18224.pdf' target='_blank'>https://arxiv.org/pdf/2502.18224.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eduardo Aguilar, Bogdan Raducanu, Petia Radeva
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18224">Multi-label out-of-distribution detection via evidential learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A crucial requirement for machine learning algorithms is not only to perform well, but also to show robustness and adaptability when encountering novel scenarios. One way to achieve these characteristics is to endow the deep learning models with the ability to detect out-of-distribution (OOD) data, i.e. data that belong to distributions different from the one used during their training. It is even a more complicated situation, when these data usually are multi-label. In this paper, we propose an approach based on evidential deep learning in order to meet these challenges applied to visual recognition problems. More concretely, we designed a CNN architecture that uses a Beta Evidential Neural Network to compute both the likelihood and the predictive uncertainty of the samples. Based on these results, we propose afterwards two new uncertainty-based scores for OOD data detection: (i) OOD - score Max, based on the maximum evidence; and (ii) OOD score - Sum, which considers the evidence from all outputs. Extensive experiments have been carried out to validate the proposed approach using three widely-used datasets: PASCAL-VOC, MS-COCO and NUS-WIDE, demonstrating its outperformance over several State-of-the-Art methods.
<div id='section'>Paperid: <span id='pid'>939, <a href='https://arxiv.org/pdf/2502.14003.pdf' target='_blank'>https://arxiv.org/pdf/2502.14003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryo Moriai, Nakamasa Inoue, Masayuki Tanaka, Rei Kawakami, Satoshi Ikehata, Ikuro Sato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14003">Rectified Lagrangian for Out-of-Distribution Detection in Modern Hopfield Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern Hopfield networks (MHNs) have recently gained significant attention in the field of artificial intelligence because they can store and retrieve a large set of patterns with an exponentially large memory capacity. A MHN is generally a dynamical system defined with Lagrangians of memory and feature neurons, where memories associated with in-distribution (ID) samples are represented by attractors in the feature space. One major problem in existing MHNs lies in managing out-of-distribution (OOD) samples because it was originally assumed that all samples are ID samples. To address this, we propose the rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that explicitly incorporates an attractor for OOD samples in the dynamical system of MHNs. RecLag creates a trivial point attractor for any interaction matrix, enabling OOD detection by identifying samples that fall into this attractor as OOD. The interaction matrix is optimized so that the probability densities can be estimated to identify ID/OOD. We demonstrate the effectiveness of RecLag-based MHNs compared to energy-based OOD detection methods, including those using state-of-the-art Hopfield energies, across nine image datasets.
<div id='section'>Paperid: <span id='pid'>940, <a href='https://arxiv.org/pdf/2502.03982.pdf' target='_blank'>https://arxiv.org/pdf/2502.03982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hannah Rosa Friesacher, Emma Svensson, Susanne Winiwarter, Lewis Mervin, Adam Arany, Ola Engkvist
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03982">Temporal Distribution Shift in Real-World Pharmaceutical Data: Implications for Uncertainty Quantification in QSAR Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The estimation of uncertainties associated with predictions from quantitative structure-activity relationship (QSAR) models can accelerate the drug discovery process by identifying promising experiments and allowing an efficient allocation of resources. Several computational tools exist that estimate the predictive uncertainty in machine learning models. However, deviations from the i.i.d. setting have been shown to impair the performance of these uncertainty quantification methods. We use a real-world pharmaceutical dataset to address the pressing need for a comprehensive, large-scale evaluation of uncertainty estimation methods in the context of realistic distribution shifts over time. We investigate the performance of several uncertainty estimation methods, including ensemble-based and Bayesian approaches. Furthermore, we use this real-world setting to systematically assess the distribution shifts in label and descriptor space and their impact on the capability of the uncertainty estimation methods. Our study reveals significant shifts over time in both label and descriptor space and a clear connection between the magnitude of the shift and the nature of the assay. Moreover, we show that pronounced distribution shifts impair the performance of popular uncertainty estimation methods used in QSAR models. This work highlights the challenges of identifying uncertainty quantification methods that remain reliable under distribution shifts introduced by real-world data.
<div id='section'>Paperid: <span id='pid'>941, <a href='https://arxiv.org/pdf/2501.17827.pdf' target='_blank'>https://arxiv.org/pdf/2501.17827.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haque Ishfaq, Guangyuan Wang, Sami Nur Islam, Doina Precup
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17827">Langevin Soft Actor-Critic: Efficient Exploration through Uncertainty-Driven Critic Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing actor-critic algorithms, which are popular for continuous control reinforcement learning (RL) tasks, suffer from poor sample efficiency due to lack of principled exploration mechanism within them. Motivated by the success of Thompson sampling for efficient exploration in RL, we propose a novel model-free RL algorithm, Langevin Soft Actor Critic (LSAC), which prioritizes enhancing critic learning through uncertainty estimation over policy optimization. LSAC employs three key innovations: approximate Thompson sampling through distributional Langevin Monte Carlo (LMC) based $Q$ updates, parallel tempering for exploring multiple modes of the posterior of the $Q$ function, and diffusion synthesized state-action samples regularized with $Q$ action gradients. Our extensive experiments demonstrate that LSAC outperforms or matches the performance of mainstream model-free RL algorithms for continuous control tasks. Notably, LSAC marks the first successful application of an LMC based Thompson sampling in continuous control tasks with continuous action spaces.
<div id='section'>Paperid: <span id='pid'>942, <a href='https://arxiv.org/pdf/2501.14741.pdf' target='_blank'>https://arxiv.org/pdf/2501.14741.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Denis Kleyko, Dmitri A. Rachkovskij
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14741">On Design Choices in Similarity-Preserving Sparse Randomized Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Expand & Sparsify is a principle that is observed in anatomically similar neural circuits found in the mushroom body (insects) and the cerebellum (mammals). Sensory data are projected randomly to much higher-dimensionality (expand part) where only few the most strongly excited neurons are activated (sparsify part). This principle has been leveraged to design a FlyHash algorithm that forms similarity-preserving sparse embeddings, which have been found useful for such tasks as novelty detection, pattern recognition, and similarity search. Despite its simplicity, FlyHash has a number of design choices to be set such as preprocessing of the input data, choice of sparsifying activation function, and formation of the random projection matrix. In this paper, we explore the effect of these choices on the performance of similarity search with FlyHash embeddings. We find that the right combination of design choices can lead to drastic difference in the search performance.
<div id='section'>Paperid: <span id='pid'>943, <a href='https://arxiv.org/pdf/2501.01525.pdf' target='_blank'>https://arxiv.org/pdf/2501.01525.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammadreza M. Kalan, Eitan J. Neugut, Samory Kpotufe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01525">Transfer Neyman-Pearson Algorithm for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of transfer learning in outlier detection where target abnormal data is rare. While transfer learning has been considered extensively in traditional balanced classification, the problem of transfer in outlier detection and more generally in imbalanced classification settings has received less attention. We propose a general meta-algorithm which is shown theoretically to yield strong guarantees w.r.t. to a range of changes in abnormal distribution, and at the same time amenable to practical implementation. We then investigate different instantiations of this general meta-algorithm, e.g., based on multi-layer neural networks, and show empirically that they outperform natural extensions of transfer methods for traditional balanced classification settings (which are the only solutions available at the moment).
<div id='section'>Paperid: <span id='pid'>944, <a href='https://arxiv.org/pdf/2412.12566.pdf' target='_blank'>https://arxiv.org/pdf/2412.12566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haonan Xu, Yang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12566">ITP: Instance-Aware Test Pruning for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring the reliable deployment of deep models in real-world scenarios. Recently, from the perspective of over-parameterization, a series of methods leveraging weight sparsification techniques have shown promising performance. These methods typically focus on selecting important parameters for in-distribution (ID) data to reduce the negative impact of redundant parameters on OOD detection. However, we empirically find that these selected parameters may behave overconfidently toward OOD data and hurt OOD detection. To address this issue, we propose a simple yet effective post-hoc method called Instance-aware Test Pruning (ITP), which performs OOD detection by considering both coarse-grained and fine-grained levels of parameter pruning. Specifically, ITP first estimates the class-specific parameter contribution distribution by exploring the ID data. By using the contribution distribution, ITP conducts coarse-grained pruning to eliminate redundant parameters. More importantly, ITP further adopts a fine-grained test pruning process based on the right-tailed Z-score test, which can adaptively remove instance-level overconfident parameters. Finally, ITP derives OOD scores from the pruned model to achieve more reliable predictions. Extensive experiments on widely adopted benchmarks verify the effectiveness of ITP, demonstrating its competitive performance.
<div id='section'>Paperid: <span id='pid'>945, <a href='https://arxiv.org/pdf/2412.00401.pdf' target='_blank'>https://arxiv.org/pdf/2412.00401.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Zhou, Marlen Neubert, Yuri Koide, Yumeng Zhang, Van-Quan Vuong, Tobias SchlÃ¶der, Stefanie Dehnen, Pascal Friederich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00401">PAL -- Parallel active learning for machine-learned potentials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing datasets representative of the target domain is essential for training effective machine learning models. Active learning (AL) is a promising method that iteratively extends training data to enhance model performance while minimizing data acquisition costs. However, current AL workflows often require human intervention and lack parallelism, leading to inefficiencies and underutilization of modern computational resources. In this work, we introduce PAL, an automated, modular, and parallel active learning library that integrates AL tasks and manages their execution and communication on shared- and distributed-memory systems using the Message Passing Interface (MPI). PAL provides users with the flexibility to design and customize all components of their active learning scenarios, including machine learning models with uncertainty estimation, oracles for ground truth labeling, and strategies for exploring the target space. We demonstrate that PAL significantly reduces computational overhead and improves scalability, achieving substantial speed-ups through asynchronous parallelization on CPU and GPU hardware. Applications of PAL to several real-world scenarios - including ground-state reactions in biomolecular systems, excited-state dynamics of molecules, simulations of inorganic clusters, and thermo-fluid dynamics - illustrate its effectiveness in accelerating the development of machine learning models. Our results show that PAL enables efficient utilization of high-performance computing resources in active learning workflows, fostering advancements in scientific research and engineering applications.
<div id='section'>Paperid: <span id='pid'>946, <a href='https://arxiv.org/pdf/2410.21712.pdf' target='_blank'>https://arxiv.org/pdf/2410.21712.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julien Pallage, Bertrand Scherrer, Salma Naccache, Christophe BÃ©langer, Antoine Lesage-Landry
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21712">Sliced-Wasserstein-based Anomaly Detection and Open Dataset for Localized Critical Peak Rebates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present a new unsupervised anomaly (outlier) detection (AD) method using the sliced-Wasserstein metric. This filtering technique is conceptually interesting for MLOps pipelines deploying machine learning models in critical sectors, e.g., energy, as it offers a conservative data selection. Additionally, we open the first dataset showcasing localized critical peak rebate demand response in a northern climate. We demonstrate the capabilities of our method on synthetic datasets as well as standard AD datasets and use it in the making of a first benchmark for our open-source localized critical peak rebate dataset.
<div id='section'>Paperid: <span id='pid'>947, <a href='https://arxiv.org/pdf/2410.20312.pdf' target='_blank'>https://arxiv.org/pdf/2410.20312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Zhang, Linjiajie Fang, Kexin Shi, Wenjia Wang, Bing-Yi Jing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20312">Q-Distribution guided Q-learning for offline reinforcement learning: Uncertainty penalized Q-value via consistency model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>``Distribution shift'' is the main obstacle to the success of offline reinforcement learning. A learning policy may take actions beyond the behavior policy's knowledge, referred to as Out-of-Distribution (OOD) actions. The Q-values for these OOD actions can be easily overestimated. As a result, the learning policy is biased by using incorrect Q-value estimates. One common approach to avoid Q-value overestimation is to make a pessimistic adjustment. Our key idea is to penalize the Q-values of OOD actions associated with high uncertainty. In this work, we propose Q-Distribution Guided Q-Learning (QDQ), which applies a pessimistic adjustment to Q-values in OOD regions based on uncertainty estimation. This uncertainty measure relies on the conditional Q-value distribution, learned through a high-fidelity and efficient consistency model. Additionally, to prevent overly conservative estimates, we introduce an uncertainty-aware optimization objective for updating the Q-value function. The proposed QDQ demonstrates solid theoretical guarantees for the accuracy of Q-value distribution learning and uncertainty measurement, as well as the performance of the learning policy. QDQ consistently shows strong performance on the D4RL benchmark and achieves significant improvements across many tasks.
<div id='section'>Paperid: <span id='pid'>948, <a href='https://arxiv.org/pdf/2410.07725.pdf' target='_blank'>https://arxiv.org/pdf/2410.07725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yonghang Zhou, Hongyi Zhu, Yidong Chai, Yuanchun Jiang, Yezheng Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07725">Towards Trustworthy Web Attack Detection: An Uncertainty-Aware Ensemble Deep Kernel Learning Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Web attacks are one of the major and most persistent forms of cyber threats, which bring huge costs and losses to web application-based businesses. Various detection methods, such as signature-based, machine learning-based, and deep learning-based, have been proposed to identify web attacks. However, these methods either (1) heavily rely on accurate and complete rule design and feature engineering, which may not adapt to fast-evolving attacks, or (2) fail to estimate model uncertainty, which is essential to the trustworthiness of the prediction made by the model. In this study, we proposed an Uncertainty-aware Ensemble Deep Kernel Learning (UEDKL) model to detect web attacks from HTTP request payload data with the model uncertainty captured from the perspective of both data distribution and model parameters. The proposed UEDKL utilizes a deep kernel learning model to distinguish normal HTTP requests from different types of web attacks with model uncertainty estimated from data distribution perspective. Multiple deep kernel learning models were trained as base learners to capture the model uncertainty from model parameters perspective. An attention-based ensemble learning approach was designed to effectively integrate base learners' predictions and model uncertainty. We also proposed a new metric named High Uncertainty Ratio-F Score Curve to evaluate model uncertainty estimation. Experiments on BDCI and SRBH datasets demonstrated that the proposed UEDKL framework yields significant improvement in both web attack detection performance and uncertainty estimation quality compared to benchmark models.
<div id='section'>Paperid: <span id='pid'>949, <a href='https://arxiv.org/pdf/2409.16305.pdf' target='_blank'>https://arxiv.org/pdf/2409.16305.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis Gustavo Gioacon Villani, Samuel da Silva, Americo Cunha, Michael D. Todd
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.16305">Damage detection in an uncertain nonlinear beam based on stochastic Volterra series: an experimental application</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The damage detection problem becomes a more difficult task when the intrinsically nonlinear behavior of the structures and the natural data variation are considered in the analysis because both phenomena can be confused with damage if linear and deterministic approaches are implemented. Therefore, this work aims the experimental application of a stochastic version of the Volterra series combined with a novelty detection approach to detect damage in an initially nonlinear system taking into account the measured data variation, caused by the presence of uncertainties. The experimental setup is composed by a cantilever beam operating in a nonlinear regime of motion, even in the healthy condition, induced by the presence of a magnet near to the free extremity. The damage associated with mass changes in a bolted connection (nuts loosed) is detected based on the comparison between linear and nonlinear contributions of the stochastic Volterra kernels in the total response, estimated in the reference and damaged conditions. The experimental measurements were performed on different days to add natural variation to the data measured. The results obtained through the stochastic proposed approach are compared with those obtained by the deterministic version of the Volterra series, showing the advantage of the stochastic model use when we consider the experimental data variation with the capability to detect the presence of the damage with statistical confidence. Besides, the nonlinear metric used presented a higher sensitivity to the occurrence of the damage compared with the linear one, justifying the application of a nonlinear metric when the system exhibits intrinsically nonlinear behavior.
<div id='section'>Paperid: <span id='pid'>950, <a href='https://arxiv.org/pdf/2409.10655.pdf' target='_blank'>https://arxiv.org/pdf/2409.10655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel FlÃ¶gel, Marcos GÃ³mez VillafaÃ±e, Joshua Ransiek, SÃ¶ren Hohmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10655">Disentangling Uncertainty for Safe Social Navigation using Deep Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous mobile robots are increasingly used in pedestrian-rich environments where safe navigation and appropriate human interaction are crucial. While Deep Reinforcement Learning (DRL) enables socially integrated robot behavior, challenges persist in novel or perturbed scenarios to indicate when and why the policy is uncertain. Unknown uncertainty in decision-making can lead to collisions or human discomfort and is one reason why safe and risk-aware navigation is still an open problem. This work introduces a novel approach that integrates aleatoric, epistemic, and predictive uncertainty estimation into a DRL navigation framework for policy distribution uncertainty estimates. We, therefore, incorporate Observation-Dependent Variance (ODV) and dropout into the Proximal Policy Optimization (PPO) algorithm. For different types of perturbations, we compare the ability of deep ensembles and Monte-Carlo dropout (MC-dropout) to estimate the uncertainties of the policy. In uncertain decision-making situations, we propose to change the robot's social behavior to conservative collision avoidance. The results show improved training performance with ODV and dropout in PPO and reveal that the training scenario has an impact on the generalization. In addition, MC-dropout is more sensitive to perturbations and correlates the uncertainty type to the perturbation better. With the safe action selection, the robot can navigate in perturbed environments with fewer collisions.
<div id='section'>Paperid: <span id='pid'>951, <a href='https://arxiv.org/pdf/2409.08636.pdf' target='_blank'>https://arxiv.org/pdf/2409.08636.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars BÃ¶cking, Leopold MÃ¼ller, Niklas KÃ¼hl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08636">Utilizing Data Fingerprints for Privacy-Preserving Algorithm Selection in Time Series Classification: Performance and Uncertainty Estimation on Unseen Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The selection of algorithms is a crucial step in designing AI services for real-world time series classification use cases. Traditional methods such as neural architecture search, automated machine learning, combined algorithm selection, and hyperparameter optimizations are effective but require considerable computational resources and necessitate access to all data points to run their optimizations. In this work, we introduce a novel data fingerprint that describes any time series classification dataset in a privacy-preserving manner and provides insight into the algorithm selection problem without requiring training on the (unseen) dataset. By decomposing the multi-target regression problem, only our data fingerprints are used to estimate algorithm performance and uncertainty in a scalable and adaptable manner. Our approach is evaluated on the 112 University of California riverside benchmark datasets, demonstrating its effectiveness in predicting the performance of 35 state-of-the-art algorithms and providing valuable insights for effective algorithm selection in time series classification service systems, improving a naive baseline by 7.32% on average in estimating the mean performance and 15.81% in estimating the uncertainty.
<div id='section'>Paperid: <span id='pid'>952, <a href='https://arxiv.org/pdf/2409.06270.pdf' target='_blank'>https://arxiv.org/pdf/2409.06270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mulin Chen, Haojian Huang, Qiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06270">Towards Robust Uncertainty-Aware Incomplete Multi-View Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Handling incomplete data in multi-view classification is challenging, especially when traditional imputation methods introduce biases that compromise uncertainty estimation. Existing Evidential Deep Learning (EDL) based approaches attempt to address these issues, but they often struggle with conflicting evidence due to the limitations of the Dempster-Shafer combination rule, leading to unreliable decisions. To address these challenges, we propose the Alternating Progressive Learning Network (APLN), specifically designed to enhance EDL-based methods in incomplete MVC scenarios. Our approach mitigates bias from corrupted observed data by first applying coarse imputation, followed by mapping the data to a latent space. In this latent space, we progressively learn an evidence distribution aligned with the target domain, incorporating uncertainty considerations through EDL. Additionally, we introduce a conflict-aware Dempster-Shafer combination rule (DSCR) to better handle conflicting evidence. By sampling from the learned distribution, we optimize the latent representations of missing views, reducing bias and enhancing decision-making robustness. Extensive experiments demonstrate that APLN, combined with DSCR, significantly outperforms traditional methods, particularly in environments characterized by high uncertainty and conflicting evidence, establishing it as a promising solution for incomplete multi-view classification.
<div id='section'>Paperid: <span id='pid'>953, <a href='https://arxiv.org/pdf/2409.04159.pdf' target='_blank'>https://arxiv.org/pdf/2409.04159.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Clemens Damke, Eyke HÃ¼llermeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04159">CUQ-GNN: Committee-based Graph Uncertainty Quantification using Posterior Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we study the influence of domain-specific characteristics when defining a meaningful notion of predictive uncertainty on graph data. Previously, the so-called Graph Posterior Network (GPN) model has been proposed to quantify uncertainty in node classification tasks. Given a graph, it uses Normalizing Flows (NFs) to estimate class densities for each node independently and converts those densities into Dirichlet pseudo-counts, which are then dispersed through the graph using the personalized Page-Rank algorithm. The architecture of GPNs is motivated by a set of three axioms on the properties of its uncertainty estimates. We show that those axioms are not always satisfied in practice and therefore propose the family of Committe-based Uncertainty Quantification Graph Neural Networks (CUQ-GNNs), which combine standard Graph Neural Networks with the NF-based uncertainty estimation of Posterior Networks (PostNets). This approach adapts more flexibly to domain-specific demands on the properties of uncertainty estimates. We compare CUQ-GNN against GPN and other uncertainty quantification approaches on common node classification benchmarks and show that it is effective at producing useful uncertainty estimates.
<div id='section'>Paperid: <span id='pid'>954, <a href='https://arxiv.org/pdf/2408.12355.pdf' target='_blank'>https://arxiv.org/pdf/2408.12355.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanyun Lu, Renshu Gu, Huimin Cheng, Siyu Pang, Mingyu Xu, Peifang Xu, Yaqi Wang, Yuichiro Kinoshita, Juan Ye, Gangyong Jia, Qing Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12355">Class-balanced Open-set Semi-supervised Object Detection for Medical Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical image datasets in the real world are often unlabeled and imbalanced, and Semi-Supervised Object Detection (SSOD) can utilize unlabeled data to improve an object detector. However, existing approaches predominantly assumed that the unlabeled data and test data do not contain out-of-distribution (OOD) classes. The few open-set semi-supervised object detection methods have two weaknesses: first, the class imbalance is not considered; second, the OOD instances are distinguished and simply discarded during pseudo-labeling. In this paper, we consider the open-set semi-supervised object detection problem which leverages unlabeled data that contain OOD classes to improve object detection for medical images. Our study incorporates two key innovations: Category Control Embed (CCE) and out-of-distribution Detection Fusion Classifier (OODFC). CCE is designed to tackle dataset imbalance by constructing a Foreground information Library, while OODFC tackles open-set challenges by integrating the ``unknown'' information into basic pseudo-labels. Our method outperforms the state-of-the-art SSOD performance, achieving a 4.25 mAP improvement on the public Parasite dataset.
<div id='section'>Paperid: <span id='pid'>955, <a href='https://arxiv.org/pdf/2407.15110.pdf' target='_blank'>https://arxiv.org/pdf/2407.15110.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxiang Yi, Ji Cheng, Miguel A. Bessa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15110">Practical multi-fidelity machine learning: fusion of deterministic and Bayesian models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-fidelity machine learning methods address the accuracy-efficiency trade-off by integrating scarce, resource-intensive high-fidelity data with abundant but less accurate low-fidelity data. We propose a practical multi-fidelity strategy for problems spanning low- and high-dimensional domains, integrating a non-probabilistic regression model for the low-fidelity with a Bayesian model for the high-fidelity. The models are trained in a staggered scheme, where the low-fidelity model is transfer-learned to the high-fidelity data and a Bayesian model is trained to learn the residual between the data and the transfer-learned model. This three-model strategy -- deterministic low-fidelity, transfer-learning, and Bayesian residual -- leads to a prediction that includes uncertainty quantification for noisy and noiseless multi-fidelity data. The strategy is general and unifies the topic, highlighting the expressivity trade-off between the transfer-learning and Bayesian models (a complex transfer-learning model leads to a simpler Bayesian model, and vice versa). We propose modeling choices for two scenarios, and argue in favor of using a linear transfer-learning model that fuses 1) kernel ridge regression for low-fidelity with Gaussian processes for high-fidelity; or 2) deep neural network for low-fidelity with a Bayesian neural network for high-fidelity. We demonstrate the effectiveness and efficiency of the proposed strategies and contrast them with the state-of-the-art based on various numerical examples and two engineering problems. The results indicate that the proposed approach achieves comparable performance in both mean and uncertainty estimation while significantly reducing training time for machine learning modeling in data-scarce scenarios. Moreover, in data-rich settings, it outperforms other multi-fidelity architectures by effectively mitigating overfitting.
<div id='section'>Paperid: <span id='pid'>956, <a href='https://arxiv.org/pdf/2407.14185.pdf' target='_blank'>https://arxiv.org/pdf/2407.14185.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hannah Rosa Friesacher, Ola Engkvist, Lewis Mervin, Yves Moreau, Adam Arany
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14185">Achieving Well-Informed Decision-Making in Drug Discovery: A Comprehensive Calibration Study using Neural Network-Based Structure-Activity Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the drug discovery process, where experiments can be costly and time-consuming, computational models that predict drug-target interactions are valuable tools to accelerate the development of new therapeutic agents. Estimating the uncertainty inherent in these neural network predictions provides valuable information that facilitates optimal decision-making when risk assessment is crucial. However, such models can be poorly calibrated, which results in unreliable uncertainty estimates that do not reflect the true predictive uncertainty. In this study, we compare different metrics, including accuracy and calibration scores, used for model hyperparameter tuning to investigate which model selection strategy achieves well-calibrated models. Furthermore, we propose to use a computationally efficient Bayesian uncertainty estimation method named Bayesian Linear Probing (BLP), which generates Hamiltonian Monte Carlo (HMC) trajectories to obtain samples for the parameters of a Bayesian Logistic Regression fitted to the hidden layer of the baseline neural network. We report that BLP improves model calibration and achieves the performance of common uncertainty quantification methods by combining the benefits of uncertainty estimation and probability calibration methods. Finally, we show that combining post hoc calibration method with well-performing uncertainty quantification approaches can boost model accuracy and calibration.
<div id='section'>Paperid: <span id='pid'>957, <a href='https://arxiv.org/pdf/2407.13392.pdf' target='_blank'>https://arxiv.org/pdf/2407.13392.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Judith Dijk, Gertjan Burghouts, Kapil D. Katyal, Bryanna Y. Yeh, Craig T. Knuth, Ella Fokkinga, Tejaswi Kasarla, Pascal Mettes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13392">Lightweight Uncertainty Quantification with Simplex Semantic Segmentation for Terrain Traversability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For navigation of robots, image segmentation is an important component to determining a terrain's traversability. For safe and efficient navigation, it is key to assess the uncertainty of the predicted segments. Current uncertainty estimation methods are limited to a specific choice of model architecture, are costly in terms of training time, require large memory for inference (ensembles), or involve complex model architectures (energy-based, hyperbolic, masking). In this paper, we propose a simple, light-weight module that can be connected to any pretrained image segmentation model, regardless of its architecture, with marginal additional computation cost because it reuses the model's backbone. Our module is based on maximum separation of the segmentation classes by respective prototype vectors. This optimizes the probability that out-of-distribution segments are projected in between the prototype vectors. The uncertainty value in the classification label is obtained from the distance to the nearest prototype. We demonstrate the effectiveness of our module for terrain segmentation.
<div id='section'>Paperid: <span id='pid'>958, <a href='https://arxiv.org/pdf/2406.01170.pdf' target='_blank'>https://arxiv.org/pdf/2406.01170.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Choubo Ding, Guansong Pang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01170">Zero-Shot Out-of-Distribution Detection with Outlier Label Exposure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As vision-language models like CLIP are widely applied to zero-shot tasks and gain remarkable performance on in-distribution (ID) data, detecting and rejecting out-of-distribution (OOD) inputs in the zero-shot setting have become crucial for ensuring the safety of using such models on the fly. Most existing zero-shot OOD detectors rely on ID class label-based prompts to guide CLIP in classifying ID images and rejecting OOD images. In this work we instead propose to leverage a large set of diverse auxiliary outlier class labels as pseudo OOD class text prompts to CLIP for enhancing zero-shot OOD detection, an approach we called Outlier Label Exposure (OLE). The key intuition is that ID images are expected to have lower similarity to these outlier class prompts than OOD images. One issue is that raw class labels often include noise labels, e.g., synonyms of ID labels, rendering raw OLE-based detection ineffective. To address this issue, we introduce an outlier prototype learning module that utilizes the prompt embeddings of the outlier labels to learn a small set of pivotal outlier prototypes for an embedding similarity-based OOD scoring. Additionally, the outlier classes and their prototypes can be loosely coupled with the ID classes, leading to an inseparable decision region between them. Thus, we also introduce an outlier label generation module that synthesizes our outlier prototypes and ID class embeddings to generate in-between outlier prototypes to further calibrate the detection in OLE. Despite its simplicity, extensive experiments show that OLE substantially improves detection performance and achieves new state-of-the-art performance in large-scale OOD and hard OOD detection benchmarks.
<div id='section'>Paperid: <span id='pid'>959, <a href='https://arxiv.org/pdf/2405.15991.pdf' target='_blank'>https://arxiv.org/pdf/2405.15991.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuesong Wang, He Zhao, Edwin V. Bonilla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15991">RÃ©nyi Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Processes (NPs) are deep probabilistic models that represent stochastic processes by conditioning their prior distributions on a set of context points. Despite their advantages in uncertainty estimation for complex distributions, NPs enforce parameterization coupling between the conditional prior model and the posterior model. We show that this coupling amounts to prior misspecification and revisit the NP objective to address this issue. More specifically, we propose RÃ©nyi Neural Processes (RNP), a method that replaces the standard KL divergence with the RÃ©nyi divergence, dampening the effects of the misspecified prior during posterior updates. We validate our approach across multiple benchmarks including regression and image inpainting tasks, and show significant performance improvements of RNPs in real-world problems. Our extensive experiments show consistently better log-likelihoods over state-of-the-art NP models.
<div id='section'>Paperid: <span id='pid'>960, <a href='https://arxiv.org/pdf/2405.13864.pdf' target='_blank'>https://arxiv.org/pdf/2405.13864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Konstantinos Pitas, Julyan Arbel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13864">Just rotate it! Uncertainty estimation in closed-source models via multiple queries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a simple and effective method to estimate the uncertainty of closed-source deep neural network image classification models. Given a base image, our method creates multiple transformed versions and uses them to query the top-1 prediction of the closed-source model. We demonstrate significant improvements in the calibration of uncertainty estimates compared to the naive baseline of assigning 100\% confidence to all predictions. While we initially explore Gaussian perturbations, our empirical findings indicate that natural transformations, such as rotations and elastic deformations, yield even better-calibrated predictions. Furthermore, through empirical results and a straightforward theoretical analysis, we elucidate the reasons behind the superior performance of natural transformations over Gaussian noise. Leveraging these insights, we propose a transfer learning approach that further improves our calibration results.
<div id='section'>Paperid: <span id='pid'>961, <a href='https://arxiv.org/pdf/2404.16954.pdf' target='_blank'>https://arxiv.org/pdf/2404.16954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harit Vishwakarma, Heguang Lin, Ramya Korlakai Vinayak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16954">Taming False Positives in Out-of-Distribution Detection with Human Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robustness to out-of-distribution (OOD) samples is crucial for safely deploying machine learning models in the open world. Recent works have focused on designing scoring functions to quantify OOD uncertainty. Setting appropriate thresholds for these scoring functions for OOD detection is challenging as OOD samples are often unavailable up front. Typically, thresholds are set to achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can lead to very high false positive rates (FPR), ranging from 60 to 96\%, as observed in the Open-OOD benchmark. In safety-critical real-life applications, e.g., medical diagnosis, controlling the FPR is essential when dealing with various OOD samples dynamically. To address these challenges, we propose a mathematically grounded OOD detection framework that leverages expert feedback to \emph{safely} update the threshold on the fly. We provide theoretical results showing that it is guaranteed to meet the FPR constraint at all times while minimizing the use of human feedback. Another key feature of our framework is that it can work with any scoring function for OOD uncertainty quantification. Empirical evaluation of our system on synthetic and benchmark OOD datasets shows that our method can maintain FPR at most $5\%$ while maximizing TPR.
<div id='section'>Paperid: <span id='pid'>962, <a href='https://arxiv.org/pdf/2404.13288.pdf' target='_blank'>https://arxiv.org/pdf/2404.13288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zirui Zang, Ahmad Amine, Rahul Mangharam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.13288">PoseINN: Realtime Visual-based Pose Regression and Localization with Invertible Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating ego-pose from cameras is an important problem in robotics with applications ranging from mobile robotics to augmented reality. While SOTA models are becoming increasingly accurate, they can still be unwieldy due to high computational costs. In this paper, we propose to solve the problem by using invertible neural networks (INN) to find the mapping between the latent space of images and poses for a given scene. Our model achieves similar performance to the SOTA while being faster to train and only requiring offline rendering of low-resolution synthetic data. By using normalizing flows, the proposed method also provides uncertainty estimation for the output. We also demonstrated the efficiency of this method by deploying the model on a mobile robot.
<div id='section'>Paperid: <span id='pid'>963, <a href='https://arxiv.org/pdf/2404.04456.pdf' target='_blank'>https://arxiv.org/pdf/2404.04456.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Asad, Ihsan Ullah, Ganesh Sistu, Michael G. Madden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04456">Beyond the Known: Adversarial Autoencoders in Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In novelty detection, the goal is to decide if a new data point should be categorized as an inlier or an outlier, given a training dataset that primarily captures the inlier distribution. Recent approaches typically use deep encoder and decoder network frameworks to derive a reconstruction error, and employ this error either to determine a novelty score, or as the basis for a one-class classifier. In this research, we use a similar framework but with a lightweight deep network, and we adopt a probabilistic score with reconstruction error. Our methodology calculates the probability of whether the sample comes from the inlier distribution or not. This work makes two key contributions. The first is that we compute the novelty probability by linearizing the manifold that holds the structure of the inlier distribution. This allows us to interpret how the probability is distributed and can be determined in relation to the local coordinates of the manifold tangent space. The second contribution is that we improve the training protocol for the network. Our results indicate that our approach is effective at learning the target class, and it outperforms recent state-of-the-art methods on several benchmark datasets.
<div id='section'>Paperid: <span id='pid'>964, <a href='https://arxiv.org/pdf/2403.14067.pdf' target='_blank'>https://arxiv.org/pdf/2403.14067.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Blanchet, Jiajin Li, Markus Pelger, Greg Zanotti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14067">Automatic Outlier Rectification via Optimal Transport</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel conceptual framework to detect outliers using optimal transport with a concave cost function. Conventional outlier detection approaches typically use a two-stage procedure: first, outliers are detected and removed, and then estimation is performed on the cleaned data. However, this approach does not inform outlier removal with the estimation task, leaving room for improvement. To address this limitation, we propose an automatic outlier rectification mechanism that integrates rectification and estimation within a joint optimization framework. We take the first step to utilize the optimal transport distance with a concave cost function to construct a rectification set in the space of probability distributions. Then, we select the best distribution within the rectification set to perform the estimation task. Notably, the concave cost function we introduced in this paper is the key to making our estimator effectively identify the outlier during the optimization process. We demonstrate the effectiveness of our approach over conventional approaches in simulations and empirical analyses for mean estimation, least absolute regression, and the fitting of option implied volatility surfaces.
<div id='section'>Paperid: <span id='pid'>965, <a href='https://arxiv.org/pdf/2403.11418.pdf' target='_blank'>https://arxiv.org/pdf/2403.11418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jurijs Nazarovs, Zhichun Huang, Xingjian Zhen, Sourav Pal, Rudrasis Chakraborty, Vikas Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11418">Variational Sampling of Temporal Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A deterministic temporal process can be determined by its trajectory, an element in the product space of (a) initial condition $z_0 \in \mathcal{Z}$ and (b) transition function $f: (\mathcal{Z}, \mathcal{T}) \to \mathcal{Z}$ often influenced by the control of the underlying dynamical system. Existing methods often model the transition function as a differential equation or as a recurrent neural network. Despite their effectiveness in predicting future measurements, few results have successfully established a method for sampling and statistical inference of trajectories using neural networks, partially due to constraints in the parameterization. In this work, we introduce a mechanism to learn the distribution of trajectories by parameterizing the transition function $f$ explicitly as an element in a function space. Our framework allows efficient synthesis of novel trajectories, while also directly providing a convenient tool for inference, i.e., uncertainty estimation, likelihood evaluations and out of distribution detection for abnormal trajectories. These capabilities can have implications for various downstream tasks, e.g., simulation and evaluation for reinforcement learning.
<div id='section'>Paperid: <span id='pid'>966, <a href='https://arxiv.org/pdf/2403.10168.pdf' target='_blank'>https://arxiv.org/pdf/2403.10168.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arthur Thuy, Dries F. Benoit
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10168">Explainability through uncertainty: Trustworthy decision-making with neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty is a key feature of any machine learning model and is particularly important in neural networks, which tend to be overconfident. This overconfidence is worrying under distribution shifts, where the model performance silently degrades as the data distribution diverges from the training data distribution. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Although methods for uncertainty estimation have been developed, they have not been explicitly linked to the field of explainable artificial intelligence (XAI). Furthermore, literature in operations research ignores the actionability component of uncertainty estimation and does not consider distribution shifts. This work proposes a general uncertainty framework, with contributions being threefold: (i) uncertainty estimation in ML models is positioned as an XAI technique, giving local and model-specific explanations; (ii) classification with rejection is used to reduce misclassifications by bringing a human expert in the loop for uncertain observations; (iii) the framework is applied to a case study on neural networks in educational data mining subject to distribution shifts. Uncertainty as XAI improves the model's trustworthiness in downstream decision-making tasks, giving rise to more actionable and robust machine learning systems in operations research.
<div id='section'>Paperid: <span id='pid'>967, <a href='https://arxiv.org/pdf/2403.01485.pdf' target='_blank'>https://arxiv.org/pdf/2403.01485.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sam Dauncey, Chris Holmes, Christopher Williams, Fabian Falck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01485">Approximations to the Fisher Information Metric of Deep Generative Models for Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Likelihood-based deep generative models such as score-based diffusion models and variational autoencoders are state-of-the-art machine learning models approximating high-dimensional distributions of data such as images, text, or audio. One of many downstream tasks they can be naturally applied to is out-of-distribution (OOD) detection. However, seminal work by Nalisnick et al. which we reproduce showed that deep generative models consistently infer higher log-likelihoods for OOD data than data they were trained on, marking an open problem. In this work, we analyse using the gradient of a data point with respect to the parameters of the deep generative model for OOD detection, based on the simple intuition that OOD data should have larger gradient norms than training data. We formalise measuring the size of the gradient as approximating the Fisher information metric. We show that the Fisher information matrix (FIM) has large absolute diagonal values, motivating the use of chi-square distributed, layer-wise gradient norms as features. We combine these features to make a simple, model-agnostic and hyperparameter-free method for OOD detection which estimates the joint density of the layer-wise gradient norms for a given data point. We find that these layer-wise gradient norms are weakly correlated, rendering their combined usage informative, and prove that the layer-wise gradient norms satisfy the principle of (data representation) invariance. Our empirical results indicate that this method outperforms the Typicality test for most deep generative models and image dataset pairings.
<div id='section'>Paperid: <span id='pid'>968, <a href='https://arxiv.org/pdf/2402.08088.pdf' target='_blank'>https://arxiv.org/pdf/2402.08088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ghada Zamzmi, Kesavan Venkatesh, Brandon Nelson, Smriti Prathapan, Paul H. Yi, Berkman Sahiner, Jana G. Delfino
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08088">Out-of-Distribution Detection and Data Drift Monitoring using Statistical Process Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Machine learning (ML) methods often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices in clinical settings, where data drift may cause unexpected performance that jeopardizes patient safety.
  Method: We propose a ML-enabled Statistical Process Control (SPC) framework for out-of-distribution (OOD) detection and drift monitoring. SPC is advantageous as it visually and statistically highlights deviations from the expected distribution. To demonstrate the utility of the proposed framework for monitoring data drift in radiological images, we investigated different design choices, including methods for extracting feature representations, drift quantification, and SPC parameter selection.
  Results: We demonstrate the effectiveness of our framework for two tasks: 1) differentiating axial vs. non-axial computed tomography (CT) images and 2) separating chest x-ray (CXR) from other modalities. For both tasks, we achieved high accuracy in detecting OOD inputs, with 0.913 in CT and 0.995 in CXR, and sensitivity of 0.980 in CT and 0.984 in CXR. Our framework was also adept at monitoring data streams and identifying the time a drift occurred. In a simulation with 100 daily CXR cases, we detected a drift in OOD input percentage from 0-1% to 3-5% within two days, maintaining a low false-positive rate. Through additional experimental results, we demonstrate the framework's data-agnostic nature and independence from the underlying model's structure.
  Conclusion: We propose a framework for OOD detection and drift monitoring that is agnostic to data, modality, and model. The framework is customizable and can be adapted for specific applications.
<div id='section'>Paperid: <span id='pid'>969, <a href='https://arxiv.org/pdf/2402.00396.pdf' target='_blank'>https://arxiv.org/pdf/2402.00396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vikranth Dwaracherla, Seyed Mohammad Asghari, Botao Hao, Benjamin Van Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00396">Efficient Exploration for LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present evidence of substantial benefit from efficient exploration in gathering human feedback to improve large language models. In our experiments, an agent sequentially generates queries while fitting a reward model to the feedback received. Our best-performing agent generates queries using double Thompson sampling, with uncertainty represented by an epistemic neural network. Our results demonstrate that efficient exploration enables high levels of performance with far fewer queries. Further, both uncertainty estimation and the choice of exploration scheme play critical roles.
<div id='section'>Paperid: <span id='pid'>970, <a href='https://arxiv.org/pdf/2401.10288.pdf' target='_blank'>https://arxiv.org/pdf/2401.10288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunju Kim, Dongman Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.10288">Self-supervised New Activity Detection in Sensor-based Smart Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rapid advancement of ubiquitous computing technology, human activity analysis based on time series data from a diverse range of sensors enables the delivery of more intelligent services. Despite the importance of exploring new activities in real-world scenarios, existing human activity recognition studies generally rely on predefined known activities and often overlook detecting new patterns (novelties) that have not been previously observed during training. Novelty detection in human activities becomes even more challenging due to (1) diversity of patterns within the same known activity, (2) shared patterns between known and new activities, and (3) differences in sensor properties of each activity dataset. We introduce CLAN, a two-tower model that leverages Contrastive Learning with diverse data Augmentation for New activity detection in sensor-based environments. CLAN simultaneously and explicitly utilizes multiple types of strongly shifted data as negative samples in contrastive learning, effectively learning invariant representations that adapt to various pattern variations within the same activity. To enhance the ability to distinguish between known and new activities that share common features, CLAN incorporates both time and frequency domains, enabling the learning of multi-faceted discriminative representations. Additionally, we design an automatic selection mechanism of data augmentation methods tailored to each dataset's properties, generating appropriate positive and negative pairs for contrastive learning. Comprehensive experiments on real-world datasets show that CLAN achieves a 9.24% improvement in AUROC compared to the best-performing baseline model.
<div id='section'>Paperid: <span id='pid'>971, <a href='https://arxiv.org/pdf/2512.20797.pdf' target='_blank'>https://arxiv.org/pdf/2512.20797.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haizhou Yang, Jiyang Zhang, Brahmajee K. Nallamothu, Krishna Garikipati, C. Alberto Figueroa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.20797">Assessing Coronary Microvascular Dysfunction using Angiography-based Data-driven Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coronary microvascular dysfunction (CMD), characterized by impaired regulation of blood flow in the coronary microcirculation, plays a key role in the pathogenesis of ischemic heart disease and is increasingly recognized as a contributor to adverse cardiovascular outcomes. Despite its clinical importance, CMD remains underdiagnosed due to the reliance on invasive procedures such as pressure wire-based measurements of the index of microcirculatory resistance (IMR) and coronary flow reserve (CFR), which are costly, time-consuming, and carry procedural risks. To date, no study has sought to quantify CMD indices using data-driven approaches while leveraging the rich information contained in coronary angiograms. To address these limitations, this study proposes a novel data-driven framework for inference of CMD indices based on coronary angiography. A physiologically validated multi-physics model was used to generate synthetic datasets for data-driven model training, consisting of CMD indices and computational angiograms with corresponding contrast intensity profiles (CIPs). Two neural network architectures were developed: a single-input-channel encoder-MLP model for IMR prediction and a dual-input-channel encoder-MLP model for CFR prediction, both incorporating epistemic uncertainty estimation to quantify prediction confidence. Results demonstrate that the data-driven models achieve high predictive accuracy when evaluated against physics-based synthetic datasets, and that the uncertainty estimates are positively correlated with prediction errors. Furthermore, the utility of CIPs as informative surrogates for coronary physiology is demonstrated, underscoring the potential of the proposed framework to enable accurate, real-time, image-based CMD assessment using routine angiography without the need for more invasive approaches.
<div id='section'>Paperid: <span id='pid'>972, <a href='https://arxiv.org/pdf/2512.18977.pdf' target='_blank'>https://arxiv.org/pdf/2512.18977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Baiyang Chen, Zhong Yuan, Dezhong Peng, Xiaoliang Chen, Hongmei Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.18977">Consistency-guided semi-supervised outlier detection in heterogeneous data using fuzzy rough sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection aims to find samples that behave differently from the majority of the data. Semi-supervised detection methods can utilize the supervision of partial labels, thus reducing false positive rates. However, most of the current semi-supervised methods focus on numerical data and neglect the heterogeneity of data information. In this paper, we propose a consistency-guided outlier detection algorithm (COD) for heterogeneous data with the fuzzy rough set theory in a semi-supervised manner. First, a few labeled outliers are leveraged to construct label-informed fuzzy similarity relations. Next, the consistency of the fuzzy decision system is introduced to evaluate attributes' contributions to knowledge classification. Subsequently, we define the outlier factor based on the fuzzy similarity class and predict outliers by integrating the classification consistency and the outlier factor. The proposed algorithm is extensively evaluated on 15 freshly proposed datasets. Experimental results demonstrate that COD is better than or comparable with the leading outlier detectors. This manuscript is the accepted author version of a paper published by Elsevier. The final published version is available at https://doi.org/10.1016/j.asoc.2024.112070
<div id='section'>Paperid: <span id='pid'>973, <a href='https://arxiv.org/pdf/2512.18774.pdf' target='_blank'>https://arxiv.org/pdf/2512.18774.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Baiyang Chen, Zhong Yuan, Dezhong Peng, Hongmei Chen, Xiaomin Song, Huiming Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.18774">Label-Informed Outlier Detection Based on Granule Density</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection, crucial for identifying unusual patterns with significant implications across numerous applications, has drawn considerable research interest. Existing semi-supervised methods typically treat data as purely numerical and} in a deterministic manner, thereby neglecting the heterogeneity and uncertainty inherent in complex, real-world datasets. This paper introduces a label-informed outlier detection method for heterogeneous data based on Granular Computing and Fuzzy Sets, namely Granule Density-based Outlier Factor (GDOF). Specifically, GDOF first employs label-informed fuzzy granulation to effectively represent various data types and develops granule density for precise density estimation. Subsequently, granule densities from individual attributes are integrated for outlier scoring by assessing attribute relevance with a limited number of labeled outliers. Experimental results on various real-world datasets show that GDOF stands out in detecting outliers in heterogeneous data with a minimal number of labeled outliers. The integration of Fuzzy Sets and Granular Computing in GDOF offers a practical framework for outlier detection in complex and diverse data types. All relevant datasets and source codes are publicly available for further research. This is the author's accepted manuscript of a paper published in IEEE Transactions on Fuzzy Systems. The final version is available at https://doi.org/10.1109/TFUZZ.2024.3514853
<div id='section'>Paperid: <span id='pid'>974, <a href='https://arxiv.org/pdf/2512.07041.pdf' target='_blank'>https://arxiv.org/pdf/2512.07041.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hiroki Sawada, Alexandre Pitti, Mathias Quoy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.07041">CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robots interacting with humans must not only generate learned movements in real-time, but also infer the intent behind observed behaviors and estimate the confidence of their own inferences. This paper proposes a unified model that achieves all three capabilities within a single hierarchical predictive-coding recurrent neural network (PC-RNN) equipped with a class embedding vector, CERNet, which leverages a dynamically updated class embedding vector to unify motor generation and recognition. The model operates in two modes: generation and inference. In the generation mode, the class embedding constrains the hidden state dynamics to a class-specific subspace; in the inference mode, it is optimized online to minimize prediction error, enabling real-time recognition. Validated on a humanoid robot across 26 kinesthetically taught alphabets, our hierarchical model achieves 76% lower trajectory reproduction error than a parameter-matched single-layer baseline, maintains motion fidelity under external perturbations, and infers the demonstrated trajectory class online with 68% Top-1 and 81% Top-2 accuracy. Furthermore, internal prediction errors naturally reflect the model's confidence in its recognition. This integration of robust generation, real-time recognition, and intrinsic uncertainty estimation within a compact PC-RNN framework offers a compact and extensible approach to motor memory in physical robots, with potential applications in intent-sensitive human-robot collaboration.
<div id='section'>Paperid: <span id='pid'>975, <a href='https://arxiv.org/pdf/2512.05791.pdf' target='_blank'>https://arxiv.org/pdf/2512.05791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moritz Blumenthal, Tina Holliber, Jonathan I. Tamir, Martin Uecker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.05791">Fast and Robust Diffusion Posterior Sampling for MR Image Reconstruction Using the Preconditioned Unadjusted Langevin Algorithm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose: The Unadjusted Langevin Algorithm (ULA) in combination with diffusion models can generate high quality MRI reconstructions with uncertainty estimation from highly undersampled k-space data. However, sampling methods such as diffusion posterior sampling or likelihood annealing suffer from long reconstruction times and the need for parameter tuning. The purpose of this work is to develop a robust sampling algorithm with fast convergence. Theory and Methods: In the reverse diffusion process used for sampling the posterior, the exact likelihood is multiplied with the diffused prior at all noise scales. To overcome the issue of slow convergence, preconditioning is used. The method is trained on fastMRI data and tested on retrospectively undersampled brain data of a healthy volunteer. Results: For posterior sampling in Cartesian and non-Cartesian accelerated MRI the new approach outperforms annealed sampling in terms of reconstruction speed and sample quality. Conclusion: The proposed exact likelihood with preconditioning enables rapid and reliable posterior sampling across various MRI reconstruction tasks without the need for parameter tuning.
<div id='section'>Paperid: <span id='pid'>976, <a href='https://arxiv.org/pdf/2511.19996.pdf' target='_blank'>https://arxiv.org/pdf/2511.19996.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dishanika Denipitiyage, Naveen Karunanayake, Suranga Seneviratne, Sanjay Chawla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.19996">RankOOD -- Class Ranking-based Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose RankOOD, a rank-based Out-of-Distribution (OOD) detection approach based on training a model with the Placket-Luce loss, which is now extensively used for preference alignment tasks in foundational models. Our approach is based on the insight that with a deep learning model trained using the Cross Entropy Loss, in-distribution (ID) class prediction induces a ranking pattern for each ID class prediction. The RankOOD framework formalizes the insight by first extracting a rank list for each class using an initial classifier and then uses another round of training with the Plackett-Luce loss, where the class rank, a fixed permutation for each class, is the predicted variable. An OOD example may get assigned with high probability to an ID example, but the probability of it respecting the ranking classification is likely to be small. RankOOD, achieves SOTA performance on the near-ODD TinyImageNet evaluation benchmark, reducing FPR95 by 4.3%.
<div id='section'>Paperid: <span id='pid'>977, <a href='https://arxiv.org/pdf/2511.17636.pdf' target='_blank'>https://arxiv.org/pdf/2511.17636.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijun Gao, Rundong He, Jinyang Dong, Yongshun Gong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.17636">TSRE: Channel-Aware Typical Set Refinement for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is a critical capability for ensuring the safe deployment of machine learning models in open-world environments, where unexpected or anomalous inputs can compromise model reliability and performance. Activation-based methods play a fundamental role in OOD detection by mitigating anomalous activations and enhancing the separation between in-distribution (ID) and OOD data. However, existing methods apply activation rectification while often overlooking channel's intrinsic characteristics and distributional skewness, which results in inaccurate typical set estimation. This discrepancy can lead to the improper inclusion of anomalous activations across channels. To address this limitation, we propose a typical set refinement method based on discriminability and activity, which rectifies activations into a channel-aware typical set. Furthermore, we introduce a skewness-based refinement to mitigate distributional bias in typical set estimation. Finally, we leverage the rectified activations to compute the energy score for OOD detection. Experiments on the ImageNet-1K and CIFAR-100 benchmarks demonstrate that our method achieves state-of-the-art performance and generalizes effectively across backbones and score functions.
<div id='section'>Paperid: <span id='pid'>978, <a href='https://arxiv.org/pdf/2511.16427.pdf' target='_blank'>https://arxiv.org/pdf/2511.16427.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Aslanimoghanloo, Ahmed ElGazzar, Marcel van Gerven
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.16427">Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clinical time series data from electronic health records and medical registries offer unprecedented opportunities to understand patient trajectories and inform medical decision-making. However, leveraging such data presents significant challenges due to irregular sampling, complex latent physiology, and inherent uncertainties in both measurements and disease progression. To address these challenges, we propose a generative modeling framework based on latent neural stochastic differential equations (SDEs) that views clinical time series as discrete-time partial observations of an underlying controlled stochastic dynamical system. Our approach models latent dynamics via neural SDEs with modality-dependent emission models, while performing state estimation and parameter learning through variational inference. This formulation naturally handles irregularly sampled observations, learns complex non-linear interactions, and captures the stochasticity of disease progression and measurement noise within a unified scalable probabilistic framework. We validate the framework on two complementary tasks: (i) individual treatment effect estimation using a simulated pharmacokinetic-pharmacodynamic (PKPD) model of lung cancer, and (ii) probabilistic forecasting of physiological signals using real-world intensive care unit (ICU) data from 12,000 patients. Results show that our framework outperforms ordinary differential equation and long short-term memory baseline models in accuracy and uncertainty estimation. These results highlight its potential for enabling precise, uncertainty-aware predictions to support clinical decision-making.
<div id='section'>Paperid: <span id='pid'>979, <a href='https://arxiv.org/pdf/2511.13539.pdf' target='_blank'>https://arxiv.org/pdf/2511.13539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanchao Wang, Tian Qin, Eduardo Valle, Bruno Abrahao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.13539">BootOOD: Self-Supervised Out-of-Distribution Detection via Synthetic Sample Exposure under Neural Collapse</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical for deploying image classifiers in safety-sensitive environments, yet existing detectors often struggle when OOD samples are semantically similar to the in-distribution (ID) classes. We present BootOOD, a fully self-supervised OOD detection framework that bootstraps exclusively from ID data and is explicitly designed to handle semantically challenging OOD samples. BootOOD synthesizes pseudo-OOD features through simple transformations of ID representations and leverages Neural Collapse (NC), where ID features cluster tightly around class means with consistent feature norms. Unlike prior approaches that aim to constrain OOD features into subspaces orthogonal to the collapsed ID means, BootOOD introduces a lightweight auxiliary head that performs radius-based classification on feature norms. This design decouples OOD detection from the primary classifier and imposes a relaxed requirement: OOD samples are learned to have smaller feature norms than ID features, which is easier to satisfy when ID and OOD are semantically close. Experiments on CIFAR-10, CIFAR-100, and ImageNet-200 show that BootOOD outperforms prior post-hoc methods, surpasses training-based methods without outlier exposure, and is competitive with state-of-the-art outlier-exposure approaches while maintaining or improving ID accuracy.
<div id='section'>Paperid: <span id='pid'>980, <a href='https://arxiv.org/pdf/2511.09397.pdf' target='_blank'>https://arxiv.org/pdf/2511.09397.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haiyi Li, Qi Chen, Denis Kalkofen, Hsiang-Ting Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.09397">OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in 3D Gaussian Splatting (3DGS) have achieved state-of-the-art results for novel view synthesis. However, efficiently capturing high-fidelity reconstructions of specific objects within complex scenes remains a significant challenge. A key limitation of existing active reconstruction methods is their reliance on scene-level uncertainty metrics, which are often biased by irrelevant background clutter and lead to inefficient view selection for object-centric tasks. We present OUGS, a novel framework that addresses this challenge with a more principled, physically-grounded uncertainty formulation for 3DGS. Our core innovation is to derive uncertainty directly from the explicit physical parameters of the 3D Gaussian primitives (e.g., position, scale, rotation). By propagating the covariance of these parameters through the rendering Jacobian, we establish a highly interpretable uncertainty model. This foundation allows us to then seamlessly integrate semantic segmentation masks to produce a targeted, object-aware uncertainty score that effectively disentangles the object from its environment. This allows for a more effective active view selection strategy that prioritizes views critical to improving object fidelity. Experimental evaluations on public datasets demonstrate that our approach significantly improves the efficiency of the 3DGS reconstruction process and achieves higher quality for targeted objects compared to existing state-of-the-art methods, while also serving as a robust uncertainty estimator for the global scene.
<div id='section'>Paperid: <span id='pid'>981, <a href='https://arxiv.org/pdf/2511.05582.pdf' target='_blank'>https://arxiv.org/pdf/2511.05582.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gaoxiang Zhao, Ruina Qiu, Pengpeng Zhao, Rongjin Wang, Zhangang Lin, Xiaoqiang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.05582">Distillation-Accelerated Uncertainty Modeling for Multi-Objective RTA Interception</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-Time Auction (RTA) Interception aims to filter out invalid or irrelevant traffic to enhance the integrity and reliability of downstream data. However, two key challenges remain: (i) the need for accurate estimation of traffic quality together with sufficiently high confidence in the model's predictions, typically addressed through uncertainty modeling, and (ii) the efficiency bottlenecks that such uncertainty modeling introduces in real-time applications due to repeated inference. To address these challenges, we propose DAUM, a joint modeling framework that integrates multi-objective learning with uncertainty modeling, yielding both traffic quality predictions and reliable confidence estimates. Building on DAUM, we further apply knowledge distillation to reduce the computational overhead of uncertainty modeling, while largely preserving predictive accuracy and retaining the benefits of uncertainty estimation. Experiments on the JD advertisement dataset demonstrate that DAUM consistently improves predictive performance, with the distilled model delivering a tenfold increase in inference speed.
<div id='section'>Paperid: <span id='pid'>982, <a href='https://arxiv.org/pdf/2510.13643.pdf' target='_blank'>https://arxiv.org/pdf/2510.13643.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akib Mohammed Khan, Bartosz Krawczyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.13643">Towards Adversarial Robustness and Uncertainty Quantification in DINOv2-based Few-Shot Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models such as DINOv2 have shown strong performance in few-shot anomaly detection, yet two key questions remain unexamined: (i) how susceptible are these detectors to adversarial perturbations; and (ii) how well do their anomaly scores reflect calibrated uncertainty? Building on AnomalyDINO, a training-free deep nearest-neighbor detector over DINOv2 features, we present one of the first systematic studies of adversarial attacks and uncertainty estimation in this setting. To enable white-box gradient attacks while preserving test-time behavior, we attach a lightweight linear head to frozen DINOv2 features only for crafting perturbations. Using this heuristic, we evaluate the impact of FGSM across the MVTec-AD and VisA datasets and observe consistent drops in F1, AUROC, AP, and G-mean, indicating that imperceptible perturbations can flip nearest-neighbor relations in feature space to induce confident misclassification. Complementing robustness, we probe reliability and find that raw anomaly scores are poorly calibrated, revealing a gap between confidence and correctness that limits safety-critical use. As a simple, strong baseline toward trustworthiness, we apply post-hoc Platt scaling to the anomaly scores for uncertainty estimation. The resulting calibrated posteriors yield significantly higher predictive entropy on adversarially perturbed inputs than on clean ones, enabling a practical flagging mechanism for attack detection while reducing calibration error (ECE). Our findings surface concrete vulnerabilities in DINOv2-based few-shot anomaly detectors and establish an evaluation protocol and baseline for robust, uncertainty-aware anomaly detection. We argue that adversarial robustness and principled uncertainty quantification are not optional add-ons but essential capabilities if anomaly detection systems are to be trustworthy and ready for real-world deployment.
<div id='section'>Paperid: <span id='pid'>983, <a href='https://arxiv.org/pdf/2510.12967.pdf' target='_blank'>https://arxiv.org/pdf/2510.12967.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Athyrson Machado Ribeiro, Marcos Medeiros Raimundo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.12967">Balancing Performance and Reject Inclusion: A Novel Confident Inlier Extrapolation Framework for Credit Scoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reject Inference (RI) methods aim to address sample bias by inferring missing repayment data for rejected credit applicants. Traditional approaches often assume that the behavior of rejected clients can be extrapolated from accepted clients, despite potential distributional differences between the two populations. To mitigate this blind extrapolation, we propose a novel Confident Inlier Extrapolation framework (CI-EX). CI-EX iteratively identifies the distribution of rejected client samples using an outlier detection model and assigns labels to rejected individuals closest to the distribution of the accepted population based on probabilities derived from a supervised classification model. The effectiveness of our proposed framework is validated through experiments on two large real-world credit datasets. Performance is evaluated using the Area Under the Curve (AUC) as well as RI-specific metrics such as Kickout and a novel metric introduced in this work, denoted as Area under the Kickout. Our findings reveal that RI methods, including the proposed framework, generally involve a trade-off between AUC and RI-specific metrics. However, the proposed CI-EX framework consistently outperforms existing RI models from the credit literature in terms of RI-specific metrics while maintaining competitive performance in AUC across most experiments.
<div id='section'>Paperid: <span id='pid'>984, <a href='https://arxiv.org/pdf/2510.12713.pdf' target='_blank'>https://arxiv.org/pdf/2510.12713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wissam Salhab, Darine Ameyed, Hamid Mcheick, Fehmi Jaafar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.12713">Towards Robust Artificial Intelligence: Self-Supervised Learning Approach for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robustness in AI systems refers to their ability to maintain reliable and accurate performance under various conditions, including out-of-distribution (OOD) samples, adversarial attacks, and environmental changes. This is crucial in safety-critical systems, such as autonomous vehicles, transportation, or healthcare, where malfunctions could have severe consequences. This paper proposes an approach to improve OOD detection without the need of labeled data, thereby increasing the AI systems' robustness. The proposed approach leverages the principles of self-supervised learning, allowing the model to learn useful representations from unlabeled data. Combined with graph-theoretical techniques, this enables the more efficient identification and categorization of OOD samples. Compared to existing state-of-the-art methods, this approach achieved an Area Under the Receiver Operating Characteristic Curve (AUROC) = 0.99.
<div id='section'>Paperid: <span id='pid'>985, <a href='https://arxiv.org/pdf/2508.20066.pdf' target='_blank'>https://arxiv.org/pdf/2508.20066.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheng Li, Yanming Guo, WenZhe Liu, Xueyi Zhang, Zhaoyun Ding, Long Xu, Mingrui Lao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20066">PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cross-view geo-localization is a critical task for UAV navigation, event detection, and aerial surveying, as it enables matching between drone-captured and satellite imagery. Most existing approaches embed multi-modal data into a joint feature space to maximize the similarity of paired images. However, these methods typically assume perfect alignment of image pairs during training, which rarely holds true in real-world scenarios. In practice, factors such as urban canyon effects, electromagnetic interference, and adverse weather frequently induce GPS drift, resulting in systematic alignment shifts where only partial correspondences exist between pairs. Despite its prevalence, this source of noisy correspondence has received limited attention in current research. In this paper, we formally introduce and address the Noisy Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to bridge the gap between idealized benchmarks and practical applications. To this end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a novel framework that partitions and augments training data based on estimated data uncertainty through uncertainty-aware co-augmentation and evidential co-training. Specifically, PAUL selectively augments regions with high correspondence confidence and utilizes uncertainty estimation to refine feature learning, effectively suppressing noise from misaligned pairs. Distinct from traditional filtering or label correction, PAUL leverages both data uncertainty and loss discrepancy for targeted partitioning and augmentation, thus providing robust supervision for noisy samples. Comprehensive experiments validate the effectiveness of individual components in PAUL,which consistently achieves superior performance over other competitive noisy-correspondence-driven methods in various noise ratios.
<div id='section'>Paperid: <span id='pid'>986, <a href='https://arxiv.org/pdf/2508.18188.pdf' target='_blank'>https://arxiv.org/pdf/2508.18188.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Neo Christopher Chung, Jakub Binda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18188">Explain and Monitor Deep Learning Models for Computer Vision using Obz AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has transformed computer vision (CV), achieving outstanding performance in classification, segmentation, and related tasks. Such AI-based CV systems are becoming prevalent, with applications spanning from medical imaging to surveillance. State of the art models such as convolutional neural networks (CNNs) and vision transformers (ViTs) are often regarded as ``black boxes,'' offering limited transparency into their decision-making processes. Despite a recent advancement in explainable AI (XAI), explainability remains underutilized in practical CV deployments. A primary obstacle is the absence of integrated software solutions that connect XAI techniques with robust knowledge management and monitoring frameworks. To close this gap, we have developed Obz AI, a comprehensive software ecosystem designed to facilitate state-of-the-art explainability and observability for vision AI systems. Obz AI provides a seamless integration pipeline, from a Python client library to a full-stack analytics dashboard. With Obz AI, a machine learning engineer can easily incorporate advanced XAI methodologies, extract and analyze features for outlier detection, and continuously monitor AI models in real time. By making the decision-making mechanisms of deep models interpretable, Obz AI promotes observability and responsible deployment of computer vision systems.
<div id='section'>Paperid: <span id='pid'>987, <a href='https://arxiv.org/pdf/2508.13406.pdf' target='_blank'>https://arxiv.org/pdf/2508.13406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nooshin Bahador, Milad Lankarany
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13406">Semi-Supervised Anomaly Detection Pipeline for SOZ Localization Using Ictal-Related Chirp</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a quantitative framework for evaluating the spatial concordance between clinically defined seizure onset zones (SOZs) and statistically anomalous channels identified through time-frequency analysis of chirp events. The proposed pipeline employs a two-step methodology: (1) Unsupervised Outlier Detection, where Local Outlier Factor (LOF) analysis with adaptive neighborhood selection identifies anomalous channels based on spectro-temporal features of chirp (Onset frequency, offset frequency, and temporal duration); and (2) Spatial Correlation Analysis, which computes both exact co-occurrence metrics and weighted index similarity, incorporating hemispheric congruence and electrode proximity. Key findings demonstrate that the LOF-based approach (N neighbors=20, contamination=0.2) effectively detects outliers, with index matching (weighted by channel proximity) outperforming exact matching in SOZ localization. Performance metrics (precision, recall, F1) were highest for seizure-free patients (Index Precision mean: 0.903) and those with successful surgical outcomes (Index Precision mean: 0.865), whereas failure cases exhibited lower concordance (Index Precision mean: 0.460). The key takeaway is that chirp-based outlier detection, combined with weighted spatial metrics, provides a complementary method for SOZ localization, particularly in patients with successful surgical outcomes.
<div id='section'>Paperid: <span id='pid'>988, <a href='https://arxiv.org/pdf/2508.07923.pdf' target='_blank'>https://arxiv.org/pdf/2508.07923.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jakub Binda, Valentina Paneta, Vasileios Eleftheriadis, Hongkyou Chung, Panagiotis Papadimitroulas, Neo Christopher Chung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07923">Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative AI holds great potentials to automate and enhance data synthesis in nuclear medicine. However, the high-stakes nature of biomedical imaging necessitates robust mechanisms to detect and manage unexpected or erroneous model behavior. We introduce development and implementation of a hybrid anomaly detection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems. Two applications are demonstrated: Pose2Xray, which generates synthetic X-rays from photographic mouse images, and DosimetrEYE, which estimates 3D radiation dose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD) enhances reliability, reduces manual oversight, and supports real-time quality control. This approach strengthens the industrial viability of GenAI in preclinical settings by increasing robustness, scalability, and regulatory compliance.
<div id='section'>Paperid: <span id='pid'>989, <a href='https://arxiv.org/pdf/2507.17193.pdf' target='_blank'>https://arxiv.org/pdf/2507.17193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyi Wang, Bingqian Dai, Kin Wong, Yaochen Li, Yang Cheng, Qingyuan Shu, Haoran He, Puyang Huang, Hanshen Huang, Kang L. Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.17193">Spintronic Bayesian Hardware Driven by Stochastic Magnetic Domain Wall Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As artificial intelligence (AI) advances into diverse applications, ensuring reliability of AI models is increasingly critical. Conventional neural networks offer strong predictive capabilities but produce deterministic outputs without inherent uncertainty estimation, limiting their reliability in safety-critical domains. Probabilistic neural networks (PNNs), which introduce randomness, have emerged as a powerful approach for enabling intrinsic uncertainty quantification. However, traditional CMOS architectures are inherently designed for deterministic operation and actively suppress intrinsic randomness. This poses a fundamental challenge for implementing PNNs, as probabilistic processing introduces significant computational overhead. To address this challenge, we introduce a Magnetic Probabilistic Computing (MPC) platform-an energy-efficient, scalable hardware accelerator that leverages intrinsic magnetic stochasticity for uncertainty-aware computing. This physics-driven strategy utilizes spintronic systems based on magnetic domain walls (DWs) and their dynamics to establish a new paradigm of physical probabilistic computing for AI. The MPC platform integrates three key mechanisms: thermally induced DW stochasticity, voltage controlled magnetic anisotropy (VCMA), and tunneling magnetoresistance (TMR), enabling fully electrical and tunable probabilistic functionality at the device level. As a representative demonstration, we implement a Bayesian Neural Network (BNN) inference structure and validate its functionality on CIFAR-10 classification tasks. Compared to standard 28nm CMOS implementations, our approach achieves a seven orders of magnitude improvement in the overall figure of merit, with substantial gains in area efficiency, energy consumption, and speed. These results underscore the MPC platform's potential to enable reliable and trustworthy physical AI systems.
<div id='section'>Paperid: <span id='pid'>990, <a href='https://arxiv.org/pdf/2507.07668.pdf' target='_blank'>https://arxiv.org/pdf/2507.07668.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Frohnert, Denny Lane B. Sombillo, Evert van Nieuwenburg, Patrick Emonts
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07668">Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Matching theoretical predictions to experimental data remains a central challenge in hadron spectroscopy. In particular, the identification of new hadronic states is difficult, as exotic signals near threshold can arise from a variety of physical mechanisms. A key diagnostic in this context is the pole structure of the scattering amplitude, but different configurations can produce similar signatures. The mapping between pole configurations and line shapes is especially ambiguous near the mass threshold, where analytic control is limited. In this work, we introduce an uncertainty-aware machine learning approach for classifying pole structures in $S$-matrix elements. Our method is based on an ensemble of classifier chains that provide both epistemic and aleatoric uncertainty estimates. We apply a rejection criterion based on predictive uncertainty, achieving a validation accuracy of nearly $95\%$ while discarding only a small fraction of high-uncertainty predictions. Trained on synthetic data with known pole structures, the model generalizes to previously unseen experimental data, including enhancements associated with the $P_{c\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole structure, representing the presence of a genuine compact pentaquark in the presence of a higher channel virtual state pole with non-vanishing width. While evaluated on this particular state, our framework is broadly applicable to other candidate hadronic states and offers a scalable tool for pole structure inference in scattering amplitudes.
<div id='section'>Paperid: <span id='pid'>991, <a href='https://arxiv.org/pdf/2507.06111.pdf' target='_blank'>https://arxiv.org/pdf/2507.06111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamad H. Danesh, Maxime Wabartha, Stanley Wu, Joelle Pineau, Hsiu-Chin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06111">Safe Domain Randomization via Uncertainty-Aware Out-of-Distribution Detection and Policy Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying reinforcement learning (RL) policies in real-world involves significant challenges, including distribution shifts, safety concerns, and the impracticality of direct interactions during policy refinement. Existing methods, such as domain randomization (DR) and off-dynamics RL, enhance policy robustness by direct interaction with the target domain, an inherently unsafe practice. We propose Uncertainty-Aware RL (UARL), a novel framework that prioritizes safety during training by addressing Out-Of-Distribution (OOD) detection and policy adaptation without requiring direct interactions in target domain. UARL employs an ensemble of critics to quantify policy uncertainty and incorporates progressive environmental randomization to prepare the policy for diverse real-world conditions. By iteratively refining over high-uncertainty regions of the state space in simulated environments, UARL enhances robust generalization to the target domain without explicitly training on it. We evaluate UARL on MuJoCo benchmarks and a quadrupedal robot, demonstrating its effectiveness in reliable OOD detection, improved performance, and enhanced sample efficiency compared to baselines.
<div id='section'>Paperid: <span id='pid'>992, <a href='https://arxiv.org/pdf/2507.05904.pdf' target='_blank'>https://arxiv.org/pdf/2507.05904.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Astrid Franz, Frederik Hoppe, Marianne Michaelis, Udo GÃ¶bel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05904">Universal Embeddings of Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tabular data in relational databases represents a significant portion of industrial data. Hence, analyzing and interpreting tabular data is of utmost importance. Application tasks on tabular data are manifold and are often not specified when setting up an industrial database. To address this, we present a novel framework for generating universal, i.e., task-independent embeddings of tabular data for performing downstream tasks without predefined targets. Our method transforms tabular data into a graph structure, leverages Graph Auto-Encoders to create entity embeddings, which are subsequently aggregated to obtain embeddings for each table row, i.e., each data sample. This two-step approach has the advantage that unseen samples, consisting of similar entities, can be embedded without additional training. Downstream tasks such as regression, classification or outlier detection, can then be performed by applying a distance-based similarity measure in the embedding space. Experiments on real-world datasets demonstrate that our method achieves superior performance compared to existing universal tabular data embedding techniques.
<div id='section'>Paperid: <span id='pid'>993, <a href='https://arxiv.org/pdf/2506.17872.pdf' target='_blank'>https://arxiv.org/pdf/2506.17872.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sree Bhargavi Balija, Amitash Nanda, Debashis Sahoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17872">Decoding Federated Learning: The FedNAM+ Conformal Revolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning has significantly advanced distributed training of machine learning models across decentralized data sources. However, existing frameworks often lack comprehensive solutions that combine uncertainty quantification, interpretability, and robustness. To address this, we propose FedNAM+, a federated learning framework that integrates Neural Additive Models (NAMs) with a novel conformal prediction method to enable interpretable and reliable uncertainty estimation. Our method introduces a dynamic level adjustment technique that utilizes gradient-based sensitivity maps to identify key input features influencing predictions. This facilitates both interpretability and pixel-wise uncertainty estimates. Unlike traditional interpretability methods such as LIME and SHAP, which do not provide confidence intervals, FedNAM+ offers visual insights into prediction reliability. We validate our approach through experiments on CT scan, MNIST, and CIFAR datasets, demonstrating high prediction accuracy with minimal loss (e.g., only 0.1% on MNIST), along with transparent uncertainty measures. Visual analysis highlights variable uncertainty intervals, revealing low-confidence regions where model performance can be improved with additional data. Compared to Monte Carlo Dropout, FedNAM+ delivers efficient and global uncertainty estimates with reduced computational overhead, making it particularly suitable for federated learning scenarios. Overall, FedNAM+ provides a robust, interpretable, and computationally efficient framework that enhances trust and transparency in decentralized predictive modeling.
<div id='section'>Paperid: <span id='pid'>994, <a href='https://arxiv.org/pdf/2506.15505.pdf' target='_blank'>https://arxiv.org/pdf/2506.15505.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Agnimitra Dasgupta, Javier Murgoitio-Esandi, Ali Fardisi, Assad A Oberai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15505">Time-dependent density estimation using binary classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a data-driven method to learn the time-dependent probability density of a multivariate stochastic process from sample paths, assuming that the initial probability density is known and can be evaluated. Our method uses a novel time-dependent binary classifier trained using a contrastive estimation-based objective that trains the classifier to discriminate between realizations of the stochastic process at two nearby time instants. Significantly, the proposed method explicitly models the time-dependent probability distribution, which means that it is possible to obtain the value of the probability density within the time horizon of interest. Additionally, the input before the final activation in the time-dependent classifier is a second-order approximation to the partial derivative, with respect to time, of the logarithm of the density. We apply the proposed approach to approximate the time-dependent probability density functions for systems driven by stochastic excitations. We also use the proposed approach to synthesize new samples of a random vector from a given set of its realizations. In such applications, we generate sample paths necessary for training using stochastic interpolants. Subsequently, new samples are generated using gradient-based Markov chain Monte Carlo methods because automatic differentiation can efficiently provide the necessary gradient. Further, we demonstrate the utility of an explicit approximation to the time-dependent probability density function through applications in unsupervised outlier detection. Through several numerical experiments, we show that the proposed method accurately reconstructs complex time-dependent, multi-modal, and near-degenerate densities, scales effectively to moderately high-dimensional problems, and reliably detects rare events among real-world data.
<div id='section'>Paperid: <span id='pid'>995, <a href='https://arxiv.org/pdf/2506.09745.pdf' target='_blank'>https://arxiv.org/pdf/2506.09745.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangrui Zhu, Junhua Bao, Yipan Wei, Yapeng Li, Bo Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09745">Class Similarity-Based Multimodal Classification under Heterogeneous Category Sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing multimodal methods typically assume that different modalities share the same category set. However, in real-world applications, the category distributions in multimodal data exhibit inconsistencies, which can hinder the model's ability to effectively utilize cross-modal information for recognizing all categories. In this work, we propose the practical setting termed Multi-Modal Heterogeneous Category-set Learning (MMHCL), where models are trained in heterogeneous category sets of multi-modal data and aim to recognize complete classes set of all modalities during test. To effectively address this task, we propose a Class Similarity-based Cross-modal Fusion model (CSCF). Specifically, CSCF aligns modality-specific features to a shared semantic space to enable knowledge transfer between seen and unseen classes. It then selects the most discriminative modality for decision fusion through uncertainty estimation. Finally, it integrates cross-modal information based on class similarity, where the auxiliary modality refines the prediction of the dominant one. Experimental results show that our method significantly outperforms existing state-of-the-art (SOTA) approaches on multiple benchmark datasets, effectively addressing the MMHCL task.
<div id='section'>Paperid: <span id='pid'>996, <a href='https://arxiv.org/pdf/2505.18890.pdf' target='_blank'>https://arxiv.org/pdf/2505.18890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Morteza Rakhshaninejad, Mira Jurgens, Nicolas Dewolf, Willem Waegeman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18890">Conformal Prediction for Uncertainty Estimation in Drug-Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate drug-target interaction (DTI) prediction with machine learning models is essential for drug discovery. Such models should also provide a credible representation of their uncertainty, but applying classical marginal conformal prediction (CP) in DTI prediction often overlooks variability across drug and protein subgroups. In this work, we analyze three cluster-conditioned CP methods for DTI prediction, and compare them with marginal and group-conditioned CP. Clusterings are obtained via nonconformity scores, feature similarity, and nearest neighbors, respectively. Experiments on the KIBA dataset using four data-splitting strategies show that nonconformity-based clustering yields the tightest intervals and most reliable subgroup coverage, especially in random and fully unseen drug-protein splits. Group-conditioned CP works well when one entity is familiar, but residual-driven clustering provides robust uncertainty estimates even in sparse or novel scenarios. These results highlight the potential of cluster-based CP for improving DTI prediction under uncertainty.
<div id='section'>Paperid: <span id='pid'>997, <a href='https://arxiv.org/pdf/2505.15443.pdf' target='_blank'>https://arxiv.org/pdf/2505.15443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Artem Zabolotnyi, Roman Makarov, Mile Mitrovic, Polina Proskura, Oleg Travkin, Roman Alferov, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15443">AdUE: Improving uncertainty estimation head for LoRA adapters in LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation remains a critical challenge in adapting pre-trained language models to classification tasks, particularly under parameter-efficient fine-tuning approaches such as adapters. We introduce AdUE1, an efficient post-hoc uncertainty estimation (UE) method, to enhance softmax-based estimates. Our approach (1) uses a differentiable approximation of the maximum function and (2) applies additional regularization through L2-SP, anchoring the fine-tuned head weights and regularizing the model. Evaluations on five NLP classification datasets across four language models (RoBERTa, ELECTRA, LLaMA-2, Qwen) demonstrate that our method consistently outperforms established baselines such as Mahalanobis distance and softmax response. Our approach is lightweight (no base-model changes) and produces better-calibrated confidence.
<div id='section'>Paperid: <span id='pid'>998, <a href='https://arxiv.org/pdf/2505.12803.pdf' target='_blank'>https://arxiv.org/pdf/2505.12803.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawen Xu, Odej Kao, Margret Keuper
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12803">Informed Mixing -- Improving Open Set Recognition via Attribution-based Augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open set recognition (OSR) is devised to address the problem of detecting novel classes during model inference. Even in recent vision models, this remains an open issue which is receiving increasing attention. Thereby, a crucial challenge is to learn features that are relevant for unseen categories from given data, for which these features might not be discriminative. To facilitate this process and "optimize to learn" more diverse features, we propose GradMix, a data augmentation method that dynamically leverages gradient-based attribution maps of the model during training to mask out already learned concepts. Thus GradMix encourages the model to learn a more complete set of representative features from the same data source. Extensive experiments on open set recognition, close set classification, and out-of-distribution detection reveal that our method can often outperform the state-of-the-art. GradMix can further increase model robustness to corruptions as well as downstream classification performance for self-supervised learning, indicating its benefit for model generalization.
<div id='section'>Paperid: <span id='pid'>999, <a href='https://arxiv.org/pdf/2505.06516.pdf' target='_blank'>https://arxiv.org/pdf/2505.06516.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yilin Dong, Tianyun Zhu, Xinde Li, Jean Dezert, Rigui Zhou, Changming Zhu, Lei Cao, Shuzhi Sam Ge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06516">Quantum Conflict Measurement in Decision Making for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantum Dempster-Shafer Theory (QDST) uses quantum interference effects to derive a quantum mass function (QMF) as a fuzzy metric type from information obtained from various data sources. In addition, QDST uses quantum parallel computing to speed up computation. Nevertheless, the effective management of conflicts between multiple QMFs in QDST is a challenging question. This work aims to address this problem by proposing a Quantum Conflict Indicator (QCI) that measures the conflict between two QMFs in decision-making. Then, the properties of the QCI are carefully investigated. The obtained results validate its compliance with desirable conflict measurement properties such as non-negativity, symmetry, boundedness, extreme consistency and insensitivity to refinement. We then apply the proposed QCI in conflict fusion methods and compare its performance with several commonly used fusion approaches. This comparison demonstrates the superiority of the QCI-based conflict fusion method. Moreover, the Class Description Domain Space (C-DDS) and its optimized version, C-DDS+ by utilizing the QCI-based fusion method, are proposed to address the Out-of-Distribution (OOD) detection task. The experimental results show that the proposed approach gives better OOD performance with respect to several state-of-the-art baseline OOD detection methods. Specifically, it achieves an average increase in Area Under the Receiver Operating Characteristic Curve (AUC) of 1.2% and a corresponding average decrease in False Positive Rate at 95% True Negative Rate (FPR95) of 5.4% compared to the optimal baseline method.
<div id='section'>Paperid: <span id='pid'>1000, <a href='https://arxiv.org/pdf/2505.04787.pdf' target='_blank'>https://arxiv.org/pdf/2505.04787.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sriram Mandalika, Harsha Vardhan, Athira Nambiar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04787">Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Learning entails progressively acquiring knowledge from new data while retaining previously acquired knowledge, thereby mitigating ``Catastrophic Forgetting'' in neural networks. Our work presents a novel uncertainty-driven Unsupervised Continual Learning framework using Generative Replay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture efficiently uses unlabelled and synthetic labelled data in a balanced proportion using a cluster-level uncertainty-driven feedback mechanism and a VLM-powered generative replay module. Unlike traditional memory-buffer methods that depend on pretrained models and pseudo-labels, our R2R framework operates without any prior training. It leverages visual features from unlabeled data and adapts continuously using clustering-based uncertainty estimation coupled with dynamic thresholding. Concurrently, a generative replay mechanism along with DeepSeek-R1 powered CLIP VLM produces labelled synthetic data representative of past experiences, resembling biological visual thinking that replays memory to remember and act in new, unseen tasks. Extensive experimental analyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and TinyImageNet datasets. Our proposed R2R approach improves knowledge retention, achieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%, 59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.
<div id='section'>Paperid: <span id='pid'>1001, <a href='https://arxiv.org/pdf/2505.04019.pdf' target='_blank'>https://arxiv.org/pdf/2505.04019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matteo Ceschin, Leonardo Arrighi, Luca Longo, Sylvio Barbon Junior
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04019">Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The need to explain predictive models is well-established in modern machine learning. However, beyond model interpretability, understanding pre-processing methods is equally essential. Understanding how data modifications impact model performance improvements and potential biases and promoting a reliable pipeline is mandatory for developing robust machine learning solutions. Isolation Forest (iForest) is a widely used technique for outlier detection that performs well. Its effectiveness increases with the number of tree-based learners. However, this also complicates the explanation of outlier selection and the decision boundaries for inliers. This research introduces a novel Explainable AI (XAI) method, tackling the problem of global explainability. In detail, it aims to offer a global explanation for outlier detection to address its opaque nature. Our approach is based on the Decision Predicate Graph (DPG), which clarifies the logic of ensemble methods and provides both insights and a graph-based metric to explain how samples are identified as outliers using the proposed Inlier-Outlier Propagation Score (IOP-Score). Our proposal enhances iForest's explainability and provides a comprehensive view of the decision-making process, detailing which features contribute to outlier identification and how the model utilizes them. This method advances the state-of-the-art by providing insights into decision boundaries and a comprehensive view of holistic feature usage in outlier identification. -- thus promoting a fully explainable machine learning pipeline.
<div id='section'>Paperid: <span id='pid'>1002, <a href='https://arxiv.org/pdf/2503.13909.pdf' target='_blank'>https://arxiv.org/pdf/2503.13909.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pavia Bera, Sanjukta Bhanja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13909">Quantification of Uncertainties in Probabilistic Deep Neural Network by Implementing Boosting of Variational Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern neural network architectures have achieved remarkable accuracies but remain highly dependent on their training data, often lacking interpretability in their learned mappings. While effective on large datasets, they tend to overfit on smaller ones. Probabilistic neural networks, such as those utilizing variational inference, address this limitation by incorporating uncertainty estimation through weight distributions rather than point estimates. However, standard variational inference often relies on a single-density approximation, which can lead to poor posterior estimates and hinder model performance. We propose Boosted Bayesian Neural Networks (BBNN), a novel approach that enhances neural network weight distribution approximations using Boosting Variational Inference (BVI). By iteratively constructing a mixture of densities, BVI expands the approximating family, enabling a more expressive posterior that leads to improved generalization and uncertainty estimation. While this approach increases computational complexity, it significantly enhances accuracy an essential tradeoff, particularly in high-stakes applications such as medical diagnostics, where false negatives can have severe consequences. Our experimental results demonstrate that BBNN achieves ~5% higher accuracy compared to conventional neural networks while providing superior uncertainty quantification. This improvement highlights the effectiveness of leveraging a mixture-based variational family to better approximate the posterior distribution, ultimately advancing probabilistic deep learning.
<div id='section'>Paperid: <span id='pid'>1003, <a href='https://arxiv.org/pdf/2502.14281.pdf' target='_blank'>https://arxiv.org/pdf/2502.14281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weipeng Huang, Qin Li, Yang Xiao, Cheng Qiao, Tie Cai, Junwei Liang, Neil J. Hurley, Guangyuan Piao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14281">Correcting Noisy Multilabel Predictions: Modeling Label Noise through Latent Space Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Noise in data appears to be inevitable in most real-world machine learning applications and would cause severe overfitting problems. Not only can data features contain noise, but labels are also prone to be noisy due to human input. In this paper, rather than noisy label learning in multiclass classifications, we instead focus on the less explored area of noisy label learning for multilabel classifications. Specifically, we investigate the post-correction of predictions generated from classifiers learned with noisy labels. The reasons are two-fold. Firstly, this approach can directly work with the trained models to save computational resources. Secondly, it could be applied on top of other noisy label correction techniques to achieve further improvements. To handle this problem, we appeal to deep generative approaches that are possible for uncertainty estimation. Our model posits that label noise arises from a stochastic shift in the latent variable, providing a more robust and beneficial means for noisy learning. We develop both unsupervised and semi-supervised learning methods for our model. The extensive empirical study presents solid evidence to that our approach is able to consistently improve the independent models and performs better than a number of existing methods across various noisy label settings. Moreover, a comprehensive empirical analysis of the proposed method is carried out to validate its robustness, including sensitivity analysis and an ablation study, among other elements.
<div id='section'>Paperid: <span id='pid'>1004, <a href='https://arxiv.org/pdf/2501.01072.pdf' target='_blank'>https://arxiv.org/pdf/2501.01072.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiang Shang, Yuanmeng Wu, Xiaoxiang Han, Xi Chen, Qi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01072">Evidential Calibrated Uncertainty-Guided Interactive Segmentation paradigm for Ultrasound Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and robust ultrasound image segmentation is critical for computer-aided diagnostic systems. Nevertheless, the inherent challenges of ultrasound imaging, such as blurry boundaries and speckle noise, often cause traditional segmentation methods to struggle with performance. Despite recent advancements in universal image segmentation, such as the Segment Anything Model, existing interactive segmentation methods still suffer from inefficiency and lack of specialization. These methods rely heavily on extensive accurate manual or random sampling prompts for interaction, necessitating numerous prompts and iterations to reach satisfactory performance. In response to this challenge, we propose the Evidential Uncertainty-Guided Interactive Segmentation (EUGIS), an end-to-end, efficient tiered interactive segmentation paradigm based on evidential uncertainty estimation for ultrasound image segmentation. Specifically, EUGIS harnesses evidence-based uncertainty estimation, grounded in Dempster-Shafer theory and Subjective Logic, to gauge the level of uncertainty in the predictions of model for different regions. By prioritizing sampling the high-uncertainty region, our method can effectively simulate the interactive behavior of well-trained radiologists, enhancing the targeted of sampling while reducing the number of prompts and iterations required.Additionally, we propose a trainable calibration mechanism for uncertainty estimation, which can further optimize the boundary between certainty and uncertainty, thereby enhancing the confidence of uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1005, <a href='https://arxiv.org/pdf/2412.12890.pdf' target='_blank'>https://arxiv.org/pdf/2412.12890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shijing Wang, Yaping Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12890">Suppressing Uncertainty in Gaze Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty in gaze estimation manifests in two aspects: 1) low-quality images caused by occlusion, blurriness, inconsistent eye movements, or even non-face images; 2) incorrect labels resulting from the misalignment between the labeled and actual gaze points during the annotation process. Allowing these uncertainties to participate in training hinders the improvement of gaze estimation. To tackle these challenges, in this paper, we propose an effective solution, named Suppressing Uncertainty in Gaze Estimation (SUGE), which introduces a novel triplet-label consistency measurement to estimate and reduce the uncertainties. Specifically, for each training sample, we propose to estimate a novel ``neighboring label'' calculated by a linearly weighted projection from the neighbors to capture the similarity relationship between image features and their corresponding labels, which can be incorporated with the predicted pseudo label and ground-truth label for uncertainty estimation. By modeling such triplet-label consistency, we can measure the qualities of both images and labels, and further largely reduce the negative effects of unqualified images and wrong labels through our designed sample weighting and label correction strategies. Experimental results on the gaze estimation benchmarks indicate that our proposed SUGE achieves state-of-the-art performance.
<div id='section'>Paperid: <span id='pid'>1006, <a href='https://arxiv.org/pdf/2412.07961.pdf' target='_blank'>https://arxiv.org/pdf/2412.07961.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric Bigelow, Ari Holtzman, Hidenori Tanaka, Tomer Ullman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07961">Forking Paths in Neural Text Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating uncertainty in Large Language Models (LLMs) is important for properly evaluating LLMs, and ensuring safety for users. However, prior approaches to uncertainty estimation focus on the final answer in generated text, ignoring intermediate steps that might dramatically impact the outcome. We hypothesize that there exist key forking tokens, such that re-sampling the system at those specific tokens, but not others, leads to very different outcomes. To test this empirically, we develop a novel approach to representing uncertainty dynamics across individual tokens of text generation, and applying statistical models to test our hypothesis. Our approach is highly flexible: it can be applied to any dataset and any LLM, without fine tuning or accessing model weights. We use our method to analyze LLM responses on 7 different tasks across 4 domains, spanning a wide range of typical use cases. We find many examples of forking tokens, including surprising ones such as punctuation marks, suggesting that LLMs are often just a single token away from saying something very different.
<div id='section'>Paperid: <span id='pid'>1007, <a href='https://arxiv.org/pdf/2412.04177.pdf' target='_blank'>https://arxiv.org/pdf/2412.04177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis A. Ortega, SimÃ³n RodrÃ­guez-Santana, Daniel HernÃ¡ndez-Lobato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04177">Fixed-Mean Gaussian Processes for Post-hoc Bayesian Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, there has been an increasing interest in performing post-hoc uncertainty estimation about the predictions of pre-trained deep neural networks (DNNs). Given a pre-trained DNN via back-propagation, these methods enhance the original network by adding output confidence measures, such as error bars, without compromising its initial accuracy. In this context, we introduce a novel family of sparse variational Gaussian processes (GPs), where the posterior mean is fixed to any continuous function when using a universal kernel. Specifically, we fix the mean of this GP to the output of the pre-trained DNN, allowing our approach to effectively fit the GP's predictive variances to estimate the DNN prediction uncertainty. Our approach leverages variational inference (VI) for efficient stochastic optimization, with training costs that remain independent of the number of training points, scaling efficiently to large datasets such as ImageNet. The proposed method, called fixed mean GP (FMGP), is architecture-agnostic, relying solely on the pre-trained model's outputs to adjust the predictive variances. Experimental results demonstrate that FMGP improves both uncertainty estimation and computational efficiency when compared to state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1008, <a href='https://arxiv.org/pdf/2411.00718.pdf' target='_blank'>https://arxiv.org/pdf/2411.00718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurav R. Pandey, Aaqib Saeed, Harlin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00718">PedSleepMAE: Generative Model for Multimodal Pediatric Sleep Signals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pediatric sleep is an important but often overlooked area in health informatics. We present PedSleepMAE, a generative model that fully leverages multimodal pediatric sleep signals including multichannel EEGs, respiratory signals, EOGs and EMG. This masked autoencoder-based model performs comparably to supervised learning models in sleep scoring and in the detection of apnea, hypopnea, EEG arousal and oxygen desaturation. Its embeddings are also shown to capture subtle differences in sleep signals coming from a rare genetic disorder. Furthermore, PedSleepMAE generates realistic signals that can be used for sleep segment retrieval, outlier detection, and missing channel imputation. This is the first general-purpose generative model trained on multiple types of pediatric sleep signals.
<div id='section'>Paperid: <span id='pid'>1009, <a href='https://arxiv.org/pdf/2410.23883.pdf' target='_blank'>https://arxiv.org/pdf/2410.23883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rena Gao, Xuetong Wu, Siwen Luo, Caren Han, Feng Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.23883">'No' Matters: Out-of-Distribution Detection in Multimodality Long Dialogue</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection in multimodal contexts is essential for identifying deviations in combined inputs from different modalities, particularly in applications like open-domain dialogue systems or real-life dialogue interactions. This paper aims to improve the user experience that involves multi-round long dialogues by efficiently detecting OOD dialogues and images. We introduce a novel scoring framework named Dialogue Image Aligning and Enhancing Framework (DIAEF) that integrates the visual language models with the novel proposed scores that detect OOD in two key scenarios (1) mismatches between the dialogue and image input pair and (2) input pairs with previously unseen labels. Our experimental results, derived from various benchmarks, demonstrate that integrating image and multi-round dialogue OOD detection is more effective with previously unseen labels than using either modality independently. In the presence of mismatched pairs, our proposed score effectively identifies these mismatches and demonstrates strong robustness in long dialogues. This approach enhances domain-aware, adaptive conversational agents and establishes baselines for future studies.
<div id='section'>Paperid: <span id='pid'>1010, <a href='https://arxiv.org/pdf/2410.13822.pdf' target='_blank'>https://arxiv.org/pdf/2410.13822.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>ClÃ©ment Playout, Renaud Duval, Marie Carole Boucher, Farida Cheriet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13822">Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The diagnosis of diabetic retinopathy, which relies on fundus images, faces challenges in achieving transparency and interpretability when using a global classification approach. However, segmentation-based databases are significantly more expensive to acquire and combining them is often problematic. This paper introduces a novel method, termed adversarial style conversion, to address the lack of standardization in annotation styles across diverse databases. By training a single architecture on combined databases, the model spontaneously modifies its segmentation style depending on the input, demonstrating the ability to convert among different labeling styles. The proposed methodology adds a linear probe to detect dataset origin based on encoder features and employs adversarial attacks to condition the model's segmentation style. Results indicate significant qualitative and quantitative through dataset combination, offering avenues for improved model generalization, uncertainty estimation and continuous interpolation between annotation styles. Our approach enables training a segmentation model with diverse databases while controlling and leveraging annotation styles for improved retinopathy diagnosis.
<div id='section'>Paperid: <span id='pid'>1011, <a href='https://arxiv.org/pdf/2410.08739.pdf' target='_blank'>https://arxiv.org/pdf/2410.08739.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qihang Yang, Yang Zhao, Hong Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08739">MMLF: Multi-modal Multi-class Late Fusion for Object Detection with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving necessitates advanced object detection techniques that integrate information from multiple modalities to overcome the limitations associated with single-modal approaches. The challenges of aligning diverse data in early fusion and the complexities, along with overfitting issues introduced by deep fusion, underscore the efficacy of late fusion at the decision level. Late fusion ensures seamless integration without altering the original detector's network structure. This paper introduces a pioneering Multi-modal Multi-class Late Fusion method, designed for late fusion to enable multi-class detection. Fusion experiments conducted on the KITTI validation and official test datasets illustrate substantial performance improvements, presenting our model as a versatile solution for multi-modal object detection in autonomous driving. Moreover, our approach incorporates uncertainty analysis into the classification fusion process, rendering our model more transparent and trustworthy and providing more reliable insights into category predictions.
<div id='section'>Paperid: <span id='pid'>1012, <a href='https://arxiv.org/pdf/2410.08651.pdf' target='_blank'>https://arxiv.org/pdf/2410.08651.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gleb Radchenko, Victoria Andrea Fill
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08651">Edge AI Collaborative Learning: Bayesian Approaches to Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in edge computing have significantly enhanced the AI capabilities of Internet of Things (IoT) devices. However, these advancements introduce new challenges in knowledge exchange and resource management, particularly addressing the spatiotemporal data locality in edge computing environments. This study examines algorithms and methods for deploying distributed machine learning within autonomous, network-capable, AI-enabled edge devices. We focus on determining confidence levels in learning outcomes considering the spatial variability of data encountered by independent agents. Using collaborative mapping as a case study, we explore the application of the Distributed Neural Network Optimization (DiNNO) algorithm extended with Bayesian neural networks (BNNs) for uncertainty estimation. We implement a 3D environment simulation using the Webots platform to simulate collaborative mapping tasks, decouple the DiNNO algorithm into independent processes for asynchronous network communication in distributed learning, and integrate distributed uncertainty estimation using BNNs. Our experiments demonstrate that BNNs can effectively support uncertainty estimation in a distributed learning context, with precise tuning of learning hyperparameters crucial for effective uncertainty assessment. Notably, applying Kullback-Leibler divergence for parameter regularization resulted in a 12-30% reduction in validation loss during distributed BNN training compared to other regularization strategies.
<div id='section'>Paperid: <span id='pid'>1013, <a href='https://arxiv.org/pdf/2410.07806.pdf' target='_blank'>https://arxiv.org/pdf/2410.07806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Niklas Erdmann, Lars Ã. Bentsen, Roy Stenbro, Heine N. Riise, Narada Warakagoda, Paal Engelstad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07806">Deep and Probabilistic Solar Irradiance Forecast at the Arctic Circle</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solar irradiance forecasts can be dynamic and unreliable due to changing weather conditions. Near the Arctic circle, this also translates into a distinct set of further challenges. This work is forecasting solar irradiance with Norwegian data using variations of Long-Short-Term Memory units (LSTMs). In order to gain more trustworthiness of results, the probabilistic approaches Quantile Regression (QR) and Maximum Likelihood (MLE) are optimized on top of the LSTMs, providing measures of uncertainty for the results. MLE is further extended by using a Johnson's SU distribution, a Johnson's SB distribution, and a Weibull distribution in addition to a normal Gaussian to model parameters. Contrary to a Gaussian, Weibull, Johnson's SU and Johnson's SB can return skewed distributions, enabling it to fit the non-normal solar irradiance distribution more optimally. The LSTMs are compared against each other, a simple Multi-layer Perceptron (MLP), and a smart-persistence estimator. The proposed LSTMs are found to be more accurate than smart persistence and the MLP for a multi-horizon, day-ahead (36 hours) forecast. The deterministic LSTM showed better root mean squared error (RMSE), but worse mean absolute error (MAE) than a MLE with Johnson's SB distribution. Probabilistic uncertainty estimation is shown to fit relatively well across the distribution of observed irradiance. While QR shows better uncertainty estimation calibration, MLE with Johnson's SB, Johnson's SU, or Gaussian show better performance in the other metrics employed. Optimizing and comparing the models against each other reveals a seemingly inherent trade-off between point-prediction and uncertainty estimation calibration.
<div id='section'>Paperid: <span id='pid'>1014, <a href='https://arxiv.org/pdf/2410.05468.pdf' target='_blank'>https://arxiv.org/pdf/2410.05468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanhao Sun, Thanos Triantafyllou, Anthos Makris, Maja DrmaÄ, Kai Xu, Luo Mai, Mahesh K. Marina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.05468">PH-Dropout: Practical Epistemic Uncertainty Quantification for View Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>View synthesis using Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) has demonstrated impressive fidelity in rendering real-world scenarios. However, practical methods for accurate and efficient epistemic Uncertainty Quantification (UQ) in view synthesis are lacking. Existing approaches for NeRF either introduce significant computational overhead (e.g., ``10x increase in training time" or ``10x repeated training") or are limited to specific uncertainty conditions or models. Notably, GS models lack any systematic approach for comprehensive epistemic UQ. This capability is crucial for improving the robustness and scalability of neural view synthesis, enabling active model updates, error estimation, and scalable ensemble modeling based on uncertainty. In this paper, we revisit NeRF and GS-based methods from a function approximation perspective, identifying key differences and connections in 3D representation learning. Building on these insights, we introduce PH-Dropout (Post hoc Dropout), the first real-time and accurate method for epistemic uncertainty estimation that operates directly on pre-trained NeRF and GS models. Extensive evaluations validate our theoretical findings and demonstrate the effectiveness of PH-Dropout.
<div id='section'>Paperid: <span id='pid'>1015, <a href='https://arxiv.org/pdf/2409.06593.pdf' target='_blank'>https://arxiv.org/pdf/2409.06593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hugo Gobato Souto, Francisco Louzada Neto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06593">Advancing Causal Inference: A Nonparametric Approach to ATE and CATE Estimation with Continuous Treatments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a generalized ps-BART model for the estimation of Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE) in continuous treatments, addressing limitations of the Bayesian Causal Forest (BCF) model. The ps-BART model's nonparametric nature allows for flexibility in capturing nonlinear relationships between treatment and outcome variables. Across three distinct sets of Data Generating Processes (DGPs), the ps-BART model consistently outperforms the BCF model, particularly in highly nonlinear settings. The ps-BART model's robustness in uncertainty estimation and accuracy in both point-wise and probabilistic estimation demonstrate its utility for real-world applications. This research fills a crucial gap in causal inference literature, providing a tool better suited for nonlinear treatment-outcome relationships and opening avenues for further exploration in the domain of continuous treatment effect estimation.
<div id='section'>Paperid: <span id='pid'>1016, <a href='https://arxiv.org/pdf/2409.02079.pdf' target='_blank'>https://arxiv.org/pdf/2409.02079.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alice Williams, Boris Kovalerchuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02079">Synthetic Data Generation and Automated Multidimensional Data Labeling for AI/ML in General and Circular Coordinates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Insufficient amounts of available training data is a critical challenge for both development and deployment of artificial intelligence and machine learning (AI/ML) models. This paper proposes a unified approach to both synthetic data generation (SDG) and automated data labeling (ADL) with a unified SDG-ADL algorithm. SDG-ADL uses multidimensional (n-D) representations of data visualized losslessly with General Line Coordinates (GLCs), relying on reversible GLC properties to visualize n-D data in multiple GLCs. This paper demonstrates use of the new Circular Coordinates in Static and Dynamic forms, used with Parallel Coordinates and Shifted Paired Coordinates, since each GLC exemplifies unique data properties, such as interattribute n-D distributions and outlier detection. The approach is interactively implemented in computer software with the Dynamic Coordinates Visualization system (DCVis). Results with real data are demonstrated in case studies, evaluating impact on classifiers.
<div id='section'>Paperid: <span id='pid'>1017, <a href='https://arxiv.org/pdf/2408.15874.pdf' target='_blank'>https://arxiv.org/pdf/2408.15874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philipp RÃ¶chner, Henrique O. Marques, Ricardo J. G. B. Campello, Arthur Zimek, Franz Rothlauf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15874">Robust Statistical Scaling of Outlier Scores: Improving the Quality of Outlier Probabilities for Outliers (Extended Version)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection algorithms typically assign an outlier score to each observation in a dataset, indicating the degree to which an observation is an outlier. However, these scores are often not comparable across algorithms and can be difficult for humans to interpret. Statistical scaling addresses this problem by transforming outlier scores into outlier probabilities without using ground-truth labels, thereby improving interpretability and comparability across algorithms. However, the quality of this transformation can be different for outliers and inliers. Missing outliers in scenarios where they are of particular interest - such as healthcare, finance, or engineering - can be costly or dangerous. Thus, ensuring good probabilities for outliers is essential. This paper argues that statistical scaling, as commonly used in the literature, does not produce equally good probabilities for outliers as for inliers. Therefore, we propose robust statistical scaling, which uses robust estimators to improve the probabilities for outliers. We evaluate several variants of our method against other outlier score transformations for real-world datasets and outlier detection algorithms, where it can improve the probabilities for outliers.
<div id='section'>Paperid: <span id='pid'>1018, <a href='https://arxiv.org/pdf/2408.10713.pdf' target='_blank'>https://arxiv.org/pdf/2408.10713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Padmanaba Srinivasan, William Knottenbelt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10713">Offline Model-Based Reinforcement Learning with Anti-Exploration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model-based reinforcement learning (MBRL) algorithms learn a dynamics model from collected data and apply it to generate synthetic trajectories to enable faster learning. This is an especially promising paradigm in offline reinforcement learning (RL) where data may be limited in quantity, in addition to being deficient in coverage and quality. Practical approaches to offline MBRL usually rely on ensembles of dynamics models to prevent exploitation of any individual model and to extract uncertainty estimates that penalize values in states far from the dataset support. Uncertainty estimates from ensembles can vary greatly in scale, making it challenging to generalize hyperparameters well across even similar tasks. In this paper, we present Morse Model-based offline RL (MoMo), which extends the anti-exploration paradigm found in offline model-free RL to the model-based space. We develop model-free and model-based variants of MoMo and show how the model-free version can be extended to detect and deal with out-of-distribution (OOD) states using explicit uncertainty estimation without the need for large ensembles. MoMo performs offline MBRL using an anti-exploration bonus to counteract value overestimation in combination with a policy constraint, as well as a truncation function to terminate synthetic rollouts that are excessively OOD. Experimentally, we find that both model-free and model-based MoMo perform well, and the latter outperforms prior model-based and model-free baselines on the majority of D4RL datasets tested.
<div id='section'>Paperid: <span id='pid'>1019, <a href='https://arxiv.org/pdf/2407.13708.pdf' target='_blank'>https://arxiv.org/pdf/2407.13708.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ji-Hun Oh, Kianoush Falahkheirkhah, Rohit Bhargava
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13708">Are We Ready for Out-of-Distribution Detection in Digital Pathology?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of semantic and covariate out-of-distribution (OOD) examples is a critical yet overlooked challenge in digital pathology (DP). Recently, substantial insight and methods on OOD detection were presented by the ML community, but how do they fare in DP applications? To this end, we establish a benchmark study, our highlights being: 1) the adoption of proper evaluation protocols, 2) the comparison of diverse detectors in both a single and multi-model setting, and 3) the exploration into advanced ML settings like transfer learning (ImageNet vs. DP pre-training) and choice of architecture (CNNs vs. transformers). Through our comprehensive experiments, we contribute new insights and guidelines, paving the way for future research and discussion.
<div id='section'>Paperid: <span id='pid'>1020, <a href='https://arxiv.org/pdf/2407.13141.pdf' target='_blank'>https://arxiv.org/pdf/2407.13141.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aryan Gulati, Xingjian Dong, Carlos Hurtado, Sarath Shekkizhar, Swabha Swayamdipta, Antonio Ortega
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13141">Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As language models become more general purpose, increased attention needs to be paid to detecting out-of-distribution (OOD) instances, i.e., those not belonging to any of the distributions seen during training. Existing methods for detecting OOD data are computationally complex and storage-intensive. We propose a novel soft clustering approach for OOD detection based on non-negative kernel regression. Our approach greatly reduces computational and space complexities (up to 11x improvement in inference time and 87% reduction in storage requirements) and outperforms existing approaches by up to 4 AUROC points on four different benchmarks. We also introduce an entropy-constrained version of our algorithm, which leads to further reductions in storage requirements (up to 97% lower than comparable approaches) while retaining competitive performance. Our soft clustering approach for OOD detection highlights its potential for detecting tail-end phenomena in extreme-scale data settings.
<div id='section'>Paperid: <span id='pid'>1021, <a href='https://arxiv.org/pdf/2407.11873.pdf' target='_blank'>https://arxiv.org/pdf/2407.11873.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Zozoulenko, Thomas Cass, Lukas Gonon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11873">Infinite-dimensional Mahalanobis Distance with Applications to Kernelized Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Mahalanobis distance is a classical tool used to measure the covariance-adjusted distance between points in $\bbR^d$. In this work, we extend the concept of Mahalanobis distance to separable Banach spaces by reinterpreting it as a Cameron-Martin norm associated with a probability measure. This approach leads to a basis-free, data-driven notion of anomaly distance through the so-called variance norm, which can naturally be estimated using empirical measures of a sample. Our framework generalizes the classical $\bbR^d$, functional $(L^2[0,1])^d$, and kernelized settings; importantly, it incorporates non-injective covariance operators. We prove that the variance norm is invariant under invertible bounded linear transformations of the data, extending previous results which are limited to unitary operators. In the Hilbert space setting, we connect the variance norm to the RKHS of the covariance operator and establish consistency and convergence results for estimation using empirical measures. Using the variance norm, we introduce the notion of a kernelized nearest-neighbour Mahalanobis distance. In an empirical study on 12 real-world data sets, we demonstrate that the kernelized nearest-neighbour Mahalanobis distance outperforms the traditional kernelized Mahalanobis distance for multivariate time series novelty detection, using state-of-the-art time series kernels such as the signature, global alignment, and Volterra reservoir kernels.
<div id='section'>Paperid: <span id='pid'>1022, <a href='https://arxiv.org/pdf/2407.04760.pdf' target='_blank'>https://arxiv.org/pdf/2407.04760.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MZ Naser, Ahmed Z Naser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04760">SPINEX: Similarity-based Predictions with Explainable Neighbors Exploration for Anomaly and Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel anomaly and outlier detection algorithm from the SPINEX (Similarity-based Predictions with Explainable Neighbors Exploration) family. This algorithm leverages the concept of similarity and higher-order interactions across multiple subspaces to identify outliers. A comprehensive set of experiments was conducted to evaluate the performance of SPINEX. This algorithm was examined against 21 commonly used anomaly detection algorithms, namely, namely, Angle-Based Outlier Detection (ABOD), Connectivity-Based Outlier Factor (COF), Copula-Based Outlier Detection (COPOD), ECOD, Elliptic Envelope (EE), Feature Bagging with KNN, Gaussian Mixture Models (GMM), Histogram-based Outlier Score (HBOS), Isolation Forest (IF), Isolation Neural Network Ensemble (INNE), Kernel Density Estimation (KDE), K-Nearest Neighbors (KNN), Lightweight Online Detector of Anomalies (LODA), Linear Model Deviation-based Detector (LMDD), Local Outlier Factor (LOF), Minimum Covariance Determinant (MCD), One-Class SVM (OCSVM), Quadratic MCD (QMCD), Robust Covariance (RC), Stochastic Outlier Selection (SOS), and Subspace Outlier Detection (SOD), and across 39 synthetic and real datasets from various domains and of a variety of dimensions and complexities. Furthermore, a complexity analysis was carried out to examine the complexity of the proposed algorithm. Our results demonstrate that SPINEX achieves superior performance, outperforms commonly used anomaly detection algorithms, and has moderate complexity (e.g., O(n log n d)). More specifically, SPINEX was found to rank at the top of algorithms on the synthetic datasets and the 7th on the real datasets. Finally, a demonstration of the explainability capabilities of SPINEX, along with future research needs, is presented.
<div id='section'>Paperid: <span id='pid'>1023, <a href='https://arxiv.org/pdf/2406.12082.pdf' target='_blank'>https://arxiv.org/pdf/2406.12082.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anna Susmelj, Mael Macuglia, NataÅ¡a Tagasovska, Reto Sutter, Sebastiano Caprara, Jean-Philippe Thiran, Ender Konukoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12082">Uncertainty modeling for fine-tuned implicit functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Implicit functions such as Neural Radiance Fields (NeRFs), occupancy networks, and signed distance functions (SDFs) have become pivotal in computer vision for reconstructing detailed object shapes from sparse views. Achieving optimal performance with these models can be challenging due to the extreme sparsity of inputs and distribution shifts induced by data corruptions. To this end, large, noise-free synthetic datasets can serve as shape priors to help models fill in gaps, but the resulting reconstructions must be approached with caution. Uncertainty estimation is crucial for assessing the quality of these reconstructions, particularly in identifying areas where the model is uncertain about the parts it has inferred from the prior. In this paper, we introduce Dropsembles, a novel method for uncertainty estimation in tuned implicit functions. We demonstrate the efficacy of our approach through a series of experiments, starting with toy examples and progressing to a real-world scenario. Specifically, we train a Convolutional Occupancy Network on synthetic anatomical data and test it on low-resolution MRI segmentations of the lumbar spine. Our results show that Dropsembles achieve the accuracy and calibration levels of deep ensembles but with significantly less computational cost.
<div id='section'>Paperid: <span id='pid'>1024, <a href='https://arxiv.org/pdf/2406.09966.pdf' target='_blank'>https://arxiv.org/pdf/2406.09966.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Constantine Maganaris, Eftychios Protopapadakis, Nikolaos Doulamis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09966">Outlier detection in maritime environments using AIS data and deep recurrent architectures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A methodology based on deep recurrent models for maritime surveillance, over publicly available Automatic Identification System (AIS) data, is presented in this paper. The setup employs a deep Recurrent Neural Network (RNN)-based model, for encoding and reconstructing the observed ships' motion patterns. Our approach is based on a thresholding mechanism, over the calculated errors between observed and reconstructed motion patterns of maritime vessels. Specifically, a deep-learning framework, i.e. an encoder-decoder architecture, is trained using the observed motion patterns, enabling the models to learn and predict the expected trajectory, which will be compared to the effective ones. Our models, particularly the bidirectional GRU with recurrent dropouts, showcased superior performance in capturing the temporal dynamics of maritime data, illustrating the potential of deep learning to enhance maritime surveillance capabilities. Our work lays a solid foundation for future research in this domain, highlighting a path toward improved maritime safety through the innovative application of technology.
<div id='section'>Paperid: <span id='pid'>1025, <a href='https://arxiv.org/pdf/2406.03188.pdf' target='_blank'>https://arxiv.org/pdf/2406.03188.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qutub Syed, Michael Paulitsch, Korbinian Hagn, Neslihan Kose Cihangir, Kay-Ulrich Scholl, Fabian Oboril, Gereon Hinz, Alois Knoll
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03188">Situation Monitor: Diversity-Driven Zero-Shot Out-of-Distribution Detection using Budding Ensemble Architecture for Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Situation Monitor, a novel zero-shot Out-of-Distribution (OOD) detection approach for transformer-based object detection models to enhance reliability in safety-critical machine learning applications such as autonomous driving. The Situation Monitor utilizes the Diversity-based Budding Ensemble Architecture (DBEA) and increases the OOD performance by integrating a diversity loss into the training process on top of the budding ensemble architecture, detecting Far-OOD samples and minimizing false positives on Near-OOD samples. Moreover, utilizing the resulting DBEA increases the model's OOD performance and improves the calibration of confidence scores, particularly concerning the intersection over union of the detected objects. The DBEA model achieves these advancements with a 14% reduction in trainable parameters compared to the vanilla model. This signifies a substantial improvement in efficiency without compromising the model's ability to detect OOD instances and calibrate the confidence scores accurately.
<div id='section'>Paperid: <span id='pid'>1026, <a href='https://arxiv.org/pdf/2404.11599.pdf' target='_blank'>https://arxiv.org/pdf/2404.11599.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>James Harrison, John Willes, Jasper Snoek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.11599">Variational Bayesian Last Layers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a deterministic variational formulation for training Bayesian last layer neural networks. This yields a sampling-free, single-pass model and loss that effectively improves uncertainty estimation. Our variational Bayesian last layer (VBLL) can be trained and evaluated with only quadratic complexity in last layer width, and is thus (nearly) computationally free to add to standard architectures. We experimentally investigate VBLLs, and show that they improve predictive accuracy, calibration, and out of distribution detection over baselines across both regression and classification. Finally, we investigate combining VBLL layers with variational Bayesian feature learning, yielding a lower variance collapsed variational inference method for Bayesian neural networks.
<div id='section'>Paperid: <span id='pid'>1027, <a href='https://arxiv.org/pdf/2404.10124.pdf' target='_blank'>https://arxiv.org/pdf/2404.10124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanjing Wang, Qiang Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10124">Epistemic Uncertainty Quantification For Pre-trained Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Epistemic uncertainty quantification (UQ) identifies where models lack knowledge. Traditional UQ methods, often based on Bayesian neural networks, are not suitable for pre-trained non-Bayesian models. Our study addresses quantifying epistemic uncertainty for any pre-trained model, which does not need the original training data or model modifications and can ensure broad applicability regardless of network architectures or training techniques. Specifically, we propose a gradient-based approach to assess epistemic uncertainty, analyzing the gradients of outputs relative to model parameters, and thereby indicating necessary model adjustments to accurately represent the inputs. We first explore theoretical guarantees of gradient-based methods for epistemic UQ, questioning the view that this uncertainty is only calculable through differences between multiple models. We further improve gradient-driven UQ by using class-specific weights for integrating gradients and emphasizing distinct contributions from neural network layers. Additionally, we enhance UQ accuracy by combining gradient and perturbation methods to refine the gradients. We evaluate our approach on out-of-distribution detection, uncertainty calibration, and active learning, demonstrating its superiority over current state-of-the-art UQ methods for pre-trained models.
<div id='section'>Paperid: <span id='pid'>1028, <a href='https://arxiv.org/pdf/2403.18539.pdf' target='_blank'>https://arxiv.org/pdf/2403.18539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taku Yamagata, Raul Santos-Rodriguez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18539">Safe and Robust Reinforcement Learning: Principles and Practice</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement Learning (RL) has shown remarkable success in solving relatively complex tasks, yet the deployment of RL systems in real-world scenarios poses significant challenges related to safety and robustness. This paper aims to identify and further understand those challenges thorough the exploration of the main dimensions of the safe and robust RL landscape, encompassing algorithmic, ethical, and practical considerations. We conduct a comprehensive review of methodologies and open problems that summarizes the efforts in recent years to address the inherent risks associated with RL applications.
  After discussing and proposing definitions for both safe and robust RL, the paper categorizes existing research works into different algorithmic approaches that enhance the safety and robustness of RL agents. We examine techniques such as uncertainty estimation, optimisation methodologies, exploration-exploitation trade-offs, and adversarial training. Environmental factors, including sim-to-real transfer and domain adaptation, are also scrutinized to understand how RL systems can adapt to diverse and dynamic surroundings. Moreover, human involvement is an integral ingredient of the analysis, acknowledging the broad set of roles that humans can take in this context.
  Importantly, to aid practitioners in navigating the complexities of safe and robust RL implementation, this paper introduces a practical checklist derived from the synthesized literature. The checklist encompasses critical aspects of algorithm design, training environment considerations, and ethical guidelines. It will serve as a resource for developers and policymakers alike to ensure the responsible deployment of RL systems in many application domains.
<div id='section'>Paperid: <span id='pid'>1029, <a href='https://arxiv.org/pdf/2403.18207.pdf' target='_blank'>https://arxiv.org/pdf/2403.18207.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chihiro Noguchi, Toshiaki Ohgushi, Masao Yamanaka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18207">Road Obstacle Detection based on Unknown Objectness Scores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of unknown traffic obstacles is vital to ensure safe autonomous driving. The standard object-detection methods cannot identify unknown objects that are not included under predefined categories. This is because object-detection methods are trained to assign a background label to pixels corresponding to the presence of unknown objects. To address this problem, the pixel-wise anomaly-detection approach has attracted increased research attention. Anomaly-detection techniques, such as uncertainty estimation and perceptual difference from reconstructed images, make it possible to identify pixels of unknown objects as out-of-distribution (OoD) samples. However, when applied to images with many unknowns and complex components, such as driving scenes, these methods often exhibit unstable performance. The purpose of this study is to achieve stable performance for detecting unknown objects by incorporating the object-detection fashions into the pixel-wise anomaly detection methods. To achieve this goal, we adopt a semantic-segmentation network with a sigmoid head that simultaneously provides pixel-wise anomaly scores and objectness scores. Our experimental results show that the objectness scores play an important role in improving the detection performance. Based on these results, we propose a novel anomaly score by integrating these two scores, which we term as unknown objectness score. Quantitative evaluations show that the proposed method outperforms state-of-the-art methods when applied to the publicly available datasets.
<div id='section'>Paperid: <span id='pid'>1030, <a href='https://arxiv.org/pdf/2403.13324.pdf' target='_blank'>https://arxiv.org/pdf/2403.13324.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>K Huang, G Song, Hanwen Su, Jiyan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13324">Out-of-Distribution Detection Using Peer-Class Generated by Large Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical task to ensure the reliability and security of machine learning models deployed in real-world applications. Conventional methods for OOD detection that rely on single-modal information, often struggle to capture the rich variety of OOD instances. The primary difficulty in OOD detection arises when an input image has numerous similarities to a particular class in the in-distribution (ID) dataset, e.g., wolf to dog, causing the model to misclassify it. Nevertheless, it may be easy to distinguish these classes in the semantic domain. To this end, in this paper, a novel method called ODPC is proposed, in which specific prompts to generate OOD peer classes of ID semantics are designed by a large language model as an auxiliary modality to facilitate detection. Moreover, a contrastive loss based on OOD peer classes is devised to learn compact representations of ID classes and improve the clarity of boundaries between different classes. The extensive experiments on five benchmark datasets show that the method we propose can yield state-of-the-art results.
<div id='section'>Paperid: <span id='pid'>1031, <a href='https://arxiv.org/pdf/2403.09141.pdf' target='_blank'>https://arxiv.org/pdf/2403.09141.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gleb Radchenko, Victoria Andrea Fill
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.09141">Uncertainty Estimation in Multi-Agent Distributed Learning for AI-Enabled Edge Devices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Initially considered as low-power units with limited autonomous processing, Edge IoT devices have seen a paradigm shift with the introduction of FPGAs and AI accelerators. This advancement has vastly amplified their computational capabilities, emphasizing the practicality of edge AI. Such progress introduces new challenges of optimizing AI tasks for the limitations of energy and network resources typical in Edge computing environments. Our study explores methods that enable distributed data processing through AI-enabled edge devices, enhancing collaborative learning capabilities. A key focus of our research is the challenge of determining confidence levels in learning outcomes, considering the spatial and temporal variability of data sets encountered by independent agents. To address this issue, we investigate the application of Bayesian neural networks, proposing a novel approach to manage uncertainty in distributed learning environments.
<div id='section'>Paperid: <span id='pid'>1032, <a href='https://arxiv.org/pdf/2402.14892.pdf' target='_blank'>https://arxiv.org/pdf/2402.14892.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paola Arrubarrena, Maud Lemercier, Bojan Nikolic, Terry Lyons, Thomas Cass
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14892">Novelty Detection on Radio Astronomy Data using Signatures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce SigNova, a new semi-supervised framework for detecting anomalies in streamed data. While our initial examples focus on detecting radio-frequency interference (RFI) in digitized signals within the field of radio astronomy, it is important to note that SigNova's applicability extends to any type of streamed data. The framework comprises three primary components. Firstly, we use the signature transform to extract a canonical collection of summary statistics from observational sequences. This allows us to represent variable-length visibility samples as finite-dimensional feature vectors. Secondly, each feature vector is assigned a novelty score, calculated as the Mahalanobis distance to its nearest neighbor in an RFI-free training set. By thresholding these scores we identify observation ranges that deviate from the expected behavior of RFI-free visibility samples without relying on stringent distributional assumptions. Thirdly, we integrate this anomaly detector with Pysegments, a segmentation algorithm, to localize consecutive observations contaminated with RFI, if any. This approach provides a compelling alternative to classical windowing techniques commonly used for RFI detection. Importantly, the complexity of our algorithm depends on the RFI pattern rather than on the size of the observation window. We demonstrate how SigNova improves the detection of various types of RFI (e.g., broadband and narrowband) in time-frequency visibility data. We validate our framework on the Murchison Widefield Array (MWA) telescope and simulated data and the Hydrogen Epoch of Reionization Array (HERA).
<div id='section'>Paperid: <span id='pid'>1033, <a href='https://arxiv.org/pdf/2402.14080.pdf' target='_blank'>https://arxiv.org/pdf/2402.14080.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Nolte, Souparno Ghosh, Ranadip Pal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14080">Efficient Normalized Conformal Prediction and Uncertainty Quantification for Anti-Cancer Drug Sensitivity Prediction with Deep Regression Forests</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models are being adopted and applied on various critical decision-making tasks, yet they are trained to provide point predictions without providing degrees of confidence. The trustworthiness of deep learning models can be increased if paired with uncertainty estimations. Conformal Prediction has emerged as a promising method to pair machine learning models with prediction intervals, allowing for a view of the model's uncertainty. However, popular uncertainty estimation methods for conformal prediction fail to provide heteroskedastic intervals that are equally accurate for all samples. In this paper, we propose a method to estimate the uncertainty of each sample by calculating the variance obtained from a Deep Regression Forest. We show that the deep regression forest variance improves the efficiency and coverage of normalized inductive conformal prediction on a drug response prediction task.
<div id='section'>Paperid: <span id='pid'>1034, <a href='https://arxiv.org/pdf/2402.03478.pdf' target='_blank'>https://arxiv.org/pdf/2402.03478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew A. Chan, Maria J. Molina, Christopher A. Metzler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03478">Estimating Epistemic and Aleatoric Uncertainty with a Single Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating and disentangling epistemic uncertainty, uncertainty that is reducible with more training data, and aleatoric uncertainty, uncertainty that is inherent to the task at hand, is critically important when applying machine learning to high-stakes applications such as medical imaging and weather forecasting. Conditional diffusion models' breakthrough ability to accurately and efficiently sample from the posterior distribution of a dataset now makes uncertainty estimation conceptually straightforward: One need only train and sample from a large ensemble of diffusion models. Unfortunately, training such an ensemble becomes computationally intractable as the complexity of the model architecture grows. In this work we introduce a new approach to ensembling, hyper-diffusion models (HyperDM), which allows one to accurately estimate both epistemic and aleatoric uncertainty with a single model. Unlike existing single-model uncertainty methods like Monte-Carlo dropout and Bayesian neural networks, HyperDM offers prediction accuracy on par with, and in some cases superior to, multi-model ensembles. Furthermore, our proposed approach scales to modern network architectures such as Attention U-Net and yields more accurate uncertainty estimates compared to existing methods. We validate our method on two distinct real-world tasks: x-ray computed tomography reconstruction and weather temperature forecasting.
<div id='section'>Paperid: <span id='pid'>1035, <a href='https://arxiv.org/pdf/2401.12129.pdf' target='_blank'>https://arxiv.org/pdf/2401.12129.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Will LeVine, Benjamin Pikus, Jacob Phillips, Berk Norman, Fernando Amat Gil, Sean Hendryx
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.12129">Out-of-Distribution Detection & Applications With Ablated Learned Temperature Energy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As deep neural networks become adopted in high-stakes domains, it is crucial to identify when inference inputs are Out-of-Distribution (OOD) so that users can be alerted of likely drops in performance and calibration despite high confidence -- ultimately to know when networks' decisions (and their uncertainty in those decisions) should be trusted. In this paper we introduce Ablated Learned Temperature Energy (or "AbeT" for short), an OOD detection method which lowers the False Positive Rate at 95\% True Positive Rate (FPR@95) by $43.43\%$ in classification compared to state of the art without training networks in multiple stages or requiring hyperparameters or test-time backward passes. We additionally provide empirical insights as to why our model learns to distinguish between In-Distribution (ID) and OOD samples while only being explicitly trained on ID samples via exposure to misclassified ID examples at training time. Lastly, we show the efficacy of our method in identifying predicted bounding boxes and pixels corresponding to OOD objects in object detection and semantic segmentation, respectively -- with an AUROC increase of $5.15\%$ in object detection and both a decrease in FPR@95 of $41.48\%$ and an increase in AUPRC of $34.20\%$ in semantic segmentation compared to previous state of the art.
<div id='section'>Paperid: <span id='pid'>1036, <a href='https://arxiv.org/pdf/2512.11052.pdf' target='_blank'>https://arxiv.org/pdf/2512.11052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joe Suk, Samory Kpotufe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.11052">An Efficient Variant of One-Class SVM with Lifelong Online Learning Guarantees</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study outlier (a.k.a., anomaly) detection for single-pass non-stationary streaming data. In the well-studied offline or batch outlier detection problem, traditional methods such as kernel One-Class SVM (OCSVM) are both computationally heavy and prone to large false-negative (Type II) errors under non-stationarity. To remedy this, we introduce SONAR, an efficient SGD-based OCSVM solver with strongly convex regularization. We show novel theoretical guarantees on the Type I/II errors of SONAR, superior to those known for OCSVM, and further prove that SONAR ensures favorable lifelong learning guarantees under benign distribution shifts. In the more challenging problem of adversarial non-stationary data, we show that SONAR can be used within an ensemble method and equipped with changepoint detection to achieve adaptive guarantees, ensuring small Type I/II errors on each phase of data. We validate our theoretical findings on synthetic and real-world datasets.
<div id='section'>Paperid: <span id='pid'>1037, <a href='https://arxiv.org/pdf/2512.08445.pdf' target='_blank'>https://arxiv.org/pdf/2512.08445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Madhav Gupta, Vishak Prasad C, Ganesh Ramakrishnan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.08445">Uncertainty-Aware Subset Selection for Robust Visual Explainability under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Subset selection-based methods are widely used to explain deep vision models: they attribute predictions by highlighting the most influential image regions and support object-level explanations. While these methods perform well in in-distribution (ID) settings, their behavior under out-of-distribution (OOD) conditions remains poorly understood. Through extensive experiments across multiple ID-OOD sets, we find that reliability of the existing subset based methods degrades markedly, yielding redundant, unstable, and uncertainty-sensitive explanations. To address these shortcomings, we introduce a framework that combines submodular subset selection with layer-wise, gradient-based uncertainty estimation to improve robustness and fidelity without requiring additional training or auxiliary models. Our approach estimates uncertainty via adaptive weight perturbations and uses these estimates to guide submodular optimization, ensuring diverse and informative subset selection. Empirical evaluations show that, beyond mitigating the weaknesses of existing methods under OOD scenarios, our framework also yields improvements in ID settings. These findings highlight limitations of current subset-based approaches and demonstrate how uncertainty-driven optimization can enhance attribution and object-level interpretability, paving the way for more transparent and trustworthy AI in real-world vision applications.
<div id='section'>Paperid: <span id='pid'>1038, <a href='https://arxiv.org/pdf/2511.22959.pdf' target='_blank'>https://arxiv.org/pdf/2511.22959.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minh Duc Vu, Mingshuo Liu, Doudou Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.22959">A Trainable Centrality Framework for Modern Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Measuring how central or typical a data point is underpins robust estimation, ranking, and outlier detection, but classical depth notions become expensive and unstable in high dimensions and are hard to extend beyond Euclidean data. We introduce Fused Unified centrality Score Estimation (FUSE), a neural centrality framework that operates on top of arbitrary representations. FUSE combines a global head, trained from pairwise distance-based comparisons to learn an anchor-free centrality score, with a local head, trained by denoising score matching to approximate a smoothed log-density potential. A single parameter between 0 and 1 interpolates between these calibrated signals, yielding depth-like centrality from different views via one forward pass. Across synthetic distributions, real images, time series, and text data, and standard outlier detection benchmarks, FUSE recovers meaningful classical ordering, reveals multi-scale geometric structures, and attains competitive performance with strong classical baselines while remaining simple and efficient.
<div id='section'>Paperid: <span id='pid'>1039, <a href='https://arxiv.org/pdf/2511.22225.pdf' target='_blank'>https://arxiv.org/pdf/2511.22225.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Aguirre, Simay Atasoy Bingöl, Heiko Hamann, Jonas Kuckling
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.22225">Bayesian Decentralized Decision-making for Multi-Robot Systems: Sample-efficient Estimation of Event Rates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective collective decision-making in swarm robotics often requires balancing exploration, communication and individual uncertainty estimation, especially in hazardous environments where direct measurements are limited or costly. We propose a decentralized Bayesian framework that enables a swarm of simple robots to identify the safer of two areas, each characterized by an unknown rate of hazardous events governed by a Poisson process. Robots employ a conjugate prior to gradually predict the times between events and derive confidence estimates to adapt their behavior. Our simulation results show that the robot swarm consistently chooses the correct area while reducing exposure to hazardous events by being sample-efficient. Compared to baseline heuristics, our proposed approach shows better performance in terms of safety and speed of convergence. The proposed scenario has potential to extend the current set of benchmarks in collective decision-making and our method has applications in adaptive risk-aware sampling and exploration in hazardous, dynamic environments.
<div id='section'>Paperid: <span id='pid'>1040, <a href='https://arxiv.org/pdf/2511.21566.pdf' target='_blank'>https://arxiv.org/pdf/2511.21566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Amirahmadi, Gökçe Geylan, Leonardo De Maria, Farzaneh Etminani, Mattias Ohlsson, Alessandro Tibo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.21566">A decoupled alignment kernel for peptide membrane permeability predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cyclic peptides are promising modalities for targeting intracellular sites; however, cell-membrane permeability remains a key bottleneck, exacerbated by limited public data and the need for well-calibrated uncertainty. Instead of relying on data-eager complex deep learning architecture, we propose a monomer-aware decoupled global alignment kernel (MD-GAK), which couples chemically meaningful residue-residue similarity with sequence alignment while decoupling local matches from gap penalties. MD-GAK is a relatively simple kernel. To further demonstrate the robustness of our framework, we also introduce a variant, PMD-GAK, which incorporates a triangular positional prior. As we will show in the experimental section, PMD-GAK can offer additional advantages over MD-GAK, particularly in reducing calibration errors. Since our focus is on uncertainty estimation, we use Gaussian Processes as the predictive model, as both MD-GAK and PMD-GAK can be directly applied within this framework. We demonstrate the effectiveness of our methods through an extensive set of experiments, comparing our fully reproducible approach against state-of-the-art models, and show that it outperforms them across all metrics.
<div id='section'>Paperid: <span id='pid'>1041, <a href='https://arxiv.org/pdf/2511.18214.pdf' target='_blank'>https://arxiv.org/pdf/2511.18214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthijs van der Lende, Juan Cardenas-Cartagena
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.18214">Deep Gaussian Process Proximal Policy Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation for Reinforcement Learning (RL) is a critical component in control tasks where agents must balance safe exploration and efficient learning. While deep neural networks have enabled breakthroughs in RL, they often lack calibrated uncertainty estimates. We introduce Deep Gaussian Process Proximal Policy Optimization (GPPO), a scalable, model-free actor-critic algorithm that leverages Deep Gaussian Processes (DGPs) to approximate both the policy and value function. GPPO maintains competitive performance with respect to Proximal Policy Optimization on standard high-dimensional continuous control benchmarks while providing well-calibrated uncertainty estimates that can inform safer and more effective exploration.
<div id='section'>Paperid: <span id='pid'>1042, <a href='https://arxiv.org/pdf/2511.17219.pdf' target='_blank'>https://arxiv.org/pdf/2511.17219.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomas Javurek, Michal Gregor, Sebastian Kula, Marian Simko
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.17219">DelTriC: A Novel Clustering Method with Accurate Outlier</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The paper introduces DelTriC (Delaunay Triangulation Clustering), a clustering algorithm which integrates PCA/UMAP-based projection, Delaunay triangulation, and a novel back-projection mechanism to form clusters in the original high-dimensional space. DelTriC decouples neighborhood construction from decision-making by first triangulating in a low-dimensional proxy to index local adjacency, and then back-projecting to the original space to perform robust edge pruning, merging, and anomaly detection. DelTriC can outperform traditional methods such as k-means, DBSCAN, and HDBSCAN in many scenarios; it is both scalable and accurate, and it also significantly improves outlier detection.
<div id='section'>Paperid: <span id='pid'>1043, <a href='https://arxiv.org/pdf/2511.15551.pdf' target='_blank'>https://arxiv.org/pdf/2511.15551.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yukun Du, Haiyue Yu, Xiaotong Xie, Yan Zheng, Lixin Zhan, Yudong Du, Chongshuang Hu, Boxuan Wang, Jiang Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.15551">Meta-Black-Box Optimization with Bi-Space Landscape Analysis and Dual-Control Mechanism for SAEA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Surrogate-Assisted Evolutionary Algorithms (SAEAs) are widely used for expensive Black-Box Optimization. However, their reliance on rigid, manually designed components such as infill criteria and evolutionary strategies during the search process limits their flexibility across tasks. To address these limitations, we propose Dual-Control Bi-Space Surrogate-Assisted Evolutionary Algorithm (DB-SAEA), a Meta-Black-Box Optimization (MetaBBO) framework tailored for multi-objective problems. DB-SAEA learns a meta-policy that jointly regulates candidate generation and infill criterion selection, enabling dual control. The bi-space Exploratory Landscape Analysis (ELA) module in DB-SAEA adopts an attention-based architecture to capture optimization states from both true and surrogate evaluation spaces, while ensuring scalability across problem dimensions, population sizes, and objectives. Additionally, we integrate TabPFN as the surrogate model for accurate and efficient prediction with uncertainty estimation. The framework is trained via reinforcement learning, leveraging parallel sampling and centralized training to enhance efficiency and transferability across tasks. Experimental results demonstrate that DB-SAEA not only outperforms state-of-the-art baselines across diverse benchmarks, but also exhibits strong zero-shot transfer to unseen tasks with higher-dimensional settings. This work introduces the first MetaBBO framework with dual-level control over SAEAs and a bi-space ELA that captures surrogate model information.
<div id='section'>Paperid: <span id='pid'>1044, <a href='https://arxiv.org/pdf/2511.11934.pdf' target='_blank'>https://arxiv.org/pdf/2511.11934.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>C. César Claros Olivares, Austin J. Brockmeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.11934">A Systematic Analysis of Out-of-Distribution Detection Under Representation and Training Paradigm Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a systematic comparison of out-of-distribution (OOD) detection methods across CLIP-stratified regimes using AURC and AUGRC as primary metrics. Experiments cover two representation paradigms: CNNs trained from scratch and a fine-tuned Vision Transformer (ViT), evaluated on CIFAR-10/100, SuperCIFAR-100, and TinyImageNet. Using a multiple-comparison-controlled, rank-based pipeline (Friedman test with Conover-Holm post-hoc) and Bron-Kerbosch cliques, we find that the learned feature space largely determines OOD efficacy. For both CNNs and ViTs, probabilistic scores (e.g., MSR, GEN) dominate misclassification (ID) detection. Under stronger shifts, geometry-aware scores (e.g., NNGuide, fDBD, CTM) prevail on CNNs, whereas on ViTs GradNorm and KPCA Reconstruction Error remain consistently competitive. We further show a class-count-dependent trade-off for Monte-Carlo Dropout (MCD) and that a simple PCA projection improves several detectors. These results support a representation-centric view of OOD detection and provide statistically grounded guidance for method selection under distribution shift.
<div id='section'>Paperid: <span id='pid'>1045, <a href='https://arxiv.org/pdf/2511.10296.pdf' target='_blank'>https://arxiv.org/pdf/2511.10296.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florian Ebmeier, Nicole Ludwig, Jannik Thuemmel, Georg Martius, Volker H. Franz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.10296">Fault Detection in Solar Thermal Systems using Probabilistic Reconstructions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solar thermal systems (STS) present a promising avenue for low-carbon heat generation, with a well-running system providing heat at minimal cost and carbon emissions. However, STS can exhibit faults due to improper installation, maintenance, or operation, often resulting in a substantial reduction in efficiency or even damage to the system. As monitoring at the individual level is economically prohibitive for small-scale systems, automated monitoring and fault detection should be used to address such issues. Recent advances in data-driven anomaly detection, particularly in time series analysis, offer a cost-effective solution by leveraging existing sensors to identify abnormal system states. Here, we propose a probabilistic reconstruction-based framework for anomaly detection. We evaluate our method on the publicly available PaSTS dataset of operational domestic STS, which features real-world complexities and diverse fault types. Our experiments show that reconstruction-based methods can detect faults in domestic STS both qualitatively and quantitatively, while generalizing to previously unseen systems. We also demonstrate that our model outperforms both simple and more complex deep learning baselines. Additionally, we show that heteroscedastic uncertainty estimation is essential to fault detection performance. Finally, we discuss the engineering overhead required to unlock these improvements and make a case for simple deep learning models.
<div id='section'>Paperid: <span id='pid'>1046, <a href='https://arxiv.org/pdf/2511.09178.pdf' target='_blank'>https://arxiv.org/pdf/2511.09178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Niclas Flehmig, Mary Ann Lundteigen, Shen Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.09178">Perspectives on a Reliability Monitoring Framework for Agentic AI Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The implementation of agentic AI systems has the potential of providing more helpful AI systems in a variety of applications. These systems work autonomously towards a defined goal with reduced external control. Despite their potential, one of their flaws is the insufficient reliability which makes them especially unsuitable for high-risk domains such as healthcare or process industry. Unreliable systems pose a risk in terms of unexpected behavior during operation and mitigation techniques are needed. In this work, we derive the main reliability challenges of agentic AI systems during operation based on their characteristics. We draw the connection to traditional AI systems and formulate a fundamental reliability challenge during operation which is inherent to traditional and agentic AI systems. As our main contribution, we propose a two-layered reliability monitoring framework for agentic AI systems which consists of a out-of-distribution detection layer for novel inputs and AI transparency layer to reveal internal operations. This two-layered monitoring approach gives a human operator the decision support which is needed to decide whether an output is potential unreliable or not and intervene. This framework provides a foundation for developing mitigation techniques to reduce risk stemming from uncertain reliability during operation.
<div id='section'>Paperid: <span id='pid'>1047, <a href='https://arxiv.org/pdf/2510.23327.pdf' target='_blank'>https://arxiv.org/pdf/2510.23327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Hossein Jafari Naeimi, Ali Norouzi, Athena Abdi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.23327">GRAD: Real-Time Gated Recurrent Anomaly Detection in Autonomous Vehicle Sensors Using Reinforced EMA and Multi-Stage Sliding Window Techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces GRAD, a real-time anomaly detection method for autonomous vehicle sensors that integrates statistical analysis and deep learning to ensure the reliability of sensor data. The proposed approach combines the Reinforced Exponential Moving Average (REMA), which adapts smoothing factors and thresholding for outlier detection, with the Multi-Stage Sliding Window (MS-SW) technique for capturing both short- and long-term patterns. These features are processed using a lightweight Gated Recurrent Unit (GRU) model, which detects and classifies anomalies based on bias types, while a recovery module restores damaged sensor data to ensure continuous system operation. GRAD has a lightweight architecture consisting of two layers of GRU with a limited number of neurons that make it appropriate for real-time applications while maintaining high detection accuracy. The GRAD framework achieved remarkable performance in anomaly detection and classification. The model demonstrated an overall F1-score of 97.6% for abnormal data and 99.4% for normal data, signifying its high accuracy in distinguishing between normal and anomalous sensor data. Regarding the anomaly classification, GRAD successfully categorized different anomaly types with high precision, enabling the recovery module to accurately restore damaged sensor data. Relative to analogous studies, GRAD surpasses current models by attaining a balance between elevated detection accuracy and diminished computational expense. These results demonstrate GRAD's potential as a reliable and efficient solution for real-time anomaly detection in autonomous vehicle systems, guaranteeing safe vehicle operation with minimal computational overhead.
<div id='section'>Paperid: <span id='pid'>1048, <a href='https://arxiv.org/pdf/2510.21153.pdf' target='_blank'>https://arxiv.org/pdf/2510.21153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lianghong Chen, Dongkyu Eugene Kim, Mike Domaratzki, Pingzhao Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.21153">Uncertainty-Aware Multi-Objective Reinforcement Learning-Guided Diffusion Models for 3D De Novo Molecular Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing de novo 3D molecules with desirable properties remains a fundamental challenge in drug discovery and molecular engineering. While diffusion models have demonstrated remarkable capabilities in generating high-quality 3D molecular structures, they often struggle to effectively control complex multi-objective constraints critical for real-world applications. In this study, we propose an uncertainty-aware Reinforcement Learning (RL) framework to guide the optimization of 3D molecular diffusion models toward multiple property objectives while enhancing the overall quality of the generated molecules. Our method leverages surrogate models with predictive uncertainty estimation to dynamically shape reward functions, facilitating balance across multiple optimization objectives. We comprehensively evaluate our framework across three benchmark datasets and multiple diffusion model architectures, consistently outperforming baselines for molecular quality and property optimization. Additionally, Molecular Dynamics (MD) simulations and ADMET profiling of top generated candidates indicate promising drug-like behavior and binding stability, comparable to known Epidermal Growth Factor Receptor (EGFR) inhibitors. Our results demonstrate the strong potential of RL-guided generative diffusion models for advancing automated molecular design.
<div id='section'>Paperid: <span id='pid'>1049, <a href='https://arxiv.org/pdf/2510.20460.pdf' target='_blank'>https://arxiv.org/pdf/2510.20460.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christian Hobelsberger, Theresa Winner, Andreas Nawroth, Oliver Mitevski, Anna-Carolina Haensch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.20460">Systematic Evaluation of Uncertainty Estimation Methods in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) produce outputs with varying levels of uncertainty, and, just as often, varying levels of correctness; making their practical reliability far from guaranteed. To quantify this uncertainty, we systematically evaluate four approaches for confidence estimation in LLM outputs: VCE, MSP, Sample Consistency, and CoCoA (Vashurin et al., 2025). For the evaluation of the approaches, we conduct experiments on four question-answering tasks using a state-of-the-art open-source LLM. Our results show that each uncertainty metric captures a different facet of model confidence and that the hybrid CoCoA approach yields the best reliability overall, improving both calibration and discrimination of correct answers. We discuss the trade-offs of each method and provide recommendations for selecting uncertainty measures in LLM applications.
<div id='section'>Paperid: <span id='pid'>1050, <a href='https://arxiv.org/pdf/2508.15737.pdf' target='_blank'>https://arxiv.org/pdf/2508.15737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joonas JÃ¤rve, Karl Kaspar Haavel, Meelis Kull
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15737">Probability Density from Latent Diffusion Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite rapid advances in AI, safety remains the main bottleneck to deploying machine-learning systems. A critical safety component is out-of-distribution detection: given an input, decide whether it comes from the same distribution as the training data. In generative models, the most natural OOD score is the data likelihood. Actually, under the assumption of uniformly distributed OOD data, the likelihood is even the optimal OOD detector, as we show in this work. However, earlier work reported that likelihood often fails in practice, raising doubts about its usefulness. We explore whether, in practice, the representation space also suffers from the inability to learn good density estimation for OOD detection, or if it is merely a problem of the pixel space typically used in generative models. To test this, we trained a Variational Diffusion Model not on images, but on the representation space of a pre-trained ResNet-18 to assess the performance of our likelihood-based detector in comparison to state-of-the-art methods from the OpenOOD suite.
<div id='section'>Paperid: <span id='pid'>1051, <a href='https://arxiv.org/pdf/2508.15119.pdf' target='_blank'>https://arxiv.org/pdf/2508.15119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rachel Ma, Jingyi Qu, Andreea Bobu, Dylan Hadfield-Menell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15119">Open-Universe Assistance Games</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Embodied AI agents must infer and act in an interpretable way on diverse human goals and preferences that are not predefined. To formalize this setting, we introduce Open-Universe Assistance Games (OU-AGs), a framework where the agent must reason over an unbounded and evolving space of possible goals. In this context, we introduce GOOD (GOals from Open-ended Dialogue), a data-efficient, online method that extracts goals in the form of natural language during an interaction with a human, and infers a distribution over natural language goals. GOOD prompts an LLM to simulate users with different complex intents, using its responses to perform probabilistic inference over candidate goals. This approach enables rich goal representations and uncertainty estimation without requiring large offline datasets. We evaluate GOOD in a text-based grocery shopping domain and in a text-operated simulated household robotics environment (AI2Thor), using synthetic user profiles. Our method outperforms a baseline without explicit goal tracking, as confirmed by both LLM-based and human evaluations.
<div id='section'>Paperid: <span id='pid'>1052, <a href='https://arxiv.org/pdf/2508.06096.pdf' target='_blank'>https://arxiv.org/pdf/2508.06096.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric Jing, Abdeslam Boularias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06096">Bounding Distributional Shifts in World Modeling through Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent work on visual world models shows significant promise in latent state dynamics obtained from pre-trained image backbones. However, most of the current approaches are sensitive to training quality, requiring near-complete coverage of the action and state space during training to prevent divergence during inference. To make a model-based planning algorithm more robust to the quality of the learned world model, we propose in this work to use a variational autoencoder as a novelty detector to ensure that proposed action trajectories during planning do not cause the learned model to deviate from the training data distribution. To evaluate the effectiveness of this approach, a series of experiments in challenging simulated robot environments was carried out, with the proposed method incorporated into a model-predictive control policy loop extending the DINO-WM architecture. The results clearly show that the proposed method improves over state-of-the-art solutions in terms of data efficiency.
<div id='section'>Paperid: <span id='pid'>1053, <a href='https://arxiv.org/pdf/2507.21521.pdf' target='_blank'>https://arxiv.org/pdf/2507.21521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Athmanarayanan Lakshmi Narayanan, Amrutha Machireddy, Ranganath Krishnan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21521">Optimizing Active Learning in Vision-Language Models via Parameter-Efficient Uncertainty Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active Learning (AL) has emerged as a powerful approach for minimizing labeling costs by selectively sampling the most informative data for neural network model development. Effective AL for large-scale vision-language models necessitates addressing challenges in uncertainty estimation and efficient sampling given the vast number of parameters involved. In this work, we introduce a novel parameter-efficient learning methodology that incorporates uncertainty calibration loss within the AL framework. We propose a differentiable loss function that promotes uncertainty calibration for effectively selecting fewer and most informative data samples for fine-tuning. Through extensive experiments across several datasets and vision backbones, we demonstrate that our solution can match and exceed the performance of complex feature-based sampling techniques while being computationally very efficient. Additionally, we investigate the efficacy of Prompt learning versus Low-rank adaptation (LoRA) in sample selection, providing a detailed comparative analysis of these methods in the context of efficient AL.
<div id='section'>Paperid: <span id='pid'>1054, <a href='https://arxiv.org/pdf/2507.18106.pdf' target='_blank'>https://arxiv.org/pdf/2507.18106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JinYoung Kim, DaeUng Jo, Kimin Yun, Jeonghyo Song, Youngjoon Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18106">Distributional Uncertainty for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating uncertainty from deep neural networks is a widely used approach for detecting out-of-distribution (OoD) samples, which typically exhibit high predictive uncertainty. However, conventional methods such as Monte Carlo (MC) Dropout often focus solely on either model or data uncertainty, failing to align with the semantic objective of OoD detection. To address this, we propose the Free-Energy Posterior Network, a novel framework that jointly models distributional uncertainty and identifying OoD and misclassified regions using free energy. Our method introduces two key contributions: (1) a free-energy-based density estimator parameterized by a Beta distribution, which enables fine-grained uncertainty estimation near ambiguous or unseen regions; and (2) a loss integrated within a posterior network, allowing direct uncertainty estimation from learned parameters without requiring stochastic sampling. By integrating our approach with the residual prediction branch (RPL) framework, the proposed method goes beyond post-hoc energy thresholding and enables the network to learn OoD regions by leveraging the variance of the Beta distribution, resulting in a semantically meaningful and computationally efficient solution for uncertainty-aware segmentation. We validate the effectiveness of our method on challenging real-world benchmarks, including Fishyscapes, RoadAnomaly, and Segment-Me-If-You-Can.
<div id='section'>Paperid: <span id='pid'>1055, <a href='https://arxiv.org/pdf/2507.16424.pdf' target='_blank'>https://arxiv.org/pdf/2507.16424.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hui Xiang, Jinqiao Shi, Ting Zhang, Xiaojie Zhao, Yong Liu, Yong Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16424">PromptAL: Sample-Aware Dynamic Soft Prompts for Few-Shot Active Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active learning (AL) aims to optimize model training and reduce annotation costs by selecting the most informative samples for labeling. Typically, AL methods rely on the empirical distribution of labeled data to define the decision boundary and perform uncertainty or diversity estimation, subsequently identifying potential high-quality samples. In few-shot scenarios, the empirical distribution often diverges significantly from the target distribution, causing the decision boundary to shift away from its optimal position. However, existing methods overlook the role of unlabeled samples in enhancing the empirical distribution to better align with the target distribution, resulting in a suboptimal decision boundary and the selection of samples that inadequately represent the target distribution. To address this, we propose a hybrid AL framework, termed \textbf{PromptAL} (Sample-Aware Dynamic Soft \textbf{Prompts} for Few-Shot \textbf{A}ctive \textbf{L}earning). This framework accounts for the contribution of each unlabeled data point in aligning the current empirical distribution with the target distribution, thereby optimizing the decision boundary. Specifically, PromptAL first leverages unlabeled data to construct sample-aware dynamic soft prompts that adjust the model's predictive distribution and decision boundary. Subsequently, based on the adjusted decision boundary, it integrates uncertainty estimation with both global and local diversity to select high-quality samples that more accurately represent the target distribution. Experimental results on six in-domain and three out-of-domain datasets show that PromptAL achieves superior performance over nine baselines. Our codebase is openly accessible.
<div id='section'>Paperid: <span id='pid'>1056, <a href='https://arxiv.org/pdf/2507.07714.pdf' target='_blank'>https://arxiv.org/pdf/2507.07714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julio Garrido, Javier Vales, Diego Silva-MuÃ±iz, Enrique Riveiro, Pablo LÃ³pez-Matencio, JosuÃ© Rivera-Andrade
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07714">Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cable-Driven Parallel Robots (CDPRs) are increasingly used for load manipulation tasks involving predefined toolpaths with intermediate stops. At each stop, where the platform maintains a fixed pose and the motors keep the cables under tension, the system must evaluate whether it is safe to proceed by detecting anomalies that could compromise performance (e.g., wind gusts or cable impacts). This paper investigates whether anomalies can be detected using only motor torque data, without additional sensors. It introduces an adaptive, unsupervised outlier detection algorithm based on Gaussian Mixture Models (GMMs) to identify anomalies from torque signals. The method starts with a brief calibration period, just a few seconds, during which a GMM is fit on known anomaly-free data. Real-time torque measurements are then evaluated using Mahalanobis distance from the GMM, with statistically derived thresholds triggering anomaly flags. Model parameters are periodically updated using the latest segments identified as anomaly-free to adapt to changing conditions. Validation includes 14 long-duration test sessions simulating varied wind intensities. The proposed method achieves a 100% true positive rate and 95.4% average true negative rate, with 1-second detection latency. Comparative evaluation against power threshold and non-adaptive GMM methods indicates higher robustness to drift and environmental variation.
<div id='section'>Paperid: <span id='pid'>1057, <a href='https://arxiv.org/pdf/2507.06624.pdf' target='_blank'>https://arxiv.org/pdf/2507.06624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dazhi Fu, Jicong Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06624">UniOD: A Universal Model for Outlier Detection across Diverse Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) seeks to distinguish inliers and outliers in completely unlabeled datasets and plays a vital role in science and engineering. Most existing OD methods require troublesome dataset-specific hyperparameter tuning and costly model training before they can be deployed to identify outliers. In this work, we propose UniOD, a universal OD framework that leverages labeled datasets to train a single model capable of detecting outliers of datasets from diverse domains. Specifically, UniOD converts each dataset into multiple graphs, produces consistent node features, and frames outlier detection as a node-classification task, and is able to generalize to unseen domains. As a result, UniOD avoids effort on model selection and hyperparameter tuning, reduces computational cost, and effectively utilizes the knowledge from historical datasets, which improves the convenience and accuracy in real applications. We evaluate UniOD on 15 benchmark OD datasets against 15 state-of-the-art baselines, demonstrating its effectiveness.
<div id='section'>Paperid: <span id='pid'>1058, <a href='https://arxiv.org/pdf/2507.01541.pdf' target='_blank'>https://arxiv.org/pdf/2507.01541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ãlvaro Zaera, Diana Nicoleta Popa, Ivan Sekulic, Paolo Rosso
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01541">Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-scope (OOS) intent detection is a critical challenge in task-oriented dialogue systems (TODS), as it ensures robustness to unseen and ambiguous queries. In this work, we propose a novel but simple modular framework that combines uncertainty modeling with fine-tuned large language models (LLMs) for efficient and accurate OOS detection. The first step applies uncertainty estimation to the output of an in-scope intent detection classifier, which is currently deployed in a real-world TODS handling tens of thousands of user interactions daily. The second step then leverages an emerging LLM-based approach, where a fine-tuned LLM is triggered to make a final decision on instances with high uncertainty. Unlike prior approaches, our method effectively balances computational efficiency and performance, combining traditional approaches with LLMs and yielding state-of-the-art results on key OOS detection benchmarks, including real-world OOS data acquired from a deployed TODS.
<div id='section'>Paperid: <span id='pid'>1059, <a href='https://arxiv.org/pdf/2507.00866.pdf' target='_blank'>https://arxiv.org/pdf/2507.00866.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas Chris Ferrao, Dickson Dias, Pranav Naik, Glory D'Cruz, Anish Naik, Siya Khandeparkar, Manisha Gokuldas Fal Dessai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00866">Template-Fitting Meets Deep Learning: Redshift Estimation Using Physics-Guided Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate photometric redshift estimation is critical for observational cosmology, especially in large-scale surveys where spectroscopic measurements are impractical. Traditional approaches include template fitting and machine learning, each with distinct strengths and limitations. We present a hybrid method that integrates template fitting with deep learning using physics-guided neural networks. By embedding spectral energy distribution templates into the network architecture, our model encodes physical priors into the training process. The system employs a multimodal design, incorporating cross-attention mechanisms to fuse photometric and image data, along with Bayesian layers for uncertainty estimation. We evaluate our model on the publicly available PREML dataset, which includes approximately 400,000 galaxies from the Hyper Suprime-Cam PDR3 release, with 5-band photometry, multi-band imaging, and spectroscopic redshifts. Our approach achieves an RMS error of 0.0507, a 3-sigma catastrophic outlier rate of 0.13%, and a bias of 0.0028. The model satisfies two of the three LSST photometric redshift requirements for redshifts below 3. These results highlight the potential of combining physically motivated templates with data-driven models for robust redshift estimation in upcoming cosmological surveys.
<div id='section'>Paperid: <span id='pid'>1060, <a href='https://arxiv.org/pdf/2506.22511.pdf' target='_blank'>https://arxiv.org/pdf/2506.22511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingting Zhou, Feng Zhang, Haoyang Fu, Baoxiang Pan, Renhe Zhang, Feng Lu, Zhixin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22511">Lighting the Night with Generative Artificial Intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The visible light reflectance data from geostationary satellites is crucial for meteorological observations and plays an important role in weather monitoring and forecasting. However, due to the lack of visible light at night, it is impossible to conduct continuous all-day weather observations using visible light reflectance data. This study pioneers the use of generative diffusion models to address this limitation. Based on the multi-band thermal infrared brightness temperature data from the Advanced Geostationary Radiation Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we developed a high-precision visible light reflectance generative model, called Reflectance Diffusion (RefDiff), which enables 0.47~Î¼\mathrm{m}, 0.65~Î¼\mathrm{m}, and 0.825~Î¼\mathrm{m} bands visible light reflectance generation at night. Compared to the classical models, RefDiff not only significantly improves accuracy through ensemble averaging but also provides uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90, with particularly significant improvements in areas with complex cloud structures and thick clouds. The model's nighttime generation capability was validated using VIIRS nighttime product, demonstrating comparable performance to its daytime counterpart. In summary, this research has made substantial progress in the ability to generate visible light reflectance at night, with the potential to expand the application of nighttime visible light data.
<div id='section'>Paperid: <span id='pid'>1061, <a href='https://arxiv.org/pdf/2506.17672.pdf' target='_blank'>https://arxiv.org/pdf/2506.17672.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weiming Mai, Jie Gao, Oded Cats
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17672">Learning Personalized Utility Functions for Drivers in Ride-hailing Systems Using Ensemble Hypernetworks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In ride-hailing systems, drivers decide whether to accept or reject ride requests based on factors such as order characteristics, traffic conditions, and personal preferences. Accurately predicting these decisions is essential for improving the efficiency and reliability of these systems. Traditional models, such as the Random Utility Maximization (RUM) approach, typically predict drivers' decisions by assuming linear correlations among attributes. However, these models often fall short because they fail to account for non-linear interactions between attributes and do not cater to the unique, personalized preferences of individual drivers. In this paper, we develop a method for learning personalized utility functions using hypernetwork and ensemble learning. Hypernetworks dynamically generate weights for a linear utility function based on trip request data and driver profiles, capturing the non-linear relationships. An ensemble of hypernetworks trained on different data segments further improve model adaptability and generalization by introducing controlled randomness, thereby reducing over-fitting. We validate the performance of our ensemble hypernetworks model in terms of prediction accuracy and uncertainty estimation in a real-world dataset. The results demonstrate that our approach not only accurately predicts each driver's utility but also effectively balances the needs for explainability and uncertainty quantification. Additionally, our model serves as a powerful tool for revealing the personalized preferences of different drivers, clearly illustrating which attributes largely impact their rider acceptance decisions.
<div id='section'>Paperid: <span id='pid'>1062, <a href='https://arxiv.org/pdf/2506.14497.pdf' target='_blank'>https://arxiv.org/pdf/2506.14497.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Franco Matzkin, Agostina Larrazabal, Diego H Milone, Jose Dolz, Enzo Ferrante
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14497">Towards Reliable WMH Segmentation under Domain Shift: An Application Study using Maximum Entropy Regularization to Improve Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate segmentation of white matter hyperintensities (WMH) is crucial for clinical decision-making, particularly in the context of multiple sclerosis. However, domain shifts, such as variations in MRI machine types or acquisition parameters, pose significant challenges to model calibration and uncertainty estimation. This study investigates the impact of domain shift on WMH segmentation by proposing maximum-entropy regularization techniques to enhance model calibration and uncertainty estimation, with the purpose of identifying errors post-deployment using predictive uncertainty as a proxy measure that does not require ground-truth labels. To do this, we conducted experiments using a U-Net architecture to evaluate these regularization schemes on two publicly available datasets, assessing performance with the Dice coefficient, expected calibration error, and entropy-based uncertainty estimates. Our results show that entropy-based uncertainty estimates can anticipate segmentation errors, and that maximum-entropy regularization further strengthens the correlation between uncertainty and segmentation performance while also improving model calibration under domain shift.
<div id='section'>Paperid: <span id='pid'>1063, <a href='https://arxiv.org/pdf/2506.14194.pdf' target='_blank'>https://arxiv.org/pdf/2506.14194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sudeepta Mondal, Zhuolin Jiang, Ganesh Sundaramoorthi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14194">A Variational Information Theoretic Approach to Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a theory for the construction of out-of-distribution (OOD) detection features for neural networks. We introduce random features for OOD through a novel information-theoretic loss functional consisting of two terms, the first based on the KL divergence separates resulting in-distribution (ID) and OOD feature distributions and the second term is the Information Bottleneck, which favors compressed features that retain the OOD information. We formulate a variational procedure to optimize the loss and obtain OOD features. Based on assumptions on OOD distributions, one can recover properties of existing OOD features, i.e., shaping functions. Furthermore, we show that our theory can predict a new shaping function that out-performs existing ones on OOD benchmarks. Our theory provides a general framework for constructing a variety of new features with clear explainability.
<div id='section'>Paperid: <span id='pid'>1064, <a href='https://arxiv.org/pdf/2506.09270.pdf' target='_blank'>https://arxiv.org/pdf/2506.09270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rodrigo Carrasco-Davis, Sebastian Lee, Claudia Clopath, Will Dabney
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09270">Uncertainty Prioritized Experience Replay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prioritized experience replay, which improves sample efficiency by selecting relevant transitions to update parameter estimates, is a crucial component of contemporary value-based deep reinforcement learning models. Typically, transitions are prioritized based on their temporal difference error. However, this approach is prone to favoring noisy transitions, even when the value estimation closely approximates the target mean. This phenomenon resembles the noisy TV problem postulated in the exploration literature, in which exploration-guided agents get stuck by mistaking noise for novelty. To mitigate the disruptive effects of noise in value estimation, we propose using epistemic uncertainty estimation to guide the prioritization of transitions from the replay buffer. Epistemic uncertainty quantifies the uncertainty that can be reduced by learning, hence reducing transitions sampled from the buffer generated by unpredictable random processes. We first illustrate the benefits of epistemic uncertainty prioritized replay in two tabular toy models: a simple multi-arm bandit task, and a noisy gridworld. Subsequently, we evaluate our prioritization scheme on the Atari suite, outperforming quantile regression deep Q-learning benchmarks; thus forging a path for the use of uncertainty prioritized replay in reinforcement learning agents.
<div id='section'>Paperid: <span id='pid'>1065, <a href='https://arxiv.org/pdf/2506.01994.pdf' target='_blank'>https://arxiv.org/pdf/2506.01994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wanshan Cui, Yejin Jeong, Inwook Song, Gyuri Kim, Minsang Kwon, Donghun Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01994">Re-experiment Smart: a Novel Method to Enhance Data-driven Prediction of Mechanical Properties of Epoxy Polymers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of polymer material properties through data-driven approaches greatly accelerates novel material development by reducing redundant experiments and trial-and-error processes. However, inevitable outliers in empirical measurements can severely skew machine learning results, leading to erroneous prediction models and suboptimal material designs. To address this limitation, we propose a novel approach to enhance dataset quality efficiently by integrating multi-algorithm outlier detection with selective re-experimentation of unreliable outlier cases. To validate the empirical effectiveness of the approach, we systematically construct a new dataset containing 701 measurements of three key mechanical properties: glass transition temperature ($T_g$), tan $Î´$ peak, and crosslinking density ($v_{c}$). To demonstrate its general applicability, we report the performance improvements across multiple machine learning models, including Elastic Net, SVR, Random Forest, and TPOT, to predict the three key properties. Our method reliably reduces prediction error (RMSE) and significantly improves accuracy with minimal additional experimental work, requiring only about 5% of the dataset to be re-measured. These findings highlight the importance of data quality enhancement in achieving reliable machine learning applications in polymer science and present a scalable strategy for improving predictive reliability in materials science.
<div id='section'>Paperid: <span id='pid'>1066, <a href='https://arxiv.org/pdf/2505.23845.pdf' target='_blank'>https://arxiv.org/pdf/2505.23845.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jakub Podolak, Rajeev Verma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23845">Read Your Own Mind: Reasoning Helps Surface Self-Confidence Signals in LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the source of uncertainty in DeepSeek R1-32B by analyzing its self-reported verbal confidence on question answering (QA) tasks. In the default answer-then-confidence setting, the model is regularly over-confident, whereas semantic entropy - obtained by sampling many responses - remains reliable. We hypothesize that this is because of semantic entropy's larger test-time compute, which lets us explore the model's predictive distribution. We show that granting DeepSeek the budget to explore its distribution by forcing a long chain-of-thought before the final answer greatly improves its verbal score effectiveness, even on simple fact-retrieval questions that normally require no reasoning. Furthermore, a separate reader model that sees only the chain can reconstruct very similar confidences, indicating the verbal score might be merely a statistic of the alternatives surfaced during reasoning. Our analysis concludes that reliable uncertainty estimation requires explicit exploration of the generative space, and self-reported confidence is trustworthy only after such exploration.
<div id='section'>Paperid: <span id='pid'>1067, <a href='https://arxiv.org/pdf/2505.19750.pdf' target='_blank'>https://arxiv.org/pdf/2505.19750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huaiyuan Zhang, Hang Chen, Yu Cheng, Shunyi Wu, Linghao Sun, Linao Han, Zeyu Shi, Lei Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19750">SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this technical report, we present our solution to the CVPR 2025 Visual Anomaly and Novelty Detection (VAND) 3.0 Workshop Challenge Track 1: Adapt & Detect: Robust Anomaly Detection in Real-World Applications. In real-world industrial anomaly detection, it is crucial to accurately identify anomalies with physical complexity, such as transparent or reflective surfaces, occlusions, and low-contrast contaminations. The recently proposed MVTec AD 2 dataset significantly narrows the gap between publicly available benchmarks and anomalies found in real-world industrial environments. To address the challenges posed by this dataset--such as complex and varying lighting conditions and real anomalies with large scale differences--we propose a fully training-free anomaly detection and segmentation method based on feature extraction using the DINOv2 model named SuperAD. Our method carefully selects a small number of normal reference images and constructs a memory bank by leveraging the strong representational power of DINOv2. Anomalies are then segmented by performing nearest neighbor matching between test image features and the memory bank. Our method achieves competitive results on both test sets of the MVTec AD 2 dataset.
<div id='section'>Paperid: <span id='pid'>1068, <a href='https://arxiv.org/pdf/2505.08639.pdf' target='_blank'>https://arxiv.org/pdf/2505.08639.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyi Zhou, Dongzhuo Liu, Songtao Guo, Yuanyuan Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08639">Robust Indoor Localization via Conformal Methods and Variational Bayesian Adaptive Filtering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Indoor localization is critical for IoT applications, yet challenges such as non-Gaussian noise, environmental interference, and measurement outliers hinder the robustness of traditional methods. Existing approaches, including Kalman filtering and its variants, often rely on Gaussian assumptions or static thresholds, limiting adaptability in dynamic environments. This paper proposes a hierarchical robust framework integrating Variational Bayesian (VB) parameter learning, Huber M-estimation, and Conformal Outlier Detection (COD) to address these limitations. First, VB inference jointly estimates state and noise parameters, adapting to time-varying uncertainties. Second, Huber-based robust filtering suppresses mild outliers while preserving Gaussian efficiency. Third, COD provides statistical guarantees for outlier detection via dynamically calibrated thresholds, ensuring a user-controlled false alarm rate. Theoretically, we prove the Semi-positive Definiteness of Huber-based Kalman filtering covariance and the coverage of sliding window conformal prediction. Experiments on geomagnetic fingerprint datasets demonstrate significant improvements: fingerprint matching accuracy increases from 81.25% to 93.75%, and positioning errors decrease from 0.62-6.87 m to 0.03-0.35 m. Comparative studies further validate the framework's robustness, showing consistent performance gains under non-Gaussian noise and outlier conditions.
<div id='section'>Paperid: <span id='pid'>1069, <a href='https://arxiv.org/pdf/2504.21247.pdf' target='_blank'>https://arxiv.org/pdf/2504.21247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangyang Qu, Dazhi Fu, Jicong Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.21247">Subject Information Extraction for Novelty Detection with Domain Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised novelty detection (UND), aimed at identifying novel samples, is essential in fields like medical diagnosis, cybersecurity, and industrial quality control. Most existing UND methods assume that the training data and testing normal data originate from the same domain and only consider the distribution variation between training data and testing data. However, in real scenarios, it is common for normal testing and training data to originate from different domains, a challenge known as domain shift. The discrepancies between training and testing data often lead to incorrect classification of normal data as novel by existing methods. A typical situation is that testing normal data and training data describe the same subject, yet they differ in the background conditions. To address this problem, we introduce a novel method that separates subject information from background variation encapsulating the domain information to enhance detection performance under domain shifts. The proposed method minimizes the mutual information between the representations of the subject and background while modelling the background variation using a deep Gaussian mixture model, where the novelty detection is conducted on the subject representations solely and hence is not affected by the variation of domains. Extensive experiments demonstrate that our model generalizes effectively to unseen domains and significantly outperforms baseline methods, especially under substantial domain shifts between training and testing data.
<div id='section'>Paperid: <span id='pid'>1070, <a href='https://arxiv.org/pdf/2504.11307.pdf' target='_blank'>https://arxiv.org/pdf/2504.11307.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sonia Laguna, Lin Zhang, Can Deniz Bezek, Monika Farkas, Dieter Schweizer, Rahel A. Kubik-Huch, Orcun Goksel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11307">Uncertainty Estimation for Trust Attribution to Speed-of-Sound Reconstruction with Variational Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speed-of-sound (SoS) is a biomechanical characteristic of tissue, and its imaging can provide a promising biomarker for diagnosis. Reconstructing SoS images from ultrasound acquisitions can be cast as a limited-angle computed-tomography problem, with Variational Networks being a promising model-based deep learning solution. Some acquired data frames may, however, get corrupted by noise due to, e.g., motion, lack of contact, and acoustic shadows, which in turn negatively affects the resulting SoS reconstructions. We propose to use the uncertainty in SoS reconstructions to attribute trust to each individual acquired frame. Given multiple acquisitions, we then use an uncertainty based automatic selection among these retrospectively, to improve diagnostic decisions. We investigate uncertainty estimation based on Monte Carlo Dropout and Bayesian Variational Inference. We assess our automatic frame selection method for differential diagnosis of breast cancer, distinguishing between benign fibroadenoma and malignant carcinoma. We evaluate 21 lesions classified as BI-RADS~4, which represents suspicious cases for probable malignancy. The most trustworthy frame among four acquisitions of each lesion was identified using uncertainty based criteria. Selecting a frame informed by uncertainty achieved an area under curve of 76% and 80% for Monte Carlo Dropout and Bayesian Variational Inference, respectively, superior to any uncertainty-uninformed baselines with the best one achieving 64%. A novel use of uncertainty estimation is proposed for selecting one of multiple data acquisitions for further processing and decision making.
<div id='section'>Paperid: <span id='pid'>1071, <a href='https://arxiv.org/pdf/2504.04583.pdf' target='_blank'>https://arxiv.org/pdf/2504.04583.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal TeÅ¡nar, Bilal Wehbe, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04583">Modeling of AUV Dynamics with Limited Resources: Efficient Online Learning Using Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning proves effective in constructing dynamics models from data, especially for underwater vehicles. Continuous refinement of these models using incoming data streams, however, often requires storage of an overwhelming amount of redundant data. This work investigates the use of uncertainty in the selection of data points to rehearse in online learning when storage capacity is constrained. The models are learned using an ensemble of multilayer perceptrons as they perform well at predicting epistemic uncertainty. We present three novel approaches: the Threshold method, which excludes samples with uncertainty below a specified threshold, the Greedy method, designed to maximize uncertainty among the stored points, and Threshold-Greedy, which combines the previous two approaches. The methods are assessed on data collected by an underwater vehicle Dagon. Comparison with baselines reveals that the Threshold exhibits enhanced stability throughout the learning process and also yields a model with the least cumulative testing loss. We also conducted detailed analyses on the impact of model parameters and storage size on the performance of the models, as well as a comparison of three different uncertainty estimation methods.
<div id='section'>Paperid: <span id='pid'>1072, <a href='https://arxiv.org/pdf/2503.18817.pdf' target='_blank'>https://arxiv.org/pdf/2503.18817.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeonghyeon Kim, Sangheum Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18817">Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prior research on out-of-distribution detection (OoDD) has primarily focused on single-modality models. Recently, with the advent of large-scale pretrained vision-language models such as CLIP, OoDD methods utilizing such multi-modal representations through zero-shot and prompt learning strategies have emerged. However, these methods typically involve either freezing the pretrained weights or only partially tuning them, which can be suboptimal for downstream datasets. In this paper, we highlight that multi-modal fine-tuning (MMFT) can achieve notable OoDD performance. Despite some recent works demonstrating the impact of fine-tuning methods for OoDD, there remains significant potential for performance improvement. We investigate the limitation of naÃ¯ve fine-tuning methods, examining why they fail to fully leverage the pretrained knowledge. Our empirical analysis suggests that this issue could stem from the modality gap within in-distribution (ID) embeddings. To address this, we propose a training objective that enhances cross-modal alignment by regularizing the distances between image and text embeddings of ID data. This adjustment helps in better utilizing pretrained textual information by aligning similar semantics from different modalities (i.e., text and image) more closely in the hyperspherical representation space. We theoretically demonstrate that the proposed regularization corresponds to the maximum likelihood estimation of an energy-based model on a hypersphere. Utilizing ImageNet-1k OoD benchmark datasets, we show that our method, combined with post-hoc OoDD approaches leveraging pretrained knowledge (e.g., NegLabel), significantly outperforms existing methods, achieving state-of-the-art OoDD performance and leading ID accuracy.
<div id='section'>Paperid: <span id='pid'>1073, <a href='https://arxiv.org/pdf/2503.15583.pdf' target='_blank'>https://arxiv.org/pdf/2503.15583.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabian Denoodt, JosÃ© Oramas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15583">Efficient Post-Hoc Uncertainty Calibration via Variance-Based Smoothing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since state-of-the-art uncertainty estimation methods are often computationally demanding, we investigate whether incorporating prior information can improve uncertainty estimates in conventional deep neural networks. Our focus is on machine learning tasks where meaningful predictions can be made from sub-parts of the input. For example, in speaker classification, the speech waveform can be divided into sequential patches, each containing information about the same speaker. We observe that the variance between sub-predictions serves as a reliable proxy for uncertainty in such settings. Our proposed variance-based scaling framework produces competitive uncertainty estimates in classification while being less computationally demanding and allowing for integration as a post-hoc calibration tool. This approach also leads to a simple extension of deep ensembles, improving the expressiveness of their predicted distributions.
<div id='section'>Paperid: <span id='pid'>1074, <a href='https://arxiv.org/pdf/2503.11851.pdf' target='_blank'>https://arxiv.org/pdf/2503.11851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jutika Borah, Hidam Kumarjit Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.11851">DCAT: Dual Cross-Attention Fusion for Disease Classification in Radiological Images with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and reliable image classification is crucial in radiology, where diagnostic decisions significantly impact patient outcomes. Conventional deep learning models tend to produce overconfident predictions despite underlying uncertainties, potentially leading to misdiagnoses. Attention mechanisms have emerged as powerful tools in deep learning, enabling models to focus on relevant parts of the input data. Combined with feature fusion, they can be effective in addressing uncertainty challenges. Cross-attention has become increasingly important in medical image analysis for capturing dependencies across features and modalities. This paper proposes a novel dual cross-attention fusion model for medical image analysis by addressing key challenges in feature integration and interpretability. Our approach introduces a bidirectional cross-attention mechanism with refined channel and spatial attention that dynamically fuses feature maps from EfficientNetB4 and ResNet34 leveraging multi-network contextual dependencies. The refined features through channel and spatial attention highlights discriminative patterns crucial for accurate classification. The proposed model achieved AUC of 99.75%, 100%, 99.93% and 98.69% and AUPR of 99.81%, 100%, 99.97%, and 96.36% on Covid-19, Tuberculosis, Pneumonia Chest X-ray images and Retinal OCT images respectively. The entropy values and several high uncertain samples give an interpretable visualization from the model enhancing transparency. By combining multi-scale feature extraction, bidirectional attention and uncertainty estimation, our proposed model strongly impacts medical image analysis.
<div id='section'>Paperid: <span id='pid'>1075, <a href='https://arxiv.org/pdf/2502.19122.pdf' target='_blank'>https://arxiv.org/pdf/2502.19122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian ChwilczyÅski, Dariusz Brzezinski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19122">Random Similarity Isolation Forests</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With predictive models becoming prevalent, companies are expanding the types of data they gather. As a result, the collected datasets consist not only of simple numerical features but also more complex objects such as time series, images, or graphs. Such multi-modal data have the potential to improve performance in predictive tasks like outlier detection, where the goal is to identify objects deviating from the main data distribution. However, current outlier detection algorithms are dedicated to individual types of data. Consequently, working with mixed types of data requires either fusing multiple data-specific models or transforming all of the representations into a single format, both of which can hinder predictive performance. In this paper, we propose a multi-modal outlier detection algorithm called Random Similarity Isolation Forest. Our method combines the notions of isolation and similarity-based projection to handle datasets with mixtures of features of arbitrary data types. Experiments performed on 47 benchmark datasets demonstrate that Random Similarity Isolation Forest outperforms five state-of-the-art competitors. Our study shows that the use of multiple modalities can indeed improve the detection of anomalies and highlights the need for new outlier detection benchmarks tailored for multi-modal algorithms.
<div id='section'>Paperid: <span id='pid'>1076, <a href='https://arxiv.org/pdf/2502.18389.pdf' target='_blank'>https://arxiv.org/pdf/2502.18389.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicola Cecere, Andrea Bacciu, Ignacio FernÃ¡ndez TobÃ­as, Amin Mantrach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18389">Monte Carlo Temperature: a robust sampling strategy for LLM's uncertainty quantification methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification (UQ) in Large Language Models (LLMs) is essential for their safe and reliable deployment, particularly in critical applications where incorrect outputs can have serious consequences. Current UQ methods typically rely on querying the model multiple times using non-zero temperature sampling to generate diverse outputs for uncertainty estimation. However, the impact of selecting a given temperature parameter is understudied, and our analysis reveals that temperature plays a fundamental role in the quality of uncertainty estimates. The conventional approach of identifying optimal temperature values requires expensive hyperparameter optimization (HPO) that must be repeated for each new model-dataset combination. We propose Monte Carlo Temperature (MCT), a robust sampling strategy that eliminates the need for temperature calibration. Our analysis reveals that: 1) MCT provides more robust uncertainty estimates across a wide range of temperatures, 2) MCT improves the performance of UQ methods by replacing fixed-temperature strategies that do not rely on HPO, and 3) MCT achieves statistical parity with oracle temperatures, which represent the ideal outcome of a well-tuned but computationally expensive HPO process. These findings demonstrate that effective UQ can be achieved without the computational burden of temperature parameter calibration.
<div id='section'>Paperid: <span id='pid'>1077, <a href='https://arxiv.org/pdf/2502.14698.pdf' target='_blank'>https://arxiv.org/pdf/2502.14698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Schmitt, John Shawe-Taylor, Hado van Hasselt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14698">General Uncertainty Estimation with Delta Variances</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Decision makers may suffer from uncertainty induced by limited data. This may be mitigated by accounting for epistemic uncertainty, which is however challenging to estimate efficiently for large neural networks. To this extent we investigate Delta Variances, a family of algorithms for epistemic uncertainty quantification, that is computationally efficient and convenient to implement. It can be applied to neural networks and more general functions composed of neural networks. As an example we consider a weather simulator with a neural-network-based step function inside -- here Delta Variances empirically obtain competitive results at the cost of a single gradient computation. The approach is convenient as it requires no changes to the neural network architecture or training procedure. We discuss multiple ways to derive Delta Variances theoretically noting that special cases recover popular techniques and present a unified perspective on multiple related methods. Finally we observe that this general perspective gives rise to a natural extension and empirically show its benefit.
<div id='section'>Paperid: <span id='pid'>1078, <a href='https://arxiv.org/pdf/2502.11620.pdf' target='_blank'>https://arxiv.org/pdf/2502.11620.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arindam Sharma, Cristina David
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11620">Assessing Correctness in LLM-Based Code Generation via Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we explore uncertainty estimation as a proxy for correctness in LLM-generated code. To this end, we adapt two state-of-the-art techniques from natural language generation -- one based on entropy and another on mutual information -- to the domain of code generation. Given the distinct semantic properties of code, we introduce modifications, including a semantic equivalence check based on symbolic execution. Our findings indicate a strong correlation between the uncertainty computed through these techniques and correctness, highlighting the potential of uncertainty estimation for quality assessment. Additionally, we propose a simplified version of the entropy-based method that assumes a uniform distribution over the LLM's responses, demonstrating comparable effectiveness. Using these techniques, we develop an abstention policy that prevents the model from making predictions when uncertainty is high, reducing incorrect outputs to near zero. Our evaluation on the LiveCodeBench shows that our approach significantly outperforms a baseline relying solely on LLM-reported log-probabilities.
<div id='section'>Paperid: <span id='pid'>1079, <a href='https://arxiv.org/pdf/2502.02537.pdf' target='_blank'>https://arxiv.org/pdf/2502.02537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huiqun Huang, Cong Chen, Jean-Philippe Monteuuis, Jonathan Petit, Fei Miao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.02537">Uncertainty Quantification for Collaborative Object Detection Under Adversarial Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Collaborative Object Detection (COD) and collaborative perception can integrate data or features from various entities, and improve object detection accuracy compared with individual perception. However, adversarial attacks pose a potential threat to the deep learning COD models, and introduce high output uncertainty. With unknown attack models, it becomes even more challenging to improve COD resiliency and quantify the output uncertainty for highly dynamic perception scenes such as autonomous vehicles. In this study, we propose the Trusted Uncertainty Quantification in Collaborative Perception framework (TUQCP). TUQCP leverages both adversarial training and uncertainty quantification techniques to enhance the adversarial robustness of existing COD models. More specifically, TUQCP first adds perturbations to the shared information of randomly selected agents during object detection collaboration by adversarial training. TUQCP then alleviates the impacts of adversarial attacks by providing output uncertainty estimation through learning-based module and uncertainty calibration through conformal prediction. Our framework works for early and intermediate collaboration COD models and single-agent object detection models. We evaluate TUQCP on V2X-Sim, a comprehensive collaborative perception dataset for autonomous driving, and demonstrate a 80.41% improvement in object detection accuracy compared to the baselines under the same adversarial attacks. TUQCP demonstrates the importance of uncertainty quantification to COD under adversarial attacks.
<div id='section'>Paperid: <span id='pid'>1080, <a href='https://arxiv.org/pdf/2501.16718.pdf' target='_blank'>https://arxiv.org/pdf/2501.16718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hengzhuang Li, Teng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16718">Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for developing trustworthy and reliable machine learning systems. Recent advances in training with auxiliary OOD data demonstrate efficacy in enhancing detection capabilities. Nonetheless, these methods heavily rely on acquiring a large pool of high-quality natural outliers. Some prior methods try to alleviate this problem by synthesizing virtual outliers but suffer from either poor quality or high cost due to the monotonous sampling strategy and the heavy-parameterized generative models. In this paper, we overcome all these problems by proposing the Hamiltonian Monte Carlo Outlier Synthesis (HamOS) framework, which views the synthesis process as sampling from Markov chains. Based solely on the in-distribution data, the Markov chains can extensively traverse the feature space and generate diverse and representative outliers, hence exposing the model to miscellaneous potential OOD scenarios. The Hamiltonian Monte Carlo with sampling acceptance rate almost close to 1 also makes our framework enjoy great efficiency. By empirically competing with SOTA baselines on both standard and large-scale benchmarks, we verify the efficacy and efficiency of our proposed HamOS.
<div id='section'>Paperid: <span id='pid'>1081, <a href='https://arxiv.org/pdf/2501.04577.pdf' target='_blank'>https://arxiv.org/pdf/2501.04577.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zephan M. Enciso, Boyang Cheng, Likai Pei, Jianbo Liu, Steven Davis, Michael Niemier, Ningyuan Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04577">A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is an indispensable capability for AI-enabled, safety-critical applications, e.g. autonomous vehicles or medical diagnosis. Bayesian neural networks (BNNs) use Bayesian statistics to provide both classification predictions and uncertainty estimation, but they suffer from high computational overhead associated with random number generation and repeated sample iterations. Furthermore, BNNs are not immediately amenable to acceleration through compute-in-memory architectures due to the frequent memory writes necessary after each RNG operation. To address these challenges, we present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the SRAM memory words. This integration reduces RNG overhead and enables fully-parallel compute-in-memory operations for BNNs. The prototype chip achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput while occupying 0.45 mm2, bringing AI uncertainty estimation to edge computation.
<div id='section'>Paperid: <span id='pid'>1082, <a href='https://arxiv.org/pdf/2501.01061.pdf' target='_blank'>https://arxiv.org/pdf/2501.01061.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Hu, Luc, Chen, Yiwei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01061">An Efficient Outlier Detection Algorithm for Data Streaming</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The nature of modern data is increasingly real-time, making outlier detection crucial in any data-related field, such as finance for fraud detection and healthcare for monitoring patient vitals. Traditional outlier detection methods, such as the Local Outlier Factor (LOF) algorithm, struggle with real-time data due to the need for extensive recalculations with each new data point, limiting their application in real-time environments. While the Incremental LOF (ILOF) algorithm has been developed to tackle the challenges of online anomaly detection, it remains computationally expensive when processing large streams of data points, and its detection performance may degrade after a certain threshold of points have streamed in. In this paper, we propose a novel approach to enhance the efficiency of LOF algorithms for online anomaly detection, named the Efficient Incremental LOF (EILOF) algorithm. The EILOF algorithm only computes the LOF scores of new points without altering the LOF scores of existing data points. Although exact LOF scores have not yet been computed for the existing points in the new algorithm, datasets often contain noise, and minor deviations in LOF score calculations do not necessarily degrade detection performance. In fact, such deviations can sometimes enhance outlier detection. We systematically tested this approach on both simulated and real-world datasets, demonstrating that EILOF outperforms ILOF as the volume of streaming data increases across various scenarios. The EILOF algorithm not only significantly reduces computational costs, but also systematically improves detection accuracy when the number of additional points increases compared to the ILOF algorithm.
<div id='section'>Paperid: <span id='pid'>1083, <a href='https://arxiv.org/pdf/2412.20918.pdf' target='_blank'>https://arxiv.org/pdf/2412.20918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Chen, Chih-Li Sung, Arpan Kusari, Xiaoyang Song, Wenbo Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20918">Uncertainty-Aware Out-of-Distribution Detection with Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) are often constructed under the closed-world assumption, which may fail to generalize to the out-of-distribution (OOD) data. This leads to DNNs producing overconfident wrong predictions and can result in disastrous consequences in safety-critical applications. Existing OOD detection methods mainly rely on curating a set of OOD data for model training or hyper-parameter tuning to distinguish OOD data from training data (also known as in-distribution data or InD data). However, OOD samples are not always available during the training phase in real-world applications, hindering the OOD detection accuracy. To overcome this limitation, we propose a Gaussian-process-based OOD detection method to establish a decision boundary based on InD data only. The basic idea is to perform uncertainty quantification of the unconstrained softmax scores of a DNN via a multi-class Gaussian process (GP), and then define a score function to separate InD and potential OOD data based on their fundamental differences in the posterior predictive distribution from the GP. Two case studies on conventional image classification datasets and real-world image datasets are conducted to demonstrate that the proposed method outperforms the state-of-the-art OOD detection methods when OOD samples are not observed in the training phase.
<div id='section'>Paperid: <span id='pid'>1084, <a href='https://arxiv.org/pdf/2412.20586.pdf' target='_blank'>https://arxiv.org/pdf/2412.20586.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufei Wu, Stefan Radev, Francis Tuerlinckx
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20586">Testing and Improving the Robustness of Amortized Bayesian Inference for Cognitive Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contaminant observations and outliers often cause problems when estimating the parameters of cognitive models, which are statistical models representing cognitive processes. In this study, we test and improve the robustness of parameter estimation using amortized Bayesian inference (ABI) with neural networks. To this end, we conduct systematic analyses on a toy example and analyze both synthetic and real data using a popular cognitive model, the Drift Diffusion Models (DDM). First, we study the sensitivity of ABI to contaminants with tools from robust statistics: the empirical influence function and the breakdown point. Next, we propose a data augmentation or noise injection approach that incorporates a contamination distribution into the data-generating process during training. We examine several candidate distributions and evaluate their performance and cost in terms of accuracy and efficiency loss relative to a standard estimator. Introducing contaminants from a Cauchy distribution during training considerably increases the robustness of the neural density estimator as measured by bounded influence functions and a much higher breakdown point. Overall, the proposed method is straightforward and practical to implement and has a broad applicability in fields where outlier detection or removal is challenging.
<div id='section'>Paperid: <span id='pid'>1085, <a href='https://arxiv.org/pdf/2412.20007.pdf' target='_blank'>https://arxiv.org/pdf/2412.20007.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elhoucine Elfatimi, Pratik Shah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20007">Uncertainty Quantified Deep Learning and Regression Analysis Framework for Image Segmentation of Skin Cancer Lesions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models (DLMs) frequently achieve accurate segmentation and classification of tumors from medical images. However, DLMs lacking feedback on their image segmentation mechanisms, such as Dice coefficients and confidence in their performance, face challenges when processing previously unseen images in real-world clinical settings. Uncertainty estimates to identify DLM predictions at the cellular or single-pixel level that require clinician review can enhance trust. However, their deployment requires significant computational resources. This study reports two DLMs, one trained from scratch and another based on transfer learning, with Monte Carlo dropout or Bayes-by-backprop uncertainty estimations to segment lesions from the publicly available The International Skin Imaging Collaboration-19 dermoscopy image database with cancerous lesions. A novel approach to compute pixel-by-pixel uncertainty estimations of DLM segmentation performance in multiple clinical regions from a single dermoscopy image with corresponding Dice scores is reported for the first time. Image-level uncertainty maps demonstrated correspondence between imperfect DLM segmentation and high uncertainty levels in specific skin tissue regions, with or without lesions. Four new linear regression models that can predict the Dice performance of DLM segmentation using constants and uncertainty measures, either individually or in combination from lesions, tissue structures, and non-tissue pixel regions critical for clinical diagnosis and prognostication in skin images (Spearman's correlation, p < 0.05), are reported for the first time for low-compute uncertainty estimation workflows.
<div id='section'>Paperid: <span id='pid'>1086, <a href='https://arxiv.org/pdf/2412.05669.pdf' target='_blank'>https://arxiv.org/pdf/2412.05669.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Li, Shuliang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05669">Detecting outliers by clustering algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clustering and outlier detection are two important tasks in data mining. Outliers frequently interfere with clustering algorithms to determine the similarity between objects, resulting in unreliable clustering results. Currently, only a few clustering algorithms (e.g., DBSCAN) have the ability to detect outliers to eliminate interference. For other clustering algorithms, it is tedious to introduce another outlier detection task to eliminate outliers before each clustering process. Obviously, how to equip more clustering algorithms with outlier detection ability is very meaningful. Although a common strategy allows clustering algorithms to detect outliers based on the distance between objects and clusters, it is contradictory to improving the performance of clustering algorithms on the datasets with outliers. In this paper, we propose a novel outlier detection approach, called ODAR, for clustering. ODAR maps outliers and normal objects into two separated clusters by feature transformation. As a result, any clustering algorithm can detect outliers by identifying clusters. Experiments show that ODAR is robust to diverse datasets. Compared with baseline methods, the clustering algorithms achieve the best on 7 out of 10 datasets with the help of ODAR, with at least 5% improvement in accuracy.
<div id='section'>Paperid: <span id='pid'>1087, <a href='https://arxiv.org/pdf/2412.02875.pdf' target='_blank'>https://arxiv.org/pdf/2412.02875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ankita Samaddar, Nicholas Potteiger, Xenofon Koutsoukos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02875">Out-of-Distribution Detection for Neurosymbolic Autonomous Cyber Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous agents for cyber applications take advantage of modern defense techniques by adopting intelligent agents with conventional and learning-enabled components. These intelligent agents are trained via reinforcement learning (RL) algorithms, and can learn, adapt to, reason about and deploy security rules to defend networked computer systems while maintaining critical operational workflows. However, the knowledge available during training about the state of the operational network and its environment may be limited. The agents should be trustworthy so that they can reliably detect situations they cannot handle, and hand them over to cyber experts. In this work, we develop an out-of-distribution (OOD) Monitoring algorithm that uses a Probabilistic Neural Network (PNN) to detect anomalous or OOD situations of RL-based agents with discrete states and discrete actions. To demonstrate the effectiveness of the proposed approach, we integrate the OOD monitoring algorithm with a neurosymbolic autonomous cyber agent that uses behavior trees with learning-enabled components. We evaluate the proposed approach in a simulated cyber environment under different adversarial strategies. Experimental results over a large number of episodes illustrate the overall efficiency of our proposed approach.
<div id='section'>Paperid: <span id='pid'>1088, <a href='https://arxiv.org/pdf/2412.00278.pdf' target='_blank'>https://arxiv.org/pdf/2412.00278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Sun, Sander BohtÃ©
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00278">Average-Over-Time Spiking Neural Networks for Uncertainty Estimation in Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a standard tool to quantify the reliability of modern deep learning models, and crucial for many real-world applications. However, efficient uncertainty estimation methods for spiking neural networks, particularly for regression models, have been lacking. Here, we introduce two methods that adapt the Average-Over-Time Spiking Neural Network (AOT-SNN) framework to regression tasks, enhancing uncertainty estimation in event-driven models. The first method uses the heteroscedastic Gaussian approach, where SNNs predict both the mean and variance at each time step, thereby generating a conditional probability distribution of the target variable. The second method leverages the Regression-as-Classification (RAC) approach, reformulating regression as a classification problem to facilitate uncertainty estimation. We evaluate our approaches on both a toy dataset and several benchmark datasets, demonstrating that the proposed AOT-SNN models achieve performance comparable to or better than state-of-the-art deep neural network methods, particularly in uncertainty estimation. Our findings highlight the potential of SNNs for uncertainty estimation in regression tasks, providing an efficient and biologically inspired alternative for applications requiring both accuracy and energy efficiency.
<div id='section'>Paperid: <span id='pid'>1089, <a href='https://arxiv.org/pdf/2411.16370.pdf' target='_blank'>https://arxiv.org/pdf/2411.16370.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. M. A. Valiuddin, R. J. G. van Sloun, C. G. A. Viviers, P. H. N. de With, F. van der Sommen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16370">A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in architectural design, data availability, and compute have driven remarkable progress in semantic segmentation. Yet, these models often rely on relaxed Bayesian assumptions, omitting critical uncertainty information needed for robust decision-making. The resulting reliance on point estimates has fueled interest in probabilistic segmentation, but the literature remains fragmented. In response, this review consolidates and contextualizes foundational concepts in uncertainty modeling, including the non-trivial task of distinguishing between epistemic and aleatoric uncertainty and examining their roles across four key downstream segmentation tasks, highlighting Active Learning as particularly promising. By unifying theory, terminology, and applications, we provide a coherent foundation for researchers and identify critical challenges, such as strong assumptions in spatial aggregation, lack of standardized benchmarks, and pitfalls in current uncertainty quantification methods. We identify trends such as the adoption of contemporary generative models, driven by advances in the broader field of generative modeling, with segmentation-specific innovation primarily in the conditioning mechanisms. Moreover, we observe growing interest in distribution- and sampling-free approaches to uncertainty estimation. We further propose directions for advancing uncertainty-aware segmentation in deep learning, including pragmatic strategies for disentangling different sources of uncertainty, novel uncertainty modeling approaches and improved Transformer-based backbones. In this way, we aim to support the development of more reliable, efficient, and interpretable segmentation models that effectively incorporate uncertainty into real-world applications.
<div id='section'>Paperid: <span id='pid'>1090, <a href='https://arxiv.org/pdf/2411.11132.pdf' target='_blank'>https://arxiv.org/pdf/2411.11132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alisa Sheinkman, Sara Wade
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11132">Variational Bayesian Bow tie Neural Networks with Shrinkage</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the dominant role of deep models in machine learning, limitations persist, including overconfident predictions, susceptibility to adversarial attacks, and underestimation of variability in predictions. The Bayesian paradigm provides a natural framework to overcome such issues and has become the gold standard for uncertainty estimation with deep models, also providing improved accuracy and a framework for tuning critical hyperparameters. However, exact Bayesian inference is challenging, typically involving variational algorithms that impose strong independence and distributional assumptions. Moreover, existing methods are sensitive to the architectural choice of the network. We address these issues by focusing on a stochastic relaxation of the standard feed-forward rectified neural network and using sparsity-promoting priors on the weights of the neural network for increased robustness to architectural design. Thanks to Polya-Gamma data augmentation tricks, which render a conditionally linear and Gaussian model, we derive a fast, approximate variational inference algorithm that avoids distributional assumptions and independence across layers. Suitable strategies to further improve scalability and account for multimodality are considered.
<div id='section'>Paperid: <span id='pid'>1091, <a href='https://arxiv.org/pdf/2411.05324.pdf' target='_blank'>https://arxiv.org/pdf/2411.05324.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Chen, Alan McMillan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05324">SASWISE-UE: Segmentation and Synthesis with Interpretable Scalable Ensembles for Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces an efficient sub-model ensemble framework aimed at enhancing the interpretability of medical deep learning models, thus increasing their clinical applicability. By generating uncertainty maps, this framework enables end-users to evaluate the reliability of model outputs. We developed a strategy to develop diverse models from a single well-trained checkpoint, facilitating the training of a model family. This involves producing multiple outputs from a single input, fusing them into a final output, and estimating uncertainty based on output disagreements. Implemented using U-Net and UNETR models for segmentation and synthesis tasks, this approach was tested on CT body segmentation and MR-CT synthesis datasets. It achieved a mean Dice coefficient of 0.814 in segmentation and a Mean Absolute Error of 88.17 HU in synthesis, improved from 89.43 HU by pruning. Additionally, the framework was evaluated under corruption and undersampling, maintaining correlation between uncertainty and error, which highlights its robustness. These results suggest that the proposed approach not only maintains the performance of well-trained models but also enhances interpretability through effective uncertainty estimation, applicable to both convolutional and transformer models in a range of imaging tasks.
<div id='section'>Paperid: <span id='pid'>1092, <a href='https://arxiv.org/pdf/2411.00259.pdf' target='_blank'>https://arxiv.org/pdf/2411.00259.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Smerkous, Qinxun Bai, Fuxin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00259">Enhancing Diversity in Bayesian Deep Learning via Hyperspherical Energy Minimization of CKA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Particle-based Bayesian deep learning often requires a similarity metric to compare two networks. However, naive similarity metrics lack permutation invariance and are inappropriate for comparing networks. Centered Kernel Alignment (CKA) on feature kernels has been proposed to compare deep networks but has not been used as an optimization objective in Bayesian deep learning. In this paper, we explore the use of CKA in Bayesian deep learning to generate diverse ensembles and hypernetworks that output a network posterior. Noting that CKA projects kernels onto a unit hypersphere and that directly optimizing the CKA objective leads to diminishing gradients when two networks are very similar. We propose adopting the approach of hyperspherical energy (HE) on top of CKA kernels to address this drawback and improve training stability. Additionally, by leveraging CKA-based feature kernels, we derive feature repulsive terms applied to synthetically generated outlier examples. Experiments on both diverse ensembles and hypernetworks show that our approach significantly outperforms baselines in terms of uncertainty quantification in both synthetic and realistic outlier detection tasks.
<div id='section'>Paperid: <span id='pid'>1093, <a href='https://arxiv.org/pdf/2410.21081.pdf' target='_blank'>https://arxiv.org/pdf/2410.21081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benjamin Schiffer, Lucas Janson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21081">Foundations of Safe Online Reinforcement Learning in the Linear Quadratic Regulator: Generalized Baselines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many practical applications of online reinforcement learning require the satisfaction of safety constraints while learning about the unknown environment. In this work, we establish theoretical foundations for reinforcement learning with safety constraints by studying the canonical problem of Linear Quadratic Regulator learning with unknown dynamics, but with the additional constraint that the position must stay within a safe region for the entire trajectory with high probability. Our primary contribution is a general framework for studying stronger baselines of nonlinear controllers that are better suited for constrained problems than linear controllers. Due to the difficulty of analyzing non-linear controllers in a constrained problem, we focus on 1-dimensional state- and action- spaces, however we also discuss how we expect the high-level takeaways can generalize to higher dimensions. Using our framework, we show that for \emph{any} non-linear baseline satisfying natural assumptions, $\tilde{O}_T(\sqrt{T})$-regret is possible when the noise distribution has sufficiently large support, and $\tilde{O}_T(T^{2/3})$-regret is possible for \emph{any} subgaussian noise distribution. In proving these results, we introduce a new uncertainty estimation bound for nonlinear controls which shows that enforcing safety in the presence of sufficient noise can provide ``free exploration'' that compensates for the added cost of uncertainty in safety-constrained control.
<div id='section'>Paperid: <span id='pid'>1094, <a href='https://arxiv.org/pdf/2410.14582.pdf' target='_blank'>https://arxiv.org/pdf/2410.14582.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juyeon Heo, Miao Xiong, Christina Heinze-Deml, Jaya Narain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14582">Do LLMs estimate uncertainty well in instruction-following?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) could be valuable personal AI agents across various domains, provided they can precisely follow user instructions. However, recent studies have shown significant limitations in LLMs' instruction-following capabilities, raising concerns about their reliability in high-stakes applications. Accurately estimating LLMs' uncertainty in adhering to instructions is critical to mitigating deployment risks. We present, to our knowledge, the first systematic evaluation of the uncertainty estimation abilities of LLMs in the context of instruction-following. Our study identifies key challenges with existing instruction-following benchmarks, where multiple factors are entangled with uncertainty stems from instruction-following, complicating the isolation and comparison across methods and models. To address these issues, we introduce a controlled evaluation setup with two benchmark versions of data, enabling a comprehensive comparison of uncertainty estimation methods under various conditions. Our findings show that existing uncertainty methods struggle, particularly when models make subtle errors in instruction following. While internal model states provide some improvement, they remain inadequate in more complex scenarios. The insights from our controlled evaluation setups provide a crucial understanding of LLMs' limitations and potential for uncertainty estimation in instruction-following tasks, paving the way for more trustworthy AI agents.
<div id='section'>Paperid: <span id='pid'>1095, <a href='https://arxiv.org/pdf/2409.13466.pdf' target='_blank'>https://arxiv.org/pdf/2409.13466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniele Malpetti, Laura Azzimonti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13466">Global Outlier Detection in a Federated Learning Setting with Isolation Forest</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel strategy for detecting global outliers in a federated learning setting, targeting in particular cross-silo scenarios. Our approach involves the use of two servers and the transmission of masked local data from clients to one of the servers. The masking of the data prevents the disclosure of sensitive information while still permitting the identification of outliers. Moreover, to further safeguard privacy, a permutation mechanism is implemented so that the server does not know which client owns any masked data point. The server performs outlier detection on the masked data, using either Isolation Forest or its extended version, and then communicates outlier information back to the clients, allowing them to identify and remove outliers in their local datasets before starting any subsequent federated model training. This approach provides comparable results to a centralized execution of Isolation Forest algorithms on plain data.
<div id='section'>Paperid: <span id='pid'>1096, <a href='https://arxiv.org/pdf/2409.12535.pdf' target='_blank'>https://arxiv.org/pdf/2409.12535.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simone Fassio, Simone Monaco, Daniele Apiletti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.12535">Deep Probability Segmentation: Are segmentation models probability estimators?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has revolutionized various fields by enabling highly accurate predictions and estimates. One important application is probabilistic prediction, where models estimate the probability of events rather than deterministic outcomes. This approach is particularly relevant and, therefore, still unexplored for segmentation tasks where each pixel in an image needs to be classified. Conventional models often overlook the probabilistic nature of labels, but accurate uncertainty estimation is crucial for improving the reliability and applicability of models.
  In this study, we applied Calibrated Probability Estimation (CaPE) to segmentation tasks to evaluate its impact on model calibration. Our results indicate that while CaPE improves calibration, its effect is less pronounced compared to classification tasks, suggesting that segmentation models can inherently provide better probability estimates. We also investigated the influence of dataset size and bin optimization on the effectiveness of calibration. Our results emphasize the expressive power of segmentation models as probability estimators and incorporate probabilistic reasoning, which is crucial for applications requiring precise uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>1097, <a href='https://arxiv.org/pdf/2409.01175.pdf' target='_blank'>https://arxiv.org/pdf/2409.01175.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrija Djurisic, Rosanne Liu, Mladen Nikolic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01175">Logit Scaling for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The safe deployment of machine learning and AI models in open-world settings hinges critically on the ability to detect out-of-distribution (OOD) data accurately, data samples that contrast vastly from what the model was trained with. Current approaches to OOD detection often require further training the model, and/or statistics about the training data which may no longer be accessible. Additionally, many existing OOD detection methods struggle to maintain performance when transferred across different architectures. Our research tackles these issues by proposing a simple, post-hoc method that does not require access to the training data distribution, keeps a trained network intact, and holds strong performance across a variety of architectures. Our method, Logit Scaling (LTS), as the name suggests, simply scales the logits in a manner that effectively distinguishes between in-distribution (ID) and OOD samples. We tested our method on benchmarks across various scales, including CIFAR-10, CIFAR-100, ImageNet and OpenOOD. The experiments cover 3 ID and 14 OOD datasets, as well as 9 model architectures. Overall, we demonstrate state-of-the-art performance, robustness and adaptability across different architectures, paving the way towards a universally applicable solution for advanced OOD detection.
<div id='section'>Paperid: <span id='pid'>1098, <a href='https://arxiv.org/pdf/2408.14229.pdf' target='_blank'>https://arxiv.org/pdf/2408.14229.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leonid Erlygin, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14229">Holistic Uncertainty Estimation For Open-Set Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty estimation is a critical challenge in open-set recognition, where a probe biometric sample may belong to an unknown identity. It can be addressed through sample quality estimation via probabilistic embeddings. However, the low variance of probabilistic embedding only partly implies a low identification error probability: an embedding of a sample could be close to several classes in a gallery, thus yielding high uncertainty despite high sample quality. We propose HolUE - a holistic uncertainty estimation method based on a Bayesian probabilistic model; it is aware of two sources of ambiguity in the open-set recognition system: (1) the gallery uncertainty caused by overlapping classes and (2) the uncertainty of embeddings. Challenging open-set recognition datasets, such as IJB-C for the image domain and VoxBlink for the audio domain, serve as a testbed for our method. We also provide a new open-set recognition protocol for the identification of whales and dolphins. In all cases, HolUE better identifies recognition errors than alternative uncertainty estimation methods, including those based solely on sample quality.
<div id='section'>Paperid: <span id='pid'>1099, <a href='https://arxiv.org/pdf/2408.12322.pdf' target='_blank'>https://arxiv.org/pdf/2408.12322.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>TamÃ¡s Matuszka, PÃ©ter Hajas, DÃ¡vid Szeghy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12322">Multimodal Foundational Models for Unsupervised 3D General Obstacle Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current autonomous driving perception models primarily rely on supervised learning with predefined categories. However, these models struggle to detect general obstacles not included in the fixed category set due to their variability and numerous edge cases. To address this issue, we propose a combination of multimodal foundational model-based obstacle segmentation with traditional unsupervised computational geometry-based outlier detection. Our approach operates offline, allowing us to leverage non-causality, and utilizes training-free methods. This enables the detection of general obstacles in 3D without the need for expensive retraining. To overcome the limitations of publicly available obstacle detection datasets, we collected and annotated our dataset, which includes various obstacles even in distant regions.
<div id='section'>Paperid: <span id='pid'>1100, <a href='https://arxiv.org/pdf/2408.09791.pdf' target='_blank'>https://arxiv.org/pdf/2408.09791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seoyoung Cho, Jaesung Hwang, Kwan-Young Bak, Dongha Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09791">ALTBI: Constructing Improved Outlier Detection Models via Optimization of Inlier-Memorization Effect</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) is the task of identifying unusual observations (or outliers) from a given or upcoming data by learning unique patterns of normal observations (or inliers). Recently, a study introduced a powerful unsupervised OD (UOD) solver based on a new observation of deep generative models, called inlier-memorization (IM) effect, which suggests that generative models memorize inliers before outliers in early learning stages. In this study, we aim to develop a theoretically principled method to address UOD tasks by maximally utilizing the IM effect. We begin by observing that the IM effect is observed more clearly when the given training data contain fewer outliers. This finding indicates a potential for enhancing the IM effect in UOD regimes if we can effectively exclude outliers from mini-batches when designing the loss function. To this end, we introduce two main techniques: 1) increasing the mini-batch size as the model training proceeds and 2) using an adaptive threshold to calculate the truncated loss function. We theoretically show that these two techniques effectively filter out outliers from the truncated loss function, allowing us to utilize the IM effect to the fullest. Coupled with an additional ensemble strategy, we propose our method and term it Adaptive Loss Truncation with Batch Increment (ALTBI). We provide extensive experimental results to demonstrate that ALTBI achieves state-of-the-art performance in identifying outliers compared to other recent methods, even with significantly lower computation costs. Additionally, we show that our method yields robust performances when combined with privacy-preserving algorithms.
<div id='section'>Paperid: <span id='pid'>1101, <a href='https://arxiv.org/pdf/2408.08432.pdf' target='_blank'>https://arxiv.org/pdf/2408.08432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdur R. Fayjie, Jutika Borah, Florencia Carbone, Jan Tack, Patrick Vandewalle
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08432">Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has shown tremendous progress in a wide range of digital pathology and medical image classification tasks. Its integration into safe clinical decision-making support requires robust and reliable models. However, real-world data comes with diversities that often lie outside the intended source distribution. Moreover, when test samples are dramatically different, clinical decision-making is greatly affected. Quantifying predictive uncertainty in models is crucial for well-calibrated predictions and determining when (or not) to trust a model. Unfortunately, many works have overlooked the importance of predictive uncertainty estimation. This paper evaluates whether predictive uncertainty estimation adds robustness to deep learning-based diagnostic decision-making systems. We investigate the effect of various carcinoma distribution shift scenarios on predictive performance and calibration. We first systematically investigate three popular methods for improving predictive uncertainty: Monte Carlo dropout, deep ensemble, and few-shot learning on lung adenocarcinoma classification as a primary disease in whole slide images. Secondly, we compare the effectiveness of the methods in terms of performance and calibration under clinically relevant distribution shifts such as in-distribution shifts comprising primary disease sub-types and other characterization analysis data; out-of-distribution shifts comprising well-differentiated cases, different organ origin, and imaging modality shifts. While studies on uncertainty estimation exist, to our best knowledge, no rigorous large-scale benchmark compares predictive uncertainty estimation including these dataset shifts for lung carcinoma classification.
<div id='section'>Paperid: <span id='pid'>1102, <a href='https://arxiv.org/pdf/2408.02908.pdf' target='_blank'>https://arxiv.org/pdf/2408.02908.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryohei Oura, Yuji Ito
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02908">Dirichlet Logistic Gaussian Processes for Evaluation of Black-Box Stochastic Systems under Complex Requirements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The requirement-driven performance evaluation of a black-box cyber-physical system (CPS) that utilizes machine learning methods has proven to be an effective way to assess the quality of the CPS. However, the distributional evaluation of the performance has been poorly considered. Although many uncertainty estimation methods have been advocated, they have not successfully estimated highly complex performance distributions under small data. In this paper, we propose a method to distributionally evaluate the performance under complex requirements using small input-trajectory data. To handle the unknown complex probability distributions under small data, we discretize the corresponding performance measure, yielding a discrete random process over an input region. Then, we propose a semiparametric Bayesian model of the discrete process based on a Dirichlet random field whose parameter function is represented by multiple logistic Gaussian processes (LGPs). The Dirichlet posterior parameter function is estimated through the LGP posteriors in a reasonable and conservative fashion. We show that the proposed Bayesian model converges to the true discrete random process as the number of data becomes large enough. We also empirically demonstrate the effectiveness of the proposed method by simulation.
<div id='section'>Paperid: <span id='pid'>1103, <a href='https://arxiv.org/pdf/2408.02052.pdf' target='_blank'>https://arxiv.org/pdf/2408.02052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mateusz Ochal, Massimiliano Patacchiola, Malik Boudiaf, Sen Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02052">EOL: Transductive Few-Shot Open-Set Recognition by Enhancing Outlier Logits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In Few-Shot Learning (FSL), models are trained to recognise unseen objects from a query set, given a few labelled examples from a support set. In standard FSL, models are evaluated on query instances sampled from the same class distribution of the support set. In this work, we explore the more nuanced and practical challenge of Open-Set Few-Shot Recognition (OSFSL). Unlike standard FSL, OSFSL incorporates unknown classes into the query set, thereby requiring the model not only to classify known classes but also to identify outliers. Building on the groundwork laid by previous studies, we define a novel transductive inference technique that leverages the InfoMax principle to exploit the unlabelled query set. We called our approach the Enhanced Outlier Logit (EOL) method. EOL refines class prototype representations through model calibration, effectively balancing the inlier-outlier ratio. This calibration enhances pseudo-label accuracy for the query set and improves the optimisation objective within the transductive inference process. We provide a comprehensive empirical evaluation demonstrating that EOL consistently surpasses traditional methods, recording performance improvements ranging from approximately $+1.3%$ to $+6.3%$ across a variety of classification and outlier detection metrics and benchmarks, even in the presence of inlier-outlier imbalance.
<div id='section'>Paperid: <span id='pid'>1104, <a href='https://arxiv.org/pdf/2407.17356.pdf' target='_blank'>https://arxiv.org/pdf/2407.17356.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Hummos, Felipe del RÃ­o, Brabeeba Mien Wang, Julio Hurtado, Cristian B. Calderon, Guangyu Robert Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.17356">Gradient-based inference of abstract task representations for generalization in neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Humans and many animals show remarkably adaptive behavior and can respond differently to the same input depending on their internal goals. The brain not only represents the intermediate abstractions needed to perform a computation but also actively maintains a representation of the computation itself (task abstraction). Such separation of the computation and its abstraction is associated with faster learning, flexible decision-making, and broad generalization capacity. We investigate if such benefits might extend to neural networks trained with task abstractions. For such benefits to emerge, one needs a task inference mechanism that possesses two crucial abilities: First, the ability to infer abstract task representations when no longer explicitly provided (task inference), and second, manipulate task representations to adapt to novel problems (task recomposition). To tackle this, we cast task inference as an optimization problem from a variational inference perspective and ground our approach in an expectation-maximization framework. We show that gradients backpropagated through a neural network to a task representation layer are an efficient heuristic to infer current task demands, a process we refer to as gradient-based inference (GBI). Further iterative optimization of the task representation layer allows for recomposing abstractions to adapt to novel situations. Using a toy example, a novel image classifier, and a language model, we demonstrate that GBI provides higher learning efficiency and generalization to novel tasks and limits forgetting. Moreover, we show that GBI has unique advantages such as preserving information for uncertainty estimation and detecting out-of-distribution samples.
<div id='section'>Paperid: <span id='pid'>1105, <a href='https://arxiv.org/pdf/2407.11181.pdf' target='_blank'>https://arxiv.org/pdf/2407.11181.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ekaterina Zaychenkova, Dmitrii Iarchuk, Sergey Korchagin, Alexey Zaitsev, Egor Ershov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11181">Expert-aware uncertainty estimation for quality control of neural-based blood typing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In medical diagnostics, accurate uncertainty estimation for neural-based models is essential for complementing second-opinion systems. Despite neural network ensembles' proficiency in this problem, a gap persists between actual uncertainties and predicted estimates. A major difficulty here is the lack of labels on the hardness of examples: a typical dataset includes only ground truth target labels, making the uncertainty estimation problem almost unsupervised. Our novel approach narrows this gap by integrating expert assessments of case complexity into the neural network's learning process, utilizing both definitive target labels and supplementary complexity ratings. We validate our methodology for blood typing, leveraging a new dataset "BloodyWell" unique in augmenting labeled reaction images with complexity scores from six medical specialists. Experiments demonstrate enhancement of our approach in uncertainty prediction, achieving a 2.5-fold improvement with expert labels and a 35% increase in performance with estimates of neural-based expert consensus.
<div id='section'>Paperid: <span id='pid'>1106, <a href='https://arxiv.org/pdf/2407.10844.pdf' target='_blank'>https://arxiv.org/pdf/2407.10844.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joseph Musielewicz, Janice Lan, Matt Uyttendaele, John R. Kitchin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10844">Improved Uncertainty Estimation of Graph Neural Network Potentials Using Engineered Latent Space Distances</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph neural networks (GNNs) have been shown to be astonishingly capable models for molecular property prediction, particularly as surrogates for expensive density functional theory calculations of relaxed energy for novel material discovery. However, one limitation of GNNs in this context is the lack of useful uncertainty prediction methods, as this is critical to the material discovery pipeline. In this work, we show that uncertainty quantification for relaxed energy calculations is more complex than uncertainty quantification for other kinds of molecular property prediction, due to the effect that structure optimizations have on the error distribution. We propose that distribution-free techniques are more useful tools for assessing calibration, recalibrating, and developing uncertainty prediction methods for GNNs performing relaxed energy calculations. We also develop a relaxed energy task for evaluating uncertainty methods for equivariant GNNs, based on distribution-free recalibration and using the Open Catalyst Project dataset. We benchmark a set of popular uncertainty prediction methods on this task, and show that latent distance methods, with our novel improvements, are the most well-calibrated and economical approach for relaxed energy calculations. Finally, we demonstrate that our latent space distance method produces results which align with our expectations on a clustering example, and on specific equation of state and adsorbate coverage examples from outside the training dataset.
<div id='section'>Paperid: <span id='pid'>1107, <a href='https://arxiv.org/pdf/2407.02089.pdf' target='_blank'>https://arxiv.org/pdf/2407.02089.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriele Franch, Elena Tomasi, Rishabh Wanjari, Virginia Poli, Chiara Cardinali, Pier Paolo Alberoni, Marco Cristoforetti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02089">GPTCast: a weather language model for precipitation nowcasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces GPTCast, a generative deep-learning method for ensemble nowcast of radar-based precipitation, inspired by advancements in large language models (LLMs). We employ a GPT model as a forecaster to learn spatiotemporal precipitation dynamics using tokenized radar images. The tokenizer is based on a Quantized Variational Autoencoder featuring a novel reconstruction loss tailored for the skewed distribution of precipitation that promotes faithful reconstruction of high rainfall rates. The approach produces realistic ensemble forecasts and provides probabilistic outputs with accurate uncertainty estimation. The model is trained without resorting to randomness, all variability is learned solely from the data and exposed by model at inference for ensemble generation. We train and test GPTCast using a 6-year radar dataset over the Emilia-Romagna region in Northern Italy, showing superior results compared to state-of-the-art ensemble extrapolation methods.
<div id='section'>Paperid: <span id='pid'>1108, <a href='https://arxiv.org/pdf/2406.10943.pdf' target='_blank'>https://arxiv.org/pdf/2406.10943.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weiqing Xiao, Wei Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10943">Rectified Iterative Disparity for Stereo Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Both uncertainty-assisted and iteration-based methods have achieved great success in stereo matching. However, existing uncertainty estimation methods take a single image and the corresponding disparity as input, which imposes higher demands on the estimation network. In this paper, we propose Cost volume-based disparity Uncertainty Estimation (UEC). Based on the rich similarity information in the cost volume coming from the image pairs, the proposed UEC can achieve competitive performance with low computational cost. Secondly, we propose two methods of uncertainty-assisted disparity estimation, Uncertainty-based Disparity Rectification (UDR) and Uncertainty-based Disparity update Conditioning (UDC). These two methods optimise the disparity update process of the iterative-based approach without adding extra parameters. In addition, we propose Disparity Rectification loss that significantly improves the accuracy of small amount of disparity updates. We present a high-performance stereo architecture, DR Stereo, which is a combination of the proposed methods. Experimental results from SceneFlow, KITTI, Middlebury 2014, and ETH3D show that DR-Stereo achieves very competitive disparity estimation performance.
<div id='section'>Paperid: <span id='pid'>1109, <a href='https://arxiv.org/pdf/2406.04317.pdf' target='_blank'>https://arxiv.org/pdf/2406.04317.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tristan Cinquin, Robert Bamler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04317">Regularized KL-Divergence for Well-Defined Function-Space Variational Inference in Bayesian neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian neural networks (BNN) promise to combine the predictive performance of neural networks with principled uncertainty modeling important for safety-critical systems and decision making. However, posterior uncertainty estimates depend on the choice of prior, and finding informative priors in weight-space has proven difficult. This has motivated variational inference (VI) methods that pose priors directly on the function generated by the BNN rather than on weights. In this paper, we address a fundamental issue with such function-space VI approaches pointed out by Burt et al. (2020), who showed that the objective function (ELBO) is negative infinite for most priors of interest. Our solution builds on generalized VI (Knoblauch et al., 2019) with the regularized KL divergence (Quang, 2019) and is, to the best of our knowledge, the first well-defined variational objective for function-space inference in BNNs with Gaussian process (GP) priors. Experiments show that our method incorporates the properties specified by the GP prior on synthetic and small real-world data sets, and provides competitive uncertainty estimates for regression, classification and out-of-distribution detection compared to BNN baselines with both function and weight-space priors.
<div id='section'>Paperid: <span id='pid'>1110, <a href='https://arxiv.org/pdf/2405.12658.pdf' target='_blank'>https://arxiv.org/pdf/2405.12658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Azizmalayeri, Ameen Abu-Hanna, Giovanni CinÃ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12658">Mitigating Overconfidence in Out-of-Distribution Detection by Capturing Extreme Activations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) instances is crucial for the reliable deployment of machine learning models in real-world scenarios. OOD inputs are commonly expected to cause a more uncertain prediction in the primary task; however, there are OOD cases for which the model returns a highly confident prediction. This phenomenon, denoted as "overconfidence", presents a challenge to OOD detection. Specifically, theoretical evidence indicates that overconfidence is an intrinsic property of certain neural network architectures, leading to poor OOD detection. In this work, we address this issue by measuring extreme activation values in the penultimate layer of neural networks and then leverage this proxy of overconfidence to improve on several OOD detection baselines. We test our method on a wide array of experiments spanning synthetic data and real-world data, tabular and image datasets, multiple architectures such as ResNet and Transformer, different training loss functions, and include the scenarios examined in previous theoretical work. Compared to the baselines, our method often grants substantial improvements, with double-digit increases in OOD detection AUC, and it does not damage performance in any scenario.
<div id='section'>Paperid: <span id='pid'>1111, <a href='https://arxiv.org/pdf/2404.10314.pdf' target='_blank'>https://arxiv.org/pdf/2404.10314.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexey Kornaev, Elena Kornaeva, Oleg Ivanov, Ilya Pershin, Danis Alukaev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10314">Awareness of uncertainty in classification using a multivariate model and multi-views</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One of the ways to make artificial intelligence more natural is to give it some room for doubt. Two main questions should be resolved in that way. First, how to train a model to estimate uncertainties of its own predictions? And then, what to do with the uncertain predictions if they appear? First, we proposed an uncertainty-aware negative log-likelihood loss for the case of N-dimensional multivariate normal distribution with spherical variance matrix to the solution of N-classes classification tasks. The loss is similar to the heteroscedastic regression loss. The proposed model regularizes uncertain predictions, and trains to calculate both the predictions and their uncertainty estimations. The model fits well with the label smoothing technique. Second, we expanded the limits of data augmentation at the training and test stages, and made the trained model to give multiple predictions for a given number of augmented versions of each test sample. Given the multi-view predictions together with their uncertainties and confidences, we proposed several methods to calculate final predictions, including mode values and bin counts with soft and hard weights. For the latter method, we formalized the model tuning task in the form of multimodal optimization with non-differentiable criteria of maximum accuracy, and applied particle swarm optimization to solve the tuning task. The proposed methodology was tested using CIFAR-10 dataset with clean and noisy labels and demonstrated good results in comparison with other uncertainty estimation methods related to sample selection, co-teaching, and label smoothing.
<div id='section'>Paperid: <span id='pid'>1112, <a href='https://arxiv.org/pdf/2404.00589.pdf' target='_blank'>https://arxiv.org/pdf/2404.00589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenyu Qian, Yiming Qian, Yuting Song, Fei Gao, Hai Jin, Chen Yu, Xia Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00589">Harnessing the Power of Large Language Model for Uncertainty Aware Graph Processing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Handling graph data is one of the most difficult tasks. Traditional techniques, such as those based on geometry and matrix factorization, rely on assumptions about the data relations that become inadequate when handling large and complex graph data. On the other hand, deep learning approaches demonstrate promising results in handling large graph data, but they often fall short of providing interpretable explanations. To equip the graph processing with both high accuracy and explainability, we introduce a novel approach that harnesses the power of a large language model (LLM), enhanced by an uncertainty-aware module to provide a confidence score on the generated answer. We experiment with our approach on two graph processing tasks: few-shot knowledge graph completion and graph classification. Our results demonstrate that through parameter efficient fine-tuning, the LLM surpasses state-of-the-art algorithms by a substantial margin across ten diverse benchmark datasets. Moreover, to address the challenge of explainability, we propose an uncertainty estimation based on perturbation, along with a calibration scheme to quantify the confidence scores of the generated answers. Our confidence measure achieves an AUC of 0.8 or higher on seven out of the ten datasets in predicting the correctness of the answer generated by LLM.
<div id='section'>Paperid: <span id='pid'>1113, <a href='https://arxiv.org/pdf/2403.17224.pdf' target='_blank'>https://arxiv.org/pdf/2403.17224.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mihir Mulye, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17224">Uncertainty Quantification for Gradient-based Explanations in Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explanation methods help understand the reasons for a model's prediction. These methods are increasingly involved in model debugging, performance optimization, and gaining insights into the workings of a model. With such critical applications of these methods, it is imperative to measure the uncertainty associated with the explanations generated by these methods. In this paper, we propose a pipeline to ascertain the explanation uncertainty of neural networks by combining uncertainty estimation methods and explanation methods. We use this pipeline to produce explanation distributions for the CIFAR-10, FER+, and California Housing datasets. By computing the coefficient of variation of these distributions, we evaluate the confidence in the explanation and determine that the explanations generated using Guided Backpropagation have low uncertainty associated with them. Additionally, we compute modified pixel insertion/deletion metrics to evaluate the quality of the generated explanations.
<div id='section'>Paperid: <span id='pid'>1114, <a href='https://arxiv.org/pdf/2403.17212.pdf' target='_blank'>https://arxiv.org/pdf/2403.17212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matias Valdenegro-Toro, Mihir Mulye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17212">Sanity Checks for Explanation Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explanations for machine learning models can be hard to interpret or be wrong. Combining an explanation method with an uncertainty estimation method produces explanation uncertainty. Evaluating explanation uncertainty is difficult. In this paper we propose sanity checks for uncertainty explanation methods, where a weight and data randomization tests are defined for explanations with uncertainty, allowing for quick tests to combinations of uncertainty and explanation methods. We experimentally show the validity and effectiveness of these tests on the CIFAR10 and California Housing datasets, noting that Ensembles seem to consistently pass both tests with Guided Backpropagation, Integrated Gradients, and LIME explanations.
<div id='section'>Paperid: <span id='pid'>1115, <a href='https://arxiv.org/pdf/2403.13170.pdf' target='_blank'>https://arxiv.org/pdf/2403.13170.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jagatpreet Singh Nir, Dennis Giaya, Hanumant Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13170">On Designing Consistent Covariance Recovery from a Deep Learning Visual Odometry Engine</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning techniques have significantly advanced in providing accurate visual odometry solutions by leveraging large datasets. However, generating uncertainty estimates for these methods remains a challenge. Traditional sensor fusion approaches in a Bayesian framework are well-established, but deep learning techniques with millions of parameters lack efficient methods for uncertainty estimation.
  This paper addresses the issue of uncertainty estimation for pre-trained deep-learning models in monocular visual odometry. We propose formulating a factor graph on an implicit layer of the deep learning network to recover relative covariance estimates, which allows us to determine the covariance of the Visual Odometry (VO) solution. We showcase the consistency of the deep learning engine's covariance approximation with an empirical analysis of the covariance model on the EUROC datasets to demonstrate the correctness of our formulation.
<div id='section'>Paperid: <span id='pid'>1116, <a href='https://arxiv.org/pdf/2403.11532.pdf' target='_blank'>https://arxiv.org/pdf/2403.11532.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Novello, Joseba Dalmau, LÃ©o Andeol
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11532">Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Research on Out-Of-Distribution (OOD) detection focuses mainly on building scores that efficiently distinguish OOD data from In Distribution (ID) data. On the other hand, Conformal Prediction (CP) uses non-conformity scores to construct prediction sets with probabilistic coverage guarantees. In this work, we propose to use CP to better assess the efficiency of OOD scores. Specifically, we emphasize that in standard OOD benchmark settings, evaluation metrics can be overly optimistic due to the finite sample size of the test dataset. Based on the work of (Bates et al., 2022), we define new conformal AUROC and conformal FRP@TPR95 metrics, which are corrections that provide probabilistic conservativeness guarantees on the variability of these metrics. We show the effect of these corrections on two reference OOD and anomaly detection benchmarks, OpenOOD (Yang et al., 2022) and ADBench (Han et al., 2022). We also show that the benefits of using OOD together with CP apply the other way around by using OOD scores as non-conformity scores, which results in improving upon current CP methods. One of the key messages of these contributions is that since OOD is concerned with designing scores and CP with interpreting these scores, the two fields may be inherently intertwined.
<div id='section'>Paperid: <span id='pid'>1117, <a href='https://arxiv.org/pdf/2403.06681.pdf' target='_blank'>https://arxiv.org/pdf/2403.06681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jintao Huang, Yiu-Ming Cheung, Chi-Man Vong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06681">PLOOD: Partial Label Learning with Out-of-distribution Objects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing Partial Label Learning (PLL) methods posit that training and test data adhere to the same distribution, a premise that frequently does not hold in practical application where Out-of-Distribution (OOD) objects are present. We introduce the OODPLL paradigm to tackle this significant yet underexplored issue. And our newly proposed PLOOD framework enables PLL to tackle OOD objects through Positive-Negative Sample Augmented (PNSA) feature learning and Partial Energy (PE)-based label refinement. The PNSA module enhances feature discrimination and OOD recognition by simulating in- and out-of-distribution instances, which employ structured positive and negative sample augmentation, in contrast to conventional PLL methods struggling to distinguish OOD samples. The PE scoring mechanism combines label confidence with energy-based uncertainty estimation, thereby reducing the impact of imprecise supervision and effectively achieving label disambiguation. Experimental results on CIFAR-10 and CIFAR-100, alongside various OOD datasets, demonstrate that conventional PLL methods exhibit substantial degradation in OOD scenarios, underscoring the necessity of incorporating OOD considerations in PLL approaches. Ablation studies show that PNSA feature learning and PE-based label refinement are necessary for PLOOD to work, offering a robust solution for open-set PLL problems.
<div id='section'>Paperid: <span id='pid'>1118, <a href='https://arxiv.org/pdf/2402.17686.pdf' target='_blank'>https://arxiv.org/pdf/2402.17686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis Itza Vazquez-Salazar, Silvan KÃ¤ser, Markus Meuwly
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17686">Outlier-Detection for Reactive Machine Learned Potential Energy Surfaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification (UQ) to detect samples with large expected errors (outliers) is applied to reactive molecular potential energy surfaces (PESs). Three methods - Ensembles, Deep Evidential Regression (DER), and Gaussian Mixture Models (GMM) - were applied to the H-transfer reaction between ${\it syn-}$Criegee and vinyl hydroxyperoxide. The results indicate that ensemble models provide the best results for detecting outliers, followed by GMM. For example, from a pool of 1000 structures with the largest uncertainty, the detection quality for outliers is $\sim 90$ \% and $\sim 50$ \%, respectively, if 25 or 1000 structures with large errors are sought. On the contrary, the limitations of the statistical assumptions of DER greatly impacted its prediction capabilities. Finally, a structure-based indicator was found to be correlated with large average error, which may help to rapidly classify new structures into those that provide an advantage for refining the neural network.
<div id='section'>Paperid: <span id='pid'>1119, <a href='https://arxiv.org/pdf/2402.14418.pdf' target='_blank'>https://arxiv.org/pdf/2402.14418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasily Kostumov, Bulat Nutfullin, Oleg Pilipenko, Eugene Ilyushin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14418">Uncertainty-Aware Evaluation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in popularity recently due to their impressive performance in several vision-language tasks. Current evaluation methods, however, overlook an essential component: uncertainty, which is crucial for a comprehensive assessment of VLMs. Addressing this oversight, we present a benchmark incorporating uncertainty quantification into evaluating VLMs.
  Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question Answering (VQA) task. We examine models on 5 datasets that evaluate various vision-language capabilities.
  Using conformal prediction as an uncertainty estimation approach, we demonstrate that the models' uncertainty is not aligned with their accuracy. Specifically, we show that models with the highest accuracy may also have the highest uncertainty, which confirms the importance of measuring it for VLMs. Our empirical findings also reveal a correlation between model uncertainty and its language model part.
<div id='section'>Paperid: <span id='pid'>1120, <a href='https://arxiv.org/pdf/2402.14184.pdf' target='_blank'>https://arxiv.org/pdf/2402.14184.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Polina Proskura, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14184">Beyond Simple Averaging: Improving NLP Ensemble Performance with Topological-Data-Analysis-Based Weighting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In machine learning, ensembles are important tools for improving the model performance. In natural language processing specifically, ensembles boost the performance of a method due to multiple large models available in open source. However, existing approaches mostly rely on simple averaging of predictions by ensembles with equal weights for each model, ignoring differences in the quality and conformity of models. We propose to estimate weights for ensembles of NLP models using not only knowledge of their individual performance but also their similarity to each other. By adopting distance measures based on Topological Data Analysis (TDA), we improve our ensemble. The quality improves for both text classification accuracy and relevant uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1121, <a href='https://arxiv.org/pdf/2402.10477.pdf' target='_blank'>https://arxiv.org/pdf/2402.10477.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Genki Osada, Tsubasa Takahashi, Takashi Nishide
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10477">Understanding Likelihood of Normalizing Flow and Image Complexity through the Lens of Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial to safety-critical machine learning applications and has been extensively studied. While recent studies have predominantly focused on classifier-based methods, research on deep generative model (DGM)-based methods have lagged relatively. This disparity may be attributed to a perplexing phenomenon: DGMs often assign higher likelihoods to unknown OOD inputs than to their known training data. This paper focuses on explaining the underlying mechanism of this phenomenon. We propose a hypothesis that less complex images concentrate in high-density regions in the latent space, resulting in a higher likelihood assignment in the Normalizing Flow (NF). We experimentally demonstrate its validity for five NF architectures, concluding that their likelihood is untrustworthy. Additionally, we show that this problem can be alleviated by treating image complexity as an independent variable. Finally, we provide evidence of the potential applicability of our hypothesis in another DGM, PixelCNN++.
<div id='section'>Paperid: <span id='pid'>1122, <a href='https://arxiv.org/pdf/2402.06537.pdf' target='_blank'>https://arxiv.org/pdf/2402.06537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Evan D. Cook, Marc-Antoine Lavoie, Steven L. Waslander
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06537">Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.
<div id='section'>Paperid: <span id='pid'>1123, <a href='https://arxiv.org/pdf/2401.09492.pdf' target='_blank'>https://arxiv.org/pdf/2401.09492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>RubÃ©n Antonio GarcÃ­a-Ruiz, JosÃ© Luis Blanco-Claraco, Javier LÃ³pez-MartÃ­nez, Ãngel JesÃºs CallejÃ³n-Ferre
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.09492">Uncertainty-Aware Calibration of a Hot-Wire Anemometer With Gaussian Process Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Expensive ultrasonic anemometers are usually required to measure wind speed accurately. The aim of this work is to overcome the loss of accuracy of a low cost hot-wire anemometer caused by the changes of air temperature, by means of a probabilistic calibration using Gaussian Process Regression. Gaussian Process Regression is a non-parametric, Bayesian, and supervised learning method designed to make predictions of an unknown target variable as a function of one or more known input variables. Our approach is validated against real datasets, obtaining a good performance in inferring the actual wind speed values. By performing, before its real use in the field, a calibration of the hot-wire anemometer taking into account air temperature, permits that the wind speed can be estimated for the typical range of ambient temperatures, including a grounded uncertainty estimation for each speed measure.
<div id='section'>Paperid: <span id='pid'>1124, <a href='https://arxiv.org/pdf/2401.05453.pdf' target='_blank'>https://arxiv.org/pdf/2401.05453.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alastair Anderberg, James Bailey, Ricardo J. G. B. Campello, Michael E. Houle, Henrique O. Marques, MiloÅ¡ RadovanoviÄ, Arthur Zimek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05453">Dimensionality-Aware Outlier Detection: Theoretical and Experimental Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a nonparametric method for outlier detection that takes full account of local variations in intrinsic dimensionality within the dataset. Using the theory of Local Intrinsic Dimensionality (LID), our 'dimensionality-aware' outlier detection method, DAO, is derived as an estimator of an asymptotic local expected density ratio involving the query point and a close neighbor drawn at random. The dimensionality-aware behavior of DAO is due to its use of local estimation of LID values in a theoretically-justified way. Through comprehensive experimentation on more than 800 synthetic and real datasets, we show that DAO significantly outperforms three popular and important benchmark outlier detection methods: Local Outlier Factor (LOF), Simplified LOF, and kNN.
<div id='section'>Paperid: <span id='pid'>1125, <a href='https://arxiv.org/pdf/2512.20949.pdf' target='_blank'>https://arxiv.org/pdf/2512.20949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shize Liang, Hongzhi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.20949">Neural Probe-Based Hallucination Detection for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models(LLMs) excel at text generation and knowledge question-answering tasks, but they are prone to generating hallucinated content, severely limiting their application in high-risk domains. Current hallucination detection methods based on uncertainty estimation and external knowledge retrieval suffer from the limitation that they still produce erroneous content at high confidence levels and rely heavily on retrieval efficiency and knowledge coverage. In contrast, probe methods that leverage the model's hidden-layer states offer real-time and lightweight advantages. However, traditional linear probes struggle to capture nonlinear structures in deep semantic spaces.To overcome these limitations, we propose a neural network-based framework for token-level hallucination detection. By freezing language model parameters, we employ lightweight MLP probes to perform nonlinear modeling of high-level hidden states. A multi-objective joint loss function is designed to enhance detection stability and semantic disambiguity. Additionally, we establish a layer position-probe performance response model, using Bayesian optimization to automatically search for optimal probe insertion layers and achieve superior training results.Experimental results on LongFact, HealthBench, and TriviaQA demonstrate that MLP probes significantly outperform state-of-the-art methods in accuracy, recall, and detection capability under low false-positive conditions.
<div id='section'>Paperid: <span id='pid'>1126, <a href='https://arxiv.org/pdf/2512.15228.pdf' target='_blank'>https://arxiv.org/pdf/2512.15228.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Songze Huo, Xiao-Ming Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.15228">Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The adsorption energy serves as a crucial descriptor for the large-scale screening of catalysts. Nevertheless, the limited distribution of training data for the extensively utilised machine learning interatomic potential (MLIP), predominantly sourced from near-equilibrium structures, results in unreliable adsorption structures and consequent adsorption energy predictions. In this context, we present DBCata, a deep generative model that integrates a periodic Brownian-bridge framework with an equivariant graph neural network to establish a low-dimensional transition manifold between unrelaxed and DFT-relaxed structures, without requiring explicit energy or force information. Upon training, DBCata effectively generates high-fidelity adsorption geometries, achieving an interatomic distance mean absolute error (DMAE) of 0.035 \textÅ on the Catalysis-Hub dataset, which is nearly three times superior to that of the current state-of-the-art machine learning potential models. Moreover, the corresponding DFT accuracy can be improved within 0.1 eV in 94\% of instances by identifying and refining anomalous predictions through a hybrid chemical-heuristic and self-supervised outlier detection approach. We demonstrate that the remarkable performance of DBCata facilitates accelerated high-throughput computational screening for efficient alloy catalysts in the oxygen reduction reaction, highlighting the potential of DBCata as a powerful tool for catalyst design and optimisation.
<div id='section'>Paperid: <span id='pid'>1127, <a href='https://arxiv.org/pdf/2512.14851.pdf' target='_blank'>https://arxiv.org/pdf/2512.14851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aslak Djupskås, Alexander Johannes Stasik, Signe Riemer-Sørensen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.14851">Unreliable Uncertainty Estimates with Monte Carlo Dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation is crucial for machine learning models, especially in safety-critical domains. While exact Bayesian inference offers a principled approach, it is often computationally infeasible for deep neural networks. Monte Carlo dropout (MCD) was proposed as an efficient approximation to Bayesian inference in deep learning by applying neuron dropout at inference time \citep{gal2016dropout}. Hence, the method generates multiple sub-models yielding a distribution of predictions to estimate uncertainty. We empirically investigate its ability to capture true uncertainty and compare to Gaussian Processes (GP) and Bayesian Neural Networks (BNN). We find that MCD struggles to accurately reflect the underlying true uncertainty, particularly failing to capture increased uncertainty in extrapolation and interpolation regions as observed in Bayesian models. The findings suggest that uncertainty estimates from MCD, as implemented and evaluated in these experiments, is not as reliable as those from traditional Bayesian approaches for capturing epistemic and aleatoric uncertainty.
<div id='section'>Paperid: <span id='pid'>1128, <a href='https://arxiv.org/pdf/2512.08969.pdf' target='_blank'>https://arxiv.org/pdf/2512.08969.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elias Hossain, Umesh Biswas, Charan Gudla, Sai Phani Parsa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.08969">Learning Robust Representations for Malicious Content Detection via Contrastive Sampling and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the Uncertainty Contrastive Framework (UCF), a Positive-Unlabeled (PU) representation learning framework that integrates uncertainty-aware contrastive loss, adaptive temperature scaling, and a self-attention-guided LSTM encoder to improve classification under noisy and imbalanced conditions. UCF dynamically adjusts contrastive weighting based on sample confidence, stabilizes training using positive anchors, and adapts temperature parameters to batch-level variability. Applied to malicious content classification, UCF-generated embeddings enable multiple traditional classifiers to achieve more than 93.38% accuracy, precision above 0.93, and near-perfect recall, with minimal false negatives and competitive ROC-AUC scores. Visual analyses confirm clear separation between positive and unlabeled instances, highlighting the framework's ability to produce calibrated, discriminative embeddings. These results position UCF as a robust and scalable solution for PU learning in high-stakes domains such as cybersecurity and biomedical text mining.
<div id='section'>Paperid: <span id='pid'>1129, <a href='https://arxiv.org/pdf/2512.04571.pdf' target='_blank'>https://arxiv.org/pdf/2512.04571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditi Naiknaware, Sanchit Singh, Hajar Homayouni, Salimeh Sekeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.04571">Temp-SCONE: A Novel Out-of-Distribution Detection and Domain Generalization Framework for Wild Data with Temporal Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open-world learning (OWL) requires models that can adapt to evolving environments while reliably detecting out-of-distribution (OOD) inputs. Existing approaches, such as SCONE, achieve robustness to covariate and semantic shifts but assume static environments, leading to degraded performance in dynamic domains. In this paper, we propose Temp-SCONE, a temporally consistent extension of SCONE designed to handle temporal shifts in dynamic environments. Temp-SCONE introduces a confidence-driven regularization loss based on Average Thresholded Confidence (ATC), penalizing instability in predictions across time steps while preserving SCONE's energy-margin separation. Experiments on dynamic datasets demonstrate that Temp-SCONE significantly improves robustness under temporal drift, yielding higher corrupted-data accuracy and more reliable OOD detection compared to SCONE. On distinct datasets without temporal continuity, Temp-SCONE maintains comparable performance, highlighting the importance and limitations of temporal regularization. Our theoretical insights on temporal stability and generalization error further establish Temp-SCONE as a step toward reliable OWL in evolving dynamic environments.
<div id='section'>Paperid: <span id='pid'>1130, <a href='https://arxiv.org/pdf/2512.02302.pdf' target='_blank'>https://arxiv.org/pdf/2512.02302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Varun Kumar Dasoju, Qingsu Cheng, Zeyun Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.02302">Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.
<div id='section'>Paperid: <span id='pid'>1131, <a href='https://arxiv.org/pdf/2511.22567.pdf' target='_blank'>https://arxiv.org/pdf/2511.22567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feyza Eksen, Stefan Oehmcke, Stefan Lüdtke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.22567">Where to Measure: Epistemic Uncertainty-Based Sensor Placement with ConvCNPs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate sensor placement is critical for modeling spatio-temporal systems such as environmental and climate processes. Neural Processes (NPs), particularly Convolutional Conditional Neural Processes (ConvCNPs), provide scalable probabilistic models with uncertainty estimates, making them well-suited for data-driven sensor placement. However, existing approaches rely on total predictive uncertainty, which conflates epistemic and aleatoric components, that may lead to suboptimal sensor selection in ambiguous regions. To address this, we propose expected reduction in epistemic uncertainty as a new acquisition function for sensor placement. To enable this, we extend ConvCNPs with a Mixture Density Networks (MDNs) output head for epistemic uncertainty estimation. Preliminary results suggest that epistemic uncertainty driven sensor placement more effectively reduces model error than approaches based on overall uncertainty.
<div id='section'>Paperid: <span id='pid'>1132, <a href='https://arxiv.org/pdf/2511.22236.pdf' target='_blank'>https://arxiv.org/pdf/2511.22236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Püttmann, Jonathan Jair Sànchez Contreras, Lennart Kowitz, Peter Lampen, Saumya Gupta, Davide Panzeri, Nina Hagemann, Qiaojie Xiong, Dirk M. Hermann, Cao Chen, Jianxu Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.22236">Bridging 3D Deep Learning and Curation for Analysis and High-Quality Segmentation in Practice</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate 3D microscopy image segmentation is critical for quantitative bioimage analysis but even state-of-the-art foundation models yield error-prone results. Therefore, manual curation is still widely used for either preparing high-quality training data or fixing errors before analysis. We present VessQC, an open-source tool for uncertainty-guided curation of large 3D microscopy segmentations. By integrating uncertainty maps, VessQC directs user attention to regions most likely containing biologically meaningful errors. In a preliminary user study uncertainty-guided correction significantly improved error detection recall from 67% to 94.0% (p=0.007) without a significant increase in total curation time. VessQC thus enables efficient, human-in-the-loop refinement of volumetric segmentations and bridges a key gap in real-world applications between uncertainty estimation and practical human-computer interaction. The software is freely available at github.com/MMV-Lab/VessQC.
<div id='section'>Paperid: <span id='pid'>1133, <a href='https://arxiv.org/pdf/2511.21607.pdf' target='_blank'>https://arxiv.org/pdf/2511.21607.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zarin Tahia Hossain, Mostafa Milani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.21607">Beyond Accuracy: An Empirical Study of Uncertainty Estimation in Imputation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Handling missing data is a central challenge in data-driven analysis. Modern imputation methods not only aim for accurate reconstruction but also differ in how they represent and quantify uncertainty. Yet, the reliability and calibration of these uncertainty estimates remain poorly understood. This paper presents a systematic empirical study of uncertainty in imputation, comparing representative methods from three major families: statistical (MICE, SoftImpute), distribution alignment (OT-Impute), and deep generative (GAIN, MIWAE, TabCSDI). Experiments span multiple datasets, missingness mechanisms (MCAR, MAR, MNAR), and missingness rates. Uncertainty is estimated through three complementary routes: multi-run variability, conditional sampling, and predictive-distribution modeling, and evaluated using calibration curves and the Expected Calibration Error (ECE). Results show that accuracy and calibration are often misaligned: models with high reconstruction accuracy do not necessarily yield reliable uncertainty. We analyze method-specific trade-offs among accuracy, calibration, and runtime, identify stable configurations, and offer guidelines for selecting uncertainty-aware imputers in data cleaning and downstream machine learning pipelines.
<div id='section'>Paperid: <span id='pid'>1134, <a href='https://arxiv.org/pdf/2511.20139.pdf' target='_blank'>https://arxiv.org/pdf/2511.20139.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mariana M Garcez Duarte, Mahmoud Sakr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.20139">An experimental study of existing tools for outlier detection and cleaning in trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection and cleaning are essential steps in data preprocessing to ensure the integrity and validity of data analyses. This paper focuses on outlier points within individual trajectories, i.e., points that deviate significantly inside a single trajectory. We experiment with ten open-source libraries to comprehensively evaluate available tools, comparing their efficiency and accuracy in identifying and cleaning outliers. This experiment considers the libraries as they are offered to end users, with real-world applicability. We compare existing outlier detection libraries, introduce a method for establishing ground-truth, and aim to guide users in choosing the most appropriate tool for their specific outlier detection needs. Furthermore, we survey the state-of-the-art algorithms for outlier detection and classify them into five types: Statistic-based methods, Sliding window algorithms, Clustering-based methods, Graph-based methods, and Heuristic-based methods. Our research provides insights into these libraries' performance and contributes to developing data preprocessing and outlier detection methodologies.
<div id='section'>Paperid: <span id='pid'>1135, <a href='https://arxiv.org/pdf/2511.19805.pdf' target='_blank'>https://arxiv.org/pdf/2511.19805.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Y. A. Rouzoumka, E. Terreaux, C. Morisseau, J. -P. Ovarlez, C. Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.19805">Latent-space metrics for Complex-Valued VAE out-of-distribution detection under radar clutter</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate complex-valued Variational AutoEncoders (CVAE) for radar Out-Of-Distribution (OOD) detection in complex radar environments. We proposed several detection metrics: the reconstruction error of CVAE (CVAE-MSE), the latent-based scores (Mahalanobis, Kullback-Leibler divergence (KLD)), and compared their performance against the classical ANMF-Tyler detector (ANMF-FP). The performance of all these detectors is analyzed on synthetic and experimental radar data, showing the advantages and the weaknesses of each detector.
<div id='section'>Paperid: <span id='pid'>1136, <a href='https://arxiv.org/pdf/2511.18813.pdf' target='_blank'>https://arxiv.org/pdf/2511.18813.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sing-Yuan Yeh, Chun-Hao Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.18813">Uncertainty of Network Topology with Applications to Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Persistent homology (PH) is a crucial concept in computational topology, providing a multiscale topological description of a space. It is particularly significant in topological data analysis, which aims to make statistical inference from a topological perspective. In this work, we introduce a new topological summary for Bayesian neural networks, termed the predictive topological uncertainty (pTU). The proposed pTU measures the uncertainty in the interaction between the model and the inputs. It provides insights from the model perspective: if two samples interact with a model in a similar way, then they are considered identically distributed. We also show that the pTU is insensitive to the model architecture. As an application, pTU is used to solve the out-of-distribution (OOD) detection problem, which is critical to ensure model reliability. Failure to detect OOD input can lead to incorrect and unreliable predictions. To address this issue, we propose a significance test for OOD based on the pTU, providing a statistical framework for this issue. The effectiveness of the framework is validated through various experiments, in terms of its statistical power, sensitivity, and robustness.
<div id='section'>Paperid: <span id='pid'>1137, <a href='https://arxiv.org/pdf/2511.13984.pdf' target='_blank'>https://arxiv.org/pdf/2511.13984.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hilaf Hasson, Ruocheng Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.13984">Node-Level Uncertainty Estimation in LLM-Generated SQL</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a practical framework for detecting errors in LLM-generated SQL by estimating uncertainty at the level of individual nodes in the query's abstract syntax tree (AST). Our approach proceeds in two stages. First, we introduce a semantically aware labeling algorithm that, given a generated SQL and a gold reference, assigns node-level correctness without over-penalizing structural containers or alias variation. Second, we represent each node with a rich set of schema-aware and lexical features - capturing identifier validity, alias resolution, type compatibility, ambiguity in scope, and typo signals - and train a supervised classifier to predict per-node error probabilities. We interpret these probabilities as calibrated uncertainty, enabling fine-grained diagnostics that pinpoint exactly where a query is likely to be wrong. Across multiple databases and datasets, our method substantially outperforms token log-probabilities: average AUC improves by +27.44% while maintaining robustness under cross-database evaluation. Beyond serving as an accuracy signal, node-level uncertainty supports targeted repair, human-in-the-loop review, and downstream selective execution. Together, these results establish node-centric, semantically grounded uncertainty estimation as a strong and interpretable alternative to aggregate sequence level confidence measures.
<div id='section'>Paperid: <span id='pid'>1138, <a href='https://arxiv.org/pdf/2511.11486.pdf' target='_blank'>https://arxiv.org/pdf/2511.11486.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roman Kinakh, Gonzalo R. Ríos-Muñoz, Arrate Muñoz-Barrutia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.11486">Multimodal Posterior Sampling-based Uncertainty in PD-L1 Segmentation from H&E Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate assessment of PD-L1 expression is critical for guiding immunotherapy, yet current immunohistochemistry (IHC) based methods are resource-intensive. We present nnUNet-B: a Bayesian segmentation framework that infers PD-L1 expression directly from H&E-stained histology images using Multimodal Posterior Sampling (MPS). Built upon nnUNet-v2, our method samples diverse model checkpoints during cyclic training to approximate the posterior, enabling both accurate segmentation and epistemic uncertainty estimation via entropy and standard deviation. Evaluated on a dataset of lung squamous cell carcinoma, our approach achieves competitive performance against established baselines with mean Dice Score and mean IoU of 0.805 and 0.709, respectively, while providing pixel-wise uncertainty maps. Uncertainty estimates show strong correlation with segmentation error, though calibration remains imperfect. These results suggest that uncertainty-aware H&E-based PD-L1 prediction is a promising step toward scalable, interpretable biomarker assessment in clinical workflows.
<div id='section'>Paperid: <span id='pid'>1139, <a href='https://arxiv.org/pdf/2511.09326.pdf' target='_blank'>https://arxiv.org/pdf/2511.09326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Viola Rädle, Tilman Hartwig, Benjamin Oesen, Emily Alice Kröger, Julius Vogt, Eike Gericke, Martin Baron
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.09326">GAMMA_FLOW: Guided Analysis of Multi-label spectra by MAtrix Factorization for Lightweight Operational Workflows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>GAMMA_FLOW is an open-source Python package for real-time analysis of spectral data. It supports classification, denoising, decomposition, and outlier detection of both single- and multi-component spectra. Instead of relying on large, computationally intensive models, it employs a supervised approach to non-negative matrix factorization (NMF) for dimensionality reduction. This ensures a fast, efficient, and adaptable analysis while reducing computational costs. gamma_flow achieves classification accuracies above 90% and enables reliable automated spectral interpretation. Originally developed for gamma-ray spectra, it is applicable to any type of one-dimensional spectral data. As an open and flexible alternative to proprietary software, it supports various applications in research and industry.
<div id='section'>Paperid: <span id='pid'>1140, <a href='https://arxiv.org/pdf/2511.04333.pdf' target='_blank'>https://arxiv.org/pdf/2511.04333.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Federico Pirola, Fabio Stella, Marco Grzegorczyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.04333">LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamic Bayesian networks (DBNs) are increasingly used in healthcare due to their ability to model complex temporal relationships in patient data while maintaining interpretability, an essential feature for clinical decision-making. However, existing approaches to handling missing data in longitudinal clinical datasets are largely derived from static Bayesian networks literature, failing to properly account for the temporal nature of the data. This gap limits the ability to quantify uncertainty over time, which is particularly critical in settings such as intensive care, where understanding the temporal dynamics is fundamental for model trustworthiness and applicability across diverse patient groups. Despite the potential of DBNs, a full Bayesian framework that integrates missing data handling remains underdeveloped. In this work, we propose a novel Gibbs sampling-based method for learning DBNs from incomplete data. Our method treats each missing value as an unknown parameter following a Gaussian distribution. At each iteration, the unobserved values are sampled from their full conditional distributions, allowing for principled imputation and uncertainty estimation. We evaluate our method on both simulated datasets and real-world intensive care data from critically ill patients. Compared to standard model-agnostic techniques such as MICE, our Bayesian approach demonstrates superior reconstruction accuracy and convergence properties. These results highlight the clinical relevance of incorporating full Bayesian inference in temporal models, providing more reliable imputations and offering deeper insight into model behavior. Our approach supports safer and more informed clinical decision-making, particularly in settings where missing data are frequent and potentially impactful.
<div id='section'>Paperid: <span id='pid'>1141, <a href='https://arxiv.org/pdf/2511.00849.pdf' target='_blank'>https://arxiv.org/pdf/2511.00849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhexiao Huang, Weihao He, Shutao Deng, Junzhe Chen, Chao Yuan, Hongxin Wang, Changsheng Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.00849">Perturbations in the Orthogonal Complement Subspace for Efficient Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for deploying deep learning models in open-world environments. Existing approaches, such as energy-based scoring and gradient-projection methods, typically rely on high-dimensional representations to separate in-distribution (ID) and OOD samples. We introduce P-OCS (Perturbations in the Orthogonal Complement Subspace), a lightweight and theoretically grounded method that operates in the orthogonal complement of the principal subspace defined by ID features. P-OCS applies a single projected perturbation restricted to this complementary subspace, enhancing subtle ID-OOD distinctions while preserving the geometry of ID representations. We show that a one-step update is sufficient in the small-perturbation regime and provide convergence guarantees for the resulting detection score. Experiments across multiple architectures and datasets demonstrate that P-OCS achieves state-of-the-art OOD detection with negligible computational cost and without requiring model retraining, access to OOD data, or changes to model architecture.
<div id='section'>Paperid: <span id='pid'>1142, <a href='https://arxiv.org/pdf/2508.16617.pdf' target='_blank'>https://arxiv.org/pdf/2508.16617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>KÃ©vin Ducharlet, Louise TravÃ©-MassuyÃ¨s, Jean-Bernard Lasserre, Marie-VÃ©ronique Le Lann, Youssef Miloudi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16617">Leveraging the Christoffel Function for Outlier Detection in Data Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection holds significant importance in the realm of data mining, particularly with the growing pervasiveness of data acquisition methods. The ability to identify outliers in data streams is essential for maintaining data quality and detecting faults. However, dealing with data streams presents challenges due to the non-stationary nature of distributions and the ever-increasing data volume. While numerous methods have been proposed to tackle this challenge, a common drawback is the lack of straightforward parameterization in many of them. This article introduces two novel methods: DyCF and DyCG. DyCF leverages the Christoffel function from the theory of approximation and orthogonal polynomials. Conversely, DyCG capitalizes on the growth properties of the Christoffel function, eliminating the need for tuning parameters. Both approaches are firmly rooted in a well-defined algebraic framework, meeting crucial demands for data stream processing, with a specific focus on addressing low-dimensional aspects and maintaining data history without memory cost. A comprehensive comparison between DyCF, DyCG, and state-of-the-art methods is presented, using both synthetic and real industrial data streams. The results show that DyCF outperforms fine-tuning methods, offering superior performance in terms of execution time and memory usage. DyCG performs less well, but has the considerable advantage of requiring no tuning at all.
<div id='section'>Paperid: <span id='pid'>1143, <a href='https://arxiv.org/pdf/2508.16527.pdf' target='_blank'>https://arxiv.org/pdf/2508.16527.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrei-Stefan Bulzan, Cosmin Cernazanu-Glavan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16527">Towards Open World Detection: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For decades, Computer Vision has aimed at enabling machines to perceive the external world. Initial limitations led to the development of highly specialized niches. As success in each task accrued and research progressed, increasingly complex perception tasks emerged. This survey charts the convergence of these tasks and, in doing so, introduces Open World Detection (OWD), an umbrella term we propose to unify class-agnostic and generally applicable detection models in the vision domain. We start from the history of foundational vision subdomains and cover key concepts, methodologies and datasets making up today's state-of-the-art landscape. This traverses topics starting from early saliency detection, foreground/background separation, out of distribution detection and leading up to open world object detection, zero-shot detection and Vision Large Language Models (VLLMs). We explore the overlap between these subdomains, their increasing convergence, and their potential to unify into a singular domain in the future, perception.
<div id='section'>Paperid: <span id='pid'>1144, <a href='https://arxiv.org/pdf/2508.14597.pdf' target='_blank'>https://arxiv.org/pdf/2508.14597.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nitish Kumar Mahala, Muzammil Khan, Pushpendra Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14597">Reliable Smoke Detection via Optical Flow-Guided Feature Fusion and Transformer-Based Uncertainty Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fire outbreaks pose critical threats to human life and infrastructure, necessitating high-fidelity early-warning systems that detect combustion precursors such as smoke. However, smoke plumes exhibit complex spatiotemporal dynamics influenced by illumination variability, flow kinematics, and environmental noise, undermining the reliability of traditional detectors. To address these challenges without the logistical complexity of multi-sensor arrays, we propose an information-fusion framework by integrating smoke feature representations extracted from monocular imagery. Specifically, a Two-Phase Uncertainty-Aware Shifted Windows Transformer for robust and reliable smoke detection, leveraging a novel smoke segmentation dataset, constructed via optical flow-based motion encoding, is proposed. The optical flow estimation is performed with a four-color-theorem-inspired dual-phase level-set fractional-order variational model, which preserves motion discontinuities. The resulting color-encoded optical flow maps are fused with appearance cues via a Gaussian Mixture Model to generate binary segmentation masks of the smoke regions. These fused representations are fed into the novel Shifted-Windows Transformer, which is augmented with a multi-scale uncertainty estimation head and trained under a two-phase learning regimen. First learning phase optimizes smoke detection accuracy, while during the second phase, the model learns to estimate plausibility confidence in its predictions by jointly modeling aleatoric and epistemic uncertainties. Extensive experiments using multiple evaluation metrics and comparative analysis with state-of-the-art approaches demonstrate superior generalization and robustness, offering a reliable solution for early fire detection in surveillance, industrial safety, and autonomous monitoring applications.
<div id='section'>Paperid: <span id='pid'>1145, <a href='https://arxiv.org/pdf/2508.13568.pdf' target='_blank'>https://arxiv.org/pdf/2508.13568.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Diego Correa da Silva, Denis Robson Dantas Boaventura, Mayki dos Santos Oliveira, Eduardo Ferreira da Silva, Joel Machado Pires, Frederico AraÃºjo DurÃ£o
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13568">Understanding Distribution Structure on Calibrated Recommendation Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional recommender systems aim to generate a recommendation list comprising the most relevant or similar items to the user's profile. These approaches can create recommendation lists that omit item genres from the less prominent areas of a user's profile, thereby undermining the user's experience. To solve this problem, the calibrated recommendation system provides a guarantee of including less representative areas in the recommended list. The calibrated context works with three distributions. The first is from the user's profile, the second is from the candidate items, and the last is from the recommendation list. These distributions are G-dimensional, where G is the total number of genres in the system. This high dimensionality requires a different evaluation method, considering that traditional recommenders operate in a one-dimensional data space. In this sense, we implement fifteen models that help to understand how these distributions are structured. We evaluate the users' patterns in three datasets from the movie domain. The results indicate that the models of outlier detection provide a better understanding of the structures. The calibrated system creates recommendation lists that act similarly to traditional recommendation lists, allowing users to change their groups of preferences to the same degree.
<div id='section'>Paperid: <span id='pid'>1146, <a href='https://arxiv.org/pdf/2508.11460.pdf' target='_blank'>https://arxiv.org/pdf/2508.11460.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aurora Grefsrud, Nello Blaser, Trygve Buanes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.11460">Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rigorous statistical methods, including parameter estimation with accompanying uncertainties, underpin the validity of scientific discovery, especially in the natural sciences. With increasingly complex data models such as deep learning techniques, uncertainty quantification has become exceedingly difficult and a plethora of techniques have been proposed. In this case study, we use the unifying framework of approximate Bayesian inference combined with empirical tests on carefully created synthetic classification datasets to investigate qualitative properties of six different probabilistic machine learning algorithms for class probability and uncertainty estimation: (i) a neural network ensemble, (ii) neural network ensemble with conflictual loss, (iii) evidential deep learning, (iv) a single neural network with Monte Carlo Dropout, (v) Gaussian process classification and (vi) a Dirichlet process mixture model. We check if the algorithms produce uncertainty estimates which reflect commonly desired properties, such as being well calibrated and exhibiting an increase in uncertainty for out-of-distribution data points. Our results indicate that all algorithms are well calibrated, but none of the deep learning based algorithms provide uncertainties that consistently reflect lack of experimental evidence for out-of-distribution data points. We hope our study may serve as a clarifying example for researchers developing new methods of uncertainty estimation for scientific data-driven modeling.
<div id='section'>Paperid: <span id='pid'>1147, <a href='https://arxiv.org/pdf/2508.11338.pdf' target='_blank'>https://arxiv.org/pdf/2508.11338.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prathamesh Devadiga, Yashmitha Shailesh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.11338">RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce RegimeNAS, a novel differentiable architecture search framework specifically designed to enhance cryptocurrency trading performance by explicitly integrating market regime awareness. Addressing the limitations of static deep learning models in highly dynamic financial environments, RegimeNAS features three core innovations: (1) a theoretically grounded Bayesian search space optimizing architectures with provable convergence properties; (2) specialized, dynamically activated neural modules (Volatility, Trend, and Range blocks) tailored for distinct market conditions; and (3) a multi-objective loss function incorporating market-specific penalties (e.g., volatility matching, transition smoothness) alongside mathematically enforced Lipschitz stability constraints. Regime identification leverages multi-head attention across multiple timeframes for improved accuracy and uncertainty estimation. Rigorous empirical evaluation on extensive real-world cryptocurrency data demonstrates that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving an 80.3% Mean Absolute Error reduction compared to the best traditional recurrent baseline and converging substantially faster (9 vs. 50+ epochs). Ablation studies and regime-specific analysis confirm the critical contribution of each component, particularly the regime-aware adaptation mechanism. This work underscores the imperative of embedding domain-specific knowledge, such as market regimes, directly within the NAS process to develop robust and adaptive models for challenging financial applications.
<div id='section'>Paperid: <span id='pid'>1148, <a href='https://arxiv.org/pdf/2508.10148.pdf' target='_blank'>https://arxiv.org/pdf/2508.10148.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maria Stoica, Francesco Leofante, Alessio Lomuscio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10148">Out-of-Distribution Detection using Counterfactual Distance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and explainable out-of-distribution (OOD) detection is required to use machine learning systems safely. Previous work has shown that feature distance to decision boundaries can be used to identify OOD data effectively. In this paper, we build on this intuition and propose a post-hoc OOD detection method that, given an input, calculates the distance to decision boundaries by leveraging counterfactual explanations. Since computing explanations can be expensive for large architectures, we also propose strategies to improve scalability by computing counterfactuals directly in embedding space. Crucially, as the method employs counterfactual explanations, we can seamlessly use them to help interpret the results of our detector. We show that our method is in line with the state of the art on CIFAR-10, achieving 93.50% AUROC and 25.80% FPR95. Our method outperforms these methods on CIFAR-100 with 97.05% AUROC and 13.79% FPR95 and on ImageNet-200 with 92.55% AUROC and 33.55% FPR95 across four OOD datasets
<div id='section'>Paperid: <span id='pid'>1149, <a href='https://arxiv.org/pdf/2508.05454.pdf' target='_blank'>https://arxiv.org/pdf/2508.05454.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Li, Zixin Wang, Qizheng Sun, Qixiang Gao, Fenglei Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05454">EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty Estimation for Energy Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and reliable energy time series prediction is of great significance for power generation planning and allocation. At present, deep learning time series prediction has become the mainstream method. However, the multi-scale time dynamics and the irregularity of real data lead to the limitations of the existing methods. Therefore, we propose EnergyPatchTST, which is an extension of the Patch Time Series Transformer specially designed for energy forecasting. The main innovations of our method are as follows: (1) multi-scale feature extraction mechanism to capture patterns with different time resolutions; (2) probability prediction framework to estimate uncertainty through Monte Carlo elimination; (3) integration path of future known variables (such as temperature and wind conditions); And (4) Pre-training and Fine-tuning examples to enhance the performance of limited energy data sets. A series of experiments on common energy data sets show that EnergyPatchTST is superior to other commonly used methods, the prediction error is reduced by 7-12%, and reliable uncertainty estimation is provided, which provides an important reference for time series prediction in the energy field.
<div id='section'>Paperid: <span id='pid'>1150, <a href='https://arxiv.org/pdf/2508.03405.pdf' target='_blank'>https://arxiv.org/pdf/2508.03405.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fei Shuang, Zixiong Wei, Kai Liu, Wei Gao, Poulumi Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03405">Model Accuracy and Data Heterogeneity Shape Uncertainty Quantification in Machine Learning Interatomic Potentials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning interatomic potentials (MLIPs) enable accurate atomistic modelling, but reliable uncertainty quantification (UQ) remains elusive. In this study, we investigate two UQ strategies, ensemble learning and D-optimality, within the atomic cluster expansion framework. It is revealed that higher model accuracy strengthens the correlation between predicted uncertainties and actual errors and improves novelty detection, with D-optimality yielding more conservative estimates. Both methods deliver well calibrated uncertainties on homogeneous training sets, yet they underpredict errors and exhibit reduced novelty sensitivity on heterogeneous datasets. To address this limitation, we introduce clustering-enhanced local D-optimality, which partitions configuration space into clusters during training and applies D-optimality within each cluster. This approach substantially improves the detection of novel atomic environments in heterogeneous datasets. Our findings clarify the roles of model fidelity and data heterogeneity in UQ performance and provide a practical route to robust active learning and adaptive sampling strategies for MLIP development.
<div id='section'>Paperid: <span id='pid'>1151, <a href='https://arxiv.org/pdf/2507.18366.pdf' target='_blank'>https://arxiv.org/pdf/2507.18366.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lakshmana Sri Harsha Nemani, P. K. Srijith, Tomasz KuÅmierczyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18366">Efficient Uncertainty in LLMs through Evidential Knowledge Distillation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty quantification remains a key challenge for standard LLMs, prompting the adoption of Bayesian and ensemble-based methods. However, such methods typically necessitate computationally expensive sampling, involving multiple forward passes to effectively estimate predictive uncertainty.
  In this paper, we introduce a novel approach enabling efficient and effective uncertainty estimation in LLMs without sacrificing performance. Specifically, we distill uncertainty-aware teacher models - originally requiring multiple forward passes - into compact student models sharing the same architecture but fine-tuned using Low-Rank Adaptation (LoRA). We compare two distinct distillation strategies: one in which the student employs traditional softmax-based outputs, and another in which the student leverages Dirichlet-distributed outputs to explicitly model epistemic uncertainty via evidential learning.
  Empirical evaluations on classification datasets demonstrate that such students can achieve comparable or superior predictive and uncertainty quantification performance relative to their teacher models, while critically requiring only a single forward pass. To our knowledge, this is the first demonstration that immediate and robust uncertainty quantification can be achieved in LLMs through evidential distillation.
<div id='section'>Paperid: <span id='pid'>1152, <a href='https://arxiv.org/pdf/2507.16952.pdf' target='_blank'>https://arxiv.org/pdf/2507.16952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Min-Ha-Zul Abedin, Tazqia Mehrub
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16952">Evaluating Ensemble and Deep Learning Models for Static Malware Detection with Dimensionality Reduction Using the EMBER Dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the effectiveness of several machine learning algorithms for static malware detection using the EMBER dataset, which contains feature representations of Portable Executable (PE) files. We evaluate eight classification models: LightGBM, XGBoost, CatBoost, Random Forest, Extra Trees, HistGradientBoosting, k-Nearest Neighbors (KNN), and TabNet, under three preprocessing settings: original feature space, Principal Component Analysis (PCA), and Linear Discriminant Analysis (LDA). The models are assessed on accuracy, precision, recall, F1 score, and AUC to examine both predictive performance and robustness. Ensemble methods, especially LightGBM and XGBoost, show the best overall performance across all configurations, with minimal sensitivity to PCA and consistent generalization. LDA improves KNN performance but significantly reduces accuracy for boosting models. TabNet, while promising in theory, underperformed under feature reduction, likely due to architectural sensitivity to input structure. The analysis is supported by detailed exploratory data analysis (EDA), including mutual information ranking, PCA or t-SNE visualizations, and outlier detection using Isolation Forest and Local Outlier Factor (LOF), which confirm the discriminatory capacity of key features in the EMBER dataset. The results suggest that boosting models remain the most reliable choice for high-dimensional static malware detection, and that dimensionality reduction should be applied selectively based on model type. This work provides a benchmark for comparing classification models and preprocessing strategies in malware detection tasks and contributes insights that can guide future system development and real-world deployment.
<div id='section'>Paperid: <span id='pid'>1153, <a href='https://arxiv.org/pdf/2507.14649.pdf' target='_blank'>https://arxiv.org/pdf/2507.14649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minsuh Joo, Hyunsoo Cho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14649">Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the outstanding performance of large language models (LLMs) across various NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate responses--remains as a critical problem as it can be directly connected to a crisis of building safe and reliable LLMs. Uncertainty estimation is primarily used to measure hallucination levels in LLM responses so that correct and incorrect answers can be distinguished clearly. This study proposes an effective uncertainty estimation approach, \textbf{Cl}ust\textbf{e}ring-based sem\textbf{an}tic con\textbf{s}ist\textbf{e}ncy (\textbf{Cleanse}). Cleanse quantifies the uncertainty with the proportion of the intra-cluster consistency in the total consistency between LLM hidden embeddings which contain adequate semantic information of generations, by employing clustering. The effectiveness of Cleanse for detecting hallucination is validated using four off-the-shelf models, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two question-answering benchmarks, SQuAD and CoQA.
<div id='section'>Paperid: <span id='pid'>1154, <a href='https://arxiv.org/pdf/2507.14588.pdf' target='_blank'>https://arxiv.org/pdf/2507.14588.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Usayd Shahul, J. Harshan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14588">FORTA: Byzantine-Resilient FL Aggregation via DFT-Guided Krum</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Secure federated learning enables collaborative model training across decentralized users while preserving data privacy. A key component is secure aggregation, which keeps individual updates hidden from both the server and users, while also defending against Byzantine users who corrupt the aggregation. To this end, Jinhyun So et al. recently developed a Byzantine-resilient secure aggregation scheme using a secret-sharing strategy over finite-field arithmetic. However, such an approach can suffer from numerical errors and overflows when applied to real-valued model updates, motivating the need for secure aggregation methods that operate directly over the real domain. We propose FORTA, a Byzantine-resilient secure aggregation framework that operates entirely in the real domain. FORTA leverages Discrete Fourier Transform (DFT) codes for privacy and employs Krum-based outlier detection for robustness. While DFT decoder is error-free under infinite precision, finite precision introduces numerical perturbations that can distort distance estimates and allow malicious updates to evade detection. To address this, FORTA refines Krum using feedback from DFT decoder, improving the selection of trustworthy updates. Theoretical analysis and experiments show that our modification of Krum offers improved robustness and more accurate aggregation than standard Krum.
<div id='section'>Paperid: <span id='pid'>1155, <a href='https://arxiv.org/pdf/2507.11106.pdf' target='_blank'>https://arxiv.org/pdf/2507.11106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>VÃ­ctor Blanco, Inmaculada Espejo, RaÃºl PÃ¡ez, Antonio M. RodrÃ­guez-ChÃ­a
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11106">A Mathematical Optimization Approach to Multisphere Support Vector Data Description</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel mathematical optimization framework for outlier detection in multimodal datasets, extending Support Vector Data Description approaches. We provide a primal formulation, in the shape of a Mixed Integer Second Order Cone model, that constructs Euclidean hyperspheres to identify anomalous observations. Building on this, we develop a dual model that enables the application of the kernel trick, thus allowing for the detection of outliers within complex, non-linear data structures. An extensive computational study demonstrates the effectiveness of our exact method, showing clear advantages over existing heuristic techniques in terms of accuracy and robustness.
<div id='section'>Paperid: <span id='pid'>1156, <a href='https://arxiv.org/pdf/2507.02256.pdf' target='_blank'>https://arxiv.org/pdf/2507.02256.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Yang, Xiaolu Zhou, Bosong Ding, Miao Xin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02256">Uncertainty-aware Reward Design Process</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing effective reward functions is a cornerstone of reinforcement learning (RL), yet it remains a challenging process due to the inefficiencies and inconsistencies inherent in conventional reward engineering methodologies. Recent advances have explored leveraging large language models (LLMs) to automate reward function design. However, their suboptimal performance in numerical optimization often yields unsatisfactory reward quality, while the evolutionary search paradigm demonstrates inefficient utilization of simulation resources, resulting in prohibitively lengthy design cycles with disproportionate computational overhead. To address these challenges, we propose the Uncertainty-aware Reward Design Process (URDP), a novel framework that integrates large language models to streamline reward function design and evaluation in RL environments. URDP quantifies candidate reward function uncertainty based on self-consistency analysis, enabling simulation-free identification of ineffective reward components while discovering novel reward components. Furthermore, we introduce uncertainty-aware Bayesian optimization (UABO), which incorporates uncertainty estimation to significantly enhance hyperparameter configuration efficiency. Finally, we construct a bi-level optimization architecture by decoupling the reward component optimization and the hyperparameter tuning. URDP orchestrates synergistic collaboration between the reward logic reasoning of the LLMs and the numerical optimization strengths of the Bayesian Optimization. We conduct a comprehensive evaluation of URDP across 35 diverse tasks spanning three benchmark environments. Our experimental results demonstrate that URDP not only generates higher-quality reward functions but also achieves significant improvements in the efficiency of automated reward design compared to existing approaches.
<div id='section'>Paperid: <span id='pid'>1157, <a href='https://arxiv.org/pdf/2507.00368.pdf' target='_blank'>https://arxiv.org/pdf/2507.00368.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hikaru Shijo, Yutaka Yoshihama, Kenichi Yadani, Norifumi Murata
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00368">Out-of-Distribution Detection with Adaptive Top-K Logits Integration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks often make overconfident predictions from out-of-distribution (OOD) samples. Detection of OOD data is therefore crucial to improve the safety of machine learning. The simplest and most powerful method for OOD detection is MaxLogit, which uses the model's maximum logit to provide an OOD score. We have discovered that, in addition to the maximum logit, some other logits are also useful for OOD detection. Based on this finding, we propose a new method called ATLI (Adaptive Top-k Logits Integration), which adaptively determines effective top-k logits that are specific to each model and combines the maximum logit with the other top-k logits. In this study we evaluate our proposed method using ImageNet-1K benchmark. Extensive experiments showed our proposed method to reduce the false positive rate (FPR95) by 6.73% compared to the MaxLogit approach, and decreased FPR95 by an additional 2.67% compared to other state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1158, <a href='https://arxiv.org/pdf/2506.23446.pdf' target='_blank'>https://arxiv.org/pdf/2506.23446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Elbasheer, Adewale Akinfaderin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23446">User-Based Sequential Modeling with Transformer Encoders for Insider Threat Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Insider threat detection presents unique challenges due to the authorized status of malicious actors and the subtlety of anomalous behaviors. Existing machine learning methods often treat user activity as isolated events, thereby failing to leverage sequential dependencies in user behavior. In this study, we propose a User-Based Sequencing (UBS) methodology, transforming the CERT insider threat dataset into structured temporal sequences suitable for deep sequential modeling. We deploy a Transformer Encoder architecture to model benign user activity and employ its reconstruction errors as anomaly scores. These scores are subsequently evaluated using three unsupervised outlier detection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and Isolation Forest (iForest). Across four rigorously designed test sets, including combinations of multiple CERT dataset releases, our UBS-Transformer pipeline consistently achieves state-of-the-art performance - notably 96.61% accuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low false negative (0.0057) and false positive (0.0571) rates. Comparative analyses demonstrate that our approach substantially outperforms tabular and conventional autoencoder baselines, underscoring the efficacy of sequential user modeling and advanced anomaly detection in the insider threat domain.
<div id='section'>Paperid: <span id='pid'>1159, <a href='https://arxiv.org/pdf/2506.19895.pdf' target='_blank'>https://arxiv.org/pdf/2506.19895.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miguel N. Font, JosÃ© L. Jorro-Aragoneses, Carlos M. AlaÃ­z
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19895">A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Networks have high accuracy in solving problems where it is difficult to detect patterns or create a logical model. However, these algorithms sometimes return wrong solutions, which become problematic in high-risk domains like medical diagnosis or autonomous driving. One strategy to detect and mitigate these errors is the measurement of the uncertainty over neural network decisions. In this paper, we present a novel post-hoc framework for measuring the uncertainty of a decision based on retrieved training cases that have a similar activation vector to the query for each layer. Based on these retrieved cases, we propose two new metrics: Decision Change and Layer Uncertainty, which capture changes in nearest-neighbor class distributions across layers. We evaluated our approach in a classification model for two datasets: CIFAR-10 and MNIST. The results show that these metrics enhance uncertainty estimation, especially in challenging classification tasks, outperforming softmax-based confidence.
<div id='section'>Paperid: <span id='pid'>1160, <a href='https://arxiv.org/pdf/2506.18162.pdf' target='_blank'>https://arxiv.org/pdf/2506.18162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hendrik Mehrtens, Tabea Bucher, Titus J. Brinker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18162">Pitfalls of Conformal Predictions for Medical Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation is one of the major challenges for medical classification tasks. While many approaches have been proposed, recently the statistical framework of conformal predictions has gained a lot of attention, due to its ability to provide provable calibration guarantees. Nonetheless, the application of conformal predictions in safety-critical areas such as medicine comes with pitfalls, limitations and assumptions that practitioners need to be aware of. We demonstrate through examples from dermatology and histopathology that conformal predictions are unreliable under distributional shifts in input and label variables. Additionally, conformal predictions should not be used for selecting predictions to improve accuracy and are not reliable for subsets of the data, such as individual classes or patient attributes. Moreover, in classification settings with a small number of classes, which are common in medical image classification tasks, conformal predictions have limited practical value.
<div id='section'>Paperid: <span id='pid'>1161, <a href='https://arxiv.org/pdf/2506.15851.pdf' target='_blank'>https://arxiv.org/pdf/2506.15851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiyuan Wu, Mark Campbell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15851">Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The uncertainty quantification of sensor measurements coupled with deep learning networks is crucial for many robotics systems, especially for safety-critical applications such as self-driving cars. This paper develops an uncertainty quantification approach in the context of visual localization for autonomous driving, where locations are selected based on images. Key to our approach is to learn the measurement uncertainty using light-weight sensor error model, which maps both image feature and semantic information to 2-dimensional error distribution. Our approach enables uncertainty estimation conditioned on the specific context of the matched image pair, implicitly capturing other critical, unannotated factors (e.g., city vs highway, dynamic vs static scenes, winter vs summer) in a latent manner. We demonstrate the accuracy of our uncertainty prediction framework using the Ithaca365 dataset, which includes variations in lighting and weather (sunny, night, snowy). Both the uncertainty quantification of the sensor+network is evaluated, along with Bayesian localization filters using unique sensor gating method. Results show that the measurement error does not follow a Gaussian distribution with poor weather and lighting conditions, and is better predicted by our Gaussian Mixture model.
<div id='section'>Paperid: <span id='pid'>1162, <a href='https://arxiv.org/pdf/2506.14390.pdf' target='_blank'>https://arxiv.org/pdf/2506.14390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Conrad Orglmeister, Erik Bochinski, Volker Eiselein, Elvira Fleig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14390">Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the decision-making and trusting the reliability of Deep Machine Learning Models is crucial for adopting such methods to safety-relevant applications. We extend self-explainable Prototypical Variational models with autoencoder-based out-of-distribution (OOD) detection: A Variational Autoencoder is applied to learn a meaningful latent space which can be used for distance-based classification, likelihood estimation for OOD detection, and reconstruction. The In-Distribution (ID) region is defined by a Gaussian mixture distribution with learned prototypes representing the center of each mode. Furthermore, a novel restriction loss is introduced that promotes a compact ID region in the latent space without collapsing it into single points. The reconstructive capabilities of the Autoencoder ensure the explainability of the prototypes and the ID region of the classifier, further aiding the discrimination of OOD samples. Extensive evaluations on common OOD detection benchmarks as well as a large-scale dataset from a real-world railway application demonstrate the usefulness of the approach, outperforming previous methods.
<div id='section'>Paperid: <span id='pid'>1163, <a href='https://arxiv.org/pdf/2506.10769.pdf' target='_blank'>https://arxiv.org/pdf/2506.10769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alberto Testoni, Iacer Calixto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10769">Mind the Gap: Benchmarking LLM Uncertainty, Discrimination, and Calibration in Specialty-Aware Clinical QA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty quantification (UQ) is essential when employing large language models (LLMs) in high-risk domains such as clinical question answering (QA). In this work, we evaluate uncertainty estimation methods for clinical QA focusing, for the first time, on eleven clinical specialties and six question types, and across ten open-source LLMs (general-purpose, biomedical, and reasoning models). We analyze score-based UQ methods, present a case study introducing a novel lightweight method based on behavioral features derived from reasoning-oriented models, and examine conformal prediction as a complementary set-based approach. Our findings reveal that uncertainty reliability is not a monolithic property, but one that depends on clinical specialty and question type due to shifts in calibration and discrimination. Our results highlight the need to select or ensemble models based on their distinct, complementary strengths and clinical use.
<div id='section'>Paperid: <span id='pid'>1164, <a href='https://arxiv.org/pdf/2506.04241.pdf' target='_blank'>https://arxiv.org/pdf/2506.04241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Konstantin Kirchheim, Frank Ortmeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.04241">Improving Out-of-Distribution Detection with Markov Logic Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for ensuring the reliability of deep learning models operating in open-world scenarios. Current OOD detectors mainly rely on statistical models to identify unusual patterns in the latent representations of a deep neural network. This work proposes to augment existing OOD detectors with probabilistic reasoning, utilizing Markov logic networks (MLNs). MLNs connect first-order logic with probabilistic reasoning to assign probabilities to inputs based on weighted logical constraints defined over human-understandable concepts, which offers improved explainability. Through extensive experiments on multiple datasets, we demonstrate that MLNs can significantly enhance the performance of a wide range of existing OOD detectors while maintaining computational efficiency. Furthermore, we introduce a simple algorithm for learning logical constraints for OOD detection from a dataset and showcase its effectiveness.
<div id='section'>Paperid: <span id='pid'>1165, <a href='https://arxiv.org/pdf/2506.03657.pdf' target='_blank'>https://arxiv.org/pdf/2506.03657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leonardo Martins Bianco, Christine Keribin, Zacharie Naulet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.03657">SubSearch: Robust Estimation and Outlier Detection for Stochastic Block Models via Subgraph Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Community detection is a fundamental task in graph analysis, with methods often relying on fitting models like the Stochastic Block Model (SBM) to observed networks. While many algorithms can accurately estimate SBM parameters when the input graph is a perfect sample from the model, real-world graphs rarely conform to such idealized assumptions. Therefore, robust algorithms are crucial-ones that can recover model parameters even when the data deviates from the assumed distribution. In this work, we propose SubSearch, an algorithm for robustly estimating SBM parameters by exploring the space of subgraphs in search of one that closely aligns with the model's assumptions. Our approach also functions as an outlier detection method, properly identifying nodes responsible for the graph's deviation from the model and going beyond simple techniques like pruning high-degree nodes. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our method.
<div id='section'>Paperid: <span id='pid'>1166, <a href='https://arxiv.org/pdf/2506.00662.pdf' target='_blank'>https://arxiv.org/pdf/2506.00662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeho Jo, Eun Hye Lee, Alzheimer's Disease Sequencing Project
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00662">Uncertainty-Aware Genomic Classification of Alzheimer's Disease: A Transformer-Based Ensemble Approach with Monte Carlo Dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>INTRODUCTION: Alzheimer's disease (AD) is genetically complex, complicating robust classification from genomic data. METHODS: We developed a transformer-based ensemble model (TrUE-Net) using Monte Carlo Dropout for uncertainty estimation in AD classification from whole-genome sequencing (WGS). We combined a transformer that preserves single-nucleotide polymorphism (SNP) sequence structure with a concurrent random forest using flattened genotypes. An uncertainty threshold separated samples into an uncertain (high-variance) group and a more certain (low-variance) group. RESULTS: We analyzed 1050 individuals, holding out half for testing. Overall accuracy and area under the receiver operating characteristic (ROC) curve (AUC) were 0.6514 and 0.6636, respectively. Excluding the uncertain group improved accuracy from 0.6263 to 0.7287 (10.24% increase) and F1 from 0.5843 to 0.8205 (23.62% increase). DISCUSSION: Monte Carlo Dropout-driven uncertainty helps identify ambiguous cases that may require further clinical evaluation, thus improving reliability in AD genomic classification.
<div id='section'>Paperid: <span id='pid'>1167, <a href='https://arxiv.org/pdf/2505.20691.pdf' target='_blank'>https://arxiv.org/pdf/2505.20691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shenkai Zhao, Xinao Zhang, Lipeng Pan, Xiaobin Xu, Danilo Pelusi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20691">Evidential Deep Active Learning for Semi-Supervised Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised classification based on active learning has made significant progress, but the existing methods often ignore the uncertainty estimation (or reliability) of the prediction results during the learning process, which makes it questionable whether the selected samples can effectively update the model. Hence, this paper proposes an evidential deep active learning approach for semi-supervised classification (EDALSSC). EDALSSC builds a semi-supervised learning framework to simultaneously quantify the uncertainty estimation of labeled and unlabeled data during the learning process. The uncertainty estimation of the former is associated with evidential deep learning, while that of the latter is modeled by combining ignorance information and conflict information of the evidence from the perspective of the T-conorm operator. Furthermore, this article constructs a heuristic method to dynamically balance the influence of evidence and the number of classes on uncertainty estimation to ensure that it does not produce counter-intuitive results in EDALSSC. For the sample selection strategy, EDALSSC selects the sample with the greatest uncertainty estimation that is calculated in the form of a sum when the training loss increases in the latter half of the learning process. Experimental results demonstrate that EDALSSC outperforms existing semi-supervised and supervised active learning approaches on image classification datasets.
<div id='section'>Paperid: <span id='pid'>1168, <a href='https://arxiv.org/pdf/2505.14285.pdf' target='_blank'>https://arxiv.org/pdf/2505.14285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eirini Panteli, Paulo E. Santos, Nabil Humphrey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14285">AquaSignal: An Integrated Framework for Robust Underwater Acoustic Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents AquaSignal, a modular and scalable pipeline for preprocessing, denoising, classification, and novelty detection of underwater acoustic signals. Designed to operate effectively in noisy and dynamic marine environments, AquaSignal integrates state-of-the-art deep learning architectures to enhance the reliability and accuracy of acoustic signal analysis. The system is evaluated on a combined dataset from the Deepship and Ocean Networks Canada (ONC) benchmarks, providing a diverse set of real-world underwater scenarios. AquaSignal employs a U-Net architecture for denoising, a ResNet18 convolutional neural network for classifying known acoustic events, and an AutoEncoder-based model for unsupervised detection of novel or anomalous signals. To our knowledge, this is the first comprehensive study to apply and evaluate this combination of techniques on maritime vessel acoustic data. Experimental results show that AquaSignal improves signal clarity and task performance, achieving 71% classification accuracy and 91% accuracy in novelty detection. Despite slightly lower classification performance compared to some state-of-the-art models, differences in data partitioning strategies limit direct comparisons. Overall, AquaSignal demonstrates strong potential for real-time underwater acoustic monitoring in scientific, environmental, and maritime domains.
<div id='section'>Paperid: <span id='pid'>1169, <a href='https://arxiv.org/pdf/2505.12353.pdf' target='_blank'>https://arxiv.org/pdf/2505.12353.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prakash Palanivelu Rajmohan, Fred Roosta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12353">Importance Sampling for Nonlinear Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While norm-based and leverage-score-based methods have been extensively studied for identifying "important" data points in linear models, analogous tools for nonlinear models remain significantly underdeveloped. By introducing the concept of the adjoint operator of a nonlinear map, we address this gap and generalize norm-based and leverage-score-based importance sampling to nonlinear settings. We demonstrate that sampling based on these generalized notions of norm and leverage scores provides approximation guarantees for the underlying nonlinear mapping, similar to linear subspace embeddings. As direct applications, these nonlinear scores not only reduce the computational complexity of training nonlinear models by enabling efficient sampling over large datasets but also offer a novel mechanism for model explainability and outlier detection. Our contributions are supported by both theoretical analyses and experimental results across a variety of supervised learning scenarios.
<div id='section'>Paperid: <span id='pid'>1170, <a href='https://arxiv.org/pdf/2505.11804.pdf' target='_blank'>https://arxiv.org/pdf/2505.11804.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi Wang, Eric Nalisnick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11804">Are vision language models robust to uncertain inputs?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robustness against uncertain and ambiguous inputs is a critical challenge for deep learning models. While recent advancements in large scale vision language models (VLMs, e.g. GPT4o) might suggest that increasing model and training dataset size would mitigate this issue, our empirical evaluation shows a more complicated picture. Testing models using two classic uncertainty quantification tasks, anomaly detection and classification under inherently ambiguous conditions, we find that newer and larger VLMs indeed exhibit improved robustness compared to earlier models, but still suffer from a tendency to strictly follow instructions, often causing them to hallucinate confident responses even when faced with unclear or anomalous inputs. Remarkably, for natural images such as ImageNet, this limitation can be overcome without pipeline modifications: simply prompting models to abstain from uncertain predictions enables significant reliability gains, achieving near-perfect robustness in several settings. However, for domain-specific tasks such as galaxy morphology classification, a lack of specialized knowledge prevents reliable uncertainty estimation. Finally, we propose a novel mechanism based on caption diversity to reveal a model's internal uncertainty, enabling practitioners to predict when models will successfully abstain without relying on labeled data.
<div id='section'>Paperid: <span id='pid'>1171, <a href='https://arxiv.org/pdf/2505.09319.pdf' target='_blank'>https://arxiv.org/pdf/2505.09319.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaustabha Ray, Nelson Mimura Gonzalez, Bruno Wassermann, Rachel Tzoref-Brill, Dean H. Lorenz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09319">Statistical Modeling and Uncertainty Estimation of LLM Inference Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Model (LLM) inference systems present significant challenges in statistical performance characterization due to dynamic workload variations, diverse hardware architectures, and complex interactions between model size, batch processing, and throughput requirements. Accurate statistical characterization enables better workload scheduling, adaptive resource provisioning, and cost-aware inference optimization, making it crucial for improving efficiency in large-scale AI deployments. Traditional analytical models provide explainability but cannot cover the vast diversity of real-world workloads, making it impossible to benchmark every scenario in advance. Machine learning (ML) approaches effectively predict performance for non-benchmarked cases but struggle when extrapolating beyond their observed training space. To address these limitations for LLM inference systems, we propose an Analytical with Learning Augmentation (ALA) framework that bridges analytical modeling with \ml for robust statistical prediction and uncertainty estimation in LLM inference workloads. Our method employs an analytical throughput model with parameters estimated for benchmarked workloads, then extends to unobserved configurations using \ml predictions. We enhance this with simulated annealing to exploit subsets of the workload data point combinations and develop an error predictor. Finally, we quantify uncertainty based on vector space similarity between new and observed workloads to ensure robust generalization. Through extensive experimentation on diverse LLM inference workloads, we demonstrate that our framework achieves low median errors while maintaining adaptability to new inference scenarios.
<div id='section'>Paperid: <span id='pid'>1172, <a href='https://arxiv.org/pdf/2505.08940.pdf' target='_blank'>https://arxiv.org/pdf/2505.08940.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeremie Blanchard, Lisa Casino, Jordan Gierschendorf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08940">NeurIPS 2024 Ariel Data Challenge: Characterisation of Exoplanetary Atmospheres Using a Data-Centric Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The characterization of exoplanetary atmospheres through spectral analysis is a complex challenge. The NeurIPS 2024 Ariel Data Challenge, in collaboration with the European Space Agency's (ESA) Ariel mission, provided an opportunity to explore machine learning techniques for extracting atmospheric compositions from simulated spectral data. In this work, we focus on a data-centric business approach, prioritizing generalization over competition-specific optimization. We briefly outline multiple experimental axes, including feature extraction, signal transformation, and heteroskedastic uncertainty modeling. Our experiments demonstrate that uncertainty estimation plays a crucial role in the Gaussian Log-Likelihood (GLL) score, impacting performance by several percentage points. Despite improving the GLL score by 11%, our results highlight the inherent limitations of tabular modeling and feature engineering for this task, as well as the constraints of a business-driven approach within a Kaggle-style competition framework. Our findings emphasize the trade-offs between model simplicity, interpretability, and generalization in astrophysical data analysis.
<div id='section'>Paperid: <span id='pid'>1173, <a href='https://arxiv.org/pdf/2505.08489.pdf' target='_blank'>https://arxiv.org/pdf/2505.08489.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Ulrich, Jan KrÅÃ¡vek, Roman Å enkeÅÃ­k, Zuzana KomÃ­nkovÃ¡ OplatkovÃ¡, Radek Vala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08489">Isolation Forest in Novelty Detection Scenario</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data mining offers a diverse toolbox for extracting meaningful structures from complex datasets, with anomaly detection emerging as a critical subfield particularly in the context of streaming or real-time data. Within anomaly detection, novelty detection focuses on identifying previously unseen patterns after training solely on regular data. While classic algorithms such as One-Class SVM or Local Outlier Factor (LOF) have been widely applied, they often lack interpretability and scalability. In this work, we explore the Half-Space Tree (HST) algorithm, originally proposed for streaming anomaly detection, and propose a novel theoretical modification to adapt it specifically for novelty detection tasks. Our approach is grounded in the idea that anomalies i.e., novelties tend to appear in the higher leaves of the tree, which are less frequently visited by regular instances. We analytically demonstrate the effectiveness of this approach using probabilistic analysis, expected depth (EXD) calculations, and combinatorial reasoning. A comparative analysis of expected depths between our modified HST and the original Isolation Forest highlights that novelty points are significantly more isolated in our approach. This supports the hypothesis that HSTs, with appropriate structural adaptation, can serve as interpretable and efficient novelty detectors. The paper contributes a theoretical foundation and supporting analysis for this adaptation, setting the stage for further application and experimentation.
<div id='section'>Paperid: <span id='pid'>1174, <a href='https://arxiv.org/pdf/2505.06459.pdf' target='_blank'>https://arxiv.org/pdf/2505.06459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Flores, Olga Graf, Pavlos Protopapas, Karim Pichara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06459">Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have been widely used to obtain solutions to various physical phenomena modeled as Differential Equations. As PINNs are not naturally equipped with mechanisms for Uncertainty Quantification, some work has been done to quantify the different uncertainties that arise when dealing with PINNs. In this paper, we use a two-step procedure to train Bayesian Neural Networks that provide uncertainties over the solutions to differential equation systems provided by PINNs. We use available error bounds over PINNs to formulate a heteroscedastic variance that improves the uncertainty estimation. Furthermore, we solve forward problems and utilize the obtained uncertainties when doing parameter estimation in inverse problems in cosmology.
<div id='section'>Paperid: <span id='pid'>1175, <a href='https://arxiv.org/pdf/2504.20174.pdf' target='_blank'>https://arxiv.org/pdf/2504.20174.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yashat Tavakoli, Amilcar Soares, Lourdes Pena
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20174">A Novel Multilevel Taxonomical Approach for Describing High-Dimensional Unlabeled Movement Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Movement data is prevalent across various applications and scientific fields, often characterized by its massive scale and complexity. Exploratory Data Analysis (EDA) plays a crucial role in summarizing and describing such data, enabling researchers to generate insights and support scientific hypotheses. Despite its importance, traditional EDA practices face limitations when applied to high-dimensional, unlabeled movement data. The complexity and multi-faceted nature of this type of data require more advanced methods that go beyond the capabilities of current EDA techniques. This study addresses the gap in current EDA practices by proposing a novel approach that leverages movement variable taxonomies and outlier detection. We hypothesize that organizing movement features into a taxonomy, and applying anomaly detection to combinations of taxonomic nodes, can reveal meaningful patterns and lead to more interpretable descriptions of the data. To test this hypothesis, we introduce TUMD, a new method that integrates movement taxonomies with outlier detection to enhance data analysis and interpretation. TUMD was evaluated across four diverse datasets of moving objects using fixed parameter values. Its effectiveness was assessed through two passes: the first pass categorized the majority of movement patterns as Kinematic, Geometric, or Hybrid for all datasets, while the second pass refined these behaviors into more specific categories such as Speed, Acceleration, or Indentation. TUMD met the effectiveness criteria in three datasets, demonstrating its ability to describe and refine movement behaviors. The results confirmed our hypothesis, showing that the combination of movement taxonomies and anomaly detection successfully uncovers meaningful and interpretable patterns within high-dimensional, unlabeled movement data.
<div id='section'>Paperid: <span id='pid'>1176, <a href='https://arxiv.org/pdf/2504.12718.pdf' target='_blank'>https://arxiv.org/pdf/2504.12718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Walid Rehamnia, Alexandra Getmanskaya, Evgeniy Vasilyev, Vadim Turlapov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12718">TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole Slide Images of Histology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Digital pathology, augmented by artificial intelligence (AI), holds significant promise for improving the workflow of pathologists. However, challenges such as the labor-intensive annotation of whole slide images (WSIs), high computational demands, and trust concerns arising from the absence of uncertainty estimation in predictions hinder the practical application of current AI methodologies in histopathology. To address these issues, we present a novel trustful fully unsupervised multi-level segmentation methodology (TUMLS) for WSIs. TUMLS adopts an autoencoder (AE) as a feature extractor to identify the different tissue types within low-resolution training data. It selects representative patches from each identified group based on an uncertainty measure and then does unsupervised nuclei segmentation in their respective higher-resolution space without using any ML algorithms. Crucially, this solution integrates seamlessly into clinicians workflows, transforming the examination of a whole WSI into a review of concise, interpretable cross-level insights. This integration significantly enhances and accelerates the workflow while ensuring transparency. We evaluated our approach using the UPENN-GBM dataset, where the AE achieved a mean squared error (MSE) of 0.0016. Additionally, nucleus segmentation is assessed on the MoNuSeg dataset, outperforming all unsupervised approaches with an F1 score of 77.46% and a Jaccard score of 63.35%. These results demonstrate the efficacy of TUMLS in advancing the field of digital pathology.
<div id='section'>Paperid: <span id='pid'>1177, <a href='https://arxiv.org/pdf/2504.07370.pdf' target='_blank'>https://arxiv.org/pdf/2504.07370.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenyu Han, Corentin Dumery
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07370">View-Dependent Uncertainty Estimation of 3D Gaussian Splatting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>3D Gaussian Splatting (3DGS) has become increasingly popular in 3D scene reconstruction for its high visual accuracy. However, uncertainty estimation of 3DGS scenes remains underexplored and is crucial to downstream tasks such as asset extraction and scene completion. Since the appearance of 3D gaussians is view-dependent, the color of a gaussian can thus be certain from an angle and uncertain from another. We thus propose to model uncertainty in 3DGS as an additional view-dependent per-gaussian feature that can be modeled with spherical harmonics. This simple yet effective modeling is easily interpretable and can be integrated into the traditional 3DGS pipeline. It is also significantly faster than ensemble methods while maintaining high accuracy, as demonstrated in our experiments.
<div id='section'>Paperid: <span id='pid'>1178, <a href='https://arxiv.org/pdf/2503.15953.pdf' target='_blank'>https://arxiv.org/pdf/2503.15953.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammed Attaoui, Fabrizio Pastore
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15953">GAN-enhanced Simulation-driven DNN Testing in Absence of Ground Truth</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The generation of synthetic inputs via simulators driven by search algorithms is essential for cost-effective testing of Deep Neural Network (DNN) components for safety-critical systems. However, in many applications, simulators are unable to produce the ground-truth data needed for automated test oracles and to guide the search process.
  To tackle this issue, we propose an approach for the generation of inputs for computer vision DNNs that integrates a generative network to ensure simulator fidelity and employs heuristic-based search fitnesses that leverage transformation consistency, noise resistance, surprise adequacy, and uncertainty estimation. We compare the performance of our fitnesses with that of a traditional fitness function leveraging ground truth; further, we assess how the integration of a GAN not leveraging the ground truth impacts on test and retraining effectiveness.
  Our results suggest that leveraging transformation consistency is the best option to generate inputs for both DNN testing and retraining; it maximizes input diversity, spots the inputs leading to worse DNN performance, and leads to best DNN performance after retraining. Besides enabling simulator-based testing in the absence of ground truth, our findings pave the way for testing solutions that replace costly simulators with diffusion and large language models, which might be more affordable than simulators, but cannot generate ground-truth data.
<div id='section'>Paperid: <span id='pid'>1179, <a href='https://arxiv.org/pdf/2503.07119.pdf' target='_blank'>https://arxiv.org/pdf/2503.07119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danil Kuzin, Olga Isupova, Steven Reece, Brooke D Simmons
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07119">Improving Deep Ensembles by Estimating Confusion Matrices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensembling in deep learning improves accuracy and calibration over single networks. The traditional aggregation approach, ensemble averaging, treats all individual networks equally by averaging their outputs. Inspired by crowdsourcing we propose an aggregation method called soft Dawid Skene for deep ensembles that estimates confusion matrices of ensemble members and weighs them according to their inferred performance. Soft Dawid Skene aggregates soft labels in contrast to hard labels often used in crowdsourcing. We empirically show the superiority of soft Dawid Skene in accuracy, calibration and out of distribution detection in comparison to ensemble averaging in extensive experiments.
<div id='section'>Paperid: <span id='pid'>1180, <a href='https://arxiv.org/pdf/2503.05757.pdf' target='_blank'>https://arxiv.org/pdf/2503.05757.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prasenjit Dey, Srujana Merugu, Sivaramakrishnan Kaveri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05757">Uncertainty-Aware Fusion: An Ensemble Framework for Mitigating Hallucinations in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are known to hallucinate and generate non-factual outputs which can undermine user trust. Traditional methods to directly mitigate hallucinations, such as representation editing and contrastive decoding, often require additional training data and involve high implementation complexity. While ensemble-based approaches harness multiple LLMs to tap into the "wisdom of crowds", these methods overlook uncertainties in individual model responses. Recent studies reveal that uncertainty estimation can enable LLMs to self-assess the likelihood of generating hallucinations. In this work, we focus on factoid question answering (QA) and observe that LLMs accuracy and self-assessment capabilities vary widely with different models excelling in different scenarios. Leveraging this insight, we propose Uncertainty-Aware Fusion (UAF), an ensemble framework to reduces hallucinations by strategically combining multiple LLM based on their accuracy and self-assessment abilities. Empirical results on several public benchmark datasets show that UAF outperforms state-of-the-art hallucination mitigation methods by $8\%$ in factual accuracy, while either narrowing or surpassing the performance gap with GPT-4.
<div id='section'>Paperid: <span id='pid'>1181, <a href='https://arxiv.org/pdf/2502.18122.pdf' target='_blank'>https://arxiv.org/pdf/2502.18122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>B. Sun, P. LiÃ²
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18122">EU-Nets: Enhanced, Explainable and Parsimonious U-Nets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we propose MHEX+, a framework adaptable to any U-Net architecture. Built upon MHEX+, we introduce novel U-Net variants, EU-Nets, which enhance explainability and uncertainty estimation, addressing the limitations of traditional U-Net models while improving performance and stability. A key innovation is the Equivalent Convolutional Kernel, which unifies consecutive convolutional layers, boosting interpretability. For uncertainty estimation, we propose the collaboration gradient approach, measuring gradient consistency across decoder layers. Notably, EU-Nets achieve an average accuracy improvement of 1.389\% and a variance reduction of 0.83\% across all networks and datasets in our experiments, requiring fewer than 0.1M parameters.
<div id='section'>Paperid: <span id='pid'>1182, <a href='https://arxiv.org/pdf/2502.16124.pdf' target='_blank'>https://arxiv.org/pdf/2502.16124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditi De, NeuroBits Labs
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16124">ZIA: A Theoretical Framework for Zero-Input AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Zero-Input AI (ZIA) introduces a novel framework for human-computer interaction by enabling proactive intent prediction without explicit user commands. It integrates gaze tracking, bio-signals (EEG, heart rate), and contextual data (time, location, usage history) into a multi-modal model for real-time inference, targeting <100 ms latency. The proposed architecture employs a transformer-based model with cross-modal attention, variational Bayesian inference for uncertainty estimation, and reinforcement learning for adaptive optimization. To support deployment on edge devices (CPUs, TPUs, NPUs), ZIA utilizes quantization, weight pruning, and linear attention to reduce complexity from quadratic to linear with sequence length. Theoretical analysis establishes an information-theoretic bound on prediction error and demonstrates how multi-modal fusion improves accuracy over single-modal approaches. Expected performance suggests 85-90% accuracy with EEG integration and 60-100 ms inference latency. ZIA provides a scalable, privacy-preserving framework for accessibility, healthcare, and consumer applications, advancing AI toward anticipatory intelligence.
<div id='section'>Paperid: <span id='pid'>1183, <a href='https://arxiv.org/pdf/2502.08593.pdf' target='_blank'>https://arxiv.org/pdf/2502.08593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aram Ebtekar, Yuhao Wang, Dominik Janzing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08593">Toward Universal Laws of Outlier Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When a variety of anomalous features motivate flagging different samples as outliers, Algorithmic Information Theory (AIT) offers a principled way to unify them in terms of a sample's randomness deficiency. Subject to the algorithmic Markov condition on a causal Bayesian network, we show that the randomness deficiency of a joint sample decomposes into a sum of randomness deficiencies at each causal mechanism. Consequently, anomalous observations can be attributed to their root causes, i.e., the mechanisms that behaved anomalously. As an extension of Levin's law of randomness conservation, we show that weak outliers cannot cause strong ones. We show how these information theoretic laws clarify our understanding of outlier detection and attribution, in the context of more specialized outlier scores from prior literature.
<div id='section'>Paperid: <span id='pid'>1184, <a href='https://arxiv.org/pdf/2502.01335.pdf' target='_blank'>https://arxiv.org/pdf/2502.01335.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Costin F. Ciusdel, Alex Serban, Tiziano Passerini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01335">ConceptVAE: Self-Supervised Fine-Grained Concept Disentanglement from 2D Echocardiographies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While traditional self-supervised learning methods improve performance and robustness across various medical tasks, they rely on single-vector embeddings that may not capture fine-grained concepts such as anatomical structures or organs. The ability to identify such concepts and their characteristics without supervision has the potential to improve pre-training methods, and enable novel applications such as fine-grained image retrieval and concept-based outlier detection. In this paper, we introduce ConceptVAE, a novel pre-training framework that detects and disentangles fine-grained concepts from their style characteristics in a self-supervised manner. We present a suite of loss terms and model architecture primitives designed to discretise input data into a preset number of concepts along with their local style. We validate ConceptVAE both qualitatively and quantitatively, demonstrating its ability to detect fine-grained anatomical structures such as blood pools and septum walls from 2D cardiac echocardiographies. Quantitatively, ConceptVAE outperforms traditional self-supervised methods in tasks such as region-based instance retrieval, semantic segmentation, out-of-distribution detection, and object detection. Additionally, we explore the generation of in-distribution synthetic data that maintains the same concepts as the training data but with distinct styles, highlighting its potential for more calibrated data generation. Overall, our study introduces and validates a promising new pre-training technique based on concept-style disentanglement, opening multiple avenues for developing models for medical image analysis that are more interpretable and explainable than black-box approaches.
<div id='section'>Paperid: <span id='pid'>1185, <a href='https://arxiv.org/pdf/2501.12204.pdf' target='_blank'>https://arxiv.org/pdf/2501.12204.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edward T. Reehorst, Philip Schniter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12204">Score Combining for Contrastive OOD Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In out-of-distribution (OOD) detection, one is asked to classify whether a test sample comes from a known inlier distribution or not. We focus on the case where the inlier distribution is defined by a training dataset and there exists no additional knowledge about the novelties that one is likely to encounter. This problem is also referred to as novelty detection, one-class classification, and unsupervised anomaly detection. The current literature suggests that contrastive learning techniques are state-of-the-art for OOD detection. We aim to improve on those techniques by combining/ensembling their scores using the framework of null hypothesis testing and, in particular, a novel generalized likelihood ratio test (GLRT). We demonstrate that our proposed GLRT-based technique outperforms the state-of-the-art CSI and SupCSI techniques from Tack et al. 2020 in dataset-vs-dataset experiments with CIFAR-10, SVHN, LSUN, ImageNet, and CIFAR-100, as well as leave-one-class-out experiments with CIFAR-10. We also demonstrate that our GLRT outperforms the score-combining methods of Fisher, Bonferroni, Simes, Benjamini-Hochwald, and Stouffer in our application.
<div id='section'>Paperid: <span id='pid'>1186, <a href='https://arxiv.org/pdf/2501.12178.pdf' target='_blank'>https://arxiv.org/pdf/2501.12178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maxime Di Folco, Gabriel Bernardino, Patrick Clarysse, Nicolas Duchateau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12178">High-dimensional multimodal uncertainty estimation by manifold alignment:Application to 3D right ventricular strain computations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Confidence in the results is a key ingredient to improve the adoption of machine learning methods by clinicians. Uncertainties on the results have been considered in the literature, but mostly those originating from the learning and processing methods. Uncertainty on the data is hardly challenged, as a single sample is often considered representative enough of each subject included in the analysis. In this paper, we propose a representation learning strategy to estimate local uncertainties on a physiological descriptor (here, myocardial deformation) previously obtained from medical images by different definitions or computations. We first use manifold alignment to match the latent representations associated to different high-dimensional input descriptors. Then, we formulate plausible distributions of latent uncertainties, and finally exploit them to reconstruct uncertainties on the input high-dimensional descriptors. We demonstrate its relevance for the quantification of myocardial deformation (strain) from 3D echocardiographic image sequences of the right ventricle, for which a lack of consensus exists in its definition and which directional component to use. We used a database of 100 control subjects with right ventricle overload, for which different types of strain are available at each point of the right ventricle endocardial surface mesh. Our approach quantifies local uncertainties on myocardial deformation from different descriptors defining this physiological concept. Such uncertainties cannot be directly estimated by local statistics on such descriptors, potentially of heterogeneous types. Beyond this controlled illustrative application, our methodology has the potential to be generalized to many other population analyses considering heterogeneous high-dimensional descriptors.
<div id='section'>Paperid: <span id='pid'>1187, <a href='https://arxiv.org/pdf/2501.11638.pdf' target='_blank'>https://arxiv.org/pdf/2501.11638.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>F. S. Pezzicoli, V. Ros, F. P. Landes, M. Baity-Jesi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11638">Class Imbalance in Anomaly Detection: Learning from an Exactly Solvable Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Class imbalance (CI) is a longstanding problem in machine learning, slowing down training and reducing performances. Although empirical remedies exist, it is often unclear which ones work best and when, due to the lack of an overarching theory. We address a common case of imbalance, that of anomaly (or outlier) detection. We provide a theoretical framework to analyze, interpret and address CI. It is based on an exact solution of the teacher-student perceptron model, through replica theory. Within this framework, one can distinguish several sources of CI: either intrinsic, train or test imbalance. Our analysis reveals that the optimal train imbalance is generally different from 50%, with a non trivial dependence on the intrinsic imbalance, the abundance of data and on the noise in the learning. Moreover, there is a crossover between a small noise training regime where results are independent of the noise level to a high noise regime where performances quickly degrade with noise. Our results challenge some of the conventional wisdom on CI and offer practical guidelines to address it.
<div id='section'>Paperid: <span id='pid'>1188, <a href='https://arxiv.org/pdf/2501.11054.pdf' target='_blank'>https://arxiv.org/pdf/2501.11054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohit Mapakshi, Sayma Akther, Mark Stamp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11054">Temporal Analysis of Adversarial Attacks in Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we experimentally analyze the robustness of selected Federated Learning (FL) systems in the presence of adversarial clients. We find that temporal attacks significantly affect model performance in the FL models tested, especially when the adversaries are active throughout or during the later rounds. We consider a variety of classic learning models, including Multinominal Logistic Regression (MLR), Random Forest, XGBoost, Support Vector Classifier (SVC), as well as various Neural Network models including Multilayer Perceptron (MLP), Convolution Neural Network (CNN), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM). Our results highlight the effectiveness of temporal attacks and the need to develop strategies to make the FL process more robust against such attacks. We also briefly consider the effectiveness of defense mechanisms, including outlier detection in the aggregation algorithm.
<div id='section'>Paperid: <span id='pid'>1189, <a href='https://arxiv.org/pdf/2501.10920.pdf' target='_blank'>https://arxiv.org/pdf/2501.10920.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Konrad Sundsgaard, Kutay BÃ¶lat, Guangya Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.10920">Data Enrichment Opportunities for Distribution Grid Cable Networks using Variational Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electricity distribution cable networks suffer from incomplete and unbalanced data, hindering the effectiveness of machine learning models for predictive maintenance and reliability evaluation. Features such as the installation date of the cables are frequently missing. To address data scarcity, this study investigates the application of Variational Autoencoders (VAEs) for data enrichment, synthetic data generation, imbalanced data handling, and outlier detection. Based on a proof-of-concept case study for Denmark, targeting the imputation of missing age information in cable network asset registers, the analysis underlines the potential of generative models to support data-driven maintenance. However, the study also highlights several areas for improvement, including enhanced feature importance analysis, incorporating network characteristics and external features, and handling biases in missing data. Future initiatives should expand the application of VAEs by incorporating semi-supervised learning, advanced sampling techniques, and additional distribution grid elements, including low-voltage networks, into the analysis.
<div id='section'>Paperid: <span id='pid'>1190, <a href='https://arxiv.org/pdf/2501.05809.pdf' target='_blank'>https://arxiv.org/pdf/2501.05809.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fuhang Liang, Rucong Xu, Deng Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05809">AdaPRL: Adaptive Pairwise Regression Learning with Uncertainty Estimation for Universal Regression Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current deep regression models usually learn in a point-wise way that treats each sample as an independent input, neglecting the relative ordering among different data. Consequently, the regression model could neglect the data's interrelationships, potentially resulting in suboptimal performance. Moreover, the existence of aleatoric uncertainty in the training data may drive the model to capture non-generalizable patterns, contributing to increased overfitting. To address these issues, we propose a novel adaptive pairwise learning framework for regression tasks (AdaPRL) which leverages the relative differences between data points and integrates with deep probabilistic models to quantify the uncertainty associated with the predictions. Additionally, we adapt AdaPRL for applications in multi-task learning and multivariate time series forecasting. Extensive experiments with several real-world regression datasets including recommendation systems, age prediction, time series forecasting, natural language understanding, finance, and industry datasets show that AdaPRL is compatible with different backbone networks in various tasks and achieves state-of-the-art performance on the vast majority of tasks without extra inference cost, highlighting its notable potential including enhancing prediction accuracy and ranking ability, increasing generalization capability, improving robustness to noisy data, improving resilience to reduced data, and enhancing interpretability. Experiments also show that AdaPRL can be seamlessly incorporated into recently proposed regression frameworks to gain performance improvement.
<div id='section'>Paperid: <span id='pid'>1191, <a href='https://arxiv.org/pdf/2501.05228.pdf' target='_blank'>https://arxiv.org/pdf/2501.05228.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Kang Lee, Jun-Cheng Chen, Ja-Ling Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05228">Harnessing Large Language and Vision-Language Models for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection has seen significant advancements with zero-shot approaches by leveraging the powerful Vision-Language Models (VLMs) such as CLIP. However, prior research works have predominantly focused on enhancing Far-OOD performance, while potentially compromising Near-OOD efficacy, as observed from our pilot study. To address this issue, we propose a novel strategy to enhance zero-shot OOD detection performances for both Far-OOD and Near-OOD scenarios by innovatively harnessing Large Language Models (LLMs) and VLMs. Our approach first exploit an LLM to generate superclasses of the ID labels and their corresponding background descriptions followed by feature extraction using CLIP. We then isolate the core semantic features for ID data by subtracting background features from the superclass features. The refined representation facilitates the selection of more appropriate negative labels for OOD data from a comprehensive candidate label set of WordNet, thereby enhancing the performance of zero-shot OOD detection in both scenarios. Furthermore, we introduce novel few-shot prompt tuning and visual prompt tuning to adapt the proposed framework to better align with the target distribution. Experimental results demonstrate that the proposed approach consistently outperforms current state-of-the-art methods across multiple benchmarks, with an improvement of up to 2.9% in AUROC and a reduction of up to 12.6% in FPR95. Additionally, our method exhibits superior robustness against covariate shift across different domains, further highlighting its effectiveness in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>1192, <a href='https://arxiv.org/pdf/2501.03402.pdf' target='_blank'>https://arxiv.org/pdf/2501.03402.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Louis L Chen, Roberto Szechtman, Matan Seri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03402">On the Adversarial Robustness of Benjamini Hochberg</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Benjamini-Hochberg (BH) procedure is widely used to control the false detection rate (FDR) in multiple testing. Applications of this control abound in drug discovery, forensics, anomaly detection, and, in particular, machine learning, ranging from nonparametric outlier detection to out-of-distribution detection and one-class classification methods. Considering this control could be relied upon in critical safety/security contexts, we investigate its adversarial robustness. More precisely, we study under what conditions BH does and does not exhibit adversarial robustness, we present a class of simple and easily implementable adversarial test-perturbation algorithms, and we perform computational experiments. With our algorithms, we demonstrate that there are conditions under which BH's control can be significantly broken with relatively few (even just one) test score perturbation(s), and provide non-asymptotic guarantees on the expected adversarial-adjustment to FDR. Our technical analysis involves a combinatorial reframing of the BH procedure as a ``balls into bins'' process, and drawing a connection to generalized ballot problems to facilitate an information-theoretic approach for deriving non-asymptotic lower bounds.
<div id='section'>Paperid: <span id='pid'>1193, <a href='https://arxiv.org/pdf/2412.05010.pdf' target='_blank'>https://arxiv.org/pdf/2412.05010.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>ZeinabSadat Taghavi, Hossein Mirzaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05010">Backdooring Outlier Detection Methods: A Novel Attack Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There have been several efforts in backdoor attacks, but these have primarily focused on the closed-set performance of classifiers (i.e., classification). This has left a gap in addressing the threat to classifiers' open-set performance, referred to as outlier detection in the literature. Reliable outlier detection is crucial for deploying classifiers in critical real-world applications such as autonomous driving and medical image analysis. First, we show that existing backdoor attacks fall short in affecting the open-set performance of classifiers, as they have been specifically designed to confuse intra-closed-set decision boundaries. In contrast, an effective backdoor attack for outlier detection needs to confuse the decision boundary between the closed and open sets. Motivated by this, in this study, we propose BATOD, a novel Backdoor Attack targeting the Outlier Detection task. Specifically, we design two categories of triggers to shift inlier samples to outliers and vice versa. We evaluate BATOD using various real-world datasets and demonstrate its superior ability to degrade the open-set performance of classifiers compared to previous attacks, both before and after applying defenses.
<div id='section'>Paperid: <span id='pid'>1194, <a href='https://arxiv.org/pdf/2412.01193.pdf' target='_blank'>https://arxiv.org/pdf/2412.01193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnav Kharbanda, Advait Chandorkar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01193">Divergent Ensemble Networks: Enhancing Uncertainty Estimation with Shared Representations and Independent Branching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensemble learning has proven effective in improving predictive performance and estimating uncertainty in neural networks. However, conventional ensemble methods often suffer from redundant parameter usage and computational inefficiencies due to entirely independent network training. To address these challenges, we propose the Divergent Ensemble Network (DEN), a novel architecture that combines shared representation learning with independent branching. DEN employs a shared input layer to capture common features across all branches, followed by divergent, independently trainable layers that form an ensemble. This shared-to-branching structure reduces parameter redundancy while maintaining ensemble diversity, enabling efficient and scalable learning.
<div id='section'>Paperid: <span id='pid'>1195, <a href='https://arxiv.org/pdf/2412.00205.pdf' target='_blank'>https://arxiv.org/pdf/2412.00205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michele De Vita, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00205">Diffusion Model Guided Sampling with Pixel-Wise Aleatoric Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the remarkable progress in generative modelling, current diffusion models lack a quantitative approach to assess image quality. To address this limitation, we propose to estimate the pixel-wise aleatoric uncertainty during the sampling phase of diffusion models and utilise the uncertainty to improve the sample generation quality. The uncertainty is computed as the variance of the denoising scores with a perturbation scheme that is specifically designed for diffusion models. We then show that the aleatoric uncertainty estimates are related to the second-order derivative of the diffusion noise distribution. We evaluate our uncertainty estimation algorithm and the uncertainty-guided sampling on the ImageNet and CIFAR-10 datasets. In our comparisons with the related work, we demonstrate promising results in filtering out low quality samples. Furthermore, we show that our guided approach leads to better sample generation in terms of FID scores.
<div id='section'>Paperid: <span id='pid'>1196, <a href='https://arxiv.org/pdf/2411.16427.pdf' target='_blank'>https://arxiv.org/pdf/2411.16427.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Somjit Nath, Yik Chau Lui, Siqi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16427">Unsupervised Event Outlier Detection in Continuous Time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Event sequence data record the occurrences of events in continuous time. Event sequence forecasting based on temporal point processes (TPPs) has been extensively studied, but outlier or anomaly detection, especially without any supervision from humans, is still underexplored. In this work, we develop, to the best our knowledge, the first unsupervised outlier detection approach to detecting abnormal events. Our novel unsupervised outlier detection framework is based on ideas from generative adversarial networks (GANs) and reinforcement learning (RL). We train a 'generator' that corrects outliers in the data with a 'discriminator' that learns to discriminate the corrected data from the real data, which may contain outliers. A key insight is that if the generator made a mistake in the correction, it would generate anomalies that are different from the anomalies in the real data, so it serves as data augmentation for the discriminator learning. Different from typical GAN-based outlier detection approaches, our method employs the generator to detect outliers in an online manner. The experimental results show that our method can detect event outliers more accurately than the state-of-the-art approaches.
<div id='section'>Paperid: <span id='pid'>1197, <a href='https://arxiv.org/pdf/2411.15944.pdf' target='_blank'>https://arxiv.org/pdf/2411.15944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinzhe Cao, Yadong Xu, Xiaofeng Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15944">Customer Lifetime Value Prediction with Uncertainty Estimation Using Monte Carlo Dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting customer Lifetime Value (LTV) is crucial for companies to optimize their revenue strategies. Traditional deep learning models for LTV prediction are effective but typically provide only point estimates and fail to capture model uncertainty in modeling user behaviors. To address this limitation, we propose a novel approach that enhances the architecture of purely neural network models by incorporating the Monte Carlo Dropout (MCD) framework. We benchmarked the proposed method using data from one of the most downloaded mobile games in the world, and demonstrated a substantial improvement in predictive Top 5\% Mean Absolute Percentage Error compared to existing state-of-the-art methods. Additionally, our approach provides confidence metric as an extra dimension for performance evaluation across various neural network models, facilitating more informed business decisions.
<div id='section'>Paperid: <span id='pid'>1198, <a href='https://arxiv.org/pdf/2411.14457.pdf' target='_blank'>https://arxiv.org/pdf/2411.14457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maryam Shoaeinaeini, Brent Harrison
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14457">Guiding Reinforcement Learning Using Uncertainty-Aware Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human guidance in reinforcement learning (RL) is often impractical for large-scale applications due to high costs and time constraints. Large Language Models (LLMs) offer a promising alternative to mitigate RL sample inefficiency and potentially replace human trainers. However, applying LLMs as RL trainers is challenging due to their overconfidence and less reliable solutions in sequential tasks. We address this limitation by introducing a calibrated guidance system that uses Monte Carlo Dropout to enhance LLM advice reliability by assessing prediction variances from multiple forward passes. Additionally, we develop a novel RL policy shaping method based on dynamic model average entropy to adjust the LLM's influence on RL policies according to guidance uncertainty. This approach ensures robust RL training by relying on reliable LLM guidance. To validate our contributions, we conduct extensive experiments in a Minigrid environment with three goals in varying environment sizes. The results showcase superior model performance compared to uncalibrated LLMs, unguided RL, and calibrated LLMs with different shaping policies. Moreover, we analyze various uncertainty estimation methods, demonstrating the effectiveness of average entropy in reflecting higher uncertainty in incorrect guidance. These findings highlight the persistent overconfidence in fine-tuned LLMs and underscore the importance of effective calibration in sequential decision-making problems.
<div id='section'>Paperid: <span id='pid'>1199, <a href='https://arxiv.org/pdf/2411.12102.pdf' target='_blank'>https://arxiv.org/pdf/2411.12102.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Richard Kurle, Alexej Klushyn, Ralf Herbrich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.12102">BALI: Learning Neural Networks via Bayesian Layerwise Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a new method for learning Bayesian neural networks, treating them as a stack of multivariate Bayesian linear regression models. The main idea is to infer the layerwise posterior exactly if we know the target outputs of each layer. We define these pseudo-targets as the layer outputs from the forward pass, updated by the backpropagated gradients of the objective function. The resulting layerwise posterior is a matrix-normal distribution with a Kronecker-factorized covariance matrix, which can be efficiently inverted. Our method extends to the stochastic mini-batch setting using an exponential moving average over natural-parameter terms, thus gradually forgetting older data. The method converges in few iterations and performs as well as or better than leading Bayesian neural network methods on various regression, classification, and out-of-distribution detection benchmarks.
<div id='section'>Paperid: <span id='pid'>1200, <a href='https://arxiv.org/pdf/2411.08867.pdf' target='_blank'>https://arxiv.org/pdf/2411.08867.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kushankur Ghosh, Murilo Coelho Naldi, JÃ¶rg Sander, Euijin Choo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08867">Unsupervised Parameter-free Outlier Detection using HDBSCAN* Outlier Profiles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In machine learning and data mining, outliers are data points that significantly differ from the dataset and often introduce irrelevant information that can induce bias in its statistics and models. Therefore, unsupervised methods are crucial to detect outliers if there is limited or no information about them. Global-Local Outlier Scores based on Hierarchies (GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a state-of-the-art hierarchical clustering method. GLOSH estimates outlier scores for each data point by comparing its density to the highest density of the region they reside in the HDBSCAN* hierarchy. GLOSH may be sensitive to HDBSCAN*'s minpts parameter that influences density estimation. With limited knowledge about the data, choosing an appropriate minpts value beforehand is challenging as one or some minpts values may better represent the underlying cluster structure than others. Additionally, in the process of searching for ``potential outliers'', one has to define the number of outliers n a dataset has, which may be impractical and is often unknown. In this paper, we propose an unsupervised strategy to find the ``best'' minpts value, leveraging the range of GLOSH scores across minpts values to identify the value for which GLOSH scores can best identify outliers from the rest of the dataset. Moreover, we propose an unsupervised strategy to estimate a threshold for classifying points into inliers and (potential) outliers without the need to pre-define any value. Our experiments show that our strategies can automatically find the minpts value and threshold that yield the best or near best outlier detection results using GLOSH.
<div id='section'>Paperid: <span id='pid'>1201, <a href='https://arxiv.org/pdf/2411.03082.pdf' target='_blank'>https://arxiv.org/pdf/2411.03082.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Irum Mehboob, Li Sun, Alireza Astegarpanah, Rustam Stolkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.03082">Self-supervised cross-modality learning for uncertainty-aware object detection and recognition in applications which lack pre-labelled training data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper shows how an uncertainty-aware, deep neural network can be trained to detect, recognise and localise objects in 2D RGB images, in applications lacking annotated train-ng datasets. We propose a self-supervising teacher-student pipeline, in which a relatively simple teacher classifier, trained with only a few labelled 2D thumbnails, automatically processes a larger body of unlabelled RGB-D data to teach a student network based on a modified YOLOv3 architecture. Firstly, 3D object detection with back projection is used to automatically extract and teach 2D detection and localisation information to the student network. Secondly, a weakly supervised 2D thumbnail classifier, with minimal training on a small number of hand-labelled images, is used to teach object category recognition. Thirdly, we use a Gaussian Process GP to encode and teach a robust uncertainty estimation functionality, so that the student can output confidence scores with each categorization. The resulting student significantly outperforms the same YOLO architecture trained directly on the same amount of labelled data. Our GP-based approach yields robust and meaningful uncertainty estimations for complex industrial object classifications. The end-to-end network is also capable of real-time processing, needed for robotics applications. Our method can be applied to many important industrial tasks, where labelled datasets are typically unavailable. In this paper, we demonstrate an example of detection, localisation, and object category recognition of nuclear mixed-waste materials in highly cluttered and unstructured scenes. This is critical for robotic sorting and handling of legacy nuclear waste, which poses complex environmental remediation challenges in many nuclearised nations.
<div id='section'>Paperid: <span id='pid'>1202, <a href='https://arxiv.org/pdf/2410.22685.pdf' target='_blank'>https://arxiv.org/pdf/2410.22685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yashvir S. Grewal, Edwin V. Bonilla, Thang D. Bui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.22685">Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the-art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional entailment criteria between multiple generated responses and also depend on sequence likelihoods. While effective, these approaches often overestimate uncertainty due to their sensitivity to minor wording differences, additional correct information, and non-important words in the sequence. We propose a novel approach that leverages semantic embeddings to achieve smoother and more robust estimation of semantic uncertainty in LLMs. By capturing semantic similarities without depending on sequence likelihoods, our method inherently reduces any biases introduced by irrelevant words in the answers. Furthermore, we introduce an amortised version of our approach by explicitly modelling semantics as latent variables in a joint probabilistic model. This allows for uncertainty estimation in the embedding space with a single forward pass, significantly reducing computational overhead compared to existing multi-pass methods. Experiments across multiple question-answering datasets and frontier LLMs demonstrate that our embedding-based methods provide more accurate and nuanced uncertainty quantification than traditional approaches.
<div id='section'>Paperid: <span id='pid'>1203, <a href='https://arxiv.org/pdf/2410.21797.pdf' target='_blank'>https://arxiv.org/pdf/2410.21797.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seunghyeon Shin, Seokjin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21797">Representational learning for an anomalous sound detection system with source separation model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of anomalous sounds in machinery operation presents a significant challenge due to the difficulty in generalizing anomalous acoustic patterns. This task is typically approached as an unsupervised learning or novelty detection problem, given the complexities associated with the acquisition of comprehensive anomalous acoustic data. Conventional methodologies for training anomalous sound detection systems primarily employ auto-encoder architectures or representational learning with auxiliary tasks. However, both approaches have inherent limitations. Auto-encoder structures are constrained to utilizing only the target machine's operational sounds, while training with auxiliary tasks, although capable of incorporating diverse acoustic inputs, may yield representations that lack correlation with the characteristic acoustic signatures of anomalous conditions. We propose a training method based on the source separation model (CMGAN) that aims to isolate non-target machine sounds from a mixture of target and non-target class acoustic signals. This approach enables the effective utilization of diverse machine sounds and facilitates the training of complex neural network architectures with limited sample sizes. Our experimental results demonstrate that the proposed method yields better performance compared to both conventional auto-encoder training approaches and source separation techniques that focus on isolating target machine signals. Moreover, our experimental results demonstrate that the proposed method exhibits the potential for enhanced representation learning as the quantity of non-target data increases, even while maintaining a constant volume of target class data.
<div id='section'>Paperid: <span id='pid'>1204, <a href='https://arxiv.org/pdf/2410.21006.pdf' target='_blank'>https://arxiv.org/pdf/2410.21006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pau Ferrer-Cid, Jose M. Barcelo-Ordinas, Jorge Garcia-Vidal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21006">A Review of Graph-Powered Data Quality Applications for IoT Monitoring Sensor Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of Internet of Things (IoT) technologies has led to the widespread adoption of monitoring networks for a wide variety of applications, such as smart cities, environmental monitoring, and precision agriculture. A major research focus in recent years has been the development of graph-based techniques to improve the quality of data from sensor networks, a key aspect for the use of sensed data in decision-making processes, digital twins, and other applications. Emphasis has been placed on the development of machine learning and signal processing techniques over graphs, taking advantage of the benefits provided by the use of structured data through a graph topology. Many technologies such as the graph signal processing (GSP) or the successful graph neural networks (GNNs) have been used for data quality enhancement tasks. In this survey, we focus on graph-based models for data quality control in monitoring sensor networks. Furthermore, we delve into the technical details that are commonly leveraged for providing powerful graph-based solutions for data quality tasks in sensor networks, including missing value imputation, outlier detection, or virtual sensing. To conclude, we have identified future trends and challenges such as graph-based models for digital twins or model transferability and generalization.
<div id='section'>Paperid: <span id='pid'>1205, <a href='https://arxiv.org/pdf/2410.17851.pdf' target='_blank'>https://arxiv.org/pdf/2410.17851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>K. Darshana Abeyrathna, Sara El Mekkaoui, Andreas Hafver, Christian Agrell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.17851">The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tsetlin Machines (TMs) have emerged as a compelling alternative to conventional deep learning methods, offering notable advantages such as smaller memory footprint, faster inference, fault-tolerant properties, and interpretability. Although various adaptations of TMs have expanded their applicability across diverse domains, a fundamental gap remains in understanding how TMs quantify uncertainty in their predictions. In response, this paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed at providing a robust, reliable, and interpretable approach for uncertainty quantification. Unlike the original TM, the PTM learns the probability of staying on each state of each Tsetlin Automaton (TA) across all clauses. These probabilities are updated using the feedback tables that are part of the TM framework: Type I and Type II feedback. During inference, TAs decide their actions by sampling states based on learned probability distributions, akin to Bayesian neural networks when generating weight values. In our experimental analysis, we first illustrate the spread of the probabilities across TA states for the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models using both simulated and real-world datasets. The experiments on the simulated dataset reveal the PTM's effectiveness in uncertainty quantification, particularly in delineating decision boundaries and identifying regions of high uncertainty. Moreover, when applied to multiclass classification tasks using the Iris dataset, the PTM demonstrates competitive performance in terms of predictive entropy and expected calibration error, showcasing its potential as a reliable tool for uncertainty estimation. Our findings underscore the importance of selecting appropriate models for accurate uncertainty quantification in predictive tasks, with the PTM offering a particularly interpretable and effective solution.
<div id='section'>Paperid: <span id='pid'>1206, <a href='https://arxiv.org/pdf/2410.17142.pdf' target='_blank'>https://arxiv.org/pdf/2410.17142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. V. Kornilov, V. S. Korolev, K. L. Malanchev, A. D. Lavrukhina, E. Russeil, T. A. Semenikhin, E. Gangler, E. E. O. Ishida, M. V. Pruzhinskaya, A. A. Volnova, S. Sreejith
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.17142">Coniferest: a complete active anomaly detection framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present coniferest, an open source generic purpose active anomaly detection framework written in Python. The package design and implemented algorithms are described. Currently, static outlier detection analysis is supported via the Isolation forest algorithm. Moreover, Active Anomaly Discovery (AAD) and Pineforest algorithms are available to tackle active anomaly detection problems. The algorithms and package performance are evaluated on a series of synthetic datasets. We also describe a few success cases which resulted from applying the package to real astronomical data in active anomaly detection tasks within the SNAD project.
<div id='section'>Paperid: <span id='pid'>1207, <a href='https://arxiv.org/pdf/2410.12250.pdf' target='_blank'>https://arxiv.org/pdf/2410.12250.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ng Wen Zheng Terence, Chen Jianda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12250">Dual Action Policy for Robust Sim-to-Real Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents Dual Action Policy (DAP), a novel approach to address the dynamics mismatch inherent in the sim-to-real gap of reinforcement learning. DAP uses a single policy to predict two sets of actions: one for maximizing task rewards in simulation and another specifically for domain adaptation via reward adjustments. This decoupling makes it easier to maximize the overall reward in the source domain during training. Additionally, DAP incorporates uncertainty-based exploration during training to enhance agent robustness. Experimental results demonstrate DAP's effectiveness in bridging the sim-to-real gap, outperforming baselines on challenging tasks in simulation, and further improvement is achieved by incorporating uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1208, <a href='https://arxiv.org/pdf/2410.08958.pdf' target='_blank'>https://arxiv.org/pdf/2410.08958.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Salnikov, Kevin Michalewicz, Dan Leonte
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08958">Lifted Coefficient of Determination: Fast model-free prediction intervals and likelihood-free model comparison</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the $\textit{lifted linear model}$, and derive model-free prediction intervals that become tighter as the correlation between predictions and observations increases. These intervals motivate the $\textit{Lifted Coefficient of Determination}$, a model comparison criterion for arbitrary loss functions in prediction-based settings, e.g., regression, classification or counts. We extend the prediction intervals to more general error distributions, and propose a fast model-free outlier detection algorithm for regression. Finally, we illustrate the framework via numerical experiments.
<div id='section'>Paperid: <span id='pid'>1209, <a href='https://arxiv.org/pdf/2410.08687.pdf' target='_blank'>https://arxiv.org/pdf/2410.08687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanieh Shojaei, Qianqian Zou, Max Mehltretter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08687">Uncertainty Estimation and Out-of-Distribution Detection for LiDAR Scene Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safe navigation in new environments requires autonomous vehicles and robots to accurately interpret their surroundings, relying on LiDAR scene segmentation, out-of-distribution (OOD) obstacle detection, and uncertainty computation. We propose a method to distinguish in-distribution (ID) from OOD samples and quantify both epistemic and aleatoric uncertainties using the feature space of a single deterministic model. After training a semantic segmentation network, a Gaussian Mixture Model (GMM) is fitted to its feature space. OOD samples are detected by checking if their squared Mahalanobis distances to each Gaussian component conform to a chi-squared distribution, eliminating the need for an additional OOD training set. Given that the estimated mean and covariance matrix of a multivariate Gaussian distribution follow Gaussian and Inverse-Wishart distributions, multiple GMMs are generated by sampling from these distributions to assess epistemic uncertainty through classification variability. Aleatoric uncertainty is derived from the entropy of responsibility values within Gaussian components. Comparing our method with deep ensembles and logit-sampling for uncertainty computation demonstrates its superior performance in real-world applications for quantifying epistemic and aleatoric uncertainty, as well as detecting OOD samples. While deep ensembles miss some highly uncertain samples, our method successfully detects them and assigns high epistemic uncertainty.
<div id='section'>Paperid: <span id='pid'>1210, <a href='https://arxiv.org/pdf/2410.06120.pdf' target='_blank'>https://arxiv.org/pdf/2410.06120.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giovanni Messuti, ortensia Amoroso, Ferdinando Napolitano, Mariarosaria Falanga, Paolo Capuano, Silvia Scarpetta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06120">Uncertainty estimation via ensembles of deep learning models and dropout layers for seismic traces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models have demonstrated remarkable success in various fields, including seismology. However, one major challenge in deep learning is the presence of mislabeled examples. Additionally, accurately estimating model uncertainty is another challenge in machine learning. In this study, we develop Convolutional Neural Networks (CNNs) to classify seismic waveforms based on first-motion polarity. We trained multiple CNN models with different settings. We also constructed ensembles of networks to estimate uncertainty. The results showed that each training setting achieved satisfactory performances, with the ensemble method outperforming individual networks in uncertainty estimation. We observe that the uncertainty estimation ability of the ensembles of networks can be enhanced using dropout layers. In addition, comparisons among different training settings revealed that the use of dropout improved the robustness of networks to mislabeled examples.
<div id='section'>Paperid: <span id='pid'>1211, <a href='https://arxiv.org/pdf/2409.18628.pdf' target='_blank'>https://arxiv.org/pdf/2409.18628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marvin Tom Teichmann, Manasi Datar, Lisa Kratzke, Fernando Vega, Florin C. Ghesu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18628">Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The precision of contouring target structures and organs-at-risk (OAR) in radiotherapy planning is crucial for ensuring treatment efficacy and patient safety. Recent advancements in deep learning (DL) have significantly improved OAR contouring performance, yet the reliability of these models, especially in the presence of out-of-distribution (OOD) scenarios, remains a concern in clinical settings. This application study explores the integration of epistemic uncertainty estimation within the OAR contouring workflow to enable OOD detection in clinically relevant scenarios, using specifically compiled data. Furthermore, we introduce an advanced statistical method for OOD detection to enhance the methodological framework of uncertainty estimation. Our empirical evaluation demonstrates that epistemic uncertainty estimation is effective in identifying instances where model predictions are unreliable and may require an expert review. Notably, our approach achieves an AUC-ROC of 0.95 for OOD detection, with a specificity of 0.95 and a sensitivity of 0.92 for implant cases, underscoring its efficacy. This study addresses significant gaps in the current research landscape, such as the lack of ground truth for uncertainty estimation and limited empirical evaluations. Additionally, it provides a clinically relevant application of epistemic uncertainty estimation in an FDA-approved and widely used clinical solution for OAR segmentation from Varian, a Siemens Healthineers company, highlighting its practical benefits.
<div id='section'>Paperid: <span id='pid'>1212, <a href='https://arxiv.org/pdf/2409.05234.pdf' target='_blank'>https://arxiv.org/pdf/2409.05234.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Javad Ghorbanian, Nicholas Casaprima, Audrey Olivier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.05234">Empowering Bayesian Neural Networks with Functional Priors through Anchored Ensembling for Mechanics Surrogate Modeling Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, neural networks (NNs) have become increasingly popular for surrogate modeling tasks in mechanics and materials modeling applications. While traditional NNs are deterministic functions that rely solely on data to learn the input--output mapping, casting NN training within a Bayesian framework allows to quantify uncertainties, in particular epistemic uncertainties that arise from lack of training data, and to integrate a priori knowledge via the Bayesian prior. However, the high dimensionality and non-physicality of the NN parameter space, and the complex relationship between parameters (NN weights) and predicted outputs, renders both prior design and posterior inference challenging. In this work we present a novel BNN training scheme based on anchored ensembling that can integrate a priori information available in the function space, from e.g. low-fidelity models. The anchoring scheme makes use of low-rank correlations between NN parameters, learnt from pre-training to realizations of the functional prior. We also perform a study to demonstrate how correlations between NN weights, which are often neglected in existing BNN implementations, is critical to appropriately transfer knowledge between the function-space and parameter-space priors. Performance of our novel BNN algorithm is first studied on a small 1D example to illustrate the algorithm's behavior in both interpolation and extrapolation settings. Then, a thorough assessment is performed on a multi--input--output materials surrogate modeling example, where we demonstrate the algorithm's capabilities both in terms of accuracy and quality of the uncertainty estimation, for both in-distribution and out-of-distribution data.
<div id='section'>Paperid: <span id='pid'>1213, <a href='https://arxiv.org/pdf/2409.02976.pdf' target='_blank'>https://arxiv.org/pdf/2409.02976.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Y. Arteaga, Thomas B. SchÃ¶n, Nicolas Pielawski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02976">Hallucination Detection in LLMs: Fast and Memory-Efficient Fine-Tuned Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a necessary component when implementing AI in high-risk settings, such as autonomous cars, medicine, or insurances. Large Language Models (LLMs) have seen a surge in popularity in recent years, but they are subject to hallucinations, which may cause serious harm in high-risk settings. Despite their success, LLMs are expensive to train and run: they need a large amount of computations and memory, preventing the use of ensembling methods in practice. In this work, we present a novel method that allows for fast and memory-friendly training of LLM ensembles. We show that the resulting ensembles can detect hallucinations and are a viable approach in practice as only one GPU is needed for training and inference.
<div id='section'>Paperid: <span id='pid'>1214, <a href='https://arxiv.org/pdf/2409.02478.pdf' target='_blank'>https://arxiv.org/pdf/2409.02478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Petter Uvdal, Mohsen Mirkhalaf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02478">Test-time data augmentation: improving predictions of recurrent neural network models of composites</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recurrent Neural Networks (RNNs) have emerged as an interesting alternative to conventional material modeling approaches, particularly for nonlinear path dependent materials. Remarkable computational enhancements are obtained using RNNs compared to classical approaches such as the computational homogenization method. However, RNN predictive errors accumulate, leading to issues when predicting temporal dependencies in time series data. This study aims to address and mitigate inaccuracies induced by neural networks in predicting path dependent plastic deformations of short fiber reinforced composite materials. We propose using an approach of Test Time data Augmentation (TTA), which, to the best of the authors knowledge, is previously untested in the context of RNNs. The method is based on augmenting the input test data using random rotations and subsequently rotating back the predicted output signal. By aggregating the back rotated predictions, a more accurate prediction compared to individual predictions is obtained. Our analysis also demonstrates improved shape consistency between the prediction and the target pseudo time signal. Additionally, this method provides an uncertainty estimation which correlates with the absolute prediction error. The TTA approach is reproducible with different randomly generated data augmentations, establishing a promising framework for optimizing predictions of deep learning models. We believe there are broader implications of the proposed method for various fields reliant on accurate predictive data driven modeling.
<div id='section'>Paperid: <span id='pid'>1215, <a href='https://arxiv.org/pdf/2409.00980.pdf' target='_blank'>https://arxiv.org/pdf/2409.00980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Priyanka Chudasama, Anil Surisetty, Aakarsh Malhotra, Alok Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00980">DNN-GDITD: Out-of-distribution detection via Deep Neural Network based Gaussian Descriptor for Imbalanced Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Classification tasks present challenges due to class imbalances and evolving data distributions. Addressing these issues requires a robust method to handle imbalances while effectively detecting out-of-distribution (OOD) samples not encountered during training. This study introduces a novel OOD detection algorithm designed for tabular datasets, titled Deep Neural Network-based Gaussian Descriptor for Imbalanced Tabular Data (DNN-GDITD). The DNN-GDITD algorithm can be placed on top of any DNN to facilitate better classification of imbalanced data and OOD detection using spherical decision boundaries. Using a combination of Push, Score-based, and focal losses, DNN-GDITD assigns confidence scores to test data points, categorizing them as known classes or as an OOD sample. Extensive experimentation on tabular datasets demonstrates the effectiveness of DNN-GDITD compared to three OOD algorithms. Evaluation encompasses imbalanced and balanced scenarios on diverse tabular datasets, including a synthetic financial dispute dataset and publicly available tabular datasets like Gas Sensor, Drive Diagnosis, and MNIST, showcasing DNN-GDITD's versatility.
<div id='section'>Paperid: <span id='pid'>1216, <a href='https://arxiv.org/pdf/2408.11249.pdf' target='_blank'>https://arxiv.org/pdf/2408.11249.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matias Valdenegro-Toro, Radina Stoykova
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11249">The Dilemma of Uncertainty Estimation for General Purpose AI in the EU AI Act</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The AI act is the European Union-wide regulation of AI systems. It includes specific provisions for general-purpose AI models which however need to be further interpreted in terms of technical standards and state-of-art studies to ensure practical compliance solutions. This paper examines the AI act requirements for providers and deployers of general-purpose AI and further proposes uncertainty estimation as a suitable measure for legal compliance and quality assurance in training of such models. We argue that uncertainty estimation should be a required component for deploying models in the real world, and under the EU AI Act, it could fulfill several requirements for transparency, accuracy, and trustworthiness. However, generally using uncertainty estimation methods increases the amount of computation, producing a dilemma, as computation might go over the threshold ($10^{25}$ FLOPS) to classify the model as a systemic risk system which bears more regulatory burden.
<div id='section'>Paperid: <span id='pid'>1217, <a href='https://arxiv.org/pdf/2408.08142.pdf' target='_blank'>https://arxiv.org/pdf/2408.08142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sangita Das, Subhrajyoti Maji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08142">Impact of Comprehensive Data Preprocessing on Predictive Modelling of COVID-19 Mortality</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate predictive models are crucial for analysing COVID-19 mortality trends. This study evaluates the impact of a custom data preprocessing pipeline on ten machine learning models predicting COVID-19 mortality using data from Our World in Data (OWID). Our pipeline differs from a standard preprocessing pipeline through four key steps. Firstly, it transforms weekly reported totals into daily updates, correcting reporting biases and providing more accurate estimates. Secondly, it uses localised outlier detection and processing to preserve data variance and enhance accuracy. Thirdly, it utilises computational dependencies among columns to ensure data consistency. Finally, it incorporates an iterative feature selection process to optimise the feature set and improve model performance. Results show a significant improvement with the custom pipeline: the MLP Regressor achieved a test RMSE of 66.556 and a test R-squared of 0.991, surpassing the DecisionTree Regressor from the standard pipeline, which had a test RMSE of 222.858 and a test R-squared of 0.817. These findings highlight the importance of tailored preprocessing techniques in enhancing predictive modelling accuracy for COVID-19 mortality. Although specific to this study, these methodologies offer valuable insights into diverse datasets and domains, improving predictive performance across various contexts.
<div id='section'>Paperid: <span id='pid'>1218, <a href='https://arxiv.org/pdf/2408.02295.pdf' target='_blank'>https://arxiv.org/pdf/2408.02295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seyeon Kim, Joonhun Lee, Namhoon Cho, Sungjun Han, Wooseop Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02295">Generalized Gaussian Temporal Difference Error for Uncertainty-aware Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional uncertainty-aware temporal difference (TD) learning often assumes a zero-mean Gaussian distribution for TD errors, leading to inaccurate error representations and compromised uncertainty estimation. We introduce a novel framework for generalized Gaussian error modeling in deep reinforcement learning to enhance the flexibility of error distribution modeling by incorporating additional higher-order moment, particularly kurtosis, thereby improving the estimation and mitigation of data-dependent aleatoric uncertainty. We examine the influence of the shape parameter of the generalized Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form expression that demonstrates an inverse relationship between uncertainty and the shape parameter. Additionally, we propose a theoretically grounded weighting scheme to address epistemic uncertainty by fully leveraging the GGD. We refine batch inverse variance weighting with bias reduction and kurtosis considerations, enhancing robustness. Experiments with policy gradient algorithms demonstrate significant performance gains.
<div id='section'>Paperid: <span id='pid'>1219, <a href='https://arxiv.org/pdf/2408.01301.pdf' target='_blank'>https://arxiv.org/pdf/2408.01301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gregory Canal, Vladimir Leung, Philip Sage, Eric Heim, I-Jeng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01301">A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI) has revolutionized decision-making processes and systems throughout society and, in particular, has emerged as a significant technology in high-impact scenarios of national interest. Yet, despite AI's impressive predictive capabilities in controlled settings, it still suffers from a range of practical setbacks preventing its widespread use in various critical scenarios. In particular, it is generally unclear if a given AI system's predictions can be trusted by decision-makers in downstream applications. To address the need for more transparent, robust, and trustworthy AI systems, a suite of tools has been developed to quantify the uncertainty of AI predictions and, more generally, enable AI to "self-assess" the reliability of its predictions. In this manuscript, we categorize methods for AI self-assessment along several key dimensions and provide guidelines for selecting and designing the appropriate method for a practitioner's needs. In particular, we focus on uncertainty estimation techniques that consider the impact of self-assessment on the choices made by downstream decision-makers and on the resulting costs and benefits of decision outcomes. To demonstrate the utility of our methodology for self-assessment design, we illustrate its use for two realistic national-interest scenarios. This manuscript is a practical guide for machine learning engineers and AI system users to select the ideal self-assessment techniques for each problem.
<div id='section'>Paperid: <span id='pid'>1220, <a href='https://arxiv.org/pdf/2407.16119.pdf' target='_blank'>https://arxiv.org/pdf/2407.16119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atul Kumar, Siddharth Garg, Soumya Dutta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16119">Uncertainty-Aware Deep Neural Representations for Visual Analysis of Vector Field Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The widespread use of Deep Neural Networks (DNNs) has recently resulted in their application to challenging scientific visualization tasks. While advanced DNNs demonstrate impressive generalization abilities, understanding factors like prediction quality, confidence, robustness, and uncertainty is crucial. These insights aid application scientists in making informed decisions. However, DNNs lack inherent mechanisms to measure prediction uncertainty, prompting the creation of distinct frameworks for constructing robust uncertainty-aware models tailored to various visualization tasks. In this work, we develop uncertainty-aware implicit neural representations to model steady-state vector fields effectively. We comprehensively evaluate the efficacy of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout, aimed at enabling uncertainty-informed visual analysis of features within steady vector field data. Our detailed exploration using several vector data sets indicate that uncertainty-aware models generate informative visualization results of vector field features. Furthermore, incorporating prediction uncertainty improves the resilience and interpretability of our DNN model, rendering it applicable for the analysis of non-trivial vector field data sets.
<div id='section'>Paperid: <span id='pid'>1221, <a href='https://arxiv.org/pdf/2407.12609.pdf' target='_blank'>https://arxiv.org/pdf/2407.12609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>LuÃ­s Almeida, InÃªs Dutra, Francesco Renna
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12609">Instance-wise Uncertainty for Class Imbalance in Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic segmentation is a fundamental computer vision task with a vast number of applications. State of the art methods increasingly rely on deep learning models, known to incorrectly estimate uncertainty and being overconfident in predictions, especially in data not seen during training. This is particularly problematic in semantic segmentation due to inherent class imbalance. Popular uncertainty quantification approaches are task-agnostic and fail to leverage spatial pixel correlations in uncertainty estimates, crucial in this task. In this work, a novel training methodology specifically designed for semantic segmentation is presented. Training samples are weighted by instance-wise uncertainty masks computed by an ensemble. This is shown to increase performance on minority classes, boost model generalization and robustness to domain-shift when compared to using the inverse of class proportions or no class weights at all. This method addresses the challenges of class imbalance and uncertainty estimation in semantic segmentation, potentially enhancing model performance and reliability across various applications.
<div id='section'>Paperid: <span id='pid'>1222, <a href='https://arxiv.org/pdf/2407.11006.pdf' target='_blank'>https://arxiv.org/pdf/2407.11006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oluyemi Enoch Amujo, Shanchieh Jay Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11006">Evaluating the Efficacy of Foundational Models: Advancing Benchmarking Practices to Enhance Fine-Tuning Decision-Making</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, large language models (LLMs) have expanded into various domains. However, there remains a need to evaluate how these models perform when prompted with commonplace queries compared to domain-specific queries, which may be useful for benchmarking prior to fine-tuning for domain-specific downstream tasks. This study evaluates LLMs, specifically Gemma-2B and Gemma-7B, across diverse domains, including cybersecurity, medicine, and finance, compared to common knowledge queries. This study utilizes a comprehensive methodology to assess foundational models, which includes problem formulation, data analysis, and the development of ThroughCut, a novel outlier detection technique that automatically identifies response throughput outliers based on their conciseness. This methodological rigor enhances the credibility of the presented evaluation frameworks. This study focused on assessing inference time, response length, throughput, quality, and resource utilization and investigated the correlations between these factors. The results indicate that model size and types of prompts used for inference significantly influenced response length and quality. In addition, common prompts, which include various types of queries, generate diverse and inconsistent responses at irregular intervals. In contrast, domain-specific prompts consistently generate concise responses within a reasonable time. Overall, this study underscores the need for comprehensive evaluation frameworks to enhance the reliability of benchmarking procedures in multidomain AI research.
<div id='section'>Paperid: <span id='pid'>1223, <a href='https://arxiv.org/pdf/2407.03791.pdf' target='_blank'>https://arxiv.org/pdf/2407.03791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florian Schneider, Sunayana Sitaram
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03791">M5 -- A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since the release of ChatGPT, the field of Natural Language Processing has experienced rapid advancements, particularly in Large Language Models (LLMs) and their multimodal counterparts, Large Multimodal Models (LMMs). Despite their impressive capabilities, LLMs often exhibit significant performance disparities across different languages and cultural contexts, as demonstrated by various text-only benchmarks. However, current research lacks such benchmarks for multimodal visio-linguistic settings. This work fills this gap by introducing M5, the first comprehensive benchmark designed to evaluate LMMs on diverse vision-language tasks within a multilingual and multicultural context. M5 includes eight datasets covering five tasks and $41$ languages, with a focus on underrepresented languages and culturally diverse images. Furthermore, we introduce two novel datasets, M5-VGR and M5-VLOD, including a new Visio-Linguistic Outlier Detection task, in which all evaluated open-source models fail to significantly surpass the random baseline. Through extensive evaluation and analyses, we highlight substantial task-agnostic performance disparities between high- and low-resource languages. Moreover, we show that larger models do not necessarily outperform smaller ones in a multilingual setting.
<div id='section'>Paperid: <span id='pid'>1224, <a href='https://arxiv.org/pdf/2407.03489.pdf' target='_blank'>https://arxiv.org/pdf/2407.03489.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saandeep Aathreya, Shaun Canavan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03489">FlowCon: Out-of-Distribution Detection using Flow-Based Contrastive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying Out-of-distribution (OOD) data is becoming increasingly critical as the real-world applications of deep learning methods expand. Post-hoc methods modify softmax scores fine-tuned on outlier data or leverage intermediate feature layers to identify distinctive patterns between In-Distribution (ID) and OOD samples. Other methods focus on employing diverse OOD samples to learn discrepancies between ID and OOD. These techniques, however, are typically dependent on the quality of the outlier samples assumed. Density-based methods explicitly model class-conditioned distributions but this requires long training time or retraining the classifier. To tackle these issues, we introduce \textit{FlowCon}, a new density-based OOD detection technique. Our main innovation lies in efficiently combining the properties of normalizing flow with supervised contrastive learning, ensuring robust representation learning with tractable density estimation. Empirical evaluation shows the enhanced performance of our method across common vision datasets such as CIFAR-10 and CIFAR-100 pretrained on ResNet18 and WideResNet classifiers. We also perform quantitative analysis using likelihood plots and qualitative visualization using UMAP embeddings and demonstrate the robustness of the proposed method under various OOD contexts. Code will be open-sourced post decision.
<div id='section'>Paperid: <span id='pid'>1225, <a href='https://arxiv.org/pdf/2407.03140.pdf' target='_blank'>https://arxiv.org/pdf/2407.03140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elizabeth Hou, Ross Greenwood, Piyush Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03140">Machine Learning Models for Improved Tracking from Range-Doppler Map Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Statistical tracking filters depend on accurate target measurements and uncertainty estimates for good tracking performance. In this work, we propose novel machine learning models for target detection and uncertainty estimation in range-Doppler map (RDM) images for Ground Moving Target Indicator (GMTI) radars. We show that by using the outputs of these models, we can significantly improve the performance of a multiple hypothesis tracker for complex multi-target air-to-ground tracking scenarios.
<div id='section'>Paperid: <span id='pid'>1226, <a href='https://arxiv.org/pdf/2407.02926.pdf' target='_blank'>https://arxiv.org/pdf/2407.02926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Victor WÃ¥hlstrand SkÃ¤rstrÃ¶m, Lisa Johansson, Jennifer AlvÃ©n, Mattias Lorentzon, Ida HÃ¤ggstrÃ¶m
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02926">Explainable vertebral fracture analysis with uncertainty estimation using differentiable rule-based classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel method for explainable vertebral fracture assessment (XVFA) in low-dose radiographs using deep neural networks, incorporating vertebra detection and keypoint localization with uncertainty estimates. We incorporate Genant's semi-quantitative criteria as a differentiable rule-based means of classifying both vertebra fracture grade and morphology. Unlike previous work, XVFA provides explainable classifications relatable to current clinical methodology, as well as uncertainty estimations, while at the same time surpassing state-of-the art methods with a vertebra-level sensitivity of 93% and end-to-end AUC of 97% in a challenging setting. Moreover, we compare intra-reader agreement with model uncertainty estimates, with model reliability on par with human annotators.
<div id='section'>Paperid: <span id='pid'>1227, <a href='https://arxiv.org/pdf/2407.02271.pdf' target='_blank'>https://arxiv.org/pdf/2407.02271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hilarie Sit, Brendan Keith, Karianne Bergen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02271">Improving Explainability of Softmax Classifiers Using a Prototype-Based Joint Embedding Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a prototype-based approach for improving explainability of softmax classifiers that provides an understandable prediction confidence, generated through stochastic sampling of prototypes, and demonstrates potential for out of distribution detection (OOD). By modifying the model architecture and training to make predictions using similarities to any set of class examples from the training dataset, we acquire the ability to sample for prototypical examples that contributed to the prediction, which provide an instance-based explanation for the model's decision. Furthermore, by learning relationships between images from the training dataset through relative distances within the model's latent space, we obtain a metric for uncertainty that is better able to detect out of distribution data than softmax confidence.
<div id='section'>Paperid: <span id='pid'>1228, <a href='https://arxiv.org/pdf/2407.00295.pdf' target='_blank'>https://arxiv.org/pdf/2407.00295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geng Li, Di Qiu, Lok Ming Lui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00295">A deep neural network framework for dynamic multi-valued mapping estimation and its applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the problem of modeling and estimating dynamic multi-valued mappings. While most mathematical models provide a unique solution for a given input, real-world applications often lack deterministic solutions. In such scenarios, estimating dynamic multi-valued mappings is necessary to suggest different reasonable solutions for each input. This paper introduces a deep neural network framework incorporating a generative network and a classification component. The objective is to model the dynamic multi-valued mapping between the input and output by providing a reliable uncertainty measurement. Generating multiple solutions for a given input involves utilizing a discrete codebook comprising finite variables. These variables are fed into a generative network along with the input, producing various output possibilities. The discreteness of the codebook enables efficient estimation of the output's conditional probability distribution for any given input using a classifier. By jointly optimizing the discrete codebook and its uncertainty estimation during training using a specially designed loss function, a highly accurate approximation is achieved. The effectiveness of our proposed framework is demonstrated through its application to various imaging problems, using both synthetic and real imaging data. Experimental results show that our framework accurately estimates the dynamic multi-valued mapping with uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1229, <a href='https://arxiv.org/pdf/2406.12915.pdf' target='_blank'>https://arxiv.org/pdf/2406.12915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijin Zhou, Yutang Ge, Xiaowen Dong, Yuguang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12915">How Out-of-Distribution Detection Learning Theory Enhances Transformer: Learnability and Reliability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformers excel in natural language processing and computer vision tasks. However, they still face challenges in generalizing to Out-of-Distribution (OOD) datasets, i.e. data whose distribution differs from that seen during training. OOD detection aims to distinguish outliers while preserving in-distribution (ID) data performance. This paper introduces the OOD detection Probably Approximately Correct (PAC) Theory for transformers, which establishes the conditions for data distribution and model configurations for the OOD detection learnability of transformers. It shows that outliers can be accurately represented and distinguished with sufficient data under conditions. The theoretical implications highlight the trade-off between theoretical principles and practical training paradigms. By examining this trade-off, we naturally derived the rationale for leveraging auxiliary outliers to enhance OOD detection. Our theory suggests that by penalizing the misclassification of outliers within the loss function and strategically generating soft synthetic outliers, one can robustly bolster the reliability of transformer networks. This approach yields a novel algorithm that ensures learnability and refines the decision boundaries between inliers and outliers. In practice, the algorithm consistently achieves state-of-the-art (SOTA) performance across various data formats.
<div id='section'>Paperid: <span id='pid'>1230, <a href='https://arxiv.org/pdf/2406.10686.pdf' target='_blank'>https://arxiv.org/pdf/2406.10686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuang Wu, Arash A. Amini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10686">Graph Neural Thompson Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider an online decision-making problem with a reward function defined over graph-structured data. We formally formulate the problem as an instance of graph action bandit. We then propose \texttt{GNN-TS}, a Graph Neural Network (GNN) powered Thompson Sampling (TS) algorithm which employs a GNN approximator for estimating the mean reward function and the graph neural tangent features for uncertainty estimation. We prove that, under certain boundness assumptions on the reward function, GNN-TS achieves a state-of-the-art regret bound which is (1) sub-linear of order $\tilde{\mathcal{O}}((\tilde{d} T)^{1/2})$ in the number of interaction rounds, $T$, and a notion of effective dimension $\tilde{d}$, and (2) independent of the number of graph nodes. Empirical results validate that our proposed \texttt{GNN-TS} exhibits competitive performance and scales well on graph action bandit problems.
<div id='section'>Paperid: <span id='pid'>1231, <a href='https://arxiv.org/pdf/2406.06946.pdf' target='_blank'>https://arxiv.org/pdf/2406.06946.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeinab Abboud, Herve Lombaert, Samuel Kadoury
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06946">Sparse Bayesian Networks: Efficient Uncertainty Quantification in Medical Image Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficiently quantifying predictive uncertainty in medical images remains a challenge. While Bayesian neural networks (BNN) offer predictive uncertainty, they require substantial computational resources to train. Although Bayesian approximations such as ensembles have shown promise, they still suffer from high training and inference costs. Existing approaches mainly address the costs of BNN inference post-training, with little focus on improving training efficiency and reducing parameter complexity. This study introduces a training procedure for a sparse (partial) Bayesian network. Our method selectively assigns a subset of parameters as Bayesian by assessing their deterministic saliency through gradient sensitivity analysis. The resulting network combines deterministic and Bayesian parameters, exploiting the advantages of both representations to achieve high task-specific performance and minimize predictive uncertainty. Demonstrated on multi-label ChestMNIST for classification and ISIC, LIDC-IDRI for segmentation, our approach achieves competitive performance and predictive uncertainty estimation by reducing Bayesian parameters by over 95\%, significantly reducing computational expenses compared to fully Bayesian and ensemble methods.
<div id='section'>Paperid: <span id='pid'>1232, <a href='https://arxiv.org/pdf/2406.00332.pdf' target='_blank'>https://arxiv.org/pdf/2406.00332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fahimeh Fakour, Ali Mosleh, Ramin Ramezani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00332">A Structured Review of Literature on Uncertainty in Machine Learning & Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The adaptation and use of Machine Learning (ML) in our daily lives has led to concerns in lack of transparency, privacy, reliability, among others. As a result, we are seeing research in niche areas such as interpretability, causality, bias and fairness, and reliability. In this survey paper, we focus on a critical concern for adaptation of ML in risk-sensitive applications, namely understanding and quantifying uncertainty. Our paper approaches this topic in a structured way, providing a review of the literature in the various facets that uncertainty is enveloped in the ML process. We begin by defining uncertainty and its categories (e.g., aleatoric and epistemic), understanding sources of uncertainty (e.g., data and model), and how uncertainty can be assessed in terms of uncertainty quantification techniques (Ensembles, Bayesian Neural Networks, etc.). As part of our assessment and understanding of uncertainty in the ML realm, we cover metrics for uncertainty quantification for a single sample, dataset, and metrics for accuracy of the uncertainty estimation itself. This is followed by discussions on calibration (model and uncertainty), and decision making under uncertainty. Thus, we provide a more complete treatment of uncertainty: from the sources of uncertainty to the decision-making process. We have focused the review of uncertainty quantification methods on Deep Learning (DL), while providing the necessary background for uncertainty discussion within ML in general. Key contributions in this review are broadening the scope of uncertainty discussion, as well as an updated review of uncertainty quantification methods in DL.
<div id='section'>Paperid: <span id='pid'>1233, <a href='https://arxiv.org/pdf/2405.13907.pdf' target='_blank'>https://arxiv.org/pdf/2405.13907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Yang, Chen Chen, Konstantinos Pitas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13907">Just rephrase it! Uncertainty estimation in closed-source language models via multiple rephrased queries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State-of-the-art large language models are sometimes distributed as open-source software but are also increasingly provided as a closed-source service. These closed-source large-language models typically see the widest usage by the public, however, they often do not provide an estimate of their uncertainty when responding to queries. As even the best models are prone to ``hallucinating" false information with high confidence, a lack of a reliable estimate of uncertainty limits the applicability of these models in critical settings. We explore estimating the uncertainty of closed-source LLMs via multiple rephrasings of an original base query. Specifically, we ask the model, multiple rephrased questions, and use the similarity of the answers as an estimate of uncertainty. We diverge from previous work in i) providing rules for rephrasing that are simple to memorize and use in practice ii) proposing a theoretical framework for why multiple rephrased queries obtain calibrated uncertainty estimates. Our method demonstrates significant improvements in the calibration of uncertainty estimates compared to the baseline and provides intuition as to how query strategies should be designed for optimal test calibration.
<div id='section'>Paperid: <span id='pid'>1234, <a href='https://arxiv.org/pdf/2405.13285.pdf' target='_blank'>https://arxiv.org/pdf/2405.13285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Pogorzelski, Peter Arlinghaus, Wenyan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13285">Enhancing Active Learning for Sentinel 2 Imagery through Contrastive Learning and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce a novel method designed to enhance label efficiency in satellite imagery analysis by integrating semi-supervised learning (SSL) with active learning strategies. Our approach utilizes contrastive learning together with uncertainty estimations via Monte Carlo Dropout (MC Dropout), with a particular focus on Sentinel-2 imagery analyzed using the Eurosat dataset. We explore the effectiveness of our method in scenarios featuring both balanced and unbalanced class distributions. Our results show that the proposed method performs better than several other popular methods in this field, enabling significant savings in labeling effort while maintaining high classification accuracy. These findings highlight the potential of our approach to facilitate scalable and cost-effective satellite image analysis, particularly advantageous for extensive environmental monitoring and land use classification tasks.
<div id='section'>Paperid: <span id='pid'>1235, <a href='https://arxiv.org/pdf/2405.11816.pdf' target='_blank'>https://arxiv.org/pdf/2405.11816.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anastasios Foliadis, Mario H. CastaÃ±eda, Richard A. Stirling-Gallacher, Reiner S. ThomÃ¤
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11816">Transfer Learning for CSI-based Positioning with Multi-environment Meta-learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Utilizing deep learning (DL) techniques for radio-based positioning of user equipment (UE) through channel state information (CSI) fingerprints has demonstrated significant potential. DL models can extract complex characteristics from the CSI fingerprints of a particular environment and accurately predict the position of a UE. Nonetheless, the effectiveness of the DL model trained on CSI fingerprints is highly dependent on the particular training environment, limiting the trained model's applicability across different environments. This paper proposes a novel DL model structure consisting of two parts, where the first part aims at identifying features that are independent from any specific environment, while the second part combines those features in an environment specific way with the goal of positioning. To train such a two-part model, we propose the multi-environment meta-learning (MEML) approach for the first part to facilitate training across various environments, while the second part of the model is trained solely on data from a specific environment. Our findings indicate that employing the MEML approach for initializing the weights of the DL model for a new unseen environment significantly boosts the accuracy of UE positioning in the new target environment as well the reliability of its uncertainty estimation. This method outperforms traditional transfer learning methods, whether direct transfer learning (DTL) between environments or completely training from scratch with data from a new environment. The proposed approach is verified with real measurements for both line-of-sight (LOS) and non-LOS (NLOS) environments.
<div id='section'>Paperid: <span id='pid'>1236, <a href='https://arxiv.org/pdf/2405.06293.pdf' target='_blank'>https://arxiv.org/pdf/2405.06293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>V. Kisielius, E. Illarionov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06293">Machine learning for reconstruction of polarity inversion lines from solar filaments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solar filaments are well-known tracers of polarity inversion lines that separate two opposite magnetic polarities on the solar photosphere. Because observations of filaments began long before the systematic observations of solar magnetic fields, historical filament catalogs can facilitate the reconstruction of magnetic polarity maps at times when direct magnetic observations were not yet available. In practice, this reconstruction is often ambiguous and typically performed manually. We propose an automatic approach based on a machine-learning model that generates a variety of magnetic polarity maps consistent with filament observations. To evaluate the model and discuss the results we use the catalog of solar filaments and polarity maps compiled by McIntosh. We realize that the process of manual compilation of polarity maps includes not only information on filaments, but also a large amount of prior information, which is difficult to formalize. In order to compensate for the lack of prior knowledge for the machine-learning model, we provide it with polarity information at several reference points. We demonstrate that this process, which can be considered as the user-guided reconstruction or super-resolution, leads to polarity maps that are reasonably close to hand-drawn ones, and additionally allows for uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1237, <a href='https://arxiv.org/pdf/2405.04759.pdf' target='_blank'>https://arxiv.org/pdf/2405.04759.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihan Mei, Xinyu Wang, Dell Zhang, Xiaoling Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.04759">Multi-Label Out-of-Distribution Detection with Spectral Normalized Joint Energy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In today's interconnected world, achieving reliable out-of-distribution (OOD) detection poses a significant challenge for machine learning models. While numerous studies have introduced improved approaches for multi-class OOD detection tasks, the investigation into multi-label OOD detection tasks has been notably limited. We introduce Spectral Normalized Joint Energy (SNoJoE), a method that consolidates label-specific information across multiple labels through the theoretically justified concept of an energy-based function. Throughout the training process, we employ spectral normalization to manage the model's feature space, thereby enhancing model efficacy and generalization, in addition to bolstering robustness. Our findings indicate that the application of spectral normalization to joint energy scores notably amplifies the model's capability for OOD detection. We perform OOD detection experiments utilizing PASCAL-VOC as the in-distribution dataset and ImageNet-22K or Texture as the out-of-distribution datasets. Our experimental results reveal that, in comparison to prior top performances, SNoJoE achieves 11% and 54% relative reductions in FPR95 on the respective OOD datasets, thereby defining the new state of the art in this field of study.
<div id='section'>Paperid: <span id='pid'>1238, <a href='https://arxiv.org/pdf/2405.02917.pdf' target='_blank'>https://arxiv.org/pdf/2405.02917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tobias Groot, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02917">Overconfidence is Key: Verbalized Uncertainty Evaluation in Large Language and Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language and Vision-Language Models (LLMs/VLMs) have revolutionized the field of AI by their ability to generate human-like text and understand images, but ensuring their reliability is crucial. This paper aims to evaluate the ability of LLMs (GPT4, GPT-3.5, LLaMA2, and PaLM 2) and VLMs (GPT4V and Gemini Pro Vision) to estimate their verbalized uncertainty via prompting. We propose the new Japanese Uncertain Scenes (JUS) dataset, aimed at testing VLM capabilities via difficult queries and object counting, and the Net Calibration Error (NCE) to measure direction of miscalibration. Results show that both LLMs and VLMs have a high calibration error and are overconfident most of the time, indicating a poor capability for uncertainty estimation. Additionally we develop prompts for regression tasks, and we show that VLMs have poor calibration when producing mean/standard deviation and 95% confidence intervals.
<div id='section'>Paperid: <span id='pid'>1239, <a href='https://arxiv.org/pdf/2404.17023.pdf' target='_blank'>https://arxiv.org/pdf/2404.17023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mojtaba Abolfazli, Mohammad Zaeri Amirani, Anders HÃ¸st-Madsen, June Zhang, Andras Bratincsak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17023">Out-of-Distribution Detection using Maximum Entropy Coding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given a default distribution $P$ and a set of test data $x^M=\{x_1,x_2,\ldots,x_M\}$ this paper seeks to answer the question if it was likely that $x^M$ was generated by $P$. For discrete distributions, the definitive answer is in principle given by Kolmogorov-Martin-LÃ¶f randomness. In this paper we seek to generalize this to continuous distributions. We consider a set of statistics $T_1(x^M),T_2(x^M),\ldots$. To each statistic we associate its maximum entropy distribution and with this a universal source coder. The maximum entropy distributions are subsequently combined to give a total codelength, which is compared with $-\log P(x^M)$. We show that this approach satisfied a number of theoretical properties.
  For real world data $P$ usually is unknown. We transform data into a standard distribution in the latent space using a bidirectional generate network and use maximum entropy coding there. We compare the resulting method to other methods that also used generative neural networks to detect anomalies. In most cases, our results show better performance.
<div id='section'>Paperid: <span id='pid'>1240, <a href='https://arxiv.org/pdf/2404.11929.pdf' target='_blank'>https://arxiv.org/pdf/2404.11929.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Walid Abdullah Al, Il Dong Yun, Yun Jung Bae
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.11929">A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease With Enhanced Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dopamine transporter (DAT) imaging is commonly used for monitoring Parkinson's disease (PD), where striatal DAT uptake amount is computed to assess PD severity. However, DAT imaging has a high cost and the risk of radiance exposure and is not available in general clinics. Recently, MRI patch of the nigral region has been proposed as a safer and easier alternative. This paper proposes a symmetric regressor for predicting the DAT uptake amount from the nigral MRI patch. Acknowledging the symmetry between the right and left nigrae, the proposed regressor incorporates a paired input-output model that simultaneously predicts the DAT uptake amounts for both the right and left striata. Moreover, it employs a symmetric loss that imposes a constraint on the difference between right-to-left predictions, resembling the high correlation in DAT uptake amounts in the two lateral sides. Additionally, we propose a symmetric Monte-Carlo (MC) dropout method for providing a fruitful uncertainty estimate of the DAT uptake prediction, which utilizes the above symmetry. We evaluated the proposed approach on 734 nigral patches, which demonstrated significantly improved performance of the symmetric regressor compared with the standard regressors while giving better explainability and feature representation. The symmetric MC dropout also gave precise uncertainty ranges with a high probability of including the true DAT uptake amounts within the range.
<div id='section'>Paperid: <span id='pid'>1241, <a href='https://arxiv.org/pdf/2404.09821.pdf' target='_blank'>https://arxiv.org/pdf/2404.09821.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuri Kinoshita, Taro Toyoizumi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.09821">A provable control of sensitivity of neural networks through a direct parameterization of the overall bi-Lipschitzness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While neural networks can enjoy an outstanding flexibility and exhibit unprecedented performance, the mechanism behind their behavior is still not well-understood. To tackle this fundamental challenge, researchers have tried to restrict and manipulate some of their properties in order to gain new insights and better control on them. Especially, throughout the past few years, the concept of \emph{bi-Lipschitzness} has been proved as a beneficial inductive bias in many areas. However, due to its complexity, the design and control of bi-Lipschitz architectures are falling behind, and a model that is precisely designed for bi-Lipschitzness realizing a direct and simple control of the constants along with solid theoretical analysis is lacking. In this work, we investigate and propose a novel framework for bi-Lipschitzness that can achieve such a clear and tight control based on convex neural networks and the Legendre-Fenchel duality. Its desirable properties are illustrated with concrete experiments. We also apply this framework to uncertainty estimation and monotone problem settings to illustrate its broad range of applications.
<div id='section'>Paperid: <span id='pid'>1242, <a href='https://arxiv.org/pdf/2404.06198.pdf' target='_blank'>https://arxiv.org/pdf/2404.06198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Claudia Ehrig, Benedikt Sonnleitner, Ursula Neumann, Catherine Cleophas, Germain Forestier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06198">The impact of data set similarity and diversity on transfer learning success in time series forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained models have become pivotal in enhancing the efficiency and accuracy of time series forecasting on target data sets by leveraging transfer learning. While benchmarks validate the performance of model generalization on various target data sets, there is no structured research providing similarity and diversity measures to explain which characteristics of source and target data lead to transfer learning success. Our study pioneers in systematically evaluating the impact of source-target similarity and source diversity on zero-shot and fine-tuned forecasting outcomes in terms of accuracy, bias, and uncertainty estimation. We investigate these dynamics using pre-trained neural networks across five public source datasets, applied to forecasting five target data sets, including real-world wholesales data. We identify two feature-based similarity and diversity measures, finding that source-target similarity reduces forecasting bias, while source diversity improves forecasting accuracy and uncertainty estimation, but increases the bias.
<div id='section'>Paperid: <span id='pid'>1243, <a href='https://arxiv.org/pdf/2403.19826.pdf' target='_blank'>https://arxiv.org/pdf/2403.19826.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qitian Ma, Shyam Nanda Rai, Carlo Masone, Tatiana Tommasi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.19826">Segmentation Re-thinking Uncertainty Estimation Metrics for Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the domain of computer vision, semantic segmentation emerges as a fundamental application within machine learning, wherein individual pixels of an image are classified into distinct semantic categories. This task transcends traditional accuracy metrics by incorporating uncertainty quantification, a critical measure for assessing the reliability of each segmentation prediction. Such quantification is instrumental in facilitating informed decision-making, particularly in applications where precision is paramount. Within this nuanced framework, the metric known as PAvPU (Patch Accuracy versus Patch Uncertainty) has been developed as a specialized tool for evaluating entropy-based uncertainty in image segmentation tasks. However, our investigation identifies three core deficiencies within the PAvPU framework and proposes robust solutions aimed at refining the metric. By addressing these issues, we aim to enhance the reliability and applicability of uncertainty quantification, especially in scenarios that demand high levels of safety and accuracy, thus contributing to the advancement of semantic segmentation methodologies in critical applications.
<div id='section'>Paperid: <span id='pid'>1244, <a href='https://arxiv.org/pdf/2403.08652.pdf' target='_blank'>https://arxiv.org/pdf/2403.08652.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Ardis, Arjuna Flenner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08652">Extracting Explanations, Justification, and Uncertainty from Black-Box Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Neural Networks (DNNs) do not inherently compute or exhibit empirically-justified task confidence. In mission critical applications, it is important to both understand associated DNN reasoning and its supporting evidence. In this paper, we propose a novel Bayesian approach to extract explanations, justifications, and uncertainty estimates from DNNs. Our approach is efficient both in terms of memory and computation, and can be applied to any black box DNN without any retraining, including applications to anomaly detection and out-of-distribution detection tasks. We validate our approach on the CIFAR-10 dataset, and show that it can significantly improve the interpretability and reliability of DNNs.
<div id='section'>Paperid: <span id='pid'>1245, <a href='https://arxiv.org/pdf/2403.06874.pdf' target='_blank'>https://arxiv.org/pdf/2403.06874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>L. E. Hogeweg, R. Gangireddy, D. Brunink, V. J. Kalkman, L. Cornelissen, J. W. Kamminga
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06874">COOD: Combined out-of-distribution detection using multiple measures for anomaly & novel class detection in large-scale hierarchical classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-performing out-of-distribution (OOD) detection, both anomaly and novel class, is an important prerequisite for the practical use of classification models. In this paper, we focus on the species recognition task in images concerned with large databases, a large number of fine-grained hierarchical classes, severe class imbalance, and varying image quality. We propose a framework for combining individual OOD measures into one combined OOD (COOD) measure using a supervised model. The individual measures are several existing state-of-the-art measures and several novel OOD measures developed with novel class detection and hierarchical class structure in mind. COOD was extensively evaluated on three large-scale (500k+ images) biodiversity datasets in the context of anomaly and novel class detection. We show that COOD outperforms individual, including state-of-the-art, OOD measures by a large margin in terms of TPR@1% FPR in the majority of experiments, e.g., improving detecting ImageNet images (OOD) from 54.3% to 85.4% for the iNaturalist 2018 dataset. SHAP (feature contribution) analysis shows that different individual OOD measures are essential for various tasks, indicating that multiple OOD measures and combinations are needed to generalize. Additionally, we show that explicitly considering ID images that are incorrectly classified for the original (species) recognition task is important for constructing high-performing OOD detection methods and for practical applicability. The framework can easily be extended or adapted to other tasks and media modalities.
<div id='section'>Paperid: <span id='pid'>1246, <a href='https://arxiv.org/pdf/2402.18960.pdf' target='_blank'>https://arxiv.org/pdf/2402.18960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jennie Karlsson, Marisa Wodrich, Niels Christian Overgaard, Freja Sahlin, Kristina LÃ¥ng, Anders Heyden, Ida Arvidsson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18960">Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has shown to have great potential in medical applications. In critical domains as such, it is of high interest to have trustworthy algorithms which are able to tell when reliable assessments cannot be guaranteed. Detecting out-of-distribution (OOD) samples is a crucial step towards building a safe classifier. Following a previous study, showing that it is possible to classify breast cancer in point-of-care ultrasound images, this study investigates OOD detection using three different methods: softmax, energy score and deep ensembles. All methods are tested on three different OOD data sets. The results show that the energy score method outperforms the softmax method, performing well on two of the data sets. The ensemble method is the most robust, performing the best at detecting OOD samples for all three OOD data sets.
<div id='section'>Paperid: <span id='pid'>1247, <a href='https://arxiv.org/pdf/2402.15143.pdf' target='_blank'>https://arxiv.org/pdf/2402.15143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shota Sugawara, Ryuji Imamura
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.15143">PUAD: Frustratingly Simple Method for Robust Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing an accurate and fast anomaly detection model is an important task in real-time computer vision applications. There has been much research to develop a single model that detects either structural or logical anomalies, which are inherently distinct. The majority of the existing approaches implicitly assume that the anomaly can be represented by identifying the anomalous location. However, we argue that logical anomalies, such as the wrong number of objects, can not be well-represented by the spatial feature maps and require an alternative approach. In addition, we focused on the possibility of detecting logical anomalies by using an out-of-distribution detection approach on the feature space, which aggregates the spatial information of the feature map. As a demonstration, we propose a method that incorporates a simple out-of-distribution detection method on the feature space against state-of-the-art reconstruction-based approaches. Despite the simplicity of our proposal, our method PUAD (Picturable and Unpicturable Anomaly Detection) achieves state-of-the-art performance on the MVTec LOCO AD dataset.
<div id='section'>Paperid: <span id='pid'>1248, <a href='https://arxiv.org/pdf/2402.06937.pdf' target='_blank'>https://arxiv.org/pdf/2402.06937.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masoumeh Javanbakhat, Md Tasnimul Hasan, Cristoph Lippert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06937">Assessing Uncertainty Estimation Methods for 3D Image Segmentation under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, machine learning has witnessed extensive adoption across various sectors, yet its application in medical image-based disease detection and diagnosis remains challenging due to distribution shifts in real-world data. In practical settings, deployed models encounter samples that differ significantly from the training dataset, especially in the health domain, leading to potential performance issues. This limitation hinders the expressiveness and reliability of deep learning models in health applications. Thus, it becomes crucial to identify methods capable of producing reliable uncertainty estimation in the context of distribution shifts in the health sector. In this paper, we explore the feasibility of using cutting-edge Bayesian and non-Bayesian methods to detect distributionally shifted samples, aiming to achieve reliable and trustworthy diagnostic predictions in segmentation task. Specifically, we compare three distinct uncertainty estimation methods, each designed to capture either unimodal or multimodal aspects in the posterior distribution. Our findings demonstrate that methods capable of addressing multimodal characteristics in the posterior distribution, offer more dependable uncertainty estimates. This research contributes to enhancing the utility of deep learning in healthcare, making diagnostic predictions more robust and trustworthy.
<div id='section'>Paperid: <span id='pid'>1249, <a href='https://arxiv.org/pdf/2401.17814.pdf' target='_blank'>https://arxiv.org/pdf/2401.17814.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Laurens P. Stoop, Erik Duijm, Ad J. Feelders, Machteld van den Broek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.17814">Detection of Critical Events in Renewable Energy Production Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The introduction of more renewable energy sources into the energy system increases the variability and weather dependence of electricity generation. Power system simulations are used to assess the adequacy and reliability of the electricity grid over decades, but often become computational intractable for such long simulation periods with high technical detail. To alleviate this computational burden, we investigate the use of outlier detection algorithms to find periods of extreme renewable energy generation which enables detailed modelling of the performance of power systems under these circumstances. Specifically, we apply the Maximum Divergent Intervals (MDI) algorithm to power generation time series that have been derived from ERA5 historical climate reanalysis covering the period from 1950 through 2019. By applying the MDI algorithm on these time series, we identified intervals of extreme low and high energy production. To determine the outlierness of an interval different divergence measures can be used. Where the cross-entropy measure results in shorter and strongly peaking outliers, the unbiased Kullback-Leibler divergence tends to detect longer and more persistent intervals. These intervals are regarded as potential risks for the electricity grid by domain experts, showcasing the capability of the MDI algorithm to detect critical events in these time series. For the historical period analysed, we found no trend in outlier intensity, or shift and lengthening of the outliers that could be attributed to climate change. By applying MDI on climate model output, power system modellers can investigate the adequacy and possible changes of risk for the current and future electricity grid under a wider range of scenarios.
<div id='section'>Paperid: <span id='pid'>1250, <a href='https://arxiv.org/pdf/2401.17013.pdf' target='_blank'>https://arxiv.org/pdf/2401.17013.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jens Henriksson, Christian Berger, Stig Ursing, Markus Borg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.17013">Evaluation of Out-of-Distribution Detection Performance on Autonomous Driving Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safety measures need to be systemically investigated to what extent they evaluate the intended performance of Deep Neural Networks (DNNs) for critical applications. Due to a lack of verification methods for high-dimensional DNNs, a trade-off is needed between accepted performance and handling of out-of-distribution (OOD) samples.
  This work evaluates rejecting outputs from semantic segmentation DNNs by applying a Mahalanobis distance (MD) based on the most probable class-conditional Gaussian distribution for the predicted class as an OOD score. The evaluation follows three DNNs trained on the Cityscapes dataset and tested on four automotive datasets and finds that classification risk can drastically be reduced at the cost of pixel coverage, even when applied on unseen datasets. The applicability of our findings will support legitimizing safety measures and motivate their usage when arguing for safe usage of DNNs in automotive perception.
<div id='section'>Paperid: <span id='pid'>1251, <a href='https://arxiv.org/pdf/2401.05594.pdf' target='_blank'>https://arxiv.org/pdf/2401.05594.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prakash Mallick, Feras Dayoub, Jamie Sherrah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05594">Wasserstein Distance-based Expansion of Low-Density Latent Regions for Unknown Class Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the significant challenge in open-set object detection (OSOD): the tendency of state-of-the-art detectors to erroneously classify unknown objects as known categories with high confidence. We present a novel approach that effectively identifies unknown objects by distinguishing between high and low-density regions in latent space. Our method builds upon the Open-Det (OD) framework, introducing two new elements to the loss function. These elements enhance the known embedding space's clustering and expand the unknown space's low-density regions. The first addition is the Class Wasserstein Anchor (CWA), a new function that refines the classification boundaries. The second is a spectral normalisation step, improving the robustness of the model. Together, these augmentations to the existing Contrastive Feature Learner (CFL) and Unknown Probability Learner (UPL) loss functions significantly improve OSOD performance. Our proposed OpenDet-CWA (OD-CWA) method demonstrates: a) a reduction in open-set errors by approximately 17%-22%, b) an enhancement in novelty detection capability by 1.5%-16%, and c) a decrease in the wilderness index by 2%-20% across various open-set scenarios. These results represent a substantial advancement in the field, showcasing the potential of our approach in managing the complexities of open-set object detection.
<div id='section'>Paperid: <span id='pid'>1252, <a href='https://arxiv.org/pdf/2401.04144.pdf' target='_blank'>https://arxiv.org/pdf/2401.04144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sankalp Gilda, Neel Bhandari, Wendy Mak, Andrea Panizza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04144">Robust Calibration For Improved Weather Prediction Under Distributional Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present results on improving out-of-domain weather prediction and uncertainty estimation as part of the \texttt{Shifts Challenge on Robustness and Uncertainty under Real-World Distributional Shift} challenge. We find that by leveraging a mixture of experts in conjunction with an advanced data augmentation technique borrowed from the computer vision domain, in conjunction with robust \textit{post-hoc} calibration of predictive uncertainties, we can potentially achieve more accurate and better-calibrated results with deep neural networks than with boosted tree models for tabular data. We quantify our predictions using several metrics and propose several future lines of inquiry and experimentation to boost performance.
<div id='section'>Paperid: <span id='pid'>1253, <a href='https://arxiv.org/pdf/2401.00773.pdf' target='_blank'>https://arxiv.org/pdf/2401.00773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongwook Kim, Juyeon Park, Hee Cheol Chung, Seonghyun Jeong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00773">Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Probabilistic mixture models are recognized as effective tools for unsupervised outlier detection owing to their interpretability and global characteristics. Among these, Dirichlet process mixture models stand out as a strong alternative to conventional finite mixture models for both clustering and outlier detection tasks. Unlike finite mixture models, Dirichlet process mixtures are infinite mixture models that automatically determine the number of mixture components based on the data. Despite their advantages, the adoption of Dirichlet process mixture models for unsupervised outlier detection has been limited by challenges related to computational inefficiency and sensitivity to outliers in the construction of outlier detectors. Additionally, Dirichlet process Gaussian mixtures struggle to effectively model non-Gaussian data with discrete or binary features. To address these challenges, we propose a novel outlier detection method that utilizes ensembles of Dirichlet process Gaussian mixtures. This unsupervised algorithm employs random subspace and subsampling ensembles to ensure efficient computation and improve the robustness of the outlier detector. The ensemble approach further improves the suitability of the proposed method for detecting outliers in non-Gaussian data. Furthermore, our method uses variational inference for Dirichlet process mixtures, which ensures both efficient and rapid computation. Empirical analyses using benchmark datasets demonstrate that our method outperforms existing approaches in unsupervised outlier detection.
<div id='section'>Paperid: <span id='pid'>1254, <a href='https://arxiv.org/pdf/2512.22199.pdf' target='_blank'>https://arxiv.org/pdf/2512.22199.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Teja Chinthala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.22199">Bidirectional RAG: Safe Self-Improving Retrieval-Augmented Generation Through Multi-Stage Validation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Retrieval-Augmented Generation RAG systems enhance large language models by grounding responses in external knowledge bases, but conventional RAG architectures operate with static corpora that cannot evolve from user interactions. We introduce Bidirectional RAG, a novel RAG architecture that enables safe corpus expansion through validated write back of high quality generated responses. Our system employs a multi stage acceptance layer combining grounding verification (NLI based entailment, attribution checking, and novelty detection to prevent hallucination pollution while enabling knowledge accumulation. Across four datasets Natural Questions, TriviaQA, HotpotQA, Stack Overflow with three random seeds 12 experiments per system, Bidirectional RAG achieves 40.58% average coverage nearly doubling Standard RAG 20.33% while adding 72% fewer documents than naive write back 140 vs 500. Our work demonstrates that self improving RAG is feasible and safe when governed by rigorous validation, offering a practical path toward RAG systems that learn from deployment.
<div id='section'>Paperid: <span id='pid'>1255, <a href='https://arxiv.org/pdf/2512.14739.pdf' target='_blank'>https://arxiv.org/pdf/2512.14739.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jahidul Arafat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.14739">How Deep Does Your Dependency Tree Go? An Empirical Study of Dependency Amplification Across 10 Package Ecosystems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern software development relies on package ecosystems where a single declared dependency can pull in many additional transitive packages. This dependency amplification, defined as the ratio of transitive to direct dependencies, has major implications for software supply chain security, yet amplification patterns across ecosystems have not been compared at scale. We present an empirical study of 500 projects across ten major ecosystems, including Maven Central for Java, npm Registry for JavaScript, crates io for Rust, PyPI for Python, NuGet Gallery for dot NET, RubyGems for Ruby, Go Modules for Go, Packagist for PHP, CocoaPods for Swift and Objective C, and Pub for Dart. Our analysis shows that Maven exhibits mean amplification of 24.70 times, compared to 4.48 times for Go Modules, 4.32 times for npm, and 0.32 times for CocoaPods. We find significant differences with large effect sizes in 22 of 45 pairwise comparisons, challenging the assumption that npm has the highest amplification due to its many small purpose packages. We observe that 28 percent of Maven projects exceed 10 times amplification, indicating a systematic pattern rather than isolated outliers, compared to 14 percent for RubyGems, 12 percent for npm, and zero percent for Cargo, PyPI, Packagist, CocoaPods, and Pub. We attribute these differences to ecosystem design choices such as dependency resolution behavior, standard library completeness, and platform constraints. Our findings suggest adopting ecosystem specific security strategies, including systematic auditing for Maven environments, targeted outlier detection for npm and RubyGems, and continuation of current practices for ecosystems with controlled amplification. We provide a full replication package with data and analysis scripts.
<div id='section'>Paperid: <span id='pid'>1256, <a href='https://arxiv.org/pdf/2512.05306.pdf' target='_blank'>https://arxiv.org/pdf/2512.05306.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Y. Sungtaek Ju
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2512.05306">Uncertainty Quantification for Scientific Machine Learning using Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KAN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kolmogorov-Arnold Networks have emerged as interpretable alternatives to traditional multi-layer perceptrons. However, standard implementations lack principled uncertainty quantification capabilities essential for many scientific applications. We present a framework integrating sparse variational Gaussian process inference with the Kolmogorov-Arnold topology, enabling scalable Bayesian inference with computational complexity quasi-linear in sample size. Through analytic moment matching, we propagate uncertainty through deep additive structures while maintaining interpretability. We use three example studies to demonstrate the framework's ability to distinguish aleatoric from epistemic uncertainty: calibration of heteroscedastic measurement noise in fluid flow reconstruction, quantification of prediction confidence degradation in multi-step forecasting of advection-diffusion dynamics, and out-of-distribution detection in convolutional autoencoders. These results suggest Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KANs) is a promising architecture for uncertainty-aware learning in scientific machine learning.
<div id='section'>Paperid: <span id='pid'>1257, <a href='https://arxiv.org/pdf/2511.15741.pdf' target='_blank'>https://arxiv.org/pdf/2511.15741.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyo-Jeong Jang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.15741">Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.
<div id='section'>Paperid: <span id='pid'>1258, <a href='https://arxiv.org/pdf/2511.15005.pdf' target='_blank'>https://arxiv.org/pdf/2511.15005.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moses Kiprono
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.15005">Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.
<div id='section'>Paperid: <span id='pid'>1259, <a href='https://arxiv.org/pdf/2511.05529.pdf' target='_blank'>https://arxiv.org/pdf/2511.05529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jophy Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2511.05529">Selective Diabetic Retinopathy Screening with Accuracy-Weighted Deep Ensembles and Entropy-Guided Abstention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diabetic retinopathy (DR), a microvascular complication of diabetes and a leading cause of preventable blindness, is projected to affect more than 130 million individuals worldwide by 2030. Early identification is essential to reduce irreversible vision loss, yet current diagnostic workflows rely on methods such as fundus photography and expert review, which remain costly and resource-intensive. This, combined with DR's asymptomatic nature, results in its underdiagnosis rate of approximately 25 percent. Although convolutional neural networks (CNNs) have demonstrated strong performance in medical imaging tasks, limited interpretability and the absence of uncertainty quantification restrict clinical reliability. Therefore, in this study, a deep ensemble learning framework integrated with uncertainty estimation is introduced to improve robustness, transparency, and scalability in DR detection. The ensemble incorporates seven CNN architectures-ResNet-50, DenseNet-121, MobileNetV3 (Small and Large), and EfficientNet (B0, B2, B3)- whose outputs are fused through an accuracy-weighted majority voting strategy. A probability-weighted entropy metric quantifies prediction uncertainty, enabling low-confidence samples to be excluded or flagged for additional review. Training and validation on 35,000 EyePACS retinal fundus images produced an unfiltered accuracy of 93.70 percent (F1 = 0.9376). Uncertainty-filtering later was conducted to remove unconfident samples, resulting in maximum-accuracy of 99.44 percent (F1 = 0.9932). The framework shows that uncertainty-aware, accuracy-weighted ensembling improves reliability without hindering performance. With confidence-calibrated outputs and a tunable accuracy-coverage trade-off, it offers a generalizable paradigm for deploying trustworthy AI diagnostics in high-risk care.
<div id='section'>Paperid: <span id='pid'>1260, <a href='https://arxiv.org/pdf/2510.24043.pdf' target='_blank'>https://arxiv.org/pdf/2510.24043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akira Tamamori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.24043">Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection framework that overcomes the coexisting limitations of conventional projection-based methods: their reliance on a fixed statistical metric and their assumption of a single data structure. Our framework uniquely synthesizes three key concepts: (1) a generalized loss-based outlyingness measure (PLO) that replaces the fixed metric with flexible, adaptive loss functions like our proposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear data structures; and (3) a subsequent local clustering stage to handle multi-modal distributions. Comprehensive 5-fold cross-validation experiments on 10 benchmark datasets, with automated hyperparameter optimization, demonstrate that Two-Stage LKPLO achieves state-of-the-art performance. It significantly outperforms strong baselines on datasets with challenging structures where existing methods fail, most notably on multi-cluster data (Optdigits) and complex, high-dimensional data (Arrhythmia). Furthermore, an ablation study empirically confirms that the synergistic combination of both the kernelization and localization stages is indispensable for its superior performance. This work contributes a powerful new tool for a significant class of outlier detection problems and underscores the importance of hybrid, multi-stage architectures.
<div id='section'>Paperid: <span id='pid'>1261, <a href='https://arxiv.org/pdf/2510.15422.pdf' target='_blank'>https://arxiv.org/pdf/2510.15422.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.15422">Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open world Machine Learning (OWML) aims to develop intelligent systems capable of recognizing known categories, rejecting unknown samples, and continually learning from novel information. Despite significant progress in open set recognition, novelty detection, and continual learning, the field still lacks a unified theoretical foundation that can quantify uncertainty, characterize information transfer, and explain learning adaptability in dynamic, nonstationary environments. This paper presents a comprehensive review of information theoretic approaches in open world machine learning, emphasizing how core concepts such as entropy, mutual information, and Kullback Leibler divergence provide a mathematical language for describing knowledge acquisition, uncertainty suppression, and risk control under open world conditions. We synthesize recent studies into three major research axes: information theoretic open set recognition enabling safe rejection of unknowns, information driven novelty discovery guiding new concept formation, and information retentive continual learning ensuring stable long term adaptation. Furthermore, we discuss theoretical connections between information theory and provable learning frameworks, including PAC Bayes bounds, open-space risk theory, and causal information flow, to establish a pathway toward provable and trustworthy open world intelligence. Finally, the review identifies key open problems and future research directions, such as the quantification of information risk, development of dynamic mutual information bounds, multimodal information fusion, and integration of information theory with causal reasoning and world model learning.
<div id='section'>Paperid: <span id='pid'>1262, <a href='https://arxiv.org/pdf/2509.18132.pdf' target='_blank'>https://arxiv.org/pdf/2509.18132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiuyi Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18132">Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty is a fundamental challenge in medical practice, but current medical AI systems fail to explicitly quantify or communicate uncertainty in a way that aligns with clinical reasoning. Existing XAI works focus on interpreting model predictions but do not capture the confidence or reliability of these predictions. Conversely, uncertainty estimation (UE) techniques provide confidence measures but lack intuitive explanations. The disconnect between these two areas limits AI adoption in medicine. To address this gap, we propose Explainable Uncertainty Estimation (XUE) that integrates explainability with uncertainty quantification to enhance trust and usability in medical AI. We systematically map medical uncertainty to AI uncertainty concepts and identify key challenges in implementing XUE. We outline technical directions for advancing XUE, including multimodal uncertainty quantification, model-agnostic visualization techniques, and uncertainty-aware decision support systems. Lastly, we propose guiding principles to ensure effective XUE realisation. Our analysis highlights the need for AI systems that not only generate reliable predictions but also articulate confidence levels in a clinically meaningful way. This work contributes to the development of trustworthy medical AI by bridging explainability and uncertainty, paving the way for AI systems that are aligned with real-world clinical complexities.
<div id='section'>Paperid: <span id='pid'>1263, <a href='https://arxiv.org/pdf/2509.10048.pdf' target='_blank'>https://arxiv.org/pdf/2509.10048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Madhushan Ramalingam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10048">Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictive models are being increasingly used across a wide range of domains, including safety-critical applications such as medical diagnosis and criminal justice. Reliable uncertainty estimation is a crucial task in such settings. Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine learning foundation model for tabular dataset, which uses a generative transformer architecture. Variational Bayesian Last Layers (VBLL) is a state-of-the-art lightweight variational formulation that effectively improves uncertainty estimation with minimal computational overhead. In this work we aim to evaluate the performance of VBLL integrated with the recently proposed TabPFN in uncertainty calibration. Our experiments, conducted on three benchmark medical tabular datasets, compare the performance of the original TabPFN and the VBLL-integrated version. Contrary to expectations, we observed that original TabPFN consistently outperforms VBLL integrated TabPFN in uncertainty calibration across all datasets.
<div id='section'>Paperid: <span id='pid'>1264, <a href='https://arxiv.org/pdf/2509.06902.pdf' target='_blank'>https://arxiv.org/pdf/2509.06902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aivin V. Solatorio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06902">Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) as stochastic systems may generate numbers that deviate from available data, a failure known as \emph{numeric hallucination}. Existing safeguards -- retrieval-augmented generation, citations, and uncertainty estimation -- improve transparency but cannot guarantee fidelity: fabricated or misquoted values may still be displayed as if correct. We propose \textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that enforces numeric fidelity through mechanical verification. Under PCN, numeric spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a verifier checks each token under a declared policy (e.g., exact equality, rounding, aliases, or tolerance with qualifiers). Crucially, PCN places verification in the \emph{renderer}, not the model: only claim-checked numbers are marked as verified, and all others default to unverified. This separation prevents spoofing and guarantees fail-closed behavior. We formalize PCN and prove soundness, completeness under honest tokens, fail-closed behavior, and monotonicity under policy refinement. PCN is lightweight and model-agnostic, integrates seamlessly into existing applications, and can be extended with cryptographic commitments. By enforcing verification as a mandatory step before display, PCN establishes a simple contract for numerically sensitive settings: \emph{trust is earned only by proof}, while the absence of a mark communicates uncertainty.
<div id='section'>Paperid: <span id='pid'>1265, <a href='https://arxiv.org/pdf/2508.21463.pdf' target='_blank'>https://arxiv.org/pdf/2508.21463.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Rakotoarivony
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21463">Multi-Method Ensemble for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is essential for neural networks operating in open-world settings, particularly in safety-critical applications. Existing methods have improved OOD detection by leveraging two main techniques: feature truncation, which increases the separation between in-distribution (ID) and OOD samples, and scoring functions, which assign scores to distinguish between ID and OOD data. However, most approaches either focus on a single family of techniques or evaluate their effectiveness on a specific type of OOD dataset, overlooking the potential of combining multiple existing solutions. Motivated by this observation, we theoretically and empirically demonstrate that state-of-the-art feature truncation and scoring functions can be effectively combined. Moreover, we show that aggregating multiple scoring functions enhances robustness against various types of OOD samples. Based on these insights, we propose the Multi-Method Ensemble (MME) score, which unifies state-of-the-art OOD detectors into a single, more effective scoring function. Extensive experiments on both large-scale and small-scale benchmarks, covering near-OOD and far-OOD scenarios, show that MME significantly outperforms recent state-of-the-art methods across all benchmarks. Notably, using the BiT model, our method achieves an average FPR95 of 27.57% on the challenging ImageNet-1K benchmark, improving performance by 6% over the best existing baseline.
<div id='section'>Paperid: <span id='pid'>1266, <a href='https://arxiv.org/pdf/2508.18001.pdf' target='_blank'>https://arxiv.org/pdf/2508.18001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian G. Gruber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18001">A Novel Framework for Uncertainty Quantification via Proper Scores for Classification and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this PhD thesis, we propose a novel framework for uncertainty quantification in machine learning, which is based on proper scores. Uncertainty quantification is an important cornerstone for trustworthy and reliable machine learning applications in practice. Usually, approaches to uncertainty quantification are problem-specific, and solutions and insights cannot be readily transferred from one task to another. Proper scores are loss functions minimized by predicting the target distribution. Due to their very general definition, proper scores apply to regression, classification, or even generative modeling tasks. We contribute several theoretical results, that connect epistemic uncertainty, aleatoric uncertainty, and model calibration with proper scores, resulting in a general and widely applicable framework. We achieve this by introducing a general bias-variance decomposition for strictly proper scores via functional Bregman divergences. Specifically, we use the kernel score, a kernel-based proper score, for evaluating sample-based generative models in various domains, like image, audio, and natural language generation. This includes a novel approach for uncertainty estimation of large language models, which outperforms state-of-the-art baselines. Further, we generalize the calibration-sharpness decomposition beyond classification, which motivates the definition of proper calibration errors. We then introduce a novel estimator for proper calibration errors in classification, and a novel risk-based approach to compare different estimators for squared calibration errors. Last, we offer a decomposition of the kernel spherical score, another kernel-based proper score, allowing a more fine-grained and interpretable evaluation of generative image models.
<div id='section'>Paperid: <span id='pid'>1267, <a href='https://arxiv.org/pdf/2508.15019.pdf' target='_blank'>https://arxiv.org/pdf/2508.15019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos Stein Brito
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15019">Twin-Boot: Uncertainty-Aware Optimization via Online Two-Sample Bootstrapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard gradient descent methods yield point estimates with no measure of confidence. This limitation is acute in overparameterized and low-data regimes, where models have many parameters relative to available data and can easily overfit. Bootstrapping is a classical statistical framework for uncertainty estimation based on resampling, but naively applying it to deep learning is impractical: it requires training many replicas, produces post-hoc estimates that cannot guide learning, and implicitly assumes comparable optima across runs - an assumption that fails in non-convex landscapes. We introduce Twin-Bootstrap Gradient Descent (Twin-Boot), a resampling-based training procedure that integrates uncertainty estimation into optimization. Two identical models are trained in parallel on independent bootstrap samples, and a periodic mean-reset keeps both trajectories in the same basin so that their divergence reflects local (within-basin) uncertainty. During training, we use this estimate to sample weights in an adaptive, data-driven way, providing regularization that favors flatter solutions. In deep neural networks and complex high-dimensional inverse problems, the approach improves calibration and generalization and yields interpretable uncertainty maps.
<div id='section'>Paperid: <span id='pid'>1268, <a href='https://arxiv.org/pdf/2508.13121.pdf' target='_blank'>https://arxiv.org/pdf/2508.13121.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos Celemin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13121">Bayesian Optimization-based Search for Agent Control in Automated Game Testing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces an automated testing approach that employs agents controlling game characters to detect potential bugs within a game level. Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient search, the method determines the next sampling point by analyzing the data collected so far and calculates the data point that will maximize information acquisition. To support the BO process, we introduce a game testing-specific model built on top of a grid map, that features the smoothness and uncertainty estimation required by BO, however and most importantly, it does not suffer the scalability issues that traditional models carry. The experiments demonstrate that the approach significantly improves map coverage capabilities in both time efficiency and exploration distribution.
<div id='section'>Paperid: <span id='pid'>1269, <a href='https://arxiv.org/pdf/2508.07948.pdf' target='_blank'>https://arxiv.org/pdf/2508.07948.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>John D. Mayfield
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07948">Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Progressive neurodegenerative diseases, including Alzheimer's disease (AD), multiple sclerosis (MS), Parkinson's disease (PD), and amyotrophic lateral sclerosis (ALS), exhibit complex, nonlinear trajectories that challenge deterministic modeling. Traditional time-domain analyses of multiomic and neuroimaging data often fail to capture hidden oscillatory patterns, limiting predictive accuracy. We propose a theoretical mathematical framework that transforms time-series data into frequency or s-domain using Fourier and Laplace transforms, models neuronal dynamics via Hamiltonian formulations, and employs quantum-classical hybrid computing with variational quantum eigensolvers (VQE) for enhanced pattern detection. This theoretical construct serves as a foundation for future empirical works in quantum-enhanced analysis of neurodegenerative diseases. We extend this to quaternionic representations with three imaginary axes ($i, j, k$) to model multistate Hamiltonians in multifaceted disorders, drawing from quantum neuromorphic computing to capture entangled neural dynamics \citep{Pehle2020, Emani2019}. This approach leverages quantum advantages in handling high-dimensional amplitude-phase data, enabling outlier detection and frequency signature analysis. Potential clinical applications include identifying high-risk patients with rapid progression or therapy resistance using s-domain biomarkers, supported by quantum machine learning (QML) precedents achieving up to 99.89% accuracy in Alzheimer's classification \citep{Belay2024, Bhowmik2025}. This framework aims to lay the groundwork for redefining precision medicine for neurodegenerative diseases through future validations.
<div id='section'>Paperid: <span id='pid'>1270, <a href='https://arxiv.org/pdf/2508.07556.pdf' target='_blank'>https://arxiv.org/pdf/2508.07556.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stephan Rabanser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07556">Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) systems are increasingly deployed in high-stakes domains where reliability is paramount. This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, focusing on selective prediction -- where models abstain when confidence is low. We first show that a model's training trajectory contains rich uncertainty signals that can be exploited without altering its architecture or loss. By ensembling predictions from intermediate checkpoints, we propose a lightweight, post-hoc abstention method that works across tasks, avoids the cost of deep ensembles, and achieves state-of-the-art selective prediction performance. Crucially, this approach is fully compatible with differential privacy (DP), allowing us to study how privacy noise affects uncertainty quality. We find that while many methods degrade under DP, our trajectory-based approach remains robust, and we introduce a framework for isolating the privacy-uncertainty trade-off. Next, we then develop a finite-sample decomposition of the selective classification gap -- the deviation from the oracle accuracy-coverage curve -- identifying five interpretable error sources and clarifying which interventions can close the gap. This explains why calibration alone cannot fix ranking errors, motivating methods that improve uncertainty ordering. Finally, we show that uncertainty signals can be adversarially manipulated to hide errors or deny service while maintaining high accuracy, and we design defenses combining calibration audits with verifiable inference. Together, these contributions advance reliable ML by improving, evaluating, and safeguarding uncertainty estimation, enabling models that not only make accurate predictions -- but also know when to say "I do not know".
<div id='section'>Paperid: <span id='pid'>1271, <a href='https://arxiv.org/pdf/2508.03720.pdf' target='_blank'>https://arxiv.org/pdf/2508.03720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmet GÃ¶khan Poyraz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03720">Outlier Detection Algorithm for Circle Fitting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Circle fitting methods are extensively utilized in various industries, particularly in quality control processes and design applications. The effectiveness of these algorithms can be significantly compromised when the point sets to be predicted are noisy. To mitigate this issue, outlier detection and removal algorithms are often applied before the circle fitting procedure. This study introduces the Polar Coordinate-Based Outlier Detection (PCOD) algorithm, which can be effectively employed in circle fitting applications. In the proposed approach, the point set is first transformed into polar coordinates, followed by the calculation of both local and global standard deviations. Outliers are then identified by comparing local mean values with the global standard deviation. The practicality and efficiency of the proposed method are demonstrated by focusing on the high-precision diameter measurement of industrial washer parts. Images from a machine vision system are processed through preprocessing steps, including sub-pixel edge detection. The resulting sub-pixel edge points are then cleaned using the proposed outlier detection and removal algorithm, after which circle fitting is performed. A comparison is made using ten different circle fitting algorithms and five distinct outlier detection methods. The results indicate that the proposed method outperforms the other approaches, delivering the best performance in terms of accuracy within the dataset, thereby demonstrating its potential for enhancing circle fitting applications in industrial environments.
<div id='section'>Paperid: <span id='pid'>1272, <a href='https://arxiv.org/pdf/2507.22915.pdf' target='_blank'>https://arxiv.org/pdf/2507.22915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Esmail Gumaan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22915">Theoretical Foundations and Mitigation of Hallucination in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hallucination in Large Language Models (LLMs) refers to the generation of content that is not faithful to the input or the real-world facts. This paper provides a rigorous treatment of hallucination in LLMs, including formal definitions and theoretical analyses. We distinguish between intrinsic and extrinsic hallucinations, and define a \textit{hallucination risk} for models. We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes and Rademacher complexity). We then survey detection strategies for hallucinations, such as token-level uncertainty estimation, confidence calibration, and attention alignment checks. On the mitigation side, we discuss approaches including retrieval-augmented generation, hallucination-aware fine-tuning, logit calibration, and the incorporation of fact-verification modules. We propose a unified detection and mitigation workflow, illustrated with a diagram, to integrate these strategies. Finally, we outline evaluation protocols for hallucination, recommending datasets, metrics, and experimental setups to quantify and reduce hallucinations. Our work lays a theoretical foundation and practical guidelines for addressing the crucial challenge of hallucination in LLMs.
<div id='section'>Paperid: <span id='pid'>1273, <a href='https://arxiv.org/pdf/2507.21203.pdf' target='_blank'>https://arxiv.org/pdf/2507.21203.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcello D'Orazio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21203">An empirical comparison of some outlier detection methods with longitudinal data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This note investigates the problem of detecting outliers in longitudinal data. It compares well-known methods used in official statistics with proposals from the fields of data mining and machine learning that are based on the distance between observations or binary partitioning trees. This is achieved by applying the methods to panel survey data related to different types of statistical units. Traditional methods are quite simple, enabling the direct identification of potential outliers, but they require specific assumptions. In contrast, recent methods provide only a score whose magnitude is directly related to the likelihood of an outlier being present. All the methods require the user to set a number of tuning parameters. However, the most recent methods are more flexible and sometimes more effective than traditional methods. In addition, these methods can be applied to multidimensional data.
<div id='section'>Paperid: <span id='pid'>1274, <a href='https://arxiv.org/pdf/2507.14960.pdf' target='_blank'>https://arxiv.org/pdf/2507.14960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Letteri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14960">A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of outliers within cryptocurrency limit order books (LOBs) is of paramount importance for comprehending market dynamics, particularly in highly volatile and nascent regulatory environments. This study conducts a comprehensive comparative analysis of robust statistical methods and advanced machine learning techniques for real-time anomaly identification in cryptocurrency LOBs. Within a unified testing environment, named AITA Order Book Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to identify which approaches are most suitable for detecting potentially manipulative trading behaviours. An empirical evaluation, conducted via backtesting on a dataset of 26,204 records from a major exchange, demonstrates that the top-performing model, Empirical Covariance (EC), achieves a 6.70% gain, significantly outperforming a standard Buy-and-Hold benchmark. These findings underscore the effectiveness of outlier-driven strategies and provide insights into the trade-offs between model complexity, trade frequency, and performance. This study contributes to the growing corpus of research on cryptocurrency market microstructure by furnishing a rigorous benchmark of anomaly detection models and highlighting their potential for augmenting algorithmic trading and risk management.
<div id='section'>Paperid: <span id='pid'>1275, <a href='https://arxiv.org/pdf/2507.06269.pdf' target='_blank'>https://arxiv.org/pdf/2507.06269.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rushil Desai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06269">BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate surface estimation is critical for downstream tasks in scientific simulation, and quantifying uncertainty in implicit neural 3D representations still remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. However, current neural implicit surface models do not offer a principled way to quantify uncertainty, limiting their reliability in real-world applications. Inspired by recent probabilistic rendering approaches, we introduce BayesSDF, a novel probabilistic framework for uncertainty estimation in neural implicit 3D representations. Unlike radiance-based models such as Neural Radiance Fields (NeRF) or 3D Gaussian Splatting, Signed Distance Functions (SDFs) provide continuous, differentiable surface representations, making them especially well-suited for uncertainty-aware modeling. BayesSDF applies a Laplace approximation over SDF weights and derives Hessian-based metrics to estimate local geometric instability. We empirically demonstrate that these uncertainty estimates correlate strongly with surface reconstruction error across both synthetic and real-world benchmarks. By enabling surface-aware uncertainty quantification, BayesSDF lays the groundwork for more robust, interpretable, and actionable 3D perception systems.
<div id='section'>Paperid: <span id='pid'>1276, <a href='https://arxiv.org/pdf/2506.22809.pdf' target='_blank'>https://arxiv.org/pdf/2506.22809.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cooper Doyle
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22809">Low-rank variational dropout: Uncertainty and rank selection in adapters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parameter-efficient fine-tuning (PEFT) methods such as LoRA adapt large language models by inserting low-rank adapters, but they leave open two key questions: how to give the adapted model calibrated uncertainty, and how to choose the adapter rank. Existing approaches to uncertainty are typically post-hoc, while rank selection is manual and task-specific. BayesLoRA revisits variational dropout in the LoRA setting and shows that the natural unit of stochasticity is not individual weights but entire ranks of the adapter. By placing rank-wise variational distributions over adapter components, BayesLoRA defines a posterior that (i) yields calibrated predictions through adapter-only Monte Carlo sampling and (ii) prunes redundant ranks automatically via an ARD-style KL term. Theoretical analysis shows that this rank-parameterized posterior localizes uncertainty to the adapted subspace and explains amplification under distribution shift. Empirically, BayesLoRA improves calibration while at the same time producing lighter, faster adapters, removing the need to tune ranks by hand. This dual role of uncertainty estimation and uncertainty-driven pruning suggests BayesLoRA may offer a practical default for reliable and efficient PEFT.
<div id='section'>Paperid: <span id='pid'>1277, <a href='https://arxiv.org/pdf/2506.13828.pdf' target='_blank'>https://arxiv.org/pdf/2506.13828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdullah Burkan Bereketoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13828">Hybrid Meta-Learning Framework for Anomaly Forecasting in Nonlinear Dynamical Systems via Physics-Inspired Simulation and Deep Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a hybrid meta-learning framework for forecasting and anomaly detection in nonlinear dynamical systems characterized by nonstationary and stochastic behavior. The approach integrates a physics-inspired simulator that captures nonlinear growth-relaxation dynamics with random perturbations, representative of many complex physical, industrial, and cyber-physical systems. We use CNN-LSTM architectures for spatio-temporal feature extraction, Variational Autoencoders (VAE) for unsupervised anomaly scoring, and Isolation Forests for residual-based outlier detection in addition to a Dual-Stage Attention Recurrent Neural Network (DA-RNN) for one-step forecasting on top of the generated simulation data. To create composite anomaly forecasts, these models are combined using a meta-learner that combines forecasting outputs, reconstruction errors, and residual scores. The hybrid ensemble performs better than standalone models in anomaly localization, generalization, and robustness to nonlinear deviations, according to simulation-based experiments. The framework provides a broad, data-driven approach to early defect identification and predictive monitoring in nonlinear systems, which may be applied to a variety of scenarios where complete physical models might not be accessible.
<div id='section'>Paperid: <span id='pid'>1278, <a href='https://arxiv.org/pdf/2505.12061.pdf' target='_blank'>https://arxiv.org/pdf/2505.12061.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel T. M. Ball
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12061">Bayesian Deep Learning Approaches for Uncertainty-Aware Retinal OCT Image Segmentation for Multiple Sclerosis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optical Coherence Tomography (OCT) provides valuable insights in ophthalmology, cardiology, and neurology due to high-resolution, cross-sectional images of the retina. One critical task for ophthalmologists using OCT is delineation of retinal layers within scans. This process is time-consuming and prone to human bias, affecting the accuracy and reliability of diagnoses. Previous efforts to automate delineation using deep learning face challenges in uptake from clinicians and statisticians due to the absence of uncertainty estimation, leading to "confidently wrong" models via hallucinations. In this study, we address these challenges by applying Bayesian convolutional neural networks (BCNNs) to segment an openly available OCT imaging dataset containing 35 human retina OCTs split between healthy controls and patients with multiple sclerosis. Our findings demonstrate that Bayesian models can be used to provide uncertainty maps of the segmentation, which can further be used to identify highly uncertain samples that exhibit recording artefacts such as noise or miscalibration at inference time. Our method also allows for uncertainty-estimation for important secondary measurements such as layer thicknesses, that are medically relevant for patients. We show that these features come in addition to greater performance compared to similar work over all delineations; with an overall Dice score of 95.65%. Our work brings greater clinical applicability, statistical robustness, and performance to retinal OCT segmentation.
<div id='section'>Paperid: <span id='pid'>1279, <a href='https://arxiv.org/pdf/2505.07528.pdf' target='_blank'>https://arxiv.org/pdf/2505.07528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07528">SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Retrieval-Augmented Generation (RAG) models frequently encounter hallucination phenomena when integrating external information with internal parametric knowledge. Empirical studies demonstrate that the disequilibrium between external contextual information and internal parametric knowledge constitutes a primary factor in hallucination generation. Existing hallucination detection methodologies predominantly emphasize either the external or internal mechanism in isolation, thereby overlooking their synergistic effects. The recently proposed ReDeEP framework decouples these dual mechanisms, identifying two critical contributors to hallucinations: excessive reliance on parametric knowledge encoded in feed-forward networks (FFN) and insufficient utilization of external information by attention mechanisms (particularly copy heads). ReDeEP quantitatively assesses these factors to detect hallucinations and dynamically modulates the contributions of FFNs and copy heads to attenuate their occurrence. Nevertheless, ReDeEP and numerous other hallucination detection approaches have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, inadequately address the semantic dimensions of model responses, resulting in inconsistent hallucination assessments in RAG implementations. Building upon ReDeEP's foundation, this paper introduces SEReDeEP, which enhances computational processes through semantic entropy captured via trained linear probes, thereby achieving hallucination assessments that more accurately reflect ground truth evaluations.
<div id='section'>Paperid: <span id='pid'>1280, <a href='https://arxiv.org/pdf/2504.18650.pdf' target='_blank'>https://arxiv.org/pdf/2504.18650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bruce Collins
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18650">Unsupervised outlier detection to improve bird audio dataset labels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Xeno-Canto bird audio repository is an invaluable resource for those interested in vocalizations and other sounds made by birds around the world. This is particularly the case for machine learning researchers attempting to improve on the bird species recognition accuracy of classification models. However, the task of extracting labeled datasets from the recordings found in this crowd-sourced repository faces several challenges. One challenge of particular significance to machine learning practitioners is that one bird species label is applied to each audio recording, but frequently other sounds are also captured including other bird species, other animal sounds, anthropogenic and other ambient sounds. These non-target bird species sounds can result in dataset labeling discrepancies referred to as label noise. In this work we present a cleaning process consisting of audio preprocessing followed by dimensionality reduction and unsupervised outlier detection (UOD) to reduce the label noise in a dataset derived from Xeno-Canto recordings. We investigate three neural network dimensionality reduction techniques: two flavors of convolutional autoencoders and variational deep embedding (VaDE (Jiang, 2017)). While both methods show some degree of effectiveness at detecting outliers for most bird species datasets, we found significant variation in the performance of the methods from one species to the next. We believe that the results of this investigation demonstrate that the application of our cleaning process can meaningfully reduce the label noise of bird species datasets derived from Xeno-Canto audio repository but results vary across species.
<div id='section'>Paperid: <span id='pid'>1281, <a href='https://arxiv.org/pdf/2504.15562.pdf' target='_blank'>https://arxiv.org/pdf/2504.15562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dip Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15562">Bayesian Autoencoder for Medical Anomaly Detection: Uncertainty-Aware Approach for Brain 2 MRI Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In medical imaging, anomaly detection is a vital element of healthcare diagnostics, especially for neurological conditions which can be life-threatening. Conventional deterministic methods often fall short when it comes to capturing the inherent uncertainty of anomaly detection tasks. This paper introduces a Bayesian Variational Autoencoder (VAE) equipped with multi-head attention mechanisms for detecting anomalies in brain magnetic resonance imaging (MRI). For the purpose of improving anomaly detection performance, we incorporate both epistemic and aleatoric uncertainty estimation through Bayesian inference. The model was tested on the BraTS2020 dataset, and the findings were a 0.83 ROC AUC and a 0.83 PR AUC. The data in our paper suggests that modeling uncertainty is an essential component of anomaly detection, enhancing both performance and interpretability and providing confidence estimates, as well as anomaly predictions, for clinicians to leverage in making medical decisions.
<div id='section'>Paperid: <span id='pid'>1282, <a href='https://arxiv.org/pdf/2504.14372.pdf' target='_blank'>https://arxiv.org/pdf/2504.14372.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Marie Antonio Minoza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.14372">Learning Enhanced Structural Representations with Block-Based Uncertainties for Ocean Floor Mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate ocean modeling and coastal hazard prediction depend on high-resolution bathymetric data; yet, current worldwide datasets are too coarse for exact numerical simulations. While recent deep learning advances have improved earth observation data resolution, existing methods struggle with the unique challenges of producing detailed ocean floor maps, especially in maintaining physical structure consistency and quantifying uncertainties. This work presents a novel uncertainty-aware mechanism using spatial blocks to efficiently capture local bathymetric complexity based on block-based conformal prediction. Using the Vector Quantized Variational Autoencoder (VQ-VAE) architecture, the integration of this uncertainty quantification framework yields spatially adaptive confidence estimates while preserving topographical features via discrete latent representations. With smaller uncertainty widths in well-characterized areas and appropriately larger bounds in areas of complex seafloor structures, the block-based design adapts uncertainty estimates to local bathymetric complexity. Compared to conventional techniques, experimental results over several ocean regions show notable increases in both reconstruction quality and uncertainty estimation reliability. This framework increases the reliability of bathymetric reconstructions by preserving structural integrity while offering spatially adaptive uncertainty estimates, so opening the path for more solid climate modeling and coastal hazard assessment.
<div id='section'>Paperid: <span id='pid'>1283, <a href='https://arxiv.org/pdf/2504.02432.pdf' target='_blank'>https://arxiv.org/pdf/2504.02432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aidan Tiruvan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02432">Robust Randomized Low-Rank Approximation with Row-Wise Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robust low-rank approximation under row-wise adversarial corruption can be achieved with a single pass, randomized procedure that detects and removes outlier rows by thresholding their projected norms. We propose a scalable, non-iterative algorithm that efficiently recovers the underlying low-rank structure in the presence of row-wise adversarial corruption. By first compressing the data with a Johnson Lindenstrauss projection, our approach preserves the geometry of clean rows while dramatically reducing dimensionality. Robust statistical techniques based on the median and median absolute deviation then enable precise identification and removal of outlier rows with abnormally high norms. The subsequent rank-k approximation achieves near-optimal error bounds with a one pass procedure that scales linearly with the number of observations. Empirical results confirm that combining random sketches with robust statistics yields efficient, accurate decompositions even in the presence of large fractions of corrupted rows.
<div id='section'>Paperid: <span id='pid'>1284, <a href='https://arxiv.org/pdf/2503.22714.pdf' target='_blank'>https://arxiv.org/pdf/2503.22714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergio Torres Aguilar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22714">TRIDIS: A Comprehensive Medieval and Early Modern Corpus for HTR and NER</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces TRIDIS (Tria Digita Scribunt), an open-source corpus of medieval and early modern manuscripts. TRIDIS aggregates multiple legacy collections (all published under open licenses) and incorporates large metadata descriptions. While prior publications referenced some portions of this corpus, here we provide a unified overview with a stronger focus on its constitution. We describe (i) the narrative, chronological, and editorial background of each major sub-corpus, (ii) its semi-diplomatic transcription rules (expansion, normalization, punctuation), (iii) a strategy for challenging out-of-domain test splits driven by outlier detection in a joint embedding space, and (iv) preliminary baseline experiments using TrOCR and MiniCPM2.5 comparing random and outlier-based test partitions. Overall, TRIDIS is designed to stimulate joint robust Handwritten Text Recognition (HTR) and Named Entity Recognition (NER) research across medieval and early modern textual heritage.
<div id='section'>Paperid: <span id='pid'>1285, <a href='https://arxiv.org/pdf/2503.12354.pdf' target='_blank'>https://arxiv.org/pdf/2503.12354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Farhad Pourkamali-Anaraki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.12354">Probabilistic Neural Networks (PNNs) with t-Distributed Outputs: Adaptive Prediction Intervals Beyond Gaussian Assumptions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional neural network regression models provide only point estimates, failing to capture predictive uncertainty. Probabilistic neural networks (PNNs) address this limitation by producing output distributions, enabling the construction of prediction intervals. However, the common assumption of Gaussian output distributions often results in overly wide intervals, particularly in the presence of outliers or deviations from normality. To enhance the adaptability of PNNs, we propose t-Distributed Neural Networks (TDistNNs), which generate t-distributed outputs, parameterized by location, scale, and degrees of freedom. The degrees of freedom parameter allows TDistNNs to model heavy-tailed predictive distributions, improving robustness to non-Gaussian data and enabling more adaptive uncertainty quantification. We develop a novel loss function tailored for the t-distribution and derive efficient gradient computations for seamless integration into deep learning frameworks. Empirical evaluations on synthetic and real-world data demonstrate that TDistNNs improve the balance between coverage and interval width. Notably, for identical architectures, TDistNNs consistently produce narrower prediction intervals than Gaussian-based PNNs while maintaining proper coverage. This work contributes a flexible framework for uncertainty estimation in neural networks tasked with regression, particularly suited to settings involving complex output distributions.
<div id='section'>Paperid: <span id='pid'>1286, <a href='https://arxiv.org/pdf/2502.15648.pdf' target='_blank'>https://arxiv.org/pdf/2502.15648.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Raina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15648">Logit Disagreement: OoD Detection with Bayesian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian neural networks (BNNs), which estimate the full posterior distribution over model parameters, are well-known for their role in uncertainty quantification and its promising application in out-of-distribution detection (OoD). Amongst other uncertainty measures, BNNs provide a state-of-the art estimation of predictive entropy (total uncertainty) which can be decomposed as the sum of mutual information and expected entropy. In the context of OoD detection the estimation of predictive uncertainty in the form of the predictive entropy score confounds aleatoric and epistemic uncertainty, the latter being hypothesized to be high for OoD points. Despite these justifications, the mutual information score has been shown to perform worse than predictive entropy. Taking inspiration from Bayesian variational autoencoder (BVAE) literature, this work proposes to measure the disagreement between a corrected version of the pre-softmax quantities, otherwise known as logits, as an estimate of epistemic uncertainty for Bayesian NNs under mean field variational inference. The three proposed epistemic uncertainty scores demonstrate marked improvements over mutual information on a range of OoD experiments, with equal performance otherwise. Moreover, the epistemic uncertainty scores perform on par with the Bayesian benchmark predictive entropy on a range of MNIST and CIFAR10 experiments.
<div id='section'>Paperid: <span id='pid'>1287, <a href='https://arxiv.org/pdf/2502.07425.pdf' target='_blank'>https://arxiv.org/pdf/2502.07425.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keon Vin Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07425">Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws into neural network training. However, traditional PINN models are typically designed for single PDEs, limiting their generalizability across different physical systems. In this work, we explore the potential of a foundation PINN model capable of solving multiple PDEs within a unified architecture. We investigate the efficacy of a single PINN framework trained on four distinct PDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D Wave Equation, and the 2D Laplace Equation, demonstrating its ability to learn diverse physical dynamics.
  To enhance sample efficiency, we incorporate Active Learning (AL) using Monte Carlo (MC) Dropout-based uncertainty estimation, selecting the most informative training samples iteratively. We evaluate different active learning strategies, comparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset, and analyze their impact on solution accuracy. Our results indicate that targeted uncertainty sampling significantly improves performance with fewer training samples, leading to efficient learning across multiple PDEs.
  This work highlights the feasibility of a generalizable PINN-based foundation model, capable of adapting to different physics-based problems without redesigning network architectures. Our findings suggest that multi-PDE PINNs with active learning can serve as an effective approach for reducing computational costs while maintaining high accuracy in physics-based deep learning applications.
<div id='section'>Paperid: <span id='pid'>1288, <a href='https://arxiv.org/pdf/2502.05496.pdf' target='_blank'>https://arxiv.org/pdf/2502.05496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05496">Feature Explosion: a generic optimization strategy for outlier detection algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection tasks aim at discovering potential issues or opportunities and are widely used in cybersecurity, financial security, industrial inspection, etc. To date, thousands of outlier detection algorithms have been proposed. Clearly, in real-world scenarios, such a large number of algorithms is unnecessary. In other words, a large number of outlier detection algorithms are redundant. We believe the root cause of this redundancy lies in the current highly customized (i.e., non-generic) optimization strategies. Specifically, when researchers seek to improve the performance of existing outlier detection algorithms, they have to design separate optimized versions tailored to the principles of each algorithm, leading to an ever-growing number of outlier detection algorithms. To address this issue, in this paper, we introduce the explosion from physics into the outlier detection task and propose a generic optimization strategy based on feature explosion, called OSD (Optimization Strategy for outlier Detection algorithms). In the future, when improving the performance of existing outlier detection algorithms, it will be sufficient to invoke the OSD plugin without the need to design customized optimized versions for them. We compared the performances of 14 outlier detection algorithms on 24 datasets before and after invoking the OSD plugin. The experimental results show that the performances of all outlier detection algorithms are improved on almost all datasets. In terms of average accuracy, OSD make these outlier detection algorithms improve by 15% (AUC), 63.7% (AP).
<div id='section'>Paperid: <span id='pid'>1289, <a href='https://arxiv.org/pdf/2412.07520.pdf' target='_blank'>https://arxiv.org/pdf/2412.07520.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Koby Bibas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07520">Quantifying the Prediction Uncertainty of Machine Learning Models for Individual Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models have exhibited exceptional results in various domains. The most prevalent approach for learning is the empirical risk minimizer (ERM), which adapts the model's weights to reduce the loss on a training set and subsequently leverages these weights to predict the label for new test data. Nonetheless, ERM makes the assumption that the test distribution is similar to the training distribution, which may not always hold in real-world situations. In contrast, the predictive normalized maximum likelihood (pNML) was proposed as a min-max solution for the individual setting where no assumptions are made on the distribution of the tested input. This study investigates pNML's learnability for linear regression and neural networks, and demonstrates that pNML can improve the performance and robustness of these models on various tasks. Moreover, the pNML provides an accurate confidence measure for its output, showcasing state-of-the-art results for out-of-distribution detection, resistance to adversarial attacks, and active learning.
<div id='section'>Paperid: <span id='pid'>1290, <a href='https://arxiv.org/pdf/2412.03592.pdf' target='_blank'>https://arxiv.org/pdf/2412.03592.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harsh Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03592">Using Images to Find Context-Independent Word Representations in Vector Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many methods have been proposed to find vector representation for words, but most rely on capturing context from the text to find semantic relationships between these vectors. We propose a novel method of using dictionary meanings and image depictions to find word vectors independent of any context. We use auto-encoder on the word images to find meaningful representations and use them to calculate the word vectors. We finally evaluate our method on word similarity, concept categorization and outlier detection tasks. Our method performs comparably to context-based methods while taking much less training time.
<div id='section'>Paperid: <span id='pid'>1291, <a href='https://arxiv.org/pdf/2411.16457.pdf' target='_blank'>https://arxiv.org/pdf/2411.16457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoming Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16457">Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a novel trajectory prediction model for autonomous driving, combining a Characterized Diffusion Module and a Spatial-Temporal Interaction Network to address the challenges posed by dynamic and heterogeneous traffic environments. Our model enhances the accuracy and reliability of trajectory predictions by incorporating uncertainty estimation and complex agent interactions. Through extensive experimentation on public datasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms existing state-of-the-art methods. We demonstrate its ability to capture the underlying spatial-temporal dynamics of traffic scenarios and improve prediction precision, especially in complex environments. The proposed model showcases strong potential for application in real-world autonomous driving systems.
<div id='section'>Paperid: <span id='pid'>1292, <a href='https://arxiv.org/pdf/2410.00408.pdf' target='_blank'>https://arxiv.org/pdf/2410.00408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahamudul Hasan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00408">ECORS: An Ensembled Clustering Approach to Eradicate The Local And Global Outlier In Collaborative Filtering Recommender System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recommender systems are designed to suggest items based on user preferences, helping users navigate the vast amount of information available on the internet. Given the overwhelming content, outlier detection has emerged as a key research area in recommender systems. It involves identifying unusual or suspicious patterns in user behavior. However, existing studies in this field face several challenges, including the limited universality of algorithms, difficulties in selecting users, and a lack of optimization. In this paper, we propose an approach that addresses these challenges by employing various clustering algorithms. Specifically, we utilize a user-user matrix-based clustering technique to detect outliers. By constructing a user-user matrix, we can identify suspicious users in the system. Both local and global outliers are detected to ensure comprehensive analysis. Our experimental results demonstrate that this approach significantly improves the accuracy of outlier detection in recommender systems.
<div id='section'>Paperid: <span id='pid'>1293, <a href='https://arxiv.org/pdf/2409.13984.pdf' target='_blank'>https://arxiv.org/pdf/2409.13984.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geonuk Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13984">Cycle-Consistency Uncertainty Estimation for Visual Prompting based One-Shot Defect Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Industrial defect detection traditionally relies on supervised learning models trained on fixed datasets of known defect types. While effective within a closed set, these models struggle with new, unseen defects, necessitating frequent re-labeling and re-training. Recent advances in visual prompting offer a solution by allowing models to adaptively infer novel categories based on provided visual cues. However, a prevalent issue in these methods is the over-confdence problem, where models can mis-classify unknown objects as known objects with high certainty. To addresssing the fundamental concerns about the adaptability, we propose a solution to estimate uncertainty of the visual prompting process by cycle-consistency. We designed to check whether it can accurately restore the original prompt from its predictions. To quantify this, we measure the mean Intersection over Union (mIoU) between the restored prompt mask and the originally provided prompt mask. Without using complex designs or ensemble methods with multiple networks, our approach achieved a yield rate of 0.9175 in the VISION24 one-shot industrial challenge.
<div id='section'>Paperid: <span id='pid'>1294, <a href='https://arxiv.org/pdf/2409.02628.pdf' target='_blank'>https://arxiv.org/pdf/2409.02628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andreas Kirsch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02628">(Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in Large Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Epistemic uncertainty is crucial for safety-critical applications and data acquisition tasks. Yet, we find an important phenomenon in deep learning models: an epistemic uncertainty collapse as model complexity increases, challenging the assumption that larger models invariably offer better uncertainty quantification. We introduce implicit ensembling as a possible explanation for this phenomenon. To investigate this hypothesis, we provide theoretical analysis and experiments that demonstrate uncertainty collapse in explicit ensembles of ensembles and show experimental evidence of similar collapse in wider models across various architectures, from simple MLPs to state-of-the-art vision models including ResNets and Vision Transformers. We further develop implicit ensemble extraction techniques to decompose larger models into diverse sub-models, showing we can thus recover epistemic uncertainty. We explore the implications of these findings for uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1295, <a href='https://arxiv.org/pdf/2409.01154.pdf' target='_blank'>https://arxiv.org/pdf/2409.01154.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Morris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01154">Forecasting infectious disease prevalence with associated uncertainty using neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Infectious diseases pose significant human and economic burdens. Accurately forecasting disease incidence can enable public health agencies to respond effectively to existing or emerging diseases. Despite progress in the field, developing accurate forecasting models remains a significant challenge. This thesis proposes two methodological frameworks using neural networks (NNs) with associated uncertainty estimates - a critical component limiting the application of NNs to epidemic forecasting thus far. We develop our frameworks by forecasting influenza-like illness (ILI) in the United States. Our first proposed method uses Web search activity data in conjunction with historical ILI rates as observations for training NN architectures. Our models incorporate Bayesian layers to produce uncertainty intervals, positioning themselves as legitimate alternatives to more conventional approaches. The best performing architecture: iterative recurrent neural network (IRNN), reduces mean absolute error by 10.3% and improves Skill by 17.1% on average in forecasting tasks across four flu seasons compared to the state-of-the-art. We build on this method by introducing IRNNs, an architecture which changes the sampling procedure in the IRNN to improve the uncertainty estimation. Our second framework uses neural ordinary differential equations to bridge the gap between mechanistic compartmental models and NNs; benefiting from the physical constraints that compartmental models provide. We evaluate eight neural ODE models utilising a mixture of ILI rates and Web search activity data to provide forecasts. These are compared with the IRNN and IRNN0 - the IRNN using only ILI rates. Models trained without Web search activity data outperform the IRNN0 by 16% in terms of Skill. Future work should focus on more effectively using neural ODEs with Web search data to compete with the best performing IRNN.
<div id='section'>Paperid: <span id='pid'>1296, <a href='https://arxiv.org/pdf/2407.19684.pdf' target='_blank'>https://arxiv.org/pdf/2407.19684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinye Sha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.19684">Application of Computer Technology in Financial Investment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In order to understand the application of computer technology in financial investment, the author proposes a research on the application of computer technology in financial investment. The author used user transaction data from a certain online payment platform as a sample, with a total of 284908 sample records, including 593 positive samples (fraud samples) and 285214 negative samples (normal samples), to conduct an empirical study on user fraud detection based on data mining. In this process, facing the problem of imbalanced positive and negative samples, the author proposes to use the Under Sampling method to construct sub samples, and then perform feature scaling, outlier detection, feature screening and other processing on the sub samples. Then, four classification models, logistic regression, K-nearest neighbor algorithm, decision tree, and support vector machine, are trained on the processed sub samples. The prediction results of the four models are evaluated, and the results show that the recall rate, Fl score, and AUC value of the logistic regression model are the highest, indicating that the detection method based on computer data mining is practical and feasible.
<div id='section'>Paperid: <span id='pid'>1297, <a href='https://arxiv.org/pdf/2407.05357.pdf' target='_blank'>https://arxiv.org/pdf/2407.05357.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Welter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.05357">On the power of data augmentation for head pose estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has been impressively successful in the last decade in predicting human head poses from monocular images. However, for in-the-wild inputs the research community relies predominantly on a single training set, 300W-LP, of semisynthetic nature without many alternatives. This paper focuses on gradual extension and improvement of the data to explore the performance achievable with augmentation and synthesis strategies further. Modeling-wise a novel multitask head/loss design which includes uncertainty estimation is proposed. Overall, the thus obtained models are small, efficient, suitable for full 6 DoF pose estimation, and exhibit very competitive accuracy.
<div id='section'>Paperid: <span id='pid'>1298, <a href='https://arxiv.org/pdf/2407.01403.pdf' target='_blank'>https://arxiv.org/pdf/2407.01403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vitaly Bulgakov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01403">Optimization of Retrieval-Augmented Generation Context with Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we focus on methods to reduce the size and improve the quality of the prompt context required for question-answering systems. Attempts to increase the number of retrieved chunked documents and thereby enlarge the context related to the query can significantly complicate the processing and decrease the performance of a Large Language Model (LLM) when generating responses to queries. It is well known that a large set of documents retrieved from a database in response to a query may contain irrelevant information, which often leads to hallucinations in the resulting answers. Our goal is to select the most semantically relevant documents, treating the discarded ones as outliers. We propose and evaluate several methods for identifying outliers by creating features that utilize the distances of embedding vectors, retrieved from the vector database, to both the centroid and the query vectors. The methods were evaluated by comparing the similarities of the retrieved LLM responses to ground-truth answers obtained using the OpenAI GPT-4o model. It was found that the greatest improvements were achieved with increasing complexity of the questions and answers.
<div id='section'>Paperid: <span id='pid'>1299, <a href='https://arxiv.org/pdf/2406.09548.pdf' target='_blank'>https://arxiv.org/pdf/2406.09548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Feder Cooper
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09548">Between Randomness and Arbitrariness: Some Lessons for Reliable Machine Learning at Scale</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To develop rigorous knowledge about ML models -- and the systems in which they are embedded -- we need reliable measurements. But reliable measurement is fundamentally challenging, and touches on issues of reproducibility, scalability, uncertainty quantification, epistemology, and more. This dissertation addresses criteria needed to take reliability seriously: both criteria for designing meaningful metrics, and for methodologies that ensure that we can dependably and efficiently measure these metrics at scale and in practice. In doing so, this dissertation articulates a research vision for a new field of scholarship at the intersection of machine learning, law, and policy. Within this frame, we cover topics that fit under three different themes: (1) quantifying and mitigating sources of arbitrariness in ML, (2) taming randomness in uncertainty estimation and optimization algorithms, in order to achieve scalability without sacrificing reliability, and (3) providing methods for evaluating generative-AI systems, with specific focuses on quantifying memorization in language models and training latent diffusion models on open-licensed data. By making contributions in these three themes, this dissertation serves as an empirical proof by example that research on reliable measurement for machine learning is intimately and inescapably bound up with research in law and policy. These different disciplines pose similar research questions about reliable measurement in machine learning. They are, in fact, two complementary sides of the same research vision, which, broadly construed, aims to construct machine-learning systems that cohere with broader societal values.
<div id='section'>Paperid: <span id='pid'>1300, <a href='https://arxiv.org/pdf/2405.05097.pdf' target='_blank'>https://arxiv.org/pdf/2405.05097.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jarek Duda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.05097">Biology-inspired joint distribution neurons based on Hierarchical Correlation Reconstruction allowing for multidirectional neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological neural networks seem qualitatively superior (e.g. in learning, flexibility, robustness) to current artificial like Multi-Layer Perceptron (MLP) or Kolmogorov-Arnold Network (KAN). Simultaneously, in contrast to them: biological have fundamentally multidirectional signal propagation \cite{axon}, also of probability distributions e.g. for uncertainty estimation, and are believed not being able to use standard backpropagation training \cite{backprop}. There are proposed novel artificial neurons based on HCR (Hierarchical Correlation Reconstruction) allowing to remove the above low level differences: with neurons containing local joint distribution model (of its connections), representing joint density on normalized variables as just linear combination of $(f_\mathbf{j})$ orthonormal polynomials: $Ï(\mathbf{x})=\sum_{\mathbf{j}\in B} a_\mathbf{j} f_\mathbf{j}(\mathbf{x})$ for $\mathbf{x} \in [0,1]^d$ and $B\subset \mathbb{N}^d$ some chosen basis. By various index summations of such $(a_\mathbf{j})_{\mathbf{j}\in B}$ tensor as neuron parameters, we get simple formulas for e.g. conditional expected values for propagation in any direction, like $E[x|y,z]$, $E[y|x]$, which degenerate to KAN-like parametrization if restricting to pairwise dependencies. Such HCR network can also propagate probability distributions (also joint) like $Ï(y,z|x)$. It also allows for additional training approaches, like direct $(a_\mathbf{j})$ estimation, through tensor decomposition, or more biologically plausible information bottleneck training: layers directly influencing only neighbors, optimizing content to maximize information about the next layer, and minimizing about the previous to remove noise, extract crucial information.
<div id='section'>Paperid: <span id='pid'>1301, <a href='https://arxiv.org/pdf/2405.00631.pdf' target='_blank'>https://arxiv.org/pdf/2405.00631.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Assefa Seyoum Wahd
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00631">Deep Metric Learning-Based Out-of-Distribution Detection with Synthetic Outlier Exposure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a novel approach that combines deep metric learning and synthetic data generation using diffusion models for out-of-distribution (OOD) detection. One popular approach for OOD detection is outlier exposure, where models are trained using a mixture of in-distribution (ID) samples and ``seen" OOD samples. For the OOD samples, the model is trained to minimize the KL divergence between the output probability and the uniform distribution while correctly classifying the in-distribution (ID) data. In this paper, we propose a label-mixup approach to generate synthetic OOD data using Denoising Diffusion Probabilistic Models (DDPMs). Additionally, we explore recent advancements in metric learning to train our models.
  In the experiments, we found that metric learning-based loss functions perform better than the softmax. Furthermore, the baseline models (including softmax, and metric learning) show a significant improvement when trained with the generated OOD data. Our approach outperforms strong baselines in conventional OOD detection metrics.
<div id='section'>Paperid: <span id='pid'>1302, <a href='https://arxiv.org/pdf/2404.04498.pdf' target='_blank'>https://arxiv.org/pdf/2404.04498.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomoya Wakayama
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04498">Bayesian Inference for Consistent Predictions in Overparameterized Nonlinear Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The remarkable generalization performance of large-scale models has been challenging the conventional wisdom of the statistical learning theory. Although recent theoretical studies have shed light on this behavior in linear models and nonlinear classifiers, a comprehensive understanding of overparameterization in nonlinear regression models is still lacking. This study explores the predictive properties of overparameterized nonlinear regression within the Bayesian framework, extending the methodology of the adaptive prior considering the intrinsic spectral structure of the data. Posterior contraction is established for generalized linear and single-neuron models with Lipschitz continuous activation functions, demonstrating the consistency in the predictions of the proposed approach. Moreover, the Bayesian framework enables uncertainty estimation of the predictions. The proposed method was validated via numerical simulations and a real data application, showing its ability to achieve accurate predictions and reliable uncertainty estimates. This work provides a theoretical understanding of the advantages of overparameterization and a principled Bayesian approach to large nonlinear models.
<div id='section'>Paperid: <span id='pid'>1303, <a href='https://arxiv.org/pdf/2403.15361.pdf' target='_blank'>https://arxiv.org/pdf/2403.15361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoling Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15361">Learning Topological Representations for Deep Image Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many scenarios, especially biomedical applications, the correct delineation of complex fine-scaled structures such as neurons, tissues, and vessels is critical for downstream analysis. Despite the strong predictive power of deep learning methods, they do not provide a satisfactory representation of these structures, thus creating significant barriers in scalable annotation and downstream analysis. In this dissertation, we tackle such challenges by proposing novel representations of these topological structures in a deep learning framework. We leverage the mathematical tools from topological data analysis, i.e., persistent homology and discrete Morse theory, to develop principled methods for better segmentation and uncertainty estimation, which will become powerful tools for scalable annotation.
<div id='section'>Paperid: <span id='pid'>1304, <a href='https://arxiv.org/pdf/2403.14678.pdf' target='_blank'>https://arxiv.org/pdf/2403.14678.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Romeo Valentin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14678">Towards a Framework for Deep Learning Certification in Safety-Critical Applications Using Inherently Safe Design and Run-Time Error Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although an ever-growing number of applications employ deep learning based systems for prediction, decision-making, or state estimation, almost no certification processes have been established that would allow such systems to be deployed in safety-critical applications. In this work we consider real-world problems arising in aviation and other safety-critical areas, and investigate their requirements for a certified model. To this end, we investigate methodologies from the machine learning research community aimed towards verifying robustness and reliability of deep learning systems, and evaluate these methodologies with regard to their applicability to real-world problems. Then, we establish a new framework towards deep learning certification based on (i) inherently safe design, and (ii) run-time error detection. Using a concrete use case from aviation, we show how deep learning models can recover disentangled variables through the use of weakly-supervised representation learning. We argue that such a system design is inherently less prone to common model failures, and can be verified to encode underlying mechanisms governing the data. Then, we investigate four techniques related to the run-time safety of a model, namely (i) uncertainty quantification, (ii) out-of-distribution detection, (iii) feature collapse, and (iv) adversarial attacks. We evaluate each for their applicability and formulate a set of desiderata that a certified model should fulfill. Finally, we propose a novel model structure that exhibits all desired properties discussed in this work, and is able to make regression and uncertainty predictions, as well as detect out-of-distribution inputs, while requiring no regression labels to train. We conclude with a discussion of the current state and expected future progress of deep learning certification, and its industrial and social implications.
<div id='section'>Paperid: <span id='pid'>1305, <a href='https://arxiv.org/pdf/2403.08198.pdf' target='_blank'>https://arxiv.org/pdf/2403.08198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Dunn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08198">Validating and Exploring Large Geographic Corpora</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates the impact of corpus creation decisions on large multi-lingual geographic web corpora. Beginning with a 427 billion word corpus derived from the Common Crawl, three methods are used to improve the quality of sub-corpora representing specific language-country pairs like New Zealand English: (i) the agreement of independent language identification systems, (ii) hash-based deduplication, and (iii) location-specific outlier detection. The impact of each of these steps is then evaluated at the language level and the country level by using corpus similarity measures to compare each resulting corpus with baseline data sets. The goal is to understand the impact of upstream data cleaning decisions on downstream corpora with a specific focus on under-represented languages and populations. The evaluation shows that the validity of sub-corpora is improved with each stage of cleaning but that this improvement is unevenly distributed across languages and populations. This result shows how standard corpus creation techniques can accidentally exclude under-represented populations.
<div id='section'>Paperid: <span id='pid'>1306, <a href='https://arxiv.org/pdf/2402.12307.pdf' target='_blank'>https://arxiv.org/pdf/2402.12307.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Enrique Garcia-Ceja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12307">Multi-View Conformal Learning for Heterogeneous Sensor Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Being able to assess the confidence of individual predictions in machine learning models is crucial for decision making scenarios. Specially, in critical applications such as medical diagnosis, security, and unmanned vehicles, to name a few. In the last years, complex predictive models have had great success in solving hard tasks and new methods are being proposed every day. While the majority of new developments in machine learning models focus on improving the overall performance, less effort is put on assessing the trustworthiness of individual predictions, and even to a lesser extent, in the context of sensor fusion. To this end, we build and test multi-view and single-view conformal models for heterogeneous sensor fusion. Our models provide theoretical marginal confidence guarantees since they are based on the conformal prediction framework. We also propose a multi-view semi-conformal model based on sets intersection. Through comprehensive experimentation, we show that multi-view models perform better than single-view models not only in terms of accuracy-based performance metrics (as it has already been shown in several previous works) but also in conformal measures that provide uncertainty estimation. Our results also showed that multi-view models generate prediction sets with less uncertainty compared to single-view models.
<div id='section'>Paperid: <span id='pid'>1307, <a href='https://arxiv.org/pdf/2401.07145.pdf' target='_blank'>https://arxiv.org/pdf/2401.07145.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soyed Tuhin Ahmed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.07145">Scalable and Efficient Methods for Uncertainty Estimation and Reduction in Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks (NNs) can achieved high performance in various fields such as computer vision, and natural language processing. However, deploying NNs in resource-constrained safety-critical systems has challenges due to uncertainty in the prediction caused by out-of-distribution data, and hardware non-idealities. To address the challenges of deploying NNs in resource-constrained safety-critical systems, this paper summarizes the (4th year) PhD thesis work that explores scalable and efficient methods for uncertainty estimation and reduction in deep learning, with a focus on Computation-in-Memory (CIM) using emerging resistive non-volatile memories. We tackle the inherent uncertainties arising from out-of-distribution inputs and hardware non-idealities, crucial in maintaining functional safety in automated decision-making systems. Our approach encompasses problem-aware training algorithms, novel NN topologies, and hardware co-design solutions, including dropout-based \emph{binary} Bayesian Neural Networks leveraging spintronic devices and variational inference techniques. These innovations significantly enhance OOD data detection, inference accuracy, and energy efficiency, thereby contributing to the reliability and robustness of NN implementations.
