<!DOCTYPE html>
<html>
<head>
<title>Paper collected by Wang</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">


/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

span#pid {
  color:red;
  
}
span#filename{
  font-style: oblique;
}

span#title{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: italic;
  font-size: 20px;
  border:1px solid #B50;
}
span#abs{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: oblique;
  font-size: 18px;
}
</style>
</head>
<body>

</p></br></br><div id='section'>Paperid: <span id='pid'>1, <a href='https://arxiv.org/pdf/2510.02109.pdf' target='_blank'>https://arxiv.org/pdf/2510.02109.pdf</a></span>   <span><a href='https://github.com/utkuozbulak/spurbreast' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jong Bum Won, Wesley De Neve, Joris Vankerschaver, Utku Ozbulak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02109">SpurBreast: A Curated Dataset for Investigating Spurious Correlations in Real-world Breast MRI Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) have demonstrated remarkable success in medical imaging, yet their real-world deployment remains challenging due to spurious correlations, where models can learn non-clinical features instead of meaningful medical patterns. Existing medical imaging datasets are not designed to systematically study this issue, largely due to restrictive licensing and limited supplementary patient data. To address this gap, we introduce SpurBreast, a curated breast MRI dataset that intentionally incorporates spurious correlations to evaluate their impact on model performance. Analyzing over 100 features involving patient, device, and imaging protocol, we identify two dominant spurious signals: magnetic field strength (a global feature influencing the entire image) and image orientation (a local feature affecting spatial alignment). Through controlled dataset splits, we demonstrate that DNNs can exploit these non-clinical signals, achieving high validation accuracy while failing to generalize to unbiased test data. Alongside these two datasets containing spurious correlations, we also provide benchmark datasets without spurious correlations, allowing researchers to systematically investigate clinically relevant and irrelevant features, uncertainty estimation, adversarial robustness, and generalization strategies. Models and datasets are available at https://github.com/utkuozbulak/spurbreast.
<div id='section'>Paperid: <span id='pid'>2, <a href='https://arxiv.org/pdf/2509.26294.pdf' target='_blank'>https://arxiv.org/pdf/2509.26294.pdf</a></span>   <span><a href='https://github.com/lionelblonde/ngt-pytorch' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lionel Blondé, Joao A. Candido Ramos, Alexandros Kalousis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.26294">Noise-Guided Transport for Imitation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider imitation learning in the low-data regime, where only a limited number of expert demonstrations are available. In this setting, methods that rely on large-scale pretraining or high-capacity architectures can be difficult to apply, and efficiency with respect to demonstration data becomes critical. We introduce Noise-Guided Transport (NGT), a lightweight off-policy method that casts imitation as an optimal transport problem solved via adversarial training. NGT requires no pretraining or specialized architectures, incorporates uncertainty estimation by design, and is easy to implement and tune. Despite its simplicity, NGT achieves strong performance on challenging continuous control tasks, including high-dimensional Humanoid tasks, under ultra-low data regimes with as few as 20 transitions. Code is publicly available at: https://github.com/lionelblonde/ngt-pytorch.
<div id='section'>Paperid: <span id='pid'>3, <a href='https://arxiv.org/pdf/2509.25438.pdf' target='_blank'>https://arxiv.org/pdf/2509.25438.pdf</a></span>   <span><a href='https://github.com/Akuna23Matata/LPM_exploration' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhibo Hou, Zhiyu An, Wan Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25438">Beyond Noisy-TVs: Noise-Robust Exploration Via Learning Progress Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When there exists an unlearnable source of randomness (noisy-TV) in the environment, a naively intrinsic reward driven exploring agent gets stuck at that source of randomness and fails at exploration. Intrinsic reward based on uncertainty estimation or distribution similarity, while eventually escapes noisy-TVs as time unfolds, suffers from poor sample efficiency and high computational cost. Inspired by recent findings from neuroscience that humans monitor their improvements during exploration, we propose a novel method for intrinsically-motivated exploration, named Learning Progress Monitoring (LPM). During exploration, LPM rewards model improvements instead of prediction error or novelty, effectively rewards the agent for observing learnable transitions rather than the unlearnable transitions. We introduce a dual-network design that uses an error model to predict the expected prediction error of the dynamics model in its previous iteration, and use the difference between the model errors of the current iteration and previous iteration to guide exploration. We theoretically show that the intrinsic reward of LPM is zero-equivariant and a monotone indicator of Information Gain (IG), and that the error model is necessary to achieve monotonicity correspondence with IG. We empirically compared LPM against state-of-the-art baselines in noisy environments based on MNIST, 3D maze with 160x120 RGB inputs, and Atari. Results show that LPM's intrinsic reward converges faster, explores more states in the maze experiment, and achieves higher extrinsic reward in Atari. This conceptually simple approach marks a shift-of-paradigm of noise-robust exploration. For code to reproduce our experiments, see https://github.com/Akuna23Matata/LPM_exploration
<div id='section'>Paperid: <span id='pid'>4, <a href='https://arxiv.org/pdf/2509.22380.pdf' target='_blank'>https://arxiv.org/pdf/2509.22380.pdf</a></span>   <span><a href='https://github.com/stat-ml/multidimensional_uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Kotelevskii, Maiya Goloburda, Vladimir Kondratyev, Alexander Fishkov, Mohsen Guizani, Eric Moulines, Maxim Panov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22380">Multidimensional Uncertainty Quantification via Optimal Transport</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most uncertainty quantification (UQ) approaches provide a single scalar value as a measure of model reliability. However, different uncertainty measures could provide complementary information on the prediction confidence. Even measures targeting the same type of uncertainty (e.g., ensemble-based and density-based measures of epistemic uncertainty) may capture different failure modes. We take a multidimensional view on UQ by stacking complementary UQ measures into a vector. Such vectors are assigned with Monge-Kantorovich ranks produced by an optimal-transport-based ordering method. The prediction is then deemed more uncertain than the other if it has a higher rank. The resulting VecUQ-OT algorithm uses entropy-regularized optimal transport. The transport map is learned on vectors of scores from in-distribution data and, by design, applies to unseen inputs, including out-of-distribution cases, without retraining. Our framework supports flexible non-additive uncertainty fusion (including aleatoric and epistemic components). It yields a robust ordering for downstream tasks such as selective prediction, misclassification detection, out-of-distribution detection, and selective generation. Across synthetic, image, and text data, VecUQ-OT shows high efficiency even when individual measures fail. The code for the method is available at: https://github.com/stat-ml/multidimensional_uncertainty.
<div id='section'>Paperid: <span id='pid'>5, <a href='https://arxiv.org/pdf/2509.21055.pdf' target='_blank'>https://arxiv.org/pdf/2509.21055.pdf</a></span>   <span><a href='https://github.com/YuzunoKawori/Mambo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Songyue Cai, Zongqian Wu, Yujie Mo, Liang Peng, Ping Hu, Xiaoshuang Shi, Xiaofeng Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21055">Background Prompt for Few-Shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing foreground-background (FG-BG) decomposition methods for the few-shot out-of-distribution (FS-OOD) detection often suffer from low robustness due to over-reliance on the local class similarity and a fixed background patch extraction strategy. To address these challenges, we propose a new FG-BG decomposition framework, namely Mambo, for FS-OOD detection. Specifically, we propose to first learn a background prompt to obtain the local background similarity containing both the background and image semantic information, and then refine the local background similarity using the local class similarity. As a result, we use both the refined local background similarity and the local class similarity to conduct background extraction, reducing the dependence of the local class similarity in previous methods. Furthermore, we propose the patch self-calibrated tuning to consider the sample diversity to flexibly select numbers of background patches for different samples, and thus exploring the issue of fixed background extraction strategies in previous methods. Extensive experiments on real-world datasets demonstrate that our proposed Mambo achieves the best performance, compared to SOTA methods in terms of OOD detection and near OOD detection setting. The source code will be released at https://github.com/YuzunoKawori/Mambo.
<div id='section'>Paperid: <span id='pid'>6, <a href='https://arxiv.org/pdf/2509.17098.pdf' target='_blank'>https://arxiv.org/pdf/2509.17098.pdf</a></span>   <span><a href='https://github.com/suiannaius/SURE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuzhu Li, An Sui, Fuping Wu, Xiahai Zhuang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17098">Uncertainty-Supervised Interpretable and Robust Evidential Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation has been widely studied in medical image segmentation as a tool to provide reliability, particularly in deep learning approaches. However, previous methods generally lack effective supervision in uncertainty estimation, leading to low interpretability and robustness of the predictions. In this work, we propose a self-supervised approach to guide the learning of uncertainty. Specifically, we introduce three principles about the relationships between the uncertainty and the image gradients around boundaries and noise. Based on these principles, two uncertainty supervision losses are designed. These losses enhance the alignment between model predictions and human interpretation. Accordingly, we introduce novel quantitative metrics for evaluating the interpretability and robustness of uncertainty. Experimental results demonstrate that compared to state-of-the-art approaches, the proposed method can achieve competitive segmentation performance and superior results in out-of-distribution (OOD) scenarios while significantly improving the interpretability and robustness of uncertainty estimation. Code is available via https://github.com/suiannaius/SURE.
<div id='section'>Paperid: <span id='pid'>7, <a href='https://arxiv.org/pdf/2509.16926.pdf' target='_blank'>https://arxiv.org/pdf/2509.16926.pdf</a></span>   <span><a href='https://github.com/Ragib-Amin-Nihal/BEATsCA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ragib Amin Nihal, Benjamin Yen, Takeshi Ashizawa, Kazuhiro Nakadai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16926">Cross-Attention with Confidence Weighting for Multi-Channel Audio Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-channel audio alignment is a key requirement in bioacoustic monitoring, spatial audio systems, and acoustic localization. However, existing methods often struggle to address nonlinear clock drift and lack mechanisms for quantifying uncertainty. Traditional methods like Cross-correlation and Dynamic Time Warping assume simple drift patterns and provide no reliability measures. Meanwhile, recent deep learning models typically treat alignment as a binary classification task, overlooking inter-channel dependencies and uncertainty estimation. We introduce a method that combines cross-attention mechanisms with confidence-weighted scoring to improve multi-channel audio synchronization. We extend BEATs encoders with cross-attention layers to model temporal relationships between channels. We also develop a confidence-weighted scoring function that uses the full prediction distribution instead of binary thresholding. Our method achieved first place in the BioDCASE 2025 Task 1 challenge with 0.30 MSE average across test datasets, compared to 0.58 for the deep learning baseline. On individual datasets, we achieved 0.14 MSE on ARU data (77% reduction) and 0.45 MSE on zebra finch data (18% reduction). The framework supports probabilistic temporal alignment, moving beyond point estimates. While validated in a bioacoustic context, the approach is applicable to a broader range of multi-channel audio tasks where alignment confidence is critical. Code available on: https://github.com/Ragib-Amin-Nihal/BEATsCA
<div id='section'>Paperid: <span id='pid'>8, <a href='https://arxiv.org/pdf/2509.11728.pdf' target='_blank'>https://arxiv.org/pdf/2509.11728.pdf</a></span>   <span><a href='https://github.com/edahelsinki/JK-kNN/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lauri Seppäläinen, Jakub Kubečka, Jonas Elm, Kai Puolamäki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11728">Fast and Interpretable Machine Learning Modelling of Atmospheric Molecular Clusters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding how atmospheric molecular clusters form and grow is key to resolving one of the biggest uncertainties in climate modelling: the formation of new aerosol particles. While quantum chemistry offers accurate insights into these early-stage clusters, its steep computational costs limit large-scale exploration. In this work, we present a fast, interpretable, and surprisingly powerful alternative: $k$-nearest neighbour ($k$-NN) regression model. By leveraging chemically informed distance metrics, including a kernel-induced metric and one learned via metric learning for kernel regression (MLKR), we show that simple $k$-NN models can rival more complex kernel ridge regression (KRR) models in accuracy, while reducing computational time by orders of magnitude. We perform this comparison with the well-established Faber-Christensen-Huang-Lilienfeld (FCHL19) molecular descriptor, but other descriptors (e.g., FCHL18, MBDF, and CM) can be shown to have similar performance. Applied to both simple organic molecules in the QM9 benchmark set and large datasets of atmospheric molecular clusters (sulphuric acid-water and sulphuric-multibase -base systems), our $k$-NN models achieve near-chemical accuracy, scale seamlessly to datasets with over 250,000 entries, and even appears to extrapolate to larger unseen clusters with minimal error (often nearing 1 kcal/mol). With built-in interpretability and straightforward uncertainty estimation, this work positions $k$-NN as a potent tool for accelerating discovery in atmospheric chemistry and beyond.
<div id='section'>Paperid: <span id='pid'>9, <a href='https://arxiv.org/pdf/2509.07925.pdf' target='_blank'>https://arxiv.org/pdf/2509.07925.pdf</a></span>   <span><a href='https://github.com/ODYSSEYWT/GUQ' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tuo Wang, Adithya Kulkarni, Tyler Cody, Peter A. Beling, Yujun Yan, Dawei Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07925">GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is essential for enhancing the reliability of Large Language Models (LLMs), particularly in high-stakes applications. Existing methods often overlook semantic dependencies, relying on token-level probability measures that fail to capture structural relationships within the generated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty Estimation for Large Language Models, a structure-aware framework that leverages dependency parse trees and hierarchical graph pooling to refine uncertainty quantification. By incorporating supervised learning, GENUINE effectively models semantic and structural relationships, improving confidence assessments. Extensive experiments across NLP tasks show that GENUINE achieves up to 29% higher AUROC than semantic entropy-based approaches and reduces calibration errors by over 15%, demonstrating the effectiveness of graph-based uncertainty modeling. The code is available at https://github.com/ODYSSEYWT/GUQ.
<div id='section'>Paperid: <span id='pid'>10, <a href='https://arxiv.org/pdf/2509.06988.pdf' target='_blank'>https://arxiv.org/pdf/2509.06988.pdf</a></span>   <span><a href='https://github.com/Aie0923/ClaFR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingsheng Wang, Shuo Lu, Jian Liang, Aihua Zheng, Ran He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06988">Frustratingly Easy Feature Reconstruction for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection helps models identify data outside the training categories, crucial for security applications. While feature-based post-hoc methods address this by evaluating data differences in the feature space without changing network parameters, they often require access to training data, which may not be suitable for some data privacy scenarios. This may not be suitable in scenarios where data privacy protection is a concern. In this paper, we propose a simple yet effective post-hoc method, termed Classifier-based Feature Reconstruction (ClaFR), from the perspective of subspace projection. It first performs an orthogonal decomposition of the classifier's weights to extract the class-known subspace, then maps the original data features into this subspace to obtain new data representations. Subsequently, the OOD score is determined by calculating the feature reconstruction error of the data within the subspace. Compared to existing OOD detection algorithms, our method does not require access to training data while achieving leading performance on multiple OOD benchmarks. Our code is released at https://github.com/Aie0923/ClaFR.
<div id='section'>Paperid: <span id='pid'>11, <a href='https://arxiv.org/pdf/2508.18142.pdf' target='_blank'>https://arxiv.org/pdf/2508.18142.pdf</a></span>   <span><a href='https://github.com/UserMirrorer/UserMirrorer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianjun Wei, Huizhong Guo, Yingpeng Du, Zhu Sun, Chen Huang, Dongxia Wang, Jie Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18142">Mirroring Users: Towards Building Preference-aligned User Simulator with User Feedback in Recommendation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>User simulation is increasingly vital to develop and evaluate recommender systems (RSs). While Large Language Models (LLMs) offer promising avenues to simulate user behavior, they often struggle with the absence of specific domain alignment required for RSs and the efficiency demands of large-scale simulation. A vast yet underutilized resource for enhancing this alignment is the extensive user feedback inherent in RSs. However, directly leveraging such feedback presents two significant challenges. First, user feedback in RSs is often ambiguous and noisy, which negatively impacts effective preference alignment. Second, the massive volume of feedback largely hinders the efficiency of preference alignment, necessitating an efficient filtering mechanism to identify more informative samples. To overcome these hurdles, we introduce a novel data construction framework that leverages user feedback in RSs with advanced LLM capabilities to generate high-quality simulation data. Our framework unfolds in two key phases: (1) employing LLMs to generate cognitive decision-making processes on constructed simulation samples, reducing ambiguity in raw user feedback; (2) data distillation based on uncertainty estimation and behavior sampling to filter challenging yet denoised simulation samples. Accordingly, we fine-tune lightweight LLMs, as user simulators, using such high-quality dataset with corresponding decision-making processes. Extensive experiments verify that our framework significantly boosts the alignment with human preferences and in-domain reasoning capabilities of fine-tuned LLMs, and provides more insightful and interpretable signals when interacting with RSs. We believe our work will advance the RS community and offer valuable insights for broader human-centric AI research.
<div id='section'>Paperid: <span id='pid'>12, <a href='https://arxiv.org/pdf/2508.17886.pdf' target='_blank'>https://arxiv.org/pdf/2508.17886.pdf</a></span>   <span><a href='https://github.com/hao-duan/PGTuner' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Duan, Yitong Song, Bin Yao, Anqi Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17886">PGTuner: An Efficient Framework for Automatic and Transferable Configuration Tuning of Proximity Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Approximate Nearest Neighbor Search (ANNS) plays a crucial role in many key areas. Proximity graphs (PGs) are the leading method for ANNS, offering the best balance between query efficiency and accuracy. However, their performance heavily depends on various construction and query parameters, which are difficult to optimize due to their complex inter-dependencies. Given that users often prioritize specific accuracy levels, efficiently identifying the optimal PG configurations to meet these targets is essential. Although some studies have explored automatic configuration tuning for PGs, they are limited by inefficiencies and suboptimal results. These issues stem from the need to construct numerous PGs for searching and re-tuning from scratch whenever the dataset changes, as well as the failure to capture the complex dependencies between configurations, query performance, and tuning objectives.
  To address these challenges, we propose PGTuner, an efficient framework for automatic PG configuration tuning leveraging pre-training knowledge and model transfer techniques. PGTuner improves efficiency through a pre-trained query performance prediction (QPP) model, eliminating the need to build multiple PGs. It also features a deep reinforcement learning-based parameter configuration recommendation (PCR) model to recommend optimal configurations for specific datasets and accuracy targets. Additionally, PGTuner incorporates out-of-distribution detection and deep active learning for efficient tuning in dynamic scenarios and transferring to new datasets. Extensive experiments demonstrate that PGTuner can stably achieve the top-level tuning effect across different datasets while significantly improving tuning efficiency by up to 14.69X, with a 14.64X boost in dynamic scenarios. The code and data for PGTuner are available online at https://github.com/hao-duan/PGTuner.
<div id='section'>Paperid: <span id='pid'>13, <a href='https://arxiv.org/pdf/2508.17768.pdf' target='_blank'>https://arxiv.org/pdf/2508.17768.pdf</a></span>   <span><a href='https://github.com/toufiqmusah/nn-uncertainty.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Toufiq Musah, Chinasa Kalaiwo, Maimoona Akram, Ubaida Napari Abdulai, Maruf Adewole, Farouk Dako, Adaobi Chiazor Emegoakor, Udunna C. Anazodo, Prince Ebenezer Adjei, Confidence Raymond
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17768">Towards Trustworthy Breast Tumor Segmentation in Ultrasound using Monte Carlo Dropout and Deep Ensembles for Epistemic Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated segmentation of BUS images is important for precise lesion delineation and tumor characterization, but is challenged by inherent artifacts and dataset inconsistencies. In this work, we evaluate the use of a modified Residual Encoder U-Net for breast ultrasound segmentation, with a focus on uncertainty quantification. We identify and correct for data duplication in the BUSI dataset, and use a deduplicated subset for more reliable estimates of generalization performance. Epistemic uncertainty is quantified using Monte Carlo dropout, deep ensembles, and their combination. Models are benchmarked on both in-distribution and out-of-distribution datasets to demonstrate how they generalize to unseen cross-domain data. Our approach achieves state-of-the-art segmentation accuracy on the Breast-Lesion-USG dataset with in-distribution validation, and provides calibrated uncertainty estimates that effectively signal regions of low model confidence. Performance declines and increased uncertainty observed in out-of-distribution evaluation highlight the persistent challenge of domain shift in medical imaging, and the importance of integrated uncertainty modeling for trustworthy clinical deployment. \footnote{Code available at: https://github.com/toufiqmusah/nn-uncertainty.git}
<div id='section'>Paperid: <span id='pid'>14, <a href='https://arxiv.org/pdf/2508.17408.pdf' target='_blank'>https://arxiv.org/pdf/2508.17408.pdf</a></span>   <span><a href='https://github.com/mp31192/E-BayesSAM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bin Huang, Zhong Liu, Huiying Wen, Bingsheng Huang, Xin Chen, Shuo Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17408">E-BayesSAM: Efficient Bayesian Adaptation of SAM with Self-Optimizing KAN-Based Interpretation for Uncertainty-Aware Ultrasonic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although the Segment Anything Model (SAM) has advanced medical image segmentation, its Bayesian adaptation for uncertainty-aware segmentation remains hindered by three key issues: (1) instability in Bayesian fine-tuning of large pre-trained SAMs; (2) high computation cost due to SAM's massive parameters; (3) SAM's black-box design limits interpretability. To overcome these, we propose E-BayesSAM, an efficient framework combining Token-wise Variational Bayesian Inference (T-VBI) for efficienty Bayesian adaptation and Self-Optimizing Kolmogorov-Arnold Network (SO-KAN) for improving interpretability. T-VBI innovatively reinterprets SAM's output tokens as dynamic probabilistic weights and reparameterizes them as latent variables without auxiliary training, enabling training-free VBI for uncertainty estimation. SO-KAN improves token prediction with learnable spline activations via self-supervised learning, providing insight to prune redundant tokens to boost efficiency and accuracy. Experiments on five ultrasound datasets demonstrated that E-BayesSAM achieves: (i) real-time inference (0.03s/image), (ii) superior segmentation accuracy (average DSC: Pruned E-BayesSAM's 89.0\% vs. E-BayesSAM's 88.0% vs. MedSAM's 88.3%), and (iii) identification of four critical tokens governing SAM's decisions. By unifying efficiency, reliability, and interpretability, E-BayesSAM bridges SAM's versatility with clinical needs, advancing deployment in safety-critical medical applications. The source code is available at https://github.com/mp31192/E-BayesSAM.
<div id='section'>Paperid: <span id='pid'>15, <a href='https://arxiv.org/pdf/2508.09196.pdf' target='_blank'>https://arxiv.org/pdf/2508.09196.pdf</a></span>   <span><a href='https://github.com/asimukaye/fiva' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Asim Ukaye, Numan Saeed, Karthik Nandakumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.09196">FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Different CT segmentation datasets are typically obtained from different scanners under different capture settings and often provide segmentation labels for a limited and often disjoint set of organs. Using these heterogeneous data effectively while preserving patient privacy can be challenging. This work presents a novel federated learning approach to achieve universal segmentation across diverse abdominal CT datasets by utilizing model uncertainty for aggregation and predictive uncertainty for inference. Our approach leverages the inherent noise in stochastic mini-batch gradient descent to estimate a distribution over the model weights to provide an on-the-go uncertainty over the model parameters at the client level. The parameters are then aggregated at the server using the additional uncertainty information using a Bayesian-inspired inverse-variance aggregation scheme. Furthermore, the proposed method quantifies prediction uncertainty by propagating the uncertainty from the model weights, providing confidence measures essential for clinical decision-making. In line with recent work shown, predictive uncertainty is utilized in the inference stage to improve predictive performance. Experimental evaluations demonstrate the effectiveness of this approach in improving both the quality of federated aggregation and uncertainty-weighted inference compared to previously established baselines. The code for this work is made available at: https://github.com/asimukaye/fiva
<div id='section'>Paperid: <span id='pid'>16, <a href='https://arxiv.org/pdf/2508.03827.pdf' target='_blank'>https://arxiv.org/pdf/2508.03827.pdf</a></span>   <span><a href='https://github.com/ComputationalDesignLab/snbo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pavankumar Koratikere, Leifur Leifsson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03827">Scalable Neural Network-based Blackbox Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Optimization (BO) is a widely used approach for blackbox optimization that leverages a Gaussian process (GP) model and an acquisition function to guide future sampling. While effective in low-dimensional settings, BO faces scalability challenges in high-dimensional spaces and with large number of function evaluations due to the computational complexity of GP models. In contrast, neural networks (NNs) offer better scalability and can model complex functions, which led to the development of NN-based BO approaches. However, these methods typically rely on estimating model uncertainty in NN prediction -- a process that is often computationally intensive and complex, particularly in high dimensions. To address these limitations, a novel method, called scalable neural network-based blackbox optimization (SNBO), is proposed that does not rely on model uncertainty estimation. Specifically, SNBO adds new samples using separate criteria for exploration and exploitation, while adaptively controlling the sampling region to ensure efficient optimization. SNBO is evaluated on a range of optimization problems spanning from 10 to 102 dimensions and compared against four state-of-the-art baseline algorithms. Across the majority of test problems, SNBO attains function values better than the best-performing baseline algorithm, while requiring 40-60% fewer function evaluations and reducing the runtime by at least an order of magnitude.
<div id='section'>Paperid: <span id='pid'>17, <a href='https://arxiv.org/pdf/2508.00587.pdf' target='_blank'>https://arxiv.org/pdf/2508.00587.pdf</a></span>   <span><a href='https://github.com/glasbruch/ULRE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Marc HÃ¶lle, Walter Kellermann, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00587">Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic segmentation models trained on known object classes often fail in real-world autonomous driving scenarios by confidently misclassifying unknown objects. While pixel-wise out-of-distribution detection can identify unknown objects, existing methods struggle in complex scenes where rare object classes are often confused with truly unknown objects. We introduce an uncertainty-aware likelihood ratio estimation method that addresses these limitations. Our approach uses an evidential classifier within a likelihood ratio test to distinguish between known and unknown pixel features from a semantic segmentation model, while explicitly accounting for uncertainty. Instead of producing point estimates, our method outputs probability distributions that capture uncertainty from both rare training examples and imperfect synthetic outliers. We show that by incorporating uncertainty in this way, outlier exposure can be leveraged more effectively. Evaluated on five standard benchmark datasets, our method achieves the lowest average false positive rate (2.5%) among state-of-the-art while maintaining high average precision (90.91%) and incurring only negligible computational overhead. Code is available at https://github.com/glasbruch/ULRE.
<div id='section'>Paperid: <span id='pid'>18, <a href='https://arxiv.org/pdf/2507.20008.pdf' target='_blank'>https://arxiv.org/pdf/2507.20008.pdf</a></span>   <span><a href='https://github.com/padmavathi026/Smart-Fare-Prediction' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Padmavathi Moorthy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20008">Robust Taxi Fare Prediction Under Noisy Conditions: A Comparative Study of GAT, TimesNet, and XGBoost</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Precise fare prediction is crucial in ride-hailing platforms and urban mobility systems. This study examines three machine learning models-Graph Attention Networks (GAT), XGBoost, and TimesNet to evaluate their predictive capabilities for taxi fares using a real-world dataset comprising over 55 million records. Both raw (noisy) and denoised versions of the dataset are analyzed to assess the impact of data quality on model performance. The study evaluated the models along multiple axes, including predictive accuracy, calibration, uncertainty estimation, out-of-distribution (OOD) robustness, and feature sensitivity. We also explore pre-processing strategies, including KNN imputation, Gaussian noise injection, and autoencoder-based denoising. The study reveals critical differences between classical and deep learning models under realistic conditions, offering practical guidelines for building robust and scalable models in urban fare prediction systems.
<div id='section'>Paperid: <span id='pid'>19, <a href='https://arxiv.org/pdf/2507.19969.pdf' target='_blank'>https://arxiv.org/pdf/2507.19969.pdf</a></span>   <span><a href='https://github.com/vis-nlp/Text2Vis' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mizanur Rahman, Md Tahmid Rahman Laskar, Shafiq Joty, Enamul Hoque
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19969">Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated data visualization plays a crucial role in simplifying data interpretation, enhancing decision-making, and improving efficiency. While large language models (LLMs) have shown promise in generating visualizations from natural language, the absence of comprehensive benchmarks limits the rigorous evaluation of their capabilities. We introduce Text2Vis, a benchmark designed to assess text-to-visualization models, covering 20+ chart types and diverse data science queries, including trend analysis, correlation, outlier detection, and predictive analytics. It comprises 1,985 samples, each with a data table, natural language query, short answer, visualization code, and annotated charts. The queries involve complex reasoning, conversational turns, and dynamic data retrieval. We benchmark 11 open-source and closed-source models, revealing significant performance gaps, highlighting key challenges, and offering insights for future advancements. To close this gap, we propose the first cross-modal actor-critic agentic framework that jointly refines the textual answer and visualization code, increasing GPT-4o`s pass rate from 26% to 42% over the direct approach and improving chart quality. We also introduce an automated LLM-based evaluation framework that enables scalable assessment across thousands of samples without human annotation, measuring answer correctness, code execution success, visualization readability, and chart accuracy. We release Text2Vis at https://github.com/vis-nlp/Text2Vis.
<div id='section'>Paperid: <span id='pid'>20, <a href='https://arxiv.org/pdf/2507.19847.pdf' target='_blank'>https://arxiv.org/pdf/2507.19847.pdf</a></span>   <span><a href='https://github.com/ZhuWenjie98/KRNFT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjie Zhu, Yabin Zhang, Xin Jin, Wenjun Zeng, Lei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19847">Knowledge Regularized Negative Feature Tuning of Vision-Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for building reliable machine learning models. Although negative prompt tuning has enhanced the OOD detection capabilities of vision-language models, these tuned models often suffer from reduced generalization performance on unseen classes and styles. To address this challenge, we propose a novel method called Knowledge Regularized Negative Feature Tuning (KR-NFT), which integrates an innovative adaptation architecture termed Negative Feature Tuning (NFT) and a corresponding knowledge-regularization (KR) optimization strategy. Specifically, NFT applies distribution-aware transformations to pre-trained text features, effectively separating positive and negative features into distinct spaces. This separation maximizes the distinction between in-distribution (ID) and OOD images. Additionally, we introduce image-conditional learnable factors through a lightweight meta-network, enabling dynamic adaptation to individual images and mitigating sensitivity to class and style shifts. Compared to traditional negative prompt tuning, NFT demonstrates superior efficiency and scalability. To optimize this adaptation architecture, the KR optimization strategy is designed to enhance the discrimination between ID and OOD sets while mitigating pre-trained knowledge forgetting. This enhances OOD detection performance on trained ID classes while simultaneously improving OOD detection on unseen ID datasets. Notably, when trained with few-shot samples from ImageNet dataset, KR-NFT not only improves ID classification accuracy and OOD detection but also significantly reduces the FPR95 by 5.44\% under an unexplored generalization setting with unseen ID categories. Codes can be found at \href{https://github.com/ZhuWenjie98/KRNFT}.
<div id='section'>Paperid: <span id='pid'>21, <a href='https://arxiv.org/pdf/2507.10225.pdf' target='_blank'>https://arxiv.org/pdf/2507.10225.pdf</a></span>   <span><a href='https://github.com/Jarvisgivemeasuit/SynOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinglun Li, Kaixun Jiang, Zhaoyu Chen, Bo Lin, Yao Tang, Weifeng Ge, Wenqiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10225">Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision-language models have exhibited remarkable abilities in detecting out-of-distribution (OOD) samples. However, some challenging OOD samples, which lie close to in-distribution (InD) data in image feature space, can still lead to misclassification. The emergence of foundation models like diffusion models and multimodal large language models (MLLMs) offers a potential solution to this issue. In this work, we propose SynOOD, a novel approach that harnesses foundation models to generate synthetic, challenging OOD data for fine-tuning CLIP models, thereby enhancing boundary-level discrimination between InD and OOD samples. Our method uses an iterative in-painting process guided by contextual prompts from MLLMs to produce nuanced, boundary-aligned OOD samples. These samples are refined through noise adjustments based on gradients from OOD scores like the energy score, effectively sampling from the InD/OOD boundary. With these carefully synthesized images, we fine-tune the CLIP image encoder and negative label features derived from the text encoder to strengthen connections between near-boundary OOD samples and a set of negative labels. Finally, SynOOD achieves state-of-the-art performance on the large-scale ImageNet benchmark, with minimal increases in parameters and runtime. Our approach significantly surpasses existing methods, and the code is available at https://github.com/Jarvisgivemeasuit/SynOOD.
<div id='section'>Paperid: <span id='pid'>22, <a href='https://arxiv.org/pdf/2507.04511.pdf' target='_blank'>https://arxiv.org/pdf/2507.04511.pdf</a></span>   <span><a href='https://github.com/0xFAFA/FA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinhua Lu, Runhe Lai, Yanqi Wu, Kanghao Chen, Wei-Shi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04511">FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision-language models (VLMs) have advanced out-of-distribution (OOD) detection recently. However, existing CLIP-based methods often focus on learning OOD-related knowledge to improve OOD detection, showing limited generalization or reliance on external large-scale auxiliary datasets. In this study, instead of delving into the intricate OOD-related knowledge, we propose an innovative CLIP-based framework based on Forced prompt leArning (FA), designed to make full use of the In-Distribution (ID) knowledge and ultimately boost the effectiveness of OOD detection. Our key insight is to learn a prompt (i.e., forced prompt) that contains more diversified and richer descriptions of the ID classes beyond the textual semantics of class labels. Specifically, it promotes better discernment for ID images, by forcing more notable semantic similarity between ID images and the learnable forced prompt. Moreover, we introduce a forced coefficient, encouraging the forced prompt to learn more comprehensive and nuanced descriptions of the ID classes. In this way, FA is capable of achieving notable improvements in OOD detection, even when trained without any external auxiliary datasets, while maintaining an identical number of trainable parameters as CoOp. Extensive empirical evaluations confirm our method consistently outperforms current state-of-the-art methods. Code is available at https://github.com/0xFAFA/FA.
<div id='section'>Paperid: <span id='pid'>23, <a href='https://arxiv.org/pdf/2507.04511.pdf' target='_blank'>https://arxiv.org/pdf/2507.04511.pdf</a></span>   <span><a href='https://github.com/0xFAFA/FA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinhua Lu, Runhe Lai, Yanqi Wu, Kanghao Chen, Wei-Shi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04511">FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision-language models (VLMs) have advanced out-of-distribution (OOD) detection recently. However, existing CLIP-based methods often focus on learning OOD-related knowledge to improve OOD detection, showing limited generalization or reliance on external large-scale auxiliary datasets. In this study, instead of delving into the intricate OOD-related knowledge, we propose an innovative CLIP-based framework based on Forced prompt leArning (FA), designed to make full use of the In-Distribution (ID) knowledge and ultimately boost the effectiveness of OOD detection. Our key insight is to learn a prompt (i.e., forced prompt) that contains more diversified and richer descriptions of the ID classes beyond the textual semantics of class labels. Specifically, it promotes better discernment for ID images, by forcing more notable semantic similarity between ID images and the learnable forced prompt. Moreover, we introduce a forced coefficient, encouraging the forced prompt to learn more comprehensive and nuanced descriptions of the ID classes. In this way, FA is capable of achieving notable improvements in OOD detection, even when trained without any external auxiliary datasets, while maintaining an identical number of trainable parameters as CoOp. Extensive empirical evaluations confirm our method consistently outperforms current state-of-the-art methods. Code is available at https://github.com/0xFAFA/FA.
<div id='section'>Paperid: <span id='pid'>24, <a href='https://arxiv.org/pdf/2507.03923.pdf' target='_blank'>https://arxiv.org/pdf/2507.03923.pdf</a></span>   <span><a href='https://github.com/hieuphamha19/CSDS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ha-Hieu Pham, Nguyen Lan Vi Vu, Thanh-Huy Nguyen, Ulas Bagci, Min Xu, Trung-Nghia Le, Huy-Hieu Pham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03923">Learning Disentangled Stain and Structural Representations for Semi-Supervised Histopathology Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate gland segmentation in histopathology images is essential for cancer diagnosis and prognosis. However, significant variability in Hematoxylin and Eosin (H&E) staining and tissue morphology, combined with limited annotated data, poses major challenges for automated segmentation. To address this, we propose Color-Structure Dual-Student (CSDS), a novel semi-supervised segmentation framework designed to learn disentangled representations of stain appearance and tissue structure. CSDS comprises two specialized student networks: one trained on stain-augmented inputs to model chromatic variation, and the other on structure-augmented inputs to capture morphological cues. A shared teacher network, updated via Exponential Moving Average (EMA), supervises both students through pseudo-labels. To further improve label reliability, we introduce stain-aware and structure-aware uncertainty estimation modules that adaptively modulate the contribution of each student during training. Experiments on the GlaS and CRAG datasets show that CSDS achieves state-of-the-art performance in low-label settings, with Dice score improvements of up to 1.2% on GlaS and 0.7% on CRAG at 5% labeled data, and 0.7% and 1.4% at 10%. Our code and pre-trained models are available at https://github.com/hieuphamha19/CSDS.
<div id='section'>Paperid: <span id='pid'>25, <a href='https://arxiv.org/pdf/2506.24000.pdf' target='_blank'>https://arxiv.org/pdf/2506.24000.pdf</a></span>   <span><a href='https://github.com/TomSheng21/tta-vlm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.24000">The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) methods have gained significant attention for enhancing the performance of vision-language models (VLMs) such as CLIP during inference, without requiring additional labeled data. However, current TTA researches generally suffer from major limitations such as duplication of baseline results, limited evaluation metrics, inconsistent experimental settings, and insufficient analysis. These problems hinder fair comparisons between TTA methods and obscure their practical strengths and weaknesses. To address these challenges, we introduce TTA-VLM, a comprehensive benchmark for evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7 online TTA methods within a unified and reproducible framework, and evaluates them across 15 widely used datasets. Unlike prior studies focused solely on CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA to assess generality. Beyond classification accuracy, TTA-VLM incorporates various evaluation metrics, including robustness, calibration, out-of-distribution detection, and stability, enabling a more holistic assessment of TTA methods. Through extensive experiments, we find that 1) existing TTA methods produce limited gains compared to the previous pioneering work; 2) current TTA methods exhibit poor collaboration with training-time fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced model trustworthiness. We release TTA-VLM to provide fair comparison and comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the community to develop more reliable and generalizable TTA strategies.
<div id='section'>Paperid: <span id='pid'>26, <a href='https://arxiv.org/pdf/2506.19513.pdf' target='_blank'>https://arxiv.org/pdf/2506.19513.pdf</a></span>   <span><a href='https://github.com/HT86159/Evidential-Conflict' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Huang, Zhekun Liu, Rui Wang, Yang Zhang, Liping Jing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19513">Visual hallucination detection in large vision-language models via evidential conflict</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the remarkable multimodal capabilities of Large Vision-Language Models (LVLMs), discrepancies often occur between visual inputs and textual outputs--a phenomenon we term visual hallucination. This critical reliability gap poses substantial risks in safety-critical Artificial Intelligence (AI) applications, necessitating a comprehensive evaluation benchmark and effective detection methods. Firstly, we observe that existing visual-centric hallucination benchmarks mainly assess LVLMs from a perception perspective, overlooking hallucinations arising from advanced reasoning capabilities. We develop the Perception-Reasoning Evaluation Hallucination (PRE-HAL) dataset, which enables the systematic evaluation of both perception and reasoning capabilities of LVLMs across multiple visual semantics, such as instances, scenes, and relations. Comprehensive evaluation with this new benchmark exposed more visual vulnerabilities, particularly in the more challenging task of relation reasoning. To address this issue, we propose, to the best of our knowledge, the first Dempster-Shafer theory (DST)-based visual hallucination detection method for LVLMs through uncertainty estimation. This method aims to efficiently capture the degree of conflict in high-level features at the model inference phase. Specifically, our approach employs simple mass functions to mitigate the computational complexity of evidence combination on power sets. We conduct an extensive evaluation of state-of-the-art LVLMs, LLaVA-v1.5, mPLUG-Owl2 and mPLUG-Owl3, with the new PRE-HAL benchmark. Experimental results indicate that our method outperforms five baseline uncertainty metrics, achieving average AUROC improvements of 4%, 10%, and 7% across three LVLMs. Our code is available at https://github.com/HT86159/Evidential-Conflict.
<div id='section'>Paperid: <span id='pid'>27, <a href='https://arxiv.org/pdf/2506.09460.pdf' target='_blank'>https://arxiv.org/pdf/2506.09460.pdf</a></span>   <span><a href='https://github.com/amir-khb/SSUDOSDG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Amirreza Khoshbakht, Erchan Aptoula
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09460">Evidential Deep Learning with Spectral-Spatial Uncertainty Disentanglement for Open-Set Hyperspectral Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open-set domain generalization(OSDG) for hyperspectral image classification presents significant challenges due to the presence of unknown classes in target domains and the need for models to generalize across multiple unseen domains without target-specific adaptation. Existing domain adaptation methods assume access to target domain data during training and fail to address the fundamental issue of domain shift when unknown classes are present, leading to negative transfer and reduced classification performance. To address these limitations, we propose a novel open-set domain generalization framework that combines four key components: Spectrum-Invariant Frequency Disentanglement (SIFD) for domain-agnostic feature extraction, Dual-Channel Residual Network (DCRN) for robust spectral-spatial feature learning, Evidential Deep Learning (EDL) for uncertainty quantification, and Spectral-Spatial Uncertainty Disentanglement (SSUD) for reliable open-set classification. The SIFD module extracts domain-invariant spectral features in the frequency domain through attention-weighted frequency analysis and domain-agnostic regularization, while DCRN captures complementary spectral and spatial information via parallel pathways with adaptive fusion. EDL provides principled uncertainty estimation using Dirichlet distributions, enabling the SSUD module to make reliable open-set decisions through uncertainty-aware pathway weighting and adaptive rejection thresholding. Experimental results on three cross-scene hyperspectral classification tasks show that our approach achieves performance comparable to state-of-the-art domain adaptation methods while requiring no access to the target domain during training. The implementation will be made available at https://github.com/amir-khb/SSUDOSDG upon acceptance.
<div id='section'>Paperid: <span id='pid'>28, <a href='https://arxiv.org/pdf/2506.09399.pdf' target='_blank'>https://arxiv.org/pdf/2506.09399.pdf</a></span>   <span><a href='https://github.com/workerbcd/ooddcc' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiyu Guo, Zijian Wang, Tan Pan, Brian C. Lovell, Mahsa Baktashmotlagh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09399">Improving Out-of-Distribution Detection via Dynamic Covariance Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is essential for the trustworthiness of AI systems. Methods using prior information (i.e., subspace-based methods) have shown effective performance by extracting information geometry to detect OOD data with a more appropriate distance metric. However, these methods fail to address the geometry distorted by ill-distributed samples, due to the limitation of statically extracting information geometry from the training distribution. In this paper, we argue that the influence of ill-distributed samples can be corrected by dynamically adjusting the prior geometry in response to new data. Based on this insight, we propose a novel approach that dynamically updates the prior covariance matrix using real-time input features, refining its information. Specifically, we reduce the covariance along the direction of real-time input features and constrain adjustments to the residual space, thus preserving essential data characteristics and avoiding effects on unintended directions in the principal space. We evaluate our method on two pre-trained models for the CIFAR dataset and five pre-trained models for ImageNet-1k, including the self-supervised DINO model. Extensive experiments demonstrate that our approach significantly enhances OOD detection across various models. The code is released at https://github.com/workerbcd/ooddcc.
<div id='section'>Paperid: <span id='pid'>29, <a href='https://arxiv.org/pdf/2506.07288.pdf' target='_blank'>https://arxiv.org/pdf/2506.07288.pdf</a></span>   <span><a href='https://github.com/SSSKJ/EviNET' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Guan, Haohui Wang, Jian Kang, Lihui Liu, Dawei Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07288">EVINET: Towards Open-World Graph Learning via Evidential Reasoning Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph learning has been crucial to many real-world tasks, but they are often studied with a closed-world assumption, with all possible labels of data known a priori. To enable effective graph learning in an open and noisy environment, it is critical to inform the model users when the model makes a wrong prediction to in-distribution data of a known class, i.e., misclassification detection or when the model encounters out-of-distribution from novel classes, i.e., out-of-distribution detection. This paper introduces Evidential Reasoning Network (EVINET), a framework that addresses these two challenges by integrating Beta embedding within a subjective logic framework. EVINET includes two key modules: Dissonance Reasoning for misclassification detection and Vacuity Reasoning for out-of-distribution detection. Extensive experiments demonstrate that EVINET outperforms state-of-the-art methods across multiple metrics in the tasks of in-distribution classification, misclassification detection, and out-of-distribution detection. EVINET demonstrates the necessity of uncertainty estimation and logical reasoning for misclassification detection and out-of-distribution detection and paves the way for open-world graph learning. Our code and data are available at https://github.com/SSSKJ/EviNET.
<div id='section'>Paperid: <span id='pid'>30, <a href='https://arxiv.org/pdf/2506.06719.pdf' target='_blank'>https://arxiv.org/pdf/2506.06719.pdf</a></span>   <span><a href='https://github.com/pxpana/BIG5OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mufhumudzi Muthivhi, Jiahao Huo, Fredrik Gustafsson, Terence L. van Zyl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06719">Improving Wildlife Out-of-Distribution Detection: Africas Big Five</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mitigating human-wildlife conflict seeks to resolve unwanted encounters between these parties. Computer Vision provides a solution to identifying individuals that might escalate into conflict, such as members of the Big Five African animals. However, environments often contain several varied species. The current state-of-the-art animal classification models are trained under a closed-world assumption. They almost always remain overconfident in their predictions even when presented with unknown classes. This study investigates out-of-distribution (OOD) detection of wildlife, specifically the Big Five. To this end, we select a parametric Nearest Class Mean (NCM) and a non-parametric contrastive learning approach as baselines to take advantage of pretrained and projected features from popular classification encoders. Moreover, we compare our baselines to various common OOD methods in the literature. The results show feature-based methods reflect stronger generalisation capability across varying classification thresholds. Specifically, NCM with ImageNet pre-trained features achieves a 2%, 4% and 22% improvement on AUPR-IN, AUPR-OUT and AUTC over the best OOD methods, respectively. The code can be found here https://github.com/pxpana/BIG5OOD
<div id='section'>Paperid: <span id='pid'>31, <a href='https://arxiv.org/pdf/2506.01205.pdf' target='_blank'>https://arxiv.org/pdf/2506.01205.pdf</a></span>   <span><a href='https://github.com/coastalcph/lm_ambiguity' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonia Karamolegkou, Oliver Eberle, Phillip Rust, Carina Kauf, Anders SÃ¸gaard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01205">Trick or Neat: Adversarial Ambiguity and Language Model Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting ambiguity is important for language understanding, including uncertainty estimation, humour detection, and processing garden path sentences. We assess language models' sensitivity to ambiguity by introducing an adversarial ambiguity dataset that includes syntactic, lexical, and phonological ambiguities along with adversarial variations (e.g., word-order changes, synonym replacements, and random-based alterations). Our findings show that direct prompting fails to robustly identify ambiguity, while linear probes trained on model representations can decode ambiguity with high accuracy, sometimes exceeding 90\%. Our results offer insights into the prompting paradigm and how language models encode ambiguity at different layers. We release both our code and data: https://github.com/coastalcph/lm_ambiguity.
<div id='section'>Paperid: <span id='pid'>32, <a href='https://arxiv.org/pdf/2506.01114.pdf' target='_blank'>https://arxiv.org/pdf/2506.01114.pdf</a></span>   <span><a href='https://github.com/duygunuryldz/uncertainty_in_the_wild' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yavuz Bakman, Duygu Nur Yaldiz, Sungmin Kang, Tuo Zhang, Baturalp Buyukates, Salman Avestimehr, Sai Praneeth Karimireddy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01114">Reconsidering LLM Uncertainty Estimation Methods in the Wild</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Model (LLM) Uncertainty Estimation (UE) methods have become a crucial tool for detecting hallucinations in recent years. While numerous UE methods have been proposed, most existing studies evaluate them in isolated short-form QA settings using threshold-independent metrics such as AUROC or PRR. However, real-world deployment of UE methods introduces several challenges. In this work, we systematically examine four key aspects of deploying UE methods in practical settings. Specifically, we assess (1) the sensitivity of UE methods to decision threshold selection, (2) their robustness to query transformations such as typos, adversarial prompts, and prior chat history, (3) their applicability to long-form generation, and (4) strategies for handling multiple UE scores for a single query. Our evaluations on 19 UE methods reveal that most of them are highly sensitive to threshold selection when there is a distribution shift in the calibration dataset. While these methods generally exhibit robustness against previous chat history and typos, they are significantly vulnerable to adversarial prompts. Additionally, while existing UE methods can be adapted for long-form generation through various strategies, there remains considerable room for improvement. Lastly, ensembling multiple UE scores at test time provides a notable performance boost, which highlights its potential as a practical improvement strategy. Code is available at: https://github.com/duygunuryldz/uncertainty_in_the_wild.
<div id='section'>Paperid: <span id='pid'>33, <a href='https://arxiv.org/pdf/2506.00918.pdf' target='_blank'>https://arxiv.org/pdf/2506.00918.pdf</a></span>   <span><a href='https://github.com/biggzlar/IO-CUE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lennart Bramlage, CristÃ³bal Curio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00918">Principled Input-Output-Conditioned Post-Hoc Uncertainty Estimation for Regression Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is critical in safety-sensitive applications but is often omitted from off-the-shelf neural networks due to adverse effects on predictive performance. Retrofitting uncertainty estimates post-hoc typically requires access to model parameters or gradients, limiting feasibility in practice. We propose a theoretically grounded framework for post-hoc uncertainty estimation in regression tasks by fitting an auxiliary model to both original inputs and frozen model outputs. Drawing from principles of maximum likelihood estimation and sequential parameter fitting, we formalize an exact post-hoc optimization objective that recovers the canonical MLE of Gaussian parameters, without requiring sampling or approximation at inference. While prior work has used model outputs to estimate uncertainty, we explicitly characterize the conditions under which this is valid and demonstrate the extent to which structured outputs can support quasi-epistemic inference. We find that using diverse auxiliary data, such as augmented subsets of the original training data, significantly enhances OOD detection and metric performance. Our hypothesis that frozen model outputs contain generalizable latent information about model error and predictive uncertainty is tested and confirmed. Finally, we ensure that our method maintains proper estimation of input-dependent uncertainty without relying exclusively on base model forecasts. These findings are demonstrated in toy problems and adapted to both UCI and depth regression benchmarks. Code: https://github.com/biggzlar/IO-CUE.
<div id='section'>Paperid: <span id='pid'>34, <a href='https://arxiv.org/pdf/2505.24443.pdf' target='_blank'>https://arxiv.org/pdf/2505.24443.pdf</a></span>   <span><a href='https://github.com/heejokong/DivCon' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Heejo Kong, Sung-Jin Kim, Gunho Jung, Seong-Whan Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.24443">Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional semi-supervised learning (SSL) ideally assumes that labeled and unlabeled data share an identical class distribution, however in practice, this assumption is easily violated, as unlabeled data often includes unknown class data, i.e., outliers. The outliers are treated as noise, considerably degrading the performance of SSL models. To address this drawback, we propose a novel framework, Diversify and Conquer (DAC), to enhance SSL robustness in the context of open-set semi-supervised learning. In particular, we note that existing open-set SSL methods rely on prediction discrepancies between inliers and outliers from a single model trained on labeled data. This approach can be easily failed when the labeled data is insufficient, leading to performance degradation that is worse than naive SSL that do not account for outliers. In contrast, our approach exploits prediction disagreements among multiple models that are differently biased towards the unlabeled distribution. By leveraging the discrepancies arising from training on unlabeled data, our method enables robust outlier detection even when the labeled data is underspecified. Our key contribution is constructing a collection of differently biased models through a single training process. By encouraging divergent heads to be differently biased towards outliers while making consistent predictions for inliers, we exploit the disagreement among these heads as a measure to identify unknown concepts. Our code is available at https://github.com/heejokong/DivCon.
<div id='section'>Paperid: <span id='pid'>35, <a href='https://arxiv.org/pdf/2505.16985.pdf' target='_blank'>https://arxiv.org/pdf/2505.16985.pdf</a></span>   <span><a href='https://github.com/mona4399/FeatureMixing' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Moru Liu, Hao Dong, Jessica Kelly, Olga Fink, Mario Trapp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16985">Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection and segmentation are crucial for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. While prior research has primarily focused on unimodal image data, real-world applications are inherently multimodal, requiring the integration of multiple modalities for improved OOD detection. A key challenge is the lack of supervision signals from unknown data, leading to overconfident predictions on OOD samples. To address this challenge, we propose Feature Mixing, an extremely simple and fast method for multimodal outlier synthesis with theoretical support, which can be further optimized to help the model better distinguish between in-distribution (ID) and OOD data. Feature Mixing is modality-agnostic and applicable to various modality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal dataset for OOD segmentation, featuring synthetic OOD objects across diverse scenes and weather conditions. Extensive experiments on SemanticKITTI, nuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that Feature Mixing achieves state-of-the-art performance with a $10 \times$ to $370 \times$ speedup. Our source code and dataset will be available at https://github.com/mona4399/FeatureMixing.
<div id='section'>Paperid: <span id='pid'>36, <a href='https://arxiv.org/pdf/2505.12842.pdf' target='_blank'>https://arxiv.org/pdf/2505.12842.pdf</a></span>   <span><a href='https://github.com/Wuzheng02/GEM-OODforGUIagents' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheng Wu, Pengzhou Cheng, Zongru Wu, Lingzhong Dong, Zhuosheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12842">GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graphical user interface (GUI) agents have recently emerged as an intriguing paradigm for human-computer interaction, capable of automatically executing user instructions to operate intelligent terminal devices. However, when encountering out-of-distribution (OOD) instructions that violate environmental constraints or exceed the current capabilities of agents, GUI agents may suffer task breakdowns or even pose security threats. Therefore, effective OOD detection for GUI agents is essential. Traditional OOD detection methods perform suboptimally in this domain due to the complex embedding space and evolving GUI environments. In this work, we observe that the in-distribution input semantic space of GUI agents exhibits a clustering pattern with respect to the distance from the centroid. Based on the finding, we propose GEM, a novel method based on fitting a Gaussian mixture model over input embedding distances extracted from the GUI agent that reflect its capability boundary. Evaluated on eight datasets spanning smartphones, computers, and web browsers, our method achieves an average accuracy improvement of 23.70\% over the best-performing baseline while only increasing training time by 4.9\% and testing time by 6.5\%. We also experimentally demonstrate that GEM can improve the step-wise success rate by 9.40\% by requesting assistance from the cloud model when encountering OOD samples. Analysis verifies the generalization ability of our method through experiments on nine different backbones. The codes are available at https://github.com/Wuzheng02/GEM-OODforGUIagents.
<div id='section'>Paperid: <span id='pid'>37, <a href='https://arxiv.org/pdf/2505.06843.pdf' target='_blank'>https://arxiv.org/pdf/2505.06843.pdf</a></span>   <span><a href='https://github.com/GuanZihan/Benign-Samples-Matter' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06843">Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent studies have uncovered a troubling vulnerability in the fine-tuning stage of large language models (LLMs): even fine-tuning on entirely benign datasets can lead to a significant increase in the harmfulness of LLM outputs. Building on this finding, our red teaming study takes this threat one step further by developing a more effective attack. Specifically, we analyze and identify samples within benign datasets that contribute most to safety degradation, then fine-tune LLMs exclusively on these samples. We approach this problem from an outlier detection perspective and propose Self-Inf-N, to detect and extract outliers for fine-tuning. Our findings reveal that fine-tuning LLMs on 100 outlier samples selected by Self-Inf-N in the benign datasets severely compromises LLM safety alignment. Extensive experiments across seven mainstream LLMs demonstrate that our attack exhibits high transferability across different architectures and remains effective in practical scenarios. Alarmingly, our results indicate that most existing mitigation strategies fail to defend against this attack, underscoring the urgent need for more robust alignment safeguards. Codes are available at https://github.com/GuanZihan/Benign-Samples-Matter.
<div id='section'>Paperid: <span id='pid'>38, <a href='https://arxiv.org/pdf/2505.04046.pdf' target='_blank'>https://arxiv.org/pdf/2505.04046.pdf</a></span>   <span><a href='https://github.com/Willy1005/2025-IJCAI-RDML' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuyang Wang, Siyuan Duan, Qizhi Li, Guiduo Duan, Yuan Sun, Dezhong Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04046">Reliable Disentanglement Multi-view Learning Against View Adversarial Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trustworthy multi-view learning has attracted extensive attention because evidence learning can provide reliable uncertainty estimation to enhance the credibility of multi-view predictions. Existing trusted multi-view learning methods implicitly assume that multi-view data is secure. However, in safety-sensitive applications such as autonomous driving and security monitoring, multi-view data often faces threats from adversarial perturbations, thereby deceiving or disrupting multi-view models. This inevitably leads to the adversarial unreliability problem (AUP) in trusted multi-view learning. To overcome this tricky problem, we propose a novel multi-view learning framework, namely Reliable Disentanglement Multi-view Learning (RDML). Specifically, we first propose evidential disentanglement learning to decompose each view into clean and adversarial parts under the guidance of corresponding evidences, which is extracted by a pretrained evidence extractor. Then, we employ the feature recalibration module to mitigate the negative impact of adversarial perturbations and extract potential informative features from them. Finally, to further ignore the irreparable adversarial interferences, a view-level evidential attention mechanism is designed. Extensive experiments on multi-view classification tasks with adversarial attacks show that RDML outperforms the state-of-the-art methods by a relatively large margin. Our code is available at https://github.com/Willy1005/2025-IJCAI-RDML.
<div id='section'>Paperid: <span id='pid'>39, <a href='https://arxiv.org/pdf/2505.03494.pdf' target='_blank'>https://arxiv.org/pdf/2505.03494.pdf</a></span>   <span><a href='https://github.com/chenzhao2023/UPMAD_Net_BrainSeg' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanyuan Jia, Ni Yao, Danyang Sun, Chuang Han, Yanting Li, Jiaofen Nan, Fubao Zhu, Chen Zhao, Weihua Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03494">UPMAD-Net: A Brain Tumor Segmentation Network with Uncertainty Guidance and Adaptive Multimodal Feature Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Brain tumor segmentation has a significant impact on the diagnosis and treatment of brain tumors. Accurate brain tumor segmentation remains challenging due to their irregular shapes, vague boundaries, and high variability. Objective: We propose a brain tumor segmentation method that combines deep learning with prior knowledge derived from a region-growing algorithm. Methods: The proposed method utilizes a multi-scale feature fusion (MSFF) module and adaptive attention mechanisms (AAM) to extract multi-scale features and capture global contextual information. To enhance the model's robustness in low-confidence regions, the Monte Carlo Dropout (MC Dropout) strategy is employed for uncertainty estimation. Results: Extensive experiments demonstrate that the proposed method achieves superior performance on Brain Tumor Segmentation (BraTS) datasets, significantly outperforming various state-of-the-art methods. On the BraTS2021 dataset, the test Dice scores are 89.18% for Enhancing Tumor (ET) segmentation, 93.67% for Whole Tumor (WT) segmentation, and 91.23% for Tumor Core (TC) segmentation. On the BraTS2019 validation set, the validation Dice scores are 87.43%, 90.92%, and 90.40% for ET, WT, and TC segmentation, respectively. Ablation studies further confirmed the contribution of each module to segmentation accuracy, indicating that each component played a vital role in overall performance improvement. Conclusion: This study proposed a novel 3D brain tumor segmentation network based on the U-Net architecture. By incorporating the prior knowledge and employing the uncertainty estimation method, the robustness and performance were improved. The code for the proposed method is available at https://github.com/chenzhao2023/UPMAD_Net_BrainSeg.
<div id='section'>Paperid: <span id='pid'>40, <a href='https://arxiv.org/pdf/2504.07793.pdf' target='_blank'>https://arxiv.org/pdf/2504.07793.pdf</a></span>   <span><a href='https://github.com/limchaos/Likelihood-OOD.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Ding, Arturas Aleksandraus, Amirhossein Ahmadian, Jonas Unger, Fredrik Lindsten, Gabriel Eilertsen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07793">Revisiting Likelihood-Based Out-of-Distribution Detection by Modeling Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical for ensuring the reliability of deep learning systems, particularly in safety-critical applications. Likelihood-based deep generative models have historically faced criticism for their unsatisfactory performance in OOD detection, often assigning higher likelihood to OOD data than in-distribution samples when applied to image data. In this work, we demonstrate that likelihood is not inherently flawed. Rather, several properties in the images space prohibit likelihood as a valid detection score. Given a sufficiently good likelihood estimator, specifically using the probability flow formulation of a diffusion model, we show that likelihood-based methods can still perform on par with state-of-the-art methods when applied in the representation space of pre-trained encoders. The code of our work can be found at $\href{https://github.com/limchaos/Likelihood-OOD.git}{\texttt{https://github.com/limchaos/Likelihood-OOD.git}}$.
<div id='section'>Paperid: <span id='pid'>41, <a href='https://arxiv.org/pdf/2504.03915.pdf' target='_blank'>https://arxiv.org/pdf/2504.03915.pdf</a></span>   <span><a href='https://github.com/AIDC-rPPG/RF-Net' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rufei Ma, Chao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03915">RF-BayesPhysNet: A Bayesian rPPG Uncertainty Estimation Method for Complex Scenarios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Remote photoplethysmography (rPPG) technology infers heart rate by capturing subtle color changes in facial skin
  using a camera, demonstrating great potential in non-contact heart rate measurement. However, measurement
  accuracy significantly decreases in complex scenarios such as lighting changes and head movements compared
  to ideal laboratory conditions. Existing deep learning models often neglect the quantification of measurement
  uncertainty, limiting their credibility in dynamic scenes. To address the issue of insufficient rPPG measurement
  reliability in complex scenarios, this paper introduces Bayesian neural networks to the rPPG field for the first time,
  proposing the Robust Fusion Bayesian Physiological Network (RF-BayesPhysNet), which can model both aleatoric
  and epistemic uncertainty. It leverages variational inference to balance accuracy and computational efficiency.
  Due to the current lack of uncertainty estimation metrics in the rPPG field, this paper also proposes a new set of
  methods, using Spearman correlation coefficient, prediction interval coverage, and confidence interval width, to
  measure the effectiveness of uncertainty estimation methods under different noise conditions. Experiments show
  that the model, with only double the parameters compared to traditional network models, achieves a MAE of 2.56
  on the UBFC-RPPG dataset, surpassing most models. It demonstrates good uncertainty estimation capability
  in no-noise and low-noise conditions, providing prediction confidence and significantly enhancing robustness in
  real-world applications. We have open-sourced the code at https://github.com/AIDC-rPPG/RF-Net
<div id='section'>Paperid: <span id='pid'>42, <a href='https://arxiv.org/pdf/2503.22719.pdf' target='_blank'>https://arxiv.org/pdf/2503.22719.pdf</a></span>   <span><a href='https://github.com/sarahmart/LLM-ABS-ARMMAN-prediction' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarah Martinson, Lingkai Kong, Cheol Woo Kim, Aparna Taneja, Milind Tambe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22719">LLM-based Agent Simulation for Maternal Health Interventions: Uncertainty Estimation and Decision-focused Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Agent-based simulation is crucial for modeling complex human behavior, yet traditional approaches require extensive domain knowledge and large datasets. In data-scarce healthcare settings where historic and counterfactual data are limited, large language models (LLMs) offer a promising alternative by leveraging broad world knowledge. This study examines an LLM-driven simulation of a maternal mobile health program, predicting beneficiaries' listening behavior when they receive health information via automated messages (control) or live representatives (intervention). Since uncertainty quantification is critical for decision-making in health interventions, we propose an LLM epistemic uncertainty estimation method based on binary entropy across multiple samples. We enhance model robustness through ensemble approaches, improving F1 score and model calibration compared to individual models. Beyond direct evaluation, we take a decision-focused approach, demonstrating how LLM predictions inform intervention feasibility and trial implementation in data-limited settings. The proposed method extends to public health, disaster response, and other domains requiring rapid intervention assessment under severe data constraints. All code and prompts used for this work can be found at https://github.com/sarahmart/LLM-ABS-ARMMAN-prediction.
<div id='section'>Paperid: <span id='pid'>43, <a href='https://arxiv.org/pdf/2503.21338.pdf' target='_blank'>https://arxiv.org/pdf/2503.21338.pdf</a></span>   <span><a href='https://github.com/nubot-nudt/UGNA-VPR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yehui Shen, Lei Zhang, Qingqiu Li, Xiongwei Zhao, Yue Wang, Huimin Lu, Xieyuanli Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.21338">UGNA-VPR: A Novel Training Paradigm for Visual Place Recognition Based on Uncertainty-Guided NeRF Augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual place recognition (VPR) is crucial for robots to identify previously visited locations, playing an important role in autonomous navigation in both indoor and outdoor environments. However, most existing VPR datasets are limited to single-viewpoint scenarios, leading to reduced recognition accuracy, particularly in multi-directional driving or feature-sparse scenes. Moreover, obtaining additional data to mitigate these limitations is often expensive. This paper introduces a novel training paradigm to improve the performance of existing VPR networks by enhancing multi-view diversity within current datasets through uncertainty estimation and NeRF-based data augmentation. Specifically, we initially train NeRF using the existing VPR dataset. Then, our devised self-supervised uncertainty estimation network identifies places with high uncertainty. The poses of these uncertain places are input into NeRF to generate new synthetic observations for further training of VPR networks. Additionally, we propose an improved storage method for efficient organization of augmented and original training data. We conducted extensive experiments on three datasets and tested three different VPR backbone networks. The results demonstrate that our proposed training paradigm significantly improves VPR performance by fully utilizing existing data, outperforming other training approaches. We further validated the effectiveness of our approach on self-recorded indoor and outdoor datasets, consistently demonstrating superior results. Our dataset and code have been released at \href{https://github.com/nubot-nudt/UGNA-VPR}{https://github.com/nubot-nudt/UGNA-VPR}.
<div id='section'>Paperid: <span id='pid'>44, <a href='https://arxiv.org/pdf/2503.16707.pdf' target='_blank'>https://arxiv.org/pdf/2503.16707.pdf</a></span>   <span><a href='https://github.com/TyroneLi/CUA_O3D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinlong Li, Cristiano Saltori, Fabio Poiesi, Nicu Sebe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16707">Cross-Modal and Uncertainty-Aware Agglomeration for Open-Vocabulary 3D Scene Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The lack of a large-scale 3D-text corpus has led recent works to distill open-vocabulary knowledge from vision-language models (VLMs). However, these methods typically rely on a single VLM to align the feature spaces of 3D models within a common language space, which limits the potential of 3D models to leverage the diverse spatial and semantic capabilities encapsulated in various foundation models. In this paper, we propose Cross-modal and Uncertainty-aware Agglomeration for Open-vocabulary 3D Scene Understanding dubbed CUA-O3D, the first model to integrate multiple foundation models-such as CLIP, DINOv2, and Stable Diffusion-into 3D scene understanding. We further introduce a deterministic uncertainty estimation to adaptively distill and harmonize the heterogeneous 2D feature embeddings from these models. Our method addresses two key challenges: (1) incorporating semantic priors from VLMs alongside the geometric knowledge of spatially-aware vision foundation models, and (2) using a novel deterministic uncertainty estimation to capture model-specific uncertainties across diverse semantic and geometric sensitivities, helping to reconcile heterogeneous representations during training. Extensive experiments on ScanNetV2 and Matterport3D demonstrate that our method not only advances open-vocabulary segmentation but also achieves robust cross-domain alignment and competitive spatial perception capabilities. The code will be available at: https://github.com/TyroneLi/CUA_O3D.
<div id='section'>Paperid: <span id='pid'>45, <a href='https://arxiv.org/pdf/2503.16247.pdf' target='_blank'>https://arxiv.org/pdf/2503.16247.pdf</a></span>   <span><a href='https://github.com/remic-othr/OpenMIBOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Max Gutbrod, David Rauber, Danilo Weber Nunes, Christoph Palm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16247">OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing reliance on Artificial Intelligence (AI) in critical domains such as healthcare demands robust mechanisms to ensure the trustworthiness of these systems, especially when faced with unexpected or anomalous inputs. This paper introduces the Open Medical Imaging Benchmarks for Out-Of-Distribution Detection (OpenMIBOOD), a comprehensive framework for evaluating out-of-distribution (OOD) detection methods specifically in medical imaging contexts. OpenMIBOOD includes three benchmarks from diverse medical domains, encompassing 14 datasets divided into covariate-shifted in-distribution, near-OOD, and far-OOD categories. We evaluate 24 post-hoc methods across these benchmarks, providing a standardized reference to advance the development and fair comparison of OOD detection methods. Results reveal that findings from broad-scale OOD benchmarks in natural image domains do not translate to medical applications, underscoring the critical need for such benchmarks in the medical field. By mitigating the risk of exposing AI models to inputs outside their training distribution, OpenMIBOOD aims to support the advancement of reliable and trustworthy AI systems in healthcare. The repository is available at https://github.com/remic-othr/OpenMIBOOD.
<div id='section'>Paperid: <span id='pid'>46, <a href='https://arxiv.org/pdf/2503.15801.pdf' target='_blank'>https://arxiv.org/pdf/2503.15801.pdf</a></span>   <span><a href='https://github.com/ryeii/CDRM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyu An, Zhibo Hou, Wan Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15801">Disentangling Uncertainties by Learning Compressed Data Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study aleatoric and epistemic uncertainty estimation in a learned regressive system dynamics model. Disentangling aleatoric uncertainty (the inherent randomness of the system) from epistemic uncertainty (the lack of data) is crucial for downstream tasks such as risk-aware control and reinforcement learning, efficient exploration, and robust policy transfer. While existing approaches like Gaussian Processes, Bayesian networks, and model ensembles are widely adopted, they suffer from either high computational complexity or inaccurate uncertainty estimation. To address these limitations, we propose the Compressed Data Representation Model (CDRM), a framework that learns a neural network encoding of the data distribution and enables direct sampling from the output distribution. Our approach incorporates a novel inference procedure based on Langevin dynamics sampling, allowing CDRM to predict arbitrary output distributions rather than being constrained to a Gaussian prior. Theoretical analysis provides the conditions where CDRM achieves better memory and computational complexity compared to bin-based compression methods. Empirical evaluations show that CDRM demonstrates a superior capability to identify aleatoric and epistemic uncertainties separately, achieving AUROCs of 0.8876 and 0.9981 on a single test set containing a mixture of both uncertainties. Qualitative results further show that CDRM's capability extends to datasets with multimodal output distributions, a challenging scenario where existing methods consistently fail. Code and supplementary materials are available at https://github.com/ryeii/CDRM.
<div id='section'>Paperid: <span id='pid'>47, <a href='https://arxiv.org/pdf/2503.14832.pdf' target='_blank'>https://arxiv.org/pdf/2503.14832.pdf</a></span>   <span><a href='https://github.com/YuhangLiuu/H2ST' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhang Liu, Wenjie Zhao, Yunhui Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14832">H2ST: Hierarchical Two-Sample Tests for Continual Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Task Incremental Learning (TIL) is a specialized form of Continual Learning (CL) in which a model incrementally learns from non-stationary data streams. Existing TIL methodologies operate under the closed-world assumption, presuming that incoming data remains in-distribution (ID). However, in an open-world setting, incoming samples may originate from out-of-distribution (OOD) sources, with their task identities inherently unknown. Continually detecting OOD samples presents several challenges for current OOD detection methods: reliance on model outputs leads to excessive dependence on model performance, selecting suitable thresholds is difficult, hindering real-world deployment, and binary ID/OOD classification fails to provide task-level identification. To address these issues, we propose a novel continual OOD detection method called the Hierarchical Two-sample Tests (H2ST). H2ST eliminates the need for threshold selection through hypothesis testing and utilizes feature maps to better exploit model capabilities without excessive dependence on model performance. The proposed hierarchical architecture enables task-level detection with superior performance and lower overhead compared to non-hierarchical classifier two-sample tests. Extensive experiments and analysis validate the effectiveness of H2ST in open-world TIL scenarios and its superiority to the existing methods. Code is available at \href{https://github.com/YuhangLiuu/H2ST}{https://github.com/YuhangLiuu/H2ST}.
<div id='section'>Paperid: <span id='pid'>48, <a href='https://arxiv.org/pdf/2503.10605.pdf' target='_blank'>https://arxiv.org/pdf/2503.10605.pdf</a></span>   <span><a href='https://github.com/ika-rwth-aachen/OCCUQ' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Severin Heidrich, Till Beemelmanns, Alexey Nekrasov, Bastian Leibe, Lutz Eckstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10605">OCCUQ: Exploring Efficient Uncertainty Quantification for 3D Occupancy Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving has the potential to significantly enhance productivity and provide numerous societal benefits. Ensuring robustness in these safety-critical systems is essential, particularly when vehicles must navigate adverse weather conditions and sensor corruptions that may not have been encountered during training. Current methods often overlook uncertainties arising from adversarial conditions or distributional shifts, limiting their real-world applicability. We propose an efficient adaptation of an uncertainty estimation technique for 3D occupancy prediction. Our method dynamically calibrates model confidence using epistemic uncertainty estimates. Our evaluation under various camera corruption scenarios, such as fog or missing cameras, demonstrates that our approach effectively quantifies epistemic uncertainty by assigning higher uncertainty values to unseen data. We introduce region-specific corruptions to simulate defects affecting only a single camera and validate our findings through both scene-level and region-level assessments. Our results show superior performance in Out-of-Distribution (OoD) detection and confidence calibration compared to common baselines such as Deep Ensembles and MC-Dropout. Our approach consistently demonstrates reliable uncertainty measures, indicating its potential for enhancing the robustness of autonomous driving systems in real-world scenarios. Code and dataset are available at https://github.com/ika-rwth-aachen/OCCUQ .
<div id='section'>Paperid: <span id='pid'>49, <a href='https://arxiv.org/pdf/2503.07082.pdf' target='_blank'>https://arxiv.org/pdf/2503.07082.pdf</a></span>   <span><a href='https://github.com/Orion-AI-Lab/EOUncertaintyGeneralization' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Spyros Kondylatos, Nikolaos Ioannis Bountos, Dimitrios Michail, Xiao Xiang Zhu, Gustau Camps-Valls, Ioannis Papoutsis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07082">On the Generalization of Representation Uncertainty in Earth Observation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Computer Vision have introduced the concept of pretrained representation uncertainty, enabling zero-shot uncertainty estimation. This holds significant potential for Earth Observation (EO), where trustworthiness is critical, yet the complexity of EO data poses challenges to uncertainty-aware methods. In this work, we investigate the generalization of representation uncertainty in EO, considering the domain's unique semantic characteristics. We pretrain uncertainties on large EO datasets and propose an evaluation framework to assess their zero-shot performance in multi-label classification and segmentation EO tasks. Our findings reveal that, unlike uncertainties pretrained on natural images, EO-pretraining exhibits strong generalization across unseen EO domains, geographic locations, and target granularities, while maintaining sensitivity to variations in ground sampling distance. We demonstrate the practical utility of pretrained uncertainties showcasing their alignment with task-specific uncertainties in downstream tasks, their sensitivity to real-world EO image noise, and their ability to generate spatial uncertainty estimates out-of-the-box. Initiating the discussion on representation uncertainty in EO, our study provides insights into its strengths and limitations, paving the way for future research in the field. Code and weights are available at: https://github.com/Orion-AI-Lab/EOUncertaintyGeneralization.
<div id='section'>Paperid: <span id='pid'>50, <a href='https://arxiv.org/pdf/2503.01020.pdf' target='_blank'>https://arxiv.org/pdf/2503.01020.pdf</a></span>   <span><a href='https://github.com/PyJulie/Medical-VLMs-OOD-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lie Ju, Sijin Zhou, Yukun Zhou, Huimin Lu, Zhuoting Zhu, Pearse A. Keane, Zongyuan Ge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.01020">Delving into Out-of-Distribution Detection with Medical Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in medical vision-language models (VLMs) demonstrate impressive performance in image classification tasks, driven by their strong zero-shot generalization capabilities. However, given the high variability and complexity inherent in medical imaging data, the ability of these models to detect out-of-distribution (OOD) data in this domain remains underexplored. In this work, we conduct the first systematic investigation into the OOD detection potential of medical VLMs. We evaluate state-of-the-art VLM-based OOD detection methods across a diverse set of medical VLMs, including both general and domain-specific purposes. To accurately reflect real-world challenges, we introduce a cross-modality evaluation pipeline for benchmarking full-spectrum OOD detection, rigorously assessing model robustness against both semantic shifts and covariate shifts. Furthermore, we propose a novel hierarchical prompt-based method that significantly enhances OOD detection performance. Extensive experiments are conducted to validate the effectiveness of our approach. The codes are available at https://github.com/PyJulie/Medical-VLMs-OOD-Detection.
<div id='section'>Paperid: <span id='pid'>51, <a href='https://arxiv.org/pdf/2502.19755.pdf' target='_blank'>https://arxiv.org/pdf/2502.19755.pdf</a></span>   <span><a href='https://github.com/hugo0076/HALO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hugo Lyons Keenan, Sarah Erfani, Christopher Leckie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19755">HALO: Robust Out-of-Distribution Detection via Joint Optimisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective out-of-distribution (OOD) detection is crucial for the safe deployment of machine learning models in real-world scenarios. However, recent work has shown that OOD detection methods are vulnerable to adversarial attacks, potentially leading to critical failures in high-stakes applications. This discovery has motivated work on robust OOD detection methods that are capable of maintaining performance under various attack settings. Prior approaches have made progress on this problem but face a number of limitations: often only exhibiting robustness to attacks on OOD data or failing to maintain strong clean performance. In this work, we adapt an existing robust classification framework, TRADES, extending it to the problem of robust OOD detection and discovering a novel objective function. Recognising the critical importance of a strong clean/robust trade-off for OOD detection, we introduce an additional loss term which boosts classification and detection performance. Our approach, called HALO (Helper-based AdversariaL OOD detection), surpasses existing methods and achieves state-of-the-art performance across a number of datasets and attack settings. Extensive experiments demonstrate an average AUROC improvement of 3.15 in clean settings and 7.07 under adversarial attacks when compared to the next best method. Furthermore, HALO exhibits resistance to transferred attacks, offers tuneable performance through hyperparameter selection, and is compatible with existing OOD detection frameworks out-of-the-box, leaving open the possibility of future performance gains. Code is available at: https://github.com/hugo0076/HALO
<div id='section'>Paperid: <span id='pid'>52, <a href='https://arxiv.org/pdf/2502.17912.pdf' target='_blank'>https://arxiv.org/pdf/2502.17912.pdf</a></span>   <span><a href='https://github.com/draym28/DeGEM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhan Chen, Yihong Luo, Yifan Song, Pengwen Dai, Jing Tang, Xiaochun Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17912">Decoupled Graph Energy-based Model for Node Out-of-Distribution Detection on Heterophilic Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite extensive research efforts focused on OOD detection on images, OOD detection on nodes in graph learning remains underexplored. The dependence among graph nodes hinders the trivial adaptation of existing approaches on images that assume inputs to be i.i.d. sampled, since many unique features and challenges specific to graphs are not considered, such as the heterophily issue. Recently, GNNSafe, which considers node dependence, adapted energy-based detection to the graph domain with state-of-the-art performance, however, it has two serious issues: 1) it derives node energy from classification logits without specifically tailored training for modeling data distribution, making it less effective at recognizing OOD data; 2) it highly relies on energy propagation, which is based on homophily assumption and will cause significant performance degradation on heterophilic graphs, where the node tends to have dissimilar distribution with its neighbors. To address the above issues, we suggest training EBMs by MLE to enhance data distribution modeling and remove energy propagation to overcome the heterophily issues. However, training EBMs via MLE requires performing MCMC sampling on both node feature and node neighbors, which is challenging due to the node interdependence and discrete graph topology. To tackle the sampling challenge, we introduce DeGEM, which decomposes the learning process into two parts: a graph encoder that leverages topology information for node representations and an energy head that operates in latent space. Extensive experiments validate that DeGEM, without OOD exposure during training, surpasses previous state-of-the-art methods, achieving an average AUROC improvement of 6.71% on homophilic graphs and 20.29% on heterophilic graphs, and even outperform methods trained with OOD exposure. Our code is available at: https://github.com/draym28/DeGEM.
<div id='section'>Paperid: <span id='pid'>53, <a href='https://arxiv.org/pdf/2502.16824.pdf' target='_blank'>https://arxiv.org/pdf/2502.16824.pdf</a></span>   <span><a href='https://github.com/umkiyoung/DiBO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeyoung Yun, Kiyoung Om, Jaewoo Lee, Sujin Yun, Jinkyoo Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16824">Posterior Inference with Diffusion Models for High-dimensional Black-box Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimizing high-dimensional and complex black-box functions is crucial in numerous scientific applications. While Bayesian optimization (BO) is a powerful method for sample-efficient optimization, it struggles with the curse of dimensionality and scaling to thousands of evaluations. Recently, leveraging generative models to solve black-box optimization problems has emerged as a promising framework. However, those methods often underperform compared to BO methods due to limited expressivity and difficulty of uncertainty estimation in high-dimensional spaces. To overcome these issues, we introduce \textbf{DiBO}, a novel framework for solving high-dimensional black-box optimization problems. Our method iterates two stages. First, we train a diffusion model to capture the data distribution and deep ensembles to predict function values with uncertainty quantification. Second, we cast the candidate selection as a posterior inference problem to balance exploration and exploitation in high-dimensional spaces. Concretely, we fine-tune diffusion models to amortize posterior inference. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines across synthetic and real-world tasks. Our code is publicly available \href{https://github.com/umkiyoung/DiBO}{here}.
<div id='section'>Paperid: <span id='pid'>54, <a href='https://arxiv.org/pdf/2502.12849.pdf' target='_blank'>https://arxiv.org/pdf/2502.12849.pdf</a></span>   <span><a href='https://github.com/gigug/LIR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gianluca Guglielmo, Marc Masana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12849">Leveraging Intermediate Representations for Better Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world applications, machine learning models must reliably detect Out-of-Distribution (OoD) samples to prevent unsafe decisions. Current OoD detection methods often rely on analyzing the logits or the embeddings of the penultimate layer of a neural network. However, little work has been conducted on the exploitation of the rich information encoded in intermediate layers. To address this, we analyze the discriminative power of intermediate layers and show that they can positively be used for OoD detection. Therefore, we propose to regularize intermediate layers with an energy-based contrastive loss, and by grouping multiple layers in a single aggregated response. We demonstrate that intermediate layer activations improves OoD detection performance by running a comprehensive evaluation across multiple datasets.
<div id='section'>Paperid: <span id='pid'>55, <a href='https://arxiv.org/pdf/2502.12713.pdf' target='_blank'>https://arxiv.org/pdf/2502.12713.pdf</a></span>   <span><a href='https://github.com/ThierryJudge/contouring-uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Thierry Judge, Olivier Bernard, Woo-Jin Cho Kim, Alberto Gomez, Arian Beqiri, Agisilaos Chartsias, Pierre-Marc Jodoin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12713">Uncertainty Propagation for Echocardiography Clinical Metric Estimation via Contour Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Echocardiography plays a fundamental role in the extraction of important clinical parameters (e.g. left ventricular volume and ejection fraction) required to determine the presence and severity of heart-related conditions. When deploying automated techniques for computing these parameters, uncertainty estimation is crucial for assessing their utility. Since clinical parameters are usually derived from segmentation maps, there is no clear path for converting pixel-wise uncertainty values into uncertainty estimates in the downstream clinical metric calculation. In this work, we propose a novel uncertainty estimation method based on contouring rather than segmentation. Our method explicitly predicts contour location uncertainty from which contour samples can be drawn. Finally, the sampled contours can be used to propagate uncertainty to clinical metrics. Our proposed method not only provides accurate uncertainty estimations for the task of contouring but also for the downstream clinical metrics on two cardiac ultrasound datasets. Code is available at: https://github.com/ThierryJudge/contouring-uncertainty.
<div id='section'>Paperid: <span id='pid'>56, <a href='https://arxiv.org/pdf/2502.11638.pdf' target='_blank'>https://arxiv.org/pdf/2502.11638.pdf</a></span>   <span><a href='https://github.com/dlotfi/MedOODFlow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dariush Lotfi, Mohammad-Ali Nikouei Mahani, Mohamad Koohi-Moghadam, Kyongtae Ty Bae
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11638">Safeguarding AI in Medical Imaging: Post-Hoc Out-of-Distribution Detection with Normalizing Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In AI-driven medical imaging, the failure to detect out-of-distribution (OOD) data poses a severe risk to clinical reliability, potentially leading to critical diagnostic errors. Current OOD detection methods often demand impractical retraining or modifications to pre-trained models, hindering their adoption in regulated clinical environments. To address this challenge, we propose a post-hoc normalizing flow-based approach that seamlessly integrates with existing pre-trained models without altering their weights. Our evaluation used a novel in-house built dataset, MedOOD, meticulously curated to simulate clinically relevant distributional shifts, alongside the MedMNIST benchmark dataset. On our in-house MedOOD dataset, our method achieved an AUROC of 84.61%, outperforming state-of-the-art methods like ViM (80.65%) and MDS (80.87%). Similarly, on MedMNIST, it reached an exceptional AUROC of 93.8%, surpassing leading approaches such as ViM (88.08%) and ReAct (87.05%). This superior performance, coupled with its post-hoc integration capability, positions our method as a vital safeguard for enhancing safety in medical imaging workflows. The model and code to build OOD datasets are publicly accessible at https://github.com/dlotfi/MedOODFlow.
<div id='section'>Paperid: <span id='pid'>57, <a href='https://arxiv.org/pdf/2502.08695.pdf' target='_blank'>https://arxiv.org/pdf/2502.08695.pdf</a></span>   <span><a href='https://github.com/rwl93/bnp4ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Randolph W. Linderman, Yiran Chen, Scott W. Linderman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08695">A Bayesian Nonparametric Perspective on Mahalanobis Distance for Out of Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian nonparametric methods are naturally suited to the problem of out-of-distribution (OOD) detection. However, these techniques have largely been eschewed in favor of simpler methods based on distances between pre-trained or learned embeddings of data points. Here we show a formal relationship between Bayesian nonparametric models and the relative Mahalanobis distance score (RMDS), a commonly used method for OOD detection. Building on this connection, we propose Bayesian nonparametric mixture models with hierarchical priors that generalize the RMDS. We evaluate these models on the OpenOOD detection benchmark and show that Bayesian nonparametric methods can improve upon existing OOD methods, especially in regimes where training classes differ in their covariance structure and where there are relatively few data points per class.
<div id='section'>Paperid: <span id='pid'>58, <a href='https://arxiv.org/pdf/2502.08105.pdf' target='_blank'>https://arxiv.org/pdf/2502.08105.pdf</a></span>   <span><a href='https://github.com/ca1man-2022/Awesome-GOOD-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingyi Cai, Yunliang Jiang, Yixin Liu, Ming Li, Changqin Huang, Shirui Pan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08105">Out-of-Distribution Detection on Graphs: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph machine learning has witnessed rapid growth, driving advancements across diverse domains. However, the in-distribution assumption, where training and testing data share the same distribution, often breaks in real-world scenarios, leading to degraded model performance under distribution shifts. This challenge has catalyzed interest in graph out-of-distribution (GOOD) detection, which focuses on identifying graph data that deviates from the distribution seen during training, thereby enhancing model robustness. In this paper, we provide a rigorous definition of GOOD detection and systematically categorize existing methods into four types: enhancement-based, reconstruction-based, information propagation-based, and classification-based approaches. We analyze the principles and mechanisms of each approach and clarify the distinctions between GOOD detection and related fields, such as graph anomaly detection, outlier detection, and GOOD generalization. Beyond methodology, we discuss practical applications and theoretical foundations, highlighting the unique challenges posed by graph data. Finally, we discuss the primary challenges and propose future directions to advance this emerging field. The repository of this survey is available at https://github.com/ca1man-2022/Awesome-GOOD-Detection.
<div id='section'>Paperid: <span id='pid'>59, <a href='https://arxiv.org/pdf/2502.06351.pdf' target='_blank'>https://arxiv.org/pdf/2502.06351.pdf</a></span>   <span><a href='https://github.com/sandylaker/ib-edl' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yawei Li, David RÃ¼gamer, Bernd Bischl, Mina Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06351">Calibrating LLMs with Information-Theoretic Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fine-tuned large language models (LLMs) often exhibit overconfidence, particularly when trained on small datasets, resulting in poor calibration and inaccurate uncertainty estimates. Evidential Deep Learning (EDL), an uncertainty-aware approach, enables uncertainty estimation in a single forward pass, making it a promising method for calibrating fine-tuned LLMs. However, despite its computational efficiency, EDL is prone to overfitting, as its training objective can result in overly concentrated probability distributions. To mitigate this, we propose regularizing EDL by incorporating an information bottleneck (IB). Our approach IB-EDL suppresses spurious information in the evidence generated by the model and encourages truly predictive information to influence both the predictions and uncertainty estimates. Extensive experiments across various fine-tuned LLMs and tasks demonstrate that IB-EDL outperforms both existing EDL and non-EDL approaches. By improving the trustworthiness of LLMs, IB-EDL facilitates their broader adoption in domains requiring high levels of confidence calibration. Code is available at https://github.com/sandylaker/ib-edl.
<div id='section'>Paperid: <span id='pid'>60, <a href='https://arxiv.org/pdf/2502.05964.pdf' target='_blank'>https://arxiv.org/pdf/2502.05964.pdf</a></span>   <span><a href='https://github.com/jhornauer/GrUMoDepth' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Julia Hornauer, Amir El-Ghoussani, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05964">Revisiting Gradient-based Uncertainty for Monocular Depth Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monocular depth estimation, similar to other image-based tasks, is prone to erroneous predictions due to ambiguities in the image, for example, caused by dynamic objects or shadows. For this reason, pixel-wise uncertainty assessment is required for safety-critical applications to highlight the areas where the prediction is unreliable. We address this in a post hoc manner and introduce gradient-based uncertainty estimation for already trained depth estimation models. To extract gradients without depending on the ground truth depth, we introduce an auxiliary loss function based on the consistency of the predicted depth and a reference depth. The reference depth, which acts as pseudo ground truth, is in fact generated using a simple image or feature augmentation, making our approach simple and effective. To obtain the final uncertainty score, the derivatives w.r.t. the feature maps from single or multiple layers are calculated using back-propagation. We demonstrate that our gradient-based approach is effective in determining the uncertainty without re-training using the two standard depth estimation benchmarks KITTI and NYU. In particular, for models trained with monocular sequences and therefore most prone to uncertainty, our method outperforms related approaches. In addition, we publicly provide our code and models: https://github.com/jhornauer/GrUMoDepth
<div id='section'>Paperid: <span id='pid'>61, <a href='https://arxiv.org/pdf/2502.03946.pdf' target='_blank'>https://arxiv.org/pdf/2502.03946.pdf</a></span>   <span><a href='https://github.com/datasciapps/CleanSurvival' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yousef Koka, David Selby, Gerrit GroÃmann, Sebastian Vollmer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03946">CleanSurvival: Automated data preprocessing for time-to-event models using reinforcement learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data preprocessing is a critical yet frequently neglected aspect of machine learning, often paid little attention despite its potentially significant impact on model performance. While automated machine learning pipelines are starting to recognize and integrate data preprocessing into their solutions for classification and regression tasks, this integration is lacking for more specialized tasks like survival or time-to-event models. As a result, survival analysis not only faces the general challenges of data preprocessing but also suffers from the lack of tailored, automated solutions in this area.
  To address this gap, this paper presents 'CleanSurvival', a reinforcement-learning-based solution for optimizing preprocessing pipelines, extended specifically for survival analysis. The framework can handle continuous and categorical variables, using Q-learning to select which combination of data imputation, outlier detection and feature extraction techniques achieves optimal performance for a Cox, random forest, neural network or user-supplied time-to-event model. The package is available on GitHub: https://github.com/datasciapps/CleanSurvival
  Experimental benchmarks on real-world datasets show that the Q-learning-based data preprocessing results in superior predictive performance to standard approaches, finding such a model up to 10 times faster than undirected random grid search. Furthermore, a simulation study demonstrates the effectiveness in different types and levels of missingness and noise in the data.
<div id='section'>Paperid: <span id='pid'>62, <a href='https://arxiv.org/pdf/2501.18463.pdf' target='_blank'>https://arxiv.org/pdf/2501.18463.pdf</a></span>   <span><a href='https://github.com/hoshi23/OOD-X-Benchmarks' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiho Noda, Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18463">A Benchmark and Evaluation for Real-World Out-of-Distribution Detection Using Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a task that detects OOD samples during inference to ensure the safety of deployed models. However, conventional benchmarks have reached performance saturation, making it difficult to compare recent OOD detection methods. To address this challenge, we introduce three novel OOD detection benchmarks that enable a deeper understanding of method characteristics and reflect real-world conditions. First, we present ImageNet-X, designed to evaluate performance under challenging semantic shifts. Second, we propose ImageNet-FS-X for full-spectrum OOD detection, assessing robustness to covariate shifts (feature distribution shifts). Finally, we propose Wilds-FS-X, which extends these evaluations to real-world datasets, offering a more comprehensive testbed. Our experiments reveal that recent CLIP-based OOD detection methods struggle to varying degrees across the three proposed benchmarks, and none of them consistently outperforms the others. We hope the community goes beyond specific benchmarks and includes more challenging conditions reflecting real-world scenarios. The code is https://github.com/hoshi23/OOD-X-Benchmarks.
<div id='section'>Paperid: <span id='pid'>63, <a href='https://arxiv.org/pdf/2501.17289.pdf' target='_blank'>https://arxiv.org/pdf/2501.17289.pdf</a></span>   <span><a href='https://github.com/rohban-lab/CTS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mojtaba Nafez, Moein Madadi, Arad Maleki, Mahdi Hajialilue, Zeinab Sadat Taghavi, Sepehr Rezaee, Ali Ansari, Bahar Dibaei Nia, Kian Shamsaie, Mohammadreza Salehi, Mackenzie W. Mathis, Mahdieh Soleymani Baghshah, Mohammad Sabokrou, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17289">A Contrastive Teacher-Student Framework for Novelty Detection under Style Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There have been several efforts to improve Novelty Detection (ND) performance. However, ND methods often suffer significant performance drops under minor distribution shifts caused by changes in the environment, known as style shifts. This challenge arises from the ND setup, where the absence of out-of-distribution (OOD) samples during training causes the detector to be biased toward the dominant style features in the in-distribution (ID) data. As a result, the model mistakenly learns to correlate style with core features, using this shortcut for detection. Robust ND is crucial for real-world applications like autonomous driving and medical imaging, where test samples may have different styles than the training data. Motivated by this, we propose a robust ND method that crafts an auxiliary OOD set with style features similar to the ID set but with different core features. Then, a task-based knowledge distillation strategy is utilized to distinguish core features from style features and help our model rely on core features for discriminating crafted OOD and ID sets. We verified the effectiveness of our method through extensive experimental evaluations on several datasets, including synthetic and real-world benchmarks, against nine different ND methods.
<div id='section'>Paperid: <span id='pid'>64, <a href='https://arxiv.org/pdf/2501.16971.pdf' target='_blank'>https://arxiv.org/pdf/2501.16971.pdf</a></span>   <span><a href='https://github.com/rohban-lab/RODEO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mohammad Jafari, Hamid Reza Dehbashi, Ali Ansari, Sepehr Ghobadi, Masoud Hadi, Arshia Soltani Moakhar, Mohammad Azizmalayeri, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16971">RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, there have been significant improvements in various forms of image outlier detection. However, outlier detection performance under adversarial settings lags far behind that in standard settings. This is due to the lack of effective exposure to adversarial scenarios during training, especially on unseen outliers, leading to detection models failing to learn robust features. To bridge this gap, we introduce RODEO, a data-centric approach that generates effective outliers for robust outlier detection. More specifically, we show that incorporating outlier exposure (OE) and adversarial training can be an effective strategy for this purpose, as long as the exposed training outliers meet certain characteristics, including diversity, and both conceptual differentiability and analogy to the inlier samples. We leverage a text-to-image model to achieve this goal. We demonstrate both quantitatively and qualitatively that our adaptive OE method effectively generates ``diverse'' and ``near-distribution'' outliers, leveraging information from both text and image domains. Moreover, our experimental results show that utilizing our synthesized outliers significantly enhances the performance of the outlier detector, particularly in adversarial settings.
<div id='section'>Paperid: <span id='pid'>65, <a href='https://arxiv.org/pdf/2501.15271.pdf' target='_blank'>https://arxiv.org/pdf/2501.15271.pdf</a></span>   <span><a href='https://github.com/rohban-lab/ZARND' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mohammad Jafari, Hamid Reza Dehbashi, Zeinab Sadat Taghavi, Mohammad Sabokrou, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15271">Killing it with Zero-Shot: Adversarially Robust Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty Detection (ND) plays a crucial role in machine learning by identifying new or unseen data during model inference. This capability is especially important for the safe and reliable operation of automated systems. Despite advances in this field, existing techniques often fail to maintain their performance when subject to adversarial attacks. Our research addresses this gap by marrying the merits of nearest-neighbor algorithms with robust features obtained from models pretrained on ImageNet. We focus on enhancing the robustness and performance of ND algorithms. Experimental results demonstrate that our approach significantly outperforms current state-of-the-art methods across various benchmarks, particularly under adversarial conditions. By incorporating robust pretrained features into the k-NN algorithm, we establish a new standard for performance and robustness in the field of robust ND. This work opens up new avenues for research aimed at fortifying machine learning systems against adversarial vulnerabilities. Our implementation is publicly available at https://github.com/rohban-lab/ZARND.
<div id='section'>Paperid: <span id='pid'>66, <a href='https://arxiv.org/pdf/2501.12835.pdf' target='_blank'>https://arxiv.org/pdf/2501.12835.pdf</a></span>   <span><a href='https://github.com/s-nlp/AdaRAGUE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Viktor Moskvoretskii, Maria Lysyuk, Mikhail Salnikov, Nikolay Ivanov, Sergey Pletenev, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Irina Nikishina, Alexander Panchenko
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12835">Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Retrieval Augmented Generation (RAG) improves correctness of Question Answering (QA) and addresses hallucinations in Large Language Models (LLMs), yet greatly increase computational costs. Besides, RAG is not always needed as may introduce irrelevant information. Recent adaptive retrieval methods integrate LLMs' intrinsic knowledge with external information appealing to LLM self-knowledge, but they often neglect efficiency evaluations and comparisons with uncertainty estimation techniques. We bridge this gap by conducting a comprehensive analysis of 35 adaptive retrieval methods, including 8 recent approaches and 27 uncertainty estimation techniques, across 6 datasets using 10 metrics for QA performance, self-knowledge, and efficiency. Our findings show that uncertainty estimation techniques often outperform complex pipelines in terms of efficiency and self-knowledge, while maintaining comparable QA performance.
<div id='section'>Paperid: <span id='pid'>67, <a href='https://arxiv.org/pdf/2501.11258.pdf' target='_blank'>https://arxiv.org/pdf/2501.11258.pdf</a></span>   <span><a href='https://github.com/talze/frequency-dropout' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tal Zeevi, Lawrence H. Staib, John A. Onofrey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11258">Enhancing Uncertainty Estimation in Semantic Segmentation via Monte-Carlo Frequency Dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monte-Carlo (MC) Dropout provides a practical solution for estimating predictive distributions in deterministic neural networks. Traditional dropout, applied within the signal space, may fail to account for frequency-related noise common in medical imaging, leading to biased predictive estimates. A novel approach extends Dropout to the frequency domain, allowing stochastic attenuation of signal frequencies during inference. This creates diverse global textural variations in feature maps while preserving structural integrity -- a factor we hypothesize and empirically show is contributing to accurately estimating uncertainties in semantic segmentation. We evaluated traditional MC-Dropout and the MC-frequency Dropout in three segmentation tasks involving different imaging modalities: (i) prostate zones in biparametric MRI, (ii) liver tumors in contrast-enhanced CT, and (iii) lungs in chest X-ray scans. Our results show that MC-Frequency Dropout improves calibration, convergence, and semantic uncertainty, thereby improving prediction scrutiny, boundary delineation, and has the potential to enhance medical decision-making.
<div id='section'>Paperid: <span id='pid'>68, <a href='https://arxiv.org/pdf/2501.06999.pdf' target='_blank'>https://arxiv.org/pdf/2501.06999.pdf</a></span>   <span><a href='https://github.com/lihenryhfl/pcdm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Henry Li, Ronen Basri, Yuval Kluger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06999">Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cascaded models are multi-scale generative models with a marked capacity for producing perceptually impressive samples at high resolutions. In this work, we show that they can also be excellent likelihood models, so long as we overcome a fundamental difficulty with probabilistic multi-scale models: the intractability of the likelihood function. Chiefly, in cascaded models each intermediary scale introduces extraneous variables that cannot be tractably marginalized out for likelihood evaluation. This issue vanishes by modeling the diffusion process on latent spaces induced by a class of transformations we call hierarchical volume-preserving maps, which decompose spatially structured data in a hierarchical fashion without introducing local distortions in the latent space. We demonstrate that two such maps are well-known in the literature for multiscale modeling: Laplacian pyramids and wavelet transforms. Not only do such reparameterizations allow the likelihood function to be directly expressed as a joint likelihood over the scales, we show that the Laplacian pyramid and wavelet transform also produces significant improvements to the state-of-the-art on a selection of benchmarks in likelihood modeling, including density estimation, lossless compression, and out-of-distribution detection. Investigating the theoretical basis of our empirical gains we uncover deep connections to score matching under the Earth Mover's Distance (EMD), which is a well-known surrogate for perceptual similarity. Code can be found at \href{https://github.com/lihenryhfl/pcdm}{this https url}.
<div id='section'>Paperid: <span id='pid'>69, <a href='https://arxiv.org/pdf/2501.05656.pdf' target='_blank'>https://arxiv.org/pdf/2501.05656.pdf</a></span>   <span><a href='https://github.com/FAIR4HEP/PFIN4UQAD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ayush Khot, Xiwei Wang, Avik Roy, Volodymyr Kindratenko, Mark S. Neubauer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05656">Evidential Deep Learning for Uncertainty Quantification and Out-of-Distribution Detection in Jet Identification using Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current methods commonly used for uncertainty quantification (UQ) in deep learning (DL) models utilize Bayesian methods which are computationally expensive and time-consuming. In this paper, we provide a detailed study of UQ based on evidential deep learning (EDL) for deep neural network models designed to identify jets in high energy proton-proton collisions at the Large Hadron Collider and explore its utility in anomaly detection. EDL is a DL approach that treats learning as an evidence acquisition process designed to provide confidence (or epistemic uncertainty) about test data. Using publicly available datasets for jet classification benchmarking, we explore hyperparameter optimizations for EDL applied to the challenge of UQ for jet identification. We also investigate how the uncertainty is distributed for each jet class, how this method can be implemented for the detection of anomalies, how the uncertainty compares with Bayesian ensemble methods, and how the uncertainty maps onto latent spaces for the models. Our studies uncover some pitfalls of EDL applied to anomaly detection and a more effective way to quantify uncertainty from EDL as compared with the foundational EDL setup. These studies illustrate a methodological approach to interpreting EDL in jet classification models, providing new insights on how EDL quantifies uncertainty and detects out-of-distribution data which may lead to improved EDL methods for DL models applied to classification tasks.
<div id='section'>Paperid: <span id='pid'>70, <a href='https://arxiv.org/pdf/2501.02975.pdf' target='_blank'>https://arxiv.org/pdf/2501.02975.pdf</a></span>   <span><a href='https://github.com/Xiaofeng-Tan/MGBOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Gao, Xiaofeng Tan, Jie Zhou, Weiping Ding, Witold Pedrycz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02975">Fuzzy Granule Density-Based Outlier Detection with Multi-Scale Granular Balls</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection refers to the identification of anomalous samples that deviate significantly from the distribution of normal data and has been extensively studied and used in a variety of practical tasks. However, most unsupervised outlier detection methods are carefully designed to detect specified outliers, while real-world data may be entangled with different types of outliers. In this study, we propose a fuzzy rough sets-based multi-scale outlier detection method to identify various types of outliers. Specifically, a novel fuzzy rough sets-based method that integrates relative fuzzy granule density is first introduced to improve the capability of detecting local outliers. Then, a multi-scale view generation method based on granular-ball computing is proposed to collaboratively identify group outliers at different levels of granularity. Moreover, reliable outliers and inliers determined by the three-way decision are used to train a weighted support vector machine to further improve the performance of outlier detection. The proposed method innovatively transforms unsupervised outlier detection into a semi-supervised classification problem and for the first time explores the fuzzy rough sets-based outlier detection from the perspective of multi-scale granular balls, allowing for high adaptability to different types of outliers. Extensive experiments carried out on both artificial and UCI datasets demonstrate that the proposed outlier detection method significantly outperforms the state-of-the-art methods, improving the results by at least 8.48% in terms of the Area Under the ROC Curve (AUROC) index. { The source codes are released at \url{https://github.com/Xiaofeng-Tan/MGBOD}. }
<div id='section'>Paperid: <span id='pid'>71, <a href='https://arxiv.org/pdf/2501.01816.pdf' target='_blank'>https://arxiv.org/pdf/2501.01816.pdf</a></span>   <span><a href='https://github.com/mobei1006/AMY' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hu Ding, Yan Yan, Yang Lu, Jing-Hao Xue, Hanzi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01816">Uncertainty-Aware Label Refinement on Hypergraphs for Personalized Federated Facial Expression Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most facial expression recognition (FER) models are trained on large-scale expression data with centralized learning. Unfortunately, collecting a large amount of centralized expression data is difficult in practice due to privacy concerns of facial images. In this paper, we investigate FER under the framework of personalized federated learning, which is a valuable and practical decentralized setting for real-world applications. To this end, we develop a novel uncertainty-Aware label refineMent on hYpergraphs (AMY) method. For local training, each local model consists of a backbone, an uncertainty estimation (UE) block, and an expression classification (EC) block. In the UE block, we leverage a hypergraph to model complex high-order relationships between expression samples and incorporate these relationships into uncertainty features. A personalized uncertainty estimator is then introduced to estimate reliable uncertainty weights of samples in the local client. In the EC block, we perform label propagation on the hypergraph, obtaining high-quality refined labels for retraining an expression classifier. Based on the above, we effectively alleviate heterogeneous sample uncertainty across clients and learn a robust personalized FER model in each client. Experimental results on two challenging real-world facial expression databases show that our proposed method consistently outperforms several state-of-the-art methods. This indicates the superiority of hypergraph modeling for uncertainty estimation and label refinement on the personalized federated FER task. The source code will be released at https://github.com/mobei1006/AMY.
<div id='section'>Paperid: <span id='pid'>72, <a href='https://arxiv.org/pdf/2412.16884.pdf' target='_blank'>https://arxiv.org/pdf/2412.16884.pdf</a></span>   <span><a href='https://github.com/gmr523/pop' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingrong Gong, Chaoqi Chen, Qingqiang Sun, Yue Wang, Hui Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16884">Out-of-Distribution Detection with Prototypical Outlier Proxy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a crucial task for deploying deep learning models in the wild. One of the major challenges is that well-trained deep models tend to perform over-confidence on unseen test data. Recent research attempts to leverage real or synthetic outliers to mitigate the issue, which may significantly increase computational costs and be biased toward specific outlier characteristics. In this paper, we propose a simple yet effective framework, Prototypical Outlier Proxy (POP), which introduces virtual OOD prototypes to reshape the decision boundaries between ID and OOD data. Specifically, we transform the learnable classifier into a fixed one and augment it with a set of prototypical weight vectors. Then, we introduce a hierarchical similarity boundary loss to impose adaptive penalties depending on the degree of misclassification. Extensive experiments across various benchmarks demonstrate the effectiveness of POP. Notably, POP achieves average FPR95 reductions of 7.70%, 6.30%, and 5.42% over the second-best methods on CIFAR-10, CIFAR-100, and ImageNet-200, respectively. Moreover, compared to the recent method NPOS, which relies on outlier synthesis, POP trains 7.2X faster and performs inference 19.5X faster. The source code is available at: https://github.com/gmr523/pop.
<div id='section'>Paperid: <span id='pid'>73, <a href='https://arxiv.org/pdf/2412.15844.pdf' target='_blank'>https://arxiv.org/pdf/2412.15844.pdf</a></span>   <span><a href='https://github.com/mikkoim/taxonomist-studio' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mikko ImpiÃ¶, Philipp M. Rehsen, Jenni Raitoharju
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15844">Efficient Curation of Invertebrate Image Datasets Using Feature Embeddings and Automatic Size Comparison</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The amount of image datasets collected for environmental monitoring purposes has increased in the past years as computer vision assisted methods have gained interest. Computer vision applications rely on high-quality datasets, making data curation important. However, data curation is often done ad-hoc and the methods used are rarely published. We present a method for curating large-scale image datasets of invertebrates that contain multiple images of the same taxa and/or specimens and have relatively uniform background in the images. Our approach is based on extracting feature embeddings with pretrained deep neural networks, and using these embeddings to find visually most distinct images by comparing their embeddings to the group prototype embedding. Also, we show that a simple area-based size comparison approach is able to find a lot of common erroneous images, such as images containing detached body parts and misclassified samples. In addition to the method, we propose using novel metrics for evaluating human-in-the-loop outlier detection methods. The implementations of the proposed curation methods, as well as a benchmark dataset containing annotated erroneous images, are publicly available in https://github.com/mikkoim/taxonomist-studio.
<div id='section'>Paperid: <span id='pid'>74, <a href='https://arxiv.org/pdf/2412.13394.pdf' target='_blank'>https://arxiv.org/pdf/2412.13394.pdf</a></span>   <span><a href='https://github.com/microsoft/geospatial-ood-detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Burak Ekim, Girmaw Abebe Tadesse, Caleb Robinson, Gilles Hacheme, Michael Schmitt, Rahul Dodhia, Juan M. Lavista Ferres
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13394">Distribution Shifts at Scale: Out-of-distribution Detection in Earth Observation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training robust deep learning models is crucial in Earth Observation, where globally deployed models often face distribution shifts that degrade performance, especially in low-data regions. Out-of-distribution (OOD) detection addresses this by identifying inputs that deviate from in-distribution (ID) data. However, existing methods either assume access to OOD data or compromise primary task performance, limiting real-world use. We introduce TARDIS, a post-hoc OOD detection method designed for scalable geospatial deployment. Our core innovation lies in generating surrogate distribution labels by leveraging ID data within the feature space. TARDIS takes a pre-trained model, ID data, and data from an unknown distribution (WILD), separates WILD into surrogate ID and OOD labels based on internal activations, and trains a binary classifier to detect distribution shifts. We validate on EuroSAT and xBD across 17 setups covering covariate and semantic shifts, showing near-upper-bound surrogate labeling performance in 13 cases and matching the performance of top post-hoc activation- and scoring-based methods. Finally, deploying TARDIS on Fields of the World reveals actionable insights into pre-trained model behavior at scale. The code is available at \href{https://github.com/microsoft/geospatial-ood-detection}{https://github.com/microsoft/geospatial-ood-detection}
<div id='section'>Paperid: <span id='pid'>75, <a href='https://arxiv.org/pdf/2412.12453.pdf' target='_blank'>https://arxiv.org/pdf/2412.12453.pdf</a></span>   <span><a href='https://github.com/thuiar/MIntOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanlei Zhang, Qianrui Zhou, Hua Xu, Jianhua Su, Roberto Evans, Kai Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12453">Multimodal Classification and Out-of-distribution Detection for Multimodal Intent Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal intent understanding is a significant research area that requires effective leveraging of multiple modalities to analyze human language. Existing methods face two main challenges in this domain. Firstly, they have limitations in capturing the nuanced and high-level semantics underlying complex in-distribution (ID) multimodal intents. Secondly, they exhibit poor generalization when confronted with unseen out-of-distribution (OOD) data in real-world scenarios. To address these issues, we propose a novel method for both ID classification and OOD detection (MIntOOD). We first introduce a weighted feature fusion network that models multimodal representations. This network dynamically learns the importance of each modality, adapting to multimodal contexts. To develop discriminative representations for both tasks, we synthesize pseudo-OOD data from convex combinations of ID data and engage in multimodal representation learning from both coarse-grained and fine-grained perspectives. The coarse-grained perspective focuses on distinguishing between ID and OOD binary classes, while the fine-grained perspective not only enhances the discrimination between different ID classes but also captures instance-level interactions between ID and OOD samples, promoting proximity among similar instances and separation from dissimilar ones. We establish baselines for three multimodal intent datasets and build an OOD benchmark. Extensive experiments on these datasets demonstrate that our method significantly improves OOD detection performance with a 3~10% increase in AUROC scores while achieving new state-of-the-art results in ID classification. Data and codes are available at https://github.com/thuiar/MIntOOD.
<div id='section'>Paperid: <span id='pid'>76, <a href='https://arxiv.org/pdf/2412.12154.pdf' target='_blank'>https://arxiv.org/pdf/2412.12154.pdf</a></span>   <span><a href='https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sihan Chen, Zhuangzhuang Qian, Wingchun Siu, Xingcan Hu, Jiaqi Li, Shawn Li, Yuehan Qin, Tiankai Yang, Zhuo Xiao, Wanghao Ye, Yichi Zhang, Yushun Dong, Yue Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12154">PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD), also known as anomaly detection, is a critical machine learning (ML) task with applications in fraud detection, network intrusion detection, clickstream analysis, recommendation systems, and social network moderation. Among open-source libraries for outlier detection, the Python Outlier Detection (PyOD) library is the most widely adopted, with over 8,500 GitHub stars, 25 million downloads, and diverse industry usage. However, PyOD currently faces three limitations: (1) insufficient coverage of modern deep learning algorithms, (2) fragmented implementations across PyTorch and TensorFlow, and (3) no automated model selection, making it hard for non-experts.
  To address these issues, we present PyOD Version 2 (PyOD 2), which integrates 12 state-of-the-art deep learning models into a unified PyTorch framework and introduces a large language model (LLM)-based pipeline for automated OD model selection. These improvements simplify OD workflows, provide access to 45 algorithms, and deliver robust performance on various datasets. In this paper, we demonstrate how PyOD 2 streamlines the deployment and automation of OD models and sets a new standard in both research and industry. PyOD 2 is accessible at [https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod). This study aligns with the Web Mining and Content Analysis track, addressing topics such as the robustness of Web mining methods and the quality of algorithmically-generated Web data.
<div id='section'>Paperid: <span id='pid'>77, <a href='https://arxiv.org/pdf/2412.11466.pdf' target='_blank'>https://arxiv.org/pdf/2412.11466.pdf</a></span>   <span><a href='https://github.com/UESTC-nnLab/MVOL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yutian Lei, Luping Ji, Pei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11466">Mining In-distribution Attributes in Outliers for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is indispensable for deploying reliable machine learning systems in real-world scenarios. Recent works, using auxiliary outliers in training, have shown good potential. However, they seldom concern the intrinsic correlations between in-distribution (ID) and OOD data. In this work, we discover an obvious correlation that OOD data usually possesses significant ID attributes. These attributes should be factored into the training process, rather than blindly suppressed as in previous approaches. Based on this insight, we propose a structured multi-view-based out-of-distribution detection learning (MVOL) framework, which facilitates rational handling of the intrinsic in-distribution attributes in outliers. We provide theoretical insights on the effectiveness of MVOL for OOD detection. Extensive experiments demonstrate the superiority of our framework to others. MVOL effectively utilizes both auxiliary OOD datasets and even wild datasets with noisy in-distribution data. Code is available at https://github.com/UESTC-nnLab/MVOL.
<div id='section'>Paperid: <span id='pid'>78, <a href='https://arxiv.org/pdf/2412.11148.pdf' target='_blank'>https://arxiv.org/pdf/2412.11148.pdf</a></span>   <span><a href='https://github.com/SMSD75/Redefining_Normal_ACCV24/tree/main' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammadreza Salehi, Nikolaos Apostolikas, Efstratios Gavves, Cees G. M. Snoek, Yuki M. Asano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11148">Redefining Normal: A Novel Object-Level Approach for Multi-Object Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the realm of novelty detection, accurately identifying outliers in data without specific class information poses a significant challenge. While current methods excel in single-object scenarios, they struggle with multi-object situations due to their focus on individual objects. Our paper suggests a novel approach: redefining `normal' at the object level in training datasets. Rather than the usual image-level view, we consider the most dominant object in a dataset as the norm, offering a perspective that is more effective for real-world scenarios. Adapting to our object-level definition of `normal', we modify knowledge distillation frameworks, where a student network learns from a pre-trained teacher network. Our first contribution, DeFeND(Dense Feature Fine-tuning on Normal Data), integrates dense feature fine-tuning into the distillation process, allowing the teacher network to focus on object-level features with a self-supervised loss. The second is masked knowledge distillation, where the student network works with partially hidden inputs, honing its ability to deduce and generalize from incomplete data. This approach not only fares well in single-object novelty detection but also considerably surpasses existing methods in multi-object contexts. The implementation is available at: https://github.com/SMSD75/Redefining_Normal_ACCV24/tree/main
<div id='section'>Paperid: <span id='pid'>79, <a href='https://arxiv.org/pdf/2412.08513.pdf' target='_blank'>https://arxiv.org/pdf/2412.08513.pdf</a></span>   <span><a href='https://github.com/Wickstrom/REPEAT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kristoffer K. WickstrÃ¸m, Thea BrÃ¼sch, Michael C. Kampffmeyer, Robert Jenssen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.08513">REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Incorporating uncertainty is crucial to provide trustworthy explanations of deep learning models. Recent works have demonstrated how uncertainty modeling can be particularly important in the unsupervised field of representation learning explainable artificial intelligence (R-XAI). Current R-XAI methods provide uncertainty by measuring variability in the importance score. However, they fail to provide meaningful estimates of whether a pixel is certainly important or not. In this work, we propose a new R-XAI method called REPEAT that addresses the key question of whether or not a pixel is \textit{certainly} important. REPEAT leverages the stochasticity of current R-XAI methods to produce multiple estimates of importance, thus considering each pixel in an image as a Bernoulli random variable that is either important or unimportant. From these Bernoulli random variables we can directly estimate the importance of a pixel and its associated certainty, thus enabling users to determine certainty in pixel importance. Our extensive evaluation shows that REPEAT gives certainty estimates that are more intuitive, better at detecting out-of-distribution data, and more concise.
<div id='section'>Paperid: <span id='pid'>80, <a href='https://arxiv.org/pdf/2412.07169.pdf' target='_blank'>https://arxiv.org/pdf/2412.07169.pdf</a></span>   <span><a href='https://github.com/code-supplement-25/rate-in' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tal Zeevi, Ravid Shwartz-Ziv, Yann LeCun, Lawrence H. Staib, John A. Onofrey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07169">Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty estimation is crucial for deploying neural networks in risk-sensitive applications such as medical diagnosis. Monte Carlo Dropout is a widely used technique for approximating predictive uncertainty by performing stochastic forward passes with dropout during inference. However, using static dropout rates across all layers and inputs can lead to suboptimal uncertainty estimates, as it fails to adapt to the varying characteristics of individual inputs and network layers. Existing approaches optimize dropout rates during training using labeled data, resulting in fixed inference-time parameters that cannot adjust to new data distributions, compromising uncertainty estimates in Monte Carlo simulations.
  In this paper, we propose Rate-In, an algorithm that dynamically adjusts dropout rates during inference by quantifying the information loss induced by dropout in each layer's feature maps. By treating dropout as controlled noise injection and leveraging information-theoretic principles, Rate-In adapts dropout rates per layer and per input instance without requiring ground truth labels. By quantifying the functional information loss in feature maps, we adaptively tune dropout rates to maintain perceptual quality across diverse medical imaging tasks and architectural configurations. Our extensive empirical study on synthetic data and real-world medical imaging tasks demonstrates that Rate-In improves calibration and sharpens uncertainty estimates compared to fixed or heuristic dropout rates without compromising predictive performance. Rate-In offers a practical, unsupervised, inference-time approach to optimizing dropout for more reliable predictive uncertainty estimation in critical applications.
<div id='section'>Paperid: <span id='pid'>81, <a href='https://arxiv.org/pdf/2412.05723.pdf' target='_blank'>https://arxiv.org/pdf/2412.05723.pdf</a></span>   <span><a href='https://github.com/Wang-ML-Lab/bayesian-peft' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haizhou Shi, Yibin Wang, Ligong Han, Huan Zhang, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05723">Training-Free Bayesianization for Low-Rank Adapters of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating the uncertainty of responses from Large Language Models (LLMs) remains a critical challenge. While recent Bayesian methods have demonstrated effectiveness in quantifying uncertainty through low-rank weight updates, they typically require complex fine-tuning or post-training procedures. In this paper, we propose Training-Free Bayesianization (TFB), a simple yet theoretically grounded framework that efficiently transforms trained low-rank adapters into Bayesian ones without additional training. TFB systematically searches for the maximally acceptable level of variance in the weight posterior, constrained within a family of low-rank isotropic Gaussian distributions. Our theoretical analysis shows that under mild conditions, this search process is equivalent to KL-regularized variational optimization, a generalized form of variational inference. Through comprehensive experiments, we show that TFB achieves superior uncertainty estimation and generalization compared to existing methods while eliminating the need for complex Bayesianization training procedures. Code will be available at https://github.com/Wang-ML-Lab/bayesian-peft.
<div id='section'>Paperid: <span id='pid'>82, <a href='https://arxiv.org/pdf/2412.05723.pdf' target='_blank'>https://arxiv.org/pdf/2412.05723.pdf</a></span>   <span><a href='https://github.com/Wang-ML-Lab/bayesian-peft' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haizhou Shi, Yibin Wang, Ligong Han, Huan Zhang, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05723">Training-Free Bayesianization for Low-Rank Adapters of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating the uncertainty of responses from Large Language Models (LLMs) remains a critical challenge. While recent Bayesian methods have demonstrated effectiveness in quantifying uncertainty through low-rank weight updates, they typically require complex fine-tuning or post-training procedures. In this paper, we propose Training-Free Bayesianization (TFB), a simple yet theoretically grounded framework that efficiently transforms trained low-rank adapters into Bayesian ones without additional training. TFB systematically searches for the maximally acceptable level of variance in the weight posterior, constrained within a family of low-rank isotropic Gaussian distributions. Our theoretical analysis shows that under mild conditions, this search process is equivalent to KL-regularized variational optimization, a generalized form of variational inference. Through comprehensive experiments, we show that TFB achieves superior uncertainty estimation and generalization compared to existing methods while eliminating the need for complex Bayesianization training procedures. Code will be available at https://github.com/Wang-ML-Lab/bayesian-peft.
<div id='section'>Paperid: <span id='pid'>83, <a href='https://arxiv.org/pdf/2412.05292.pdf' target='_blank'>https://arxiv.org/pdf/2412.05292.pdf</a></span>   <span><a href='https://github.com/Cverchen/TagFog' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiankang Chen, Tong Zhang, Wei-Shi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05292">TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial in many real-world applications. However, intelligent models are often trained solely on in-distribution (ID) data, leading to overconfidence when misclassifying OOD data as ID classes. In this study, we propose a new learning framework which leverage simple Jigsaw-based fake OOD data and rich semantic embeddings (`anchors') from the ChatGPT description of ID knowledge to help guide the training of the image encoder. The learning framework can be flexibly combined with existing post-hoc approaches to OOD detection, and extensive empirical evaluations on multiple OOD detection benchmarks demonstrate that rich textual representation of ID knowledge and fake OOD knowledge can well help train a visual encoder for OOD detection. With the learning framework, new state-of-the-art performance was achieved on all the benchmarks. The code is available at \url{https://github.com/Cverchen/TagFog}.
<div id='section'>Paperid: <span id='pid'>84, <a href='https://arxiv.org/pdf/2412.04935.pdf' target='_blank'>https://arxiv.org/pdf/2412.04935.pdf</a></span>   <span><a href='https://github.com/niazoys/RLS_PSDF' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Mohaiminul Islam, Coen de Vente, Bart Liefers, Caroline Klaver, Erik J Bekkers, Clara I. SÃ¡nchez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04935">Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a new approach for uncertainty-aware retinal layer segmentation in Optical Coherence Tomography (OCT) scans using probabilistic signed distance functions (SDF). Traditional pixel-wise and regression-based methods primarily encounter difficulties in precise segmentation and lack of geometrical grounding respectively. To address these shortcomings, our methodology refines the segmentation by predicting a signed distance function (SDF) that effectively parameterizes the retinal layer shape via level set. We further enhance the framework by integrating probabilistic modeling, applying Gaussian distributions to encapsulate the uncertainty in the shape parameterization. This ensures a robust representation of the retinal layer morphology even in the presence of ambiguous input, imaging noise, and unreliable segmentations. Both quantitative and qualitative evaluations demonstrate superior performance when compared to other methods. Additionally, we conducted experiments on artificially distorted datasets with various noise types-shadowing, blinking, speckle, and motion-common in OCT scans to showcase the effectiveness of our uncertainty estimation. Our findings demonstrate the possibility to obtain reliable segmentation of retinal layers, as well as an initial step towards the characterization of layer integrity, a key biomarker for disease progression. Our code is available at \url{https://github.com/niazoys/RLS_PSDF}.
<div id='section'>Paperid: <span id='pid'>85, <a href='https://arxiv.org/pdf/2412.04789.pdf' target='_blank'>https://arxiv.org/pdf/2412.04789.pdf</a></span>   <span><a href='https://github.com/CARG-uOttawa/DrIFT.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fardad Dadboud, Hamid Azad, Varun Mehta, Miodrag Bolic, Iraj Mantegh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04789">DrIFT: Autonomous Drone Dataset with Integrated Real and Synthetic Data, Flexible Views, and Transformed Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dependable visual drone detection is crucial for the secure integration of drones into the airspace. However, drone detection accuracy is significantly affected by domain shifts due to environmental changes, varied points of view, and background shifts. To address these challenges, we present the DrIFT dataset, specifically developed for visual drone detection under domain shifts. DrIFT includes fourteen distinct domains, each characterized by shifts in point of view, synthetic-to-real data, season, and adverse weather. DrIFT uniquely emphasizes background shift by providing background segmentation maps to enable background-wise metrics and evaluation. Our new uncertainty estimation metric, MCDO-map, features lower postprocessing complexity, surpassing traditional methods. We use the MCDO-map in our uncertainty-aware unsupervised domain adaptation method, demonstrating superior performance to SOTA unsupervised domain adaptation techniques. The dataset is available at: https://github.com/CARG-uOttawa/DrIFT.git.
<div id='section'>Paperid: <span id='pid'>86, <a href='https://arxiv.org/pdf/2412.02900.pdf' target='_blank'>https://arxiv.org/pdf/2412.02900.pdf</a></span>   <span><a href='https://github.com/vibujithan/macaw-2D.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Vibujithan Vigneshwaran, Erik Ohara, Matthias Wilms, Nils Forkert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02900">MACAW: A Causal Generative Model for Medical Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although deep learning techniques show promising results for many neuroimaging tasks in research settings, they have not yet found widespread use in clinical scenarios. One of the reasons for this problem is that many machine learning models only identify correlations between the input images and the outputs of interest, which can lead to many practical problems, such as encoding of uninformative biases and reduced explainability. Thus, recent research is exploring if integrating a priori causal knowledge into deep learning models is a potential avenue to identify these problems. This work introduces a new causal generative architecture named Masked Causal Flow (MACAW) for neuroimaging applications. Within this context, three main contributions are described. First, a novel approach that integrates complex causal structures into normalizing flows is proposed. Second, counterfactual prediction is performed to identify the changes in effect variables associated with a cause variable. Finally, an explicit Bayesian inference for classification is derived and implemented, providing an inherent uncertainty estimation. The feasibility of the proposed method was first evaluated using synthetic data and then using MRI brain data from more than 23000 participants of the UK biobank study. The evaluation results show that the proposed method can (1) accurately encode causal reasoning and generate counterfactuals highlighting the structural changes in the brain known to be associated with aging, (2) accurately predict a subject's age from a single 2D MRI slice, and (3) generate new samples assuming other values for subject-specific indicators such as age, sex, and body mass index. The code for a toy dataset is available at the following link: https://github.com/vibujithan/macaw-2D.git.
<div id='section'>Paperid: <span id='pid'>87, <a href='https://arxiv.org/pdf/2412.01590.pdf' target='_blank'>https://arxiv.org/pdf/2412.01590.pdf</a></span>   <span><a href='https://github.com/bhattarailab/NCDD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01590">NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of deep learning tools in gastrointestinal vision holds the potential for significant advancements in diagnosis, treatment, and overall patient care. A major challenge, however, is these tools' tendency to make overconfident predictions, even when encountering unseen or newly emerging disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an out-of-distribution (OOD) detection problem, where previously unseen and emerging diseases are identified as OOD examples. However, gastrointestinal images pose a unique challenge due to the overlapping feature representations between in- Distribution (ID) and OOD examples. Existing approaches often overlook this characteristic, as they are primarily developed for natural image datasets, where feature distinctions are more apparent. Despite the overlap, we hypothesize that the features of an in-distribution example will cluster closer to the centroids of their ground truth class, resulting in a shorter distance to the nearest centroid. In contrast, OOD examples maintain an equal distance from all class centroids. Based on this observation, we propose a novel nearest-centroid distance deficit (NCCD) score in the feature space for gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness of our approach compared to several state-of-the-art methods. The code and implementation details are publicly available at: https://github.com/bhattarailab/NCDD
<div id='section'>Paperid: <span id='pid'>88, <a href='https://arxiv.org/pdf/2412.00984.pdf' target='_blank'>https://arxiv.org/pdf/2412.00984.pdf</a></span>   <span><a href='https://github.com/kayzliu/tgtod' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/kayzliu/tgtod' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kay Liu, Jiahao Ding, MohamadAli Torkamani, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00984">TGTOD: A Global Temporal Graph Transformer for Outlier Detection at Scale</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Transformers have revolutionized machine learning on various data, existing Transformers for temporal graphs face limitations in (1) restricted receptive fields, (2) overhead of subgraph extraction, and (3) suboptimal generalization capability beyond link prediction. In this paper, we rethink temporal graph Transformers and propose TGTOD, a novel end-to-end Temporal Graph Transformer for Outlier Detection. TGTOD employs global attention to model both structural and temporal dependencies within temporal graphs. To tackle scalability, our approach divides large temporal graphs into spatiotemporal patches, which are then processed by a hierarchical Transformer architecture comprising Patch Transformer, Cluster Transformer, and Temporal Transformer. We evaluate TGTOD on three public datasets under two settings, comparing with a wide range of baselines. Our experimental results demonstrate the effectiveness of TGTOD, achieving AP improvement of 61% on Elliptic. Furthermore, our efficiency evaluation shows that TGTOD reduces training time by 44x compared to existing Transformers for temporal graphs. To foster reproducibility, we make our implementation publicly available at https://github.com/kayzliu/tgtod.
<div id='section'>Paperid: <span id='pid'>89, <a href='https://arxiv.org/pdf/2411.15736.pdf' target='_blank'>https://arxiv.org/pdf/2411.15736.pdf</a></span>   <span><a href='https://github.com/BaoshunWq/ood-GaCoOp' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Baoshun Tong, Kaiyu Song, Hanjiang Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15736">Enhancing Few-Shot Out-of-Distribution Detection with Gradient Aligned Context Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Few-shot out-of-distribution (OOD) detection aims to detect OOD images from unseen classes with only a few labeled in-distribution (ID) images. To detect OOD images and classify ID samples, prior methods have been proposed by regarding the background regions of ID samples as the OOD knowledge and performing OOD regularization and ID classification optimization. However, the gradient conflict still exists between ID classification optimization and OOD regularization caused by biased recognition. To address this issue, we present Gradient Aligned Context Optimization (GaCoOp) to mitigate this gradient conflict. Specifically, we decompose the optimization gradient to identify the scenario when the conflict occurs. Then we alleviate the conflict in inner ID samples and optimize the prompts via leveraging gradient projection. Extensive experiments over the large-scale ImageNet OOD detection benchmark demonstrate that our GaCoOp can effectively mitigate the conflict and achieve great performance. Code will be available at https://github.com/BaoshunWq/ood-GaCoOp.
<div id='section'>Paperid: <span id='pid'>90, <a href='https://arxiv.org/pdf/2411.13619.pdf' target='_blank'>https://arxiv.org/pdf/2411.13619.pdf</a></span>   <span><a href='https://github.com/LarsDoorenbos/NCIS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Doorenbos, Raphael Sznitman, Pablo MÃ¡rquez-Neila
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13619">Non-Linear Outlier Synthesis for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The reliability of supervised classifiers is severely hampered by their limitations in dealing with unexpected inputs, leading to great interest in out-of-distribution (OOD) detection. Recently, OOD detectors trained on synthetic outliers, especially those generated by large diffusion models, have shown promising results in defining robust OOD decision boundaries. Building on this progress, we present NCIS, which enhances the quality of synthetic outliers by operating directly in the diffusion's model embedding space rather than combining disjoint models as in previous work and by modeling class-conditional manifolds with a conditional volume-preserving network for more expressive characterization of the training distribution. We demonstrate that these improvements yield new state-of-the-art OOD detection results on standard ImageNet100 and CIFAR100 benchmarks and provide insights into the importance of data pre-processing and other key design choices. We make our code available at \url{https://github.com/LarsDoorenbos/NCIS}.
<div id='section'>Paperid: <span id='pid'>91, <a href='https://arxiv.org/pdf/2411.13024.pdf' target='_blank'>https://arxiv.org/pdf/2411.13024.pdf</a></span>   <span><a href='https://github.com/liuhw01/POI' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanwei Liu, Huiling Cai, Qingcheng Lin, Xuefeng Li, Hui Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13024">Prior-based Objective Inference Mining Potential Uncertainty for Facial Expression Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Annotation ambiguity caused by the inherent subjectivity of visual judgment has always been a major challenge for Facial Expression Recognition (FER) tasks, particularly for largescale datasets from in-the-wild scenarios. A potential solution is the evaluation of relatively objective emotional distributions to help mitigate the ambiguity of subjective annotations. To this end, this paper proposes a novel Prior-based Objective Inference (POI) network. This network employs prior knowledge to derive a more objective and varied emotional distribution and tackles the issue of subjective annotation ambiguity through dynamic knowledge transfer. POI comprises two key networks: Firstly, the Prior Inference Network (PIN) utilizes the prior knowledge of AUs and emotions to capture intricate motion details. To reduce over-reliance on priors and facilitate objective emotional inference, PIN aggregates inferential knowledge from various key facial subregions, encouraging mutual learning. Secondly, the Target Recognition Network (TRN) integrates subjective emotion annotations and objective inference soft labels provided by the PIN, fostering an understanding of inherent facial expression diversity, thus resolving annotation ambiguity. Moreover, we introduce an uncertainty estimation module to quantify and balance facial expression confidence. This module enables a flexible approach to dealing with the uncertainties of subjective annotations. Extensive experiments show that POI exhibits competitive performance on both synthetic noisy datasets and multiple real-world datasets. All codes and training logs will be publicly available at https://github.com/liuhw01/POI.
<div id='section'>Paperid: <span id='pid'>92, <a href='https://arxiv.org/pdf/2411.10701.pdf' target='_blank'>https://arxiv.org/pdf/2411.10701.pdf</a></span>   <span><a href='https://github.com/xbyym/DLSR>' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ying Yang, De Cheng, Chaowei Fang, Yubiao Wang, Changzhe Jiao, Lechao Cheng, Nannan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10701">Diffusion-based Layer-wise Semantic Reconstruction for Unsupervised Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised out-of-distribution (OOD) detection aims to identify out-of-domain data by learning only from unlabeled In-Distribution (ID) training samples, which is crucial for developing a safe real-world machine learning system. Current reconstruction-based methods provide a good alternative approach by measuring the reconstruction error between the input and its corresponding generative counterpart in the pixel/feature space. However, such generative methods face a key dilemma: improving the reconstruction power of the generative model while keeping a compact representation of the ID data. To address this issue, we propose the diffusion-based layer-wise semantic reconstruction approach for unsupervised OOD detection. The innovation of our approach is that we leverage the diffusion model's intrinsic data reconstruction ability to distinguish ID samples from OOD samples in the latent feature space. Moreover, to set up a comprehensive and discriminative feature representation, we devise a multi-layer semantic feature extraction strategy. By distorting the extracted features with Gaussian noise and applying the diffusion model for feature reconstruction, the separation of ID and OOD samples is implemented according to the reconstruction errors. Extensive experimental results on multiple benchmarks built upon various datasets demonstrate that our method achieves state-of-the-art performance in terms of detection accuracy and speed. Code is available at <https://github.com/xbyym/DLSR>.
<div id='section'>Paperid: <span id='pid'>93, <a href='https://arxiv.org/pdf/2411.04826.pdf' target='_blank'>https://arxiv.org/pdf/2411.04826.pdf</a></span>   <span><a href='https://github.com/Csyunling/D3epth' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyu Chen, Hong Liu, Wenhao Li, Ying Zhu, Guoquan Wang, Jianbing Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04826">D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic Scenes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Depth estimation is a crucial technology in robotics. Recently, self-supervised depth estimation methods have demonstrated great potential as they can efficiently leverage large amounts of unlabelled real-world data. However, most existing methods are designed under the assumption of static scenes, which hinders their adaptability in dynamic environments. To address this issue, we present D$^3$epth, a novel method for self-supervised depth estimation in dynamic scenes. It tackles the challenge of dynamic objects from two key perspectives. First, within the self-supervised framework, we design a reprojection constraint to identify regions likely to contain dynamic objects, allowing the construction of a dynamic mask that mitigates their impact at the loss level. Second, for multi-frame depth estimation, we introduce a cost volume auto-masking strategy that leverages adjacent frames to identify regions associated with dynamic objects and generate corresponding masks. This provides guidance for subsequent processes. Furthermore, we propose a spectral entropy uncertainty module that incorporates spectral entropy to guide uncertainty estimation during depth fusion, effectively addressing issues arising from cost volume computation in dynamic environments. Extensive experiments on KITTI and Cityscapes datasets demonstrate that the proposed method consistently outperforms existing self-supervised monocular depth estimation baselines. Code is available at \url{https://github.com/Csyunling/D3epth}.
<div id='section'>Paperid: <span id='pid'>94, <a href='https://arxiv.org/pdf/2410.20807.pdf' target='_blank'>https://arxiv.org/pdf/2410.20807.pdf</a></span>   <span><a href='https://github.com/mala-lab/AdaptOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjun Miao, Guansong Pang, Jin Zheng, Xiao Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20807">Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One key challenge in Out-of-Distribution (OOD) detection is the absence of ground-truth OOD samples during training. One principled approach to address this issue is to use samples from external datasets as outliers (i.e., pseudo OOD samples) to train OOD detectors. However, we find empirically that the outlier samples often present a distribution shift compared to the true OOD samples, especially in Long-Tailed Recognition (LTR) scenarios, where ID classes are heavily imbalanced, \ie, the true OOD samples exhibit very different probability distribution to the head and tailed ID classes from the outliers. In this work, we propose a novel approach, namely normalized outlier distribution adaptation (AdaptOD), to tackle this distribution shift problem. One of its key components is dynamic outlier distribution adaptation that effectively adapts a vanilla outlier distribution based on the outlier samples to the true OOD distribution by utilizing the OOD knowledge in the predicted OOD samples during inference. Further, to obtain a more reliable set of predicted OOD samples on long-tailed ID data, a novel dual-normalized energy loss is introduced in AdaptOD, which leverages class- and sample-wise normalized energy to enforce a more balanced prediction energy on imbalanced ID samples. This helps avoid bias toward the head samples and learn a substantially better vanilla outlier distribution than existing energy losses during training. It also eliminates the need of manually tuning the sensitive margin hyperparameters in energy losses. Empirical results on three popular benchmarks for OOD detection in LTR show the superior performance of AdaptOD over state-of-the-art methods. Code is available at https://github.com/mala-lab/AdaptOD.
<div id='section'>Paperid: <span id='pid'>95, <a href='https://arxiv.org/pdf/2410.20631.pdf' target='_blank'>https://arxiv.org/pdf/2410.20631.pdf</a></span>   <span><a href='https://github.com/RanchoGoose/PViT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianhao Zhang, Zhixiang Chen, Lyudmila S. Mihaylova
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20631">PViT: Prior-augmented Vision Transformer for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision Transformers (ViTs) have achieved remarkable success over various vision tasks, yet their robustness against data distribution shifts and inherent inductive biases remain underexplored. To enhance the robustness of ViT models for image Out-of-Distribution (OOD) detection, we introduce a novel and generic framework named Prior-augmented Vision Transformer (PViT). Taking as input the prior class logits from a pretrained model, we train PViT to predict the class logits. During inference, PViT identifies OOD samples by quantifying the divergence between the predicted class logits and the prior logits obtained from pre-trained models. Unlike existing state-of-the-art(SOTA) OOD detection methods, PViT shapes the decision boundary between ID and OOD by utilizing the proposed prior guided confidence, without requiring additional data modeling, generation methods, or structural modifications. Extensive experiments on the large-scale ImageNet benchmark, evaluated against over seven OOD datasets, demonstrate that PViT significantly outperforms existing SOTA OOD detection methods in terms of FPR95 and AUROC. The codebase is publicly available at https://github.com/RanchoGoose/PViT.
<div id='section'>Paperid: <span id='pid'>96, <a href='https://arxiv.org/pdf/2410.14975.pdf' target='_blank'>https://arxiv.org/pdf/2410.14975.pdf</a></span>   <span><a href='https://github.com/daintlab/ReGuide' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jihyo Kim, Seulbi Lee, Sangheum Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14975">Reflexive Guidance: Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the recent emergence of foundation models trained on internet-scale data and demonstrating remarkable generalization capabilities, such foundation models have become more widely adopted, leading to an expanding range of application domains. Despite this rapid proliferation, the trustworthiness of foundation models remains underexplored. Specifically, the out-of-distribution detection (OoDD) capabilities of large vision-language models (LVLMs), such as GPT-4o, which are trained on massive multi-modal data, have not been sufficiently addressed. The disparity between their demonstrated potential and practical reliability raises concerns regarding the safe and trustworthy deployment of foundation models. To address this gap, we evaluate and analyze the OoDD capabilities of various proprietary and open-source LVLMs. Our investigation contributes to a better understanding of how these foundation models represent confidence scores through their generated natural language responses. Furthermore, we propose a self-guided prompting approach, termed Reflexive Guidance (ReGuide), aimed at enhancing the OoDD capability of LVLMs by leveraging self-generated image-adaptive concept suggestions. Experimental results demonstrate that our ReGuide enhances the performance of current LVLMs in both image classification and OoDD tasks. The lists of sampled images, along with the prompts and responses for each sample are available at https://github.com/daintlab/ReGuide.
<div id='section'>Paperid: <span id='pid'>97, <a href='https://arxiv.org/pdf/2410.13338.pdf' target='_blank'>https://arxiv.org/pdf/2410.13338.pdf</a></span>   <span><a href='https://github.com/decisionintelligence/SSD-TS/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongfan Gao, Wangmeng Shen, Xiangfei Qiu, Ronghui Xu, Jilin Hu, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13338">SSD-TS: Exploring the Potential of Linear State Space Models for Diffusion Models in Time Series Imputation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Probabilistic time series imputation has been widely applied in real-world scenarios due to its ability for uncertainty estimation and denoising diffusion probabilistic models~(DDPMs) have achieved great success in probabilistic time series imputation tasks with its power to model complex distributions. However, current DDPM-based probabilistic time series imputation methodologies are confronted with two types of challenges: 1)\textit{The backbone modules of the denoising parts are not capable of achieving sequence modeling with low time complexity.} 2)~\textit{The architecture of denoising modules can not handle the dependencies in the time series data effectively.} To address the first challenge, we explore the potential of state space model, namely Mamba, as the backbone denoising module for DDPMs. To tackle the second challenge, we carefully devise several SSM-based blocks for time series data modeling. Experimental results demonstrate that our approach can achieve state-of-the-art time series imputation results on multiple real-world datasets. Our datasets and code are available at \href{https://github.com/decisionintelligence/SSD-TS/}{https://github.com/decisionintelligence/SSD-TS/}
<div id='section'>Paperid: <span id='pid'>98, <a href='https://arxiv.org/pdf/2410.11576.pdf' target='_blank'>https://arxiv.org/pdf/2410.11576.pdf</a></span>   <span><a href='https://github.com/QingyangZhang/DUL' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/QingyangZhang/DUL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingyang Zhang, Qiuxuan Feng, Joey Tianyi Zhou, Yatao Bian, Qinghua Hu, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.11576">The Best of Both Worlds: On the Dilemma of Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for model trustworthiness which aims to sensitively identify semantic OOD samples and robustly generalize for covariate-shifted OOD samples. However, we discover that the superior OOD detection performance of state-of-the-art methods is achieved by secretly sacrificing the OOD generalization ability. Specifically, the classification accuracy of these models could deteriorate dramatically when they encounter even minor noise. This phenomenon contradicts the goal of model trustworthiness and severely restricts their applicability in real-world scenarios. What is the hidden reason behind such a limitation? In this work, we theoretically demystify the ``\textit{sensitive-robust}'' dilemma that lies in many existing OOD detection methods. Consequently, a theory-inspired algorithm is induced to overcome such a dilemma. By decoupling the uncertainty learning objective from a Bayesian perspective, the conflict between OOD detection and OOD generalization is naturally harmonized and a dual-optimal performance could be expected. Empirical studies show that our method achieves superior performance on standard benchmarks. To our best knowledge, this work is the first principled OOD detection method that achieves state-of-the-art OOD detection performance without compromising OOD generalization ability. Our code is available at \href{https://github.com/QingyangZhang/DUL}{https://github.com/QingyangZhang/DUL}.
<div id='section'>Paperid: <span id='pid'>99, <a href='https://arxiv.org/pdf/2410.10744.pdf' target='_blank'>https://arxiv.org/pdf/2410.10744.pdf</a></span>   <span><a href='https://github.com/AdaptiveMotorControlLab/AROS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mackenzie W. Mathis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10744">Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite significant advancements in out-of-distribution (OOD) detection, existing methods still struggle to maintain robustness against adversarial attacks, compromising their reliability in critical real-world applications. Previous studies have attempted to address this challenge by exposing detectors to auxiliary OOD datasets alongside adversarial training. However, the increased data complexity inherent in adversarial training, and the myriad of ways that OOD samples can arise during testing, often prevent these approaches from establishing robust decision boundaries. To address these limitations, we propose AROS, a novel approach leveraging neural ordinary differential equations (NODEs) with Lyapunov stability theorem in order to obtain robust embeddings for OOD detection. By incorporating a tailored loss function, we apply Lyapunov stability theory to ensure that both in-distribution (ID) and OOD data converge to stable equilibrium points within the dynamical system. This approach encourages any perturbed input to return to its stable equilibrium, thereby enhancing the model's robustness against adversarial perturbations. To not use additional data, we generate fake OOD embeddings by sampling from low-likelihood regions of the ID data feature space, approximating the boundaries where OOD data are likely to reside. To then further enhance robustness, we propose the use of an orthogonal binary layer following the stable feature space, which maximizes the separation between the equilibrium points of ID and OOD samples. We validate our method through extensive experiments across several benchmarks, demonstrating superior performance, particularly under adversarial attacks. Notably, our approach improves robust detection performance from 37.8% to 80.1% on CIFAR-10 vs. CIFAR-100 and from 29.0% to 67.0% on CIFAR-100 vs. CIFAR-10.
<div id='section'>Paperid: <span id='pid'>100, <a href='https://arxiv.org/pdf/2410.09299.pdf' target='_blank'>https://arxiv.org/pdf/2410.09299.pdf</a></span>   <span><a href='https://github.com/HuXiaoling/Regre4Regis' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoling Hu, Karthik Gopinath, Peirong Liu, Malte Hoffmann, Koen Van Leemput, Oula Puonti, Juan Eugenio Iglesias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09299">Hierarchical Uncertainty Estimation for Learning-based Registration in Neuroimaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over recent years, deep learning based image registration has achieved impressive accuracy in many domains, including medical imaging and, specifically, human neuroimaging with magnetic resonance imaging (MRI). However, the uncertainty estimation associated with these methods has been largely limited to the application of generic techniques (e.g., Monte Carlo dropout) that do not exploit the peculiarities of the problem domain, particularly spatial modeling. Here, we propose a principled way to propagate uncertainties (epistemic or aleatoric) estimated at the level of spatial location by these methods, to the level of global transformation models, and further to downstream tasks. Specifically, we justify the choice of a Gaussian distribution for the local uncertainty modeling, and then propose a framework where uncertainties spread across hierarchical levels, depending on the choice of transformation model. Experiments on publicly available data sets show that Monte Carlo dropout correlates very poorly with the reference registration error, whereas our uncertainty estimates correlate much better. Crucially, the results also show that uncertainty-aware fitting of transformations improves the registration accuracy of brain MRI scans. Finally, we illustrate how sampling from the posterior distribution of the transformations can be used to propagate uncertainties to downstream neuroimaging tasks. Code is available at: https://github.com/HuXiaoling/Regre4Regis.
<div id='section'>Paperid: <span id='pid'>101, <a href='https://arxiv.org/pdf/2410.07185.pdf' target='_blank'>https://arxiv.org/pdf/2410.07185.pdf</a></span>   <span><a href='https://github.com/lakpa-tamang9/margin_ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lakpa D. Tamang, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07185">Margin-bounded Confidence Scores for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many critical Machine Learning applications, such as autonomous driving and medical image diagnosis, the detection of out-of-distribution (OOD) samples is as crucial as accurately classifying in-distribution (ID) inputs. Recently Outlier Exposure (OE) based methods have shown promising results in detecting OOD inputs via model fine-tuning with auxiliary outlier data. However, most of the previous OE-based approaches emphasize more on synthesizing extra outlier samples or introducing regularization to diversify OOD sample space, which is rather unquantifiable in practice. In this work, we propose a novel and straightforward method called Margin bounded Confidence Scores (MaCS) to address the nontrivial OOD detection problem by enlarging the disparity between ID and OOD scores, which in turn makes the decision boundary more compact facilitating effective segregation with a simple threshold. Specifically, we augment the learning objective of an OE regularized classifier with a supplementary constraint, which penalizes high confidence scores for OOD inputs compared to that of ID and significantly enhances the OOD detection performance while maintaining the ID classification accuracy. Extensive experiments on various benchmark datasets for image classification tasks demonstrate the effectiveness of the proposed method by significantly outperforming state-of-the-art (S.O.T.A) methods on various benchmarking metrics. The code is publicly available at https://github.com/lakpa-tamang9/margin_ood
<div id='section'>Paperid: <span id='pid'>102, <a href='https://arxiv.org/pdf/2410.04525.pdf' target='_blank'>https://arxiv.org/pdf/2410.04525.pdf</a></span>   <span><a href='https://github.com/berkerdemirel/ORA-OOD-Detection-with-Relative-Angles' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Berker Demirel, Marco Fumero, Francesco Locatello
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04525">Out-of-Distribution Detection with Relative Angles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning systems deployed in real-world applications often encounter data that is different from their in-distribution (ID). A reliable model should ideally abstain from making decisions in this out-of-distribution (OOD) setting. Existing state-of-the-art methods primarily focus on feature distances, such as k-th nearest neighbors and distances to decision boundaries, either overlooking or ineffectively using in-distribution statistics. In this work, we propose a novel angle-based metric for OOD detection that is computed relative to the in-distribution structure. We demonstrate that the angles between feature representations and decision boundaries, viewed from the mean of in-distribution features, serve as an effective discriminative factor between ID and OOD data. We evaluate our method on nine ImageNet-pretrained models. Our approach achieves the lowest FPR in 5 out of 9 ImageNet models, obtains the best average FPR overall, and consistently ranking among the top 3 across all evaluated models. Furthermore, we highlight the benefits of contrastive representations by showing strong performance with ResNet SCL and CLIP architectures. Finally, we demonstrate that the scale-invariant nature of our score enables an ensemble strategy via simple score summation. Code is available at https://github.com/berkerdemirel/ORA-OOD-Detection-with-Relative-Angles.
<div id='section'>Paperid: <span id='pid'>103, <a href='https://arxiv.org/pdf/2410.00393.pdf' target='_blank'>https://arxiv.org/pdf/2410.00393.pdf</a></span>   <span><a href='https://github.com/MengyuanChen21/Re-EDL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengyuan Chen, Junyu Gao, Changsheng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00393">Revisiting Essential and Nonessential Settings of Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evidential Deep Learning (EDL) is an emerging method for uncertainty estimation that provides reliable predictive uncertainty in a single forward pass, attracting significant attention. Grounded in subjective logic, EDL derives Dirichlet concentration parameters from neural networks to construct a Dirichlet probability density function (PDF), modeling the distribution of class probabilities. Despite its success, EDL incorporates several nonessential settings: In model construction, (1) a commonly ignored prior weight parameter is fixed to the number of classes, while its value actually impacts the balance between the proportion of evidence and its magnitude in deriving predictive scores. In model optimization, (2) the empirical risk features a variance-minimizing optimization term that biases the PDF towards a Dirac delta function, potentially exacerbating overconfidence. (3) Additionally, the structural risk typically includes a KL-divergence-minimizing regularization, whose optimization direction extends beyond the intended purpose and contradicts common sense, diminishing the information carried by the evidence magnitude. Therefore, we propose Re-EDL, a simplified yet more effective variant of EDL, by relaxing the nonessential settings and retaining the essential one, namely, the adoption of projected probability from subjective logic. Specifically, Re-EDL treats the prior weight as an adjustable hyperparameter rather than a fixed scalar, and directly optimizes the expectation of the Dirichlet PDF provided by deprecating both the variance-minimizing optimization term and the divergence regularization term. Extensive experiments and state-of-the-art performance validate the effectiveness of our method. The source code is available at https://github.com/MengyuanChen21/Re-EDL.
<div id='section'>Paperid: <span id='pid'>104, <a href='https://arxiv.org/pdf/2409.19840.pdf' target='_blank'>https://arxiv.org/pdf/2409.19840.pdf</a></span>   <span><a href='https://github.com/Saehyung-Lee/HFTT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saehyung Lee, Jisoo Mok, Sangha Park, Yongho Shin, Dahuin Jung, Sungroh Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19840">Textual Training for the Hassle-Free Removal of Unwanted Visual Data: Case Studies on OOD and Hateful Image Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In our study, we explore methods for detecting unwanted content lurking in visual datasets. We provide a theoretical analysis demonstrating that a model capable of successfully partitioning visual data can be obtained using only textual data. Based on the analysis, we propose Hassle-Free Textual Training (HFTT), a streamlined method capable of acquiring detectors for unwanted visual content, using only synthetic textual data in conjunction with pre-trained vision-language models. HFTT features an innovative objective function that significantly reduces the necessity for human involvement in data annotation. Furthermore, HFTT employs a clever textual data synthesis method, effectively emulating the integration of unknown visual data distribution into the training process at no extra cost. The unique characteristics of HFTT extend its utility beyond traditional out-of-distribution detection, making it applicable to tasks that address more abstract concepts. We complement our analyses with experiments in out-of-distribution detection and hateful image detection. Our codes are available at https://github.com/Saehyung-Lee/HFTT
<div id='section'>Paperid: <span id='pid'>105, <a href='https://arxiv.org/pdf/2409.19370.pdf' target='_blank'>https://arxiv.org/pdf/2409.19370.pdf</a></span>   <span><a href='https://github.com/GtLinyer/MambaEviScrib' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoxiang Han, Xinyu Li, Jiang Shang, Yiman Liu, Keyan Chen, Shugong Xu, Qiaohong Liu, Qi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19370">MambaEviScrib: Mamba and Evidence-Guided Consistency Enhance CNN Robustness for Scribble-Based Weakly Supervised Ultrasound Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Segmenting anatomical structures and lesions from ultrasound images contributes to disease assessment. Weakly supervised learning (WSL) based on sparse annotation has achieved encouraging performance and demonstrated the potential to reduce annotation costs. This study attempts to introduce scribble-based WSL into ultrasound image segmentation tasks. However, ultrasound images often suffer from poor contrast and unclear edges, coupled with insufficient supervison signals for edges, posing challenges to edge prediction. Uncertainty modeling has been proven to facilitate models in dealing with these issues. Nevertheless, existing uncertainty estimation paradigms are not robust enough and often filter out predictions near decision boundaries, resulting in unstable edge predictions. Therefore, we propose leveraging predictions near decision boundaries effectively. Specifically, we introduce Dempster-Shafer Theory (DST) of evidence to design an Evidence-Guided Consistency strategy. This strategy utilizes high-evidence predictions, which are more likely to occur near high-density regions, to guide the optimization of low-evidence predictions that may appear near decision boundaries. Furthermore, the diverse sizes and locations of lesions in ultrasound images pose a challenge for CNNs with local receptive fields, as they struggle to model global information. Therefore, we introduce Visual Mamba based on structured state space sequence models, which achieves long-range dependency with linear computational complexity, and we construct a novel hybrid CNN-Mamba framework. During training, the collaboration between the CNN branch and the Mamba branch in the proposed framework draws inspiration from each other based on the EGC strategy. Experiments demonstrate the competitiveness of the proposed method. Dataset and code will be available on https://github.com/GtLinyer/MambaEviScrib.
<div id='section'>Paperid: <span id='pid'>106, <a href='https://arxiv.org/pdf/2409.17485.pdf' target='_blank'>https://arxiv.org/pdf/2409.17485.pdf</a></span>   <span><a href='https://github.com/Rubiscol/D2UE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Gu, Yi Lin, Kwang-Ting Cheng, Hao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17485">Revisiting Deep Ensemble Uncertainty for Enhanced Medical Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical anomaly detection (AD) is crucial in pathological identification and localization. Current methods typically rely on uncertainty estimation in deep ensembles to detect anomalies, assuming that ensemble learners should agree on normal samples while exhibiting disagreement on unseen anomalies in the output space. However, these methods may suffer from inadequate disagreement on anomalies or diminished agreement on normal samples. To tackle these issues, we propose D2UE, a Diversified Dual-space Uncertainty Estimation framework for medical anomaly detection. To effectively balance agreement and disagreement for anomaly detection, we propose Redundancy-Aware Repulsion (RAR), which uses a similarity kernel that remains invariant to both isotropic scaling and orthogonal transformations, explicitly promoting diversity in learners' feature space. Moreover, to accentuate anomalous regions, we develop Dual-Space Uncertainty (DSU), which utilizes the ensemble's uncertainty in input and output spaces. In input space, we first calculate gradients of reconstruction error with respect to input images. The gradients are then integrated with reconstruction outputs to estimate uncertainty for inputs, enabling effective anomaly discrimination even when output space disagreement is minimal. We conduct a comprehensive evaluation of five medical benchmarks with different backbones. Experimental results demonstrate the superiority of our method to state-of-the-art methods and the effectiveness of each component in our framework. Our code is available at https://github.com/Rubiscol/D2UE.
<div id='section'>Paperid: <span id='pid'>107, <a href='https://arxiv.org/pdf/2409.11884.pdf' target='_blank'>https://arxiv.org/pdf/2409.11884.pdf</a></span>   <span><a href='https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Lu, Yingsheng Wang, Lijun Sheng, Lingxiao He, Aihua Zheng, Jian Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11884">Out-of-Distribution Detection: A Task-Oriented Survey of Recent Advances</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection aims to detect test samples outside the training category space, which is an essential component in building reliable machine learning systems. Existing reviews on OOD detection primarily focus on method taxonomy, surveying the field by categorizing various approaches. However, many recent works concentrate on non-traditional OOD detection scenarios, such as test-time adaptation, multi-modal data sources and other novel contexts. In this survey, we uniquely review recent advances in OOD detection from the task-oriented perspective for the first time. According to the user's access to the model, that is, whether the OOD detection method is allowed to modify or retrain the model, we classify the methods as training-driven or training-agnostic. Besides, considering the rapid development of pre-trained models, large pre-trained model-based OOD detection is also regarded as an important category and discussed separately. Furthermore, we provide a discussion of the evaluation scenarios, a variety of applications, and several future research directions. We believe this survey with new taxonomy will benefit the proposal of new methods and the expansion of more practical scenarios. A curated list of related papers is provided in the Github repository: https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection.
<div id='section'>Paperid: <span id='pid'>108, <a href='https://arxiv.org/pdf/2409.10044.pdf' target='_blank'>https://arxiv.org/pdf/2409.10044.pdf</a></span>   <span><a href='https://github.com/0Frett/PO-Uncertainty-Benchmarking' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10044">Benchmarking Large Language Model Uncertainty for Prompt Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prompt optimization algorithms for Large Language Models (LLMs) excel in multi-step reasoning but still lack effective uncertainty estimation. This paper introduces a benchmark dataset to evaluate uncertainty metrics, focusing on Answer, Correctness, Aleatoric, and Epistemic Uncertainty. Through analysis of models like GPT-3.5-Turbo and Meta-Llama-3.1-8B-Instruct, we show that current metrics align more with Answer Uncertainty, which reflects output confidence and diversity, rather than Correctness Uncertainty, highlighting the need for improved metrics that are optimization-objective-aware to better guide prompt optimization. Our code and dataset are available at https://github.com/0Frett/PO-Uncertainty-Benchmarking.
<div id='section'>Paperid: <span id='pid'>109, <a href='https://arxiv.org/pdf/2409.08946.pdf' target='_blank'>https://arxiv.org/pdf/2409.08946.pdf</a></span>   <span><a href='https://github.com/goose315/DELTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pengyun Wang, Yadi Cao, Chris Russell, Yanxin Shen, Junyu Luo, Ming Zhang, Siyu Heng, Xiao Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08946">DELTA: Dual Consistency Delving with Topological Uncertainty for Active Graph Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph domain adaptation has recently enabled knowledge transfer across different graphs. However, without the semantic information on target graphs, the performance on target graphs is still far from satisfactory. To address the issue, we study the problem of active graph domain adaptation, which selects a small quantitative of informative nodes on the target graph for extra annotation. This problem is highly challenging due to the complicated topological relationships and the distribution discrepancy across graphs. In this paper, we propose a novel approach named Dual Consistency Delving with Topological Uncertainty (DELTA) for active graph domain adaptation. Our DELTA consists of an edge-oriented graph subnetwork and a path-oriented graph subnetwork, which can explore topological semantics from complementary perspectives. In particular, our edge-oriented graph subnetwork utilizes the message passing mechanism to learn neighborhood information, while our path-oriented graph subnetwork explores high-order relationships from sub-structures. To jointly learn from two subnetworks, we roughly select informative candidate nodes with the consideration of consistency across two subnetworks. Then, we aggregate local semantics from its K-hop subgraph based on node degrees for topological uncertainty estimation. To overcome potential distribution shifts, we compare target nodes and their corresponding source nodes for discrepancy scores as an additional component for fine selection. Extensive experiments on benchmark datasets demonstrate that DELTA outperforms various state-of-the-art approaches. The code implementation of DELTA is available at https://github.com/goose315/DELTA.
<div id='section'>Paperid: <span id='pid'>110, <a href='https://arxiv.org/pdf/2409.05672.pdf' target='_blank'>https://arxiv.org/pdf/2409.05672.pdf</a></span>   <span><a href='https://github.com/A-Chicharito-S/FoMo-0D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchen Shen, Haomin Wen, Leman Akoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.05672">FoMo-0D: A Foundation Model for Zero-shot Tabular Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) has a vast literature as it finds numerous real-world applications. Being an unsupervised task, model selection is a key bottleneck for OD without label supervision. Despite a long list of available OD algorithms with tunable hyperparameters, the lack of systematic approaches for unsupervised algorithm and hyperparameter selection limits their effective use in practice. In this paper, we present FoMo-0D, a pre-trained Foundation Model for zero/0-shot OD on tabular data, which bypasses the hurdle of model selection altogether. Having been pre-trained on synthetic data, FoMo-0D can directly predict the (outlier/inlier) label of test samples without parameter fine-tuning -- requiring no labeled data, and no additional training or hyperparameter tuning when given a new task. Extensive experiments on 57 real-world datasets against 26 baselines show that FoMo-0D is highly competitive; outperforming the majority of the baselines with no statistically significant difference from the 2nd best method. Further, FoMo-0D is efficient in inference time requiring only 7.7 ms per sample on average, with at least 7x speed-up compared to previous methods. To facilitate future research, our implementations for data synthesis and pre-training as well as model checkpoints are openly available at https://github.com/A-Chicharito-S/FoMo-0D.
<div id='section'>Paperid: <span id='pid'>111, <a href='https://arxiv.org/pdf/2409.04796.pdf' target='_blank'>https://arxiv.org/pdf/2409.04796.pdf</a></span>   <span><a href='https://github.com/AuroraZengfh/Local-Prompt' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/AuroraZengfh/Local-Prompt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fanhu Zeng, Zhen Cheng, Fei Zhu, Hongxin Wei, Xu-Yao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04796">Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection, aiming to distinguish outliers from known categories, has gained prominence in practical scenarios. Recently, the advent of vision-language models (VLM) has heightened interest in enhancing OOD detection for VLM through few-shot tuning. However, existing methods mainly focus on optimizing global prompts, ignoring refined utilization of local information with regard to outliers. Motivated by this, we freeze global prompts and introduce Local-Prompt, a novel coarse-to-fine tuning paradigm to emphasize regional enhancement with local prompts. Our method comprises two integral components: global prompt guided negative augmentation and local prompt enhanced regional regularization. The former utilizes frozen, coarse global prompts as guiding cues to incorporate negative augmentation, thereby leveraging local outlier knowledge. The latter employs trainable local prompts and a regional regularization to capture local information effectively, aiding in outlier identification. We also propose regional-related metric to empower the enrichment of OOD detection. Moreover, since our approach explores enhancing local prompts only, it can be seamlessly integrated with trained global prompts during inference to boost the performance. Comprehensive experiments demonstrate the effectiveness and potential of our method. Notably, our method reduces average FPR95 by 5.17% against state-of-the-art method in 4-shot tuning on challenging ImageNet-1k dataset, even outperforming 16-shot results of previous methods. Code is released at https://github.com/AuroraZengfh/Local-Prompt.
<div id='section'>Paperid: <span id='pid'>112, <a href='https://arxiv.org/pdf/2409.02917.pdf' target='_blank'>https://arxiv.org/pdf/2409.02917.pdf</a></span>   <span><a href='https://github.com/wrld/UC-NeRF' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Guo, Jiangliu Wang, Ruofeng Wei, Di Kang, Qi Dou, Yun-hui Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02917">UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visualizing surgical scenes is crucial for revealing internal anatomical structures during minimally invasive procedures. Novel View Synthesis is a vital technique that offers geometry and appearance reconstruction, enhancing understanding, planning, and decision-making in surgical scenes. Despite the impressive achievements of Neural Radiance Field (NeRF), its direct application to surgical scenes produces unsatisfying results due to two challenges: endoscopic sparse views and significant photometric inconsistencies. In this paper, we propose uncertainty-aware conditional NeRF for novel view synthesis to tackle the severe shape-radiance ambiguity from sparse surgical views. The core of UC-NeRF is to incorporate the multi-view uncertainty estimation to condition the neural radiance field for modeling the severe photometric inconsistencies adaptively. Specifically, our UC-NeRF first builds a consistency learner in the form of multi-view stereo network, to establish the geometric correspondence from sparse views and generate uncertainty estimation and feature priors. In neural rendering, we design a base-adaptive NeRF network to exploit the uncertainty estimation for explicitly handling the photometric inconsistencies. Furthermore, an uncertainty-guided geometry distillation is employed to enhance geometry learning. Experiments on the SCARED and Hamlyn datasets demonstrate our superior performance in rendering appearance and geometry, consistently outperforming the current state-of-the-art approaches. Our code will be released at https://github.com/wrld/UC-NeRF.
<div id='section'>Paperid: <span id='pid'>113, <a href='https://arxiv.org/pdf/2408.16757.pdf' target='_blank'>https://arxiv.org/pdf/2408.16757.pdf</a></span>   <span><a href='https://github.com/Visual-AI/Dissect-OOD-OSR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongjun Wang, Sagar Vaze, Kai Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16757">Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting test-time distribution shift has emerged as a key capability for safely deployed machine learning models, with the question being tackled under various guises in recent years. In this paper, we aim to provide a consolidated view of the two largest sub-fields within the community: out-of-distribution (OOD) detection and open-set recognition (OSR). In particular, we aim to provide rigorous empirical analysis of different methods across settings and provide actionable takeaways for practitioners and researchers. Concretely, we make the following contributions: (i) We perform rigorous cross-evaluation between state-of-the-art methods in the OOD detection and OSR settings and identify a strong correlation between the performances of methods for them; (ii) We propose a new, large-scale benchmark setting which we suggest better disentangles the problem tackled by OOD detection and OSR, re-evaluating state-of-the-art OOD detection and OSR methods in this setting; (iii) We surprisingly find that the best performing method on standard benchmarks (Outlier Exposure) struggles when tested at scale, while scoring rules which are sensitive to the deep feature magnitude consistently show promise; and (iv) We conduct empirical analysis to explain these phenomena and highlight directions for future research. Code: https://github.com/Visual-AI/Dissect-OOD-OSR
<div id='section'>Paperid: <span id='pid'>114, <a href='https://arxiv.org/pdf/2408.16115.pdf' target='_blank'>https://arxiv.org/pdf/2408.16115.pdf</a></span>   <span><a href='https://github.com/Richard-Bergna/GraphNeuralSDE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Richard Bergna, Sergio Calvo-Ordoñez, Felix L. Opolka, Pietro Liò, Jose Miguel Hernandez-Lobato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16115">Uncertainty Modeling in Graph Neural Networks via Stochastic Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel Stochastic Differential Equation (SDE) framework to address the problem of learning uncertainty-aware representations for graph-structured data. While Graph Neural Ordinary Differential Equations (GNODEs) have shown promise in learning node representations, they lack the ability to quantify uncertainty. To address this, we introduce Latent Graph Neural Stochastic Differential Equations (LGNSDE), which enhance GNODE by embedding randomness through a Bayesian prior-posterior mechanism for epistemic uncertainty and Brownian motion for aleatoric uncertainty. By leveraging the existence and uniqueness of solutions to graph-based SDEs, we prove that the variance of the latent space bounds the variance of model outputs, thereby providing theoretically sensible guarantees for the uncertainty estimates. Furthermore, we show mathematically that LGNSDEs are robust to small perturbations in the input, maintaining stability over time. Empirical results across several benchmarks demonstrate that our framework is competitive in out-of-distribution detection, robustness to noise, and active learning, underscoring the ability of LGNSDEs to quantify uncertainty reliably. Code is available at \href{https://github.com/Richard-Bergna/GraphNeuralSDE}{\texttt{github.com/Richard-Bergna/GraphNeuralSDE}}.
<div id='section'>Paperid: <span id='pid'>115, <a href='https://arxiv.org/pdf/2408.10798.pdf' target='_blank'>https://arxiv.org/pdf/2408.10798.pdf</a></span>   <span><a href='https://github.com/mojtaba-nafez/UNODE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Mirzaei, Mojtaba Nafez, Mohammad Jafari, Mohammad Bagher Soltani, Mohammad Azizmalayeri, Jafar Habibi, Mohammad Sabokrou, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10798">Universal Novelty Detection Through Adaptive Contrastive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty detection is a critical task for deploying machine learning models in the open world. A crucial property of novelty detection methods is universality, which can be interpreted as generalization across various distributions of training or test data. More precisely, for novelty detection, distribution shifts may occur in the training set or the test set. Shifts in the training set refer to cases where we train a novelty detector on a new dataset and expect strong transferability. Conversely, distribution shifts in the test set indicate the methods' performance when the trained model encounters a shifted test sample. We experimentally show that existing methods falter in maintaining universality, which stems from their rigid inductive biases. Motivated by this, we aim for more generalized techniques that have more adaptable inductive biases. In this context, we leverage the fact that contrastive learning provides an efficient framework to easily switch and adapt to new inductive biases through the proper choice of augmentations in forming the negative pairs. We propose a novel probabilistic auto-negative pair generation method AutoAugOOD, along with contrastive learning, to yield a universal novelty detector method. Our experiments demonstrate the superiority of our method under different distribution shifts in various image benchmark datasets. Notably, our method emerges universality in the lens of adaptability to different setups of novelty detection, including one-class, unlabeled multi-class, and labeled multi-class settings. Code: https://github.com/mojtaba-nafez/UNODE
<div id='section'>Paperid: <span id='pid'>116, <a href='https://arxiv.org/pdf/2408.10676.pdf' target='_blank'>https://arxiv.org/pdf/2408.10676.pdf</a></span>   <span><a href='https://github.com/dgshin21/RNA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dong Geun Shin, Hye Won Chung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10676">Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is a critical task for reliable machine learning. However, it becomes particularly challenging when the models are trained on long-tailed datasets, as the models often struggle to distinguish tail-class in-distribution samples from OOD samples. We examine the main challenges in this problem by identifying the trade-offs between OOD detection and in-distribution (ID) classification, faced by existing methods. We then introduce our method, called \textit{Representation Norm Amplification} (RNA), which solves this challenge by decoupling the two problems. The main idea is to use the norm of the representation as a new dimension for OOD detection, and to develop a training method that generates a noticeable discrepancy in the representation norm between ID and OOD data, while not perturbing the feature learning for ID classification. Our experiments show that RNA achieves superior performance in both OOD detection and classification compared to the state-of-the-art methods, by 1.70\% and 9.46\% in FPR95 and 2.43\% and 6.87\% in classification accuracy on CIFAR10-LT and ImageNet-LT, respectively. The code for this work is available at https://github.com/dgshin21/RNA.
<div id='section'>Paperid: <span id='pid'>117, <a href='https://arxiv.org/pdf/2408.03455.pdf' target='_blank'>https://arxiv.org/pdf/2408.03455.pdf</a></span>   <span><a href='https://github.com/Sandialabs/GP-BayesOpInf' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shane A. McQuarrie, Anirban Chaudhuri, Karen E. Willcox, Mengwu Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.03455">Bayesian learning with Gaussian processes for low-dimensional representations of time-dependent nonlinear systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents a data-driven method for learning low-dimensional time-dependent physics-based surrogate models whose predictions are endowed with uncertainty estimates. We use the operator inference approach to model reduction that poses the problem of learning low-dimensional model terms as a regression of state space data and corresponding time derivatives by minimizing the residual of reduced system equations. Standard operator inference models perform well with accurate training data that are dense in time, but producing stable and accurate models when the state data are noisy and/or sparse in time remains a challenge. Another challenge is the lack of uncertainty estimation for the predictions from the operator inference models. Our approach addresses these challenges by incorporating Gaussian process surrogates into the operator inference framework to (1) probabilistically describe uncertainties in the state predictions and (2) procure analytical time derivative estimates with quantified uncertainties. The formulation leads to a generalized least-squares regression and, ultimately, reduced-order models that are described probabilistically with a closed-form expression for the posterior distribution of the operators. The resulting probabilistic surrogate model propagates uncertainties from the observed state data to reduced-order predictions. We demonstrate the method is effective for constructing low-dimensional models of two nonlinear partial differential equations representing a compressible flow and a nonlinear diffusion-reaction process, as well as for estimating the parameters of a low-dimensional system of nonlinear ordinary differential equations representing compartmental models in epidemiology.
<div id='section'>Paperid: <span id='pid'>118, <a href='https://arxiv.org/pdf/2408.02761.pdf' target='_blank'>https://arxiv.org/pdf/2408.02761.pdf</a></span>   <span><a href='https://github.com/mckellwoodland/dimen_reduce_mahal' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>McKell Woodland, Nihil Patel, Austin Castelo, Mais Al Taie, Mohamed Eltaher, Joshua P. Yung, Tucker J. Netherton, Tiffany L. Calderone, Jessica I. Sanchez, Darrel W. Cleere, Ahmed Elsaiey, Nakul Gupta, David Victor, Laura Beretta, Ankit B. Patel, Kristy K. Brock
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02761">Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clinically deployed deep learning-based segmentation models are known to fail on data outside of their training distributions. While clinicians review the segmentations, these models tend to perform well in most instances, which could exacerbate automation bias. Therefore, detecting out-of-distribution images at inference is critical to warn the clinicians that the model likely failed. This work applied the Mahalanobis distance (MD) post hoc to the bottleneck features of four Swin UNETR and nnU-net models that segmented the liver on T1-weighted magnetic resonance imaging and computed tomography. By reducing the dimensions of the bottleneck features with either principal component analysis or uniform manifold approximation and projection, images the models failed on were detected with high performance and minimal computational load. In addition, this work explored a non-parametric alternative to the MD, a k-th nearest neighbors distance (KNN). KNN drastically improved scalability and performance over MD when both were applied to raw and average-pooled bottleneck features.
<div id='section'>Paperid: <span id='pid'>119, <a href='https://arxiv.org/pdf/2408.02307.pdf' target='_blank'>https://arxiv.org/pdf/2408.02307.pdf</a></span>   <span><a href='https://github.com/hjdw2/SEMBG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hojung Lee, Jong-Seok Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02307">Low-Cost Self-Ensembles Based on Multi-Branch Transformation and Grouped Convolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in low-cost ensemble learning have demonstrated improved efficiency for image classification. However, the existing low-cost ensemble methods show relatively lower accuracy compared to conventional ensemble learning. In this paper, we propose a new low-cost ensemble learning, which can simultaneously achieve high efficiency and classification performance. A CNN is transformed into a multi-branch structure without introduction of additional components, which maintains the computational complexity as that of the original single model and also enhances diversity among the branches' outputs via sufficient separation between different pathways of the branches. In addition, we propose a new strategy that applies grouped convolution in the branches with different numbers of groups in different branches, which boosts the diversity of the branches' outputs. For training, we employ knowledge distillation using the ensemble of the outputs as the teacher signal. The high diversity among the outputs enables to form a powerful teacher, enhancing the individual branch's classification performance and consequently the overall ensemble performance. Experimental results show that our method achieves state-of-the-art classification accuracy and higher uncertainty estimation performance compared to previous low-cost ensemble methods. The code is available at https://github.com/hjdw2/SEMBG.
<div id='section'>Paperid: <span id='pid'>120, <a href='https://arxiv.org/pdf/2408.01284.pdf' target='_blank'>https://arxiv.org/pdf/2408.01284.pdf</a></span>   <span><a href='https://github.com/liuyuan-wen/AV-OOD-GZSL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Liuyuan Wen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01284">Out-Of-Distribution Detection for Audio-visual Generalized Zero-Shot Learning: A General Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generalized Zero-Shot Learning (GZSL) is a challenging task requiring accurate classification of both seen and unseen classes. Within this domain, Audio-visual GZSL emerges as an extremely exciting yet difficult task, given the inclusion of both visual and acoustic features as multi-modal inputs. Existing efforts in this field mostly utilize either embedding-based or generative-based methods. However, generative training is difficult and unstable, while embedding-based methods often encounter domain shift problem. Thus, we find it promising to integrate both methods into a unified framework to leverage their advantages while mitigating their respective disadvantages. Our study introduces a general framework employing out-of-distribution (OOD) detection, aiming to harness the strengths of both approaches. We first employ generative adversarial networks to synthesize unseen features, enabling the training of an OOD detector alongside classifiers for seen and unseen classes. This detector determines whether a test feature belongs to seen or unseen classes, followed by classification utilizing separate classifiers for each feature type. We test our framework on three popular audio-visual datasets and observe a significant improvement comparing to existing state-of-the-art works. Codes can be found in https://github.com/liuyuan-wen/AV-OOD-GZSL.
<div id='section'>Paperid: <span id='pid'>121, <a href='https://arxiv.org/pdf/2408.00169.pdf' target='_blank'>https://arxiv.org/pdf/2408.00169.pdf</a></span>   <span><a href='https://github.com/Vujas-Eteph/LazyXMem' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>StÃ©phane VujasinoviÄ, Stefan Becker, Sebastian Bullinger, Norbert Scherer-Negenborn, Michael Arens, Rainer Stiefelhagen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00169">Strike the Balance: On-the-Fly Uncertainty based User Interactions for Long-Term Video Object Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce a variant of video object segmentation (VOS) that bridges interactive and semi-automatic approaches, termed Lazy Video Object Segmentation (ziVOS). In contrast, to both tasks, which handle video object segmentation in an off-line manner (i.e., pre-recorded sequences), we propose through ziVOS to target online recorded sequences. Here, we strive to strike a balance between performance and robustness for long-term scenarios by soliciting user feedback's on-the-fly during the segmentation process. Hence, we aim to maximize the tracking duration of an object of interest, while requiring minimal user corrections to maintain tracking over an extended period. We propose a competitive baseline, i.e., Lazy-XMem, as a reference for future works in ziVOS. Our proposed approach uses an uncertainty estimation of the tracking state to determine whether a user interaction is necessary to refine the model's prediction. To quantitatively assess the performance of our method and the user's workload, we introduce complementary metrics alongside those already established in the field. We evaluate our approach using the recently introduced LVOS dataset, which offers numerous long-term videos. Our code is publicly available at https://github.com/Vujas-Eteph/LazyXMem.
<div id='section'>Paperid: <span id='pid'>122, <a href='https://arxiv.org/pdf/2407.21794.pdf' target='_blank'>https://arxiv.org/pdf/2407.21794.pdf</a></span>   <span><a href='https://github.com/AtsuMiyai/Awesome-OOD-VLM' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/AtsuMiyai/Awesome-OOD-VLM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, Ziwei Liu, Toshihiko Yamasaki, Kiyoharu Aizawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21794">Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD). To unify these problems, a generalized OOD detection framework was proposed, taxonomically categorizing these five problems. However, Vision Language Models (VLMs) such as CLIP have significantly changed the paradigm and blurred the boundaries between these fields, again confusing researchers. In this survey, we first present a generalized OOD detection v2, encapsulating the evolution of these fields in the VLM era. Our framework reveals that, with some field inactivity and integration, the demanding challenges have become OOD detection and AD. Then, we highlight the significant shift in the definition, problem settings, and benchmarks; we thus feature a comprehensive review of the methodology for OOD detection and related tasks to clarify their relationship to OOD detection. Finally, we explore the advancements in the emerging Large Vision Language Model (LVLM) era, such as GPT-4V. We conclude with open challenges and future directions. The resource is available at https://github.com/AtsuMiyai/Awesome-OOD-VLM.
<div id='section'>Paperid: <span id='pid'>123, <a href='https://arxiv.org/pdf/2407.16725.pdf' target='_blank'>https://arxiv.org/pdf/2407.16725.pdf</a></span>   <span><a href='https://github.com/alibaba/catex' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/alibaba/catex' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Liu, Zhihang Fu, Chao Chen, Sheng Jin, Ze Chen, Mingyuan Tao, Rongxin Jiang, Jieping Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16725">Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The key to OOD detection has two aspects: generalized feature representation and precise category description. Recently, vision-language models such as CLIP provide significant advances in both two issues, but constructing precise category descriptions is still in its infancy due to the absence of unseen categories. This work introduces two hierarchical contexts, namely perceptual context and spurious context, to carefully describe the precise category boundary through automatic prompt tuning. Specifically, perceptual contexts perceive the inter-category difference (e.g., cats vs apples) for current classification tasks, while spurious contexts further identify spurious (similar but exactly not) OOD samples for every single category (e.g., cats vs panthers, apples vs peaches). The two contexts hierarchically construct the precise description for a certain category, which is, first roughly classifying a sample to the predicted category and then delicately identifying whether it is truly an ID sample or actually OOD. Moreover, the precise descriptions for those categories within the vision-language framework present a novel application: CATegory-EXtensible OOD detection (CATEX). One can efficiently extend the set of recognizable categories by simply merging the hierarchical contexts learned under different sub-task settings. And extensive experiments are conducted to demonstrate CATEX's effectiveness, robustness, and category-extensibility. For instance, CATEX consistently surpasses the rivals by a large margin with several protocols on the challenging ImageNet-1K dataset. In addition, we offer new insights on how to efficiently scale up the prompt engineering in vision-language models to recognize thousands of object categories, as well as how to incorporate large language models (like GPT-3) to boost zero-shot applications. Code is publicly available at https://github.com/alibaba/catex.
<div id='section'>Paperid: <span id='pid'>124, <a href='https://arxiv.org/pdf/2407.16430.pdf' target='_blank'>https://arxiv.org/pdf/2407.16430.pdf</a></span>   <span><a href='https://github.com/alibaba/imood' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/alibaba/imood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Liu, Zhihang Fu, Sheng Jin, Chao Chen, Ze Chen, Rongxin Jiang, Fan Zhou, Yaowu Chen, Jieping Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16430">Rethinking Out-of-Distribution Detection on Imbalanced Data Distribution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting and rejecting unknown out-of-distribution (OOD) samples is critical for deployed neural networks to void unreliable predictions. In real-world scenarios, however, the efficacy of existing OOD detection methods is often impeded by the inherent imbalance of in-distribution (ID) data, which causes significant performance decline. Through statistical observations, we have identified two common challenges faced by different OOD detectors: misidentifying tail class ID samples as OOD, while erroneously predicting OOD samples as head class from ID. To explain this phenomenon, we introduce a generalized statistical framework, termed ImOOD, to formulate the OOD detection problem on imbalanced data distribution. Consequently, the theoretical analysis reveals that there exists a class-aware bias item between balanced and imbalanced OOD detection, which contributes to the performance gap. Building upon this finding, we present a unified training-time regularization technique to mitigate the bias and boost imbalanced OOD detectors across architecture designs. Our theoretically grounded method translates into consistent improvements on the representative CIFAR10-LT, CIFAR100-LT, and ImageNet-LT benchmarks against several state-of-the-art OOD detection approaches. Code is available at https://github.com/alibaba/imood.
<div id='section'>Paperid: <span id='pid'>125, <a href='https://arxiv.org/pdf/2407.15773.pdf' target='_blank'>https://arxiv.org/pdf/2407.15773.pdf</a></span>   <span><a href='https://github.com/yuyongcan/STAMP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongcan Yu, Lijun Sheng, Ran He, Jian Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15773">STAMP: Outlier-Aware Test-Time Adaptation with Stable Memory Replay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to address the distribution shift between the training and test data with only unlabeled data at test time. Existing TTA methods often focus on improving recognition performance specifically for test data associated with classes in the training set. However, during the open-world inference process, there are inevitably test data instances from unknown classes, commonly referred to as outliers. This paper pays attention to the problem that conducts both sample recognition and outlier rejection during inference while outliers exist. To address this problem, we propose a new approach called STAble Memory rePlay (STAMP), which performs optimization over a stable memory bank instead of the risky mini-batch. In particular, the memory bank is dynamically updated by selecting low-entropy and label-consistent samples in a class-balanced manner. In addition, we develop a self-weighted entropy minimization strategy that assigns higher weight to low-entropy samples. Extensive results demonstrate that STAMP outperforms existing TTA methods in terms of both recognition and outlier detection performance. The code is released at https://github.com/yuyongcan/STAMP.
<div id='section'>Paperid: <span id='pid'>126, <a href='https://arxiv.org/pdf/2407.14230.pdf' target='_blank'>https://arxiv.org/pdf/2407.14230.pdf</a></span>   <span><a href='https://github.com/master-Shix/ETSCL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyuan Yang, Bo Zhang, Yufei Shi, Ningze Zhong, Johnathan Loh, Huihui Fang, Yanwu Xu, Si Yong Yeo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14230">ETSCL: An Evidence Theory-Based Supervised Contrastive Learning Framework for Multi-modal Glaucoma Grading</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Glaucoma is one of the leading causes of vision impairment. Digital imaging techniques, such as color fundus photography (CFP) and optical coherence tomography (OCT), provide quantitative and noninvasive methods for glaucoma diagnosis. Recently, in the field of computer-aided glaucoma diagnosis, multi-modality methods that integrate the CFP and OCT modalities have achieved greater diagnostic accuracy compared to single-modality methods. However, it remains challenging to extract reliable features due to the high similarity of medical images and the unbalanced multi-modal data distribution. Moreover, existing methods overlook the uncertainty estimation of different modalities, leading to unreliable predictions. To address these challenges, we propose a novel framework, namely ETSCL, which consists of a contrastive feature extraction stage and a decision-level fusion stage. Specifically, the supervised contrastive loss is employed to enhance the discriminative power in the feature extraction process, resulting in more effective features. In addition, we utilize the Frangi vesselness algorithm as a preprocessing step to incorporate vessel information to assist in the prediction. In the decision-level fusion stage, an evidence theory-based multi-modality classifier is employed to combine multi-source information with uncertainty estimation. Extensive experiments demonstrate that our method achieves state-of-the-art performance. The code is available at \url{https://github.com/master-Shix/ETSCL}.
<div id='section'>Paperid: <span id='pid'>127, <a href='https://arxiv.org/pdf/2407.14208.pdf' target='_blank'>https://arxiv.org/pdf/2407.14208.pdf</a></span>   <span><a href='https://github.com/pascalschlachter/GMM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pascal Schlachter, Simon Wagner, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14208">Memory-Efficient Pseudo-Labeling for Online Source-Free Universal Domain Adaptation using a Gaussian Mixture Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In practice, domain shifts are likely to occur between training and test data, necessitating domain adaptation (DA) to adjust the pre-trained source model to the target domain. Recently, universal domain adaptation (UniDA) has gained attention for addressing the possibility of an additional category (label) shift between the source and target domain. This means new classes can appear in the target data, some source classes may no longer be present, or both at the same time. For practical applicability, UniDA methods must handle both source-free and online scenarios, enabling adaptation without access to the source data and performing batch-wise updates in parallel with prediction. In an online setting, preserving knowledge across batches is crucial. However, existing methods often require substantial memory, which is impractical because memory is limited and valuable, in particular on embedded systems. Therefore, we consider memory-efficiency as an additional constraint. To achieve memory-efficient online source-free universal domain adaptation (SF-UniDA), we propose a novel method that continuously captures the distribution of known classes in the feature space using a Gaussian mixture model (GMM). This approach, combined with entropy-based out-of-distribution detection, allows for the generation of reliable pseudo-labels. Finally, we combine a contrastive loss with a KL divergence loss to perform the adaptation. Our approach not only achieves state-of-the-art results in all experiments on the DomainNet and Office-Home datasets but also significantly outperforms the existing methods on the challenging VisDA-C dataset, setting a new benchmark for online SF-UniDA. Our code is available at https://github.com/pascalschlachter/GMM.
<div id='section'>Paperid: <span id='pid'>128, <a href='https://arxiv.org/pdf/2407.13163.pdf' target='_blank'>https://arxiv.org/pdf/2407.13163.pdf</a></span>   <span><a href='https://github.com/ArronDZhang/ROLeR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Zhang, Ruihong Qiu, Jiajun Liu, Sen Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13163">ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline reinforcement learning (RL) is an effective tool for real-world recommender systems with its capacity to model the dynamic interest of users and its interactive nature. Most existing offline RL recommender systems focus on model-based RL through learning a world model from offline data and building the recommendation policy by interacting with this model. Although these methods have made progress in the recommendation performance, the effectiveness of model-based offline RL methods is often constrained by the accuracy of the estimation of the reward model and the model uncertainties, primarily due to the extreme discrepancy between offline logged data and real-world data in user interactions with online platforms. To fill this gap, a more accurate reward model and uncertainty estimation are needed for the model-based RL methods. In this paper, a novel model-based Reward Shaping in Offline Reinforcement Learning for Recommender Systems, ROLeR, is proposed for reward and uncertainty estimation in recommendation systems. Specifically, a non-parametric reward shaping method is designed to refine the reward model. In addition, a flexible and more representative uncertainty penalty is designed to fit the needs of recommendation systems. Extensive experiments conducted on four benchmark datasets showcase that ROLeR achieves state-of-the-art performance compared with existing baselines. The source code can be downloaded at https://github.com/ArronDZhang/ROLeR.
<div id='section'>Paperid: <span id='pid'>129, <a href='https://arxiv.org/pdf/2407.11735.pdf' target='_blank'>https://arxiv.org/pdf/2407.11735.pdf</a></span>   <span><a href='https://github.com/walline/prosub' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Erik Wallin, Lennart Svensson, Fredrik Kahl, Lars Hammarstrand
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11735">ProSub: Probabilistic Open-Set Semi-Supervised Learning with Subspace-Based Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In open-set semi-supervised learning (OSSL), we consider unlabeled datasets that may contain unknown classes. Existing OSSL methods often use the softmax confidence for classifying data as in-distribution (ID) or out-of-distribution (OOD). Additionally, many works for OSSL rely on ad-hoc thresholds for ID/OOD classification, without considering the statistics of the problem. We propose a new score for ID/OOD classification based on angles in feature space between data and an ID subspace. Moreover, we propose an approach to estimate the conditional distributions of scores given ID or OOD data, enabling probabilistic predictions of data being ID or OOD. These components are put together in a framework for OSSL, termed \emph{ProSub}, that is experimentally shown to reach SOTA performance on several benchmark problems. Our code is available at https://github.com/walline/prosub.
<div id='section'>Paperid: <span id='pid'>130, <a href='https://arxiv.org/pdf/2407.11282.pdf' target='_blank'>https://arxiv.org/pdf/2407.11282.pdf</a></span>   <span><a href='https://github.com/qcznlp/uncertainty_attack' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingcheng Zeng, Mingyu Jin, Qinkai Yu, Zhenting Wang, Wenyue Hua, Zihao Zhou, Guangyan Sun, Yanda Meng, Shiqing Ma, Qifan Wang, Felix Juefei-Xu, Kaize Ding, Fan Yang, Ruixiang Tang, Yongfeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11282">Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are employed across various high-stakes domains, where the reliability of their outputs is crucial. One commonly used method to assess the reliability of LLMs' responses is uncertainty estimation, which gauges the likelihood of their answers being correct. While many studies focus on improving the accuracy of uncertainty estimations for LLMs, our research investigates the fragility of uncertainty estimation and explores potential attacks. We demonstrate that an attacker can embed a backdoor in LLMs, which, when activated by a specific trigger in the input, manipulates the model's uncertainty without affecting the final output. Specifically, the proposed backdoor attack method can alter an LLM's output probability distribution, causing the probability distribution to converge towards an attacker-predefined distribution while ensuring that the top-1 prediction remains unchanged. Our experimental results demonstrate that this attack effectively undermines the model's self-evaluation reliability in multiple-choice questions. For instance, we achieved a 100 attack success rate (ASR) across three different triggering strategies in four models. Further, we investigate whether this manipulation generalizes across different prompts and domains. This work highlights a significant threat to the reliability of LLMs and underscores the need for future defenses against such attacks. The code is available at https://github.com/qcznlp/uncertainty_attack.
<div id='section'>Paperid: <span id='pid'>131, <a href='https://arxiv.org/pdf/2407.07135.pdf' target='_blank'>https://arxiv.org/pdf/2407.07135.pdf</a></span>   <span><a href='https://github.com/paulnovello/multi-ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Novello, Yannick Prudent, Joseba Dalmau, Corentin Friedrich, Yann Pequignot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07135">Improving Out-of-Distribution Detection by Combining Existing Post-hoc Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since the seminal paper of Hendrycks et al. arXiv:1610.02136, Post-hoc deep Out-of-Distribution (OOD) detection has expanded rapidly. As a result, practitioners working on safety-critical applications and seeking to improve the robustness of a neural network now have a plethora of methods to choose from. However, no method outperforms every other on every dataset arXiv:2210.07242, so the current best practice is to test all the methods on the datasets at hand. This paper shifts focus from developing new methods to effectively combining existing ones to enhance OOD detection. We propose and compare four different strategies for integrating multiple detection scores into a unified OOD detector, based on techniques such as majority vote, empirical and copulas-based Cumulative Distribution Function modeling, and multivariate quantiles based on optimal transport. We extend common OOD evaluation metrics -- like AUROC and FPR at fixed TPR rates -- to these multi-dimensional OOD detectors, allowing us to evaluate them and compare them with individual methods on extensive benchmarks. Furthermore, we propose a series of guidelines to choose what OOD detectors to combine in more realistic settings, i.e. in the absence of known OOD data, relying on principles drawn from Outlier Exposure arXiv:1812.04606. The code is available at https://github.com/paulnovello/multi-ood.
<div id='section'>Paperid: <span id='pid'>132, <a href='https://arxiv.org/pdf/2407.06426.pdf' target='_blank'>https://arxiv.org/pdf/2407.06426.pdf</a></span>   <span><a href='https://github.com/lukeyoffe/debunc' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Luke Yoffe, Alfonso Amayuelas, William Yang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06426">DebUnc: Improving Large Language Model Agent Communication With Uncertainty Metrics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-agent debates have been introduced to improve the accuracy of Large Language Models (LLMs) by having multiple agents discuss solutions to a problem over several rounds of debate. However, models often generate incorrect yet confident-sounding responses, which can mislead others. This issue arises partly because agents do not consider how confident their peers are. To address this, we propose DebUnc, a debate framework that uses uncertainty metrics to assess agent confidence. Confidence is then conveyed through a modified attention mechanism that adjusts token weights, or through textual prompts. Evaluations across benchmarks show that attention-based methods are particularly effective and that performance continues to improve as uncertainty estimation becomes more reliable. The code is available at https://github.com/lukeyoffe/debunc.
<div id='section'>Paperid: <span id='pid'>133, <a href='https://arxiv.org/pdf/2407.06045.pdf' target='_blank'>https://arxiv.org/pdf/2407.06045.pdf</a></span>   <span><a href='https://github.com/mala-lab/OpenCIL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjun Miao, Guansong Pang, Trong-Tung Nguyen, Ruohang Fang, Jin Zheng, Xiao Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06045">OpenCIL: Benchmarking Out-of-Distribution Detection in Class-Incremental Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Class incremental learning (CIL) aims to learn a model that can not only incrementally accommodate new classes, but also maintain the learned knowledge of old classes. Out-of-distribution (OOD) detection in CIL is to retain this incremental learning ability, while being able to reject unknown samples that are drawn from different distributions of the learned classes. This capability is crucial to the safety of deploying CIL models in open worlds. However, despite remarkable advancements in the respective CIL and OOD detection, there lacks a systematic and large-scale benchmark to assess the capability of advanced CIL models in detecting OOD samples. To fill this gap, in this study we design a comprehensive empirical study to establish such a benchmark, named $\textbf{OpenCIL}$. To this end, we propose two principled frameworks for enabling four representative CIL models with 15 diverse OOD detection methods, resulting in 60 baseline models for OOD detection in CIL. The empirical evaluation is performed on two popular CIL datasets with six commonly-used OOD datasets. One key observation we find through our comprehensive evaluation is that the CIL models can be severely biased towards the OOD samples and newly added classes when they are exposed to open environments. Motivated by this, we further propose a new baseline for OOD detection in CIL, namely Bi-directional Energy Regularization ($\textbf{BER}$), which is specially designed to mitigate these two biases in different CIL models by having energy regularization on both old and new classes. Its superior performance is justified in our experiments. All codes and datasets are open-source at https://github.com/mala-lab/OpenCIL.
<div id='section'>Paperid: <span id='pid'>134, <a href='https://arxiv.org/pdf/2407.02830.pdf' target='_blank'>https://arxiv.org/pdf/2407.02830.pdf</a></span>   <span><a href='https://github.com/Tsuiky/3DRN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Fang, Tianyu Li, Yanghong Lin, Shudong Zhou, Wei Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02830">A Radiometric Correction based Optical Modeling Approach to Removing Reflection Noise in TLS Point Clouds of Urban Scenes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Point clouds are vital in computer vision tasks such as 3D reconstruction, autonomous driving, and robotics. However, TLS-acquired point clouds often contain virtual points from reflective surfaces, causing disruptions. This study presents a reflection noise elimination algorithm for TLS point clouds. Our innovative reflection plane detection algorithm, based on geometry-optical models and physical properties, identifies and categorizes reflection points per optical reflection theory. We've adapted the LSFH feature descriptor to retain reflection features, mitigating interference from symmetrical architectural structures. By incorporating the Hausdorff feature distance, the algorithm enhances resilience to ghosting and deformation, improving virtual point detection accuracy. Extensive experiments on the 3DRN benchmark dataset, featuring diverse urban environments with virtual TLS reflection noise, show our algorithm improves precision and recall rates for 3D points in reflective regions by 57.03\% and 31.80\%, respectively. Our method achieves a 9.17\% better outlier detection rate and 5.65\% higher accuracy than leading methods. Access the 3DRN dataset at (https://github.com/Tsuiky/3DRN).
<div id='section'>Paperid: <span id='pid'>135, <a href='https://arxiv.org/pdf/2407.01146.pdf' target='_blank'>https://arxiv.org/pdf/2407.01146.pdf</a></span>   <span><a href='https://github.com/aL3x-O-o-Hung/GLCSA_ECLoss' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Ling Yu Hung, Haoxin Zheng, Kai Zhao, Kaifeng Pang, Demetri Terzopoulos, Kyunghyun Sung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01146">Cross-Slice Attention and Evidential Critical Loss for Uncertainty-Aware Prostate Cancer Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current deep learning-based models typically analyze medical images in either 2D or 3D albeit disregarding volumetric information or suffering sub-optimal performance due to the anisotropic resolution of MR data. Furthermore, providing an accurate uncertainty estimation is beneficial to clinicians, as it indicates how confident a model is about its prediction. We propose a novel 2.5D cross-slice attention model that utilizes both global and local information, along with an evidential critical loss, to perform evidential deep learning for the detection in MR images of prostate cancer, one of the most common cancers and a leading cause of cancer-related death in men. We perform extensive experiments with our model on two different datasets and achieve state-of-the-art performance in prostate cancer detection along with improved epistemic uncertainty estimation. The implementation of the model is available at https://github.com/aL3x-O-o-Hung/GLCSA_ECLoss.
<div id='section'>Paperid: <span id='pid'>136, <a href='https://arxiv.org/pdf/2406.18999.pdf' target='_blank'>https://arxiv.org/pdf/2406.18999.pdf</a></span>   <span><a href='https://github.com/mikkoim/dnaimg-ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mikko ImpiÃ¶, Jenni Raitoharju
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18999">Improving Taxonomic Image-based Out-of-distribution Detection With DNA Barcodes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image-based species identification could help scaling biodiversity monitoring to a global scale. Many challenges still need to be solved in order to implement these systems in real-world applications. A reliable image-based monitoring system must detect out-of-distribution (OOD) classes it has not been presented before. This is challenging especially with fine-grained classes. Emerging environmental monitoring techniques, DNA metabarcoding and eDNA, can help by providing information on OOD classes that are present in a sample. In this paper, we study if DNA barcodes can also support in finding the outlier images based on the outlier DNA sequence's similarity to the seen classes. We propose a re-ordering approach that can be easily applied on any pre-trained models and existing OOD detection methods. We experimentally show that the proposed approach improves taxonomic OOD detection compared to all common baselines. We also show that the method works thanks to a correlation between visual similarity and DNA barcode proximity. The code and data are available at https://github.com/mikkoim/dnaimg-ood.
<div id='section'>Paperid: <span id='pid'>137, <a href='https://arxiv.org/pdf/2406.17274.pdf' target='_blank'>https://arxiv.org/pdf/2406.17274.pdf</a></span>   <span><a href='https://github.com/he159ok/Benchmark-of-Uncertainty-Estimation-Methods-in-Text-Summarization' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianfeng He, Runing Yang, Linlin Yu, Changbin Li, Ruoxi Jia, Feng Chen, Ming Jin, Chang-Tien Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.17274">Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Text summarization, a key natural language generation (NLG) task, is vital in various domains. However, the high cost of inaccurate summaries in risk-critical applications, particularly those involving human-in-the-loop decision-making, raises concerns about the reliability of uncertainty estimation on text summarization (UE-TS) evaluation methods. This concern stems from the dependency of uncertainty model metrics on diverse and potentially conflicting NLG metrics. To address this issue, we introduce a comprehensive UE-TS benchmark incorporating 31 NLG metrics across four dimensions. The benchmark evaluates the uncertainty estimation capabilities of two large language models and one pre-trained language model on three datasets, with human-annotation analysis incorporated where applicable. We also assess the performance of 14 common uncertainty estimation methods within this benchmark. Our findings emphasize the importance of considering multiple uncorrelated NLG metrics and diverse uncertainty estimation methods to ensure reliable and efficient evaluation of UE-TS techniques. Our code and data are available https://github.com/he159ok/Benchmark-of-Uncertainty-Estimation-Methods-in-Text-Summarization.
<div id='section'>Paperid: <span id='pid'>138, <a href='https://arxiv.org/pdf/2406.16942.pdf' target='_blank'>https://arxiv.org/pdf/2406.16942.pdf</a></span>   <span><a href='https://github.com/yuanyuanpeng0129/FMUE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanyuan Peng, Aidi Lin, Meng Wang, Tian Lin, Ke Zou, Yinglin Cheng, Tingkun Shi, Xulong Liao, Lixia Feng, Zhen Liang, Xinjian Chen, Huazhu Fu, Haoyu Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16942">Enhancing Diagnostic Reliability of Foundation Model with Uncertainty Estimation in OCT Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inability to express the confidence level and detect unseen classes has limited the clinical implementation of artificial intelligence in the real-world. We developed a foundation model with uncertainty estimation (FMUE) to detect 11 retinal conditions on optical coherence tomography (OCT). In the internal test set, FMUE achieved a higher F1 score of 96.76% than two state-of-the-art algorithms, RETFound and UIOS, and got further improvement with thresholding strategy to 98.44%. In the external test sets obtained from other OCT devices, FMUE achieved an accuracy of 88.75% and 92.73% before and after thresholding. Our model is superior to two ophthalmologists with a higher F1 score (95.17% vs. 61.93% &71.72%). Besides, our model correctly predicts high uncertainty scores for samples with ambiguous features, of non-target-category diseases, or with low-quality to prompt manual checks and prevent misdiagnosis. FMUE provides a trustworthy method for automatic retinal anomalies detection in the real-world clinical open set environment.
<div id='section'>Paperid: <span id='pid'>139, <a href='https://arxiv.org/pdf/2406.16045.pdf' target='_blank'>https://arxiv.org/pdf/2406.16045.pdf</a></span>   <span><a href='https://github.com/edadaltocg/detectors' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Eduardo Dadalto, Florence Alberge, Pierre Duhamel, Pablo Piantanida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16045">Combine and Conquer: A Meta-Analysis on Data Shift and Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a universal approach to seamlessly combine out-of-distribution (OOD) detection scores. These scores encompass a wide range of techniques that leverage the self-confidence of deep learning models and the anomalous behavior of features in the latent space. Not surprisingly, combining such a varied population using simple statistics proves inadequate. To overcome this challenge, we propose a quantile normalization to map these scores into p-values, effectively framing the problem into a multi-variate hypothesis test. Then, we combine these tests using established meta-analysis tools, resulting in a more effective detector with consolidated decision boundaries. Furthermore, we create a probabilistic interpretable criterion by mapping the final statistics into a distribution with known parameters. Through empirical investigation, we explore different types of shifts, each exerting varying degrees of impact on data. Our results demonstrate that our approach significantly improves overall robustness and performance across diverse OOD detection scenarios. Notably, our framework is easily extensible for future developments in detection scores and stands as the first to combine decision boundaries in this context. The code and artifacts associated with this work are publicly available\footnote{\url{https://github.com/edadaltocg/detectors}}.
<div id='section'>Paperid: <span id='pid'>140, <a href='https://arxiv.org/pdf/2406.15523.pdf' target='_blank'>https://arxiv.org/pdf/2406.15523.pdf</a></span>   <span><a href='https://github.com/UB-GOLD/UB-GOLD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yili Wang, Yixin Liu, Xu Shen, Chenyu Li, Kaize Ding, Rui Miao, Ying Wang, Shirui Pan, Xin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.15523">Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To build safe and reliable graph machine learning systems, unsupervised graph-level anomaly detection (GLAD) and unsupervised graph-level out-of-distribution (OOD) detection (GLOD) have received significant attention in recent years. Though those two lines of research indeed share the same objective, they have been studied independently in the community due to distinct evaluation setups, creating a gap that hinders the application and evaluation of methods from one to the other. To bridge the gap, in this work, we present a \underline{\textbf{U}}nified \underline{\textbf{B}}enchmark for unsupervised \underline{\textbf{G}}raph-level \underline{\textbf{O}}OD and anoma\underline{\textbf{L}}y \underline{\textbf{D}}etection (\ourmethod), a comprehensive evaluation framework that unifies GLAD and GLOD under the concept of generalized graph-level OOD detection. Our benchmark encompasses 35 datasets spanning four practical anomaly and OOD detection scenarios, facilitating the comparison of 18 representative GLAD/GLOD methods. We conduct multi-dimensional analyses to explore the effectiveness, OOD sensitivity spectrum, robustness, and efficiency of existing methods, shedding light on their strengths and limitations. Furthermore, we provide an open-source codebase (https://github.com/UB-GOLD/UB-GOLD) of \ourmethod to foster reproducible research and outline potential directions for future investigations based on our insights.
<div id='section'>Paperid: <span id='pid'>141, <a href='https://arxiv.org/pdf/2406.14593.pdf' target='_blank'>https://arxiv.org/pdf/2406.14593.pdf</a></span>   <span><a href='https://github.com/os-hxfan/MCME_FPGA_Acc.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Mark Chen, Liam Castelli, Martin Ferianc, Hongyu Zhou, Shuanglong Liu, Wayne Luk, Hongxiang Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14593">Enhancing Dropout-based Bayesian Neural Networks with Multi-Exit on FPGA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation plays a crucial role in various safety-critical applications such as medical diagnosis and autonomous driving. In recent years, Bayesian neural networks (BayesNNs) have gained substantial research and industrial interests due to their capability to make accurate predictions with reliable uncertainty estimation. However, the algorithmic complexity and the resulting hardware performance of BayesNNs hinder their adoption in real-life applications. To bridge this gap, this paper proposes an algorithm and hardware co-design framework that can generate field-programmable gate array (FPGA)-based accelerators for efficient BayesNNs. At the algorithm level, we propose novel multi-exit dropout-based BayesNNs with reduced computational and memory overheads while achieving high accuracy and quality of uncertainty estimation. At the hardware level, this paper introduces a transformation framework that can generate FPGA-based accelerators for the proposed efficient multi-exit BayesNNs. Several optimization techniques such as the mix of spatial and temporal mappings are introduced to reduce resource consumption and improve the overall hardware performance. Comprehensive experiments demonstrate that our approach can achieve higher energy efficiency compared to CPU, GPU, and other state-of-the-art hardware implementations. To support the future development of this research, we have open-sourced our code at: https://github.com/os-hxfan/MCME_FPGA_Acc.git
<div id='section'>Paperid: <span id='pid'>142, <a href='https://arxiv.org/pdf/2406.12784.pdf' target='_blank'>https://arxiv.org/pdf/2406.12784.pdf</a></span>   <span><a href='https://github.com/Cyno2232/UBENCH' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xunzhi Wang, Zhuowei Zhang, Gaonan Chen, Qiongyu Li, Bitong Luo, Zhixin Han, Haotian Wang, Zhiyu li, Hang Gao, Mengting Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12784">UBench: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite recent progress in systematic evaluation frameworks, benchmarking the uncertainty of large language models (LLMs) remains a highly challenging task. Existing methods for benchmarking the uncertainty of LLMs face three key challenges: the need for internal model access, additional training, or high computational costs. This is particularly unfavorable for closed-source models. To this end, we introduce UBench, a new benchmark for evaluating the uncertainty of LLMs. Unlike other benchmarks, UBench is based on confidence intervals. It encompasses 11,978 multiple-choice questions spanning knowledge, language, understanding, and reasoning capabilities. Based on this, we conduct extensive experiments. This includes comparisons with other advanced uncertainty estimation methods, the assessment of the uncertainty of 20 LLMs, and an exploration of the effects of Chain-of-Thought (CoT) prompts, role-playing (RP) prompts, and temperature on model uncertainty. Our analysis reveals several crucial insights: 1) Our confidence interval-based methods are highly effective for uncertainty quantification; 2) Regarding uncertainty, outstanding open-source models show competitive performance versus closed-source models; 3) CoT and RP prompts present potential ways to improve model reliability, while the influence of temperature changes follows no universal rule. Our implementation is available at https://github.com/Cyno2232/UBENCH.
<div id='section'>Paperid: <span id='pid'>143, <a href='https://arxiv.org/pdf/2406.12629.pdf' target='_blank'>https://arxiv.org/pdf/2406.12629.pdf</a></span>   <span><a href='https://github.com/X1AOX1A/SeTAR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yixia Li, Boya Xiong, Guanhua Chen, Yun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12629">SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for the safe deployment of neural networks. Existing CLIP-based approaches perform OOD detection by devising novel scoring functions or sophisticated fine-tuning methods. In this work, we propose SeTAR, a novel, training-free OOD detection method that leverages selective low-rank approximation of weight matrices in vision-language and vision-only models. SeTAR enhances OOD detection via post-hoc modification of the model's weight matrices using a simple greedy search algorithm. Based on SeTAR, we further propose SeTAR+FT, a fine-tuning extension optimizing model performance for OOD detection tasks. Extensive evaluations on ImageNet1K and Pascal-VOC benchmarks show SeTAR's superior performance, reducing the relatively false positive rate by up to 18.95% and 36.80% compared to zero-shot and fine-tuning baselines. Ablation studies further validate SeTAR's effectiveness, robustness, and generalizability across different model backbones. Our work offers a scalable, efficient solution for OOD detection, setting a new state-of-the-art in this area.
<div id='section'>Paperid: <span id='pid'>144, <a href='https://arxiv.org/pdf/2406.11657.pdf' target='_blank'>https://arxiv.org/pdf/2406.11657.pdf</a></span>   <span><a href='https://github.com/dong-river/Personalized-Judge' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijiang River Dong, Tiancheng Hu, Nigel Collier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11657">Can LLM be a Personalized Judge?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensuring that large language models (LLMs) reflect diverse user values and preferences is crucial as their user bases expand globally. It is therefore encouraging to see the growing interest in LLM personalization within the research community. However, current works often rely on the LLM-as-a-Judge approach for evaluation without thoroughly examining its validity. In this paper, we investigate the reliability of LLM-as-a-Personalized-Judge, asking LLMs to judge user preferences based on personas. Our findings suggest that directly applying LLM-as-a-Personalized-Judge is less reliable than previously assumed, showing low and inconsistent agreement with human ground truth. The personas typically used are often overly simplistic, resulting in low predictive power. To address these issues, we introduce verbal uncertainty estimation into the LLM-as-a-Personalized-Judge pipeline, allowing the model to express low confidence on uncertain judgments. This adjustment leads to much higher agreement (above 80%) on high-certainty samples for binary tasks. Through human evaluation, we find that the LLM-as-a-Personalized-Judge achieves comparable performance to third-party humans evaluation and even surpasses human performance on high-certainty samples. Our work indicates that certainty-enhanced LLM-as-a-Personalized-Judge offers a promising direction for developing more reliable and scalable methods for evaluating LLM personalization.
<div id='section'>Paperid: <span id='pid'>145, <a href='https://arxiv.org/pdf/2406.09867.pdf' target='_blank'>https://arxiv.org/pdf/2406.09867.pdf</a></span>   <span><a href='https://github.com/qqwsad5/IS-OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingming Long, Jie Zhang, Shiguang Shan, Xilin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09867">Rethinking the Evaluation of Out-of-Distribution Detection: A Sorites Paradox</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most existing out-of-distribution (OOD) detection benchmarks classify samples with novel labels as the OOD data. However, some marginal OOD samples actually have close semantic contents to the in-distribution (ID) sample, which makes determining the OOD sample a Sorites Paradox. In this paper, we construct a benchmark named Incremental Shift OOD (IS-OOD) to address the issue, in which we divide the test samples into subsets with different semantic and covariate shift degrees relative to the ID dataset. The data division is achieved through a shift measuring method based on our proposed Language Aligned Image feature Decomposition (LAID). Moreover, we construct a Synthetic Incremental Shift (Syn-IS) dataset that contains high-quality generated images with more diverse covariate contents to complement the IS-OOD benchmark. We evaluate current OOD detection methods on our benchmark and find several important insights: (1) The performance of most OOD detection methods significantly improves as the semantic shift increases; (2) Some methods like GradNorm may have different OOD detection mechanisms as they rely less on semantic shifts to make decisions; (3) Excessive covariate shifts in the image are also likely to be considered as OOD for some methods. Our code and data are released in https://github.com/qqwsad5/IS-OOD.
<div id='section'>Paperid: <span id='pid'>146, <a href='https://arxiv.org/pdf/2406.02103.pdf' target='_blank'>https://arxiv.org/pdf/2406.02103.pdf</a></span>   <span><a href='https://github.com/nirgreshler/bayesian-online-planning' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nir Greshler, David Ben Eli, Carmel Rabinovitz, Gabi Guetta, Liran Gispan, Guy Zohar, Aviv Tamar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02103">A Bayesian Approach to Online Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The combination of Monte Carlo tree search and neural networks has revolutionized online planning. As neural network approximations are often imperfect, we ask whether uncertainty estimates about the network outputs could be used to improve planning. We develop a Bayesian planning approach that facilitates such uncertainty quantification, inspired by classical ideas from the meta-reasoning literature. We propose a Thompson sampling based algorithm for searching the tree of possible actions, for which we prove the first (to our knowledge) finite time Bayesian regret bound, and propose an efficient implementation for a restricted family of posterior distributions. In addition we propose a variant of the Bayes-UCB method applied to trees. Empirically, we demonstrate that on the ProcGen Maze and Leaper environments, when the uncertainty estimates are accurate but the neural network output is inaccurate, our Bayesian approach searches the tree much more effectively. In addition, we investigate whether popular uncertainty estimation methods are accurate enough to yield significant gains in planning. Our code is available at: https://github.com/nirgreshler/bayesian-online-planning.
<div id='section'>Paperid: <span id='pid'>147, <a href='https://arxiv.org/pdf/2406.00806.pdf' target='_blank'>https://arxiv.org/pdf/2406.00806.pdf</a></span>   <span><a href='https://github.com/tmlr-group/EOE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chentao Cao, Zhun Zhong, Zhanke Zhou, Yang Liu, Tongliang Liu, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00806">Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is essential when deploying machine learning models in open-world scenarios. Zero-shot OOD detection, requiring no training on in-distribution (ID) data, has been possible with the advent of vision-language models like CLIP. Existing methods build a text-based classifier with only closed-set labels. However, this largely restricts the inherent capability of CLIP to recognize samples from large and open label space. In this paper, we propose to tackle this constraint by leveraging the expert knowledge and reasoning capability of large language models (LLM) to Envision potential Outlier Exposure, termed EOE, without access to any actual OOD data. Owing to better adaptation to open-world scenarios, EOE can be generalized to different tasks, including far, near, and fine-grained OOD detection. Technically, we design (1) LLM prompts based on visual similarity to generate potential outlier class labels specialized for OOD detection, as well as (2) a new score function based on potential outlier penalty to distinguish hard OOD samples effectively. Empirically, EOE achieves state-of-the-art performance across different OOD tasks and can be effectively scaled to the ImageNet-1K dataset. The code is publicly available at: https://github.com/tmlr-group/EOE.
<div id='section'>Paperid: <span id='pid'>148, <a href='https://arxiv.org/pdf/2405.19882.pdf' target='_blank'>https://arxiv.org/pdf/2405.19882.pdf</a></span>   <span><a href='https://github.com/vojirt/PixOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>TomÃ¡Å¡ VojÃ­Å, Jan Å ochman, JiÅÃ­ Matas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19882">PixOOD: Pixel-Level Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a dense image prediction out-of-distribution detection algorithm, called PixOOD, which does not require training on samples of anomalous data and is not designed for a specific application which avoids traditional training biases. In order to model the complex intra-class variability of the in-distribution data at the pixel level, we propose an online data condensation algorithm which is more robust than standard K-means and is easily trainable through SGD. We evaluate PixOOD on a wide range of problems. It achieved state-of-the-art results on four out of seven datasets, while being competitive on the rest. The source code is available at https://github.com/vojirt/PixOOD.
<div id='section'>Paperid: <span id='pid'>149, <a href='https://arxiv.org/pdf/2405.18635.pdf' target='_blank'>https://arxiv.org/pdf/2405.18635.pdf</a></span>   <span><a href='https://github.com/deeplearning-wisc/id_label' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Du, Yiyou Sun, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18635">When and How Does In-Distribution Label Help Out-of-Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting data points deviating from the training distribution is pivotal for ensuring reliable machine learning. Extensive research has been dedicated to the challenge, spanning classical anomaly detection techniques to contemporary out-of-distribution (OOD) detection approaches. While OOD detection commonly relies on supervised learning from a labeled in-distribution (ID) dataset, anomaly detection may treat the entire ID data as a single class and disregard ID labels. This fundamental distinction raises a significant question that has yet to be rigorously explored: when and how does ID label help OOD detection? This paper bridges this gap by offering a formal understanding to theoretically delineate the impact of ID labels on OOD detection. We employ a graph-theoretic approach, rigorously analyzing the separability of ID data from OOD data in a closed-form manner. Key to our approach is the characterization of data representations through spectral decomposition on the graph. Leveraging these representations, we establish a provable error bound that compares the OOD detection performance with and without ID labels, unveiling conditions for achieving enhanced OOD detection. Lastly, we present empirical results on both simulated and real datasets, validating theoretical guarantees and reinforcing our insights. Code is publicly available at https://github.com/deeplearning-wisc/id_label.
<div id='section'>Paperid: <span id='pid'>150, <a href='https://arxiv.org/pdf/2405.17816.pdf' target='_blank'>https://arxiv.org/pdf/2405.17816.pdf</a></span>   <span><a href='https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingwen Wu, Ruiji Yu, Xinwen Cheng, Zhengbao He, Xiaolin Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17816">Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the open world, detecting out-of-distribution (OOD) data, whose labels are disjoint with those of in-distribution (ID) samples, is important for reliable deep neural networks (DNNs). To achieve better detection performance, one type of approach proposes to fine-tune the model with auxiliary OOD datasets to amplify the difference between ID and OOD data through a separation loss defined on model outputs. However, none of these studies consider enlarging the feature disparity, which should be more effective compared to outputs. The main difficulty lies in the diversity of OOD samples, which makes it hard to describe their feature distribution, let alone design losses to separate them from ID features. In this paper, we neatly fence off the problem based on an aggregation property of ID features named Neural Collapse (NC). NC means that the penultimate features of ID samples within a class are nearly identical to the last layer weight of the corresponding class. Based on this property, we propose a simple but effective loss called Separation Loss, which binds the features of OOD data in a subspace orthogonal to the principal subspace of ID features formed by NC. In this way, the features of ID and OOD samples are separated by different dimensions. By optimizing the feature separation loss rather than purely enlarging output differences, our detection achieves SOTA performance on CIFAR10, CIFAR100 and ImageNet benchmarks without any additional data augmentation or sampling, demonstrating the importance of feature separation in OOD detection. Code is available at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.
<div id='section'>Paperid: <span id='pid'>151, <a href='https://arxiv.org/pdf/2405.17419.pdf' target='_blank'>https://arxiv.org/pdf/2405.17419.pdf</a></span>   <span><a href='https://github.com/donghao51/MultiOOD' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/donghao51/MultiOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Dong, Yue Zhao, Eleni Chatzi, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17419">MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is important for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. Existing research has mainly focused on unimodal scenarios on image data. However, real-world applications are inherently multimodal, which makes it essential to leverage information from multiple modalities to enhance the efficacy of OOD detection. To establish a foundation for more realistic Multimodal OOD Detection, we introduce the first-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes and varying modality combinations. We first evaluate existing unimodal OOD detection algorithms on MultiOOD, observing that the mere inclusion of additional modalities yields substantial improvements. This underscores the importance of utilizing multiple modalities for OOD detection. Based on the observation of Modality Prediction Discrepancy between in-distribution (ID) and OOD data, and its strong correlation with OOD performance, we propose the Agree-to-Disagree (A2D) algorithm to encourage such discrepancy during training. Moreover, we introduce a novel outlier synthesis method, NP-Mix, which explores broader feature spaces by leveraging the information from nearest neighbor classes and complements A2D to strengthen OOD detection performance. Extensive experiments on MultiOOD demonstrate that training with A2D and NP-Mix improves existing OOD detection algorithms by a large margin. Our source code and MultiOOD benchmark are available at https://github.com/donghao51/MultiOOD.
<div id='section'>Paperid: <span id='pid'>152, <a href='https://arxiv.org/pdf/2405.16102.pdf' target='_blank'>https://arxiv.org/pdf/2405.16102.pdf</a></span>   <span><a href='https://github.com/zenghy96/Reliable-Source-Approximation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongye Zeng, Ke Zou, Zhihao Chen, Rui Zheng, Huazhu Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16102">Reliable Source Approximation: Source-Free Unsupervised Domain Adaptation for Vestibular Schwannoma MRI Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Source-Free Unsupervised Domain Adaptation (SFUDA) has recently become a focus in the medical image domain adaptation, as it only utilizes the source model and does not require annotated target data. However, current SFUDA approaches cannot tackle the complex segmentation task across different MRI sequences, such as the vestibular schwannoma segmentation. To address this problem, we proposed Reliable Source Approximation (RSA), which can generate source-like and structure-preserved images from the target domain for updating model parameters and adapting domain shifts. Specifically, RSA deploys a conditional diffusion model to generate multiple source-like images under the guidance of varying edges of one target image. An uncertainty estimation module is then introduced to predict and refine reliable pseudo labels of generated images, and the prediction consistency is developed to select the most reliable generations. Subsequently, all reliable generated images and their pseudo labels are utilized to update the model. Our RSA is validated on vestibular schwannoma segmentation across multi-modality MRI. The experimental results demonstrate that RSA consistently improves domain adaptation performance over other state-of-the-art SFUDA methods. Code is available at https://github.com/zenghy96/Reliable-Source-Approximation.
<div id='section'>Paperid: <span id='pid'>153, <a href='https://arxiv.org/pdf/2405.13758.pdf' target='_blank'>https://arxiv.org/pdf/2405.13758.pdf</a></span>   <span><a href='https://github.com/olivesgatech/GradTrust' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohit Prabhushankar, Ghassan AlRegib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13758">Counterfactual Gradients-based Quantification of Prediction Trust in Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The widespread adoption of deep neural networks in machine learning calls for an objective quantification of esoteric trust. In this paper we propose GradTrust, a classification trust measure for large-scale neural networks at inference. The proposed method utilizes variance of counterfactual gradients, i.e. the required changes in the network parameters if the label were different. We show that GradTrust is superior to existing techniques for detecting misprediction rates on $50000$ images from ImageNet validation dataset. Depending on the network, GradTrust detects images where either the ground truth is incorrect or ambiguous, or the classes are co-occurring. We extend GradTrust to Video Action Recognition on Kinetics-400 dataset. We showcase results on $14$ architectures pretrained on ImageNet and $5$ architectures pretrained on Kinetics-400. We observe the following: (i) simple methodologies like negative log likelihood and margin classifiers outperform state-of-the-art uncertainty and out-of-distribution detection techniques for misprediction rates, and (ii) the proposed GradTrust is in the Top-2 performing methods on $37$ of the considered $38$ experimental modalities. The code is available at: https://github.com/olivesgatech/GradTrust
<div id='section'>Paperid: <span id='pid'>154, <a href='https://arxiv.org/pdf/2405.11881.pdf' target='_blank'>https://arxiv.org/pdf/2405.11881.pdf</a></span>   <span><a href='https://github.com/clear-nus/diffpath' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alvin Heng, Alexandre H. Thiery, Harold Soh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11881">Out-of-Distribution Detection with a Single Unconditional Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical task in machine learning that seeks to identify abnormal samples. Traditionally, unsupervised methods utilize a deep generative model for OOD detection. However, such approaches require a new model to be trained for each inlier dataset. This paper explores whether a single model can perform OOD detection across diverse tasks. To that end, we introduce Diffusion Paths (DiffPath), which uses a single diffusion model originally trained to perform unconditional generation for OOD detection. We introduce a novel technique of measuring the rate-of-change and curvature of the diffusion paths connecting samples to the standard normal. Extensive experiments show that with a single model, DiffPath is competitive with prior work using individual models on a variety of OOD tasks involving different distributions. Our code is publicly available at https://github.com/clear-nus/diffpath.
<div id='section'>Paperid: <span id='pid'>155, <a href='https://arxiv.org/pdf/2405.04405.pdf' target='_blank'>https://arxiv.org/pdf/2405.04405.pdf</a></span>   <span><a href='https://github.com/liupei101/MIREL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei Liu, Luping Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.04405">Weakly-Supervised Residual Evidential Learning for Multi-Instance Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation (UE), as an effective means of quantifying predictive uncertainty, is crucial for safe and reliable decision-making, especially in high-risk scenarios. Existing UE schemes usually assume that there are completely-labeled samples to support fully-supervised learning. In practice, however, many UE tasks often have no sufficiently-labeled data to use, such as the Multiple Instance Learning (MIL) with only weak instance annotations. To bridge this gap, this paper, for the first time, addresses the weakly-supervised issue of Multi-Instance UE (MIUE) and proposes a new baseline scheme, Multi-Instance Residual Evidential Learning (MIREL). Particularly, at the fine-grained instance UE with only weak supervision, we derive a multi-instance residual operator through the Fundamental Theorem of Symmetric Functions. On this operator derivation, we further propose MIREL to jointly model the high-order predictive distribution at bag and instance levels for MIUE. Extensive experiments empirically demonstrate that our MIREL not only could often make existing MIL networks perform better in MIUE, but also could surpass representative UE methods by large margins, especially in instance-level UE tasks. Our source code is available at https://github.com/liupei101/MIREL.
<div id='section'>Paperid: <span id='pid'>156, <a href='https://arxiv.org/pdf/2405.02154.pdf' target='_blank'>https://arxiv.org/pdf/2405.02154.pdf</a></span>   <span><a href='https://github.com/ddrous/ncflow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Roussel Desmond Nzoyem, David A. W. Barton, Tom Deakin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02154">Neural Context Flows for Meta-Learning of Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Ordinary Differential Equations (NODEs) often struggle to adapt to new dynamic behaviors caused by parameter changes in the underlying physical system, even when these dynamics are similar to previously observed behaviors. This problem becomes more challenging when the changing parameters are unobserved, meaning their value or influence cannot be directly measured when collecting data. To address this issue, we introduce Neural Context Flow (NCF), a robust and interpretable Meta-Learning framework that includes uncertainty estimation. NCF uses Taylor expansion to enable contextual self-modulation, allowing context vectors to influence dynamics from other domains while also modulating themselves. After establishing theoretical guarantees, we empirically test NCF and compare it to related adaptation methods. Our results show that NCF achieves state-of-the-art Out-of-Distribution performance on 5 out of 6 linear and non-linear benchmark problems. Through extensive experiments, we explore the flexible model architecture of NCF and the encoded representations within the learned context vectors. Our findings highlight the potential implications of NCF for foundational models in the physical sciences, offering a promising approach to improving the adaptability and generalization of NODEs in various scientific applications. Our code is openly available at https://github.com/ddrous/ncflow.
<div id='section'>Paperid: <span id='pid'>157, <a href='https://arxiv.org/pdf/2405.02154.pdf' target='_blank'>https://arxiv.org/pdf/2405.02154.pdf</a></span>   <span><a href='https://github.com/ddrous/ncflow' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Roussel Desmond Nzoyem, David A. W. Barton, Tom Deakin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02154">Neural Context Flows for Meta-Learning of Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Ordinary Differential Equations (NODEs) often struggle to adapt to new dynamic behaviors caused by parameter changes in the underlying physical system, even when these dynamics are similar to previously observed behaviors. This problem becomes more challenging when the changing parameters are unobserved, meaning their value or influence cannot be directly measured when collecting data. To address this issue, we introduce Neural Context Flow (NCF), a robust and interpretable Meta-Learning framework that includes uncertainty estimation. NCF uses Taylor expansion to enable contextual self-modulation, allowing context vectors to influence dynamics from other domains while also modulating themselves. After establishing theoretical guarantees, we empirically test NCF and compare it to related adaptation methods. Our results show that NCF achieves state-of-the-art Out-of-Distribution performance on 5 out of 6 linear and non-linear benchmark problems. Through extensive experiments, we explore the flexible model architecture of NCF and the encoded representations within the learned context vectors. Our findings highlight the potential implications of NCF for foundational models in the physical sciences, offering a promising approach to improving the adaptability and generalization of NODEs in various scientific applications. Our code is openly available at https://github.com/ddrous/ncflow.
<div id='section'>Paperid: <span id='pid'>158, <a href='https://arxiv.org/pdf/2405.01662.pdf' target='_blank'>https://arxiv.org/pdf/2405.01662.pdf</a></span>   <span><a href='https://github.com/Hewell0/ProjOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiuyu Zhu, Yiwei He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01662">Out-of-distribution detection based on subspace projection of high-dimensional features output by the last convolutional layer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection, crucial for reliable pattern classification, discerns whether a sample originates outside the training distribution. This paper concentrates on the high-dimensional features output by the final convolutional layer, which contain rich image features. Our key idea is to project these high-dimensional features into two specific feature subspaces, leveraging the dimensionality reduction capacity of the network's linear layers, trained with Predefined Evenly-Distribution Class Centroids (PEDCC)-Loss. This involves calculating the cosines of three projection angles and the norm values of features, thereby identifying distinctive information for in-distribution (ID) and OOD data, which assists in OOD detection. Building upon this, we have modified the batch normalization (BN) and ReLU layer preceding the fully connected layer, diminishing their impact on the output feature distributions and thereby widening the distribution gap between ID and OOD data features. Our method requires only the training of the classification network model, eschewing any need for input pre-processing or specific OOD data pre-tuning. Extensive experiments on several benchmark datasets demonstrates that our approach delivers state-of-the-art performance. Our code is available at https://github.com/Hewell0/ProjOOD.
<div id='section'>Paperid: <span id='pid'>159, <a href='https://arxiv.org/pdf/2404.17978.pdf' target='_blank'>https://arxiv.org/pdf/2404.17978.pdf</a></span>   <span><a href='https://github.com/mmajurski/ssl-gmm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Majurski, Sumeet Menon, Parniyan Farvardin, David Chapman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17978">A Method of Moments Embedding Constraint and its Application to Semi-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discriminative deep learning models with a linear+softmax final layer have a problem: the latent space only predicts the conditional probabilities $p(Y|X)$ but not the full joint distribution $p(Y,X)$, which necessitates a generative approach. The conditional probability cannot detect outliers, causing outlier sensitivity in softmax networks. This exacerbates model over-confidence impacting many problems, such as hallucinations, confounding biases, and dependence on large datasets. To address this we introduce a novel embedding constraint based on the Method of Moments (MoM). We investigate the use of polynomial moments ranging from 1st through 4th order hyper-covariance matrices. Furthermore, we use this embedding constraint to train an Axis-Aligned Gaussian Mixture Model (AAGMM) final layer, which learns not only the conditional, but also the joint distribution of the latent space. We apply this method to the domain of semi-supervised image classification by extending FlexMatch with our technique. We find our MoM constraint with the AAGMM layer is able to match the reported FlexMatch accuracy, while also modeling the joint distribution, thereby reducing outlier sensitivity. We also present a preliminary outlier detection strategy based on Mahalanobis distance and discuss future improvements to this strategy. Code is available at: \url{https://github.com/mmajurski/ssl-gmm}
<div id='section'>Paperid: <span id='pid'>160, <a href='https://arxiv.org/pdf/2404.15879.pdf' target='_blank'>https://arxiv.org/pdf/2404.15879.pdf</a></span>   <span><a href='https://github.com/uulm-mrm/mmood3d' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael KÃ¶sel, Marcel Schreiber, Michael Ulrich, Claudius GlÃ¤ser, Klaus Dietmayer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15879">Revisiting Out-of-Distribution Detection in LiDAR-based 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based 3D object detection has become an essential part of automated driving due to its ability to localize and classify objects precisely in 3D. However, object detectors face a critical challenge when dealing with unknown foreground objects, particularly those that were not present in their original training data. These out-of-distribution (OOD) objects can lead to misclassifications, posing a significant risk to the safety and reliability of automated vehicles. Currently, LiDAR-based OOD object detection has not been well studied. We address this problem by generating synthetic training data for OOD objects by perturbing known object categories. Our idea is that these synthetic OOD objects produce different responses in the feature map of an object detector compared to in-distribution (ID) objects. We then extract features using a pre-trained and fixed object detector and train a simple multilayer perceptron (MLP) to classify each detection as either ID or OOD. In addition, we propose a new evaluation protocol that allows the use of existing datasets without modifying the point cloud, ensuring a more authentic evaluation of real-world scenarios. The effectiveness of our method is validated through experiments on the newly proposed nuScenes OOD benchmark. The source code is available at https://github.com/uulm-mrm/mmood3d.
<div id='section'>Paperid: <span id='pid'>161, <a href='https://arxiv.org/pdf/2404.12368.pdf' target='_blank'>https://arxiv.org/pdf/2404.12368.pdf</a></span>   <span><a href='https://github.com/o4lc/Greg-OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sina Sharifi, Taha Entesari, Bardia Safaei, Vishal M. Patel, Mahyar Fazlyab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12368">Gradient-Regularized Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One of the challenges for neural networks in real-life applications is the overconfident errors these models make when the data is not from the original training distribution.
  Addressing this issue is known as Out-of-Distribution (OOD) detection.
  Many state-of-the-art OOD methods employ an auxiliary dataset as a surrogate for OOD data during training to achieve improved performance.
  However, these methods fail to fully exploit the local information embedded in the auxiliary dataset.
  In this work, we propose the idea of leveraging the information embedded in the gradient of the loss function during training to enable the network to not only learn a desired OOD score for each sample but also to exhibit similar behavior in a local neighborhood around each sample.
  We also develop a novel energy-based sampling method to allow the network to be exposed to more informative OOD samples during the training phase. This is especially important when the auxiliary dataset is large. We demonstrate the effectiveness of our method through extensive experiments on several OOD benchmarks, improving the existing state-of-the-art FPR95 by 4% on our ImageNet experiment.
  We further provide a theoretical analysis through the lens of certified robustness and Lipschitz analysis to showcase the theoretical foundation of our work. Our code is available at https://github.com/o4lc/Greg-OOD.
<div id='section'>Paperid: <span id='pid'>162, <a href='https://arxiv.org/pdf/2404.07032.pdf' target='_blank'>https://arxiv.org/pdf/2404.07032.pdf</a></span>   <span><a href='https://github.com/Medsemiseg' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenxi Zhang, Heng Zhou, Xiaoran Shi, Ran Ran, Chunna Tian, Feng Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07032">An Evidential-enhanced Tri-Branch Consistency Learning Method for Semi-supervised Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised segmentation presents a promising approach for large-scale medical image analysis, effectively reducing annotation burdens while achieving comparable performance. This methodology holds substantial potential for streamlining the segmentation process and enhancing its feasibility within clinical settings for translational investigations. While cross-supervised training, based on distinct co-training sub-networks, has become a prevalent paradigm for this task, addressing critical issues such as predication disagreement and label-noise suppression requires further attention and progress in cross-supervised training. In this paper, we introduce an Evidential Tri-Branch Consistency learning framework (ETC-Net) for semi-supervised medical image segmentation. ETC-Net employs three branches: an evidential conservative branch, an evidential progressive branch, and an evidential fusion branch. The first two branches exhibit complementary characteristics, allowing them to address prediction diversity and enhance training stability. We also integrate uncertainty estimation from the evidential learning into cross-supervised training, mitigating the negative impact of erroneous supervision signals. Additionally, the evidential fusion branch capitalizes on the complementary attributes of the first two branches and leverages an evidence-based Dempster-Shafer fusion strategy, supervised by more reliable and accurate pseudo-labels of unlabeled data. Extensive experiments conducted on LA, Pancreas-CT, and ACDC datasets demonstrate that ETC-Net surpasses other state-of-the-art methods for semi-supervised segmentation. The code will be made available in the near future at https://github.com/Medsemiseg.
<div id='section'>Paperid: <span id='pid'>163, <a href='https://arxiv.org/pdf/2404.06217.pdf' target='_blank'>https://arxiv.org/pdf/2404.06217.pdf</a></span>   <span><a href='https://github.com/liam0949/LLM-OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Li-Ming Zhan, Bo Liu, Xiao-Ming Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06217">VI-OOD: A Unified Representation Learning Framework for Textual Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection plays a crucial role in ensuring the safety and reliability of deep neural networks in various applications. While there has been a growing focus on OOD detection in visual data, the field of textual OOD detection has received less attention. Only a few attempts have been made to directly apply general OOD detection methods to natural language processing (NLP) tasks, without adequately considering the characteristics of textual data. In this paper, we delve into textual OOD detection with Transformers. We first identify a key problem prevalent in existing OOD detection methods: the biased representation learned through the maximization of the conditional likelihood $p(y\mid x)$ can potentially result in subpar performance. We then propose a novel variational inference framework for OOD detection (VI-OOD), which maximizes the likelihood of the joint distribution $p(x, y)$ instead of $p(y\mid x)$. VI-OOD is tailored for textual OOD detection by efficiently exploiting the representations of pre-trained Transformers. Through comprehensive experiments on various text classification tasks, VI-OOD demonstrates its effectiveness and wide applicability. Our code has been released at \url{https://github.com/liam0949/LLM-OOD}.
<div id='section'>Paperid: <span id='pid'>164, <a href='https://arxiv.org/pdf/2404.04550.pdf' target='_blank'>https://arxiv.org/pdf/2404.04550.pdf</a></span>   <span><a href='https://github.com/samahkh/NPB-REC' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Samah Khawaled, Moti Freiman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04550">NPB-REC: A Non-parametric Bayesian Deep-learning Approach for Undersampled MRI Reconstruction with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to reconstruct high-quality images from undersampled MRI data is vital in improving MRI temporal resolution and reducing acquisition times. Deep learning methods have been proposed for this task, but the lack of verified methods to quantify the uncertainty in the reconstructed images hampered clinical applicability. We introduce "NPB-REC", a non-parametric fully Bayesian framework, for MRI reconstruction from undersampled data with uncertainty estimation. We use Stochastic Gradient Langevin Dynamics during training to characterize the posterior distribution of the network parameters. This enables us to both improve the quality of the reconstructed images and quantify the uncertainty in the reconstructed images. We demonstrate the efficacy of our approach on a multi-coil MRI dataset from the fastMRI challenge and compare it to the baseline End-to-End Variational Network (E2E-VarNet). Our approach outperforms the baseline in terms of reconstruction accuracy by means of PSNR and SSIM ($34.55$, $0.908$ vs. $33.08$, $0.897$, $p<0.01$, acceleration rate $R=8$) and provides uncertainty measures that correlate better with the reconstruction error (Pearson correlation, $R=0.94$ vs. $R=0.91$). Additionally, our approach exhibits better generalization capabilities against anatomical distribution shifts (PSNR and SSIM of $32.38$, $0.849$ vs. $31.63$, $0.836$, $p<0.01$, training on brain data, inference on knee data, acceleration rate $R=8$). NPB-REC has the potential to facilitate the safe utilization of deep learning-based methods for MRI reconstruction from undersampled data. Code and trained models are available at \url{https://github.com/samahkh/NPB-REC}.
<div id='section'>Paperid: <span id='pid'>165, <a href='https://arxiv.org/pdf/2404.03248.pdf' target='_blank'>https://arxiv.org/pdf/2404.03248.pdf</a></span>   <span><a href='https://github.com/mala-lab/negprompt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianqi Li, Guansong Pang, Xiao Bai, Wenjun Miao, Jin Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.03248">Learning Transferable Negative Prompts for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing prompt learning methods have shown certain capabilities in Out-of-Distribution (OOD) detection, but the lack of OOD images in the target dataset in their training can lead to mismatches between OOD images and In-Distribution (ID) categories, resulting in a high false positive rate. To address this issue, we introduce a novel OOD detection method, named 'NegPrompt', to learn a set of negative prompts, each representing a negative connotation of a given class label, for delineating the boundaries between ID and OOD images. It learns such negative prompts with ID data only, without any reliance on external outlier data. Further, current methods assume the availability of samples of all ID classes, rendering them ineffective in open-vocabulary learning scenarios where the inference stage can contain novel ID classes not present during training. In contrast, our learned negative prompts are transferable to novel class labels. Experiments on various ImageNet benchmarks show that NegPrompt surpasses state-of-the-art prompt-learning-based OOD detection methods and maintains a consistent lead in hard OOD detection in closed- and open-vocabulary classification scenarios. Code is available at https://github.com/mala-lab/negprompt.
<div id='section'>Paperid: <span id='pid'>166, <a href='https://arxiv.org/pdf/2404.02515.pdf' target='_blank'>https://arxiv.org/pdf/2404.02515.pdf</a></span>   <span><a href='https://github.com/TakuOkawara/full_linear_wheel_odometry_factor' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taku Okawara, Kenji Koide, Shuji Oishi, Masashi Yokozuka, Atsuhiko Banno, Kentaro Uno, Kazuya Yoshida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.02515">Tightly-Coupled LiDAR-IMU-Wheel Odometry with Online Calibration of a Kinematic Model for Skid-Steering Robots</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tunnels and long corridors are challenging environments for mobile robots because a LiDAR point cloud should degenerate in these environments. To tackle point cloud degeneration, this study presents a tightly-coupled LiDAR-IMU-wheel odometry algorithm with an online calibration for skid-steering robots. We propose a full linear wheel odometry factor, which not only serves as a motion constraint but also performs the online calibration of kinematic models for skid-steering robots. Despite the dynamically changing kinematic model (e.g., wheel radii changes caused by tire pressures) and terrain conditions, our method can address the model error via online calibration. Moreover, our method enables an accurate localization in cases of degenerated environments, such as long and straight corridors, by calibration while the LiDAR-IMU fusion sufficiently operates. Furthermore, we estimate the uncertainty (i.e., covariance matrix) of the wheel odometry online for creating a reasonable constraint. The proposed method is validated through three experiments. The first indoor experiment shows that the proposed method is robust in severe degeneracy cases (long corridors) and changes in the wheel radii. The second outdoor experiment demonstrates that our method accurately estimates the sensor trajectory despite being in rough outdoor terrain owing to online uncertainty estimation of wheel odometry. The third experiment shows the proposed online calibration enables robust odometry estimation in changing terrains.
<div id='section'>Paperid: <span id='pid'>167, <a href='https://arxiv.org/pdf/2403.19137.pdf' target='_blank'>https://arxiv.org/pdf/2403.19137.pdf</a></span>   <span><a href='https://github.com/srvCodes/clap4clip' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurav Jha, Dong Gong, Lina Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.19137">CLAP4CLIP: Continual Learning with Probabilistic Finetuning for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual learning (CL) aims to help deep neural networks learn new knowledge while retaining what has been learned. Owing to their powerful generalizability, pre-trained vision-language models such as Contrastive Language-Image Pre-training (CLIP) have lately gained traction as practical CL candidates. However, the domain mismatch between the pre-training and the downstream CL tasks often calls for finetuning of the CLIP on the latter. Most existing finetuning methods exhibit deterministic nature. This makes them overlook the many possible interactions across the input modalities and deems them unsafe for high-risk tasks requiring reliable uncertainty estimation. To address these, our work proposes Continual LeArning with Probabilistic finetuning (CLAP) - a probabilistic modeling framework over visual-guided text features per task, thus providing more calibrated CL finetuning. Unlike recent data-hungry anti-forgetting CL techniques, CLAP alleviates forgetting by exploiting the rich pre-trained knowledge of CLIP for weight initialization and distribution regularization of task-specific parameters. Cooperating with the diverse range of existing prompting methods, CLAP can surpass the predominant deterministic finetuning approaches for CL with CLIP. We conclude with out-of-the-box applications of superior uncertainty estimation abilities of CLAP including novel data detection and exemplar selection within the existing CL setups. Our code is available at \url{https://github.com/srvCodes/clap4clip}.
<div id='section'>Paperid: <span id='pid'>168, <a href='https://arxiv.org/pdf/2403.17010.pdf' target='_blank'>https://arxiv.org/pdf/2403.17010.pdf</a></span>   <span><a href='https://github.com/ldkong1205/Calib3D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lingdong Kong, Xiang Xu, Jun Cen, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17010">Calib3D: Calibrating Model Preferences for Reliable 3D Scene Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safety-critical 3D scene understanding tasks necessitate not only accurate but also confident predictions from 3D perception models. This study introduces Calib3D, a pioneering effort to benchmark and scrutinize the reliability of 3D scene understanding models from an uncertainty estimation viewpoint. We comprehensively evaluate 28 state-of-the-art models across 10 diverse 3D datasets, uncovering insightful phenomena that cope with both the aleatoric and epistemic uncertainties in 3D scene understanding. We discover that despite achieving impressive levels of accuracy, existing models frequently fail to provide reliable uncertainty estimates -- a pitfall that critically undermines their applicability in safety-sensitive contexts. Through extensive analysis of key factors such as network capacity, LiDAR representations, rasterization resolutions, and 3D data augmentation techniques, we correlate these aspects directly with the model calibration efficacy. Furthermore, we introduce DeptS, a novel depth-aware scaling approach aimed at enhancing 3D model calibration. Extensive experiments across a wide range of configurations validate the superiority of our method. We hope this work could serve as a cornerstone for fostering reliable 3D scene understanding. Code and benchmark toolkit are publicly available.
<div id='section'>Paperid: <span id='pid'>169, <a href='https://arxiv.org/pdf/2403.15836.pdf' target='_blank'>https://arxiv.org/pdf/2403.15836.pdf</a></span>   <span><a href='https://github.com/HiLab-git/VLM-CPL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lanfeng Zhong, Zongyao Huang, Yang Liu, Wenjun Liao, Shichuan Zhang, Guotai Wang, Shaoting Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15836">VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Annotation-Free Pathological Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Classification of pathological images is the basis for automatic cancer diagnosis. Despite that deep learning methods have achieved remarkable performance, they heavily rely on labeled data, demanding extensive human annotation efforts. In this study, we present a novel human annotation-free method by leveraging pre-trained Vision-Language Models (VLMs). Without human annotation, pseudo-labels of the training set are obtained by utilizing the zero-shot inference capabilities of VLM, which may contain a lot of noise due to the domain gap between the pre-training and target datasets. To address this issue, we introduce VLM-CPL, a novel approach that contains two noisy label filtering techniques with a semi-supervised learning strategy. Specifically, we first obtain prompt-based pseudo-labels with uncertainty estimation by zero-shot inference with the VLM using multiple augmented views of an input. Then, by leveraging the feature representation ability of VLM, we obtain feature-based pseudo-labels via sample clustering in the feature space. Prompt-feature consensus is introduced to select reliable samples based on the consensus between the two types of pseudo-labels. We further propose High-confidence Cross Supervision by to learn from samples with reliable pseudo-labels and the remaining unlabeled samples. Additionally, we present an innovative open-set prompting strategy that filters irrelevant patches from whole slides to enhance the quality of selected patches. Experimental results on five public pathological image datasets for patch-level and slide-level classification showed that our method substantially outperformed zero-shot classification by VLMs, and was superior to existing noisy label learning methods. The code is publicly available at https://github.com/HiLab-git/VLM-CPL.
<div id='section'>Paperid: <span id='pid'>170, <a href='https://arxiv.org/pdf/2403.11256.pdf' target='_blank'>https://arxiv.org/pdf/2403.11256.pdf</a></span>   <span><a href='https://github.com/chenxi52/UPA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi Chen, Haosen Yang, Huicong Zhang, Hongxun Yao, Xiatian Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11256">Uncertainty-Aware Pseudo-Label Filtering for Source-Free Unsupervised Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Source-free unsupervised domain adaptation (SFUDA) aims to enable the utilization of a pre-trained source model in an unlabeled target domain without access to source data. Self-training is a way to solve SFUDA, where confident target samples are iteratively selected as pseudo-labeled samples to guide target model learning. However, prior heuristic noisy pseudo-label filtering methods all involve introducing extra models, which are sensitive to model assumptions and may introduce additional errors or mislabeling. In this work, we propose a method called Uncertainty-aware Pseudo-label-filtering Adaptation (UPA) to efficiently address this issue in a coarse-to-fine manner. Specially, we first introduce a sample selection module named Adaptive Pseudo-label Selection (APS), which is responsible for filtering noisy pseudo labels. The APS utilizes a simple sample uncertainty estimation method by aggregating knowledge from neighboring samples and confident samples are selected as clean pseudo-labeled. Additionally, we incorporate Class-Aware Contrastive Learning (CACL) to mitigate the memorization of pseudo-label noise by learning robust pair-wise representation supervised by pseudo labels. Through extensive experiments conducted on three widely used benchmarks, we demonstrate that our proposed method achieves competitive performance on par with state-of-the-art SFUDA methods. Code is available at https://github.com/chenxi52/UPA.
<div id='section'>Paperid: <span id='pid'>171, <a href='https://arxiv.org/pdf/2403.04073.pdf' target='_blank'>https://arxiv.org/pdf/2403.04073.pdf</a></span>   <span><a href='https://github.com/amazon-science/summarization-sicf-score' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianfeng He, Hang Su, Jason Cai, Igor Shalyminov, Hwanjun Song, Saab Mansour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04073">Semi-Supervised Dialogue Abstractive Summarization via High-Quality Pseudolabel Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised dialogue summarization (SSDS) leverages model-generated summaries to reduce reliance on human-labeled data and improve the performance of summarization models. While addressing label noise, previous works on semi-supervised learning primarily focus on natural language understanding tasks, assuming each sample has a unique label. However, these methods are not directly applicable to SSDS, as it is a generative task, and each dialogue can be summarized in different ways. In this work, we propose a novel scoring approach, SiCF, which encapsulates three primary dimensions of summarization model quality: Semantic invariance (indicative of model confidence), Coverage (factual recall), and Faithfulness (factual precision). Using the SiCF score, we select unlabeled dialogues with high-quality generated summaries to train summarization models. Comprehensive experiments on three public datasets demonstrate the effectiveness of SiCF scores in uncertainty estimation and semi-supervised learning for dialogue summarization tasks. Our code is available at \url{https://github.com/amazon-science/summarization-sicf-score}.
<div id='section'>Paperid: <span id='pid'>172, <a href='https://arxiv.org/pdf/2402.19460.pdf' target='_blank'>https://arxiv.org/pdf/2402.19460.pdf</a></span>   <span><a href='https://github.com/bmucsanyi/untangle' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>BÃ¡lint MucsÃ¡nyi, Michael Kirchhof, Seong Joon Oh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.19460">Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one source of uncertainty. This paper presents the first benchmark of uncertainty disentanglement. We reimplement and evaluate a comprehensive range of uncertainty estimators, from Bayesian over evidential to deterministic ones, across a diverse range of uncertainty tasks on ImageNet. We find that, despite recent theoretical endeavors, no existing approach provides pairs of disentangled uncertainty estimators in practice. We further find that specialized uncertainty tasks are harder than predictive uncertainty tasks, where we observe saturating performance. Our results provide both practical advice for which uncertainty estimators to use for which specific task, and reveal opportunities for future research toward task-centric and disentangled uncertainties. All our reimplementations and Weights & Biases logs are available at https://github.com/bmucsanyi/untangle.
<div id='section'>Paperid: <span id='pid'>173, <a href='https://arxiv.org/pdf/2402.18451.pdf' target='_blank'>https://arxiv.org/pdf/2402.18451.pdf</a></span>   <span><a href='https://github.com/ayanglab/MambaMIR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Huang, Liutao Yang, Fanwen Wang, Yang Nan, Angelica I. Aviles-Rivero, Carola-Bibiane SchÃ¶nlieb, Daoqiang Zhang, Guang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18451">MambaMIR: An Arbitrary-Masked Mamba for Joint Medical Image Reconstruction and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent Mamba model has shown remarkable adaptability for visual representation learning, including in medical imaging tasks. This study introduces MambaMIR, a Mamba-based model for medical image reconstruction, as well as its Generative Adversarial Network-based variant, MambaMIR-GAN. Our proposed MambaMIR inherits several advantages, such as linear complexity, global receptive fields, and dynamic weights, from the original Mamba model. The innovated arbitrary-mask mechanism effectively adapt Mamba to our image reconstruction task, providing randomness for subsequent Monte Carlo-based uncertainty estimation. Experiments conducted on various medical image reconstruction tasks, including fast MRI and SVCT, which cover anatomical regions such as the knee, chest, and abdomen, have demonstrated that MambaMIR and MambaMIR-GAN achieve comparable or superior reconstruction results relative to state-of-the-art methods. Additionally, the estimated uncertainty maps offer further insights into the reliability of the reconstruction quality. The code is publicly available at https://github.com/ayanglab/MambaMIR.
<div id='section'>Paperid: <span id='pid'>174, <a href='https://arxiv.org/pdf/2402.16569.pdf' target='_blank'>https://arxiv.org/pdf/2402.16569.pdf</a></span>   <span><a href='https://github.com/mkirchhof/url' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Kirchhof, Mark Collier, Seong Joon Oh, Enkelejda Kasneci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16569">Pretrained Visual Uncertainties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty estimation is vital to trustworthy machine learning, yet uncertainties typically have to be learned for each task anew. This work introduces the first pretrained uncertainty modules for vision models. Similar to standard pretraining this enables the zero-shot transfer of uncertainties learned on a large pretraining dataset to specialized downstream datasets. We enable our large-scale pretraining on ImageNet-21k by solving a gradient conflict in previous uncertainty modules and accelerating the training by up to 180x. We find that the pretrained uncertainties generalize to unseen datasets. In scrutinizing the learned uncertainties, we find that they capture aleatoric uncertainty, disentangled from epistemic components. We demonstrate that this enables safe retrieval and uncertainty-aware dataset visualization. To encourage applications to further problems and domains, we release all pretrained checkpoints and code under https://github.com/mkirchhof/url .
<div id='section'>Paperid: <span id='pid'>175, <a href='https://arxiv.org/pdf/2402.14371.pdf' target='_blank'>https://arxiv.org/pdf/2402.14371.pdf</a></span>   <span><a href='https://github.com/lck666666/HR-APR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Changkun Liu, Shuai Chen, Yukun Zhao, Huajian Huang, Victor Prisacariu, Tristan Braud
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14371">HR-APR: APR-agnostic Framework with Uncertainty Estimation and Hierarchical Refinement for Camera Relocalisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Absolute Pose Regressors (APRs) directly estimate camera poses from monocular images, but their accuracy is unstable for different queries. Uncertainty-aware APRs provide uncertainty information on the estimated pose, alleviating the impact of these unreliable predictions. However, existing uncertainty modelling techniques are often coupled with a specific APR architecture, resulting in suboptimal performance compared to state-of-the-art (SOTA) APR methods. This work introduces a novel APR-agnostic framework, HR-APR, that formulates uncertainty estimation as cosine similarity estimation between the query and database features. It does not rely on or affect APR network architecture, which is flexible and computationally efficient. In addition, we take advantage of the uncertainty for pose refinement to enhance the performance of APR. The extensive experiments demonstrate the effectiveness of our framework, reducing 27.4\% and 15.2\% of computational overhead on the 7Scenes and Cambridge Landmarks datasets while maintaining the SOTA accuracy in single-image APRs.
<div id='section'>Paperid: <span id='pid'>176, <a href='https://arxiv.org/pdf/2402.12128.pdf' target='_blank'>https://arxiv.org/pdf/2402.12128.pdf</a></span>   <span><a href='https://github.com/gzq17/Weakly-Supervised-by-MIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanqiang Guo, Zimeng Tan, Jianjiang Feng, Jie Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12128">3D Vascular Segmentation Supervised by 2D Annotation of Maximum Intensity Projection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vascular structure segmentation plays a crucial role in medical analysis and clinical applications. The practical adoption of fully supervised segmentation models is impeded by the intricacy and time-consuming nature of annotating vessels in the 3D space. This has spurred the exploration of weakly-supervised approaches that reduce reliance on expensive segmentation annotations. Despite this, existing weakly supervised methods employed in organ segmentation, which encompass points, bounding boxes, or graffiti, have exhibited suboptimal performance when handling sparse vascular structure. To alleviate this issue, we employ maximum intensity projection (MIP) to decrease the dimensionality of 3D volume to 2D image for efficient annotation, and the 2D labels are utilized to provide guidance and oversight for training 3D vessel segmentation model. Initially, we generate pseudo-labels for 3D blood vessels using the annotations of 2D projections. Subsequently, taking into account the acquisition method of the 2D labels, we introduce a weakly-supervised network that fuses 2D-3D deep features via MIP to further improve segmentation performance. Furthermore, we integrate confidence learning and uncertainty estimation to refine the generated pseudo-labels, followed by fine-tuning the segmentation network. Our method is validated on five datasets (including cerebral vessel, aorta and coronary artery), demonstrating highly competitive performance in segmenting vessels and the potential to significantly reduce the time and effort required for vessel annotation. Our code is available at: https://github.com/gzq17/Weakly-Supervised-by-MIP.
<div id='section'>Paperid: <span id='pid'>177, <a href='https://arxiv.org/pdf/2402.11756.pdf' target='_blank'>https://arxiv.org/pdf/2402.11756.pdf</a></span>   <span><a href='https://github.com/Ybakman/LLM_Uncertainity' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yavuz Faruk Bakman, Duygu Nur Yaldiz, Baturalp Buyukates, Chenyang Tao, Dimitrios Dimitriadis, Salman Avestimehr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11756">MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative Large Language Models (LLMs) are widely utilized for their excellence in various tasks. However, their tendency to produce inaccurate or misleading outputs poses a potential risk, particularly in high-stakes environments. Therefore, estimating the correctness of generative LLM outputs is an important task for enhanced reliability. Uncertainty Estimation (UE) in generative LLMs is an evolving domain, where SOTA probability-based methods commonly employ length-normalized scoring. In this work, we propose Meaning-Aware Response Scoring (MARS) as an alternative to length-normalized scoring for UE methods. MARS is a novel scoring function that considers the semantic contribution of each token in the generated sequence in the context of the question. We demonstrate that integrating MARS into UE methods results in a universal and significant improvement in UE performance. We conduct experiments using three distinct closed-book question-answering datasets across five popular pre-trained LLMs. Lastly, we validate the efficacy of MARS on a Medical QA dataset. Code can be found https://github.com/Ybakman/LLM_Uncertainity.
<div id='section'>Paperid: <span id='pid'>178, <a href='https://arxiv.org/pdf/2402.10573.pdf' target='_blank'>https://arxiv.org/pdf/2402.10573.pdf</a></span>   <span><a href='https://github.com/zhzhengit/LinkNER' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Zhang, Yuhua Zhao, Hang Gao, Mengting Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10573">LinkNER: Linking Local Named Entity Recognition Models to Large Language Models using Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Named Entity Recognition (NER) serves as a fundamental task in natural language understanding, bearing direct implications for web content analysis, search engines, and information retrieval systems. Fine-tuned NER models exhibit satisfactory performance on standard NER benchmarks. However, due to limited fine-tuning data and lack of knowledge, it performs poorly on unseen entity recognition. As a result, the usability and reliability of NER models in web-related applications are compromised. Instead, Large Language Models (LLMs) like GPT-4 possess extensive external knowledge, but research indicates that they lack specialty for NER tasks. Furthermore, non-public and large-scale weights make tuning LLMs difficult. To address these challenges, we propose a framework that combines small fine-tuned models with LLMs (LinkNER) and an uncertainty-based linking strategy called RDC that enables fine-tuned models to complement black-box LLMs, achieving better performance. We experiment with both standard NER test sets and noisy social media datasets. LinkNER enhances NER task performance, notably surpassing SOTA models in robustness tests. We also quantitatively analyze the influence of key components like uncertainty estimation methods, LLMs, and in-context learning on diverse NER tasks, offering specific web-related recommendations. Code is available at https://github.com/zhzhengit/LinkNER.
<div id='section'>Paperid: <span id='pid'>179, <a href='https://arxiv.org/pdf/2402.08383.pdf' target='_blank'>https://arxiv.org/pdf/2402.08383.pdf</a></span>   <span><a href='https://github.com/AI4Science-WestlakeU/le-pde-uq' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tailin Wu, Willie Neiswanger, Hongtao Zheng, Stefano Ermon, Jure Leskovec
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08383">Uncertainty Quantification for Forward and Inverse Problems of PDEs via Latent Global Evolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based surrogate models have demonstrated remarkable advantages over classical solvers in terms of speed, often achieving speedups of 10 to 1000 times over traditional partial differential equation (PDE) solvers. However, a significant challenge hindering their widespread adoption in both scientific and industrial domains is the lack of understanding about their prediction uncertainties, particularly in scenarios that involve critical decision making. To address this limitation, we propose a method that integrates efficient and precise uncertainty quantification into a deep learning-based surrogate model. Our method, termed Latent Evolution of PDEs with Uncertainty Quantification (LE-PDE-UQ), endows deep learning-based surrogate models with robust and efficient uncertainty quantification capabilities for both forward and inverse problems. LE-PDE-UQ leverages latent vectors within a latent space to evolve both the system's state and its corresponding uncertainty estimation. The latent vectors are decoded to provide predictions for the system's state as well as estimates of its uncertainty. In extensive experiments, we demonstrate the accurate uncertainty quantification performance of our approach, surpassing that of strong baselines including deep ensembles, Bayesian neural network layers, and dropout. Our method excels at propagating uncertainty over extended auto-regressive rollouts, making it suitable for scenarios involving long-term predictions. Our code is available at: https://github.com/AI4Science-WestlakeU/le-pde-uq.
<div id='section'>Paperid: <span id='pid'>180, <a href='https://arxiv.org/pdf/2402.03502.pdf' target='_blank'>https://arxiv.org/pdf/2402.03502.pdf</a></span>   <span><a href='https://github.com/deeplearning-wisc/sal' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Du, Zhen Fang, Ilias Diakonikolas, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03502">How Does Unlabeled Data Provably Help Out-of-Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Using unlabeled data to regularize the machine learning models has demonstrated promise for improving safety and reliability in detecting out-of-distribution (OOD) data. Harnessing the power of unlabeled in-the-wild data is non-trivial due to the heterogeneity of both in-distribution (ID) and OOD data. This lack of a clean set of OOD samples poses significant challenges in learning an optimal OOD classifier. Currently, there is a lack of research on formally understanding how unlabeled data helps OOD detection. This paper bridges the gap by introducing a new learning framework SAL (Separate And Learn) that offers both strong theoretical guarantees and empirical effectiveness. The framework separates candidate outliers from the unlabeled data and then trains an OOD classifier using the candidate outliers and the labeled ID data. Theoretically, we provide rigorous error bounds from the lens of separability and learnability, formally justifying the two components in our algorithm. Our theory shows that SAL can separate the candidate outliers with small error rates, which leads to a generalization guarantee for the learned OOD classifier. Empirically, SAL achieves state-of-the-art performance on common benchmarks, reinforcing our theoretical insights. Code is publicly available at https://github.com/deeplearning-wisc/sal.
<div id='section'>Paperid: <span id='pid'>181, <a href='https://arxiv.org/pdf/2402.02653.pdf' target='_blank'>https://arxiv.org/pdf/2402.02653.pdf</a></span>   <span><a href='https://github.com/jeff024/PALM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haodong Lu, Dong Gong, Shuo Wang, Jason Xue, Lina Yao, Kristen Moore
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.02653">Learning with Mixture of Prototypes for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection aims to detect testing samples far away from the in-distribution (ID) training data, which is crucial for the safe deployment of machine learning models in the real world. Distance-based OOD detection methods have emerged with enhanced deep representation learning. They identify unseen OOD samples by measuring their distances from ID class centroids or prototypes. However, existing approaches learn the representation relying on oversimplified data assumptions, e.g, modeling ID data of each class with one centroid class prototype or using loss functions not designed for OOD detection, which overlook the natural diversities within the data. Naively enforcing data samples of each class to be compact around only one prototype leads to inadequate modeling of realistic data and limited performance. To tackle these issues, we propose PrototypicAl Learning with a Mixture of prototypes (PALM) which models each class with multiple prototypes to capture the sample diversities, and learns more faithful and compact samples embeddings to enhance OOD detection. Our method automatically identifies and dynamically updates prototypes, assigning each sample to a subset of prototypes via reciprocal neighbor soft assignment weights. PALM optimizes a maximum likelihood estimation (MLE) loss to encourage the sample embeddings to be compact around the associated prototypes, as well as a contrastive loss on all prototypes to enhance intra-class compactness and inter-class discrimination at the prototype level. Moreover, the automatic estimation of prototypes enables our approach to be extended to the challenging OOD detection task with unlabelled ID data. Extensive experiments demonstrate the superiority of PALM, achieving state-of-the-art average AUROC performance of 93.82 on the challenging CIFAR-100 benchmark. Code is available at https://github.com/jeff024/PALM.
<div id='section'>Paperid: <span id='pid'>182, <a href='https://arxiv.org/pdf/2402.00865.pdf' target='_blank'>https://arxiv.org/pdf/2402.00865.pdf</a></span>   <span><a href='https://github.com/Qinyu-Allen-Zhao/OptFSOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinyu Zhao, Ming Xu, Kartik Gupta, Akshay Asthana, Liang Zheng, Stephen Gould
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00865">Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Feature shaping refers to a family of methods that exhibit state-of-the-art performance for out-of-distribution (OOD) detection. These approaches manipulate the feature representation, typically from the penultimate layer of a pre-trained deep learning model, so as to better differentiate between in-distribution (ID) and OOD samples. However, existing feature-shaping methods usually employ rules manually designed for specific model architectures and OOD datasets, which consequently limit their generalization ability. To address this gap, we first formulate an abstract optimization framework for studying feature-shaping methods. We then propose a concrete reduction of the framework with a simple piecewise constant shaping function and show that existing feature-shaping methods approximate the optimal solution to the concrete optimization problem. Further, assuming that OOD data is inaccessible, we propose a formulation that yields a closed-form solution for the piecewise constant shaping function, utilizing solely the ID data. Through extensive experiments, we show that the feature-shaping function optimized by our method improves the generalization ability of OOD detection across a large variety of datasets and model architectures.
<div id='section'>Paperid: <span id='pid'>183, <a href='https://arxiv.org/pdf/2401.17826.pdf' target='_blank'>https://arxiv.org/pdf/2401.17826.pdf</a></span>   <span><a href='https://github.com/JokerJohn/PALoc' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/JokerJohn/Cloud_Map_Evaluation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangcheng Hu, Linwei Zheng, Jin Wu, Ruoyu Geng, Yang Yu, Hexiang Wei, Xiaoyu Tang, Lujia Wang, Jianhao Jiao, Ming Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.17826">PALoc: Advancing SLAM Benchmarking with Prior-Assisted 6-DoF Trajectory Generation and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately generating ground truth (GT) trajectories is essential for Simultaneous Localization and Mapping (SLAM) evaluation, particularly under varying environmental conditions. This study introduces a systematic approach employing a prior map-assisted framework for generating dense six-degree-of-freedom (6-DoF) GT poses for the first time, enhancing the fidelity of both indoor and outdoor SLAM datasets. Our method excels in handling degenerate and stationary conditions frequently encountered in SLAM datasets, thereby increasing robustness and precision. A significant aspect of our approach is the detailed derivation of covariances within the factor graph, enabling an in-depth analysis of pose uncertainty propagation. This analysis crucially contributes to demonstrating specific pose uncertainties and enhancing trajectory reliability from both theoretical and empirical perspectives. Additionally, we provide an open-source toolbox (https://github.com/JokerJohn/Cloud_Map_Evaluation) for map evaluation criteria, facilitating the indirect assessment of overall trajectory precision. Experimental results show at least a 30\% improvement in map accuracy and a 20\% increase in direct trajectory accuracy compared to the Iterative Closest Point (ICP) \cite{sharp2002icp} algorithm across diverse campus environments, with substantially enhanced robustness. Our open-source solution (https://github.com/JokerJohn/PALoc), extensively applied in the FusionPortable\cite{Jiao2022Mar} dataset, is geared towards SLAM benchmark dataset augmentation and represents a significant advancement in SLAM evaluations.
<div id='section'>Paperid: <span id='pid'>184, <a href='https://arxiv.org/pdf/2401.08501.pdf' target='_blank'>https://arxiv.org/pdf/2401.08501.pdf</a></span>   <span><a href='https://github.com/IML-DKFZ/values' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kim-Celine Kahl, Carsten T. LÃ¼th, Maximilian Zenk, Klaus Maier-Hein, Paul F. Jaeger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08501">ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is an essential and heavily-studied component for the reliable application of semantic segmentation methods. While various studies exist claiming methodological advances on the one hand, and successful application on the other hand, the field is currently hampered by a gap between theory and practice leaving fundamental questions unanswered: Can data-related and model-related uncertainty really be separated in practice? Which components of an uncertainty method are essential for real-world performance? Which uncertainty method works well for which application? In this work, we link this research gap to a lack of systematic and comprehensive evaluation of uncertainty methods. Specifically, we identify three key pitfalls in current literature and present an evaluation framework that bridges the research gap by providing 1) a controlled environment for studying data ambiguities as well as distribution shifts, 2) systematic ablations of relevant method components, and 3) test-beds for the five predominant uncertainty applications: OoD-detection, active learning, failure detection, calibration, and ambiguity modeling. Empirical results on simulated as well as real-world data demonstrate how the proposed framework is able to answer the predominant questions in the field revealing for instance that 1) separation of uncertainty types works on simulated data but does not necessarily translate to real-world data, 2) aggregation of scores is a crucial but currently neglected component of uncertainty methods, 3) While ensembles are performing most robustly across the different downstream tasks and settings, test-time augmentation often constitutes a light-weight alternative. Code is at: https://github.com/IML-DKFZ/values
<div id='section'>Paperid: <span id='pid'>185, <a href='https://arxiv.org/pdf/2401.06176.pdf' target='_blank'>https://arxiv.org/pdf/2401.06176.pdf</a></span>   <span><a href='https://github.com/Ee1s/GOODAT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Luzhi Wang, Dongxiao He, He Zhang, Yixin Liu, Wenjie Wang, Shirui Pan, Di Jin, Tat-Seng Chua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06176">GOODAT: Towards Test-time Graph Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph neural networks (GNNs) have found widespread application in modeling graph data across diverse domains. While GNNs excel in scenarios where the testing data shares the distribution of their training counterparts (in distribution, ID), they often exhibit incorrect predictions when confronted with samples from an unfamiliar distribution (out-of-distribution, OOD). To identify and reject OOD samples with GNNs, recent studies have explored graph OOD detection, often focusing on training a specific model or modifying the data on top of a well-trained GNN. Despite their effectiveness, these methods come with heavy training resources and costs, as they need to optimize the GNN-based models on training data. Moreover, their reliance on modifying the original GNNs and accessing training data further restricts their universality. To this end, this paper introduces a method to detect Graph Out-of-Distribution At Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play solution that operates independently of training data and modifications of GNN architecture. With a lightweight graph masker, GOODAT can learn informative subgraphs from test samples, enabling the capture of distinct graph patterns between OOD and ID samples. To optimize the graph masker, we meticulously design three unsupervised objective functions based on the graph information bottleneck principle, motivating the masker to capture compact yet informative subgraphs for OOD detection. Comprehensive evaluations confirm that our GOODAT method outperforms state-of-the-art benchmarks across a variety of real-world datasets. The code is available at Github: https://github.com/Ee1s/GOODAT
<div id='section'>Paperid: <span id='pid'>186, <a href='https://arxiv.org/pdf/2401.00873.pdf' target='_blank'>https://arxiv.org/pdf/2401.00873.pdf</a></span>   <span><a href='https://github.com/emsansone/GEDI' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Emanuele Sansone, Robin Manhaeve
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00873">Unifying Self-Supervised Clustering and Energy-Based Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning excels at learning representations from large amounts of data. At the same time, generative models offer the complementary property of learning information about the underlying data generation process. In this study, we aim at establishing a principled connection between these two paradigms and highlight the benefits of their complementarity. In particular, we perform an analysis of self-supervised learning objectives, elucidating the underlying probabilistic graphical models and presenting a standardized methodology for their derivation from first principles. The analysis suggests a natural means of integrating self-supervised learning with likelihood-based generative models. We instantiate this concept within the realm of cluster-based self-supervised learning and energy models, introducing a lower bound proven to reliably penalize the most important failure modes and unlocking full unification. Our theoretical findings are substantiated through experiments on synthetic and real-world data, including SVHN, CIFAR10, and CIFAR100, demonstrating that our objective function allows to jointly train a backbone network in a discriminative and generative fashion, consequently outperforming existing self-supervised learning strategies in terms of clustering, generation and out-of-distribution detection performance by a wide margin. We also demonstrate that the solution can be integrated into a neuro-symbolic framework to tackle a simple yet non-trivial instantiation of the symbol grounding problem. The code is publicly available at https://github.com/emsansone/GEDI.
<div id='section'>Paperid: <span id='pid'>187, <a href='https://arxiv.org/pdf/2312.17679.pdf' target='_blank'>https://arxiv.org/pdf/2312.17679.pdf</a></span>   <span><a href='https://github.com/kayzliu/godm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kay Liu, Hengrui Zhang, Ziqing Hu, Fangxin Wang, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.17679">Data Augmentation for Supervised Graph Outlier Detection via Latent Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A fundamental challenge confronting supervised graph outlier detection algorithms is the prevalent problem of class imbalance, where the scarcity of outlier instances compared to normal instances often results in suboptimal performance. Recently, generative models, especially diffusion models, have demonstrated their efficacy in synthesizing high-fidelity images. Despite their extraordinary generation quality, their potential in data augmentation for supervised graph outlier detection remains largely underexplored. To bridge this gap, we introduce GODM, a novel data augmentation for mitigating class imbalance in supervised Graph Outlier detection via latent Diffusion Models. Extensive experiments conducted on multiple datasets substantiate the effectiveness and efficiency of GODM. The case study further demonstrated the generation quality of our synthetic data. To foster accessibility and reproducibility, we encapsulate GODM into a plug-and-play package and release it at PyPI: https://pypi.org/project/godm/.
<div id='section'>Paperid: <span id='pid'>188, <a href='https://arxiv.org/pdf/2312.16596.pdf' target='_blank'>https://arxiv.org/pdf/2312.16596.pdf</a></span>   <span><a href='https://github.com/himanshudce/OWAM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Himanshu Choudhary, Marwan Hassani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.16596">Enhancing Traffic Flow Prediction using Outlier-Weighted AutoEncoders: Handling Real-Time Changes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In today's urban landscape, traffic congestion poses a critical challenge, especially during outlier scenarios. These outliers can indicate abrupt traffic peaks, drops, or irregular trends, often arising from factors such as accidents, events, or roadwork. Moreover, Given the dynamic nature of traffic, the need for real-time traffic modeling also becomes crucial to ensure accurate and up-to-date traffic predictions. To address these challenges, we introduce the Outlier Weighted Autoencoder Modeling (OWAM) framework. OWAM employs autoencoders for local outlier detection and generates correlation scores to assess neighboring traffic's influence. These scores serve as a weighted factor for neighboring sensors, before fusing them into the model. This information enhances the traffic model's performance and supports effective real-time updates, a crucial aspect for capturing dynamic traffic patterns. OWAM demonstrates a favorable trade-off between accuracy and efficiency, rendering it highly suitable for real-world applications. The research findings contribute significantly to the development of more efficient and adaptive traffic prediction models, advancing the field of transportation management for the future. The code and datasets of our framework is publicly available under https://github.com/himanshudce/OWAM.
<div id='section'>Paperid: <span id='pid'>189, <a href='https://arxiv.org/pdf/2312.15514.pdf' target='_blank'>https://arxiv.org/pdf/2312.15514.pdf</a></span>   <span><a href='https://github.com/ndb796/MultipleInputMixup' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dasol Choi, Dongbin Na
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.15514">Towards Reliable AI Model Deployments: Multiple Input Mixup for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent remarkable success in the deep-learning industries has unprecedentedly increased the need for reliable model deployment. For example, the model should alert the user if the produced model outputs might not be reliable. Previous studies have proposed various methods to solve the Out-of-Distribution (OOD) detection problem, however, they generally require a burden of resources. In this work, we propose a novel and simple method, Multiple Input Mixup (MIM). Our method can help improve the OOD detection performance with only single epoch fine-tuning. Our method does not require training the model from scratch and can be attached to the classifier simply. Despite its simplicity, our MIM shows competitive performance. Our method can be suitable for various environments because our method only utilizes the In-Distribution (ID) samples to generate the synthesized OOD data. With extensive experiments with CIFAR10 and CIFAR100 benchmarks that have been largely adopted in out-of-distribution detection fields, we have demonstrated our MIM shows comprehensively superior performance compared to the SOTA method. Especially, our method does not need additional computation on the feature vectors compared to the previous studies. All source codes are publicly available at https://github.com/ndb796/MultipleInputMixup.
<div id='section'>Paperid: <span id='pid'>190, <a href='https://arxiv.org/pdf/2312.10686.pdf' target='_blank'>https://arxiv.org/pdf/2312.10686.pdf</a></span>   <span><a href='https://github.com/mala-lab/COCL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjun Miao, Guansong Pang, Tianqi Li, Xiao Bai, Jin Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10686">Out-of-Distribution Detection in Long-Tailed Recognition with Calibrated Outlier Class Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing out-of-distribution (OOD) methods have shown great success on balanced datasets but become ineffective in long-tailed recognition (LTR) scenarios where 1) OOD samples are often wrongly classified into head classes and/or 2) tail-class samples are treated as OOD samples. To address these issues, current studies fit a prior distribution of auxiliary/pseudo OOD data to the long-tailed in-distribution (ID) data. However, it is difficult to obtain such an accurate prior distribution given the unknowingness of real OOD samples and heavy class imbalance in LTR. A straightforward solution to avoid the requirement of this prior is to learn an outlier class to encapsulate the OOD samples. The main challenge is then to tackle the aforementioned confusion between OOD samples and head/tail-class samples when learning the outlier class. To this end, we introduce a novel calibrated outlier class learning (COCL) approach, in which 1) a debiased large margin learning method is introduced in the outlier class learning to distinguish OOD samples from both head and tail classes in the representation space and 2) an outlier-class-aware logit calibration method is defined to enhance the long-tailed classification confidence. Extensive empirical results on three popular benchmarks CIFAR10-LT, CIFAR100-LT, and ImageNet-LT demonstrate that COCL substantially outperforms state-of-the-art OOD detection methods in LTR while being able to improve the classification accuracy on ID data. Code is available at https://github.com/mala-lab/COCL.
<div id='section'>Paperid: <span id='pid'>191, <a href='https://arxiv.org/pdf/2312.08939.pdf' target='_blank'>https://arxiv.org/pdf/2312.08939.pdf</a></span>   <span><a href='https://github.com/Stomach-ache/Long-Tailed-OOD-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Wei, Bo-Lin Wang, Min-Ling Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.08939">EAT: Towards Long-Tailed Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite recent advancements in out-of-distribution (OOD) detection, most current studies assume a class-balanced in-distribution training dataset, which is rarely the case in real-world scenarios. This paper addresses the challenging task of long-tailed OOD detection, where the in-distribution data follows a long-tailed class distribution. The main difficulty lies in distinguishing OOD data from samples belonging to the tail classes, as the ability of a classifier to detect OOD instances is not strongly correlated with its accuracy on the in-distribution classes. To overcome this issue, we propose two simple ideas: (1) Expanding the in-distribution class space by introducing multiple abstention classes. This approach allows us to build a detector with clear decision boundaries by training on OOD data using virtual labels. (2) Augmenting the context-limited tail classes by overlaying images onto the context-rich OOD data. This technique encourages the model to pay more attention to the discriminative features of the tail classes. We provide a clue for separating in-distribution and OOD data by analyzing gradient noise. Through extensive experiments, we demonstrate that our method outperforms the current state-of-the-art on various benchmark datasets. Moreover, our method can be used as an add-on for existing long-tail learning approaches, significantly enhancing their OOD detection performance. Code is available at: https://github.com/Stomach-ache/Long-Tailed-OOD-Detection .
<div id='section'>Paperid: <span id='pid'>192, <a href='https://arxiv.org/pdf/2312.04604.pdf' target='_blank'>https://arxiv.org/pdf/2312.04604.pdf</a></span>   <span><a href='https://github.com/gokyeongryeol/TBU' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kyeongryeol Go, Kye-Hyeon Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.04604">Transferable Candidate Proposal with Bounded Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>From an empirical perspective, the subset chosen through active learning cannot guarantee an advantage over random sampling when transferred to another model. While it underscores the significance of verifying transferability, experimental design from previous works often neglected that the informativeness of a data subset can change over model configurations. To tackle this issue, we introduce a new experimental design, coined as Candidate Proposal, to find transferable data candidates from which active learning algorithms choose the informative subset. Correspondingly, a data selection algorithm is proposed, namely Transferable candidate proposal with Bounded Uncertainty (TBU), which constrains the pool of transferable data candidates by filtering out the presumably redundant data points based on uncertainty estimation. We verified the validity of TBU in image classification benchmarks, including CIFAR-10/100 and SVHN. When transferred to different model configurations, TBU consistency improves performance in existing active learning algorithms. Our code is available at https://github.com/gokyeongryeol/TBU.
<div id='section'>Paperid: <span id='pid'>193, <a href='https://arxiv.org/pdf/2311.17456.pdf' target='_blank'>https://arxiv.org/pdf/2311.17456.pdf</a></span>   <span><a href='https://github.com/IRMVLab/DifFlow3D' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/IRMVLab/DifFlow3D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiuming Liu, Guangming Wang, Weicai Ye, Chaokang Jiang, Jinru Han, Zhe Liu, Guofeng Zhang, Dalong Du, Hesheng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.17456">DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scene flow estimation, which aims to predict per-point 3D displacements of dynamic scenes, is a fundamental task in the computer vision field. However, previous works commonly suffer from unreliable correlation caused by locally constrained searching ranges, and struggle with accumulated inaccuracy arising from the coarse-to-fine structure. To alleviate these problems, we propose a novel uncertainty-aware scene flow estimation network (DifFlow3D) with the diffusion probabilistic model. Iterative diffusion-based refinement is designed to enhance the correlation robustness and resilience to challenging cases, e.g. dynamics, noisy inputs, repetitive patterns, etc. To restrain the generation diversity, three key flow-related features are leveraged as conditions in our diffusion model. Furthermore, we also develop an uncertainty estimation module within diffusion to evaluate the reliability of estimated scene flow. Our DifFlow3D achieves state-of-the-art performance, with 24.0% and 29.1% EPE3D reduction respectively on FlyingThings3D and KITTI 2015 datasets. Notably, our method achieves an unprecedented millimeter-level accuracy (0.0078m in EPE3D) on the KITTI dataset. Additionally, our diffusion-based refinement paradigm can be readily integrated as a plug-and-play module into existing scene flow networks, significantly increasing their estimation accuracy. Codes are released at https://github.com/IRMVLab/DifFlow3D.
<div id='section'>Paperid: <span id='pid'>194, <a href='https://arxiv.org/pdf/2311.15243.pdf' target='_blank'>https://arxiv.org/pdf/2311.15243.pdf</a></span>   <span><a href='https://github.com/ycfate/ID-like' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yichen Bai, Zongbo Han, Changqing Zhang, Bing Cao, Xiaoheng Jiang, Qinghua Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.15243">ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection methods often exploit auxiliary outliers to train model identifying OOD samples, especially discovering challenging outliers from auxiliary outliers dataset to improve OOD detection. However, they may still face limitations in effectively distinguishing between the most challenging OOD samples that are much like in-distribution (ID) data, i.e., \idlike samples. To this end, we propose a novel OOD detection framework that discovers \idlike outliers using CLIP \cite{DBLP:conf/icml/RadfordKHRGASAM21} from the vicinity space of the ID samples, thus helping to identify these most challenging OOD samples. Then a prompt learning framework is proposed that utilizes the identified \idlike outliers to further leverage the capabilities of CLIP for OOD detection. Benefiting from the powerful CLIP, we only need a small number of ID samples to learn the prompts of the model without exposing other auxiliary outlier datasets. By focusing on the most challenging \idlike OOD samples and elegantly exploiting the capabilities of CLIP, our method achieves superior few-shot learning performance on various real-world image datasets (e.g., in 4-shot OOD detection on the ImageNet-1k dataset, our method reduces the average FPR95 by 12.16\% and improves the average AUROC by 2.76\%, compared to state-of-the-art methods). Code is available at https://github.com/ycfate/ID-like.
<div id='section'>Paperid: <span id='pid'>195, <a href='https://arxiv.org/pdf/2311.13959.pdf' target='_blank'>https://arxiv.org/pdf/2311.13959.pdf</a></span>   <span><a href='https://github.com/KingJamesSong/RankFeat' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Song, Wei Wang, Nicu Sebe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13959">RankFeat&RankWeight: Rank-1 Feature/Weight Removal for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The task of out-of-distribution (OOD) detection is crucial for deploying machine learning models in real-world settings. In this paper, we observe that the singular value distributions of the in-distribution (ID) and OOD features are quite different: the OOD feature matrix tends to have a larger dominant singular value than the ID feature, and the class predictions of OOD samples are largely determined by it. This observation motivates us to propose \texttt{RankFeat}, a simple yet effective \emph{post hoc} approach for OOD detection by removing the rank-1 matrix composed of the largest singular value and the associated singular vectors from the high-level feature. \texttt{RankFeat} achieves \emph{state-of-the-art} performance and reduces the average false positive rate (FPR95) by 17.90\% compared with the previous best method. The success of \texttt{RankFeat} motivates us to investigate whether a similar phenomenon would exist in the parameter matrices of neural networks. We thus propose \texttt{RankWeight} which removes the rank-1 weight from the parameter matrices of a single deep layer. Our \texttt{RankWeight}is also \emph{post hoc} and only requires computing the rank-1 matrix once. As a standalone approach, \texttt{RankWeight} has very competitive performance against other methods across various backbones. Moreover, \texttt{RankWeight} enjoys flexible compatibility with a wide range of OOD detection methods. The combination of \texttt{RankWeight} and \texttt{RankFeat} refreshes the new \emph{state-of-the-art} performance, achieving the FPR95 as low as 16.13\% on the ImageNet-1k benchmark. Extensive ablation studies and comprehensive theoretical analyses are presented to support the empirical results. Code is publicly available via \url{https://github.com/KingJamesSong/RankFeat}.
<div id='section'>Paperid: <span id='pid'>196, <a href='https://arxiv.org/pdf/2311.10572.pdf' target='_blank'>https://arxiv.org/pdf/2311.10572.pdf</a></span>   <span><a href='https://github.com/YUE-FAN/SSB' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Fan, Anna Kukleva, Dengxin Dai, Bernt Schiele
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.10572">SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised learning (SSL) methods effectively leverage unlabeled data to improve model generalization. However, SSL models often underperform in open-set scenarios, where unlabeled data contain outliers from novel categories that do not appear in the labeled set. In this paper, we study the challenging and realistic open-set SSL setting, where the goal is to both correctly classify inliers and to detect outliers. Intuitively, the inlier classifier should be trained on inlier data only. However, we find that inlier classification performance can be largely improved by incorporating high-confidence pseudo-labeled data, regardless of whether they are inliers or outliers. Also, we propose to utilize non-linear transformations to separate the features used for inlier classification and outlier detection in the multi-task learning framework, preventing adverse effects between them. Additionally, we introduce pseudo-negative mining, which further boosts outlier detection performance. The three ingredients lead to what we call Simple but Strong Baseline (SSB) for open-set SSL. In experiments, SSB greatly improves both inlier classification and outlier detection performance, outperforming existing methods by a large margin. Our code will be released at https://github.com/YUE-FAN/SSB.
<div id='section'>Paperid: <span id='pid'>197, <a href='https://arxiv.org/pdf/2311.08726.pdf' target='_blank'>https://arxiv.org/pdf/2311.08726.pdf</a></span>   <span><a href='https://github.com/he159ok/UncSeqLabeling_SLPN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianfeng He, Linlin Yu, Shuo Lei, Chang-Tien Lu, Feng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.08726">Uncertainty Estimation on Sequential Labeling via Uncertainty Transmission</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sequential labeling is a task predicting labels for each token in a sequence, such as Named Entity Recognition (NER). NER tasks aim to extract entities and predict their labels given a text, which is important in information extraction. Although previous works have shown great progress in improving NER performance, uncertainty estimation on NER (UE-NER) is still underexplored but essential. This work focuses on UE-NER, which aims to estimate uncertainty scores for the NER predictions. Previous uncertainty estimation models often overlook two unique characteristics of NER: the connection between entities (i.e., one entity embedding is learned based on the other ones) and wrong span cases in the entity extraction subtask. Therefore, we propose a Sequential Labeling Posterior Network (SLPN) to estimate uncertainty scores for the extracted entities, considering uncertainty transmitted from other tokens. Moreover, we have defined an evaluation strategy to address the specificity of wrong-span cases. Our SLPN has achieved significant improvements on three datasets, such as a 5.54-point improvement in AUPR on the MIT-Restaurant dataset. Our code is available at \url{https://github.com/he159ok/UncSeqLabeling_SLPN}.
<div id='section'>Paperid: <span id='pid'>198, <a href='https://arxiv.org/pdf/2311.02719.pdf' target='_blank'>https://arxiv.org/pdf/2311.02719.pdf</a></span>   <span><a href='https://github.com/med-air/FGRM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongzheng Yang, Cheng Chen, Yueyao Chen, Markus Scheppach, Hon Chi Yip, Qi Dou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.02719">Uncertainty Estimation for Safety-critical Scene Segmentation via Fine-grained Reward Maximization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation plays an important role for future reliable deployment of deep segmentation models in safety-critical scenarios such as medical applications. However, existing methods for uncertainty estimation have been limited by the lack of explicit guidance for calibrating the prediction risk and model confidence. In this work, we propose a novel fine-grained reward maximization (FGRM) framework, to address uncertainty estimation by directly utilizing an uncertainty metric related reward function with a reinforcement learning based model tuning algorithm. This would benefit the model uncertainty estimation through direct optimization guidance for model calibration. Specifically, our method designs a new uncertainty estimation reward function using the calibration metric, which is maximized to fine-tune an evidential learning pre-trained segmentation model for calibrating prediction risk. Importantly, we innovate an effective fine-grained parameter update scheme, which imposes fine-grained reward-weighting of each network parameter according to the parameter importance quantified by the fisher information matrix. To the best of our knowledge, this is the first work exploring reward optimization for model uncertainty estimation in safety-critical vision tasks. The effectiveness of our method is demonstrated on two large safety-critical surgical scene segmentation datasets under two different uncertainty estimation settings. With real-time one forward pass at inference, our method outperforms state-of-the-art methods by a clear margin on all the calibration metrics of uncertainty estimation, while maintaining a high task accuracy for the segmentation results. Code is available at \url{https://github.com/med-air/FGRM}.
<div id='section'>Paperid: <span id='pid'>199, <a href='https://arxiv.org/pdf/2310.19272.pdf' target='_blank'>https://arxiv.org/pdf/2310.19272.pdf</a></span>   <span><a href='https://github.com/srvCodes/NPCL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurav Jha, Dong Gong, He Zhao, Lina Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19272">NPCL: Neural Processes for Uncertainty-Aware Continual Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual learning (CL) aims to train deep neural networks efficiently on streaming data while limiting the forgetting caused by new tasks. However, learning transferable knowledge with less interference between tasks is difficult, and real-world deployment of CL models is limited by their inability to measure predictive uncertainties. To address these issues, we propose handling CL tasks with neural processes (NPs), a class of meta-learners that encode different tasks into probabilistic distributions over functions all while providing reliable uncertainty estimates. Specifically, we propose an NP-based CL approach (NPCL) with task-specific modules arranged in a hierarchical latent variable model. We tailor regularizers on the learned latent distributions to alleviate forgetting. The uncertainty estimation capabilities of the NPCL can also be used to handle the task head/module inference challenge in CL. Our experiments show that the NPCL outperforms previous CL approaches. We validate the effectiveness of uncertainty estimation in the NPCL for identifying novel data and evaluating instance-level model confidence. Code is available at \url{https://github.com/srvCodes/NPCL}.
<div id='section'>Paperid: <span id='pid'>200, <a href='https://arxiv.org/pdf/2310.18715.pdf' target='_blank'>https://arxiv.org/pdf/2310.18715.pdf</a></span>   <span><a href='https://github.com/Mamba413/ROOM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Zhu, Runzhe Wan, Zhengling Qi, Shikai Luo, Chengchun Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18715">Robust Offline Reinforcement learning with Heavy-Tailed Rewards</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions. The implementation of the proposal is available at https://github.com/Mamba413/ROOM.
<div id='section'>Paperid: <span id='pid'>201, <a href='https://arxiv.org/pdf/2310.16587.pdf' target='_blank'>https://arxiv.org/pdf/2310.16587.pdf</a></span>   <span><a href='https://github.com/HKU-MedAI/bnn_uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tsai Hor Chan, Kin Wai Lau, Jiajun Shen, Guosheng Yin, Lequan Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.16587">Adaptive Uncertainty Estimation via High-Dimensional Testing on Latent Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation aims to evaluate the confidence of a trained deep neural network. However, existing uncertainty estimation approaches rely on low-dimensional distributional assumptions and thus suffer from the high dimensionality of latent features. Existing approaches tend to focus on uncertainty on discrete classification probabilities, which leads to poor generalizability to uncertainty estimation for other tasks. Moreover, most of the literature requires seeing the out-of-distribution (OOD) data in the training for better estimation of uncertainty, which limits the uncertainty estimation performance in practice because the OOD data are typically unseen. To overcome these limitations, we propose a new framework using data-adaptive high-dimensional hypothesis testing for uncertainty estimation, which leverages the statistical properties of the feature representations. Our method directly operates on latent representations and thus does not require retraining the feature encoder under a modified objective. The test statistic relaxes the feature distribution assumptions to high dimensionality, and it is more discriminative to uncertainties in the latent representations. We demonstrate that encoding features with Bayesian neural networks can enhance testing performance and lead to more accurate uncertainty estimation. We further introduce a family-wise testing procedure to determine the optimal threshold of OOD detection, which minimizes the false discovery rate (FDR). Extensive experiments validate the satisfactory performance of our framework on uncertainty estimation and task-specific prediction over a variety of competitors. The experiments on the OOD detection task also show satisfactory performance of our method when the OOD data are unseen in the training. Codes are available at https://github.com/HKU-MedAI/bnn_uncertainty.
<div id='section'>Paperid: <span id='pid'>202, <a href='https://arxiv.org/pdf/2310.16099.pdf' target='_blank'>https://arxiv.org/pdf/2310.16099.pdf</a></span>   <span><a href='https://github.com/adigasu/Anatomically-aware_Uncertainty_for_Semi-supervised_Segmentation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sukesh Adiga, Jose Dolz, Herve Lombaert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.16099">Anatomically-aware Uncertainty for Semi-supervised Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. A prominent way to exploit unlabeled data is to regularize model predictions. Since the predictions of unlabeled data can be unreliable, uncertainty-aware schemes are typically employed to gradually learn from meaningful and reliable predictions. Uncertainty estimation methods, however, rely on multiple inferences from the model predictions that must be computed for each training step, which is computationally expensive. Moreover, these uncertainty maps capture pixel-wise disparities and do not consider global information. This work proposes a novel method to estimate segmentation uncertainty by leveraging global information from the segmentation masks. More precisely, an anatomically-aware representation is first learnt to model the available segmentation masks. The learnt representation thereupon maps the prediction of a new segmentation into an anatomically-plausible segmentation. The deviation from the plausible segmentation aids in estimating the underlying pixel-level uncertainty in order to further guide the segmentation network. The proposed method consequently estimates the uncertainty using a single inference from our representation, thereby reducing the total computation. We evaluate our method on two publicly available segmentation datasets of left atria in cardiac MRIs and of multiple organs in abdominal CTs. Our anatomically-aware method improves the segmentation accuracy over the state-of-the-art semi-supervised methods in terms of two commonly used evaluation metrics.
<div id='section'>Paperid: <span id='pid'>203, <a href='https://arxiv.org/pdf/2310.13923.pdf' target='_blank'>https://arxiv.org/pdf/2310.13923.pdf</a></span>   <span><a href='https://github.com/tmlr-group/DivOE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianing Zhu, Geng Yu, Jiangchao Yao, Tongliang Liu, Gang Niu, Masashi Sugiyama, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13923">Diversified Outlier Exposure for Out-of-Distribution Detection via Informative Extrapolation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is important for deploying reliable machine learning models on real-world applications. Recent advances in outlier exposure have shown promising results on OOD detection via fine-tuning model with informatively sampled auxiliary outliers. However, previous methods assume that the collected outliers can be sufficiently large and representative to cover the boundary between ID and OOD data, which might be impractical and challenging. In this work, we propose a novel framework, namely, Diversified Outlier Exposure (DivOE), for effective OOD detection via informative extrapolation based on the given auxiliary outliers. Specifically, DivOE introduces a new learning objective, which diversifies the auxiliary distribution by explicitly synthesizing more informative outliers for extrapolation during training. It leverages a multi-step optimization method to generate novel outliers beyond the original ones, which is compatible with many variants of outlier exposure. Extensive experiments and analyses have been conducted to characterize and demonstrate the effectiveness of the proposed DivOE. The code is publicly available at: https://github.com/tmlr-group/DivOE.
<div id='section'>Paperid: <span id='pid'>204, <a href='https://arxiv.org/pdf/2310.11755.pdf' target='_blank'>https://arxiv.org/pdf/2310.11755.pdf</a></span>   <span><a href='https://github.com/aim-uofa/RGM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Songyan Zhang, Xinyu Sun, Hao Chen, Bo Li, Chunhua Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11755">RGM: A Robust Generalizable Matching Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finding corresponding pixels within a pair of images is a fundamental computer vision task with various applications. Due to the specific requirements of different tasks like optical flow estimation and local feature matching, previous works are primarily categorized into dense matching and sparse feature matching focusing on specialized architectures along with task-specific datasets, which may somewhat hinder the generalization performance of specialized models. In this paper, we propose a deep model for sparse and dense matching, termed RGM (Robust Generalist Matching). In particular, we elaborately design a cascaded GRU module for refinement by exploring the geometric similarity iteratively at multiple scales following an additional uncertainty estimation module for sparsification. To narrow the gap between synthetic training samples and real-world scenarios, we build a new, large-scale dataset with sparse correspondence ground truth by generating optical flow supervision with greater intervals. As such, we are able to mix up various dense and sparse matching datasets, significantly improving the training diversity. The generalization capacity of our proposed RGM is greatly improved by learning the matching and uncertainty estimation in a two-stage manner on the large, mixed data. Superior performance is achieved for zero-shot matching and downstream geometry estimation across multiple datasets, outperforming the previous methods by a large margin.
<div id='section'>Paperid: <span id='pid'>205, <a href='https://arxiv.org/pdf/2310.10391.pdf' target='_blank'>https://arxiv.org/pdf/2310.10391.pdf</a></span>   <span><a href='https://github.com/Luoyadan/CRB-active-3Ddet/tree/Open-CRB' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoxiao Chen, Yadan Luo, Zixin Wang, Zijian Wang, Xin Yu, Zi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10391">Open-CRB: Towards Open World Active Learning for 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based 3D object detection has recently seen significant advancements through active learning (AL), attaining satisfactory performance by training on a small fraction of strategically selected point clouds. However, in real-world deployments where streaming point clouds may include unknown or novel objects, the ability of current AL methods to capture such objects remains unexplored. This paper investigates a more practical and challenging research task: Open World Active Learning for 3D Object Detection (OWAL-3D), aimed at acquiring informative point clouds with new concepts. To tackle this challenge, we propose a simple yet effective strategy called Open Label Conciseness (OLC), which mines novel 3D objects with minimal annotation costs. Our empirical results show that OLC successfully adapts the 3D detection model to the open world scenario with just a single round of selection. Any generic AL policy can then be integrated with the proposed OLC to efficiently address the OWAL-3D problem. Based on this, we introduce the Open-CRB framework, which seamlessly integrates OLC with our preliminary AL method, CRB, designed specifically for 3D object detection. We develop a comprehensive codebase for easy reproducing and future research, supporting 15 baseline methods (\textit{i.e.}, active learning, out-of-distribution detection and open world detection), 2 types of modern 3D detectors (\textit{i.e.}, one-stage SECOND and two-stage PV-RCNN) and 3 benchmark 3D datasets (\textit{i.e.}, KITTI, nuScenes and Waymo). Extensive experiments evidence that the proposed Open-CRB demonstrates superiority and flexibility in recognizing both novel and known classes with very limited labeling costs, compared to state-of-the-art baselines. Source code is available at \url{https://github.com/Luoyadan/CRB-active-3Ddet/tree/Open-CRB}.
<div id='section'>Paperid: <span id='pid'>206, <a href='https://arxiv.org/pdf/2310.10237.pdf' target='_blank'>https://arxiv.org/pdf/2310.10237.pdf</a></span>   <span><a href='https://github.com/TommyDzh/SGOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihao Ding, Jieming Shi, Shiqi Shen, Xuequn Shang, Jiannong Cao, Zhipeng Wang, Zhi Gong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10237">SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph-level representation learning is important in a wide range of applications. Existing graph-level models are generally built on i.i.d. assumption for both training and testing graphs. However, in an open world, models can encounter out-of-distribution (OOD) testing graphs that are from different distributions unknown during training. A trustworthy model should be able to detect OOD graphs to avoid unreliable predictions, while producing accurate in-distribution (ID) predictions. To achieve this, we present SGOOD, a novel graph-level OOD detection framework. We find that substructure differences commonly exist between ID and OOD graphs, and design SGOOD with a series of techniques to encode task-agnostic substructures for effective OOD detection. Specifically, we build a super graph of substructures for every graph, and develop a two-level graph encoding pipeline that works on both original graphs and super graphs to obtain substructure-enhanced graph representations. We then devise substructure-preserving graph augmentation techniques to further capture more substructure semantics of ID graphs. Extensive experiments against 11 competitors on numerous graph datasets demonstrate the superiority of SGOOD, often surpassing existing methods by a significant margin. The code is available at https://github.com/TommyDzh/SGOOD.
<div id='section'>Paperid: <span id='pid'>207, <a href='https://arxiv.org/pdf/2310.06085.pdf' target='_blank'>https://arxiv.org/pdf/2310.06085.pdf</a></span>   <span><a href='https://github.com/taghikhah/QuantOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Masoud Taghikhah, Nishant Kumar, SiniÅ¡a Å egviÄ, Abouzar Eslami, Stefan Gumhold
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06085">Quantile-based Maximum Likelihood Training for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discriminative learning effectively predicts true object class for image classification. However, it often results in false positives for outliers, posing critical concerns in applications like autonomous driving and video surveillance systems. Previous attempts to address this challenge involved training image classifiers through contrastive learning using actual outlier data or synthesizing outliers for self-supervised learning. Furthermore, unsupervised generative modeling of inliers in pixel space has shown limited success for outlier detection. In this work, we introduce a quantile-based maximum likelihood objective for learning the inlier distribution to improve the outlier separation during inference. Our approach fits a normalizing flow to pre-trained discriminative features and detects the outliers according to the evaluated log-likelihood. The experimental evaluation demonstrates the effectiveness of our method as it surpasses the performance of the state-of-the-art unsupervised methods for outlier detection. The results are also competitive compared with a recent self-supervised approach for outlier detection. Our work allows to reduce dependency on well-sampled negative training data, which is especially important for domains like medical diagnostics or remote sensing.
<div id='section'>Paperid: <span id='pid'>208, <a href='https://arxiv.org/pdf/2310.05083.pdf' target='_blank'>https://arxiv.org/pdf/2310.05083.pdf</a></span>   <span><a href='https://github.com/linhaowei1/FLatS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haowei Lin, Yuntian Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05083">FLatS: Principled Out-of-Distribution Detection with Feature-Based Likelihood Ratio Score</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) instances is crucial for NLP models in practical applications. Although numerous OOD detection methods exist, most of them are empirical. Backed by theoretical analysis, this paper advocates for the measurement of the "OOD-ness" of a test case $\boldsymbol{x}$ through the likelihood ratio between out-distribution $\mathcal P_{\textit{out}}$ and in-distribution $\mathcal P_{\textit{in}}$. We argue that the state-of-the-art (SOTA) feature-based OOD detection methods, such as Maha and KNN, are suboptimal since they only estimate in-distribution density $p_{\textit{in}}(\boldsymbol{x})$. To address this issue, we propose FLatS, a principled solution for OOD detection based on likelihood ratio. Moreover, we demonstrate that FLatS can serve as a general framework capable of enhancing other OOD detection methods by incorporating out-distribution density $p_{\textit{out}}(\boldsymbol{x})$ estimation. Experiments show that FLatS establishes a new SOTA on popular benchmarks. Our code is publicly available at https://github.com/linhaowei1/FLatS.
<div id='section'>Paperid: <span id='pid'>209, <a href='https://arxiv.org/pdf/2310.03738.pdf' target='_blank'>https://arxiv.org/pdf/2310.03738.pdf</a></span>   <span><a href='https://github.com/bit-ml/Stylist' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefan Smeu, Elena Burceanu, Emanuela Haller, Andrei Liviu Nicolicioiu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03738">Robust Novelty Detection through Style-Conscious Feature Ranking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty detection seeks to identify samples deviating from a known distribution, yet data shifts in a multitude of ways, and only a few consist of relevant changes. Aligned with out-of-distribution generalization literature, we advocate for a formal distinction between task-relevant semantic or content changes and irrelevant style changes. This distinction forms the basis for robust novelty detection, emphasizing the identification of semantic changes resilient to style distributional shifts. To this end, we introduce Stylist, a method that utilizes pretrained large-scale model representations to selectively discard environment-biased features. By computing per-feature scores based on feature distribution distances between environments, Stylist effectively eliminates features responsible for spurious correlations, enhancing novelty detection performance. Evaluations on adapted domain generalization datasets and a synthetic dataset demonstrate Stylist's efficacy in improving novelty detection across diverse datasets with stylistic and content shifts. The code is available at https://github.com/bit-ml/Stylist.
<div id='section'>Paperid: <span id='pid'>210, <a href='https://arxiv.org/pdf/2310.01755.pdf' target='_blank'>https://arxiv.org/pdf/2310.01755.pdf</a></span>   <span><a href='https://github.com/princetonvisualai/imagenetood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>William Yang, Byron Zhang, Olga Russakovsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01755">ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The task of out-of-distribution (OOD) detection is notoriously ill-defined. Earlier works focused on new-class detection, aiming to identify label-altering data distribution shifts, also known as "semantic shift." However, recent works argue for a focus on failure detection, expanding the OOD evaluation framework to account for label-preserving data distribution shifts, also known as "covariate shift." Intriguingly, under this new framework, complex OOD detectors that were previously considered state-of-the-art now perform similarly to, or even worse than the simple maximum softmax probability baseline. This raises the question: what are the latest OOD detectors actually detecting? Deciphering the behavior of OOD detection algorithms requires evaluation datasets that decouples semantic shift and covariate shift. To aid our investigations, we present ImageNet-OOD, a clean semantic shift dataset that minimizes the interference of covariate shift. Through comprehensive experiments, we show that OOD detectors are more sensitive to covariate shift than to semantic shift, and the benefits of recent OOD detection algorithms on semantic shift detection is minimal. Our dataset and analyses provide important insights for guiding the design of future OOD detectors.
<div id='section'>Paperid: <span id='pid'>211, <a href='https://arxiv.org/pdf/2310.01202.pdf' target='_blank'>https://arxiv.org/pdf/2310.01202.pdf</a></span>   <span><a href='https://github.com/facebookresearch/UnifiedUncertaintyCalibration' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kamalika Chaudhuri, David Lopez-Paz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01202">Unified Uncertainty Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To build robust, fair, and safe AI systems, we would like our classifiers to say ``I don't know'' when facing test examples that are difficult or fall outside of the training classes.The ubiquitous strategy to predict under uncertainty is the simplistic \emph{reject-or-classify} rule: abstain from prediction if epistemic uncertainty is high, classify otherwise.Unfortunately, this recipe does not allow different sources of uncertainty to communicate with each other, produces miscalibrated predictions, and it does not allow to correct for misspecifications in our uncertainty estimates. To address these three issues, we introduce \emph{unified uncertainty calibration (U2C)}, a holistic framework to combine aleatoric and epistemic uncertainties. U2C enables a clean learning-theoretical analysis of uncertainty estimation, and outperforms reject-or-classify across a variety of ImageNet benchmarks. Our code is available at: https://github.com/facebookresearch/UnifiedUncertaintyCalibration
<div id='section'>Paperid: <span id='pid'>212, <a href='https://arxiv.org/pdf/2310.00227.pdf' target='_blank'>https://arxiv.org/pdf/2310.00227.pdf</a></span>   <span><a href='https://github.com/kai422/SCALE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Xu, Rongyu Chen, Gianni Franchi, Angela Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00227">Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The capacity of a modern deep learning system to determine if a sample falls within its realm of knowledge is fundamental and important. In this paper, we offer insights and analyses of recent state-of-the-art out-of-distribution (OOD) detection methods - extremely simple activation shaping (ASH). We demonstrate that activation pruning has a detrimental effect on OOD detection, while activation scaling enhances it. Moreover, we propose SCALE, a simple yet effective post-hoc network enhancement method for OOD detection, which attains state-of-the-art OOD detection performance without compromising in-distribution (ID) accuracy. By integrating scaling concepts into the training process to capture a sample's ID characteristics, we propose Intermediate Tensor SHaping (ISH), a lightweight method for training time OOD detection enhancement. We achieve AUROC scores of +1.85\% for near-OOD and +0.74\% for far-OOD datasets on the OpenOOD v1.5 ImageNet-1K benchmark. Our code and models are available at https://github.com/kai422/SCALE.
<div id='section'>Paperid: <span id='pid'>213, <a href='https://arxiv.org/pdf/2309.14888.pdf' target='_blank'>https://arxiv.org/pdf/2309.14888.pdf</a></span>   <span><a href='https://github.com/roomo7time/nnguide' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaewoo Park, Yoon Gyo Jung, Andrew Beng Jin Teoh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14888">Nearest Neighbor Guidance for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples are crucial for machine learning models deployed in open-world environments. Classifier-based scores are a standard approach for OOD detection due to their fine-grained detection capability. However, these scores often suffer from overconfidence issues, misclassifying OOD samples distant from the in-distribution region. To address this challenge, we propose a method called Nearest Neighbor Guidance (NNGuide) that guides the classifier-based score to respect the boundary geometry of the data manifold. NNGuide reduces the overconfidence of OOD samples while preserving the fine-grained capability of the classifier-based score. We conduct extensive experiments on ImageNet OOD detection benchmarks under diverse settings, including a scenario where the ID data undergoes natural distribution shift. Our results demonstrate that NNGuide provides a significant performance improvement on the base detection scores, achieving state-of-the-art results on both AUROC, FPR95, and AUPR metrics. The code is given at \url{https://github.com/roomo7time/nnguide}.
<div id='section'>Paperid: <span id='pid'>214, <a href='https://arxiv.org/pdf/2309.14819.pdf' target='_blank'>https://arxiv.org/pdf/2309.14819.pdf</a></span>   <span><a href='https://github.com/maxwell0027/LeFeD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingjie Zeng, Yutong Xie, Zilin Lu, Mengkang Lu, Yong Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14819">Discrepancy Matters: Learning from Inconsistent Decoder Features for Consistent Semi-supervised Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised learning (SSL) has been proven beneficial for mitigating the issue of limited labeled data especially on the task of volumetric medical image segmentation. Unlike previous SSL methods which focus on exploring highly confident pseudo-labels or developing consistency regularization schemes, our empirical findings suggest that inconsistent decoder features emerge naturally when two decoders strive to generate consistent predictions. Based on the observation, we first analyze the treasure of discrepancy in learning towards consistency, under both pseudo-labeling and consistency regularization settings, and subsequently propose a novel SSL method called LeFeD, which learns the feature-level discrepancy obtained from two decoders, by feeding the discrepancy as a feedback signal to the encoder. The core design of LeFeD is to enlarge the difference by training differentiated decoders, and then learn from the inconsistent information iteratively. We evaluate LeFeD against eight state-of-the-art (SOTA) methods on three public datasets. Experiments show LeFeD surpasses competitors without any bells and whistles such as uncertainty estimation and strong constraints, as well as setting a new state-of-the-art for semi-supervised medical image segmentation. Code is available at \textcolor{cyan}{https://github.com/maxwell0027/LeFeD}
<div id='section'>Paperid: <span id='pid'>215, <a href='https://arxiv.org/pdf/2309.13207.pdf' target='_blank'>https://arxiv.org/pdf/2309.13207.pdf</a></span>   <span><a href='https://github.com/ai2es/miles-guess' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>John S. Schreck, David John Gagne, Charlie Becker, William E. Chapman, Kim Elmore, Da Fan, Gabrielle Gantos, Eliot Kim, Dhamma Kimpara, Thomas Martin, Maria J. Molina, Vanessa M. Pryzbylo, Jacob Radford, Belen Saavedra, Justin Willson, Christopher Wirz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.13207">Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robust quantification of predictive uncertainty is critical for understanding factors that drive weather and climate outcomes. Ensembles provide predictive uncertainty estimates and can be decomposed physically, but both physics and machine learning ensembles are computationally expensive. Parametric deep learning can estimate uncertainty with one model by predicting the parameters of a probability distribution but do not account for epistemic uncertainty.. Evidential deep learning, a technique that extends parametric deep learning to higher-order distributions, can account for both aleatoric and epistemic uncertainty with one model. This study compares the uncertainty derived from evidential neural networks to those obtained from ensembles. Through applications of classification of winter precipitation type and regression of surface layer fluxes, we show evidential deep learning models attaining predictive accuracy rivaling standard methods, while robustly quantifying both sources of uncertainty. We evaluate the uncertainty in terms of how well the predictions are calibrated and how well the uncertainty correlates with prediction error. Analyses of uncertainty in the context of the inputs reveal sensitivities to underlying meteorological processes, facilitating interpretation of the models. The conceptual simplicity, interpretability, and computational efficiency of evidential neural networks make them highly extensible, offering a promising approach for reliable and practical uncertainty quantification in Earth system science modeling. In order to encourage broader adoption of evidential deep learning in Earth System Science, we have developed a new Python package, MILES-GUESS (https://github.com/ai2es/miles-guess), that enables users to train and evaluate both evidential and ensemble deep learning.
<div id='section'>Paperid: <span id='pid'>216, <a href='https://arxiv.org/pdf/2309.10230.pdf' target='_blank'>https://arxiv.org/pdf/2309.10230.pdf</a></span>   <span><a href='https://github.com/Daniellli/LiON/' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/Daniellli/LiON/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shaocong Xu, Pengfei Li, Qianpu Sun, Xinyu Liu, Yang Li, Shihui Guo, Zhen Wang, Bo Jiang, Rui Wang, Kehua Sheng, Bo Zhang, Li Jiang, Hao Zhao, Yilun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10230">LiON: Learning Point-wise Abstaining Penalty for LiDAR Outlier DetectioN Using Diverse Synthetic Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based semantic scene understanding is an important module in the modern autonomous driving perception stack. However, identifying outlier points in a LiDAR point cloud is challenging as LiDAR point clouds lack semantically-rich information. While former SOTA methods adopt heuristic architectures, we revisit this problem from the perspective of Selective Classification, which introduces a selective function into the standard closed-set classification setup. Our solution is built upon the basic idea of abstaining from choosing any inlier categories but learns a point-wise abstaining penalty with a margin-based loss. Apart from learning paradigms, synthesizing outliers to approximate unlimited real outliers is also critical, so we propose a strong synthesis pipeline that generates outliers originated from various factors: object categories, sampling patterns and sizes. We demonstrate that learning different abstaining penalties, apart from point-wise penalty, for different types of (synthesized) outliers can further improve the performance. We benchmark our method on SemanticKITTI and nuScenes and achieve SOTA results. Codes are available at https://github.com/Daniellli/LiON/.
<div id='section'>Paperid: <span id='pid'>217, <a href='https://arxiv.org/pdf/2309.09599.pdf' target='_blank'>https://arxiv.org/pdf/2309.09599.pdf</a></span>   <span><a href='https://github.com/paathelb/MEDL-U' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Helbert Paat, Qing Lian, Weilong Yao, Tong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.09599">MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advancements in deep learning-based 3D object detection necessitate the availability of large-scale datasets. However, this requirement introduces the challenge of manual annotation, which is often both burdensome and time-consuming. To tackle this issue, the literature has seen the emergence of several weakly supervised frameworks for 3D object detection which can automatically generate pseudo labels for unlabeled data. Nevertheless, these generated pseudo labels contain noise and are not as accurate as those labeled by humans. In this paper, we present the first approach that addresses the inherent ambiguities present in pseudo labels by introducing an Evidential Deep Learning (EDL) based uncertainty estimation framework. Specifically, we propose MEDL-U, an EDL framework based on MTrans, which not only generates pseudo labels but also quantifies the associated uncertainties. However, applying EDL to 3D object detection presents three primary challenges: (1) relatively lower pseudolabel quality in comparison to other autolabelers; (2) excessively high evidential uncertainty estimates; and (3) lack of clear interpretability and effective utilization of uncertainties for downstream tasks. We tackle these issues through the introduction of an uncertainty-aware IoU-based loss, an evidence-aware multi-task loss function, and the implementation of a post-processing stage for uncertainty refinement. Our experimental results demonstrate that probabilistic detectors trained using the outputs of MEDL-U surpass deterministic detectors trained using outputs from previous 3D annotators on the KITTI val set for all difficulty levels. Moreover, MEDL-U achieves state-of-the-art results on the KITTI official test set compared to existing 3D automatic annotators.
<div id='section'>Paperid: <span id='pid'>218, <a href='https://arxiv.org/pdf/2309.05994.pdf' target='_blank'>https://arxiv.org/pdf/2309.05994.pdf</a></span>   <span><a href='https://github.com/gaozhitong/ATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhitong Gao, Shipeng Yan, Xuming He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05994">ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in dense out-of-distribution (OOD) detection have primarily focused on scenarios where the training and testing datasets share a similar domain, with the assumption that no domain shift exists between them. However, in real-world situations, domain shift often exits and significantly affects the accuracy of existing out-of-distribution (OOD) detection models. In this work, we propose a dual-level OOD detection framework to handle domain shift and semantic shift jointly. The first level distinguishes whether domain shift exists in the image by leveraging global low-level features, while the second level identifies pixels with semantic shift by utilizing dense high-level feature maps. In this way, we can selectively adapt the model to unseen domains as well as enhance model's capacity in detecting novel classes. We validate the efficacy of our proposed method on several OOD segmentation benchmarks, including those with significant domain shifts and those without, observing consistent performance improvements across various baseline models. Code is available at ${\href{https://github.com/gaozhitong/ATTA}{https://github.com/gaozhitong/ATTA}}$.
<div id='section'>Paperid: <span id='pid'>219, <a href='https://arxiv.org/pdf/2309.02084.pdf' target='_blank'>https://arxiv.org/pdf/2309.02084.pdf</a></span>   <span><a href='https://github.com/ZJLAB-AMMI/VAE4OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zezhen Zeng, Bin Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02084">Unsupervised Out-of-Distribution Detection by Restoring Lossy Inputs with Variational Autoencoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep generative models have been demonstrated as problematic in the unsupervised out-of-distribution (OOD) detection task, where they tend to assign higher likelihoods to OOD samples. Previous studies on this issue are usually not applicable to the Variational Autoencoder (VAE). As a popular subclass of generative models, the VAE can be effective with a relatively smaller model size and be more stable and faster in training and inference, which can be more advantageous in real-world applications. In this paper, We propose a novel VAE-based score called Error Reduction (ER) for OOD detection, which is based on a VAE that takes a lossy version of the training set as inputs and the original set as targets. Experiments are carried out on various datasets to show the effectiveness of our method, we also present the effect of design choices with ablation experiments. Our code is available at: https://github.com/ZJLAB-AMMI/VAE4OOD.
<div id='section'>Paperid: <span id='pid'>220, <a href='https://arxiv.org/pdf/2309.01488.pdf' target='_blank'>https://arxiv.org/pdf/2309.01488.pdf</a></span>   <span><a href='https://github.com/HarryAnthony/Mahalanobis-OOD-detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Harry Anthony, Konstantinos Kamnitsas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.01488">On the use of Mahalanobis distance for out-of-distribution detection with neural networks for medical imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Implementing neural networks for clinical use in medical applications necessitates the ability for the network to detect when input data differs significantly from the training data, with the aim of preventing unreliable predictions. The community has developed several methods for out-of-distribution (OOD) detection, within which distance-based approaches - such as Mahalanobis distance - have shown potential. This paper challenges the prevailing community understanding that there is an optimal layer, or combination of layers, of a neural network for applying Mahalanobis distance for detection of any OOD pattern. Using synthetic artefacts to emulate OOD patterns, this paper shows the optimum layer to apply Mahalanobis distance changes with the type of OOD pattern, showing there is no one-fits-all solution. This paper also shows that separating this OOD detector into multiple detectors at different depths of the network can enhance the robustness for detecting different OOD patterns. These insights were validated on real-world OOD tasks, training models on CheXpert chest X-rays with no support devices, then using scans with unseen pacemakers (we manually labelled 50% of CheXpert for this research) and unseen sex as OOD cases. The results inform best-practices for the use of Mahalanobis distance for OOD detection. The manually annotated pacemaker labels and the project's code are available at: https://github.com/HarryAnthony/Mahalanobis-OOD-detection.
<div id='section'>Paperid: <span id='pid'>221, <a href='https://arxiv.org/pdf/2308.12919.pdf' target='_blank'>https://arxiv.org/pdf/2308.12919.pdf</a></span>   <span><a href='https://github.com/tim-learn/UEO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Liang, Lijun Sheng, Zhengbo Wang, Ran He, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12919">Realistic Unsupervised CLIP Fine-tuning with Universal Entropy Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The emergence of vision-language models, such as CLIP, has spurred a significant research effort towards their application for downstream supervised learning tasks. Although some previous studies have explored the unsupervised fine-tuning of CLIP, they often rely on prior knowledge in the form of class names associated with ground truth labels. This paper explores a realistic unsupervised fine-tuning scenario, considering the presence of out-of-distribution samples from unknown classes within the unlabeled data. In particular, we focus on simultaneously enhancing out-of-distribution detection and the recognition of instances associated with known classes. To tackle this problem, we present a simple, efficient, and effective approach called Universal Entropy Optimization (UEO). UEO leverages sample-level confidence to approximately minimize the conditional entropy of confident instances and maximize the marginal entropy of less confident instances. Apart from optimizing the textual prompt, UEO incorporates optimization of channel-wise affine transformations within the visual branch of CLIP. Extensive experiments across 15 domains and 4 different types of prior knowledge validate the effectiveness of UEO compared to baseline methods. The code is publicly available at \url{https://github.com/tim-learn/UEO}.
<div id='section'>Paperid: <span id='pid'>222, <a href='https://arxiv.org/pdf/2308.12659.pdf' target='_blank'>https://arxiv.org/pdf/2308.12659.pdf</a></span>   <span><a href='https://github.com/Learner0x5a/kTrans-release' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenyu Zhu, Hao Wang, Yuchen Zhou, Jiaming Wang, Zihan Sha, Zeyu Gao, Chao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12659">kTrans: Knowledge-Aware Transformer for Binary Code Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Binary Code Embedding (BCE) has important applications in various reverse engineering tasks such as binary code similarity detection, type recovery, control-flow recovery and data-flow analysis. Recent studies have shown that the Transformer model can comprehend the semantics of binary code to support downstream tasks. However, existing models overlooked the prior knowledge of assembly language. In this paper, we propose a novel Transformer-based approach, namely kTrans, to generate knowledge-aware binary code embedding. By feeding explicit knowledge as additional inputs to the Transformer, and fusing implicit knowledge with a novel pre-training task, kTrans provides a new perspective to incorporating domain knowledge into a Transformer framework. We inspect the generated embeddings with outlier detection and visualization, and also apply kTrans to 3 downstream tasks: Binary Code Similarity Detection (BCSD), Function Type Recovery (FTR) and Indirect Call Recognition (ICR). Evaluation results show that kTrans can generate high-quality binary code embeddings, and outperforms state-of-the-art (SOTA) approaches on downstream tasks by 5.2%, 6.8%, and 12.6% respectively. kTrans is publicly available at: https://github.com/Learner0x5a/kTrans-release
<div id='section'>Paperid: <span id='pid'>223, <a href='https://arxiv.org/pdf/2308.10261.pdf' target='_blank'>https://arxiv.org/pdf/2308.10261.pdf</a></span>   <span><a href='https://github.com/Awenbocc/LLM-OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Liu, Liming Zhan, Zexin Lu, Yujie Feng, Lei Xue, Xiao-Ming Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10261">How Good Are LLMs at Out-of-Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning (ML) models. The emergence of large language models (LLMs) has catalyzed a paradigm shift within the ML community, showcasing their exceptional capabilities across diverse natural language processing tasks. While existing research has probed OOD detection with relative small-scale Transformers like BERT, RoBERTa and GPT-2, the stark differences in scales, pre-training objectives, and inference paradigms call into question the applicability of these findings to LLMs. This paper embarks on a pioneering empirical investigation of OOD detection in the domain of LLMs, focusing on LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly-used OOD detectors, scrutinizing their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLMs with downstream tasks. Our findings unveil that a simple cosine distance OOD detector demonstrates superior efficacy, outperforming other OOD detectors. We provide an intriguing explanation for this phenomenon by highlighting the isotropic nature of the embedding spaces of LLMs, which distinctly contrasts with the anisotropic property observed in smaller BERT family models. The new insight enhances our understanding of how LLMs detect OOD data, thereby enhancing their adaptability and reliability in dynamic environments. We have released the source code at \url{https://github.com/Awenbocc/LLM-OOD} for other researchers to reproduce our results.
<div id='section'>Paperid: <span id='pid'>224, <a href='https://arxiv.org/pdf/2308.10239.pdf' target='_blank'>https://arxiv.org/pdf/2308.10239.pdf</a></span>   <span><a href='https://github.com/JimZAI/MODE-OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ji Zhang, Lianli Gao, Bingguang Hao, Hao Huang, Jingkuan Song, Hengtao Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10239">From Global to Local: Multi-scale Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection aims to detect "unknown" data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.
<div id='section'>Paperid: <span id='pid'>225, <a href='https://arxiv.org/pdf/2308.09065.pdf' target='_blank'>https://arxiv.org/pdf/2308.09065.pdf</a></span>   <span><a href='https://github.com/ENSTA-U2IS/DIDO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuanlong Yu, Gianni Franchi, Jindong Gu, Emanuel Aldea
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09065">Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the prediction error. For epistemic uncertainty, we propose a novel solution named Discretization-Induced Dirichlet pOsterior (DIDO), which models the Dirichlet posterior on the discretized prediction error. Extensive experiments on age estimation, monocular depth estimation, and super-resolution tasks show that our proposed method can provide robust uncertainty estimates in the face of noisy inputs and that it can be scalable to both image-level and pixel-wise tasks. Code is available at https://github.com/ENSTA-U2IS/DIDO .
<div id='section'>Paperid: <span id='pid'>226, <a href='https://arxiv.org/pdf/2308.06129.pdf' target='_blank'>https://arxiv.org/pdf/2308.06129.pdf</a></span>   <span><a href='https://github.com/alextimans/traffic4cast-uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Timans, Nina Wiedemann, Nishant Kumar, Ye Hong, Martin Raubal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06129">Uncertainty Quantification for Image-based Traffic Prediction across Cities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the strong predictive performance of deep learning models for traffic prediction, their widespread deployment in real-world intelligent transportation systems has been restrained by a lack of interpretability. Uncertainty quantification (UQ) methods provide an approach to induce probabilistic reasoning, improve decision-making and enhance model deployment potential. To gain a comprehensive picture of the usefulness of existing UQ methods for traffic prediction and the relation between obtained uncertainties and city-wide traffic dynamics, we investigate their application to a large-scale image-based traffic dataset spanning multiple cities and time periods. We compare two epistemic and two aleatoric UQ methods on both temporal and spatio-temporal transfer tasks, and find that meaningful uncertainty estimates can be recovered. We further demonstrate how uncertainty estimates can be employed for unsupervised outlier detection on changes in city traffic dynamics. We find that our approach can capture both temporal and spatial effects on traffic behaviour in a representative case study for the city of Moscow. Our work presents a further step towards boosting uncertainty awareness in traffic prediction tasks, and aims to highlight the value contribution of UQ methods to a better understanding of city traffic dynamics.
<div id='section'>Paperid: <span id='pid'>227, <a href='https://arxiv.org/pdf/2308.00728.pdf' target='_blank'>https://arxiv.org/pdf/2308.00728.pdf</a></span>   <span><a href='https://github.com/jimmy19991222/ELFNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jieming Lou, Weide Liu, Zhuo Chen, Fayao Liu, Jun Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.00728">ELFNet: Evidential Local-global Fusion for Stereo Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although existing stereo matching models have achieved continuous improvement, they often face issues related to trustworthiness due to the absence of uncertainty estimation. Additionally, effectively leveraging multi-scale and multi-view knowledge of stereo pairs remains unexplored. In this paper, we introduce the \textbf{E}vidential \textbf{L}ocal-global \textbf{F}usion (ELF) framework for stereo matching, which endows both uncertainty estimation and confidence-aware fusion with trustworthy heads. Instead of predicting the disparity map alone, our model estimates an evidential-based disparity considering both aleatoric and epistemic uncertainties. With the normal inverse-Gamma distribution as a bridge, the proposed framework realizes intra evidential fusion of multi-level predictions and inter evidential fusion between cost-volume-based and transformer-based stereo matching. Extensive experimental results show that the proposed framework exploits multi-view information effectively and achieves state-of-the-art overall performance both on accuracy and cross-domain generalization.
  The codes are available at https://github.com/jimmy19991222/ELFNet.
<div id='section'>Paperid: <span id='pid'>228, <a href='https://arxiv.org/pdf/2307.16509.pdf' target='_blank'>https://arxiv.org/pdf/2307.16509.pdf</a></span>   <span><a href='https://github.com/gallenszl/UCFNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhelun Shen, Xibin Song, Yuchao Dai, Dingfu Zhou, Zhibo Rao, Liangjun Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.16509">Digging Into Uncertainty-based Pseudo-label for Robust Stereo Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the domain differences and unbalanced disparity distribution across multiple datasets, current stereo matching approaches are commonly limited to a specific dataset and generalize poorly to others. Such domain shift issue is usually addressed by substantial adaptation on costly target-domain ground-truth data, which cannot be easily obtained in practical settings. In this paper, we propose to dig into uncertainty estimation for robust stereo matching. Specifically, to balance the disparity distribution, we employ a pixel-level uncertainty estimation to adaptively adjust the next stage disparity searching space, in this way driving the network progressively prune out the space of unlikely correspondences. Then, to solve the limited ground truth data, an uncertainty-based pseudo-label is proposed to adapt the pre-trained model to the new domain, where pixel-level and area-level uncertainty estimation are proposed to filter out the high-uncertainty pixels of predicted disparity maps and generate sparse while reliable pseudo-labels to align the domain gap. Experimentally, our method shows strong cross-domain, adapt, and joint generalization and obtains \textbf{1st} place on the stereo task of Robust Vision Challenge 2020. Additionally, our uncertainty-based pseudo-labels can be extended to train monocular depth estimation networks in an unsupervised way and even achieves comparable performance with the supervised methods. The code will be available at https://github.com/gallenszl/UCFNet.
<div id='section'>Paperid: <span id='pid'>229, <a href='https://arxiv.org/pdf/2307.09055.pdf' target='_blank'>https://arxiv.org/pdf/2307.09055.pdf</a></span>   <span><a href='https://github.com/twugithub/2024-AISTATS-ORTLRR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.09055">Robust Data Clustering with Outliers via Transformed Tensor Low-Rank Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, tensor low-rank representation (TLRR) has become a popular tool for tensor data recovery and clustering, due to its empirical success and theoretical guarantees. However, existing TLRR methods consider Gaussian or gross sparse noise, inevitably leading to performance degradation when the tensor data are contaminated by outliers or sample-specific corruptions. This paper develops an outlier-robust tensor low-rank representation (OR-TLRR) method that provides outlier detection and tensor data clustering simultaneously based on the t-SVD framework. For tensor observations with arbitrary outlier corruptions, OR-TLRR has provable performance guarantee for exactly recovering the row space of clean data and detecting outliers under mild conditions. Moreover, an extension of OR-TLRR is proposed to handle the case when parts of the data are missing. Finally, extensive experimental results on synthetic and real data demonstrate the effectiveness of the proposed algorithms. We release our code at https://github.com/twugithub/2024-AISTATS-ORTLRR.
<div id='section'>Paperid: <span id='pid'>230, <a href='https://arxiv.org/pdf/2307.03777.pdf' target='_blank'>https://arxiv.org/pdf/2307.03777.pdf</a></span>   <span><a href='https://github.com/marksgraham/ddpm-ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mark S. Graham, Walter Hugo Lopez Pinaya, Paul Wright, Petru-Daniel Tudosiu, Yee H. Mah, James T. Teo, H. Rolf JÃ¤ger, David Werring, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardoso
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.03777">Unsupervised 3D out-of-distribution detection with latent diffusion models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Methods for out-of-distribution (OOD) detection that scale to 3D data are crucial components of any real-world clinical deep learning system. Classic denoising diffusion probabilistic models (DDPMs) have been recently proposed as a robust way to perform reconstruction-based OOD detection on 2D datasets, but do not trivially scale to 3D data. In this work, we propose to use Latent Diffusion Models (LDMs), which enable the scaling of DDPMs to high-resolution 3D medical data. We validate the proposed approach on near- and far-OOD datasets and compare it to a recently proposed, 3D-enabled approach using Latent Transformer Models (LTMs). Not only does the proposed LDM-based approach achieve statistically significant better performance, it also shows less sensitivity to the underlying latent representation, more favourable memory scaling, and produces better spatial anomaly maps. Code is available at https://github.com/marksgraham/ddpm-ood
<div id='section'>Paperid: <span id='pid'>231, <a href='https://arxiv.org/pdf/2307.03741.pdf' target='_blank'>https://arxiv.org/pdf/2307.03741.pdf</a></span>   <span><a href='https://github.com/vladan-stojnic/active-outliers' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Vladan StojniÄ, Zakaria Laskar, Giorgos Tolias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.03741">Training Ensembles with Inliers and Outliers for Semi-supervised Active Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep active learning in the presence of outlier examples poses a realistic yet challenging scenario. Acquiring unlabeled data for annotation requires a delicate balance between avoiding outliers to conserve the annotation budget and prioritizing useful inlier examples for effective training. In this work, we present an approach that leverages three highly synergistic components, which are identified as key ingredients: joint classifier training with inliers and outliers, semi-supervised learning through pseudo-labeling, and model ensembling. Our work demonstrates that ensembling significantly enhances the accuracy of pseudo-labeling and improves the quality of data acquisition. By enabling semi-supervision through the joint training process, where outliers are properly handled, we observe a substantial boost in classifier accuracy through the use of all available unlabeled examples. Notably, we reveal that the integration of joint training renders explicit outlier detection unnecessary; a conventional component for acquisition in prior work. The three key components align seamlessly with numerous existing approaches. Through empirical evaluations, we showcase that their combined use leads to a performance increase. Remarkably, despite its simplicity, our proposed approach outperforms all other methods in terms of performance. Code: https://github.com/vladan-stojnic/active-outliers
<div id='section'>Paperid: <span id='pid'>232, <a href='https://arxiv.org/pdf/2307.00934.pdf' target='_blank'>https://arxiv.org/pdf/2307.00934.pdf</a></span>   <span><a href='https://github.com/fiveai/saod' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kemal Oksuz, Tom Joy, Puneet K. Dokania
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.00934">Towards Building Self-Aware Object Detectors via Reliable Uncertainty Quantification and Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The current approach for testing the robustness of object detectors suffers from serious deficiencies such as improper methods of performing out-of-distribution detection and using calibration metrics which do not consider both localisation and classification quality. In this work, we address these issues, and introduce the Self-Aware Object Detection (SAOD) task, a unified testing framework which respects and adheres to the challenges that object detectors face in safety-critical environments such as autonomous driving. Specifically, the SAOD task requires an object detector to be: robust to domain shift; obtain reliable uncertainty estimates for the entire scene; and provide calibrated confidence scores for the detections. We extensively use our framework, which introduces novel metrics and large scale test datasets, to test numerous object detectors in two different use-cases, allowing us to highlight critical insights into their robustness performance. Finally, we introduce a simple baseline for the SAOD task, enabling researchers to benchmark future proposed methods and move towards robust object detectors which are fit for purpose. Code is available at https://github.com/fiveai/saod
<div id='section'>Paperid: <span id='pid'>233, <a href='https://arxiv.org/pdf/2307.00899.pdf' target='_blank'>https://arxiv.org/pdf/2307.00899.pdf</a></span>   <span><a href='https://github.com/matt-baugh/many-tasks-make-light-work' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew Baugh, Jeremy Tan, Johanna P. MÃ¼ller, Mischa Dombrowski, James Batten, Bernhard Kainz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.00899">Many tasks make light work: Learning to localise medical anomalies from multiple synthetic tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There is a growing interest in single-class modelling and out-of-distribution detection as fully supervised machine learning models cannot reliably identify classes not included in their training. The long tail of infinitely many out-of-distribution classes in real-world scenarios, e.g., for screening, triage, and quality control, means that it is often necessary to train single-class models that represent an expected feature distribution, e.g., from only strictly healthy volunteer data. Conventional supervised machine learning would require the collection of datasets that contain enough samples of all possible diseases in every imaging modality, which is not realistic. Self-supervised learning methods with synthetic anomalies are currently amongst the most promising approaches, alongside generative auto-encoders that analyse the residual reconstruction error. However, all methods suffer from a lack of structured validation, which makes calibration for deployment difficult and dataset-dependant. Our method alleviates this by making use of multiple visually-distinct synthetic anomaly learning tasks for both training and validation. This enables more robust training and generalisation. With our approach we can readily outperform state-of-the-art methods, which we demonstrate on exemplars in brain MRI and chest X-rays. Code is available at https://github.com/matt-baugh/many-tasks-make-light-work .
<div id='section'>Paperid: <span id='pid'>234, <a href='https://arxiv.org/pdf/2306.16914.pdf' target='_blank'>https://arxiv.org/pdf/2306.16914.pdf</a></span>   <span><a href='https://github.com/cmu-delphi/covidcast-indicators/tree/main/_delphi_utils_python/delphi_utils/flash_eval' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ananya Joshi, Kathryn Mazaitis, Roni Rosenfeld, Bryan Wilder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.16914">Computationally Assisted Quality Control for Public Health Data Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of daily-updated public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful. Based on these results, FlaSH has been deployed on data streams used by public health stakeholders.
<div id='section'>Paperid: <span id='pid'>235, <a href='https://arxiv.org/pdf/2306.16556.pdf' target='_blank'>https://arxiv.org/pdf/2306.16556.pdf</a></span>   <span><a href='https://github.com/HaoWang420/bOEMD-net' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingqiao Hu, Hao Wang, Jing Luo, Yunhao Luo, Zhiheng Zhangg, Jan S. Kirschke, Benedikt Wiestler, Bjoern Menze, Jianguo Zhang, Hongwei Bran Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.16556">Inter-Rater Uncertainty Quantification in Medical Image Segmentation via Rater-Specific Bayesian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated medical image segmentation inherently involves a certain degree of uncertainty. One key factor contributing to this uncertainty is the ambiguity that can arise in determining the boundaries of a target region of interest, primarily due to variations in image appearance. On top of this, even among experts in the field, different opinions can emerge regarding the precise definition of specific anatomical structures. This work specifically addresses the modeling of segmentation uncertainty, known as inter-rater uncertainty. Its primary objective is to explore and analyze the variability in segmentation outcomes that can occur when multiple experts in medical imaging interpret and annotate the same images. We introduce a novel Bayesian neural network-based architecture to estimate inter-rater uncertainty in medical image segmentation. Our approach has three key advancements. Firstly, we introduce a one-encoder-multi-decoder architecture specifically tailored for uncertainty estimation, enabling us to capture the rater-specific representation of each expert involved. Secondly, we propose Bayesian modeling for the new architecture, allowing efficient capture of the inter-rater distribution, particularly in scenarios with limited annotations. Lastly, we enhance the rater-specific representation by integrating an attention module into each decoder. This module facilitates focused and refined segmentation results for each rater. We conduct extensive evaluations using synthetic and real-world datasets to validate our technical innovations rigorously. Our method surpasses existing baseline methods in five out of seven diverse tasks on the publicly available \emph{QUBIQ} dataset, considering two evaluation metrics encompassing different uncertainty aspects. Our codes, models, and the new dataset are available through our GitHub repository: https://github.com/HaoWang420/bOEMD-net .
<div id='section'>Paperid: <span id='pid'>236, <a href='https://arxiv.org/pdf/2306.15880.pdf' target='_blank'>https://arxiv.org/pdf/2306.15880.pdf</a></span>   <span><a href='https://github.com/jianzongwu/Awesome-Open-Vocabulary' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/jianzongwu/Awesome-Open-Vocabulary' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianzong Wu, Xiangtai Li, Shilin Xu, Haobo Yuan, Henghui Ding, Yibo Yang, Xia Li, Jiangning Zhang, Yunhai Tong, Xudong Jiang, Bernard Ghanem, Dacheng Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.15880">Towards Open Vocabulary Learning: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of visual scene understanding, deep neural networks have made impressive advancements in various core tasks like segmentation, tracking, and detection. However, most approaches operate on the close-set assumption, meaning that the model can only identify pre-defined categories that are present in the training set. Recently, open vocabulary settings were proposed due to the rapid progress of vision language pre-training. These new approaches seek to locate and recognize categories beyond the annotated label space. The open vocabulary approach is more general, practical, and effective compared to weakly supervised and zero-shot settings. This paper provides a thorough review of open vocabulary learning, summarizing and analyzing recent developments in the field. In particular, we begin by comparing it to related concepts such as zero-shot learning, open-set recognition, and out-of-distribution detection. Then, we review several closely related tasks in the case of segmentation and detection, including long-tail problems, few-shot, and zero-shot settings. For the method survey, we first present the basic knowledge of detection and segmentation in close-set as the preliminary knowledge. Next, we examine various scenarios in which open vocabulary learning is used, identifying common design elements and core ideas. Then, we compare the recent detection and segmentation approaches in commonly used datasets and benchmarks. Finally, we conclude with insights, issues, and discussions regarding future research directions. To our knowledge, this is the first comprehensive literature review of open vocabulary learning. We keep tracing related works at https://github.com/jianzongwu/Awesome-Open-Vocabulary.
<div id='section'>Paperid: <span id='pid'>237, <a href='https://arxiv.org/pdf/2306.14658.pdf' target='_blank'>https://arxiv.org/pdf/2306.14658.pdf</a></span>   <span><a href='https://github.com/glhr/beyond-auroc' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Galadrielle Humblot-Renaux, Sergio Escalera, Thomas B. Moeslund
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14658">Beyond AUROC & co. for evaluating out-of-distribution detection performance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While there has been a growing research interest in developing out-of-distribution (OOD) detection methods, there has been comparably little discussion around how these methods should be evaluated. Given their relevance for safe(r) AI, it is important to examine whether the basis for comparing OOD detection methods is consistent with practical needs. In this work, we take a closer look at the go-to metrics for evaluating OOD detection, and question the approach of exclusively reducing OOD detection to a binary classification task with little consideration for the detection threshold. We illustrate the limitations of current metrics (AUROC & its friends) and propose a new metric - Area Under the Threshold Curve (AUTC), which explicitly penalizes poor separation between ID and OOD samples. Scripts and data are available at https://github.com/glhr/beyond-auroc
<div id='section'>Paperid: <span id='pid'>238, <a href='https://arxiv.org/pdf/2306.13063.pdf' target='_blank'>https://arxiv.org/pdf/2306.13063.pdf</a></span>   <span><a href='https://github.com/MiaoXiong2320/llm-uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, Bryan Hooi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13063">Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Empowering large language models to accurately express confidence in their answers is essential for trustworthy decision-making. Previous confidence elicitation methods, which primarily rely on white-box access to internal model information or model fine-tuning, have become less suitable for LLMs, especially closed-source commercial APIs. This leads to a growing need to explore the untapped area of black-box approaches for LLM uncertainty estimation. To better break down the problem, we define a systematic framework with three components: prompting strategies for eliciting verbalized confidence, sampling methods for generating multiple responses, and aggregation techniques for computing consistency. We then benchmark these methods on two key tasks-confidence calibration and failure prediction-across five types of datasets (e.g., commonsense and arithmetic reasoning) and five widely-used LLMs including GPT-4 and LLaMA 2 Chat. Our analysis uncovers several key insights: 1) LLMs, when verbalizing their confidence, tend to be overconfident, potentially imitating human patterns of expressing confidence. 2) As model capability scales up, both calibration and failure prediction performance improve. 3) Employing our proposed strategies, such as human-inspired prompts, consistency among multiple responses, and better aggregation strategies can help mitigate this overconfidence from various perspectives. 4) Comparisons with white-box methods indicate that while white-box methods perform better, the gap is narrow, e.g., 0.522 to 0.605 in AUROC. Despite these advancements, none of these techniques consistently outperform others, and all investigated methods struggle in challenging tasks, such as those requiring professional knowledge, indicating significant scope for improvement. We believe this study can serve as a strong baseline and provide insights for eliciting confidence in black-box LLMs.
<div id='section'>Paperid: <span id='pid'>239, <a href='https://arxiv.org/pdf/2306.11048.pdf' target='_blank'>https://arxiv.org/pdf/2306.11048.pdf</a></span>   <span><a href='https://github.com/kev-in-ta/UncLe-SLAM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Erik SandstrÃ¶m, Kevin Ta, Luc Van Gool, Martin R. Oswald
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11048">UncLe-SLAM: Uncertainty Learning for Dense Neural SLAM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present an uncertainty learning framework for dense neural simultaneous localization and mapping (SLAM). Estimating pixel-wise uncertainties for the depth input of dense SLAM methods allows re-weighing the tracking and mapping losses towards image regions that contain more suitable information that is more reliable for SLAM. To this end, we propose an online framework for sensor uncertainty estimation that can be trained in a self-supervised manner from only 2D input data. We further discuss the advantages of the uncertainty learning for the case of multi-sensor input. Extensive analysis, experimentation, and ablations show that our proposed modeling paradigm improves both mapping and tracking accuracy and often performs better than alternatives that require ground truth depth or 3D. Our experiments show that we achieve a 38\% and 27\% lower absolute trajectory tracking error (ATE) on the 7-Scenes and TUM-RGBD datasets respectively. On the popular Replica dataset using two types of depth sensors, we report an 11\% F1-score improvement on RGBD SLAM compared to the recent state-of-the-art neural implicit approaches. Source code: https://github.com/kev-in-ta/UncLe-SLAM.
<div id='section'>Paperid: <span id='pid'>240, <a href='https://arxiv.org/pdf/2306.10485.pdf' target='_blank'>https://arxiv.org/pdf/2306.10485.pdf</a></span>   <span><a href='https://github.com/hyunjunChhoi/Balanced_Energy' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunjun Choi, Hawook Jeong, Jin Young Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.10485">Balanced Energy Regularization Loss for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of out-of-distribution (OOD) detection, a previous method that use auxiliary data as OOD data has shown promising performance. However, the method provides an equal loss to all auxiliary data to differentiate them from inliers. However, based on our observation, in various tasks, there is a general imbalance in the distribution of the auxiliary OOD data across classes. We propose a balanced energy regularization loss that is simple but generally effective for a variety of tasks. Our balanced energy regularization loss utilizes class-wise different prior probabilities for auxiliary data to address the class imbalance in OOD data. The main concept is to regularize auxiliary samples from majority classes, more heavily than those from minority classes. Our approach performs better for OOD detection in semantic segmentation, long-tailed image classification, and image classification than the prior energy regularization loss. Furthermore, our approach achieves state-of-the-art performance in two tasks: OOD detection in semantic segmentation and long-tailed image classification. Code is available at https://github.com/hyunjunChhoi/Balanced_Energy.
<div id='section'>Paperid: <span id='pid'>241, <a href='https://arxiv.org/pdf/2306.09301.pdf' target='_blank'>https://arxiv.org/pdf/2306.09301.pdf</a></span>   <span><a href='https://github.com/Jingkang50/OpenOOD/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyang Zhang, Jingkang Yang, Pengyun Wang, Haoqi Wang, Yueqian Lin, Haoran Zhang, Yiyou Sun, Xuefeng Du, Yixuan Li, Ziwei Liu, Yiran Chen, Hai Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09301">OpenOOD v1.5: Enhanced Benchmark for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is critical for the reliable operation of open-world intelligent systems. Despite the emergence of an increasing number of OOD detection methods, the evaluation inconsistencies present challenges for tracking the progress in this field. OpenOOD v1 initiated the unification of the OOD detection evaluation but faced limitations in scalability and scope. In response, this paper presents OpenOOD v1.5, a significant improvement from its predecessor that ensures accurate and standardized evaluation of OOD detection methodologies at large scale. Notably, OpenOOD v1.5 extends its evaluation capabilities to large-scale data sets (ImageNet) and foundation models (e.g., CLIP and DINOv2), and expands its scope to investigate full-spectrum OOD detection which considers semantic and covariate distribution shifts at the same time. This work also contributes in-depth analysis and insights derived from comprehensive experimental results, thereby enriching the knowledge pool of OOD detection methodologies. With these enhancements, OpenOOD v1.5 aims to drive advancements and offer a more robust and comprehensive evaluation benchmark for OOD detection research.
<div id='section'>Paperid: <span id='pid'>242, <a href='https://arxiv.org/pdf/2306.08852.pdf' target='_blank'>https://arxiv.org/pdf/2306.08852.pdf</a></span>   <span><a href='https://github.com/yellowmessenger/ood-detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Louis Owen, Biddwan Ahmed, Abhay Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08852">BED: Bi-Encoder-Based Detectors for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel method leveraging bi-encoder-based detectors along with a comprehensive study comparing different out-of-distribution (OOD) detection methods in NLP using different feature extractors. The feature extraction stage employs popular methods such as Universal Sentence Encoder (USE), BERT, MPNET, and GLOVE to extract informative representations from textual data. The evaluation is conducted on several datasets, including CLINC150, ROSTD-Coarse, SNIPS, and YELLOW. Performance is assessed using metrics such as F1-Score, MCC, FPR@90, FPR@95, AUPR, an AUROC. The experimental results demonstrate that the proposed bi-encoder-based detectors outperform other methods, both those that require OOD labels in training and those that do not, across all datasets, showing great potential for OOD detection in NLP. The simplicity of the training process and the superior detection performance make them applicable to real-world scenarios. The presented methods and benchmarking metrics serve as a valuable resource for future research in OOD detection, enabling further advancements in this field. The code and implementation details can be found on our GitHub repository: https://github.com/yellowmessenger/ood-detection.
<div id='section'>Paperid: <span id='pid'>243, <a href='https://arxiv.org/pdf/2306.06599.pdf' target='_blank'>https://arxiv.org/pdf/2306.06599.pdf</a></span>   <span><a href='https://github.com/Wang-ML-Lab/variational-imbalanced-regression' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyan Wang, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06599">Variational Imbalanced Regression: Fair Uncertainty Quantification via Probabilistic Smoothing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing regression models tend to fall short in both accuracy and uncertainty estimation when the label distribution is imbalanced. In this paper, we propose a probabilistic deep learning model, dubbed variational imbalanced regression (VIR), which not only performs well in imbalanced regression but naturally produces reasonable uncertainty estimation as a byproduct. Different from typical variational autoencoders assuming I.I.D. representations (a data point's representation is not directly affected by other data points), our VIR borrows data with similar regression labels to compute the latent representation's variational distribution; furthermore, different from deterministic regression models producing point estimates, VIR predicts the entire normal-inverse-gamma distributions and modulates the associated conjugate distributions to impose probabilistic reweighting on the imbalanced data, thereby providing better uncertainty estimation. Experiments in several real-world datasets show that our VIR can outperform state-of-the-art imbalanced regression models in terms of both accuracy and uncertainty estimation. Code will soon be available at https://github.com/Wang-ML-Lab/variational-imbalanced-regression.
<div id='section'>Paperid: <span id='pid'>244, <a href='https://arxiv.org/pdf/2306.05671.pdf' target='_blank'>https://arxiv.org/pdf/2306.05671.pdf</a></span>   <span><a href='https://github.com/Saumya-Gupta-26/struct-uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saumya Gupta, Yikai Zhang, Xiaoling Hu, Prateek Prasanna, Chao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.05671">Topology-Aware Uncertainty for Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Segmentation of curvilinear structures such as vasculature and road networks is challenging due to relatively weak signals and complex geometry/topology. To facilitate and accelerate large scale annotation, one has to adopt semi-automatic approaches such as proofreading by experts. In this work, we focus on uncertainty estimation for such tasks, so that highly uncertain, and thus error-prone structures can be identified for human annotators to verify. Unlike most existing works, which provide pixel-wise uncertainty maps, we stipulate it is crucial to estimate uncertainty in the units of topological structures, e.g., small pieces of connections and branches. To achieve this, we leverage tools from topological data analysis, specifically discrete Morse theory (DMT), to first capture the structures, and then reason about their uncertainties. To model the uncertainty, we (1) propose a joint prediction model that estimates the uncertainty of a structure while taking the neighboring structures into consideration (inter-structural uncertainty); (2) propose a novel Probabilistic DMT to model the inherent uncertainty within each structure (intra-structural uncertainty) by sampling its representations via a perturb-and-walk scheme. On various 2D and 3D datasets, our method produces better structure-wise uncertainty maps compared to existing works. Code available at https://github.com/Saumya-Gupta-26/struct-uncertainty
<div id='section'>Paperid: <span id='pid'>245, <a href='https://arxiv.org/pdf/2306.03715.pdf' target='_blank'>https://arxiv.org/pdf/2306.03715.pdf</a></span>   <span><a href='https://github.com/tmlr-group/Unleashing-Mask' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianing Zhu, Hengzhuang Li, Jiangchao Yao, Tongliang Liu, Jianliang Xu, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03715">Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is an indispensable aspect of secure AI when deploying machine learning models in real-world applications. Previous paradigms either explore better scoring functions or utilize the knowledge of outliers to equip the models with the ability of OOD detection. However, few of them pay attention to the intrinsic OOD detection capability of the given model. In this work, we generally discover the existence of an intermediate stage of a model trained on in-distribution (ID) data having higher OOD detection performance than that of its final stage across different settings, and further identify one critical data-level attribution to be learning with the atypical samples. Based on such insights, we propose a novel method, Unleashing Mask, which aims to restore the OOD discriminative capabilities of the well-trained model with ID data. Our method utilizes a mask to figure out the memorized atypical samples, and then finetune the model or prune it with the introduced mask to forget them. Extensive experiments and analysis demonstrate the effectiveness of our method. The code is available at: https://github.com/tmlr-group/Unleashing-Mask.
<div id='section'>Paperid: <span id='pid'>246, <a href='https://arxiv.org/pdf/2306.01293.pdf' target='_blank'>https://arxiv.org/pdf/2306.01293.pdf</a></span>   <span><a href='https://github.com/AtsuMiyai/LoCoOp' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01293">LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel vision-language prompt learning approach for few-shot out-of-distribution (OOD) detection. Few-shot OOD detection aims to detect OOD images from classes that are unseen during training using only a few labeled in-distribution (ID) images. While prompt learning methods such as CoOp have shown effectiveness and efficiency in few-shot ID classification, they still face limitations in OOD detection due to the potential presence of ID-irrelevant information in text embeddings. To address this issue, we introduce a new approach called Local regularized Context Optimization (LoCoOp), which performs OOD regularization that utilizes the portions of CLIP local features as OOD features during training. CLIP's local features have a lot of ID-irrelevant nuisances (e.g., backgrounds), and by learning to push them away from the ID class text embeddings, we can remove the nuisances in the ID class text embeddings and enhance the separation between ID and OOD. Experiments on the large-scale ImageNet OOD detection benchmarks demonstrate the superiority of our LoCoOp over zero-shot, fully supervised detection methods and prompt learning methods. Notably, even in a one-shot setting -- just one label per class, LoCoOp outperforms existing zero-shot and fully supervised detection methods. The code will be available via https://github.com/AtsuMiyai/LoCoOp.
<div id='section'>Paperid: <span id='pid'>247, <a href='https://arxiv.org/pdf/2306.00826.pdf' target='_blank'>https://arxiv.org/pdf/2306.00826.pdf</a></span>   <span><a href='https://github.com/j-cb/NINCO' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/j-cb/NINCO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian Bitterwolf, Maximilian MÃ¼ller, Matthias Hein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.00826">In or Out? Fixing ImageNet Out-of-Distribution Detection Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is the problem of identifying inputs which are unrelated to the in-distribution task. The OOD detection performance when the in-distribution (ID) is ImageNet-1K is commonly being tested on a small range of test OOD datasets. We find that most of the currently used test OOD datasets, including datasets from the open set recognition (OSR) literature, have severe issues: In some cases more than 50$\%$ of the dataset contains objects belonging to one of the ID classes. These erroneous samples heavily distort the evaluation of OOD detectors. As a solution, we introduce with NINCO a novel test OOD dataset, each sample checked to be ID free, which with its fine-grained range of OOD classes allows for a detailed analysis of an OOD detector's strengths and failure modes, particularly when paired with a number of synthetic "OOD unit-tests". We provide detailed evaluations across a large set of architectures and OOD detection methods on NINCO and the unit-tests, revealing new insights about model weaknesses and the effects of pretraining on OOD detection performance. We provide code and data at https://github.com/j-cb/NINCO.
<div id='section'>Paperid: <span id='pid'>248, <a href='https://arxiv.org/pdf/2305.19780.pdf' target='_blank'>https://arxiv.org/pdf/2305.19780.pdf</a></span>   <span><a href='https://github.com/michael-fonder/M4DepthU' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>MichaÃ«l Fonder, Marc Van Droogenbroeck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.19780">A technique to jointly estimate depth and depth uncertainty for unmanned aerial vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When used by autonomous vehicles for trajectory planning or obstacle avoidance, depth estimation methods need to be reliable. Therefore, estimating the quality of the depth outputs is critical. In this paper, we show how M4Depth, a state-of-the-art depth estimation method designed for unmanned aerial vehicle (UAV) applications, can be enhanced to perform joint depth and uncertainty estimation. For that, we present a solution to convert the uncertainty estimates related to parallax generated by M4Depth into uncertainty estimates related to depth, and show that it outperforms the standard probabilistic approach. Our experiments on various public datasets demonstrate that our method performs consistently, even in zero-shot transfer. Besides, our method offers a compelling value when compared to existing multi-view depth estimation methods as it performs similarly on a multi-view depth estimation benchmark despite being 2.5 times faster and causal, as opposed to other methods. The code of our method is publicly available at https://github.com/michael-fonder/M4DepthU .
<div id='section'>Paperid: <span id='pid'>249, <a href='https://arxiv.org/pdf/2305.18450.pdf' target='_blank'>https://arxiv.org/pdf/2305.18450.pdf</a></span>   <span><a href='https://github.com/CherylTse/GBG-plusplus' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qin Xie, Qinghua Zhang, Shuyin Xia, Fan Zhao, Chengying Wu, Guoyin Wang, Weiping Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18450">GBG++: A Fast and Stable Granular Ball Generation Method for Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Granular ball computing (GBC), as an efficient, robust, and scalable learning method, has become a popular research topic of granular computing. GBC includes two stages: granular ball generation (GBG) and multi-granularity learning based on the granular ball (GB). However, the stability and efficiency of existing GBG methods need to be further improved due to their strong dependence on $k$-means or $k$-division. In addition, GB-based classifiers only unilaterally consider the GB's geometric characteristics to construct classification rules, but the GB's quality is ignored. Therefore, in this paper, based on the attention mechanism, a fast and stable GBG (GBG++) method is proposed first. Specifically, the proposed GBG++ method only needs to calculate the distances from the data-driven center to the undivided samples when splitting each GB instead of randomly selecting the center and calculating the distances between it and all samples. Moreover, an outlier detection method is introduced to identify local outliers. Consequently, the GBG++ method can significantly improve effectiveness, robustness, and efficiency while being absolutely stable. Second, considering the influence of the sample size within the GB on the GB's quality, based on the GBG++ method, an improved GB-based $k$-nearest neighbors algorithm (GB$k$NN++) is presented, which can reduce misclassification at the class boundary. Finally, the experimental results indicate that the proposed method outperforms several existing GB-based classifiers and classical machine learning classifiers on $24$ public benchmark datasets. The implementation code of experiments is available at https://github.com/CherylTse/GBG-plusplus.
<div id='section'>Paperid: <span id='pid'>250, <a href='https://arxiv.org/pdf/2305.18026.pdf' target='_blank'>https://arxiv.org/pdf/2305.18026.pdf</a></span>   <span><a href='https://github.com/cytai/SRLOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinan Zou, Maihao Guo, Yu Tian, Yuhao Lin, Haiyao Cao, Lingqiao Liu, Ehsan Abbasnejad, Javen Qinfeng Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18026">Semantic Role Labeling Guided Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying unexpected domain-shifted instances in natural language processing is crucial in real-world applications. Previous works identify the out-of-distribution (OOD) instance by leveraging a single global feature embedding to represent the sentence, which cannot characterize subtle OOD patterns well. Another major challenge current OOD methods face is learning effective low-dimensional sentence representations to identify the hard OOD instances that are semantically similar to the in-distribution (ID) data. In this paper, we propose a new unsupervised OOD detection method, namely Semantic Role Labeling Guided Out-of-distribution Detection (SRLOOD), that separates, extracts, and learns the semantic role labeling (SRL) guided fine-grained local feature representations from different arguments of a sentence and the global feature representations of the full sentence using a margin-based contrastive loss. A novel self-supervised approach is also introduced to enhance such global-local feature learning by predicting the SRL extracted role. The resulting model achieves SOTA performance on four OOD benchmarks, indicating the effectiveness of our approach. The code is publicly accessible via \url{https://github.com/cytai/SRLOOD}.
<div id='section'>Paperid: <span id='pid'>251, <a href='https://arxiv.org/pdf/2305.16966.pdf' target='_blank'>https://arxiv.org/pdf/2305.16966.pdf</a></span>   <span><a href='https://github.com/MarcLafon/heatood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Marc Lafon, Elias Ramzi, ClÃ©ment Rambour, Nicolas Thome
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.16966">Hybrid Energy Based Model in the Feature Space for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical requirement for the deployment of deep neural networks. This paper introduces the HEAT model, a new post-hoc OOD detection method estimating the density of in-distribution (ID) samples using hybrid energy-based models (EBM) in the feature space of a pre-trained backbone. HEAT complements prior density estimators of the ID density, e.g. parametric models like the Gaussian Mixture Model (GMM), to provide an accurate yet robust density estimation. A second contribution is to leverage the EBM framework to provide a unified density estimation and to compose several energy terms. Extensive experiments demonstrate the significance of the two contributions. HEAT sets new state-of-the-art OOD detection results on the CIFAR-10 / CIFAR-100 benchmark as well as on the large-scale Imagenet benchmark. The code is available at: https://github.com/MarcLafon/heatood.
<div id='section'>Paperid: <span id='pid'>252, <a href='https://arxiv.org/pdf/2305.13119.pdf' target='_blank'>https://arxiv.org/pdf/2305.13119.pdf</a></span>   <span><a href='https://github.com/RyanLiut/WSD-UE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhu Liu, Ying Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.13119">Ambiguity Meets Uncertainty: Investigating Uncertainty Estimation for Word Sense Disambiguation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Word sense disambiguation (WSD), which aims to determine an appropriate sense for a target word given its context, is crucial for natural language understanding. Existing supervised methods treat WSD as a classification task and have achieved remarkable performance. However, they ignore uncertainty estimation (UE) in the real-world setting, where the data is always noisy and out of distribution. This paper extensively studies UE on the benchmark designed for WSD. Specifically, we first compare four uncertainty scores for a state-of-the-art WSD model and verify that the conventional predictive probabilities obtained at the end of the model are inadequate to quantify uncertainty. Then, we examine the capability of capturing data and model uncertainties by the model with the selected UE score on well-designed test scenarios and discover that the model reflects data uncertainty satisfactorily but underestimates model uncertainty. Furthermore, we explore numerous lexical properties that intrinsically affect data uncertainty and provide a detailed analysis of four critical aspects: the syntactic category, morphology, sense granularity, and semantic relations. The code is available at https://github.com/RyanLiut/WSD-UE.
<div id='section'>Paperid: <span id='pid'>253, <a href='https://arxiv.org/pdf/2305.05984.pdf' target='_blank'>https://arxiv.org/pdf/2305.05984.pdf</a></span>   <span><a href='https://github.com/DIAGNijmegen/prostateMR-USSL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Matin Hosseinzadeh, Anindo Saha, Joeran Bosma, Henkjan Huisman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.05984">Uncertainty-Aware Semi-Supervised Learning for Prostate MRI Zonal Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quality of deep convolutional neural network predictions strongly depends on the size of the training dataset and the quality of the annotations. Creating annotations, especially for 3D medical image segmentation, is time-consuming and requires expert knowledge. We propose a novel semi-supervised learning (SSL) approach that requires only a relatively small number of annotations while being able to use the remaining unlabeled data to improve model performance. Our method uses a pseudo-labeling technique that employs recent deep learning uncertainty estimation models. By using the estimated uncertainty, we were able to rank pseudo-labels and automatically select the best pseudo-annotations generated by the supervised model. We applied this to prostate zonal segmentation in T2-weighted MRI scans. Our proposed model outperformed the semi-supervised model in experiments with the ProstateX dataset and an external test set, by leveraging only a subset of unlabeled data rather than the full collection of 4953 cases, our proposed model demonstrated improved performance. The segmentation dice similarity coefficient in the transition zone and peripheral zone increased from 0.835 and 0.727 to 0.852 and 0.751, respectively, for fully supervised model and the uncertainty-aware semi-supervised learning model (USSL). Our USSL model demonstrates the potential to allow deep learning models to be trained on large datasets without requiring full annotation. Our code is available at https://github.com/DIAGNijmegen/prostateMR-USSL.
<div id='section'>Paperid: <span id='pid'>254, <a href='https://arxiv.org/pdf/2304.06707.pdf' target='_blank'>https://arxiv.org/pdf/2304.06707.pdf</a></span>   <span><a href='https://github.com/vita-epfl/UnPOSed' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saeed Saadatnejad, Mehrshad Mirmohammadi, Matin Daghyani, Parham Saremi, Yashar Zoroofchi Benisi, Amirhossein Alimohammadi, Zahra Tehraninasab, Taylor Mordan, Alexandre Alahi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06707">Toward Reliable Human Pose Forecasting with Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, there has been an arms race of pose forecasting methods aimed at solving the spatio-temporal task of predicting a sequence of future 3D poses of a person given a sequence of past observed ones. However, the lack of unified benchmarks and limited uncertainty analysis have hindered progress in the field. To address this, we first develop an open-source library for human pose forecasting, including multiple models, supporting several datasets, and employing standardized evaluation metrics, with the aim of promoting research and moving toward a unified and consistent evaluation. Second, we devise two types of uncertainty in the problem to increase performance and convey better trust: 1) we propose a method for modeling aleatoric uncertainty by using uncertainty priors to inject knowledge about the pattern of uncertainty. This focuses the capacity of the model in the direction of more meaningful supervision while reducing the number of learned parameters and improving stability; 2) we introduce a novel approach for quantifying the epistemic uncertainty of any model through clustering and measuring the entropy of its assignments. Our experiments demonstrate up to $25\%$ improvements in forecasting at short horizons, with no loss on longer horizons on Human3.6M, AMSS, and 3DPW datasets, and better performance in uncertainty estimation. The code is available online at https://github.com/vita-epfl/UnPOSed.
<div id='section'>Paperid: <span id='pid'>255, <a href='https://arxiv.org/pdf/2304.05341.pdf' target='_blank'>https://arxiv.org/pdf/2304.05341.pdf</a></span>   <span><a href='https://github.com/ur-whitelab/BO-ICL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mayk Caldas Ramos, Shane S. Michtavy, Marc D. Porosoff, Andrew D. White
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.05341">Bayesian Optimization of Catalysis With In-Context Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) can perform accurate classification with zero or few examples through in-context learning. We extend this capability to regression with uncertainty estimation using frozen LLMs (e.g., GPT-3.5, Gemini), enabling Bayesian optimization (BO) in natural language without explicit model training or feature engineering. We apply this to materials discovery by representing experimental catalyst synthesis and testing procedures as natural language prompts. A key challenge in materials discovery is the need to characterize suboptimal candidates, which slows progress. While BO is effective for navigating large design spaces, standard surrogate models like Gaussian processes assume smoothness and continuity, an assumption that fails in highly non-linear domains such as heterogeneous catalysis. Our task-agnostic BO workflow overcomes this by operating directly in language space, producing interpretable and actionable predictions without requiring structural or electronic descriptors. On benchmarks like aqueous solubility and oxidative coupling of methane (OCM), BO-ICL matches or outperforms Gaussian processes. In live experiments on the reverse water-gas shift (RWGS) reaction, BO-ICL identifies near-optimal multi-metallic catalysts within six iterations from a pool of 3,700 candidates. Our method redefines materials representation and accelerates discovery, with broad applications across catalysis, materials science, and AI. Code: https://github.com/ur-whitelab/BO-ICL.
<div id='section'>Paperid: <span id='pid'>256, <a href='https://arxiv.org/pdf/2304.04906.pdf' target='_blank'>https://arxiv.org/pdf/2304.04906.pdf</a></span>   <span><a href='https://github.com/MehediHasanTutul/Reject_option' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehedi Hasan, Moloud Abdar, Abbas Khosravi, Uwe Aickelin, Pietro Lio', Ibrahim Hossain, Ashikur Rahman, Saeid Nahavandi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04906">Survey on Leveraging Uncertainty Estimation Towards Trustworthy Deep Neural Networks: The Case of Reject Option and Post-training Processing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although neural networks (especially deep neural networks) have achieved \textit{better-than-human} performance in many fields, their real-world deployment is still questionable due to the lack of awareness about the limitation in their knowledge. To incorporate such awareness in the machine learning model, prediction with reject option (also known as selective classification or classification with abstention) has been proposed in literature. In this paper, we present a systematic review of the prediction with the reject option in the context of various neural networks. To the best of our knowledge, this is the first study focusing on this aspect of neural networks. Moreover, we discuss different novel loss functions related to the reject option and post-training processing (if any) of network output for generating suitable measurements for knowledge awareness of the model. Finally, we address the application of the rejection option in reducing the prediction time for the real-time problems and present a comprehensive summary of the techniques related to the reject option in the context of extensive variety of neural networks. Our code is available on GitHub: \url{https://github.com/MehediHasanTutul/Reject_option}
<div id='section'>Paperid: <span id='pid'>257, <a href='https://arxiv.org/pdf/2304.04521.pdf' target='_blank'>https://arxiv.org/pdf/2304.04521.pdf</a></span>   <span><a href='https://github.com/AtsuMiyai/GL-MCM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04521">GL-MCM: Global and Local Maximum Concept Matching for Zero-Shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Zero-shot out-of-distribution (OOD) detection is a task that detects OOD images during inference with only in-distribution (ID) class names. Existing methods assume ID images contain a single, centered object, and do not consider the more realistic multi-object scenarios, where both ID and OOD objects are present. To meet the needs of many users, the detection method must have the flexibility to adapt the type of ID images. To this end, we present Global-Local Maximum Concept Matching (GL-MCM), which incorporates local image scores as an auxiliary score to enhance the separability of global and local visual features. Due to the simple ensemble score function design, GL-MCM can control the type of ID images with a single weight parameter. Experiments on ImageNet and multi-object benchmarks demonstrate that GL-MCM outperforms baseline zero-shot methods and is comparable to fully supervised methods. Furthermore, GL-MCM offers strong flexibility in adjusting the target type of ID images. The code is available via https://github.com/AtsuMiyai/GL-MCM.
<div id='section'>Paperid: <span id='pid'>258, <a href='https://arxiv.org/pdf/2304.04042.pdf' target='_blank'>https://arxiv.org/pdf/2304.04042.pdf</a></span>   <span><a href='https://github.com/antoinedemathelin/DARE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Antoine de Mathelin, Francois Deheeger, Mathilde Mougeot, Nicolas Vayatis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04042">Deep Anti-Regularized Ensembles provide reliable out-of-distribution uncertainty quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of uncertainty quantification in high dimensional regression and classification for which deep ensemble have proven to be promising methods. Recent observations have shown that deep ensemble often return overconfident estimates outside the training domain, which is a major limitation because shifted distributions are often encountered in real-life scenarios. The principal challenge for this problem is to solve the trade-off between increasing the diversity of the ensemble outputs and making accurate in-distribution predictions. In this work, we show that an ensemble of networks with large weights fitting the training data are likely to meet these two objectives. We derive a simple and practical approach to produce such ensembles, based on an original anti-regularization term penalizing small weights and a control process of the weight increase which maintains the in-distribution loss under an acceptable threshold. The developed approach does not require any out-of-distribution training data neither any trade-off hyper-parameter calibration. We derive a theoretical framework for this approach and show that the proposed optimization can be seen as a "water-filling" problem. Several experiments in both regression and classification settings highlight that Deep Anti-Regularized Ensembles (DARE) significantly improve uncertainty quantification outside the training domain in comparison to recent deep ensembles and out-of-distribution detection methods. All the conducted experiments are reproducible and the source code is available at \url{https://github.com/antoinedemathelin/DARE}.
<div id='section'>Paperid: <span id='pid'>259, <a href='https://arxiv.org/pdf/2303.15140.pdf' target='_blank'>https://arxiv.org/pdf/2303.15140.pdf</a></span>   <span><a href='https://github.com/DonaldRR/SimpleNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhikang Liu, Yiming Zhou, Yuansheng Xu, Zilei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15140">SimpleNet: A Simple Network for Image Anomaly Detection and Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a simple and application-friendly network (called SimpleNet) for detecting and localizing anomalies. SimpleNet consists of four components: (1) a pre-trained Feature Extractor that generates local features, (2) a shallow Feature Adapter that transfers local features towards target domain, (3) a simple Anomaly Feature Generator that counterfeits anomaly features by adding Gaussian noise to normal features, and (4) a binary Anomaly Discriminator that distinguishes anomaly features from normal features. During inference, the Anomaly Feature Generator would be discarded. Our approach is based on three intuitions. First, transforming pre-trained features to target-oriented features helps avoid domain bias. Second, generating synthetic anomalies in feature space is more effective, as defects may not have much commonality in the image space. Third, a simple discriminator is much efficient and practical. In spite of simplicity, SimpleNet outperforms previous methods quantitatively and qualitatively. On the MVTec AD benchmark, SimpleNet achieves an anomaly detection AUROC of 99.6%, reducing the error by 55.5% compared to the next best performing model. Furthermore, SimpleNet is faster than existing methods, with a high frame rate of 77 FPS on a 3080ti GPU. Additionally, SimpleNet demonstrates significant improvements in performance on the One-Class Novelty Detection task. Code: https://github.com/DonaldRR/SimpleNet.
<div id='section'>Paperid: <span id='pid'>260, <a href='https://arxiv.org/pdf/2303.14531.pdf' target='_blank'>https://arxiv.org/pdf/2303.14531.pdf</a></span>   <span><a href='https://github.com/zjysteven/SIO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyang Zhang, Nathan Inkawhich, Randolph Linderman, Ryan Luley, Yiran Chen, Hai Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14531">SIO: Synthetic In-Distribution Data Benefits Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Building up reliable Out-of-Distribution (OOD) detectors is challenging, often requiring the use of OOD data during training. In this work, we develop a data-driven approach which is distinct and complementary to existing works: Instead of using external OOD data, we fully exploit the internal in-distribution (ID) training set by utilizing generative models to produce additional synthetic ID images. The classifier is then trained using a novel objective that computes weighted loss on real and synthetic ID samples together. Our training framework, which is termed SIO, serves as a "plug-and-play" technique that is designed to be compatible with existing and future OOD detection algorithms, including the ones that leverage available OOD training data. Our experiments on CIFAR-10, CIFAR-100, and ImageNet variants demonstrate that SIO consistently improves the performance of nearly all state-of-the-art (SOTA) OOD detection algorithms. For instance, on the challenging CIFAR-10 v.s. CIFAR-100 detection problem, SIO improves the average OOD detection AUROC of 18 existing methods from 86.25\% to 89.04\% and achieves a new SOTA of 92.94\% according to the OpenOOD benchmark. Code is available at https://github.com/zjysteven/SIO.
<div id='section'>Paperid: <span id='pid'>261, <a href='https://arxiv.org/pdf/2303.14096.pdf' target='_blank'>https://arxiv.org/pdf/2303.14096.pdf</a></span>   <span><a href='https://github.com/jh-jeong/nuisance_ib' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jongheon Jeong, Sihyun Yu, Hankook Lee, Jinwoo Shin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14096">Enhancing Multiple Reliability Measures via Nuisance-extended Information Bottleneck</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In practical scenarios where training data is limited, many predictive signals in the data can be rather from some biases in data acquisition (i.e., less generalizable), so that one cannot prevent a model from co-adapting on such (so-called) "shortcut" signals: this makes the model fragile in various distribution shifts. To bypass such failure modes, we consider an adversarial threat model under a mutual information constraint to cover a wider class of perturbations in training. This motivates us to extend the standard information bottleneck to additionally model the nuisance information. We propose an autoencoder-based training to implement the objective, as well as practical encoder designs to facilitate the proposed hybrid discriminative-generative training concerning both convolutional- and Transformer-based architectures. Our experimental results show that the proposed scheme improves robustness of learned representations (remarkably without using any domain-specific knowledge), with respect to multiple challenging reliability measures. For example, our model could advance the state-of-the-art on a recent challenging OBJECTS benchmark in novelty detection by $78.4\% \rightarrow 87.2\%$ in AUROC, while simultaneously enjoying improved corruption, background and (certified) adversarial robustness. Code is available at https://github.com/jh-jeong/nuisance_ib.
<div id='section'>Paperid: <span id='pid'>262, <a href='https://arxiv.org/pdf/2303.13408.pdf' target='_blank'>https://arxiv.org/pdf/2303.13408.pdf</a></span>   <span><a href='https://github.com/martiansideofthemoon/ai-detection-paraphrases' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, Mohit Iyyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.13408">Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rise in malicious usage of large language models, such as fake content creation and academic plagiarism, has motivated the development of approaches that identify AI-generated text, including those based on watermarking or outlier detection. However, the robustness of these detection algorithms to paraphrases of AI-generated text remains unclear. To stress test these detectors, we build a 11B parameter paraphrase generation model (DIPPER) that can paraphrase paragraphs, condition on surrounding context, and control lexical diversity and content reordering. Using DIPPER to paraphrase text generated by three large language models (including GPT3.5-davinci-003) successfully evades several detectors, including watermarking, GPTZero, DetectGPT, and OpenAI's text classifier. For example, DIPPER drops detection accuracy of DetectGPT from 70.3% to 4.6% (at a constant false positive rate of 1%), without appreciably modifying the input semantics.
  To increase the robustness of AI-generated text detection to paraphrase attacks, we introduce a simple defense that relies on retrieving semantically-similar generations and must be maintained by a language model API provider. Given a candidate text, our algorithm searches a database of sequences previously generated by the API, looking for sequences that match the candidate text within a certain threshold. We empirically verify our defense using a database of 15M generations from a fine-tuned T5-XXL model and find that it can detect 80% to 97% of paraphrased generations across different settings while only classifying 1% of human-written sequences as AI-generated. We open-source our models, code and data.
<div id='section'>Paperid: <span id='pid'>263, <a href='https://arxiv.org/pdf/2303.13148.pdf' target='_blank'>https://arxiv.org/pdf/2303.13148.pdf</a></span>   <span><a href='https://github.com/vojirt/GROOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomas Vojir, Jan Sochman, Rahaf Aljundi, Jiri Matas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.13148">Calibrated Out-of-Distribution Detection with a Generic Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution detection is a common issue in deploying vision models in practice and solving it is an essential building block in safety critical applications. Most of the existing OOD detection solutions focus on improving the OOD robustness of a classification model trained exclusively on in-distribution (ID) data. In this work, we take a different approach and propose to leverage generic pre-trained representation. We propose a novel OOD method, called GROOD, that formulates the OOD detection as a Neyman-Pearson task with well calibrated scores and which achieves excellent performance, predicated by the use of a good generic representation. Only a trivial training process is required for adapting GROOD to a particular problem. The method is simple, general, efficient, calibrated and with only a few hyper-parameters. The method achieves state-of-the-art performance on a number of OOD benchmarks, reaching near perfect performance on several of them. The source code is available at https://github.com/vojirt/GROOD.
<div id='section'>Paperid: <span id='pid'>264, <a href='https://arxiv.org/pdf/2303.11298.pdf' target='_blank'>https://arxiv.org/pdf/2303.11298.pdf</a></span>   <span><a href='https://github.com/naver/relis' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pau de Jorge, Riccardo Volpi, Philip Torr, Gregory Rogez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11298">Reliability in Semantic Segmentation: Are We on the Right Track?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motivated by the increasing popularity of transformers in computer vision, in recent times there has been a rapid development of novel architectures. While in-domain performance follows a constant, upward trend, properties like robustness or uncertainty estimation are less explored -leaving doubts about advances in model reliability. Studies along these axes exist, but they are mainly limited to classification models. In contrast, we carry out a study on semantic segmentation, a relevant task for many real-world applications where model reliability is paramount. We analyze a broad variety of models, spanning from older ResNet-based architectures to novel transformers and assess their reliability based on four metrics: robustness, calibration, misclassification detection and out-of-distribution (OOD) detection. We find that while recent models are significantly more robust, they are not overall more reliable in terms of uncertainty estimation. We further explore methods that can come to the rescue and show that improving calibration can also help with other uncertainty metrics such as misclassification or OOD detection. This is the first study on modern segmentation models focused on both robustness and uncertainty estimation and we hope it will help practitioners and researchers interested in this fundamental vision task. Code available at https://github.com/naver/relis.
<div id='section'>Paperid: <span id='pid'>265, <a href='https://arxiv.org/pdf/2303.08010.pdf' target='_blank'>https://arxiv.org/pdf/2303.08010.pdf</a></span>   <span><a href='https://github.com/Guoxoug/window-early-exit' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guoxuan Xia, Christos-Savvas Bouganis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08010">Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep Ensembles are More Efficient than Single Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Ensembles are a simple, reliable, and effective method of improving both the predictive performance and uncertainty estimates of deep learning approaches. However, they are widely criticised as being computationally expensive, due to the need to deploy multiple independent models. Recent work has challenged this view, showing that for predictive accuracy, ensembles can be more computationally efficient (at inference) than scaling single models within an architecture family. This is achieved by cascading ensemble members via an early-exit approach. In this work, we investigate extending these efficiency gains to tasks related to uncertainty estimation. As many such tasks, e.g. selective classification, are binary classification, our key novel insight is to only pass samples within a window close to the binary decision boundary to later cascade stages. Experiments on ImageNet-scale data across a number of network architectures and uncertainty tasks show that the proposed window-based early-exit approach is able to achieve a superior uncertainty-computation trade-off compared to scaling single models. For example, a cascaded EfficientNet-B2 ensemble is able to achieve similar coverage at 5% risk as a single EfficientNet-B4 with <30% the number of MACs. We also find that cascades/ensembles give more reliable improvements on OOD data vs scaling models up. Code for this work is available at: https://github.com/Guoxoug/window-early-exit.
<div id='section'>Paperid: <span id='pid'>266, <a href='https://arxiv.org/pdf/2303.07543.pdf' target='_blank'>https://arxiv.org/pdf/2303.07543.pdf</a></span>   <span><a href='https://github.com/ivalab/WDiscOOD.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiye Chen, Yunzhi Lin, Ruinian Xu, Patricio A. Vela
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07543">WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks are susceptible to generating overconfident yet erroneous predictions when presented with data beyond known concepts. This challenge underscores the importance of detecting out-of-distribution (OOD) samples in the open world. In this work, we propose a novel feature-space OOD detection score based on class-specific and class-agnostic information. Specifically, the approach utilizes Whitened Linear Discriminant Analysis to project features into two subspaces - the discriminative and residual subspaces - for which the in-distribution (ID) classes are maximally separated and closely clustered, respectively. The OOD score is then determined by combining the deviation from the input data to the ID pattern in both subspaces. The efficacy of our method, named WDiscOOD, is verified on the large-scale ImageNet-1k benchmark, with six OOD datasets that cover a variety of distribution shifts. WDiscOOD demonstrates superior performance on deep classifiers with diverse backbone architectures, including CNN and vision transformer. Furthermore, we also show that WDiscOOD more effectively detects novel concepts in representation spaces trained with contrastive objectives, including supervised contrastive loss and multi-modality contrastive loss.
<div id='section'>Paperid: <span id='pid'>267, <a href='https://arxiv.org/pdf/2303.01860.pdf' target='_blank'>https://arxiv.org/pdf/2303.01860.pdf</a></span>   <span><a href='https://github.com/giacomo97cnr/Rule-based-ODD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Giacomo De Bernardi, Sara Narteni, Enrico Cambiaso, Maurizio Mongelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01860">Rule-based Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution detection is one of the most critical issue in the deployment of machine learning. The data analyst must assure that data in operation should be compliant with the training phase as well as understand if the environment has changed in a way that autonomous decisions would not be safe anymore. The method of the paper is based on eXplainable Artificial Intelligence (XAI); it takes into account different metrics to identify any resemblance between in-distribution and out of, as seen by the XAI model. The approach is non-parametric and distributional assumption free. The validation over complex scenarios (predictive maintenance, vehicle platooning, covert channels in cybersecurity) corroborates both precision in detection and evaluation of training-operation conditions proximity. Results are available via open source and open data at the following link: https://github.com/giacomo97cnr/Rule-based-ODD.
<div id='section'>Paperid: <span id='pid'>268, <a href='https://arxiv.org/pdf/2302.11893.pdf' target='_blank'>https://arxiv.org/pdf/2302.11893.pdf</a></span>   <span><a href='https://github.com/mdabbah/COOD_benchmarking' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ido Galil, Mohammed Dabbah, Ran El-Yaniv
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11893">A framework for benchmarking class-out-of-distribution detection and its application to ImageNet</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When deployed for risk-sensitive tasks, deep neural networks must be able to detect instances with labels from outside the distribution for which they were trained. In this paper we present a novel framework to benchmark the ability of image classifiers to detect class-out-of-distribution instances (i.e., instances whose true labels do not appear in the training distribution) at various levels of detection difficulty. We apply this technique to ImageNet, and benchmark 525 pretrained, publicly available, ImageNet-1k classifiers. The code for generating a benchmark for any ImageNet-1k classifier, along with the benchmarks prepared for the above-mentioned 525 models is available at https://github.com/mdabbah/COOD_benchmarking.
  The usefulness of the proposed framework and its advantage over alternative existing benchmarks is demonstrated by analyzing the results obtained for these models, which reveals numerous novel observations including: (1) knowledge distillation consistently improves class-out-of-distribution (C-OOD) detection performance; (2) a subset of ViTs performs better C-OOD detection than any other model; (3) the language--vision CLIP model achieves good zero-shot detection performance, with its best instance outperforming 96% of all other models evaluated; (4) accuracy and in-distribution ranking are positively correlated to C-OOD detection; and (5) we compare various confidence functions for C-OOD detection. Our companion paper, also published in ICLR 2023 (What Can We Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers), examines the uncertainty estimation performance (ranking, calibration, and selective prediction performance) of these classifiers in an in-distribution setting.
<div id='section'>Paperid: <span id='pid'>269, <a href='https://arxiv.org/pdf/2302.10326.pdf' target='_blank'>https://arxiv.org/pdf/2302.10326.pdf</a></span>   <span><a href='https://github.com/zhenzhel/lift_map_detect' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenzhen Liu, Jin Peng Zhou, Yufan Wang, Kilian Q. Weinberger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10326">Unsupervised Out-of-Distribution Detection with Diffusion Inpainting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised out-of-distribution detection (OOD) seeks to identify out-of-domain data by learning only from unlabeled in-domain data. We present a novel approach for this task - Lift, Map, Detect (LMD) - that leverages recent advancement in diffusion models. Diffusion models are one type of generative models. At their core, they learn an iterative denoising process that gradually maps a noisy image closer to their training manifolds. LMD leverages this intuition for OOD detection. Specifically, LMD lifts an image off its original manifold by corrupting it, and maps it towards the in-domain manifold with a diffusion model. For an out-of-domain image, the mapped image would have a large distance away from its original manifold, and LMD would identify it as OOD accordingly. We show through extensive experiments that LMD achieves competitive performance across a broad variety of datasets. Code can be found at https://github.com/zhenzhel/lift_map_detect.
<div id='section'>Paperid: <span id='pid'>270, <a href='https://arxiv.org/pdf/2302.03679.pdf' target='_blank'>https://arxiv.org/pdf/2302.03679.pdf</a></span>   <span><a href='https://github.com/fregu856/regression_uncertainty' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/fregu856/regression_uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fredrik K. Gustafsson, Martin Danelljan, Thomas B. SchÃ¶n
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.03679">How Reliable is Your Regression Model's Uncertainty Under Real-World Distribution Shifts?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many important computer vision applications are naturally formulated as regression problems. Within medical imaging, accurate regression models have the potential to automate various tasks, helping to lower costs and improve patient outcomes. Such safety-critical deployment does however require reliable estimation of model uncertainty, also under the wide variety of distribution shifts that might be encountered in practice. Motivated by this, we set out to investigate the reliability of regression uncertainty estimation methods under various real-world distribution shifts. To that end, we propose an extensive benchmark of 8 image-based regression datasets with different types of challenging distribution shifts. We then employ our benchmark to evaluate many of the most common uncertainty estimation methods, as well as two state-of-the-art uncertainty scores from the task of out-of-distribution detection. We find that while methods are well calibrated when there is no distribution shift, they all become highly overconfident on many of the benchmark datasets. This uncovers important limitations of current uncertainty estimation methods, and the proposed benchmark therefore serves as a challenge to the research community. We hope that our benchmark will spur more work on how to develop truly reliable regression uncertainty estimation methods. Code is available at https://github.com/fregu856/regression_uncertainty.
<div id='section'>Paperid: <span id='pid'>271, <a href='https://arxiv.org/pdf/2302.02914.pdf' target='_blank'>https://arxiv.org/pdf/2302.02914.pdf</a></span>   <span><a href='https://github.com/qitianwu/GraphOOD-GNNSafe' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qitian Wu, Yiting Chen, Chenxiao Yang, Junchi Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02914">Energy-based Out-of-Distribution Detection for Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning on graphs, where instance nodes are inter-connected, has become one of the central problems for deep learning, as relational structures are pervasive and induce data inter-dependence which hinders trivial adaptation of existing approaches that assume inputs to be i.i.d.~sampled. However, current models mostly focus on improving testing performance of in-distribution data and largely ignore the potential risk w.r.t. out-of-distribution (OOD) testing samples that may cause negative outcome if the prediction is overconfident on them. In this paper, we investigate the under-explored problem, OOD detection on graph-structured data, and identify a provably effective OOD discriminator based on an energy function directly extracted from graph neural networks trained with standard classification loss. This paves a way for a simple, powerful and efficient OOD detection model for GNN-based learning on graphs, which we call GNNSafe. It also has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for in-distribution and OOD samples, which, more critically, can be further strengthened by a learning-free energy belief propagation scheme. For comprehensive evaluation, we introduce new benchmark settings that evaluate the model for detecting OOD data from both synthetic and real distribution shifts (cross-domain graph shifts and temporal graph shifts). The results show that GNNSafe achieves up to $17.0\%$ AUROC improvement over state-of-the-arts and it could serve as simple yet strong baselines in such an under-developed area.
<div id='section'>Paperid: <span id='pid'>272, <a href='https://arxiv.org/pdf/2301.12715.pdf' target='_blank'>https://arxiv.org/pdf/2301.12715.pdf</a></span>   <span><a href='https://github.com/lancopku/GNOME' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sishuo Chen, Wenkai Yang, Xiaohan Bi, Xu Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12715">Fine-Tuning Deteriorates General Textual Out-of-Distribution Detection by Distorting Task-Agnostic Features</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) inputs is crucial for the safe deployment of natural language processing (NLP) models. Though existing methods, especially those based on the statistics in the feature space of fine-tuned pre-trained language models (PLMs), are claimed to be effective, their effectiveness on different types of distribution shifts remains underexplored. In this work, we take the first step to comprehensively evaluate the mainstream textual OOD detection methods for detecting semantic and non-semantic shifts. We find that: (1) no existing method behaves well in both settings; (2) fine-tuning PLMs on in-distribution data benefits detecting semantic shifts but severely deteriorates detecting non-semantic shifts, which can be attributed to the distortion of task-agnostic features. To alleviate the issue, we present a simple yet effective general OOD score named GNOME that integrates the confidence scores derived from the task-agnostic and task-specific representations. Experiments show that GNOME works well in both semantic and non-semantic shift scenarios, and further brings significant improvement on two cross-task benchmarks where both kinds of shifts simultaneously take place. Our code is available at https://github.com/lancopku/GNOME.
<div id='section'>Paperid: <span id='pid'>273, <a href='https://arxiv.org/pdf/2301.05500.pdf' target='_blank'>https://arxiv.org/pdf/2301.05500.pdf</a></span>   <span><a href='https://github.com/hsiangyuzhao/RCPS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangyu Zhao, Zengxin Qi, Sheng Wang, Qian Wang, Xuehai Wu, Ying Mao, Lichi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.05500">RCPS: Rectified Contrastive Pseudo Supervision for Semi-Supervised Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical image segmentation methods are generally designed as fully-supervised to guarantee model performance, which require a significant amount of expert annotated samples that are high-cost and laborious. Semi-supervised image segmentation can alleviate the problem by utilizing a large number of unlabeled images along with limited labeled images. However, learning a robust representation from numerous unlabeled images remains challenging due to potential noise in pseudo labels and insufficient class separability in feature space, which undermines the performance of current semi-supervised segmentation approaches. To address the issues above, we propose a novel semi-supervised segmentation method named as Rectified Contrastive Pseudo Supervision (RCPS), which combines a rectified pseudo supervision and voxel-level contrastive learning to improve the effectiveness of semi-supervised segmentation. Particularly, we design a novel rectification strategy for the pseudo supervision method based on uncertainty estimation and consistency regularization to reduce the noise influence in pseudo labels. Furthermore, we introduce a bidirectional voxel contrastive loss to the network to ensure intra-class consistency and inter-class contrast in feature space, which increases class separability in the segmentation. The proposed RCPS segmentation method has been validated on two public datasets and an in-house clinical dataset. Experimental results reveal that the proposed method yields better segmentation performance compared with the state-of-the-art methods in semi-supervised medical image segmentation. The source code is available at https://github.com/hsiangyuzhao/RCPS.
<div id='section'>Paperid: <span id='pid'>274, <a href='https://arxiv.org/pdf/2212.10806.pdf' target='_blank'>https://arxiv.org/pdf/2212.10806.pdf</a></span>   <span><a href='https://github.com/KU-CVLAB/MaskingDepth' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jongbeom Baek, Gyeongnyeon Kim, Seonghoon Park, Honggyu An, Matteo Poggi, Seungryong Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.10806">MaskingDepth: Masked Consistency Regularization for Semi-supervised Monocular Depth Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose MaskingDepth, a novel semi-supervised learning framework for monocular depth estimation to mitigate the reliance on large ground-truth depth quantities. MaskingDepth is designed to enforce consistency between the strongly-augmented unlabeled data and the pseudo-labels derived from weakly-augmented unlabeled data, which enables learning depth without supervision. In this framework, a novel data augmentation is proposed to take the advantage of a naive masking strategy as an augmentation, while avoiding its scale ambiguity problem between depths from weakly- and strongly-augmented branches and risk of missing small-scale instances. To only retain high-confident depth predictions from the weakly-augmented branch as pseudo-labels, we also present an uncertainty estimation technique, which is used to define robust consistency regularization. Experiments on KITTI and NYU-Depth-v2 datasets demonstrate the effectiveness of each component, its robustness to the use of fewer depth-annotated images, and superior performance compared to other state-of-the-art semi-supervised methods for monocular depth estimation. Furthermore, we show our method can be easily extended to domain adaptation task. Our code is available at https://github.com/KU-CVLAB/MaskingDepth.
<div id='section'>Paperid: <span id='pid'>275, <a href='https://arxiv.org/pdf/2212.09409.pdf' target='_blank'>https://arxiv.org/pdf/2212.09409.pdf</a></span>   <span><a href='https://github.com/copenlu/aggregating-crowd-annotations-ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dustin Wright, Isabelle Augenstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.09409">Aggregating Soft Labels from Crowd Annotations Improves Uncertainty Estimation Under Distribution Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Selecting an effective training signal for machine learning tasks is difficult: expert annotations are expensive, and crowd-sourced annotations may not be reliable. Recent work has demonstrated that learning from a distribution over labels acquired from crowd annotations can be effective both for performance and uncertainty estimation. However, this has mainly been studied using a limited set of soft-labeling methods in an in-domain setting. Additionally, no one method has been shown to consistently perform well across tasks, making it difficult to know a priori which to choose. To fill these gaps, this paper provides the first large-scale empirical study on learning from crowd labels in the out-of-domain setting, systematically analyzing 8 soft-labeling methods on 4 language and vision tasks. Additionally, we propose to aggregate soft-labels via a simple average in order to achieve consistent performance across tasks. We demonstrate that this yields classifiers with improved predictive uncertainty estimation in most settings while maintaining consistent raw performance compared to learning from individual soft-labeling methods or taking a majority vote of the annotations. We additionally highlight that in regimes with abundant or minimal training data, the selection of soft labeling method is less important, while for highly subjective labels and moderate amounts of training data, aggregation yields significant improvements in uncertainty estimation over individual methods. Code can be found at https://github.com/copenlu/aggregating-crowd-annotations-ood.
<div id='section'>Paperid: <span id='pid'>276, <a href='https://arxiv.org/pdf/2212.02295.pdf' target='_blank'>https://arxiv.org/pdf/2212.02295.pdf</a></span>   <span><a href='https://github.com/gist-ailab/block-selection-for-OOD-detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeonguk Yu, Sungho Shin, Seongju Lee, Changhyun Jun, Kyoobin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.02295">Block Selection Method for Using Feature Norm in Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) inputs during the inference stage is crucial for deploying neural networks in the real world. Previous methods commonly relied on the output of a network derived from the highly activated feature map. In this study, we first revealed that a norm of the feature map obtained from the other block than the last block can be a better indicator of OOD detection. Motivated by this, we propose a simple framework consisting of FeatureNorm: a norm of the feature map and NormRatio: a ratio of FeatureNorm for ID and OOD to measure the OOD detection performance of each block. In particular, to select the block that provides the largest difference between FeatureNorm of ID and FeatureNorm of OOD, we create Jigsaw puzzle images as pseudo OOD from ID training samples and calculate NormRatio, and the block with the largest value is selected. After the suitable block is selected, OOD detection with the FeatureNorm outperforms other OOD detection methods by reducing FPR95 by up to 52.77% on CIFAR10 benchmark and by up to 48.53% on ImageNet benchmark. We demonstrate that our framework can generalize to various architectures and the importance of block selection, which can improve previous OOD detection methods as well.
<div id='section'>Paperid: <span id='pid'>277, <a href='https://arxiv.org/pdf/2211.14512.pdf' target='_blank'>https://arxiv.org/pdf/2211.14512.pdf</a></span>   <span><a href='https://github.com/yyliu01/RPL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuyuan Liu, Choubo Ding, Yu Tian, Guansong Pang, Vasileios Belagiannis, Ian Reid, Gustavo Carneiro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.14512">Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection in Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic segmentation models classify pixels into a set of known (``in-distribution'') visual classes. When deployed in an open world, the reliability of these models depends on their ability not only to classify in-distribution pixels but also to detect out-of-distribution (OoD) pixels. Historically, the poor OoD detection performance of these models has motivated the design of methods based on model re-training using synthetic training images that include OoD visual objects. Although successful, these re-trained methods have two issues: 1) their in-distribution segmentation accuracy may drop during re-training, and 2) their OoD detection accuracy does not generalise well to new contexts (e.g., country surroundings) outside the training set (e.g., city surroundings). In this paper, we mitigate these issues with: (i) a new residual pattern learning (RPL) module that assists the segmentation model to detect OoD pixels without affecting the inlier segmentation performance; and (ii) a novel context-robust contrastive learning (CoroCL) that enforces RPL to robustly detect OoD pixels among various contexts. Our approach improves by around 10\% FPR and 7\% AuPRC the previous state-of-the-art in Fishyscapes, Segment-Me-If-You-Can, and RoadAnomaly datasets. Our code is available at: https://github.com/yyliu01/RPL.
<div id='section'>Paperid: <span id='pid'>278, <a href='https://arxiv.org/pdf/2211.11838.pdf' target='_blank'>https://arxiv.org/pdf/2211.11838.pdf</a></span>   <span><a href='https://github.com/3mcloud/adafocal' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Arindam Ghosh, Thomas Schaaf, Matthew R. Gormley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.11838">AdaFocal: Calibration-aware Adaptive Focal Loss</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Much recent work has been devoted to the problem of ensuring that a neural network's confidence scores match the true probability of being correct, i.e. the calibration problem. Of note, it was found that training with focal loss leads to better calibration than cross-entropy while achieving similar level of accuracy \cite{mukhoti2020}. This success stems from focal loss regularizing the entropy of the model's prediction (controlled by the parameter $Î³$), thereby reining in the model's overconfidence. Further improvement is expected if $Î³$ is selected independently for each training sample (Sample-Dependent Focal Loss (FLSD-53) \cite{mukhoti2020}). However, FLSD-53 is based on heuristics and does not generalize well. In this paper, we propose a calibration-aware adaptive focal loss called AdaFocal that utilizes the calibration properties of focal (and inverse-focal) loss and adaptively modifies $Î³_t$ for different groups of samples based on $Î³_{t-1}$ from the previous step and the knowledge of model's under/over-confidence on the validation set. We evaluate AdaFocal on various image recognition and one NLP task, covering a wide variety of network architectures, to confirm the improvement in calibration while achieving similar levels of accuracy. Additionally, we show that models trained with AdaFocal achieve a significant boost in out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>279, <a href='https://arxiv.org/pdf/2211.11300.pdf' target='_blank'>https://arxiv.org/pdf/2211.11300.pdf</a></span>   <span><a href='https://github.com/microsoft/KC/tree/main/papers/MLKD_OOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qianhui Wu, Huiqiang Jiang, Haonan Yin, BÃ¶rje F. Karlsson, Chin-Yew Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.11300">Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised representation learning has proved to be a valuable component for out-of-distribution (OoD) detection with only the texts of in-distribution (ID) examples. These approaches either train a language model from scratch or fine-tune a pre-trained language model using ID examples, and then take the perplexity output by the language model as OoD scores. In this paper, we analyze the complementary characteristics of both OoD detection methods and propose a multi-level knowledge distillation approach that integrates their strengths while mitigating their limitations. Specifically, we use a fine-tuned model as the teacher to teach a randomly initialized student model on the ID examples. Besides the prediction layer distillation, we present a similarity-based intermediate layer distillation method to thoroughly explore the representation space of the teacher model. In this way, the learned student can better represent the ID data manifold while gaining a stronger ability to map OoD examples outside the ID data manifold with the regularization inherited from pre-training. Besides, the student model sees only ID examples during parameter learning, further promoting more distinguishable features for OoD detection. We conduct extensive experiments over multiple benchmark datasets, i.e., CLINC150, SST, ROSTD, 20 NewsGroups, and AG News; showing that the proposed method yields new state-of-the-art performance. We also explore its application as an AIGC detector to distinguish between answers generated by ChatGPT and human experts. It is observed that our model exceeds human evaluators in the pair-expert task on the Human ChatGPT Comparison Corpus.
<div id='section'>Paperid: <span id='pid'>280, <a href='https://arxiv.org/pdf/2211.11255.pdf' target='_blank'>https://arxiv.org/pdf/2211.11255.pdf</a></span>   <span><a href='https://github.com/luping-liu/DiffOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Luping Liu, Yi Ren, Xize Cheng, Rongjie Huang, Chongxuan Li, Zhou Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.11255">Diffusion Denoising Process for Perceptron Bias in Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a crucial task for ensuring the reliability and safety of deep learning. Currently, discriminator models outperform other methods in this regard. However, the feature extraction process used by discriminator models suffers from the loss of critical information, leaving room for bad cases and malicious attacks. In this paper, we introduce a new perceptron bias assumption that suggests discriminator models are more sensitive to certain features of the input, leading to the overconfidence problem. To address this issue, we propose a novel framework that combines discriminator and generation models and integrates diffusion models (DMs) into OOD detection. We demonstrate that the diffusion denoising process (DDP) of DMs serves as a novel form of asymmetric interpolation, which is well-suited to enhance the input and mitigate the overconfidence problem. The discriminator model features of OOD data exhibit sharp changes under DDP, and we utilize the norm of this change as the indicator score. Our experiments on CIFAR10, CIFAR100, and ImageNet show that our method outperforms SOTA approaches. Notably, for the challenging InD ImageNet and OOD species datasets, our method achieves an AUROC of 85.7, surpassing the previous SOTA method's score of 77.4. Our implementation is available at \url{https://github.com/luping-liu/DiffOOD}.
<div id='section'>Paperid: <span id='pid'>281, <a href='https://arxiv.org/pdf/2211.08115.pdf' target='_blank'>https://arxiv.org/pdf/2211.08115.pdf</a></span>   <span><a href='https://github.com/jhornauer/heatmap_ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Julia Hornauer, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.08115">Heatmap-based Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Our work investigates out-of-distribution (OOD) detection as a neural network output explanation problem. We learn a heatmap representation for detecting OOD images while visualizing in- and out-of-distribution image regions at the same time. Given a trained and fixed classifier, we train a decoder neural network to produce heatmaps with zero response for in-distribution samples and high response heatmaps for OOD samples, based on the classifier features and the class prediction. Our main innovation lies in the heatmap definition for an OOD sample, as the normalized difference from the closest in-distribution sample. The heatmap serves as a margin to distinguish between in- and out-of-distribution samples. Our approach generates the heatmaps not only for OOD detection, but also to indicate in- and out-of-distribution regions of the input image. In our evaluations, our approach mostly outperforms the prior work on fixed classifiers, trained on CIFAR-10, CIFAR-100 and Tiny ImageNet. The code is publicly available at: https://github.com/jhornauer/heatmap_ood.
<div id='section'>Paperid: <span id='pid'>282, <a href='https://arxiv.org/pdf/2211.07740.pdf' target='_blank'>https://arxiv.org/pdf/2211.07740.pdf</a></span>   <span><a href='https://github.com/marksgraham/ddpm-ood' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mark S. Graham, Walter H. L. Pinaya, Petru-Daniel Tudosiu, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardoso
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.07740">Denoising diffusion models for out-of-distribution detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution detection is crucial to the safe deployment of machine learning systems. Currently, unsupervised out-of-distribution detection is dominated by generative-based approaches that make use of estimates of the likelihood or other measurements from a generative model. Reconstruction-based methods offer an alternative approach, in which a measure of reconstruction error is used to determine if a sample is out-of-distribution. However, reconstruction-based approaches are less favoured, as they require careful tuning of the model's information bottleneck - such as the size of the latent dimension - to produce good results. In this work, we exploit the view of denoising diffusion probabilistic models (DDPM) as denoising autoencoders where the bottleneck is controlled externally, by means of the amount of noise applied. We propose to use DDPMs to reconstruct an input that has been noised to a range of noise levels, and use the resulting multi-dimensional reconstruction error to classify out-of-distribution inputs. We validate our approach both on standard computer-vision datasets and on higher dimension medical datasets. Our approach outperforms not only reconstruction-based methods, but also state-of-the-art generative-based approaches. Code is available at https://github.com/marksgraham/ddpm-ood.
<div id='section'>Paperid: <span id='pid'>283, <a href='https://arxiv.org/pdf/2211.06660.pdf' target='_blank'>https://arxiv.org/pdf/2211.06660.pdf</a></span>   <span><a href='https://github.com/silviogalesso/dense-ood-knns' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Silvio Galesso, Max Argus, Thomas Brox
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.06660">Far Away in the Deep Space: Dense Nearest-Neighbor-Based Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The key to out-of-distribution detection is density estimation of the in-distribution data or of its feature representations. This is particularly challenging for dense anomaly detection in domains where the in-distribution data has a complex underlying structure. Nearest-Neighbors approaches have been shown to work well in object-centric data domains, such as industrial inspection and image classification. In this paper, we show that nearest-neighbor approaches also yield state-of-the-art results on dense novelty detection in complex driving scenes when working with an appropriate feature representation. In particular, we find that transformer-based architectures produce representations that yield much better similarity metrics for the task. We identify the multi-head structure of these models as one of the reasons, and demonstrate a way to transfer some of the improvements to CNNs. Ultimately, the approach is simple and non-invasive, i.e., it does not affect the primary segmentation performance, refrains from training on examples of anomalies, and achieves state-of-the-art results on RoadAnomaly, StreetHazards, and SegmentMeIfYouCan-Anomaly.
<div id='section'>Paperid: <span id='pid'>284, <a href='https://arxiv.org/pdf/2211.04825.pdf' target='_blank'>https://arxiv.org/pdf/2211.04825.pdf</a></span>   <span><a href='https://github.com/NataliiaMolch/MS_WML_uncs' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nataliia Molchanova, Vatsal Raina, Andrey Malinin, Francesco La Rosa, Henning Muller, Mark Gales, Cristina Granziera, Mara Graziani, Meritxell Bach Cuadra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.04825">Novel structural-scale uncertainty measures and error retention curves: application to multiple sclerosis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper focuses on the uncertainty estimation for white matter lesions (WML) segmentation in magnetic resonance imaging (MRI). On one side, voxel-scale segmentation errors cause the erroneous delineation of the lesions; on the other side, lesion-scale detection errors lead to wrong lesion counts. Both of these factors are clinically relevant for the assessment of multiple sclerosis patients. This work aims to compare the ability of different voxel- and lesion-scale uncertainty measures to capture errors related to segmentation and lesion detection, respectively. Our main contributions are (i) proposing new measures of lesion-scale uncertainty that do not utilise voxel-scale uncertainties; (ii) extending an error retention curves analysis framework for evaluation of lesion-scale uncertainty measures. Our results obtained on the multi-center testing set of 58 patients demonstrate that the proposed lesion-scale measure achieves the best performance among the analysed measures. All code implementations are provided at https://github.com/NataliiaMolch/MS_WML_uncs
<div id='section'>Paperid: <span id='pid'>285, <a href='https://arxiv.org/pdf/2210.15283.pdf' target='_blank'>https://arxiv.org/pdf/2210.15283.pdf</a></span>   <span><a href='https://github.com/Zaharah/ood_audio' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zaharah Bukhsh, Aaqib Saeed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.15283">On Out-of-Distribution Detection for Audio with Deep Nearest Neighbors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is concerned with identifying data points that do not belong to the same distribution as the model's training data. For the safe deployment of predictive models in a real-world environment, it is critical to avoid making confident predictions on OOD inputs as it can lead to potentially dangerous consequences. However, OOD detection largely remains an under-explored area in the audio (and speech) domain. This is despite the fact that audio is a central modality for many tasks, such as speaker diarization, automatic speech recognition, and sound event detection. To address this, we propose to leverage feature-space of the model with deep k-nearest neighbors to detect OOD samples. We show that this simple and flexible method effectively detects OOD inputs across a broad category of audio (and speech) datasets. Specifically, it improves the false positive rate (FPR@TPR95) by 17% and the AUROC score by 7% than other prior techniques.
<div id='section'>Paperid: <span id='pid'>286, <a href='https://arxiv.org/pdf/2210.14891.pdf' target='_blank'>https://arxiv.org/pdf/2210.14891.pdf</a></span>   <span><a href='https://github.com/ethancaballero/broken_neural_scaling_laws' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ethan Caballero, Kshitij Gupta, Irina Rish, David Krueger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.14891">Broken Neural Scaling Laws</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a smoothly broken power law functional form (that we refer to as a Broken Neural Scaling Law (BNSL)) that accurately models & extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as amount of compute used for training (or inference), number of model parameters, training dataset size, model input size, number of training steps, or upstream performance varies) for various architectures & for each of various tasks within a large & diverse set of upstream & downstream tasks, in zero-shot, prompted, & finetuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, AI capabilities, robotics, out-of-distribution (OOD) generalization, continual learning, transfer learning, uncertainty estimation / calibration, OOD detection, adversarial robustness, distillation, sparsity, retrieval, quantization, pruning, fairness, molecules, computer programming/coding, math word problems, "emergent phase transitions", arithmetic, supervised learning, unsupervised/self-supervised learning, & reinforcement learning (single agent & multi-agent). When compared to other functional forms for neural scaling, this functional form yields extrapolations of scaling behavior that are considerably more accurate on this set. Moreover, this functional form accurately models & extrapolates scaling behavior that other functional forms are incapable of expressing such as the nonmonotonic transitions present in the scaling behavior of phenomena such as double descent & the delayed, sharp inflection points present in the scaling behavior of tasks such as arithmetic. Lastly, we use this functional form to glean insights about the limit of the predictability of scaling behavior. Code is available at https://github.com/ethancaballero/broken_neural_scaling_laws
<div id='section'>Paperid: <span id='pid'>287, <a href='https://arxiv.org/pdf/2210.13458.pdf' target='_blank'>https://arxiv.org/pdf/2210.13458.pdf</a></span>   <span><a href='https://github.com/wang22ti/OpenAUC' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zitai Wang, Qianqian Xu, Zhiyong Yang, Yuan He, Xiaochun Cao, Qingming Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.13458">OpenAUC: Towards AUC-Oriented Open-Set Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional machine learning follows a close-set assumption that the training and test set share the same label space. While in many practical scenarios, it is inevitable that some test samples belong to unknown classes (open-set). To fix this issue, Open-Set Recognition (OSR), whose goal is to make correct predictions on both close-set samples and open-set samples, has attracted rising attention. In this direction, the vast majority of literature focuses on the pattern of open-set samples. However, how to evaluate model performance in this challenging task is still unsolved. In this paper, a systematic analysis reveals that most existing metrics are essentially inconsistent with the aforementioned goal of OSR: (1) For metrics extended from close-set classification, such as Open-set F-score, Youden's index, and Normalized Accuracy, a poor open-set prediction can escape from a low performance score with a superior close-set prediction. (2) Novelty detection AUC, which measures the ranking performance between close-set and open-set samples, ignores the close-set performance. To fix these issues, we propose a novel metric named OpenAUC. Compared with existing metrics, OpenAUC enjoys a concise pairwise formulation that evaluates open-set performance and close-set performance in a coupling manner. Further analysis shows that OpenAUC is free from the aforementioned inconsistency properties. Finally, an end-to-end learning method is proposed to minimize the OpenAUC risk, and the experimental results on popular benchmark datasets speak to its effectiveness. Project Page: https://github.com/wang22ti/OpenAUC.
<div id='section'>Paperid: <span id='pid'>288, <a href='https://arxiv.org/pdf/2210.09846.pdf' target='_blank'>https://arxiv.org/pdf/2210.09846.pdf</a></span>   <span><a href='https://github.com/Aryan-Garg/PECNet-Pedestrian-Trajectory-Prediction.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Aryan Garg, Renu M. Rameshan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.09846">G-PECNet: Towards a Generalizable Pedestrian Trajectory Prediction System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Navigating dynamic physical environments without obstructing or damaging human assets is of quintessential importance for social robots. In this work, we solve autonomous drone navigation's sub-problem of predicting out-of-domain human and agent trajectories using a deep generative model. Our method: General-PECNet or G-PECNet observes an improvement of 9.5\% on the Final Displacement Error (FDE) on 2020's benchmark: PECNet through a combination of architectural improvements inspired by periodic activation functions and synthetic trajectory (data) augmentations using Hidden Markov Models (HMMs) and Reinforcement Learning (RL). Additionally, we propose a simple geometry-inspired metric for trajectory non-linearity and outlier detection, helpful for the task. Code available at https://github.com/Aryan-Garg/PECNet-Pedestrian-Trajectory-Prediction.git
<div id='section'>Paperid: <span id='pid'>289, <a href='https://arxiv.org/pdf/2210.09184.pdf' target='_blank'>https://arxiv.org/pdf/2210.09184.pdf</a></span>   <span><a href='https://github.com/ENSTA-U2IS/torch-uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Olivier Laurent, Adrien Lafage, Enzo Tartaglione, Geoffrey Daniel, Jean-Marc Martinez, Andrei Bursuc, Gianni Franchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.09184">Packed-Ensembles for Efficient Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our code available at https://github.com/ENSTA-U2IS/torch-uncertainty.
<div id='section'>Paperid: <span id='pid'>290, <a href='https://arxiv.org/pdf/2210.01361.pdf' target='_blank'>https://arxiv.org/pdf/2210.01361.pdf</a></span>   <span><a href='https://github.com/csiro-robotics/Uncertainty-LPR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Keita Mason, Joshua Knights, Milad Ramezani, Peyman Moghadam, Dimity Miller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.01361">Uncertainty-Aware Lidar Place Recognition in Novel Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State-of-the-art lidar place recognition models exhibit unreliable performance when tested on environments different from their training dataset, which limits their use in complex and evolving environments. To address this issue, we investigate the task of uncertainty-aware lidar place recognition, where each predicted place must have an associated uncertainty that can be used to identify and reject incorrect predictions. We introduce a novel evaluation protocol and present the first comprehensive benchmark for this task, testing across five uncertainty estimation techniques and three large-scale datasets. Our results show that an Ensembles approach is the highest performing technique, consistently improving the performance of lidar place recognition and uncertainty estimation in novel environments, though it incurs a computational cost. Code is publicly available at https://github.com/csiro-robotics/Uncertainty-LPR.
<div id='section'>Paperid: <span id='pid'>291, <a href='https://arxiv.org/pdf/2209.08928.pdf' target='_blank'>https://arxiv.org/pdf/2209.08928.pdf</a></span>   <span><a href='https://github.com/TencentAILabHealthcare/UMIX' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongbo Han, Zhipeng Liang, Fan Yang, Liu Liu, Lanqing Li, Yatao Bian, Peilin Zhao, Bingzhe Wu, Changqing Zhang, Jianhua Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.08928">UMIX: Improving Importance Weighting for Subpopulation Shift via Uncertainty-Aware Mixup</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Subpopulation shift widely exists in many real-world machine learning applications, referring to the training and test distributions containing the same subpopulation groups but varying in subpopulation frequencies. Importance reweighting is a normal way to handle the subpopulation shift issue by imposing constant or adaptive sampling weights on each sample in the training dataset. However, some recent studies have recognized that most of these approaches fail to improve the performance over empirical risk minimization especially when applied to over-parameterized neural networks. In this work, we propose a simple yet practical framework, called uncertainty-aware mixup (UMIX), to mitigate the overfitting issue in over-parameterized models by reweighting the ''mixed'' samples according to the sample uncertainty. The training-trajectories-based uncertainty estimation is equipped in the proposed UMIX for each sample to flexibly characterize the subpopulation distribution. We also provide insightful theoretical analysis to verify that UMIX achieves better generalization bounds over prior works. Further, we conduct extensive empirical studies across a wide range of tasks to validate the effectiveness of our method both qualitatively and quantitatively. Code is available at https://github.com/TencentAILabHealthcare/UMIX.
<div id='section'>Paperid: <span id='pid'>292, <a href='https://arxiv.org/pdf/2209.07959.pdf' target='_blank'>https://arxiv.org/pdf/2209.07959.pdf</a></span>   <span><a href='https://github.com/sndnyang/SADAJEM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiulong Yang, Qing Su, Shihao Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.07959">Towards Bridging the Performance Gaps of Joint Energy-based Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Can we train a hybrid discriminative-generative model within a single network? This question has recently been answered in the affirmative, introducing the field of Joint Energy-based Model (JEM), which achieves high classification accuracy and image generation quality simultaneously. Despite recent advances, there remain two performance gaps: the accuracy gap to the standard softmax classifier, and the generation quality gap to state-of-the-art generative models. In this paper, we introduce a variety of training techniques to bridge the accuracy gap and the generation quality gap of JEM. 1) We incorporate a recently proposed sharpness-aware minimization (SAM) framework to train JEM, which promotes the energy landscape smoothness and the generalizability of JEM. 2) We exclude data augmentation from the maximum likelihood estimate pipeline of JEM, and mitigate the negative impact of data augmentation to image generation quality. Extensive experiments on multiple datasets demonstrate that our SADA-JEM achieves state-of-the-art performances and outperforms JEM in image classification, image generation, calibration, out-of-distribution detection and adversarial robustness by a notable margin. Our code is available at https://github.com/sndnyang/SADAJEM.
<div id='section'>Paperid: <span id='pid'>293, <a href='https://arxiv.org/pdf/2209.06995.pdf' target='_blank'>https://arxiv.org/pdf/2209.06995.pdf</a></span>   <span><a href='https://github.com/yueyu1030/Patron' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/yueyu1030/Patron' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Yu, Rongzhi Zhang, Ran Xu, Jieyu Zhang, Jiaming Shen, Chao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.06995">Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models have demonstrated remarkable few-shot performance, but the performance can be sensitive to the selection of few-shot instances. We propose PATRON, a new method that uses prompt-based uncertainty estimation for data selection for pre-trained language model fine-tuning under cold-start scenarios, i.e., no initial labeled data are available. In PATRON, we design (1) a prompt-based uncertainty propagation approach to estimate the importance of data points and (2) a partition-then-rewrite (PTR) strategy to promote sample diversity when querying for annotations. Experiments on six text classification datasets show that PATRON outperforms the strongest cold-start data selection baselines by up to 6.9%. Besides, with 128 labels only, PATRON achieves 91.0% and 92.1% of the fully supervised performance based on vanilla fine-tuning and prompt-based learning respectively. Our implementation of PATRON is available at \url{https://github.com/yueyu1030/Patron}.
<div id='section'>Paperid: <span id='pid'>294, <a href='https://arxiv.org/pdf/2208.02005.pdf' target='_blank'>https://arxiv.org/pdf/2208.02005.pdf</a></span>   <span><a href='https://github.com/jhornauer/GrUMoDepth' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Julia Hornauer, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.02005">Gradient-based Uncertainty for Monocular Depth Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In monocular depth estimation, disturbances in the image context, like moving objects or reflecting materials, can easily lead to erroneous predictions. For that reason, uncertainty estimates for each pixel are necessary, in particular for safety-critical applications such as automated driving. We propose a post hoc uncertainty estimation approach for an already trained and thus fixed depth estimation model, represented by a deep neural network. The uncertainty is estimated with the gradients which are extracted with an auxiliary loss function. To avoid relying on ground-truth information for the loss definition, we present an auxiliary loss function based on the correspondence of the depth prediction for an image and its horizontally flipped counterpart. Our approach achieves state-of-the-art uncertainty estimation results on the KITTI and NYU Depth V2 benchmarks without the need to retrain the neural network. Models and code are publicly available at https://github.com/jhornauer/GrUMoDepth.
<div id='section'>Paperid: <span id='pid'>295, <a href='https://arxiv.org/pdf/2208.00963.pdf' target='_blank'>https://arxiv.org/pdf/2208.00963.pdf</a></span>   <span><a href='https://github.com/MECLabTUDA/FrOoDo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Stieber, Moritz Fuchs, Anirban Mukhopadhyay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.00963">FrOoDo: Framework for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>FrOoDo is an easy-to-use and flexible framework for Out-of-Distribution detection tasks in digital pathology. It can be used with PyTorch classification and segmentation models, and its modular design allows for easy extension. The goal is to automate the task of OoD Evaluation such that research can focus on the main goal of either designing new models, new methods or evaluating a new dataset. The code can be found at https://github.com/MECLabTUDA/FrOoDo.
<div id='section'>Paperid: <span id='pid'>296, <a href='https://arxiv.org/pdf/2207.11554.pdf' target='_blank'>https://arxiv.org/pdf/2207.11554.pdf</a></span>   <span><a href='https://github.com/antoalli/3D_OS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonio Alliegro, Francesco Cappio Borlino, Tatiana Tommasi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.11554">3DOS: Towards 3D Open Set Learning -- Benchmarking and Understanding Semantic Novelty Detection on Point Clouds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years there has been significant progress in the field of 3D learning on classification, detection and segmentation problems. The vast majority of the existing studies focus on canonical closed-set conditions, neglecting the intrinsic open nature of the real-world. This limits the abilities of robots and autonomous systems involved in safety-critical applications that require managing novel and unknown signals. In this context exploiting 3D data can be a valuable asset since it provides rich information about the geometry of perceived objects and scenes. With this paper we provide the first broad study on 3D Open Set learning. We introduce 3DOS: a novel testbed for semantic novelty detection that considers several settings with increasing difficulties in terms of semantic (category) shift, and covers both in-domain (synthetic-to-synthetic, real-to-real) and cross-domain (synthetic-to-real) scenarios. Moreover, we investigate the related 2D Open Set literature to understand if and how its recent improvements are effective on 3D data. Our extensive benchmark positions several algorithms in the same coherent picture, revealing their strengths and limitations. The results of our analysis may serve as a reliable foothold for future tailored 3D Open Set methods.
<div id='section'>Paperid: <span id='pid'>297, <a href='https://arxiv.org/pdf/2207.04306.pdf' target='_blank'>https://arxiv.org/pdf/2207.04306.pdf</a></span>   <span><a href='https://github.com/tahabelkhouja/SRS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taha Belkhouja, Yan Yan, Janardhan Rao Doppa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.04306">Out-of-Distribution Detection in Time-Series Domain: A Novel Seasonal Ratio Scoring Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safe deployment of time-series classifiers for real-world applications relies on the ability to detect the data which is not generated from the same distribution as training data. This task is referred to as out-of-distribution (OOD) detection. We consider the novel problem of OOD detection for the time-series domain. We discuss the unique challenges posed by time-series data and explain why prior methods from the image domain will perform poorly. Motivated by these challenges, this paper proposes a novel {\em Seasonal Ratio Scoring (SRS)} approach. SRS consists of three key algorithmic steps. First, each input is decomposed into class-wise semantic component and remainder. Second, this decomposition is employed to estimate the class-wise conditional likelihoods of the input and remainder using deep generative models. The seasonal ratio score is computed from these estimates. Third, a threshold interval is identified from the in-distribution data to detect OOD examples. Experiments on diverse real-world benchmarks demonstrate that the SRS method is well-suited for time-series OOD detection when compared to baseline methods. Open-source code for SRS method is provided at https://github.com/tahabelkhouja/SRS
<div id='section'>Paperid: <span id='pid'>298, <a href='https://arxiv.org/pdf/2207.02466.pdf' target='_blank'>https://arxiv.org/pdf/2207.02466.pdf</a></span>   <span><a href='https://github.com/Eaphan/GLENet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Zhang, Qijian Zhang, Zhiyu Zhu, Junhui Hou, Yixuan Yuan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.02466">GLENet: Boosting 3D Object Detectors with Generative Label Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The inherent ambiguity in ground-truth annotations of 3D bounding boxes, caused by occlusions, signal missing, or manual annotation errors, can confuse deep 3D object detectors during training, thus deteriorating detection accuracy. However, existing methods overlook such issues to some extent and treat the labels as deterministic. In this paper, we formulate the label uncertainty problem as the diversity of potentially plausible bounding boxes of objects. Then, we propose GLENet, a generative framework adapted from conditional variational autoencoders, to model the one-to-many relationship between a typical 3D object and its potential ground-truth bounding boxes with latent variables. The label uncertainty generated by GLENet is a plug-and-play module and can be conveniently integrated into existing deep 3D detectors to build probabilistic detectors and supervise the learning of the localization uncertainty. Besides, we propose an uncertainty-aware quality estimator architecture in probabilistic detectors to guide the training of the IoU-branch with predicted localization uncertainty. We incorporate the proposed methods into various popular base 3D detectors and demonstrate significant and consistent performance gains on both KITTI and Waymo benchmark datasets. Especially, the proposed GLENet-VR outperforms all published LiDAR-based approaches by a large margin and achieves the top rank among single-modal methods on the challenging KITTI test set. The source code and pre-trained models are publicly available at \url{https://github.com/Eaphan/GLENet}.
<div id='section'>Paperid: <span id='pid'>299, <a href='https://arxiv.org/pdf/2206.11562.pdf' target='_blank'>https://arxiv.org/pdf/2206.11562.pdf</a></span>   <span><a href='https://github.com/NoSleepDeveloper/Geometric-Calibrator' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriella Chouraqui, Liron Cohen, Gil Einziger, Liel Leman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.11562">A Geometric Method for Improved Uncertainty Estimation in Real-time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning classifiers are probabilistic in nature, and thus inevitably involve uncertainty. Predicting the probability of a specific input to be correct is called uncertainty (or confidence) estimation and is crucial for risk management. Post-hoc model calibrations can improve models' uncertainty estimations without the need for retraining, and without changing the model. Our work puts forward a geometric-based approach for uncertainty estimation. Roughly speaking, we use the geometric distance of the current input from the existing training inputs as a signal for estimating uncertainty and then calibrate that signal (instead of the model's estimation) using standard post-hoc calibration techniques. We show that our method yields better uncertainty estimations than recently proposed approaches by extensively evaluating multiple datasets and models. In addition, we also demonstrate the possibility of performing our approach in near real-time applications. Our code is available at our Github https://github.com/NoSleepDeveloper/Geometric-Calibrator.
<div id='section'>Paperid: <span id='pid'>300, <a href='https://arxiv.org/pdf/2206.10911.pdf' target='_blank'>https://arxiv.org/pdf/2206.10911.pdf</a></span>   <span><a href='https://github.com/ishaanb92/FPCPipeline' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ishaan Bhat, Josien P. W. Pluim, Max A. Viergever, Hugo J. Kuijf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.10911">Influence of uncertainty estimation techniques on false-positive reduction in liver lesion detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning techniques show success in detecting objects in medical images, but still suffer from false-positive predictions that may hinder accurate diagnosis. The estimated uncertainty of the neural network output has been used to flag incorrect predictions. We study the role played by features computed from neural network uncertainty estimates and shape-based features computed from binary predictions in reducing false positives in liver lesion detection by developing a classification-based post-processing step for different uncertainty estimation methods. We demonstrate an improvement in the lesion detection performance of the neural network (with respect to F1-score) for all uncertainty estimation methods on two datasets, comprising abdominal MR and CT images, respectively. We show that features computed from neural network uncertainty estimates tend not to contribute much toward reducing false positives. Our results show that factors like class imbalance (true over false positive ratio) and shape-based features extracted from uncertainty maps play an important role in distinguishing false positive from true positive predictions. Our code can be found at https://github.com/ishaanb92/FPCPipeline.
<div id='section'>Paperid: <span id='pid'>301, <a href='https://arxiv.org/pdf/2205.12502.pdf' target='_blank'>https://arxiv.org/pdf/2205.12502.pdf</a></span>   <span><a href='https://github.com/gicheonkang/gst-visdial' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gi-Cheon Kang, Sungdong Kim, Jin-Hwa Kim, Donghyun Kwak, Byoung-Tak Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.12502">The Dialog Must Go On: Improving Visual Dialog via Generative Self-Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual dialog (VisDial) is a task of answering a sequence of questions grounded in an image, using the dialog history as context. Prior work has trained the dialog agents solely on VisDial data via supervised learning or leveraged pre-training on related vision-and-language datasets. This paper presents a semi-supervised learning approach for visually-grounded dialog, called Generative Self-Training (GST), to leverage unlabeled images on the Web. Specifically, GST first retrieves in-domain images through out-of-distribution detection and generates synthetic dialogs regarding the images via multimodal conditional text generation. GST then trains a dialog agent on the synthetic and the original VisDial data. As a result, GST scales the amount of training data up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For robust training of the synthetic dialogs, we also propose perplexity-based data selection and multimodal consistency regularization. Evaluation on VisDial v1.0 and v0.9 datasets shows that GST achieves new state-of-the-art results on both datasets. We further observe the robustness of GST against both visual and textual adversarial attacks. Finally, GST yields strong performance gains in the low-data regime. Code is available at https://github.com/gicheonkang/gst-visdial.
<div id='section'>Paperid: <span id='pid'>302, <a href='https://arxiv.org/pdf/2205.00403.pdf' target='_blank'>https://arxiv.org/pdf/2205.00403.pdf</a></span>   <span><a href='https://github.com/google/uncertainty-baselines' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeremiah Zhe Liu, Shreyas Padhy, Jie Ren, Zi Lin, Yeming Wen, Ghassen Jerfel, Zack Nado, Jasper Snoek, Dustin Tran, Balaji Lakshminarayanan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.00403">A Simple Approach to Improve Single-Model Deep Uncertainty via Distance-Awareness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty quantification is a major challenge in deep learning, as neural networks can make overconfident errors and assign high confidence predictions to out-of-distribution (OOD) inputs. The most popular approaches to estimate predictive uncertainty in deep learning are methods that combine predictions from multiple neural networks, such as Bayesian neural networks (BNNs) and deep ensembles. However their practicality in real-time, industrial-scale applications are limited due to the high memory and computational cost. Furthermore, ensembles and BNNs do not necessarily fix all the issues with the underlying member networks. In this work, we study principled approaches to improve uncertainty property of a single network, based on a single, deterministic representation. By formalizing the uncertainty quantification as a minimax learning problem, we first identify distance awareness, i.e., the model's ability to quantify the distance of a testing example from the training data, as a necessary condition for a DNN to achieve high-quality (i.e., minimax optimal) uncertainty estimation. We then propose Spectral-normalized Neural Gaussian Process (SNGP), a simple method that improves the distance-awareness ability of modern DNNs with two simple changes: (1) applying spectral normalization to hidden weights to enforce bi-Lipschitz smoothness in representations and (2) replacing the last output layer with a Gaussian process layer. On a suite of vision and language understanding benchmarks, SNGP outperforms other single-model approaches in prediction, calibration and out-of-domain detection. Furthermore, SNGP provides complementary benefits to popular techniques such as deep ensembles and data augmentation, making it a simple and scalable building block for probabilistic deep learning. Code is open-sourced at https://github.com/google/uncertainty-baselines
<div id='section'>Paperid: <span id='pid'>303, <a href='https://arxiv.org/pdf/2204.11041.pdf' target='_blank'>https://arxiv.org/pdf/2204.11041.pdf</a></span>   <span><a href='https://github.com/oOHCIOo/CETOOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Meng Xing, Zhiyong Feng, Yong Su, Changjae Oh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.11041">Learning by Erasing: Conditional Entropy based Transferable Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential to handle the distribution shifts between training and test scenarios. For a new in-distribution (ID) dataset, existing methods require retraining to capture the dataset-specific feature representation or data distribution. In this paper, we propose a deep generative models (DGM) based transferable OOD detection method, which is unnecessary to retrain on a new ID dataset. We design an image erasing strategy to equip exclusive conditional entropy distribution for each ID dataset, which determines the discrepancy of DGM's posteriori ucertainty distribution on different ID datasets. Owing to the powerful representation capacity of convolutional neural networks, the proposed model trained on complex dataset can capture the above discrepancy between ID datasets without retraining and thus achieve transferable OOD detection. We validate the proposed method on five datasets and verity that ours achieves comparable performance to the state-of-the-art group based OOD detection methods that need to be retrained to deploy on new ID datasets. Our code is available at https://github.com/oOHCIOo/CETOOD.
<div id='section'>Paperid: <span id='pid'>304, <a href='https://arxiv.org/pdf/2204.08803.pdf' target='_blank'>https://arxiv.org/pdf/2204.08803.pdf</a></span>   <span><a href='https://github.com/JingZhang617/EBMGSOD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Zhang, Jianwen Xie, Nick Barnes, Ping Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.08803">An Energy-Based Prior for Generative Saliency</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel generative saliency prediction framework that adopts an informative energy-based model as a prior distribution. The energy-based prior model is defined on the latent space of a saliency generator network that generates the saliency map based on a continuous latent variables and an observed image. Both the parameters of saliency generator and the energy-based prior are jointly trained via Markov chain Monte Carlo-based maximum likelihood estimation, in which the sampling from the intractable posterior and prior distributions of the latent variables are performed by Langevin dynamics. With the generative saliency model, we can obtain a pixel-wise uncertainty map from an image, indicating model confidence in the saliency prediction. Different from existing generative models, which define the prior distribution of the latent variables as a simple isotropic Gaussian distribution, our model uses an energy-based informative prior which can be more expressive in capturing the latent space of the data. With the informative energy-based prior, we extend the Gaussian distribution assumption of generative models to achieve a more representative distribution of the latent space, leading to more reliable uncertainty estimation. We apply the proposed frameworks to both RGB and RGB-D salient object detection tasks with both transformer and convolutional neural network backbones. We further propose an adversarial learning algorithm and a variational inference algorithm as alternatives to train the proposed generative framework. Experimental results show that our generative saliency model with an energy-based prior can achieve not only accurate saliency predictions but also reliable uncertainty maps that are consistent with human perception. Results and code are available at \url{https://github.com/JingZhang617/EBMGSOD}.
<div id='section'>Paperid: <span id='pid'>305, <a href='https://arxiv.org/pdf/2203.04450.pdf' target='_blank'>https://arxiv.org/pdf/2203.04450.pdf</a></span>   <span><a href='https://github.com/deeplearning-wisc/cider' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifei Ming, Yiyou Sun, Ousmane Dia, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.04450">How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical task for reliable machine learning. Recent advances in representation learning give rise to distance-based OOD detection, where testing samples are detected as OOD if they are relatively far away from the centroids or prototypes of in-distribution (ID) classes. However, prior methods directly take off-the-shelf contrastive losses that suffice for classifying ID samples, but are not optimally designed when test inputs contain OOD samples. In this work, we propose CIDER, a novel representation learning framework that exploits hyperspherical embeddings for OOD detection. CIDER jointly optimizes two losses to promote strong ID-OOD separability: a dispersion loss that promotes large angular distances among different class prototypes, and a compactness loss that encourages samples to be close to their class prototypes. We analyze and establish the unexplored relationship between OOD detection performance and the embedding properties in the hyperspherical space, and demonstrate the importance of dispersion and compactness. CIDER establishes superior performance, outperforming the latest rival by 19.36% in FPR95. Code is available at https://github.com/deeplearning-wisc/cider.
<div id='section'>Paperid: <span id='pid'>306, <a href='https://arxiv.org/pdf/2203.04446.pdf' target='_blank'>https://arxiv.org/pdf/2203.04446.pdf</a></span>   <span><a href='https://github.com/MISTLab/vpr-calibration-and-uncertainty' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pierre-Yves Lajoie, Giovanni Beltrame
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.04446">Self-Supervised Domain Calibration and Uncertainty Estimation for Place Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual place recognition techniques based on deep learning, which have imposed themselves as the state-of-the-art in recent years, do not generalize well to environments visually different from the training set. Thus, to achieve top performance, it is sometimes necessary to fine-tune the networks to the target environment. To this end, we propose a self-supervised domain calibration procedure based on robust pose graph optimization from Simultaneous Localization and Mapping (SLAM) as the supervision signal without requiring GPS or manual labeling. Moreover, we leverage the procedure to improve uncertainty estimation for place recognition matches which is important in safety critical applications. We show that our approach can improve the performance of a state-of-the-art technique on a target environment dissimilar from its training set and that we can obtain uncertainty estimates. We believe that this approach will help practitioners to deploy robust place recognition solutions in real-world applications. Our code is available publicly: https://github.com/MISTLab/vpr-calibration-and-uncertainty
<div id='section'>Paperid: <span id='pid'>307, <a href='https://arxiv.org/pdf/2203.04115.pdf' target='_blank'>https://arxiv.org/pdf/2203.04115.pdf</a></span>   <span><a href='https://github.com/MJ10/BioSeq-GFN-AL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Moksh Jain, Emmanuel Bengio, Alex-Hernandez Garcia, Jarrid Rector-Brooks, Bonaventure F. P. Dossou, Chanakya Ekbote, Jie Fu, Tianyu Zhang, Micheal Kilgour, Dinghuai Zhang, Lena Simine, Payel Das, Yoshua Bengio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.04115">Biological Sequence Design with GFlowNets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Design of de novo biological sequences with desired properties, like protein and DNA sequences, often involves an active loop with several rounds of molecule ideation and expensive wet-lab evaluations. These experiments can consist of multiple stages, with increasing levels of precision and cost of evaluation, where candidates are filtered. This makes the diversity of proposed candidates a key consideration in the ideation phase. In this work, we propose an active learning algorithm leveraging epistemic uncertainty estimation and the recently proposed GFlowNets as a generator of diverse candidate solutions, with the objective to obtain a diverse batch of useful (as defined by some utility function, for example, the predicted anti-microbial activity of a peptide) and informative candidates after each round. We also propose a scheme to incorporate existing labeled datasets of candidates, in addition to a reward function, to speed up learning in GFlowNets. We present empirical results on several biological sequence design tasks, and we find that our method generates more diverse and novel batches with high scoring candidates compared to existing approaches.
<div id='section'>Paperid: <span id='pid'>308, <a href='https://arxiv.org/pdf/2112.10074.pdf' target='_blank'>https://arxiv.org/pdf/2112.10074.pdf</a></span>   <span><a href='https://github.com/RagMeh11/QU-BraTS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Raghav Mehta, Angelos Filos, Ujjwal Baid, Chiharu Sako, Richard McKinley, Michael Rebsamen, Katrin Datwyler, Raphael Meier, Piotr Radojewski, Gowtham Krishnan Murugesan, Sahil Nalawade, Chandan Ganesh, Ben Wagner, Fang F. Yu, Baowei Fei, Ananth J. Madhuranthakam, Joseph A. Maldjian, Laura Daza, Catalina Gomez, Pablo Arbelaez, Chengliang Dai, Shuo Wang, Hadrien Reynaud, Yuan-han Mo, Elsa Angelini, Yike Guo, Wenjia Bai, Subhashis Banerjee, Lin-min Pei, Murat AK, Sarahi Rosas-Gonzalez, Ilyess Zemmoura, Clovis Tauber, Minh H. Vu, Tufve Nyholm, Tommy Lofstedt, Laura Mora Ballestar, Veronica Vilaplana, Hugh McHugh, Gonzalo Maso Talou, Alan Wang, Jay Patel, Ken Chang, Katharina Hoebel, Mishka Gidwani, Nishanth Arun, Sharut Gupta, Mehak Aggarwal, Praveer Singh, Elizabeth R. Gerstner, Jayashree Kalpathy-Cramer, Nicolas Boutry, Alexis Huard, Lasitha Vidyaratne, Md Monibor Rahman, Khan M. Iftekharuddin, Joseph Chazalon, Elodie Puybareau, Guillaume Tochon, Jun Ma, Mariano Cabezas, Xavier Llado, Arnau Oliver, Liliana Valencia, Sergi Valverde, Mehdi Amian, Mohammadreza Soltaninejad, Andriy Myronenko, Ali Hatamizadeh, Xue Feng, Quan Dou, Nicholas Tustison, Craig Meyer, Nisarg A. Shah, Sanjay Talbar, Marc-Andre Weber, Abhishek Mahajan, Andras Jakab, Roland Wiest, Hassan M. Fathallah-Shaykh, Arash Nazeri, Mikhail Milchenko1, Daniel Marcus, Aikaterini Kotrotsou, Rivka Colen, John Freymann, Justin Kirby, Christos Davatzikos, Bjoern Menze, Spyridon Bakas, Yarin Gal, Tal Arbel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.10074">QU-BraTS: MICCAI BraTS 2020 Challenge on Quantifying Uncertainty in Brain Tumor Segmentation - Analysis of Ranking Scores and Benchmarking Results</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL) models have provided state-of-the-art performance in various medical imaging benchmarking challenges, including the Brain Tumor Segmentation (BraTS) challenges. However, the task of focal pathology multi-compartment segmentation (e.g., tumor and lesion sub-regions) is particularly challenging, and potential errors hinder translating DL models into clinical workflows. Quantifying the reliability of DL model predictions in the form of uncertainties could enable clinical review of the most uncertain regions, thereby building trust and paving the way toward clinical translation. Several uncertainty estimation methods have recently been introduced for DL medical image segmentation tasks. Developing scores to evaluate and compare the performance of uncertainty measures will assist the end-user in making more informed decisions. In this study, we explore and evaluate a score developed during the BraTS 2019 and BraTS 2020 task on uncertainty quantification (QU-BraTS) and designed to assess and rank uncertainty estimates for brain tumor multi-compartment segmentation. This score (1) rewards uncertainty estimates that produce high confidence in correct assertions and those that assign low confidence levels at incorrect assertions, and (2) penalizes uncertainty measures that lead to a higher percentage of under-confident correct assertions. We further benchmark the segmentation uncertainties generated by 14 independent participating teams of QU-BraTS 2020, all of which also participated in the main BraTS segmentation task. Overall, our findings confirm the importance and complementary value that uncertainty estimates provide to segmentation algorithms, highlighting the need for uncertainty quantification in medical image analyses. Finally, in favor of transparency and reproducibility, our evaluation code is made publicly available at: https://github.com/RagMeh11/QU-BraTS.
<div id='section'>Paperid: <span id='pid'>309, <a href='https://arxiv.org/pdf/2112.00337.pdf' target='_blank'>https://arxiv.org/pdf/2112.00337.pdf</a></span>   <span><a href='https://github.com/daintlab/unknown-detection-benchmarks' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jihyo Kim, Jiin Koo, Sangheum Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.00337">A Unified Benchmark for the Unknown Detection Capability of Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have achieved outstanding performance over various tasks, but they have a critical issue: over-confident predictions even for completely unknown samples. Many studies have been proposed to successfully filter out these unknown samples, but they only considered narrow and specific tasks, referred to as misclassification detection, open-set recognition, or out-of-distribution detection. In this work, we argue that these tasks should be treated as fundamentally an identical problem because an ideal model should possess detection capability for all those tasks. Therefore, we introduce the unknown detection task, an integration of previous individual tasks, for a rigorous examination of the detection capability of deep neural networks on a wide spectrum of unknown samples. To this end, unified benchmark datasets on different scales were constructed and the unknown detection capabilities of existing popular methods were subject to comparison. We found that Deep Ensemble consistently outperforms the other approaches in detecting unknowns; however, all methods are only successful for a specific type of unknown. The reproducible code and benchmark datasets are available at https://github.com/daintlab/unknown-detection-benchmarks .
<div id='section'>Paperid: <span id='pid'>310, <a href='https://arxiv.org/pdf/2106.03702.pdf' target='_blank'>https://arxiv.org/pdf/2106.03702.pdf</a></span>   <span><a href='https://github.com/DLR-MI/pim' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Edgardo Solano-Carrillo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2106.03702">Can a single neuron learn predictive uncertainty?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation methods using deep learning approaches strive against separating how uncertain the state of the world manifests to us via measurement (objective end) from the way this gets scrambled with the model specification and training procedure used to predict such state (subjective means) -- e.g., number of neurons, depth, connections, priors (if the model is bayesian), weight initialization, etc. This poses the question of the extent to which one can eliminate the degrees of freedom associated with these specifications and still being able to capture the objective end. Here, a novel non-parametric quantile estimation method for continuous random variables is introduced, based on the simplest neural network architecture with one degree of freedom: a single neuron. Its advantage is first shown in synthetic experiments comparing with the quantile estimation achieved from ranking the order statistics (specifically for small sample size) and with quantile regression. In real-world applications, the method can be used to quantify predictive uncertainty under the split conformal prediction setting, whereby prediction intervals are estimated from the residuals of a pre-trained model on a held-out validation set and then used to quantify the uncertainty in future predictions -- the single neuron used here as a structureless ``thermometer'' that measures how uncertain the pre-trained model is. Benchmarking regression and classification experiments demonstrate that the method is competitive in quality and coverage with state-of-the-art solutions, with the added benefit of being more computationally efficient.
<div id='section'>Paperid: <span id='pid'>311, <a href='https://arxiv.org/pdf/2105.05735.pdf' target='_blank'>https://arxiv.org/pdf/2105.05735.pdf</a></span>   <span><a href='https://github.com/swyoon/normalized-autoencoders' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sangwoong Yoon, Yung-Kyun Noh, Frank Chongwoo Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2105.05735">Autoencoding Under Normalization Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Likelihood is a standard estimate for outlier detection. The specific role of the normalization constraint is to ensure that the out-of-distribution (OOD) regime has a small likelihood when samples are learned using maximum likelihood. Because autoencoders do not possess such a process of normalization, they often fail to recognize outliers even when they are obviously OOD. We propose the Normalized Autoencoder (NAE), a normalized probabilistic model constructed from an autoencoder. The probability density of NAE is defined using the reconstruction error of an autoencoder, which is differently defined in the conventional energy-based model. In our model, normalization is enforced by suppressing the reconstruction of negative samples, significantly improving the outlier detection performance. Our experimental results confirm the efficacy of NAE, both in detecting outliers and in generating in-distribution samples.
<div id='section'>Paperid: <span id='pid'>312, <a href='https://arxiv.org/pdf/2102.04399.pdf' target='_blank'>https://arxiv.org/pdf/2102.04399.pdf</a></span>   <span><a href='http://github.com/self-supervisor/Escaping-Stochastic-Traps-With-Aleatoric-Mapping-Agents' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Augustine N. Mavor-Parker, Kimberly A. Young, Caswell Barry, Lewis D. Griffin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2102.04399">How to Stay Curious while Avoiding Noisy TVs using Aleatoric Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Exploration in environments with sparse rewards is difficult for artificial agents. Curiosity driven learning -- using feed-forward prediction errors as intrinsic rewards -- has achieved some success in these scenarios, but fails when faced with action-dependent noise sources. We present aleatoric mapping agents (AMAs), a neuroscience inspired solution modeled on the cholinergic system of the mammalian brain. AMAs aim to explicitly ascertain which dynamics of the environment are unpredictable, regardless of whether those dynamics are induced by the actions of the agent. This is achieved by generating separate forward predictions for the mean and variance of future states and reducing intrinsic rewards for those transitions with high aleatoric variance. We show AMAs are able to effectively circumvent action-dependent stochastic traps that immobilise conventional curiosity driven agents. The code for all experiments presented in this paper is open sourced: http://github.com/self-supervisor/Escaping-Stochastic-Traps-With-Aleatoric-Mapping-Agents.
<div id='section'>Paperid: <span id='pid'>313, <a href='https://arxiv.org/pdf/2009.09822.pdf' target='_blank'>https://arxiv.org/pdf/2009.09822.pdf</a></span>   <span><a href='https://github.com/datamllab/tods' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kwei-Herng Lai, Daochen Zha, Guanchu Wang, Junjie Xu, Yue Zhao, Devesh Kumar, Yile Chen, Purav Zumkhawaka, Mingyang Wan, Diego Martinez, Xia Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2009.09822">TODS: An Automated Time Series Outlier Detection System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present TODS, an automated Time Series Outlier Detection System for research and industrial applications. TODS is a highly modular system that supports easy pipeline construction. The basic building block of TODS is primitive, which is an implementation of a function with hyperparameters. TODS currently supports 70 primitives, including data processing, time series processing, feature analysis, detection algorithms, and a reinforcement module. Users can freely construct a pipeline using these primitives and perform end- to-end outlier detection with the constructed pipeline. TODS provides a Graphical User Interface (GUI), where users can flexibly design a pipeline with drag-and-drop. Moreover, a data-driven searcher is provided to automatically discover the most suitable pipelines given a dataset. TODS is released under Apache 2.0 license at https://github.com/datamllab/tods.
<div id='section'>Paperid: <span id='pid'>314, <a href='https://arxiv.org/pdf/2411.17401.pdf' target='_blank'>https://arxiv.org/pdf/2411.17401.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pengfei Cao, Yuheng Chen, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17401">One Mind, Many Tongues: A Deep Dive into Language-Agnostic Knowledge Neurons in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have learned vast amounts of factual knowledge through self-supervised pre-training on large-scale corpora. Meanwhile, LLMs have also demonstrated excellent multilingual capabilities, which can express the learned knowledge in multiple languages. However, the knowledge storage mechanism in LLMs still remains mysterious. Some researchers attempt to demystify the factual knowledge in LLMs from the perspective of knowledge neurons, and subsequently discover language-agnostic knowledge neurons that store factual knowledge in a form that transcends language barriers. However, the preliminary finding suffers from two limitations: 1) High Uncertainty in Localization Results. Existing study only uses a prompt-based probe to localize knowledge neurons for each fact, while LLMs cannot provide consistent answers for semantically equivalent queries. Thus, it leads to inaccurate localization results with high uncertainty. 2) Lack of Analysis in More Languages. The study only analyzes language-agnostic knowledge neurons on English and Chinese data, without exploring more language families and languages. Naturally, it limits the generalizability of the findings. To address aforementioned problems, we first construct a new benchmark called Rephrased Multilingual LAMA (RML-LAMA), which contains high-quality cloze-style multilingual parallel queries for each fact. Then, we propose a novel method named Multilingual Integrated Gradients with Uncertainty Estimation (MATRICE), which quantifies the uncertainty across queries and languages during knowledge localization. Extensive experiments show that our method can accurately localize language-agnostic knowledge neurons. We also further investigate the role of language-agnostic knowledge neurons in cross-lingual knowledge editing, knowledge enhancement and new knowledge injection.
<div id='section'>Paperid: <span id='pid'>315, <a href='https://arxiv.org/pdf/2308.04789.pdf' target='_blank'>https://arxiv.org/pdf/2308.04789.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaoqin Huang, Aofan Jiang, Ya Zhang, Yanfeng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04789">Multi-Scale Memory Comparison for Zero-/Few-Shot Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection has gained considerable attention due to its broad range of applications, particularly in industrial defect detection. To address the challenges of data collection, researchers have introduced zero-/few-shot anomaly detection techniques that require minimal normal images for each category. However, complex industrial scenarios often involve multiple objects, presenting a significant challenge. In light of this, we propose a straightforward yet powerful multi-scale memory comparison framework for zero-/few-shot anomaly detection. Our approach employs a global memory bank to capture features across the entire image, while an individual memory bank focuses on simplified scenes containing a single object. The efficacy of our method is validated by its remarkable achievement of 4th place in the zero-shot track and 2nd place in the few-shot track of the Visual Anomaly and Novelty Detection (VAND) competition.
<div id='section'>Paperid: <span id='pid'>316, <a href='https://arxiv.org/pdf/2207.05195.pdf' target='_blank'>https://arxiv.org/pdf/2207.05195.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bohan Tang, Yiqi Zhong, Chenxin Xu, Wei-Tao Wu, Ulrich Neumann, Yanfeng Wang, Ya Zhang, Siheng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.05195">Collaborative Uncertainty Benefits Multi-Agent Multi-Modal Trajectory Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In multi-modal multi-agent trajectory forecasting, two major challenges have not been fully tackled: 1) how to measure the uncertainty brought by the interaction module that causes correlations among the predicted trajectories of multiple agents; 2) how to rank the multiple predictions and select the optimal predicted trajectory. In order to handle these challenges, this work first proposes a novel concept, collaborative uncertainty (CU), which models the uncertainty resulting from interaction modules. Then we build a general CU-aware regression framework with an original permutation-equivariant uncertainty estimator to do both tasks of regression and uncertainty estimation. Further, we apply the proposed framework to current SOTA multi-agent multi-modal forecasting systems as a plugin module, which enables the SOTA systems to 1) estimate the uncertainty in the multi-agent multi-modal trajectory forecasting task; 2) rank the multiple predictions and select the optimal one based on the estimated uncertainty. We conduct extensive experiments on a synthetic dataset and two public large-scale multi-agent trajectory forecasting benchmarks. Experiments show that: 1) on the synthetic dataset, the CU-aware regression framework allows the model to appropriately approximate the ground-truth Laplace distribution; 2) on the multi-agent trajectory forecasting benchmarks, the CU-aware regression framework steadily helps SOTA systems improve their performances. Specially, the proposed framework helps VectorNet improve by 262 cm regarding the Final Displacement Error of the chosen optimal prediction on the nuScenes dataset; 3) for multi-agent multi-modal trajectory forecasting systems, prediction uncertainty is positively correlated with future stochasticity; and 4) the estimated CU values are highly related to the interactive information among agents.
<div id='section'>Paperid: <span id='pid'>317, <a href='https://arxiv.org/pdf/2310.08027.pdf' target='_blank'>https://arxiv.org/pdf/2310.08027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Dai, Hao Lang, Kaisheng Zeng, Fei Huang, Yongbin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08027">Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for reliable and trustworthy machine learning. Recent multi-modal OOD detection leverages textual information from in-distribution (ID) class names for visual OOD detection, yet it currently neglects the rich contextual information of ID classes. Large language models (LLMs) encode a wealth of world knowledge and can be prompted to generate descriptive features for each class. Indiscriminately using such knowledge causes catastrophic damage to OOD detection due to LLMs' hallucinations, as is observed by our analysis. In this paper, we propose to apply world knowledge to enhance OOD detection performance through selective generation from LLMs. Specifically, we introduce a consistency-based uncertainty calibration method to estimate the confidence score of each generation. We further extract visual objects from each image to fully capitalize on the aforementioned world knowledge. Extensive experiments demonstrate that our method consistently outperforms the state-of-the-art.
<div id='section'>Paperid: <span id='pid'>318, <a href='https://arxiv.org/pdf/2305.03236.pdf' target='_blank'>https://arxiv.org/pdf/2305.03236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Lang, Yinhe Zheng, Yixuan Li, Jian Sun, Fei Huang, Yongbin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.03236">A Survey on Out-of-Distribution Detection in NLP</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for the reliable and safe deployment of machine learning systems in the real world. Great progress has been made over the past years. This paper presents the first review of recent advances in OOD detection with a particular focus on natural language processing approaches. First, we provide a formal definition of OOD detection and discuss several related fields. We then categorize recent algorithms into three classes according to the data they used: (1) OOD data available, (2) OOD data unavailable + in-distribution (ID) label available, and (3) OOD data unavailable + ID label unavailable. Third, we introduce datasets, applications, and metrics. Finally, we summarize existing work and present potential future research topics.
<div id='section'>Paperid: <span id='pid'>319, <a href='https://arxiv.org/pdf/2503.22285.pdf' target='_blank'>https://arxiv.org/pdf/2503.22285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bin Zhang, Jinggang Chen, Xiaoyang Qu, Guokuan Li, Kai Lu, Jiguang Wan, Jing Xiao, Jianzong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22285">RUNA: Object-level Out-of-Distribution Detection via Regional Uncertainty Alignment of Multimodal Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enabling object detectors to recognize out-of-distribution (OOD) objects is vital for building reliable systems. A primary obstacle stems from the fact that models frequently do not receive supervisory signals from unfamiliar data, leading to overly confident predictions regarding OOD objects. Despite previous progress that estimates OOD uncertainty based on the detection model and in-distribution (ID) samples, we explore using pre-trained vision-language representations for object-level OOD detection. We first discuss the limitations of applying image-level CLIP-based OOD detection methods to object-level scenarios. Building upon these insights, we propose RUNA, a novel framework that leverages a dual encoder architecture to capture rich contextual information and employs a regional uncertainty alignment mechanism to distinguish ID from OOD objects effectively. We introduce a few-shot fine-tuning approach that aligns region-level semantic representations to further improve the model's capability to discriminate between similar objects. Our experiments show that RUNA substantially surpasses state-of-the-art methods in object-level OOD detection, particularly in challenging scenarios with diverse and complex object instances.
<div id='section'>Paperid: <span id='pid'>320, <a href='https://arxiv.org/pdf/2412.06168.pdf' target='_blank'>https://arxiv.org/pdf/2412.06168.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Fu, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06168">Out-of-Distribution Detection with Overlap Index</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for the deployment of machine learning models in the open world. While existing OOD detectors are effective in identifying OOD samples that deviate significantly from in-distribution (ID) data, they often come with trade-offs. For instance, deep OOD detectors usually suffer from high computational costs, require tuning hyperparameters, and have limited interpretability, whereas traditional OOD detectors may have a low accuracy on large high-dimensional datasets. To address these limitations, we propose a novel effective OOD detection approach that employs an overlap index (OI)-based confidence score function to evaluate the likelihood of a given input belonging to the same distribution as the available ID samples. The proposed OI-based confidence score function is non-parametric, lightweight, and easy to interpret, hence providing strong flexibility and generality. Extensive empirical evaluations indicate that our OI-based OOD detector is competitive with state-of-the-art OOD detectors in terms of detection accuracy on a wide range of datasets while requiring less computation and memory costs. Lastly, we show that the proposed OI-based confidence score function inherits nice properties from OI (e.g., insensitivity to small distributional variations and robustness against Huber $Îµ$-contamination) and is a versatile tool for estimating OI and model accuracy in specific contexts.
<div id='section'>Paperid: <span id='pid'>321, <a href='https://arxiv.org/pdf/2402.16926.pdf' target='_blank'>https://arxiv.org/pdf/2402.16926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georg Pichler, Marco Romanelli, Divya Prakash Manivannan, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16926">On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem.
<div id='section'>Paperid: <span id='pid'>322, <a href='https://arxiv.org/pdf/2311.09620.pdf' target='_blank'>https://arxiv.org/pdf/2311.09620.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinggang Chen, Junjie Li, Xiaoyang Qu, Jianzong Wang, Jiguang Wan, Jing Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09620">GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) examples is crucial to guarantee the reliability and safety of deep neural networks in real-world settings. In this paper, we offer an innovative perspective on quantifying the disparities between in-distribution (ID) and OOD data -- analyzing the uncertainty that arises when models attempt to explain their predictive decisions. This perspective is motivated by our observation that gradient-based attribution methods encounter challenges in assigning feature importance to OOD data, thereby yielding divergent explanation patterns. Consequently, we investigate how attribution gradients lead to uncertain explanation outcomes and introduce two forms of abnormalities for OOD detection: the zero-deflation abnormality and the channel-wise average abnormality. We then propose GAIA, a simple and effective approach that incorporates Gradient Abnormality Inspection and Aggregation. The effectiveness of GAIA is validated on both commonly utilized (CIFAR) and large-scale (ImageNet-1k) benchmarks. Specifically, GAIA reduces the average FPR95 by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared to advanced post-hoc methods.
<div id='section'>Paperid: <span id='pid'>323, <a href='https://arxiv.org/pdf/2311.03236.pdf' target='_blank'>https://arxiv.org/pdf/2311.03236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haotian Zheng, Qizhou Wang, Zhen Fang, Xiaobo Xia, Feng Liu, Tongliang Liu, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.03236">Out-of-distribution Detection Learning with Unreliable Out-of-distribution Sources</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection discerns OOD data where the predictor cannot make valid predictions as in-distribution (ID) data, thereby increasing the reliability of open-world classification. However, it is typically hard to collect real out-of-distribution (OOD) data for training a predictor capable of discerning ID and OOD patterns. This obstacle gives rise to data generation-based learning methods, synthesizing OOD data via data generators for predictor training without requiring any real OOD data. Related methods typically pre-train a generator on ID data and adopt various selection procedures to find those data likely to be the OOD cases. However, generated data may still coincide with ID semantics, i.e., mistaken OOD generation remains, confusing the predictor between ID and OOD data. To this end, we suggest that generated data (with mistaken OOD generation) can be used to devise an auxiliary OOD detection task to facilitate real OOD detection. Specifically, we can ensure that learning from such an auxiliary task is beneficial if the ID and the OOD parts have disjoint supports, with the help of a well-designed training procedure for the predictor. Accordingly, we propose a powerful data generation-based learning method named Auxiliary Task-based OOD Learning (ATOL) that can relieve the mistaken OOD generation. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts.
<div id='section'>Paperid: <span id='pid'>324, <a href='https://arxiv.org/pdf/2303.08606.pdf' target='_blank'>https://arxiv.org/pdf/2303.08606.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Ye, Shijing Si, Jianzong Wang, Ning Cheng, Zhitao Li, Jing Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08606">On the Calibration and Uncertainty with PÃ³lya-Gamma Augmentation for Dialog Retrieval Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural retrieval models have amply demonstrated their power but estimating the reliability of their predictions remains challenging. Most dialog response retrieval models output a single score for a response on how relevant it is to a given question. However, the bad calibration of deep neural network results in various uncertainty for the single score such that the unreliable predictions always misinform user decisions. To investigate these issues, we present an efficient calibration and uncertainty estimation framework PG-DRR for dialog response retrieval models which adds a Gaussian Process layer to a deterministic deep neural network and recovers conjugacy for tractable posterior inference by PÃ³lya-Gamma augmentation. Finally, PG-DRR achieves the lowest empirical calibration error (ECE) in the in-domain datasets and the distributional shift task while keeping $R_{10}@1$ and MAP performance.
<div id='section'>Paperid: <span id='pid'>325, <a href='https://arxiv.org/pdf/2303.08599.pdf' target='_blank'>https://arxiv.org/pdf/2303.08599.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Ye, Zhitao Li, Jianzong Wang, Ning Cheng, Jing Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08599">Efficient Uncertainty Estimation with Gaussian Process for Reliable Dialog Response Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have achieved remarkable performance in retrieval-based dialogue systems, but they are shown to be ill calibrated. Though basic calibration methods like Monte Carlo Dropout and Ensemble can calibrate well, these methods are time-consuming in the training or inference stages. To tackle these challenges, we propose an efficient uncertainty calibration framework GPF-BERT for BERT-based conversational search, which employs a Gaussian Process layer and the focal loss on top of the BERT architecture to achieve a high-quality neural ranker. Extensive experiments are conducted to verify the effectiveness of our method. In comparison with basic calibration methods, GPF-BERT achieves the lowest empirical calibration error (ECE) in three in-domain datasets and the distributional shift tasks, while yielding the highest $R_{10}@1$ and MAP performance on most cases. In terms of time consumption, our GPF-BERT has an 8$\times$ speedup.
<div id='section'>Paperid: <span id='pid'>326, <a href='https://arxiv.org/pdf/2303.05033.pdf' target='_blank'>https://arxiv.org/pdf/2303.05033.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qizhou Wang, Junjie Ye, Feng Liu, Quanyu Dai, Marcus Kalander, Tongliang Liu, Jianye Hao, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.05033">Out-of-distribution Detection with Implicit Outlier Transformation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier exposure (OE) is powerful in out-of-distribution (OOD) detection, enhancing detection capability via model fine-tuning with surrogate OOD data. However, surrogate data typically deviate from test OOD data. Thus, the performance of OE, when facing unseen OOD data, can be weakened. To address this issue, we propose a novel OE-based approach that makes the model perform well for unseen OOD situations, even for unseen OOD cases. It leads to a min-max learning scheme -- searching to synthesize OOD data that leads to worst judgments and learning from such OOD data for uniform performance in OOD detection. In our realization, these worst OOD data are synthesized by transforming original surrogate ones. Specifically, the associated transform functions are learned implicitly based on our novel insight that model perturbation leads to data transformation. Our methodology offers an efficient way of synthesizing OOD data, which can further benefit the detection model, besides the surrogate OOD data. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts.
<div id='section'>Paperid: <span id='pid'>327, <a href='https://arxiv.org/pdf/2505.12457.pdf' target='_blank'>https://arxiv.org/pdf/2505.12457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Zhao, Kai Xiong, Xiao Ding, Li Du, YangouOuyang, Zhouhao Sun, Jiannan Guan, Wenbin Zhang, Bin Liu, Dong Hu, Bing Qin, Ting Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12457">UFO-RL: Uncertainty-Focused Optimization for Efficient Reinforcement Learning Data Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scaling RL for LLMs is computationally expensive, largely due to multi-sampling for policy optimization and evaluation, making efficient data selection crucial. Inspired by the Zone of Proximal Development (ZPD) theory, we hypothesize LLMs learn best from data within their potential comprehension zone. Addressing the limitation of conventional, computationally intensive multi-sampling methods for data assessment, we introduce UFO-RL. This novel framework uses a computationally efficient single-pass uncertainty estimation to identify informative data instances, achieving up to 185x faster data evaluation. UFO-RL leverages this metric to select data within the estimated ZPD for training. Experiments show that training with just 10% of data selected by UFO-RL yields performance comparable to or surpassing full-data training, reducing overall training time by up to 16x while enhancing stability and generalization. UFO-RL offers a practical and highly efficient strategy for scaling RL fine-tuning of LLMs by focusing learning on valuable data.
<div id='section'>Paperid: <span id='pid'>328, <a href='https://arxiv.org/pdf/2505.04713.pdf' target='_blank'>https://arxiv.org/pdf/2505.04713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis F. Gomez, Gonzalo Garrido-Lopez, Julian Fierrez, Aythami Morales, Ruben Tolosana, Javier Rueda, Enrique Navarro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04713">Comparison of Visual Trackers for Biomechanical Analysis of Running</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human pose estimation has witnessed significant advancements in recent years, mainly due to the integration of deep learning models, the availability of a vast amount of data, and large computational resources. These developments have led to highly accurate body tracking systems, which have direct applications in sports analysis and performance evaluation.
  This work analyzes the performance of six trackers: two point trackers and four joint trackers for biomechanical analysis in sprints. The proposed framework compares the results obtained from these pose trackers with the manual annotations of biomechanical experts for more than 5870 frames. The experimental framework employs forty sprints from five professional runners, focusing on three key angles in sprint biomechanics: trunk inclination, hip flex extension, and knee flex extension. We propose a post-processing module for outlier detection and fusion prediction in the joint angles.
  The experimental results demonstrate that using joint-based models yields root mean squared errors ranging from 11.41Â° to 4.37Â°. When integrated with the post-processing modules, these errors can be reduced to 6.99Â° and 3.88Â°, respectively. The experimental findings suggest that human pose tracking approaches can be valuable resources for the biomechanical analysis of running. However, there is still room for improvement in applications where high accuracy is required.
<div id='section'>Paperid: <span id='pid'>329, <a href='https://arxiv.org/pdf/2402.11476.pdf' target='_blank'>https://arxiv.org/pdf/2402.11476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiaozhi Tan, Long Bai, Guankun Wang, Mobarakol Islam, Hongliang Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11476">EndoOOD: Uncertainty-aware Out-of-distribution Detection in Capsule Endoscopy Diagnosis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wireless capsule endoscopy (WCE) is a non-invasive diagnostic procedure that enables visualization of the gastrointestinal (GI) tract. Deep learning-based methods have shown effectiveness in disease screening using WCE data, alleviating the burden on healthcare professionals. However, existing capsule endoscopy classification methods mostly rely on pre-defined categories, making it challenging to identify and classify out-of-distribution (OOD) data, such as undefined categories or anatomical landmarks. To address this issue, we propose the Endoscopy Out-of-Distribution (EndoOOD) framework, which aims to effectively handle the OOD detection challenge in WCE diagnosis. The proposed framework focuses on improving the robustness and reliability of WCE diagnostic capabilities by incorporating uncertainty-aware mixup training and long-tailed in-distribution (ID) data calibration techniques. Additionally, virtual-logit matching is employed to accurately distinguish between OOD and ID data while minimizing information loss. To assess the performance of our proposed solution, we conduct evaluations and comparisons with 12 state-of-the-art (SOTA) methods using two publicly available datasets. The results demonstrate the effectiveness of the proposed framework in enhancing diagnostic accuracy and supporting clinical decision-making.
<div id='section'>Paperid: <span id='pid'>330, <a href='https://arxiv.org/pdf/2308.02282.pdf' target='_blank'>https://arxiv.org/pdf/2308.02282.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wang Lu, Jindong Wang, Xinwei Sun, Yiqiang Chen, Xiangyang Ji, Qiang Yang, Xing Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02282">DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time series remains one of the most challenging modalities in machine learning research. The out-of-distribution (OOD) detection and generalization on time series tend to suffer due to its non-stationary property, i.e., the distribution changes over time. The dynamic distributions inside time series pose great challenges to existing algorithms to identify invariant distributions since they mainly focus on the scenario where the domain information is given as prior knowledge. In this paper, we attempt to exploit subdomains within a whole dataset to counteract issues induced by non-stationary for generalized representation learning. We propose DIVERSIFY, a general framework, for OOD detection and generalization on dynamic distributions of time series. DIVERSIFY takes an iterative process: it first obtains the "worst-case" latent distribution scenario via adversarial training, then reduces the gap between these latent distributions. We implement DIVERSIFY via combining existing OOD detection methods according to either extracted features or outputs of models for detection while we also directly utilize outputs for classification. In addition, theoretical insights illustrate that DIVERSIFY is theoretically supported. Extensive experiments are conducted on seven datasets with different OOD settings across gesture recognition, speech commands recognition, wearable stress and affect detection, and sensor-based human activity recognition. Qualitative and quantitative results demonstrate that DIVERSIFY learns more generalized features and significantly outperforms other baselines.
<div id='section'>Paperid: <span id='pid'>331, <a href='https://arxiv.org/pdf/2403.13204.pdf' target='_blank'>https://arxiv.org/pdf/2403.13204.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anh Bui, Vy Vo, Tung Pham, Dinh Phung, Trung Le
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13204">Diversity-Aware Agnostic Ensemble of Sharpness Minimizers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There has long been plenty of theoretical and empirical evidence supporting the success of ensemble learning. Deep ensembles in particular take advantage of training randomness and expressivity of individual neural networks to gain prediction diversity, ultimately leading to better generalization, robustness and uncertainty estimation. In respect of generalization, it is found that pursuing wider local minima result in models being more robust to shifts between training and testing sets. A natural research question arises out of these two approaches as to whether a boost in generalization ability can be achieved if ensemble learning and loss sharpness minimization are integrated. Our work investigates this connection and proposes DASH - a learning algorithm that promotes diversity and flatness within deep ensembles. More concretely, DASH encourages base learners to move divergently towards low-loss regions of minimal sharpness. We provide a theoretical backbone for our method along with extensive empirical evidence demonstrating an improvement in ensemble generalizability.
<div id='section'>Paperid: <span id='pid'>332, <a href='https://arxiv.org/pdf/2509.14151.pdf' target='_blank'>https://arxiv.org/pdf/2509.14151.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rongyu Zhang, Jiaming Liu, Xiaoqi Li, Xiaowei Chi, Dan Wang, Li Du, Yuan Du, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14151">BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-centric Bird's Eye View (BEV) perception holds considerable promise for autonomous driving. Recent studies have prioritized efficiency or accuracy enhancements, yet the issue of domain shift has been overlooked, leading to substantial performance degradation upon transfer. We identify major domain gaps in real-world cross-domain scenarios and initiate the first effort to address the Domain Adaptation (DA) challenge in multi-view 3D object detection for BEV perception. Given the complexity of BEV perception approaches with their multiple components, domain shift accumulation across multi-geometric spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain adaptation. In this paper, we introduce an innovative geometric-aware teacher-student framework, BEVUDA++, to diminish this issue, comprising a Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model. Specifically, RDT effectively blends target LiDAR with dependable depth predictions to generate depth-aware information based on uncertainty estimation, enhancing the extraction of Voxel and BEV features that are essential for understanding the target domain. To collaboratively reduce the domain shift, GCS maps features from multiple spaces into a unified geometric embedding space, thereby narrowing the gap in data distribution between the two domains. Additionally, we introduce a novel Uncertainty-guided Exponential Moving Average (UEMA) to further reduce error accumulation due to domain shifts informed by previously obtained uncertainty guidance. To demonstrate the superiority of our proposed method, we execute comprehensive experiments in four cross-domain scenarios, securing state-of-the-art performance in BEV 3D object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night adaptation.
<div id='section'>Paperid: <span id='pid'>333, <a href='https://arxiv.org/pdf/2403.14676.pdf' target='_blank'>https://arxiv.org/pdf/2403.14676.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fei Wang, Qi Liu, Enhong Chen, Chuanren Liu, Zhenya Huang, Jinze Wu, Shijin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14676">Unified Uncertainty Estimation for Cognitive Diagnosis Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cognitive diagnosis models have been widely used in different areas, especially intelligent education, to measure users' proficiency levels on knowledge concepts, based on which users can get personalized instructions. As the measurement is not always reliable due to the weak links of the models and data, the uncertainty of measurement also offers important information for decisions. However, the research on the uncertainty estimation lags behind that on advanced model structures for cognitive diagnosis. Existing approaches have limited efficiency and leave an academic blank for sophisticated models which have interaction function parameters (e.g., deep learning-based models). To address these problems, we propose a unified uncertainty estimation approach for a wide range of cognitive diagnosis models. Specifically, based on the idea of estimating the posterior distributions of cognitive diagnosis model parameters, we first provide a unified objective function for mini-batch based optimization that can be more efficiently applied to a wide range of models and large datasets. Then, we modify the reparameterization approach in order to adapt to parameters defined on different domains. Furthermore, we decompose the uncertainty of diagnostic parameters into data aspect and model aspect, which better explains the source of uncertainty. Extensive experiments demonstrate that our method is effective and can provide useful insights into the uncertainty of cognitive diagnosis.
<div id='section'>Paperid: <span id='pid'>334, <a href='https://arxiv.org/pdf/2310.13022.pdf' target='_blank'>https://arxiv.org/pdf/2310.13022.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianing Wang, Qiushi Sun, Nuo Chen, Chengyu Wang, Jun Huang, Ming Gao, Xiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13022">Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios. To remedy this dilemma, we study self-training as one of the predominant semi-supervised learning (SSL) approaches, which utilizes large-scale unlabeled data to generate synthetic examples. However, too many noisy labels will hurt the model performance, and the self-training procedure requires multiple training iterations making it more expensive if all the model parameters of the PLM are updated. This paper presents UPET, a novel Uncertainty-aware Parameter-Efficient self-Training framework to effectively and efficiently address the labeled data scarcity issue. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the teacher model and then judiciously select reliable pseudo-labeled examples based on confidence and certainty. During the student training, we introduce multiple parameter-efficient learning (PEL) paradigms that allow the optimization of only a small percentage of parameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the robustness and generalization. Extensive experiments over multiple downstream tasks demonstrate that UPET achieves a substantial improvement in terms of performance and efficiency. Our codes and data are released at https: //github.com/wjn1996/UPET.
<div id='section'>Paperid: <span id='pid'>335, <a href='https://arxiv.org/pdf/2302.08659.pdf' target='_blank'>https://arxiv.org/pdf/2302.08659.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianing Wang, Chengyu Wang, Jun Huang, Ming Gao, Aoying Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08659">Uncertainty-aware Self-training for Low-resource Neural Sequence Labeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural sequence labeling (NSL) aims at assigning labels for input language tokens, which covers a broad range of applications, such as named entity recognition (NER) and slot filling, etc. However, the satisfying results achieved by traditional supervised-based approaches heavily depend on the large amounts of human annotation data, which may not be feasible in real-world scenarios due to data privacy and computation efficiency issues. This paper presents SeqUST, a novel uncertain-aware self-training framework for NSL to address the labeled data scarcity issue and to effectively utilize unlabeled data. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation at the token level and then select reliable language tokens from unlabeled data based on the model confidence and certainty. A well-designed masked sequence labeling task with a noise-robust loss supports robust training, which aims to suppress the problem of noisy pseudo labels. In addition, we develop a Gaussian-based consistency regularization technique to further improve the model robustness on Gaussian-distributed perturbed representations. This effectively alleviates the over-fitting dilemma originating from pseudo-labeled augmented data. Extensive experiments over six benchmarks demonstrate that our SeqUST framework effectively improves the performance of self-training, and consistently outperforms strong baselines by a large margin in low-resource scenarios
<div id='section'>Paperid: <span id='pid'>336, <a href='https://arxiv.org/pdf/2408.07819.pdf' target='_blank'>https://arxiv.org/pdf/2408.07819.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijia Wang, Qianqian Xu, Yangbangyan Jiang, Siran Dai, Qingming Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07819">Regularized Contrastive Partial Multi-view Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, multi-view outlier detection (MVOD) methods have advanced significantly, aiming to identify outliers within multi-view datasets. A key point is to better detect class outliers and class-attribute outliers, which only exist in multi-view data. However, existing methods either is not able to reduce the impact of outliers when learning view-consistent information, or struggle in cases with varying neighborhood structures. Moreover, most of them do not apply to partial multi-view data in real-world scenarios. To overcome these drawbacks, we propose a novel method named Regularized Contrastive Partial Multi-view Outlier Detection (RCPMOD). In this framework, we utilize contrastive learning to learn view-consistent information and distinguish outliers by the degree of consistency. Specifically, we propose (1) An outlier-aware contrastive loss with a potential outlier memory bank to eliminate their bias motivated by a theoretical analysis. (2) A neighbor alignment contrastive loss to capture the view-shared local structural correlation. (3) A spreading regularization loss to prevent the model from overfitting over outliers. With the Cross-view Relation Transfer technique, we could easily impute the missing view samples based on the features of neighbors. Experimental results on four benchmark datasets demonstrate that our proposed approach could outperform state-of-the-art competitors under different settings.
<div id='section'>Paperid: <span id='pid'>337, <a href='https://arxiv.org/pdf/2407.21742.pdf' target='_blank'>https://arxiv.org/pdf/2407.21742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junwei He, Qianqian Xu, Yangbangyan Jiang, Zitai Wang, Yuchen Sun, Qingming Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21742">HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the progressive advancements in deep graph learning, out-of-distribution (OOD) detection for graph data has emerged as a critical challenge. While the efficacy of auxiliary datasets in enhancing OOD detection has been extensively studied for image and text data, such approaches have not yet been explored for graph data. Unlike Euclidean data, graph data exhibits greater diversity but lower robustness to perturbations, complicating the integration of outliers. To tackle these challenges, we propose the introduction of \textbf{H}ybrid External and Internal \textbf{G}raph \textbf{O}utlier \textbf{E}xposure (HGOE) to improve graph OOD detection performance. Our framework involves using realistic external graph data from various domains and synthesizing internal outliers within ID subgroups to address the poor robustness and presence of OOD samples within the ID class. Furthermore, we develop a boundary-aware OE loss that adaptively assigns weights to outliers, maximizing the use of high-quality OOD samples while minimizing the impact of low-quality ones. Our proposed HGOE framework is model-agnostic and designed to enhance the effectiveness of existing graph OOD detection models. Experimental results demonstrate that our HGOE framework can significantly improve the performance of existing OOD detection models across all 8 real datasets.
<div id='section'>Paperid: <span id='pid'>338, <a href='https://arxiv.org/pdf/2310.19247.pdf' target='_blank'>https://arxiv.org/pdf/2310.19247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaqian Ren, Hao Peng, Lei Jiang, Zhiwei Liu, Jia Wu, Zhengtao Yu, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19247">Uncertainty-guided Boundary Learning for Imbalanced Social Event Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world social events typically exhibit a severe class-imbalance distribution, which makes the trained detection model encounter a serious generalization challenge. Most studies solve this problem from the frequency perspective and emphasize the representation or classifier learning for tail classes. While in our observation, compared to the rarity of classes, the calibrated uncertainty estimated from well-trained evidential deep learning networks better reflects model performance. To this end, we propose a novel uncertainty-guided class imbalance learning framework - UCL$_{SED}$, and its variant - UCL-EC$_{SED}$, for imbalanced social event detection tasks. We aim to improve the overall model performance by enhancing model generalization to those uncertain classes. Considering performance degradation usually comes from misclassifying samples as their confusing neighboring classes, we focus on boundary learning in latent space and classifier learning with high-quality uncertainty estimation. First, we design a novel uncertainty-guided contrastive learning loss, namely UCL and its variant - UCL-EC, to manipulate distinguishable representation distribution for imbalanced data. During training, they force all classes, especially uncertain ones, to adaptively adjust a clear separable boundary in the feature space. Second, to obtain more robust and accurate class uncertainty, we combine the results of multi-view evidential classifiers via the Dempster-Shafer theory under the supervision of an additional calibration method. We conduct experiments on three severely imbalanced social event datasets including Events2012\_100, Events2018\_100, and CrisisLexT\_7. Our model significantly improves social event representation and classification tasks in almost all classes, especially those uncertain ones.
<div id='section'>Paperid: <span id='pid'>339, <a href='https://arxiv.org/pdf/2309.01899.pdf' target='_blank'>https://arxiv.org/pdf/2309.01899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guangjie Zeng, Hao Peng, Angsheng Li, Zhiwei Liu, Chunyang Liu, Philip S. Yu, Lifang He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.01899">Unsupervised Skin Lesion Segmentation via Structural Entropy Minimization on Multi-Scale Superpixel Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Skin lesion segmentation is a fundamental task in dermoscopic image analysis. The complex features of pixels in the lesion region impede the lesion segmentation accuracy, and existing deep learning-based methods often lack interpretability to this problem. In this work, we propose a novel unsupervised Skin Lesion sEgmentation framework based on structural entropy and isolation forest outlier Detection, namely SLED. Specifically, skin lesions are segmented by minimizing the structural entropy of a superpixel graph constructed from the dermoscopic image. Then, we characterize the consistency of healthy skin features and devise a novel multi-scale segmentation mechanism by outlier detection, which enhances the segmentation accuracy by leveraging the superpixel features from multiple scales. We conduct experiments on four skin lesion benchmarks and compare SLED with nine representative unsupervised segmentation methods. Experimental results demonstrate the superiority of the proposed framework. Additionally, some case studies are analyzed to demonstrate the effectiveness of SLED.
<div id='section'>Paperid: <span id='pid'>340, <a href='https://arxiv.org/pdf/2204.12095.pdf' target='_blank'>https://arxiv.org/pdf/2204.12095.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kay Liu, Yingtong Dou, Xueying Ding, Xiyang Hu, Ruitong Zhang, Hao Peng, Lichao Sun, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.12095">PyGOD: A Python Library for Graph Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>PyGOD is an open-source Python library for detecting outliers in graph data. As the first comprehensive library of its kind, PyGOD supports a wide array of leading graph-based methods for outlier detection under an easy-to-use, well-documented API designed for use by both researchers and practitioners. PyGOD provides modularized components of the different detectors implemented so that users can easily customize each detector for their purposes. To ease the construction of detection workflows, PyGOD offers numerous commonly used utility functions. To scale computation to large graphs, PyGOD supports functionalities for deep models such as sampling and mini-batch processing. PyGOD uses best practices in fostering code reliability and maintainability, including unit testing, continuous integration, and code coverage. To facilitate accessibility, PyGOD is released under a BSD 2-Clause license at https://pygod.org and at the Python Package Index (PyPI).
<div id='section'>Paperid: <span id='pid'>341, <a href='https://arxiv.org/pdf/2111.11108.pdf' target='_blank'>https://arxiv.org/pdf/2111.11108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Campos, Tung Kieu, Chenjuan Guo, Feiteng Huang, Kai Zheng, Bin Yang, Christian S. Jensen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2111.11108">Unsupervised Time Series Outlier Detection with Diversity-Driven Convolutional Ensembles -- Extended Version</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the sweeping digitalization of societal, medical, industrial, and scientific processes, sensing technologies are being deployed that produce increasing volumes of time series data, thus fueling a plethora of new or improved applications. In this setting, outlier detection is frequently important, and while solutions based on neural networks exist, they leave room for improvement in terms of both accuracy and efficiency. With the objective of achieving such improvements, we propose a diversity-driven, convolutional ensemble. To improve accuracy, the ensemble employs multiple basic outlier detection models built on convolutional sequence-to-sequence autoencoders that can capture temporal dependencies in time series. Further, a novel diversity-driven training method maintains diversity among the basic models, with the aim of improving the ensemble's accuracy. To improve efficiency, the approach enables a high degree of parallelism during training. In addition, it is able to transfer some model parameters from one basic model to another, which reduces training time. We report on extensive experiments using real-world multivariate time series that offer insight into the design choices underlying the new approach and offer evidence that it is capable of improved accuracy and efficiency. This is an extended version of "Unsupervised Time Series Outlier Detection with Diversity-Driven Convolutional Ensembles", to appear in PVLDB 2022.
<div id='section'>Paperid: <span id='pid'>342, <a href='https://arxiv.org/pdf/2509.16696.pdf' target='_blank'>https://arxiv.org/pdf/2509.16696.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wataru Hashimoto, Hidetaka Kamigaito, Taro Watanabe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16696">Decoding Uncertainty: The Impact of Decoding Strategies for Uncertainty Estimation in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Decoding strategies manipulate the probability distribution underlying the output of a language model and can therefore affect both generation quality and its uncertainty. In this study, we investigate the impact of decoding strategies on uncertainty estimation in Large Language Models (LLMs). Our experiments show that Contrastive Search, which mitigates repetition, yields better uncertainty estimates on average across a range of preference-aligned LLMs. In contrast, the benefits of these strategies sometimes diverge when the model is only post-trained with supervised fine-tuning, i.e. without explicit alignment.
<div id='section'>Paperid: <span id='pid'>343, <a href='https://arxiv.org/pdf/2503.02233.pdf' target='_blank'>https://arxiv.org/pdf/2503.02233.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Zheng, Hongshen Xu, Yuncong Liu, Lu Chen, Pascale Fung, Kai Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.02233">Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) are prone to hallucination stemming from misaligned self-awareness, particularly when processing queries exceeding their knowledge boundaries. While existing mitigation strategies employ uncertainty estimation or query rejection mechanisms, they suffer from computational efficiency and sacrificed helpfulness. To address these issues, we propose the Explicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and slow reasoning systems to harmonize reliability and usability. The framework first employs a fast-thinking model to generate confidence-labeled responses, enabling immediate utilization of high-confidence outputs, whereas uncertain predictions trigger a slow refinement model for accuracy improvement. To align model behavior with our proposed object, we propose a hybrid training pipeline, enhancing self-awareness without degrading task performance. Evaluations on dialogue state tracking tasks demonstrate that EKBM achieves superior model reliability over uncertainty-based baselines. Further analysis reveals that refinement substantially boosts accuracy while maintaining low computational overhead. The framework establishes a scalable paradigm for deploying reliable LLMs in error-sensitive applications, effectively balancing accuracy and practical utility.
<div id='section'>Paperid: <span id='pid'>344, <a href='https://arxiv.org/pdf/2503.02233.pdf' target='_blank'>https://arxiv.org/pdf/2503.02233.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Zheng, Hongshen Xu, Yuncong Liu, Lu Chen, Pascale Fung, Kai Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.02233">Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) are prone to hallucination stemming from misaligned self-awareness, particularly when processing queries exceeding their knowledge boundaries. While existing mitigation strategies employ uncertainty estimation or query rejection mechanisms, they suffer from computational efficiency and sacrificed helpfulness. To address these issues, we propose the Explicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and slow reasoning systems to harmonize reliability and usability. The framework first employs a fast-thinking model to generate confidence-labeled responses, enabling immediate utilization of high-confidence outputs, whereas uncertain predictions trigger a slow refinement model for accuracy improvement. To align model behavior with our proposed object, we propose a hybrid training pipeline, enhancing self-awareness without degrading task performance. Evaluations on dialogue state tracking tasks demonstrate that EKBM achieves superior model reliability over uncertainty-based baselines. Further analysis reveals that refinement substantially boosts accuracy while maintaining low computational overhead. The framework establishes a scalable paradigm for deploying reliable LLMs in error-sensitive applications, effectively balancing accuracy and practical utility.
<div id='section'>Paperid: <span id='pid'>345, <a href='https://arxiv.org/pdf/2407.02138.pdf' target='_blank'>https://arxiv.org/pdf/2407.02138.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wataru Hashimoto, Hidetaka Kamigaito, Taro Watanabe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02138">Efficient Nearest Neighbor based Uncertainty Estimation for Natural Language Processing Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trustworthiness in model predictions is crucial for safety-critical applications in the real world. However, deep neural networks often suffer from the issues of uncertainty estimation, such as miscalibration. In this study, we propose $k$-Nearest Neighbor Uncertainty Estimation ($k$NN-UE), which is a new uncertainty estimation method that uses not only the distances from the neighbors, but also the ratio of labels in the neighbors. Experiments on sentiment analysis, natural language inference, and named entity recognition show that our proposed method outperforms the baselines and recent density-based methods in several calibration and uncertainty metrics. Moreover, our analyses indicate that approximate nearest neighbor search techniques reduce the inference overhead without significantly degrading the uncertainty estimation performance when they are appropriately combined.
<div id='section'>Paperid: <span id='pid'>346, <a href='https://arxiv.org/pdf/2407.02062.pdf' target='_blank'>https://arxiv.org/pdf/2407.02062.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wataru Hashimoto, Hidetaka Kamigaito, Taro Watanabe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02062">Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work investigates the impact of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks. For the future advance of NER in safety-critical fields like healthcare and finance, it is essential to achieve accurate predictions with calibrated confidence when applying Deep Neural Networks (DNNs), including Pre-trained Language Models (PLMs), as a real-world application. However, DNNs are prone to miscalibration, which limits their applicability. Moreover, existing methods for calibration and uncertainty estimation are computational expensive. Our investigation in NER found that data augmentation improves calibration and uncertainty in cross-genre and cross-lingual setting, especially in-domain setting. Furthermore, we showed that the calibration for NER tends to be more effective when the perplexity of the sentences generated by data augmentation is lower, and that increasing the size of the augmentation further improves calibration and uncertainty.
<div id='section'>Paperid: <span id='pid'>347, <a href='https://arxiv.org/pdf/2309.16831.pdf' target='_blank'>https://arxiv.org/pdf/2309.16831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leonhard F. Feiner, Martin J. Menten, Kerstin Hammernik, Paul Hager, Wenqi Huang, Daniel Rueckert, Rickmer F. Braren, Georgios Kaissis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16831">Propagation and Attribution of Uncertainty in Medical Imaging Pipelines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation, which provides a means of building explainable neural networks for medical imaging applications, have mostly been studied for single deep learning models that focus on a specific task. In this paper, we propose a method to propagate uncertainty through cascades of deep learning models in medical imaging pipelines. This allows us to aggregate the uncertainty in later stages of the pipeline and to obtain a joint uncertainty measure for the predictions of later models. Additionally, we can separately report contributions of the aleatoric, data-based, uncertainty of every component in the pipeline. We demonstrate the utility of our method on a realistic imaging pipeline that reconstructs undersampled brain and knee magnetic resonance (MR) images and subsequently predicts quantitative information from the images, such as the brain volume, or knee side or patient's sex. We quantitatively show that the propagated uncertainty is correlated with input uncertainty and compare the proportions of contributions of pipeline stages to the joint uncertainty measure.
<div id='section'>Paperid: <span id='pid'>348, <a href='https://arxiv.org/pdf/2212.02081.pdf' target='_blank'>https://arxiv.org/pdf/2212.02081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alon Zolfi, Guy Amit, Amit Baras, Satoru Koda, Ikuya Morikawa, Yuval Elovici, Asaf Shabtai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.02081">YolOOD: Utilizing Object Detection Concepts for Multi-Label Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection has attracted a large amount of attention from the machine learning research community in recent years due to its importance in deployed systems. Most of the previous studies focused on the detection of OOD samples in the multi-class classification task. However, OOD detection in the multi-label classification task, a more common real-world use case, remains an underexplored domain. In this research, we propose YolOOD - a method that utilizes concepts from the object detection domain to perform OOD detection in the multi-label classification task. Object detection models have an inherent ability to distinguish between objects of interest (in-distribution) and irrelevant objects (e.g., OOD objects) in images that contain multiple objects belonging to different class categories. These abilities allow us to convert a regular object detection model into an image classifier with inherent OOD detection capabilities with just minor changes. We compare our approach to state-of-the-art OOD detection methods and demonstrate YolOOD's ability to outperform these methods on a comprehensive suite of in-distribution and OOD benchmark datasets.
<div id='section'>Paperid: <span id='pid'>349, <a href='https://arxiv.org/pdf/2211.04215.pdf' target='_blank'>https://arxiv.org/pdf/2211.04215.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangning Li, Yinghui Li, Xi Chen, Hai-Tao Zheng, Ying Shen, Hong-Gee Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.04215">Active Relation Discovery: Towards General and Label-aware Open Relation Extraction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open Relation Extraction (OpenRE) aims to discover novel relations from open domains. Previous OpenRE methods mainly suffer from two problems: (1) Insufficient capacity to discriminate between known and novel relations. When extending conventional test settings to a more general setting where test data might also come from seen classes, existing approaches have a significant performance decline. (2) Secondary labeling must be performed before practical application. Existing methods cannot label human-readable and meaningful types for novel relations, which is urgently required by the downstream tasks. To address these issues, we propose the Active Relation Discovery (ARD) framework, which utilizes relational outlier detection for discriminating known and novel relations and involves active learning for labeling novel relations. Extensive experiments on three real-world datasets show that ARD significantly outperforms previous state-of-the-art methods on both conventional and our proposed general OpenRE settings. The source code and datasets will be available for reproducibility.
<div id='section'>Paperid: <span id='pid'>350, <a href='https://arxiv.org/pdf/2305.18228.pdf' target='_blank'>https://arxiv.org/pdf/2305.18228.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Sun, Andi Zhang, Haiming Zhang, Jinke Ren, Yao Zhu, Ruimao Zhang, Shuguang Cui, Zhen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18228">SR-OOD: Out-of-Distribution Detection via Sample Repairing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a crucial task for ensuring the reliability and robustness of machine learning models. Recent works have shown that generative models often assign high confidence scores to OOD samples, indicating that they fail to capture the semantic information of the data. To tackle this problem, we take advantage of sample repairing and propose a novel OOD detection framework, namely SR-OOD. Our framework leverages the idea that repairing an OOD sample can reveal its semantic inconsistency with the in-distribution data. Specifically, our framework consists of two components: a sample repairing module and a detection module. The sample repairing module applies erosion to an input sample and uses a generative adversarial network to repair it. The detection module then determines whether the input sample is OOD using a distance metric. Our framework does not require any additional data or label information for detection, making it applicable to various scenarios. We conduct extensive experiments on three image datasets: CIFAR-10, CelebA, and Pokemon. The results demonstrate that our approach achieves superior performance over the state-of-the-art generative methods in OOD detection.
<div id='section'>Paperid: <span id='pid'>351, <a href='https://arxiv.org/pdf/2412.01033.pdf' target='_blank'>https://arxiv.org/pdf/2412.01033.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiwei Zhao, Xujiang Zhao, Yanchi Liu, Wei Cheng, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Huaxiu Yao, Haifeng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01033">SAUP: Situation Awareness Uncertainty Propagation on LLM Agent</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) integrated into multistep agent systems enable complex decision-making processes across various applications. However, their outputs often lack reliability, making uncertainty estimation crucial. Existing uncertainty estimation methods primarily focus on final-step outputs, which fail to account for cumulative uncertainty over the multistep decision-making process and the dynamic interactions between agents and their environments. To address these limitations, we propose SAUP (Situation Awareness Uncertainty Propagation), a novel framework that propagates uncertainty through each step of an LLM-based agent's reasoning process. SAUP incorporates situational awareness by assigning situational weights to each step's uncertainty during the propagation. Our method, compatible with various one-step uncertainty estimation techniques, provides a comprehensive and accurate uncertainty measure. Extensive experiments on benchmark datasets demonstrate that SAUP significantly outperforms existing state-of-the-art methods, achieving up to 20% improvement in AUROC.
<div id='section'>Paperid: <span id='pid'>352, <a href='https://arxiv.org/pdf/2411.11254.pdf' target='_blank'>https://arxiv.org/pdf/2411.11254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingming Long, Jie Zhang, Shiguang Shan, Xilin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11254">Semantic or Covariate? A Study on the Intractable Case of Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The primary goal of out-of-distribution (OOD) detection tasks is to identify inputs with semantic shifts, i.e., if samples from novel classes are absent in the in-distribution (ID) dataset used for training, we should reject these OOD samples rather than misclassifying them into existing ID classes. However, we find the current definition of "semantic shift" is ambiguous, which renders certain OOD testing protocols intractable for the post-hoc OOD detection methods based on a classifier trained on the ID dataset. In this paper, we offer a more precise definition of the Semantic Space and the Covariate Space for the ID distribution, allowing us to theoretically analyze which types of OOD distributions make the detection task intractable. To avoid the flaw in the existing OOD settings, we further define the "Tractable OOD" setting which ensures the distinguishability of OOD and ID distributions for the post-hoc OOD detection methods. Finally, we conduct several experiments to demonstrate the necessity of our definitions and validate the correctness of our theorems.
<div id='section'>Paperid: <span id='pid'>353, <a href='https://arxiv.org/pdf/2406.09240.pdf' target='_blank'>https://arxiv.org/pdf/2406.09240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Lin, Muhammad Jehanzeb Mirza, Sivan Doveh, Rogerio Feris, Raja Giryes, Sepp Hochreiter, Leonid Karlinsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09240">Comparison Visual Instruction Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Comparing two images in terms of Commonalities and Differences (CaD) is a fundamental human capability that forms the basis of advanced visual reasoning and interpretation. It is essential for the generation of detailed and contextually relevant descriptions, performing comparative analysis, novelty detection, and making informed decisions based on visual data. However, surprisingly, little attention has been given to these fundamental concepts in the best current mimic of human visual intelligence - Large Multimodal Models (LMMs). We develop and contribute a new two-phase approach CaD-VI for collecting synthetic visual instructions, together with an instruction-following dataset CaD-Inst containing 349K image pairs with CaD instructions collected using CaD-VI. Our approach significantly improves the CaD spotting capabilities in LMMs, advancing the SOTA on a diverse set of related tasks by up to 17.5%. It is also complementary to existing difference-only instruction datasets, allowing automatic targeted refinement of those resources increasing their effectiveness for CaD tuning by up to 10%. Additionally, we propose an evaluation benchmark with 7.5K open-ended QAs to assess the CaD understanding abilities of LMMs.
<div id='section'>Paperid: <span id='pid'>354, <a href='https://arxiv.org/pdf/2403.02628.pdf' target='_blank'>https://arxiv.org/pdf/2403.02628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Biqing Qi, Xingquan Chen, Junqi Gao, Dong Li, Jianxing Liu, Ligang Wu, Bowen Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.02628">Interactive Continual Learning: Fast and Slow Thinking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advanced life forms, sustained by the synergistic interaction of neural cognitive mechanisms, continually acquire and transfer knowledge throughout their lifespan. In contrast, contemporary machine learning paradigms exhibit limitations in emulating the facets of continual learning (CL). Nonetheless, the emergence of large language models (LLMs) presents promising avenues for realizing CL via interactions with these models. Drawing on Complementary Learning System theory, this paper presents a novel Interactive Continual Learning (ICL) framework, enabled by collaborative interactions among models of various sizes. Specifically, we assign the ViT model as System1 and multimodal LLM as System2. To enable the memory module to deduce tasks from class information and enhance Set2Set retrieval, we propose the Class-Knowledge-Task Multi-Head Attention (CKT-MHA). Additionally, to improve memory retrieval in System1 through enhanced geometric representation, we introduce the CL-vMF mechanism, based on the von Mises-Fisher (vMF) distribution. Meanwhile, we introduce the von Mises-Fisher Outlier Detection and Interaction (vMF-ODI) strategy to identify hard examples, thus enhancing collaboration between System1 and System2 for complex reasoning realization. Comprehensive evaluation of our proposed ICL demonstrates significant resistance to forgetting and superior performance relative to existing methods. Code is available at github.com/ICL.
<div id='section'>Paperid: <span id='pid'>355, <a href='https://arxiv.org/pdf/2508.02927.pdf' target='_blank'>https://arxiv.org/pdf/2508.02927.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Srikanth Muralidharan, Heitor R. Medeiros, Masih Aminbeidokhti, Eric Granger, Marco Pedersoli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02927">Infrared Object Detection with Ultra Small ConvNets: Is ImageNet Pretraining Still Useful?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many real-world applications require recognition models that are robust to different operational conditions and modalities, but at the same time run on small embedded devices, with limited hardware. While for normal size models, pre-training is known to be very beneficial in accuracy and robustness, for small models, that can be employed for embedded and edge devices, its effect is not clear. In this work, we investigate the effect of ImageNet pretraining on increasingly small backbone architectures (ultra-small models, with $<$1M parameters) with respect to robustness in downstream object detection tasks in the infrared visual modality. Using scaling laws derived from standard object recognition architectures, we construct two ultra-small backbone families and systematically study their performance. Our experiments on three different datasets reveal that while ImageNet pre-training is still useful, beyond a certain capacity threshold, it offers diminishing returns in terms of out-of-distribution detection robustness. Therefore, we advise practitioners to still use pre-training and, when possible avoid too small models as while they might work well for in-domain problems, they are brittle when working conditions are different.
<div id='section'>Paperid: <span id='pid'>356, <a href='https://arxiv.org/pdf/2312.01732.pdf' target='_blank'>https://arxiv.org/pdf/2312.01732.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fan Lu, Kai Zhu, Kecheng Zheng, Wei Zhai, Yang Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.01732">Likelihood-Aware Semantic Alignment for Full-Spectrum Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Full-spectrum out-of-distribution (F-OOD) detection aims to accurately recognize in-distribution (ID) samples while encountering semantic and covariate shifts simultaneously. However, existing out-of-distribution (OOD) detectors tend to overfit the covariance information and ignore intrinsic semantic correlation, inadequate for adapting to complex domain transformations. To address this issue, we propose a Likelihood-Aware Semantic Alignment (LSA) framework to promote the image-text correspondence into semantically high-likelihood regions. LSA consists of an offline Gaussian sampling strategy which efficiently samples semantic-relevant visual embeddings from the class-conditional Gaussian distribution, and a bidirectional prompt customization mechanism that adjusts both ID-related and negative context for discriminative ID/OOD boundary. Extensive experiments demonstrate the remarkable OOD detection performance of our proposed LSA especially on the intractable Near-OOD setting, surpassing existing methods by a margin of $15.26\%$ and $18.88\%$ on two F-OOD benchmarks, respectively.
<div id='section'>Paperid: <span id='pid'>357, <a href='https://arxiv.org/pdf/2303.10449.pdf' target='_blank'>https://arxiv.org/pdf/2303.10449.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fan Lu, Kai Zhu, Wei Zhai, Kecheng Zheng, Yang Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10449">Uncertainty-Aware Optimal Transport for Semantically Coherent Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantically coherent out-of-distribution (SCOOD) detection aims to discern outliers from the intended data distribution with access to unlabeled extra set. The coexistence of in-distribution and out-of-distribution samples will exacerbate the model overfitting when no distinction is made. To address this problem, we propose a novel uncertainty-aware optimal transport scheme. Our scheme consists of an energy-based transport (ET) mechanism that estimates the fluctuating cost of uncertainty to promote the assignment of semantic-agnostic representation, and an inter-cluster extension strategy that enhances the discrimination of semantic property among different clusters by widening the corresponding margin distance. Furthermore, a T-energy score is presented to mitigate the magnitude gap between the parallel transport and classifier branches. Extensive experiments on two standard SCOOD benchmarks demonstrate the above-par OOD detection performance, outperforming the state-of-the-art methods by a margin of 27.69% and 34.4% on FPR@95, respectively.
<div id='section'>Paperid: <span id='pid'>358, <a href='https://arxiv.org/pdf/2403.04571.pdf' target='_blank'>https://arxiv.org/pdf/2403.04571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yoshua Bengio, Nikolay Malkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04571">Machine learning and information theory concepts towards an AI Mathematician</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The current state-of-the-art in artificial intelligence is impressive, especially in terms of mastery of language, but not so much in terms of mathematical reasoning. What could be missing? Can we learn something useful about that gap from how the brains of mathematicians go about their craft? This essay builds on the idea that current deep learning mostly succeeds at system 1 abilities -- which correspond to our intuition and habitual behaviors -- but still lacks something important regarding system 2 abilities -- which include reasoning and robust uncertainty estimation. It takes an information-theoretical posture to ask questions about what constitutes an interesting mathematical statement, which could guide future work in crafting an AI mathematician. The focus is not on proving a given theorem but on discovering new and interesting conjectures. The central hypothesis is that a desirable body of theorems better summarizes the set of all provable statements, for example by having a small description length while at the same time being close (in terms of number of derivation steps) to many provable statements.
<div id='section'>Paperid: <span id='pid'>359, <a href='https://arxiv.org/pdf/2305.12423.pdf' target='_blank'>https://arxiv.org/pdf/2305.12423.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongru Li, Wentao Yu, Hengtao He, Jiawei Shao, Shenghui Song, Jun Zhang, Khaled B. Letaief
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.12423">Task-Oriented Communication with Out-of-Distribution Detection: An Information Bottleneck Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Task-oriented communication is an emerging paradigm for next-generation communication networks, which extracts and transmits task-relevant information, instead of raw data, for downstream applications. Most existing deep learning (DL)-based task-oriented communication systems adopt a closed-world scenario, assuming either the same data distribution for training and testing, or the system could have access to a large out-of-distribution (OoD) dataset for retraining. However, in practical open-world scenarios, task-oriented communication systems need to handle unknown OoD data. Under such circumstances, the powerful approximation ability of learning methods may force the task-oriented communication systems to overfit the training data (i.e., in-distribution data) and provide overconfident judgments when encountering OoD data. Based on the information bottleneck (IB) framework, we propose a class conditional IB (CCIB) approach to address this problem in this paper, supported by information-theoretical insights. The idea is to extract distinguishable features from in-distribution data while keeping their compactness and informativeness. This is achieved by imposing the class conditional latent prior distribution and enforcing the latent of different classes to be far away from each other. Simulation results shall demonstrate that the proposed approach detects OoD data more efficiently than the baselines and state-of-the-art approaches, without compromising the rate-distortion tradeoff.
<div id='section'>Paperid: <span id='pid'>360, <a href='https://arxiv.org/pdf/2211.15335.pdf' target='_blank'>https://arxiv.org/pdf/2211.15335.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianjin Huang, Tianlong Chen, Meng Fang, Vlado Menkovski, Jiaxu Zhao, Lu Yin, Yulong Pei, Decebal Constantin Mocanu, Zhangyang Wang, Mykola Pechenizkiy, Shiwei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.15335">You Can Have Better Graph Neural Networks by Not Training Weights at All: Finding Untrained GNNs Tickets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent works have impressively demonstrated that there exists a subnetwork in randomly initialized convolutional neural networks (CNNs) that can match the performance of the fully trained dense networks at initialization, without any optimization of the weights of the network (i.e., untrained networks). However, the presence of such untrained subnetworks in graph neural networks (GNNs) still remains mysterious. In this paper we carry out the first-of-its-kind exploration of discovering matching untrained GNNs. With sparsity as the core tool, we can find \textit{untrained sparse subnetworks} at the initialization, that can match the performance of \textit{fully trained dense} GNNs. Besides this already encouraging finding of comparable performance, we show that the found untrained subnetworks can substantially mitigate the GNN over-smoothing problem, hence becoming a powerful tool to enable deeper GNNs without bells and whistles. We also observe that such sparse untrained subnetworks have appealing performance in out-of-distribution detection and robustness of input perturbations. We evaluate our method across widely-used GNN architectures on various popular datasets including the Open Graph Benchmark (OGB).
<div id='section'>Paperid: <span id='pid'>361, <a href='https://arxiv.org/pdf/2506.01116.pdf' target='_blank'>https://arxiv.org/pdf/2506.01116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyi Liu, Lipeng Ma, Yixuan Li, Weidong Yang, Qingyuan Zhou, Jiayi Song, Shuhao Li, Ben Fei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01116">ChemAU: Harness the Reasoning of LLMs in Chemical Research with Adaptive Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are widely used across various scenarios due to their exceptional reasoning capabilities and natural language understanding. While LLMs demonstrate strong performance in tasks involving mathematics and coding, their effectiveness diminishes significantly when applied to chemistry-related problems. Chemistry problems typically involve long and complex reasoning steps, which contain specific terminology, including specialized symbol systems and complex nomenclature conventions. These characteristics often cause general LLMs to experience hallucinations during the reasoning process due to their lack of specific knowledge. However, existing methods are struggling to effectively leverage chemical expertise and formulas. Moreover, current uncertainty estimation methods, designed to mitigate potential reasoning errors, are unable to precisely identify specific steps or key knowledge. In this work, we propose a novel framework called ChemAU, which incorporates our adaptive uncertainty estimation method that applies different uncertainty values based on the position of reasoning steps within the whole reasoning chain. Leveraging this method, ChemAU identifies gaps in chemistry knowledge and precisely supplements chemical expertise with the specialized domain model, thereby correcting and updating the previously flawed reasoning chain. Our experiments with three popular LLMs across three chemistry datasets demonstrate that ChemAU significantly enhances both reasoning accuracy and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>362, <a href='https://arxiv.org/pdf/2504.16136.pdf' target='_blank'>https://arxiv.org/pdf/2504.16136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chiung-Yi Tseng, Junhao Song, Ziqian Bi, Tianyang Wang, Chia Xin Liang, Ming Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16136">Active Learning Methods for Efficient Data Utilization and Model Performance Enhancement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the era of data-driven intelligence, the paradox of data abundance and annotation scarcity has emerged as a critical bottleneck in the advancement of machine learning. This paper gives a detailed overview of Active Learning (AL), which is a strategy in machine learning that helps models achieve better performance using fewer labeled examples. It introduces the basic concepts of AL and discusses how it is used in various fields such as computer vision, natural language processing, transfer learning, and real-world applications. The paper focuses on important research topics such as uncertainty estimation, handling of class imbalance, domain adaptation, fairness, and the creation of strong evaluation metrics and benchmarks. It also shows that learning methods inspired by humans and guided by questions can improve data efficiency and help models learn more effectively. In addition, this paper talks about current challenges in the field, including the need to rebuild trust, ensure reproducibility, and deal with inconsistent methodologies. It points out that AL often gives better results than passive learning, especially when good evaluation measures are used. This work aims to be useful for both researchers and practitioners by providing key insights and proposing directions for future progress in active learning.
<div id='section'>Paperid: <span id='pid'>363, <a href='https://arxiv.org/pdf/2501.11031.pdf' target='_blank'>https://arxiv.org/pdf/2501.11031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lipeng Ma, Weidong Yang, Yixuan Li, Ben Fei, Mingjie Zhou, Shuhao Li, Sihang Jiang, Bo Xu, Yanghua Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11031">AdaptiveLog: An Adaptive Log Analysis Framework with the Collaboration of Large and Small Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated log analysis is crucial to ensure high availability and reliability of complex systems. The advent of LLMs in NLP has ushered in a new era of language model-driven automated log analysis, garnering significant interest. Within this field, two primary paradigms based on language models for log analysis have become prominent. Small Language Models (SLMs) follow the pre-train and fine-tune paradigm, focusing on the specific log analysis task through fine-tuning on supervised datasets. On the other hand, LLMs following the in-context learning paradigm, analyze logs by providing a few examples in prompt contexts without updating parameters. Despite their respective strengths, we notice that SLMs are more cost-effective but less powerful, whereas LLMs with large parameters are highly powerful but expensive and inefficient. To trade-off between the performance and inference costs of both models in automated log analysis, this paper introduces an adaptive log analysis framework known as AdaptiveLog, which effectively reduces the costs associated with LLM while ensuring superior results. This framework collaborates an LLM and a small language model, strategically allocating the LLM to tackle complex logs while delegating simpler logs to the SLM. Specifically, to efficiently query the LLM, we propose an adaptive selection strategy based on the uncertainty estimation of the SLM, where the LLM is invoked only when the SLM is uncertain. In addition, to enhance the reasoning ability of the LLM in log analysis tasks, we propose a novel prompt strategy by retrieving similar error-prone cases as the reference, enabling the model to leverage past error experiences and learn solutions from these cases. Extensive experiments demonstrate that AdaptiveLog achieves state-of-the-art results across different tasks, elevating the overall accuracy of log analysis while maintaining cost efficiency.
<div id='section'>Paperid: <span id='pid'>364, <a href='https://arxiv.org/pdf/2407.21497.pdf' target='_blank'>https://arxiv.org/pdf/2407.21497.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Liu, Xiliang Zhu, Tong Han, Yuhao Huang, Jian Wang, Lian Liu, Fang Wang, Dong Ni, Zhongshan Gou, Xin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21497">Mitral Regurgitation Recognition based on Unsupervised Out-of-Distribution Detection with Residual Diffusion Amplification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mitral regurgitation (MR) is a serious heart valve disease. Early and accurate diagnosis of MR via ultrasound video is critical for timely clinical decision-making and surgical intervention. However, manual MR diagnosis heavily relies on the operator's experience, which may cause misdiagnosis and inter-observer variability. Since MR data is limited and has large intra-class variability, we propose an unsupervised out-of-distribution (OOD) detection method to identify MR rather than building a deep classifier. To our knowledge, we are the first to explore OOD in MR ultrasound videos. Our method consists of a feature extractor, a feature reconstruction model, and a residual accumulation amplification algorithm. The feature extractor obtains features from the video clips and feeds them into the feature reconstruction model to restore the original features. The residual accumulation amplification algorithm then iteratively performs noise feature reconstruction, amplifying the reconstructed error of OOD features. This algorithm is straightforward yet efficient and can seamlessly integrate as a plug-and-play component in reconstruction-based OOD detection methods. We validated the proposed method on a large ultrasound dataset containing 893 non-MR and 267 MR videos. Experimental results show that our OOD detection method can effectively identify MR samples.
<div id='section'>Paperid: <span id='pid'>365, <a href='https://arxiv.org/pdf/2311.16420.pdf' target='_blank'>https://arxiv.org/pdf/2311.16420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>YiFan Zhang, Xue Wang, Tian Zhou, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16420">Model-free Test Time Adaptation for Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for the reliability of ML models. Most existing methods for OOD detection learn a fixed decision criterion from a given in-distribution dataset and apply it universally to decide if a data point is OOD. Recent work~\cite{fang2022is} shows that given only in-distribution data, it is impossible to reliably detect OOD data without extra assumptions. Motivated by the theoretical result and recent exploration of test-time adaptation methods, we propose a Non-Parametric Test Time \textbf{Ada}ptation framework for \textbf{O}ut-Of-\textbf{D}istribution \textbf{D}etection (\abbr). Unlike conventional methods, \abbr utilizes online test samples for model adaptation during testing, enhancing adaptability to changing data distributions. The framework incorporates detected OOD instances into decision-making, reducing false positive rates, particularly when ID and OOD distributions overlap significantly. We demonstrate the effectiveness of \abbr through comprehensive experiments on multiple OOD detection benchmarks, extensive empirical studies show that \abbr significantly improves the performance of OOD detection over state-of-the-art methods. Specifically, \abbr reduces the false positive rate (FPR95) by $23.23\%$ on the CIFAR-10 benchmarks and $38\%$ on the ImageNet-1k benchmarks compared to the advanced methods. Lastly, we theoretically verify the effectiveness of \abbr.
<div id='section'>Paperid: <span id='pid'>366, <a href='https://arxiv.org/pdf/2311.12084.pdf' target='_blank'>https://arxiv.org/pdf/2311.12084.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nandish Chattopadhyay, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12084">ODDR: Outlier Detection & Dimension Reduction Based Defense Against Adversarial Patches</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adversarial attacks present a significant challenge to the dependable deployment of machine learning models, with patch-based attacks being particularly potent. These attacks introduce adversarial perturbations in localized regions of an image, deceiving even well-trained models. In this paper, we propose Outlier Detection and Dimension Reduction (ODDR), a comprehensive defense strategy engineered to counteract patch-based adversarial attacks through advanced statistical methodologies. Our approach is based on the observation that input features corresponding to adversarial patches-whether naturalistic or synthetic-deviate from the intrinsic distribution of the remaining image data and can thus be identified as outliers. ODDR operates through a robust three-stage pipeline: Fragmentation, Segregation, and Neutralization. This model-agnostic framework is versatile, offering protection across various tasks, including image classification, object detection, and depth estimation, and is proved effective in both CNN-based and Transformer-based architectures. In the Fragmentation stage, image samples are divided into smaller segments, preparing them for the Segregation stage, where advanced outlier detection techniques isolate anomalous features linked to adversarial perturbations. The Neutralization stage then applies dimension reduction techniques to these outliers, effectively neutralizing the adversarial impact while preserving critical information for the machine learning task. Extensive evaluation on benchmark datasets against state-of-the-art adversarial patches underscores the efficacy of ODDR. Our method enhances model accuracy from 39.26% to 79.1% under the GoogleAp attack, outperforming leading defenses such as LGS (53.86%), Jujutsu (60%), and Jedi (64.34%).
<div id='section'>Paperid: <span id='pid'>367, <a href='https://arxiv.org/pdf/2303.17783.pdf' target='_blank'>https://arxiv.org/pdf/2303.17783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuang Ai, Xiaoqiang Zhou, Huaibo Huang, Lei Zhang, Ran He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.17783">Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised Domain Adaptation (UDA) can effectively address domain gap issues in real-world image Super-Resolution (SR) by accessing both the source and target data. Considering privacy policies or transmission restrictions of source data in practical scenarios, we propose a SOurce-free Domain Adaptation framework for image SR (SODA-SR) to address this issue, i.e., adapt a source-trained model to a target domain with only unlabeled target data. SODA-SR leverages the source-trained model to generate refined pseudo-labels for teacher-student learning. To better utilize pseudo-labels, we propose a novel wavelet-based augmentation method, named Wavelet Augmentation Transformer (WAT), which can be flexibly incorporated with existing networks, to implicitly produce useful augmented data. WAT learns low-frequency information of varying levels across diverse samples, which is aggregated efficiently via deformable attention. Furthermore, an uncertainty-aware self-training mechanism is proposed to improve the accuracy of pseudo-labels, with inaccurate predictions being rectified by uncertainty estimation. To acquire better SR results and avoid overfitting pseudo-labels, several regularization losses are proposed to constrain target LR and SR images in the frequency domain. Experiments show that without accessing source data, SODA-SR outperforms state-of-the-art UDA methods in both synthetic$\rightarrow$real and real$\rightarrow$real adaptation settings, and is not constrained by specific network architectures.
<div id='section'>Paperid: <span id='pid'>368, <a href='https://arxiv.org/pdf/2411.01893.pdf' target='_blank'>https://arxiv.org/pdf/2411.01893.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yitong Dong, Yijin Li, Zhaoyang Huang, Weikang Bian, Jingbo Liu, Hujun Bao, Zhaopeng Cui, Hongsheng Li, Guofeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01893">A Global Depth-Range-Free Multi-View Stereo Transformer Network with Pose Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel multi-view stereo (MVS) framework that gets rid of the depth range prior. Unlike recent prior-free MVS methods that work in a pair-wise manner, our method simultaneously considers all the source images. Specifically, we introduce a Multi-view Disparity Attention (MDA) module to aggregate long-range context information within and across multi-view images. Considering the asymmetry of the epipolar disparity flow, the key to our method lies in accurately modeling multi-view geometric constraints. We integrate pose embedding to encapsulate information such as multi-view camera poses, providing implicit geometric constraints for multi-view disparity feature fusion dominated by attention. Additionally, we construct corresponding hidden states for each source image due to significant differences in the observation quality of the same pixel in the reference frame across multiple source frames. We explicitly estimate the quality of the current pixel corresponding to sampled points on the epipolar line of the source image and dynamically update hidden states through the uncertainty estimation module. Extensive results on the DTU dataset and Tanks&Temple benchmark demonstrate the effectiveness of our method. The code is available at our project page: https://zju3dv.github.io/GD-PoseMVS/.
<div id='section'>Paperid: <span id='pid'>369, <a href='https://arxiv.org/pdf/2406.02635.pdf' target='_blank'>https://arxiv.org/pdf/2406.02635.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Ragab, Peiliang Gong, Emadeldeen Eldele, Wenyu Zhang, Min Wu, Chuan-Sheng Foo, Daoqiang Zhang, Xiaoli Li, Zhenghua Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02635">Evidentially Calibrated Source-Free Time-Series Domain Adaptation with Temporal Imputation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Source-free domain adaptation (SFDA) aims to adapt a model pre-trained on a labeled source domain to an unlabeled target domain without access to source data, preserving the source domain's privacy. While SFDA is prevalent in computer vision, it remains largely unexplored in time series analysis. Existing SFDA methods, designed for visual data, struggle to capture the inherent temporal dynamics of time series, hindering adaptation performance. This paper proposes MAsk And imPUte (MAPU), a novel and effective approach for time series SFDA. MAPU addresses the critical challenge of temporal consistency by introducing a novel temporal imputation task. This task involves randomly masking time series signals and leveraging a dedicated temporal imputer to recover the original signal within the learned embedding space, bypassing the complexities of noisy raw data. Notably, MAPU is the first method to explicitly address temporal consistency in the context of time series SFDA. Additionally, it offers seamless integration with existing SFDA methods, providing greater flexibility. We further introduce E-MAPU, which incorporates evidential uncertainty estimation to address the overconfidence issue inherent in softmax predictions. To achieve that, we leverage evidential deep learning to obtain a better-calibrated pre-trained model and adapt the target encoder to map out-of-support target samples to a new feature representation closer to the source domain's support. This fosters better alignment, ultimately enhancing adaptation performance. Extensive experiments on five real-world time series datasets demonstrate that both MAPU and E-MAPU achieve significant performance gains compared to existing methods. These results highlight the effectiveness of our proposed approaches for tackling various time series domain adaptation problems.
<div id='section'>Paperid: <span id='pid'>370, <a href='https://arxiv.org/pdf/2406.00345.pdf' target='_blank'>https://arxiv.org/pdf/2406.00345.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhi Zhou, Ming Yang, Jiang-Xin Shi, Lan-Zhe Guo, Yu-Feng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00345">DeCoOp: Robust Prompt Tuning with Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs), such as CLIP, have demonstrated impressive zero-shot capabilities for various downstream tasks. Their performance can be further enhanced through few-shot prompt tuning methods. However, current studies evaluate the performance of learned prompts separately on base and new classes. This evaluation lacks practicality for real-world applications since downstream tasks cannot determine whether the data belongs to base or new classes in advance. In this paper, we explore a problem setting called Open-world Prompt Tuning (OPT), which involves tuning prompts on base classes and evaluating on a combination of base and new classes. By introducing Decomposed Prompt Tuning framework (DePT), we theoretically demonstrate that OPT can be solved by incorporating out-of-distribution detection into prompt tuning, thereby enhancing the base-to-new discriminability. Based on DePT, we present a novel prompt tuning approach, namely, Decomposed Context Optimization (DeCoOp), which introduces new-class detectors and sub-classifiers to further enhance the base-class and new-class discriminability. Experimental results on 11 benchmark datasets validate the effectiveness of DePT and demonstrate that DeCoOp outperforms current state-of-the-art methods, providing a significant 2% average accuracy improvement.
<div id='section'>Paperid: <span id='pid'>371, <a href='https://arxiv.org/pdf/2404.07580.pdf' target='_blank'>https://arxiv.org/pdf/2404.07580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinhong Wang, Yi Cheng, Jintai Chen, Hongxia Xu, Danny Chen, Jian Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07580">Multi-rater Prompting for Ambiguous Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-rater annotations commonly occur when medical images are independently annotated by multiple experts (raters). In this paper, we tackle two challenges arisen in multi-rater annotations for medical image segmentation (called ambiguous medical image segmentation): (1) How to train a deep learning model when a group of raters produces a set of diverse but plausible annotations, and (2) how to fine-tune the model efficiently when computation resources are not available for re-training the entire model on a different dataset domain. We propose a multi-rater prompt-based approach to address these two challenges altogether. Specifically, we introduce a series of rater-aware prompts that can be plugged into the U-Net model for uncertainty estimation to handle multi-annotation cases. During the prompt-based fine-tuning process, only 0.3% of learnable parameters are required to be updated comparing to training the entire model. Further, in order to integrate expert consensus and disagreement, we explore different multi-rater incorporation strategies and design a mix-training strategy for comprehensive insight learning. Extensive experiments verify the effectiveness of our new approach for ambiguous medical image segmentation on two public datasets while alleviating the heavy burden of model re-training.
<div id='section'>Paperid: <span id='pid'>372, <a href='https://arxiv.org/pdf/2505.23811.pdf' target='_blank'>https://arxiv.org/pdf/2505.23811.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hadi Askari, Shivanshu Gupta, Fei Wang, Anshuman Chhabra, Muhao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23811">LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pretrained Large Language Models (LLMs) achieve strong performance across a wide range of tasks, yet exhibit substantial variability in the various layers' training quality with respect to specific downstream applications, limiting their downstream performance. It is therefore critical to estimate layer-wise training quality in a manner that accounts for both model architecture and training data. However, existing approaches predominantly rely on model-centric heuristics (such as spectral statistics, outlier detection, or uniform allocation) while overlooking the influence of data. To address these limitations, we propose LayerIF, a data-driven framework that leverages Influence Functions to quantify the training quality of individual layers in a principled and task-sensitive manner. By isolating each layer's gradients and measuring the sensitivity of the validation loss to training examples by computing layer-wise influences, we derive data-driven estimates of layer importance. Notably, our method produces task-specific layer importance estimates for the same LLM, revealing how layers specialize for different test-time evaluation tasks. We demonstrate the utility of our scores by leveraging them for two downstream applications: (a) expert allocation in LoRA-MoE architectures and (b) layer-wise sparsity distribution for LLM pruning. Experiments across multiple LLM architectures demonstrate that our model-agnostic, influence-guided allocation leads to consistent gains in task performance.
<div id='section'>Paperid: <span id='pid'>373, <a href='https://arxiv.org/pdf/2411.05791.pdf' target='_blank'>https://arxiv.org/pdf/2411.05791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Divo, Eric Endress, Kevin Endler, Kristian Kersting, Devendra Singh Dhami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05791">Forecasting Company Fundamentals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Company fundamentals are key to assessing companies' financial and overall success and stability. Forecasting them is important in multiple fields, including investing and econometrics. While statistical and contemporary machine learning methods have been applied to many time series tasks, there is a lack of comparison of these approaches on this particularly challenging data regime. To this end, we try to bridge this gap and thoroughly evaluate the theoretical properties and practical performance of 24 deterministic and probabilistic company fundamentals forecasting models on real company data. We observe that deep learning models provide superior forecasting performance to classical models, in particular when considering uncertainty estimation. To validate the findings, we compare them to human analyst expectations and find that their accuracy is comparable to the automatic forecasts. We further show how these high-quality forecasts can benefit automated stock allocation. We close by presenting possible ways of integrating domain experts to further improve performance and increase reliability.
<div id='section'>Paperid: <span id='pid'>374, <a href='https://arxiv.org/pdf/2301.00349.pdf' target='_blank'>https://arxiv.org/pdf/2301.00349.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ke Zou, Yidi Chen, Ling Huang, Xuedong Yuan, Xiaojing Shen, Meng Wang, Rick Siow Mong Goh, Yong Liu, Huazhu Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00349">Towards Reliable Medical Image Segmentation by Modeling Evidential Calibrated Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical image segmentation is critical for disease diagnosis and treatment assessment. However, concerns regarding the reliability of segmentation regions persist among clinicians, mainly attributed to the absence of confidence assessment, robustness, and calibration to accuracy. To address this, we introduce DEviS, an easily implementable foundational model that seamlessly integrates into various medical image segmentation networks. DEviS not only enhances the calibration and robustness of baseline segmentation accuracy but also provides high-efficiency uncertainty estimation for reliable predictions. By leveraging subjective logic theory, we explicitly model probability and uncertainty for medical image segmentation. Here, the Dirichlet distribution parameterizes the distribution of probabilities for different classes of the segmentation results. To generate calibrated predictions and uncertainty, we develop a trainable calibrated uncertainty penalty. Furthermore, DEviS incorporates an uncertainty-aware filtering module, which designs the metric of uncertainty-calibrated error to filter out-of-distribution data. We conducted validation studies on publicly available datasets, including ISIC2018, KiTS2021, LiTS2017, and BraTS2019, to assess the accuracy and robustness of different backbone segmentation models enhanced by DEviS, as well as the efficiency and reliability of uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>375, <a href='https://arxiv.org/pdf/2503.20462.pdf' target='_blank'>https://arxiv.org/pdf/2503.20462.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruoqi Wen, Rongpeng Li, Xing Xu, Zhifeng Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20462">Multi-agent Uncertainty-Aware Pessimistic Model-Based Reinforcement Learning for Connected Autonomous Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Reinforcement Learning (DRL) holds significant promise for achieving human-like Autonomous Vehicle (AV) capabilities, but suffers from low sample efficiency and challenges in reward design. Model-Based Reinforcement Learning (MBRL) offers improved sample efficiency and generalizability compared to Model-Free Reinforcement Learning (MFRL) in various multi-agent decision-making scenarios. Nevertheless, MBRL faces critical difficulties in estimating uncertainty during the model learning phase, thereby limiting its scalability and applicability in real-world scenarios. Additionally, most Connected Autonomous Vehicle (CAV) studies focus on single-agent decision-making, while existing multi-agent MBRL solutions lack computationally tractable algorithms with Probably Approximately Correct (PAC) guarantees, an essential factor for ensuring policy reliability with limited training data. To address these challenges, we propose MA-PMBRL, a novel Multi-Agent Pessimistic Model-Based Reinforcement Learning framework for CAVs, incorporating a max-min optimization approach to enhance robustness and decision-making. To mitigate the inherent subjectivity of uncertainty estimation in MBRL and avoid incurring catastrophic failures in AV, MA-PMBRL employs a pessimistic optimization framework combined with Projected Gradient Descent (PGD) for both model and policy learning. MA-PMBRL also employs general function approximations under partial dataset coverage to enhance learning efficiency and system-level performance. By bounding the suboptimality of the resulting policy under mild theoretical assumptions, we successfully establish PAC guarantees for MA-PMBRL, demonstrating that the proposed framework represents a significant step toward scalable, efficient, and reliable multi-agent decision-making for CAVs.
<div id='section'>Paperid: <span id='pid'>376, <a href='https://arxiv.org/pdf/2406.01975.pdf' target='_blank'>https://arxiv.org/pdf/2406.01975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Fu, Tunhou Zhang, Hai Li, Yiran Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01975">Can Dense Connectivity Benefit Outlier Detection? An Odyssey with NAS</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in Out-of-Distribution (OOD) Detection is the driving force behind safe and reliable deployment of Convolutional Neural Networks (CNNs) in real world applications. However, existing studies focus on OOD detection through confidence score and deep generative model-based methods, without considering the impact of DNN structures, especially dense connectivity in architecture fabrications. In addition, existing outlier detection approaches exhibit high variance in generalization performance, lacking stability and confidence in evaluating and ranking different outlier detectors. In this work, we propose a novel paradigm, Dense Connectivity Search of Outlier Detector (DCSOD), that automatically explore the dense connectivity of CNN architectures on near-OOD detection task using Neural Architecture Search (NAS). We introduce a hierarchical search space containing versatile convolution operators and dense connectivity, allowing a flexible exploration of CNN architectures with diverse connectivity patterns. To improve the quality of evaluation on OOD detection during search, we propose evolving distillation based on our multi-view feature learning explanation. Evolving distillation stabilizes training for OOD detection evaluation, thus improves the quality of search. We thoroughly examine DCSOD on CIFAR benchmarks under OOD detection protocol. Experimental results show that DCSOD achieve remarkable performance over widely used architectures and previous NAS baselines. Notably, DCSOD achieves state-of-the-art (SOTA) performance on CIFAR benchmark, with AUROC improvement of $\sim$1.0%.
<div id='section'>Paperid: <span id='pid'>377, <a href='https://arxiv.org/pdf/2503.08162.pdf' target='_blank'>https://arxiv.org/pdf/2503.08162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kangan Qian, Ziang Luo, Sicong Jiang, Zilin Huang, Jinyu Miao, Zhikun Ma, Tianze Zhu, Jiayin Li, Yangfan He, Zheng Fu, Yining Shi, Boyue Wang, Hezhe Lin, Ziyu Chen, Jiangbo Yu, Xinyu Jiao, Mengmeng Yang, Kun Jiang, Diange Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08162">FASIONAD++ : Integrating High-Level Instruction and Information Bottleneck in FAt-Slow fusION Systems for Enhanced Safety in Autonomous Driving with Adaptive Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensuring safe, comfortable, and efficient planning is crucial for autonomous driving systems. While end-to-end models trained on large datasets perform well in standard driving scenarios, they struggle with complex low-frequency events. Recent Large Language Models (LLMs) and Vision Language Models (VLMs) advancements offer enhanced reasoning but suffer from computational inefficiency. Inspired by the dual-process cognitive model "Thinking, Fast and Slow", we propose $\textbf{FASIONAD}$ -- a novel dual-system framework that synergizes a fast end-to-end planner with a VLM-based reasoning module. The fast system leverages end-to-end learning to achieve real-time trajectory generation in common scenarios, while the slow system activates through uncertainty estimation to perform contextual analysis and complex scenario resolution. Our architecture introduces three key innovations: (1) A dynamic switching mechanism enabling slow system intervention based on real-time uncertainty assessment; (2) An information bottleneck with high-level plan feedback that optimizes the slow system's guidance capability; (3) A bidirectional knowledge exchange where visual prompts enhance the slow system's reasoning while its feedback refines the fast planner's decision-making. To strengthen VLM reasoning, we develop a question-answering mechanism coupled with reward-instruct training strategy. In open-loop experiments, FASIONAD achieves a $6.7\%$ reduction in average $L2$ trajectory error and $28.1\%$ lower collision rate.
<div id='section'>Paperid: <span id='pid'>378, <a href='https://arxiv.org/pdf/2303.02378.pdf' target='_blank'>https://arxiv.org/pdf/2303.02378.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amarildo Likmeta, Matteo Sacco, Alberto Maria Metelli, Marcello Restelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02378">Wasserstein Actor-Critic: Directed Exploration via Optimism for Continuous-Actions Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification has been extensively used as a means to achieve efficient directed exploration in Reinforcement Learning (RL). However, state-of-the-art methods for continuous actions still suffer from high sample complexity requirements. Indeed, they either completely lack strategies for propagating the epistemic uncertainty throughout the updates, or they mix it with aleatoric uncertainty while learning the full return distribution (e.g., distributional RL). In this paper, we propose Wasserstein Actor-Critic (WAC), an actor-critic architecture inspired by the recent Wasserstein Q-Learning (WQL) \citep{wql}, that employs approximate Q-posteriors to represent the epistemic uncertainty and Wasserstein barycenters for uncertainty propagation across the state-action space. WAC enforces exploration in a principled way by guiding the policy learning process with the optimization of an upper bound of the Q-value estimates. Furthermore, we study some peculiar issues that arise when using function approximation, coupled with the uncertainty estimation, and propose a regularized loss for the uncertainty estimation. Finally, we evaluate our algorithm on standard MujoCo tasks as well as suite of continuous-actions domains, where exploration is crucial, in comparison with state-of-the-art baselines.
<div id='section'>Paperid: <span id='pid'>379, <a href='https://arxiv.org/pdf/2503.18363.pdf' target='_blank'>https://arxiv.org/pdf/2503.18363.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenyuan Zhang, Yixiao Yang, Han Huang, Liang Han, Kanle Shi, Yu-Shen Liu, Zhizhong Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18363">MonoInstance: Enhancing Monocular Priors via Multi-view Instance Alignment for Neural Rendering and Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monocular depth priors have been widely adopted by neural rendering in multi-view based tasks such as 3D reconstruction and novel view synthesis. However, due to the inconsistent prediction on each view, how to more effectively leverage monocular cues in a multi-view context remains a challenge. Current methods treat the entire estimated depth map indiscriminately, and use it as ground truth supervision, while ignoring the inherent inaccuracy and cross-view inconsistency in monocular priors. To resolve these issues, we propose MonoInstance, a general approach that explores the uncertainty of monocular depths to provide enhanced geometric priors for neural rendering and reconstruction. Our key insight lies in aligning each segmented instance depths from multiple views within a common 3D space, thereby casting the uncertainty estimation of monocular depths into a density measure within noisy point clouds. For high-uncertainty areas where depth priors are unreliable, we further introduce a constraint term that encourages the projected instances to align with corresponding instance masks on nearby views. MonoInstance is a versatile strategy which can be seamlessly integrated into various multi-view neural rendering frameworks. Our experimental results demonstrate that MonoInstance significantly improves the performance in both reconstruction and novel view synthesis under various benchmarks.
<div id='section'>Paperid: <span id='pid'>380, <a href='https://arxiv.org/pdf/2410.11236.pdf' target='_blank'>https://arxiv.org/pdf/2410.11236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guiyu Zhang, Huan-ang Gao, Zijian Jiang, Hao Zhao, Zhedong Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.11236">Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we focus on the task of conditional image generation, where an image is synthesized according to user instructions. The critical challenge underpinning this task is ensuring both the fidelity of the generated images and their semantic alignment with the provided conditions. To tackle this issue, previous studies have employed supervised perceptual losses derived from pre-trained models, i.e., reward models, to enforce alignment between the condition and the generated result. However, we observe one inherent shortcoming: considering the diversity of synthesized images, the reward model usually provides inaccurate feedback when encountering newly generated data, which can undermine the training process. To address this limitation, we propose an uncertainty-aware reward modeling, called Ctrl-U, including uncertainty estimation and uncertainty-aware regularization, designed to reduce the adverse effects of imprecise feedback from the reward model. Given the inherent cognitive uncertainty within reward models, even images generated under identical conditions often result in a relatively large discrepancy in reward loss. Inspired by the observation, we explicitly leverage such prediction variance as an uncertainty indicator. Based on the uncertainty estimation, we regularize the model training by adaptively rectifying the reward. In particular, rewards with lower uncertainty receive higher loss weights, while those with higher uncertainty are given reduced weights to allow for larger variability. The proposed uncertainty regularization facilitates reward fine-tuning through consistency construction. Extensive experiments validate the effectiveness of our methodology in improving the controllability and generation quality, as well as its scalability across diverse conditional scenarios. Codes are publicly available at https://grenoble-zhang.github.io/Ctrl-U-Page/.
<div id='section'>Paperid: <span id='pid'>381, <a href='https://arxiv.org/pdf/2508.14496.pdf' target='_blank'>https://arxiv.org/pdf/2508.14496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huan Ma, Jiadong Pan, Jing Liu, Yan Chen, Joey Tianyi Zhou, Guangyu Wang, Qinghua Hu, Hua Wu, Changqing Zhang, Haifeng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14496">Semantic Energy: Detecting LLM Hallucination Beyond Entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are being increasingly deployed in real-world applications, but they remain susceptible to hallucinations, which produce fluent yet incorrect responses and lead to erroneous decision-making. Uncertainty estimation is a feasible approach to detect such hallucinations. For example, semantic entropy estimates uncertainty by considering the semantic diversity across multiple sampled responses, thus identifying hallucinations. However, semantic entropy relies on post-softmax probabilities and fails to capture the model's inherent uncertainty, causing it to be ineffective in certain scenarios. To address this issue, we introduce Semantic Energy, a novel uncertainty estimation framework that leverages the inherent confidence of LLMs by operating directly on logits of penultimate layer. By combining semantic clustering with a Boltzmann-inspired energy distribution, our method better captures uncertainty in cases where semantic entropy fails. Experiments across multiple benchmarks show that Semantic Energy significantly improves hallucination detection and uncertainty estimation, offering more reliable signals for downstream applications such as hallucination detection.
<div id='section'>Paperid: <span id='pid'>382, <a href='https://arxiv.org/pdf/2409.17286.pdf' target='_blank'>https://arxiv.org/pdf/2409.17286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael E. Kim, Chenyu Gao, Karthik Ramadass, Praitayini Kanakaraj, Nancy R. Newlin, Gaurav Rudravaram, Kurt G. Schilling, Blake E. Dewey, David A. Bennett, Sid OBryant, Robert C. Barber, Derek Archer, Timothy J. Hohman, Shunxing Bao, Zhiyuan Li, Bennett A. Landman, Nazirah Mohd Khairi, The Alzheimers Disease Neuroimaging Initiative, The HABSHD Study Team
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17286">Scalable quality control on processing of large diffusion-weighted and structural magnetic resonance imaging datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proper quality control (QC) is time consuming when working with large-scale medical imaging datasets, yet necessary, as poor-quality data can lead to erroneous conclusions or poorly trained machine learning models. Most efforts to reduce data QC time rely on outlier detection, which cannot capture every instance of algorithm failure. Thus, there is a need to visually inspect every output of data processing pipelines in a scalable manner. We design a QC pipeline that allows for low time cost and effort across a team setting for a large database of diffusion weighted and structural magnetic resonance images. Our proposed method satisfies the following design criteria: 1.) a consistent way to perform and manage quality control across a team of researchers, 2.) quick visualization of preprocessed data that minimizes the effort and time spent on the QC process without compromising the condition or caliber of the QC, and 3.) a way to aggregate QC results across pipelines and datasets that can be easily shared. In addition to meeting these design criteria, we also provide information on what a successful output should be and common occurrences of algorithm failures for various processing pipelines. Our method reduces the time spent on QC by a factor of over 20 when compared to naively opening outputs in an image viewer and demonstrate how it can facilitate aggregation and sharing of QC results within a team. While researchers must spend time on robust visual QC of data, there are mechanisms by which the process can be streamlined and efficient.
<div id='section'>Paperid: <span id='pid'>383, <a href='https://arxiv.org/pdf/2409.07020.pdf' target='_blank'>https://arxiv.org/pdf/2409.07020.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenjun Li, Dian Yang, Shun Yao, Shuyue Wang, Ye Wu, Le Zhang, Qiannuo Li, Kang Ik Kevin Cho, Johanna Seitz-Holland, Lipeng Ning, Jon Haitz Legarreta, Yogesh Rathi, Carl-Fredrik Westin, Lauren J. O'Donnell, Nir A. Sochen, Ofer Pasternak, Fan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07020">DDEvENet: Evidence-based Ensemble Learning for Uncertainty-aware Brain Parcellation Using Diffusion MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we developed an Evidence-based Ensemble Neural Network, namely EVENet, for anatomical brain parcellation using diffusion MRI. The key innovation of EVENet is the design of an evidential deep learning framework to quantify predictive uncertainty at each voxel during a single inference. To do so, we design an evidence-based ensemble learning framework for uncertainty-aware parcellation to leverage the multiple dMRI parameters derived from diffusion MRI. Using EVENet, we obtained accurate parcellation and uncertainty estimates across different datasets from healthy and clinical populations and with different imaging acquisitions. The overall network includes five parallel subnetworks, where each is dedicated to learning the FreeSurfer parcellation for a certain diffusion MRI parameter. An evidence-based ensemble methodology is then proposed to fuse the individual outputs. We perform experimental evaluations on large-scale datasets from multiple imaging sources, including high-quality diffusion MRI data from healthy adults and clinically diffusion MRI data from participants with various brain diseases (schizophrenia, bipolar disorder, attention-deficit/hyperactivity disorder, Parkinson's disease, cerebral small vessel disease, and neurosurgical patients with brain tumors). Compared to several state-of-the-art methods, our experimental results demonstrate highly improved parcellation accuracy across the multiple testing datasets despite the differences in dMRI acquisition protocols and health conditions. Furthermore, thanks to the uncertainty estimation, our EVENet approach demonstrates a good ability to detect abnormal brain regions in patients with lesions, enhancing the interpretability and reliability of the segmentation results.
<div id='section'>Paperid: <span id='pid'>384, <a href='https://arxiv.org/pdf/2304.10127.pdf' target='_blank'>https://arxiv.org/pdf/2304.10127.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peng Cui, Dan Zhang, Zhijie Deng, Yinpeng Dong, Jun Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10127">Learning Sample Difficulty from Pre-trained Models for Reliable Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large-scale pre-trained models have achieved remarkable success in many applications, but how to leverage them to improve the prediction reliability of downstream models is undesirably under-explored. Moreover, modern neural networks have been found to be poorly calibrated and make overconfident predictions regardless of inherent sample difficulty and data uncertainty. To address this issue, we propose to utilize large-scale pre-trained models to guide downstream model training with sample difficulty-aware entropy regularization. Pre-trained models that have been exposed to large-scale datasets and do not overfit the downstream training classes enable us to measure each training sample's difficulty via feature-space Gaussian modeling and relative Mahalanobis distance computation. Importantly, by adaptively penalizing overconfident prediction based on the sample difficulty, we simultaneously improve accuracy and uncertainty calibration across challenging benchmarks (e.g., +0.55% ACC and -3.7% ECE on ImageNet1k using ResNet34), consistently surpassing competitive baselines for reliable prediction. The improved uncertainty estimate further improves selective classification (abstaining from erroneous predictions) and out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>385, <a href='https://arxiv.org/pdf/2302.11716.pdf' target='_blank'>https://arxiv.org/pdf/2302.11716.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingyu Xu, Zheng Lian, Bin Liu, Jianhua Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11716">VRA: Variational Rectified Activation for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical to building reliable machine learning systems in the open world. Researchers have proposed various strategies to reduce model overconfidence on OOD data. Among them, ReAct is a typical and effective technique to deal with model overconfidence, which truncates high activations to increase the gap between in-distribution and OOD. Despite its promising results, is this technique the best choice for widening the gap? To answer this question, we leverage the variational method to find the optimal operation and verify the necessity of suppressing abnormally low and high activations and amplifying intermediate activations in OOD detection, rather than focusing only on high activations like ReAct. This motivates us to propose a novel technique called ``Variational Rectified Activation (VRA)'', which simulates these suppression and amplification operations using piecewise functions. Experimental results on multiple benchmark datasets demonstrate that our method outperforms existing post-hoc strategies. Meanwhile, VRA is compatible with different scoring functions and network architectures. \textcolor[rgb]{0.93,0.0,0.47}{Our code can be found in Supplementary Material}.
<div id='section'>Paperid: <span id='pid'>386, <a href='https://arxiv.org/pdf/2408.15566.pdf' target='_blank'>https://arxiv.org/pdf/2408.15566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinglun Li, Xinyu Zhou, Kaixun Jiang, Lingyi Hong, Pinxue Guo, Zhaoyu Chen, Weifeng Ge, Wenqiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15566">TagOOD: A Novel Approach to Out-of-Distribution Detection via Vision-Language Representations and Class Center Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal fusion, leveraging data like vision and language, is rapidly gaining traction. This enriched data representation improves performance across various tasks. Existing methods for out-of-distribution (OOD) detection, a critical area where AI models encounter unseen data in real-world scenarios, rely heavily on whole-image features. These image-level features can include irrelevant information that hinders the detection of OOD samples, ultimately limiting overall performance. In this paper, we propose \textbf{TagOOD}, a novel approach for OOD detection that leverages vision-language representations to achieve label-free object feature decoupling from whole images. This decomposition enables a more focused analysis of object semantics, enhancing OOD detection performance. Subsequently, TagOOD trains a lightweight network on the extracted object features to learn representative class centers. These centers capture the central tendencies of IND object classes, minimizing the influence of irrelevant image features during OOD detection. Finally, our approach efficiently detects OOD samples by calculating distance-based metrics as OOD scores between learned centers and test samples. We conduct extensive experiments to evaluate TagOOD on several benchmark datasets and demonstrate its superior performance compared to existing OOD detection methods. This work presents a novel perspective for further exploration of multimodal information utilization in OOD detection, with potential applications across various tasks.
<div id='section'>Paperid: <span id='pid'>387, <a href='https://arxiv.org/pdf/2405.17494.pdf' target='_blank'>https://arxiv.org/pdf/2405.17494.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryan Benkert, Mohit Prabhushankar, Ghassan AlRegib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17494">Transitional Uncertainty with Layered Intermediate Predictions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we discuss feature engineering for single-pass uncertainty estimation. For accurate uncertainty estimates, neural networks must extract differences in the feature space that quantify uncertainty. This could be achieved by current single-pass approaches that maintain feature distances between data points as they traverse the network. While initial results are promising, maintaining feature distances within the network representations frequently inhibits information compression and opposes the learning objective. We study this effect theoretically and empirically to arrive at a simple conclusion: preserving feature distances in the output is beneficial when the preserved features contribute to learning the label distribution and act in opposition otherwise. We then propose Transitional Uncertainty with Layered Intermediate Predictions (TULIP) as a simple approach to address the shortcomings of current single-pass estimators. Specifically, we implement feature preservation by extracting features from intermediate representations before information is collapsed by subsequent layers. We refer to the underlying preservation mechanism as transitional feature preservation. We show that TULIP matches or outperforms current single-pass methods on standard benchmarks and in practical settings where these methods are less reliable (imbalances, complex architectures, medical modalities).
<div id='section'>Paperid: <span id='pid'>388, <a href='https://arxiv.org/pdf/2403.12534.pdf' target='_blank'>https://arxiv.org/pdf/2403.12534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiazhou Zhou, Xu Zheng, Yuanhuiyi Lyu, Lin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.12534">ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action Recognition and More</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Event cameras have recently been shown beneficial for practical vision tasks, such as action recognition, thanks to their high temporal resolution, power efficiency, and reduced privacy concerns. However, current research is hindered by 1) the difficulty in processing events because of their prolonged duration and dynamic actions with complex and ambiguous semantics and 2) the redundant action depiction of the event frame representation with fixed stacks. We find language naturally conveys abundant semantic information, rendering it stunningly superior in reducing semantic uncertainty. In light of this, we propose ExACT, a novel approach that, for the first time, tackles event-based action recognition from a cross-modal conceptualizing perspective. Our ExACT brings two technical contributions. Firstly, we propose an adaptive fine-grained event (AFE) representation to adaptively filter out the repeated events for the stationary objects while preserving dynamic ones. This subtly enhances the performance of ExACT without extra computational cost. Then, we propose a conceptual reasoning-based uncertainty estimation module, which simulates the recognition process to enrich the semantic representation. In particular, conceptual reasoning builds the temporal relation based on the action semantics, and uncertainty estimation tackles the semantic uncertainty of actions based on the distributional representation. Experiments show that our ExACT achieves superior recognition accuracy of 94.83%(+2.23%), 90.10%(+37.47%) and 67.24% on PAF, HARDVS and our SeAct datasets respectively.
<div id='section'>Paperid: <span id='pid'>389, <a href='https://arxiv.org/pdf/2403.10190.pdf' target='_blank'>https://arxiv.org/pdf/2403.10190.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Zhou, Mohit Prabhushankar, Ghassan AlRegib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10190">Perceptual Quality-based Model Training under Annotator Label Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Annotators exhibit disagreement during data labeling, which can be termed as annotator label uncertainty. Annotator label uncertainty manifests in variations of labeling quality. Training with a single low-quality annotation per sample induces model reliability degradations. In this work, we first examine the effects of annotator label uncertainty in terms of the model's generalizability and prediction uncertainty. We observe that the model's generalizability and prediction uncertainty degrade with the presence of low-quality noisy labels. Meanwhile, our evaluation of existing uncertainty estimation algorithms indicates their incapability in response to annotator label uncertainty. To mitigate performance degradation, prior methods show that training models with labels collected from multiple independent annotators can enhance generalizability. However, they require massive annotations. Hence, we introduce a novel perceptual quality-based model training framework to objectively generate multiple labels for model training to enhance reliability, while avoiding massive annotations. Specifically, we first select a subset of samples with low perceptual quality scores ranked by statistical regularities of visual signals. We then assign de-aggregated labels to each sample in this subset to obtain a training set with multiple labels. Our experiments and analysis demonstrate that training with the proposed framework alleviates the degradation of generalizability and prediction uncertainty caused by annotator label uncertainty.
<div id='section'>Paperid: <span id='pid'>390, <a href='https://arxiv.org/pdf/2401.08689.pdf' target='_blank'>https://arxiv.org/pdf/2401.08689.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingqiu Zhou, Aojun Zhou, Hongsheng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08689">NODI: Out-Of-Distribution Detection with Noise from Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a crucial part of deploying machine learning models safely. It has been extensively studied with a plethora of methods developed in the literature. This problem is tackled with an OOD score computation, however, previous methods compute the OOD scores with limited usage of the in-distribution dataset. For instance, the OOD scores are computed with information from a small portion of the in-distribution data. Furthermore, these methods encode images with a neural image encoder. The robustness of these methods is rarely checked with respect to image encoders of different training methods and architectures. In this work, we introduce the diffusion process into the OOD task. The diffusion model integrates information on the whole training set into the predicted noise vectors. What's more, we deduce a closed-form solution for the noise vector (stable point). Then the noise vector is converted into our OOD score, we test both the deep model predicted noise vector and the closed-form noise vector on the OOD benchmarks \cite{openood}. Our method outperforms previous OOD methods across all types of image encoders (Table. \ref{main}). A $3.5\%$ performance gain is achieved with the MAE-based image encoder. Moreover, we studied the robustness of OOD methods by applying different types of image encoders. Some OOD methods failed to generalize well when switching image encoders from ResNet to Vision Transformers, our method performs exhibits good robustness with all the image encoders.
<div id='section'>Paperid: <span id='pid'>391, <a href='https://arxiv.org/pdf/2310.01765.pdf' target='_blank'>https://arxiv.org/pdf/2310.01765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pierre-Olivier CÃ´tÃ©, Amin Nikanjam, Nafisa Ahmed, Dmytro Humeniuk, Foutse Khomh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01765">Data Cleaning and Machine Learning: A Systematic Literature Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Context: Machine Learning (ML) is integrated into a growing number of systems for various applications. Because the performance of an ML model is highly dependent on the quality of the data it has been trained on, there is a growing interest in approaches to detect and repair data errors (i.e., data cleaning). Researchers are also exploring how ML can be used for data cleaning; hence creating a dual relationship between ML and data cleaning. To the best of our knowledge, there is no study that comprehensively reviews this relationship. Objective: This paper's objectives are twofold. First, it aims to summarize the latest approaches for data cleaning for ML and ML for data cleaning. Second, it provides future work recommendations. Method: We conduct a systematic literature review of the papers published between 2016 and 2022 inclusively. We identify different types of data cleaning activities with and for ML: feature cleaning, label cleaning, entity matching, outlier detection, imputation, and holistic data cleaning. Results: We summarize the content of 101 papers covering various data cleaning activities and provide 24 future work recommendations. Our review highlights many promising data cleaning techniques that can be further extended. Conclusion: We believe that our review of the literature will help the community develop better approaches to clean data.
<div id='section'>Paperid: <span id='pid'>392, <a href='https://arxiv.org/pdf/2306.10060.pdf' target='_blank'>https://arxiv.org/pdf/2306.10060.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinghao Li, Lingkai Kong, Yuanqi Du, Yue Yu, Yuchen Zhuang, Wenhao Mu, Chao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.10060">MUBen: Benchmarking the Uncertainty of Molecular Representation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large molecular representation models pre-trained on massive unlabeled data have shown great success in predicting molecular properties. However, these models may tend to overfit the fine-tuning data, resulting in over-confident predictions on test data that fall outside of the training distribution. To address this issue, uncertainty quantification (UQ) methods can be used to improve the models' calibration of predictions. Although many UQ approaches exist, not all of them lead to improved performance. While some studies have included UQ to improve molecular pre-trained models, the process of selecting suitable backbone and UQ methods for reliable molecular uncertainty estimation remains underexplored. To address this gap, we present MUBen, which evaluates different UQ methods for state-of-the-art backbone molecular representation models to investigate their capabilities. By fine-tuning various backbones using different molecular descriptors as inputs with UQ methods from different categories, we assess the influence of architectural decisions and training strategies. Our study offers insights for selecting UQ for backbone models, which can facilitate research on uncertainty-critical applications in fields such as materials science and drug discovery.
<div id='section'>Paperid: <span id='pid'>393, <a href='https://arxiv.org/pdf/2304.00466.pdf' target='_blank'>https://arxiv.org/pdf/2304.00466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifeng Wang, Luyang Luo, Mingxiang Wu, Qiong Wang, Hao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.00466">Learning Robust Medical Image Segmentation from Multi-source Annotations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Collecting annotations from multiple independent sources could mitigate the impact of potential noises and biases from a single source, which is a common practice in medical image segmentation. Learning segmentation networks from multi-source annotations remains a challenge due to the uncertainties brought by the variance of annotations and the quality of images. In this paper, we propose an Uncertainty-guided Multi-source Annotation Network (UMA-Net), which guides the training process by uncertainty estimation at both the pixel and the image levels. First, we developed the annotation uncertainty estimation module (AUEM) to learn the pixel-wise uncertainty of each annotation, which then guided the network to learn from reliable pixels by weighted segmentation loss. Second, a quality assessment module (QAM) was proposed to assess the image-level quality of the input samples based on the former assessed annotation uncertainties. Importantly, we introduced an auxiliary predictor to learn from the low-quality samples instead of discarding them, which ensured the preservation of their representation knowledge in the backbone without directly accumulating errors within the primary predictor. Extensive experiments demonstrated the effectiveness and feasibility of our proposed UMA-Net on various datasets, including 2D chest X-ray segmentation, fundus image segmentation, and 3D breast DCE-MRI segmentation.
<div id='section'>Paperid: <span id='pid'>394, <a href='https://arxiv.org/pdf/2405.17659.pdf' target='_blank'>https://arxiv.org/pdf/2405.17659.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Huang, Liutao Yang, Fanwen Wang, Yang Nan, Weiwen Wu, Chengyan Wang, Kuangyu Shi, Angelica I. Aviles-Rivero, Carola-Bibiane SchÃ¶nlieb, Daoqiang Zhang, Guang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17659">Enhancing Global Sensitivity and Uncertainty Quantification in Medical Image Reconstruction with Monte Carlo Arbitrary-Masked Mamba</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has been extensively applied in medical image reconstruction, where Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) represent the predominant paradigms, each possessing distinct advantages and inherent limitations: CNNs exhibit linear complexity with local sensitivity, whereas ViTs demonstrate quadratic complexity with global sensitivity. The emerging Mamba has shown superiority in learning visual representation, which combines the advantages of linear scalability and global sensitivity. In this study, we introduce MambaMIR, an Arbitrary-Masked Mamba-based model with wavelet decomposition for joint medical image reconstruction and uncertainty estimation. A novel Arbitrary Scan Masking (ASM) mechanism "masks out" redundant information to introduce randomness for further uncertainty estimation. Compared to the commonly used Monte Carlo (MC) dropout, our proposed MC-ASM provides an uncertainty map without the need for hyperparameter tuning and mitigates the performance drop typically observed when applying dropout to low-level tasks. For further texture preservation and better perceptual quality, we employ the wavelet transformation into MambaMIR and explore its variant based on the Generative Adversarial Network, namely MambaMIR-GAN. Comprehensive experiments have been conducted for multiple representative medical image reconstruction tasks, demonstrating that the proposed MambaMIR and MambaMIR-GAN outperform other baseline and state-of-the-art methods in different reconstruction tasks, where MambaMIR achieves the best reconstruction fidelity and MambaMIR-GAN has the best perceptual quality. In addition, our MC-ASM provides uncertainty maps as an additional tool for clinicians, while mitigating the typical performance drop caused by the commonly used dropout.
<div id='section'>Paperid: <span id='pid'>395, <a href='https://arxiv.org/pdf/2404.07770.pdf' target='_blank'>https://arxiv.org/pdf/2404.07770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufeng Yue, Meng Yu, Luojie Yang, Yi Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07770">Joint Conditional Diffusion Model for Image Restoration with Mixed Degradations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image restoration is rather challenging in adverse weather conditions, especially when multiple degradations occur simultaneously. Blind image decomposition was proposed to tackle this issue, however, its effectiveness heavily relies on the accurate estimation of each component. Although diffusion-based models exhibit strong generative abilities in image restoration tasks, they may generate irrelevant contents when the degraded images are severely corrupted. To address these issues, we leverage physical constraints to guide the whole restoration process, where a mixed degradation model based on atmosphere scattering model is constructed. Then we formulate our Joint Conditional Diffusion Model (JCDM) by incorporating the degraded image and degradation mask to provide precise guidance. To achieve better color and detail recovery results, we further integrate a refinement network to reconstruct the restored image, where Uncertainty Estimation Block (UEB) is employed to enhance the features. Extensive experiments performed on both multi-weather and weather-specific datasets demonstrate the superiority of our method over state-of-the-art competing methods.
<div id='section'>Paperid: <span id='pid'>396, <a href='https://arxiv.org/pdf/2303.03770.pdf' target='_blank'>https://arxiv.org/pdf/2303.03770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mattia Litrico, Alessio Del Bue, Pietro Morerio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03770">Guiding Pseudo-labels with Uncertainty Estimation for Source-free Unsupervised Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard Unsupervised Domain Adaptation (UDA) methods assume the availability of both source and target data during the adaptation. In this work, we investigate Source-free Unsupervised Domain Adaptation (SF-UDA), a specific case of UDA where a model is adapted to a target domain without access to source data. We propose a novel approach for the SF-UDA setting based on a loss reweighting strategy that brings robustness against the noise that inevitably affects the pseudo-labels. The classification loss is reweighted based on the reliability of the pseudo-labels that is measured by estimating their uncertainty. Guided by such reweighting strategy, the pseudo-labels are progressively refined by aggregating knowledge from neighbouring samples. Furthermore, a self-supervised contrastive framework is leveraged as a target space regulariser to enhance such knowledge aggregation. A novel negative pairs exclusion strategy is proposed to identify and exclude negative pairs made of samples sharing the same class, even in presence of some noise in the pseudo-labels. Our method outperforms previous methods on three major benchmarks by a large margin. We set the new SF-UDA state-of-the-art on VisDA-C and DomainNet with a performance gain of +1.8% on both benchmarks and on PACS with +12.3% in the single-source setting and +6.6% in multi-target adaptation. Additional analyses demonstrate that the proposed approach is robust to the noise, which results in significantly more accurate pseudo-labels compared to state-of-the-art approaches.
<div id='section'>Paperid: <span id='pid'>397, <a href='https://arxiv.org/pdf/2509.24202.pdf' target='_blank'>https://arxiv.org/pdf/2509.24202.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linwei Tao, Yi-Fan Yeh, Bo Kai, Minjing Dong, Tao Huang, Tom A. Lamb, Jialin Yu, Philip H. S. Torr, Chang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24202">Can Large Language Models Express Uncertainty Like Human?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) are increasingly used in high-stakes settings, where overconfident responses can mislead users. Reliable confidence estimation has been shown to enhance trust and task accuracy. Yet existing methods face practical barriers: logits are often hidden, multi-sampling is computationally expensive, and verbalized numerical uncertainty (e.g., giving a 0-100 score) deviates from natural communication. We revisit linguistic confidence (LC), where models express uncertainty through hedging language (e.g., probably, might), offering a lightweight and human-centered alternative. To advance this direction, we (1) release the first diverse, large-scale dataset of hedging expressions with human-annotated confidence scores, and (2) propose a lightweight mapper that converts hedges into confidence scores at near-zero cost. Building on these resources, we (3) conduct the first systematic study of LC across modern LLMs and QA benchmarks, revealing that while most LLMs underperform in expressing reliable LC, carefully designed prompting achieves competitive calibration and discriminability. Finally, we (4) introduce a fine-tuning framework that further improves LC reliability. Taken together, our work positions linguistic confidence as a scalable, efficient, and human-aligned approach to LLM uncertainty estimation, and calls for deeper exploration of this promising yet underexplored direction.
<div id='section'>Paperid: <span id='pid'>398, <a href='https://arxiv.org/pdf/2509.10951.pdf' target='_blank'>https://arxiv.org/pdf/2509.10951.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Wilkinghoff, Haici Yang, Janek Ebbers, François G. Germain, Gordon Wichern, Jonathan Le Roux
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10951">Local Density-Based Anomaly Score Normalization for Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State-of-the-art anomalous sound detection (ASD) systems in domain-shifted conditions rely on projecting audio signals into an embedding space and using distance-based outlier detection to compute anomaly scores. One of the major difficulties to overcome is the so-called domain mismatch between the anomaly score distributions of a source domain and a target domain that differ acoustically and in terms of the amount of training data provided. A decision threshold that is optimal for one domain may be highly sub-optimal for the other domain and vice versa. This significantly degrades the performance when only using a single decision threshold, as is required when generalizing to multiple data domains that are possibly unseen during training while still using the same trained ASD system as in the source domain. To reduce this mismatch between the domains, we propose a simple local-density-based anomaly score normalization scheme. In experiments conducted on several ASD datasets, we show that the proposed normalization scheme consistently improves performance for various types of embedding-based ASD systems and yields better results than existing anomaly score normalization approaches.
<div id='section'>Paperid: <span id='pid'>399, <a href='https://arxiv.org/pdf/2505.23854.pdf' target='_blank'>https://arxiv.org/pdf/2505.23854.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linwei Tao, Yi-Fan Yeh, Minjing Dong, Tao Huang, Philip Torr, Chang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23854">Revisiting Uncertainty Estimation and Calibration of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As large language models (LLMs) are increasingly deployed in high-stakes applications, robust uncertainty estimation is essential for ensuring the safe and trustworthy deployment of LLMs. We present the most comprehensive study to date of uncertainty estimation in LLMs, evaluating 80 models spanning open- and closed-source families, dense and Mixture-of-Experts (MoE) architectures, reasoning and non-reasoning modes, quantization variants and parameter scales from 0.6B to 671B. Focusing on three representative black-box single-pass methods, including token probability-based uncertainty (TPU), numerical verbal uncertainty (NVU), and linguistic verbal uncertainty (LVU), we systematically evaluate uncertainty calibration and selective classification using the challenging MMLU-Pro benchmark, which covers both reasoning-intensive and knowledge-based tasks. Our results show that LVU consistently outperforms TPU and NVU, offering stronger calibration and discrimination while being more interpretable. We also find that high accuracy does not imply reliable uncertainty, and that model scale, post-training, reasoning ability and quantization all influence estimation performance. Notably, LLMs exhibit better uncertainty estimates on reasoning tasks than on knowledge-heavy ones, and good calibration does not necessarily translate to effective error ranking. These findings highlight the need for multi-perspective evaluation and position LVU as a practical tool for improving the reliability of LLMs in real-world settings.
<div id='section'>Paperid: <span id='pid'>400, <a href='https://arxiv.org/pdf/2503.22725.pdf' target='_blank'>https://arxiv.org/pdf/2503.22725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinxu Lin, Linwei Tao, Minjing Dong, Chang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22725">Uncertainty Weighted Gradients for Model Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model calibration is essential for ensuring that the predictions of deep neural networks accurately reflect true probabilities in real-world classification tasks. However, deep networks often produce over-confident or under-confident predictions, leading to miscalibration. Various methods have been proposed to address this issue by designing effective loss functions for calibration, such as focal loss. In this paper, we analyze its effectiveness and provide a unified loss framework of focal loss and its variants, where we mainly attribute their superiority in model calibration to the loss weighting factor that estimates sample-wise uncertainty. Based on our analysis, existing loss functions fail to achieve optimal calibration performance due to two main issues: including misalignment during optimization and insufficient precision in uncertainty estimation. Specifically, focal loss cannot align sample uncertainty with gradient scaling and the single logit cannot indicate the uncertainty. To address these issues, we reformulate the optimization from the perspective of gradients, which focuses on uncertain samples. Meanwhile, we propose using the Brier Score as the loss weight factor, which provides a more accurate uncertainty estimation via all the logits. Extensive experiments on various models and datasets demonstrate that our method achieves state-of-the-art (SOTA) performance.
<div id='section'>Paperid: <span id='pid'>401, <a href='https://arxiv.org/pdf/2410.12295.pdf' target='_blank'>https://arxiv.org/pdf/2410.12295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linwei Tao, Haolan Guo, Minjing Dong, Chang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12295">Consistency Calibration: Improving Uncertainty Calibration via Consistency among Perturbed Neighbors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Calibration is crucial in deep learning applications, especially in fields like healthcare and autonomous driving, where accurate confidence estimates are vital for decision-making. However, deep neural networks often suffer from miscalibration, with reliability diagrams and Expected Calibration Error (ECE) being the only standard perspective for evaluating calibration performance. In this paper, we introduce the concept of consistency as an alternative perspective on model calibration, inspired by uncertainty estimation literature in large language models (LLMs). We highlight its advantages over the traditional reliability-based view. Building on this concept, we propose a post-hoc calibration method called Consistency Calibration (CC), which adjusts confidence based on the model's consistency across perturbed inputs. CC is particularly effective in locally uncertainty estimation, as it requires no additional data samples or label information, instead generating input perturbations directly from the source data. Moreover, we show that performing perturbations at the logit level significantly improves computational efficiency. We validate the effectiveness of CC through extensive comparisons with various post-hoc and training-time calibration methods, demonstrating state-of-the-art performance on standard datasets such as CIFAR-10, CIFAR-100, and ImageNet, as well as on long-tailed datasets like ImageNet-LT.
<div id='section'>Paperid: <span id='pid'>402, <a href='https://arxiv.org/pdf/2408.08208.pdf' target='_blank'>https://arxiv.org/pdf/2408.08208.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bohao Wang, Feng Liu, Changwang Zhang, Jiawei Chen, Yudi Wu, Sheng Zhou, Xingyu Lou, Jun Wang, Yan Feng, Chun Chen, Can Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08208">LLM4DSR: Leveraging Large Language Model for Denoising Sequential Recommendation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sequential Recommenders generate recommendations based on users' historical interaction sequences. However, in practice, these collected sequences are often contaminated by noisy interactions, which significantly impairs recommendation performance. Accurately identifying such noisy interactions without additional information is particularly challenging due to the absence of explicit supervisory signals indicating noise. Large Language Models (LLMs), equipped with extensive open knowledge and semantic reasoning abilities, offer a promising avenue to bridge this information gap. However, employing LLMs for denoising in sequential recommendation presents notable challenges: 1) Direct application of pretrained LLMs may not be competent for the denoising task, frequently generating nonsensical responses; 2) Even after fine-tuning, the reliability of LLM outputs remains questionable, especially given the complexity of the denoising task and the inherent hallucinatory issue of LLMs.
  To tackle these challenges, we propose LLM4DSR, a tailored approach for denoising sequential recommendation using LLMs. We constructed a self-supervised fine-tuning task to activate LLMs' capabilities to identify noisy items and suggest replacements. Furthermore, we developed an uncertainty estimation module that ensures only high-confidence responses are utilized for sequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing corrected sequences to be flexibly applied across various recommendation models. Extensive experiments validate the superiority of LLM4DSR over existing methods.
<div id='section'>Paperid: <span id='pid'>403, <a href='https://arxiv.org/pdf/2406.09262.pdf' target='_blank'>https://arxiv.org/pdf/2406.09262.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Spencer Young, Porter Jenkins, Longchao Da, Jeff Dotson, Hua Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09262">Fully Heteroscedastic Count Regression with Deep Double Poisson Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks capable of accurate, input-conditional uncertainty representation are essential for real-world AI systems. Deep ensembles of Gaussian networks have proven highly effective for continuous regression due to their ability to flexibly represent aleatoric uncertainty via unrestricted heteroscedastic variance, which in turn enables accurate epistemic uncertainty estimation. However, no analogous approach exists for count regression, despite many important applications. To address this gap, we propose the Deep Double Poisson Network (DDPN), a novel neural discrete count regression model that outputs the parameters of the Double Poisson distribution, enabling arbitrarily high or low predictive aleatoric uncertainty for count data and improving epistemic uncertainty estimation when ensembled. We formalize and prove that DDPN exhibits robust regression properties similar to heteroscedastic Gaussian models via learnable loss attenuation, and introduce a simple loss modification to control this behavior. Experiments on diverse datasets demonstrate that DDPN outperforms current baselines in accuracy, calibration, and out-of-distribution detection, establishing a new state-of-the-art in deep count regression.
<div id='section'>Paperid: <span id='pid'>404, <a href='https://arxiv.org/pdf/2406.09262.pdf' target='_blank'>https://arxiv.org/pdf/2406.09262.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Spencer Young, Porter Jenkins, Longchao Da, Jeff Dotson, Hua Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09262">Fully Heteroscedastic Count Regression with Deep Double Poisson Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks capable of accurate, input-conditional uncertainty representation are essential for real-world AI systems. Deep ensembles of Gaussian networks have proven highly effective for continuous regression due to their ability to flexibly represent aleatoric uncertainty via unrestricted heteroscedastic variance, which in turn enables accurate epistemic uncertainty estimation. However, no analogous approach exists for count regression, despite many important applications. To address this gap, we propose the Deep Double Poisson Network (DDPN), a novel neural discrete count regression model that outputs the parameters of the Double Poisson distribution, enabling arbitrarily high or low predictive aleatoric uncertainty for count data and improving epistemic uncertainty estimation when ensembled. We formalize and prove that DDPN exhibits robust regression properties similar to heteroscedastic Gaussian models via learnable loss attenuation, and introduce a simple loss modification to control this behavior. Experiments on diverse datasets demonstrate that DDPN outperforms current baselines in accuracy, calibration, and out-of-distribution detection, establishing a new state-of-the-art in deep count regression.
<div id='section'>Paperid: <span id='pid'>405, <a href='https://arxiv.org/pdf/2402.14259.pdf' target='_blank'>https://arxiv.org/pdf/2402.14259.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyuan Wang, Jinhao Duan, Chenxi Yuan, Qingyu Chen, Tianlong Chen, Yue Zhang, Ren Wang, Xiaoshuang Shi, Kaidi Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14259">Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial for the reliability of safety-critical human and artificial intelligence (AI) interaction systems, particularly in the domain of healthcare engineering. However, a robust and general uncertainty measure for free-form answers has not been well-established in open-ended medical question-answering (QA) tasks, where generative inequality introduces a large number of irrelevant words and sequences within the generated set for uncertainty quantification (UQ), which can lead to biases. This paper introduces Word-Sequence Entropy (WSE), a method that calibrates uncertainty at both the word and sequence levels, considering semantic relevance. WSE quantifies uncertainty in a way that is more closely aligned with the reliability of LLMs during uncertainty quantification (UQ). We compare WSE with six baseline methods on five free-form medical QA datasets, utilizing seven popular large language models (LLMs). Experimental results demonstrate that WSE exhibits superior performance in UQ under two standard criteria for correctness evaluation. Additionally, in terms of real-world medical QA applications, the performance of LLMs is significantly enhanced (e.g., a 6.36% improvement in model accuracy on the COVID-QA dataset) by employing responses with lower uncertainty that are identified by WSE as final answers, without any additional task-specific fine-tuning or architectural modifications.
<div id='section'>Paperid: <span id='pid'>406, <a href='https://arxiv.org/pdf/2311.00567.pdf' target='_blank'>https://arxiv.org/pdf/2311.00567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ni Yao, Hang Hu, Kaicong Chen, Chen Zhao, Yuan Guo, Boya Li, Jiaofen Nan, Yanting Li, Chuang Han, Fubao Zhu, Weihua Zhou, Li Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00567">A Robust Deep Learning Method with Uncertainty Estimation for the Pathological Classification of Renal Cell Carcinoma based on CT Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Objectives To develop and validate a deep learning-based diagnostic model incorporating uncertainty estimation so as to facilitate radiologists in the preoperative differentiation of the pathological subtypes of renal cell carcinoma (RCC) based on CT images. Methods Data from 668 consecutive patients, pathologically proven RCC, were retrospectively collected from Center 1. By using five-fold cross-validation, a deep learning model incorporating uncertainty estimation was developed to classify RCC subtypes into clear cell RCC (ccRCC), papillary RCC (pRCC), and chromophobe RCC (chRCC). An external validation set of 78 patients from Center 2 further evaluated the model's performance. Results In the five-fold cross-validation, the model's area under the receiver operating characteristic curve (AUC) for the classification of ccRCC, pRCC, and chRCC was 0.868 (95% CI: 0.826-0.923), 0.846 (95% CI: 0.812-0.886), and 0.839 (95% CI: 0.802-0.88), respectively. In the external validation set, the AUCs were 0.856 (95% CI: 0.838-0.882), 0.787 (95% CI: 0.757-0.818), and 0.793 (95% CI: 0.758-0.831) for ccRCC, pRCC, and chRCC, respectively. Conclusions The developed deep learning model demonstrated robust performance in predicting the pathological subtypes of RCC, while the incorporated uncertainty emphasized the importance of understanding model confidence, which is crucial for assisting clinical decision-making for patients with renal tumors. Clinical relevance statement Our deep learning approach, integrated with uncertainty estimation, offers clinicians a dual advantage: accurate RCC subtype predictions complemented by diagnostic confidence references, promoting informed decision-making for patients with RCC.
<div id='section'>Paperid: <span id='pid'>407, <a href='https://arxiv.org/pdf/2510.08044.pdf' target='_blank'>https://arxiv.org/pdf/2510.08044.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiyuan Yin, Chenjia Bai, Zihao Zhang, Junwei Jin, Xinxin Zhang, Chi Zhang, Xuelong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.08044">Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) demonstrate advanced reasoning abilities, enabling robots to understand natural language instructions and generate high-level plans with appropriate grounding. However, LLM hallucinations present a significant challenge, often leading to overconfident yet potentially misaligned or unsafe plans. While researchers have explored uncertainty estimation to improve the reliability of LLM-based planning, existing studies have not sufficiently differentiated between epistemic and intrinsic uncertainty, limiting the effectiveness of uncertainty estimation. In this paper, we present Combined Uncertainty estimation for Reliable Embodied planning (CURE), which decomposes the uncertainty into epistemic and intrinsic uncertainty, each estimated separately. Furthermore, epistemic uncertainty is subdivided into task clarity and task familiarity for more accurate evaluation. The overall uncertainty assessments are obtained using random network distillation and multi-layer perceptron regression heads driven by LLM features. We validated our approach in two distinct experimental settings: kitchen manipulation and tabletop rearrangement experiments. The results show that, compared to existing methods, our approach yields uncertainty estimates that are more closely aligned with the actual execution outcomes.
<div id='section'>Paperid: <span id='pid'>408, <a href='https://arxiv.org/pdf/2509.15805.pdf' target='_blank'>https://arxiv.org/pdf/2509.15805.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyang Wang, Xi Xiao, Gaofei Chen, Xiaoying Liao, Guo Cheng, Yingrui Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15805">Boosting Active Learning with Knowledge Transfer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is at the core of Active Learning (AL). Most existing methods resort to complex auxiliary models and advanced training fashions to estimate uncertainty for unlabeled data. These models need special design and hence are difficult to train especially for domain tasks, such as Cryo-Electron Tomography (cryo-ET) classification in computational biology. To address this challenge, we propose a novel method using knowledge transfer to boost uncertainty estimation in AL. Specifically, we exploit the teacher-student mode where the teacher is the task model in AL and the student is an auxiliary model that learns from the teacher. We train the two models simultaneously in each AL cycle and adopt a certain distance between the model outputs to measure uncertainty for unlabeled data. The student model is task-agnostic and does not rely on special training fashions (e.g. adversarial), making our method suitable for various tasks. More importantly, we demonstrate that data uncertainty is not tied to concrete value of task loss but closely related to the upper-bound of task loss. We conduct extensive experiments to validate the proposed method on classical computer vision tasks and cryo-ET challenges. The results demonstrate its efficacy and efficiency.
<div id='section'>Paperid: <span id='pid'>409, <a href='https://arxiv.org/pdf/2505.23412.pdf' target='_blank'>https://arxiv.org/pdf/2505.23412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Srishti Gupta, Daniele Angioni, Maura Pintor, Ambra Demontis, Lea Schönherr, Battista Biggio, Fabio Roli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23412">Buffer-free Class-Incremental Learning with Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Class-incremental learning (CIL) poses significant challenges in open-world scenarios, where models must not only learn new classes over time without forgetting previous ones but also handle inputs from unknown classes that a closed-set model would misclassify. Recent works address both issues by (i)~training multi-head models using the task-incremental learning framework, and (ii) predicting the task identity employing out-of-distribution (OOD) detectors. While effective, the latter mainly relies on joint training with a memory buffer of past data, raising concerns around privacy, scalability, and increased training time. In this paper, we present an in-depth analysis of post-hoc OOD detection methods and investigate their potential to eliminate the need for a memory buffer. We uncover that these methods, when applied appropriately at inference time, can serve as a strong substitute for buffer-based OOD detection. We show that this buffer-free approach achieves comparable or superior performance to buffer-based methods both in terms of class-incremental learning and the rejection of unknown samples. Experimental results on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets support our findings, offering new insights into the design of efficient and privacy-preserving CIL systems for open-world settings.
<div id='section'>Paperid: <span id='pid'>410, <a href='https://arxiv.org/pdf/2502.16725.pdf' target='_blank'>https://arxiv.org/pdf/2502.16725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongzhe Cheng, Tianyou Zheng, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16725">DOSE3 : Diffusion-based Out-of-distribution detection on SE(3) trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution(OOD) detection, a fundamental machine learning task aimed at identifying abnormal samples, traditionally requires model retraining for different inlier distributions. While recent research demonstrates the applicability of diffusion models to OOD detection, existing approaches are limited to Euclidean or latent image spaces. Our work extends OOD detection to trajectories in the Special Euclidean Group in 3D ($\mathbb{SE}(3)$), addressing a critical need in computer vision, robotics, and engineering applications that process object pose sequences in $\mathbb{SE}(3)$. We present $\textbf{D}$iffusion-based $\textbf{O}$ut-of-distribution detection on $\mathbb{SE}(3)$ ($\mathbf{DOSE3}$), a novel OOD framework that extends diffusion to a unified sample space of $\mathbb{SE}(3)$ pose sequences. Through extensive validation on multiple benchmark datasets, we demonstrate $\mathbf{DOSE3}$'s superior performance compared to state-of-the-art OOD detection frameworks.
<div id='section'>Paperid: <span id='pid'>411, <a href='https://arxiv.org/pdf/2411.03359.pdf' target='_blank'>https://arxiv.org/pdf/2411.03359.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geng Yu, Jianing Zhu, Jiangchao Yao, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.03359">Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for deploying reliable machine learning models in open-world applications. Recent advances in CLIP-based OOD detection have shown promising results via regularizing prompt tuning with OOD features extracted from ID data. However, the irrelevant context mined from ID data can be spurious due to the inaccurate foreground-background decomposition, thus limiting the OOD detection performance. In this work, we propose a novel framework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem for effective OOD detection with only the given few-shot ID data. Specifically, SCT introduces modulating factors respectively on the two components of the original learning objective. It adaptively directs the optimization process between the two tasks during training on data with different prediction uncertainty to calibrate the influence of OOD regularization, which is compatible with many prompt tuning based OOD detection methods. Extensive experiments and analyses have been conducted to characterize and demonstrate the effectiveness of the proposed SCT. The code is publicly available.
<div id='section'>Paperid: <span id='pid'>412, <a href='https://arxiv.org/pdf/2411.00850.pdf' target='_blank'>https://arxiv.org/pdf/2411.00850.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihua Shao, Yan Gu, Siyu Chen, Haiyang Liu, Zixian Zhu, Zijian Ling, Minxi Yan, Ziyang Yan, Chenyu Zhang, Michele Magno, Haotong Qin, Yan Wang, Jingcai Guo, Ling Shao, Hao Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00850">GWQ: Gradient-Aware Weight Quantization for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) show impressive performance in solving complex language tasks. However, its large number of parameters presents significant challenges for the deployment. So, compressing LLMs to low bits can enable to deploy on resource-constrained devices. To address this problem, we propose gradient-aware weight quantization (GWQ), the first quantization approach for low-bit weight quantization that leverages gradients to localize outliers, requiring only a minimal amount of calibration data for outlier detection. GWQ retains the top 1\% outliers preferentially at FP16 precision, while the remaining non-outlier weights are stored in a low-bit. We widely evaluate GWQ on different task include language modeling, grounding detection, massive multitask language understanding and vision-language question and answering. Results show that models quantified by GWQ performs better than other quantization method. During quantization process, GWQ only need one calibration set to realize effective quant. Also, GWQ achieves 1.2x inference speedup in comparison to the original model and effectively reduces the inference memory.
<div id='section'>Paperid: <span id='pid'>413, <a href='https://arxiv.org/pdf/2409.03801.pdf' target='_blank'>https://arxiv.org/pdf/2409.03801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yewen Li, Chaojie Wang, Xiaobo Xia, Xu He, Ruyi An, Dong Li, Tongliang Liu, Bo An, Xinrun Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03801">Resultant: Incremental Effectiveness on Likelihood for Unsupervised Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised out-of-distribution (U-OOD) detection is to identify OOD data samples with a detector trained solely on unlabeled in-distribution (ID) data. The likelihood function estimated by a deep generative model (DGM) could be a natural detector, but its performance is limited in some popular "hard" benchmarks, such as FashionMNIST (ID) vs. MNIST (OOD). Recent studies have developed various detectors based on DGMs to move beyond likelihood. However, despite their success on "hard" benchmarks, most of them struggle to consistently surpass or match the performance of likelihood on some "non-hard" cases, such as SVHN (ID) vs. CIFAR10 (OOD) where likelihood could be a nearly perfect detector. Therefore, we appeal for more attention to incremental effectiveness on likelihood, i.e., whether a method could always surpass or at least match the performance of likelihood in U-OOD detection. We first investigate the likelihood of variational DGMs and find its detection performance could be improved in two directions: i) alleviating latent distribution mismatch, and ii) calibrating the dataset entropy-mutual integration. Then, we apply two techniques for each direction, specifically post-hoc prior and dataset entropy-mutual calibration. The final method, named Resultant, combines these two directions for better incremental effectiveness compared to either technique alone. Experimental results demonstrate that the Resultant could be a new state-of-the-art U-OOD detector while maintaining incremental effectiveness on likelihood in a wide range of tasks.
<div id='section'>Paperid: <span id='pid'>414, <a href='https://arxiv.org/pdf/2307.04973.pdf' target='_blank'>https://arxiv.org/pdf/2307.04973.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guoyao Deng, Ke Zou, Kai Ren, Meng Wang, Xuedong Yuan, Sancong Ying, Huazhu Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.04973">SAM-U: Multi-box prompts triggered uncertainty estimation for reliable SAM in medical image</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, Segmenting Anything has taken an important step towards general artificial intelligence. At the same time, its reliability and fairness have also attracted great attention, especially in the field of health care. In this study, we propose multi-box prompts triggered uncertainty estimation for SAM cues to demonstrate the reliability of segmented lesions or tissues. We estimate the distribution of SAM predictions via Monte Carlo with prior distribution parameters, which employs different prompts as formulation of test-time augmentation. Our experimental results found that multi-box prompts augmentation improve the SAM performance, and endowed each pixel with uncertainty. This provides the first paradigm for a reliable SAM.
<div id='section'>Paperid: <span id='pid'>415, <a href='https://arxiv.org/pdf/2303.03037.pdf' target='_blank'>https://arxiv.org/pdf/2303.03037.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Monish R. Nallapareddy, Kshitij Sirohi, Paulo L. J. Drews-Jr, Wolfram Burgard, Chih-Hong Cheng, Abhinav Valada
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03037">EvCenterNet: Uncertainty Estimation for Object Detection using Evidential Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial in safety-critical settings such as automated driving as it provides valuable information for several downstream tasks including high-level decision making and path planning. In this work, we propose EvCenterNet, a novel uncertainty-aware 2D object detection framework using evidential learning to directly estimate both classification and regression uncertainties. To employ evidential learning for object detection, we devise a combination of evidential and focal loss functions for the sparse heatmap inputs. We introduce class-balanced weighting for regression and heatmap prediction to tackle the class imbalance encountered by evidential learning. Moreover, we propose a learning scheme to actively utilize the predicted heatmap uncertainties to improve the detection performance by focusing on the most uncertain points. We train our model on the KITTI dataset and evaluate it on challenging out-of-distribution datasets including BDD100K and nuImages. Our experiments demonstrate that our approach improves the precision and minimizes the execution time loss in relation to the base model.
<div id='section'>Paperid: <span id='pid'>416, <a href='https://arxiv.org/pdf/2302.08119.pdf' target='_blank'>https://arxiv.org/pdf/2302.08119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ke Zou, Zhihao Chen, Xuedong Yuan, Xiaojing Shen, Meng Wang, Huazhu Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08119">A Review of Uncertainty Estimation and its Application in Medical Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The use of AI systems in healthcare for the early screening of diseases is of great clinical importance. Deep learning has shown great promise in medical imaging, but the reliability and trustworthiness of AI systems limit their deployment in real clinical scenes, where patient safety is at stake. Uncertainty estimation plays a pivotal role in producing a confidence evaluation along with the prediction of the deep model. This is particularly important in medical imaging, where the uncertainty in the model's predictions can be used to identify areas of concern or to provide additional information to the clinician. In this paper, we review the various types of uncertainty in deep learning, including aleatoric uncertainty and epistemic uncertainty. We further discuss how they can be estimated in medical imaging. More importantly, we review recent advances in deep learning models that incorporate uncertainty estimation in medical imaging. Finally, we discuss the challenges and future directions in uncertainty estimation in deep learning for medical imaging. We hope this review will ignite further interest in the community and provide researchers with an up-to-date reference regarding applications of uncertainty estimation models in medical imaging.
<div id='section'>Paperid: <span id='pid'>417, <a href='https://arxiv.org/pdf/2008.12328.pdf' target='_blank'>https://arxiv.org/pdf/2008.12328.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Fahad Shahbaz Khan, Marius Popescu, Mubarak Shah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2008.12328">A Background-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Abnormal event detection in video is a complex computer vision problem that has attracted significant attention in recent years. The complexity of the task arises from the commonly-adopted definition of an abnormal event, that is, a rarely occurring event that typically depends on the surrounding context. Following the standard formulation of abnormal event detection as outlier detection, we propose a background-agnostic framework that learns from training videos containing only normal events. Our framework is composed of an object detector, a set of appearance and motion auto-encoders, and a set of classifiers. Since our framework only looks at object detections, it can be applied to different scenes, provided that normal events are defined identically across scenes and that the single main factor of variation is the background. To overcome the lack of abnormal data during training, we propose an adversarial learning strategy for the auto-encoders. We create a scene-agnostic set of out-of-domain pseudo-abnormal examples, which are correctly reconstructed by the auto-encoders before applying gradient ascent on the pseudo-abnormal examples. We further utilize the pseudo-abnormal examples to serve as abnormal examples when training appearance-based and motion-based binary classifiers to discriminate between normal and abnormal latent features and reconstructions. We compare our framework with the state-of-the-art methods on four benchmark data sets, using various evaluation metrics. Compared to existing methods, the empirical results indicate that our approach achieves favorable performance on all data sets. In addition, we provide region-based and track-based annotations for two large-scale abnormal event detection data sets from the literature, namely ShanghaiTech and Subway.
<div id='section'>Paperid: <span id='pid'>418, <a href='https://arxiv.org/pdf/2403.16594.pdf' target='_blank'>https://arxiv.org/pdf/2403.16594.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kudaibergen Abutalip, Numan Saeed, Ikboljon Sobirov, Vincent Andrearczyk, Adrien Depeursinge, Mohammad Yaqub
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.16594">EDUE: Expert Disagreement-Guided One-Pass Uncertainty Estimation for Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying deep learning (DL) models in medical applications relies on predictive performance and other critical factors, such as conveying trustworthy predictive uncertainty. Uncertainty estimation (UE) methods provide potential solutions for evaluating prediction reliability and improving the model confidence calibration. Despite increasing interest in UE, challenges persist, such as the need for explicit methods to capture aleatoric uncertainty and align uncertainty estimates with real-life disagreements among domain experts. This paper proposes an Expert Disagreement-Guided Uncertainty Estimation (EDUE) for medical image segmentation. By leveraging variability in ground-truth annotations from multiple raters, we guide the model during training and incorporate random sampling-based strategies to enhance calibration confidence. Our method achieves 55% and 23% improvement in correlation on average with expert disagreements at the image and pixel levels, respectively, better calibration, and competitive segmentation performance compared to the state-of-the-art deep ensembles, requiring only a single forward pass.
<div id='section'>Paperid: <span id='pid'>419, <a href='https://arxiv.org/pdf/2306.09067.pdf' target='_blank'>https://arxiv.org/pdf/2306.09067.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunkang Cao, Xiaohao Xu, Chen Sun, Yuqi Cheng, Liang Gao, Weiming Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09067">2nd Place Winning Solution for the CVPR2023 Visual Anomaly and Novelty Detection Challenge: Multimodal Prompting for Data-centric Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This technical report introduces the winning solution of the team Segment Any Anomaly for the CVPR2023 Visual Anomaly and Novelty Detection (VAND) challenge. Going beyond uni-modal prompt, e.g., language prompt, we present a novel framework, i.e., Segment Any Anomaly + (SAA$+$), for zero-shot anomaly segmentation with multi-modal prompts for the regularization of cascaded modern foundation models. Inspired by the great zero-shot generalization ability of foundation models like Segment Anything, we first explore their assembly (SAA) to leverage diverse multi-modal prior knowledge for anomaly localization. Subsequently, we further introduce multimodal prompts (SAA$+$) derived from domain expert knowledge and target image context to enable the non-parameter adaptation of foundation models to anomaly segmentation. The proposed SAA$+$ model achieves state-of-the-art performance on several anomaly segmentation benchmarks, including VisA and MVTec-AD, in the zero-shot setting. We will release the code of our winning solution for the CVPR2023 VAN.
<div id='section'>Paperid: <span id='pid'>420, <a href='https://arxiv.org/pdf/2303.01201.pdf' target='_blank'>https://arxiv.org/pdf/2303.01201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Cheng, Fei Zhu, Xu-Yao Zhang, Cheng-Lin Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01201">Average of Pruning: Improving Performance and Stability of Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting Out-of-distribution (OOD) inputs have been a critical issue for neural networks in the open world. However, the unstable behavior of OOD detection along the optimization trajectory during training has not been explored clearly. In this paper, we first find the performance of OOD detection suffers from overfitting and instability during training: 1) the performance could decrease when the training error is near zero, and 2) the performance would vary sharply in the final stage of training. Based on our findings, we propose Average of Pruning (AoP), consisting of model averaging and pruning, to mitigate the unstable behaviors. Specifically, model averaging can help achieve a stable performance by smoothing the landscape, and pruning is certified to eliminate the overfitting by eliminating redundant features. Comprehensive experiments on various datasets and architectures are conducted to verify the effectiveness of our method.
<div id='section'>Paperid: <span id='pid'>421, <a href='https://arxiv.org/pdf/2210.13545.pdf' target='_blank'>https://arxiv.org/pdf/2210.13545.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julius Ott, Lorenzo Servadei, Jose Arjona-Medina, Enrico Rinaldi, Gianfranco Mauro, Daniela SÃ¡nchez Lopera, Michael Stephan, Thomas Stadelmayer, Avik Santra, Robert Wille
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.13545">MEET: A Monte Carlo Exploration-Exploitation Trade-off for Buffer Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data selection is essential for any data-based optimization technique, such as Reinforcement Learning. State-of-the-art sampling strategies for the experience replay buffer improve the performance of the Reinforcement Learning agent. However, they do not incorporate uncertainty in the Q-Value estimation. Consequently, they cannot adapt the sampling strategies, including exploration and exploitation of transitions, to the complexity of the task. To address this, this paper proposes a new sampling strategy that leverages the exploration-exploitation trade-off. This is enabled by the uncertainty estimation of the Q-Value function, which guides the sampling to explore more significant transitions and, thus, learn a more efficient policy. Experiments on classical control environments demonstrate stable results across various environments. They show that the proposed method outperforms state-of-the-art sampling strategies for dense rewards w.r.t. convergence and peak performance by 26% on average.
<div id='section'>Paperid: <span id='pid'>422, <a href='https://arxiv.org/pdf/2509.18954.pdf' target='_blank'>https://arxiv.org/pdf/2509.18954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minoo Dolatabadi, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18954">Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based localization and SLAM often rely on iterative matching algorithms, particularly the Iterative Closest Point (ICP) algorithm, to align sensor data with pre-existing maps or previous scans. However, ICP is prone to errors in featureless environments and dynamic scenes, leading to inaccurate pose estimation. Accurately predicting the uncertainty associated with ICP is crucial for robust state estimation but remains challenging, as existing approaches often rely on handcrafted models or simplified assumptions. Moreover, a few deep learning-based methods for localizability estimation either depend on a pre-built map, which may not always be available, or provide a binary classification of localizable versus non-localizable, which fails to properly model uncertainty. In this work, we propose a data-driven framework that leverages deep learning to estimate the registration error covariance of ICP before matching, even in the absence of a reference map. By associating each LiDAR scan with a reliable 6-DoF error covariance estimate, our method enables seamless integration of ICP within Kalman filtering, enhancing localization accuracy and robustness. Extensive experiments on the KITTI dataset demonstrate the effectiveness of our approach, showing that it accurately predicts covariance and, when applied to localization using a pre-built map or SLAM, reduces localization errors and improves robustness.
<div id='section'>Paperid: <span id='pid'>423, <a href='https://arxiv.org/pdf/2508.12997.pdf' target='_blank'>https://arxiv.org/pdf/2508.12997.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haishun Chen, Cai Xu, Jinlong Yu, Yilin Zhang, Ziyu Guan, Wei Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12997">Fairness-Aware Multi-view Evidential Learning with Adaptive Prior</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-view evidential learning aims to integrate information from multiple views to improve prediction performance and provide trustworthy uncertainty esitimation. Most previous methods assume that view-specific evidence learning is naturally reliable. However, in practice, the evidence learning process tends to be biased. Through empirical analysis on real-world data, we reveal that samples tend to be assigned more evidence to support data-rich classes, thereby leading to unreliable uncertainty estimation in predictions. This motivates us to delve into a new Biased Evidential Multi-view Learning (BEML) problem. To this end, we propose Fairness-Aware Multi-view Evidential Learning (FAML). FAML first introduces an adaptive prior based on training trajectory, which acts as a regularization strategy to flexibly calibrate the biased evidence learning process. Furthermore, we explicitly incorporate a fairness constraint based on class-wise evidence variance to promote balanced evidence allocation. In the multi-view fusion stage, we propose an opinion alignment mechanism to mitigate view-specific bias across views, thereby encouraging the integration of consistent and mutually supportive evidence. Extensive experiments on five real-world multi-view datasets demonstrate that FAML achieves more balanced evidence allocation and improves both prediction performance and the reliability of uncertainty estimation compared to state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>424, <a href='https://arxiv.org/pdf/2505.05903.pdf' target='_blank'>https://arxiv.org/pdf/2505.05903.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Umberto Albertin, Mauro Martini, Alessandro Navone, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.05903">Adaptive Robot Localization with Ultra-wideband Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultra-wideband (UWB) technology has shown remarkable potential as a low-cost general solution for robot localization. However, limitations of the UWB signal for precise positioning arise from the disturbances caused by the environment itself, due to reflectance, multi-path effect, and Non-Line-of-Sight (NLOS) conditions. This problem is emphasized in cluttered indoor spaces where service robotic platforms usually operate. Both model-based and learning-based methods are currently under investigation to precisely predict the UWB error patterns. Despite the great capability in approximating strong non-linearity, learning-based methods often do not consider environmental factors and require data collection and re-training for unseen data distributions, making them not practically feasible on a large scale. The goal of this research is to develop a robust and adaptive UWB localization method for indoor confined spaces. A novelty detection technique is used to recognize outlier conditions from nominal UWB range data with a semi-supervised autoencoder. Then, the obtained novelty scores are combined with an Extended Kalman filter, leveraging a dynamic estimation of covariance and bias error for each range measurement received from the UWB anchors. The resulting solution is a compact, flexible, and robust system which enables the localization system to adapt the trustworthiness of UWB data spatially and temporally in the environment. The extensive experimentation conducted with a real robot in a wide range of testing scenarios demonstrates the advantages and benefits of the proposed solution in indoor cluttered spaces presenting NLoS conditions, reaching an average improvement of almost 60% and greater than 25cm of absolute positioning error.
<div id='section'>Paperid: <span id='pid'>425, <a href='https://arxiv.org/pdf/2409.07135.pdf' target='_blank'>https://arxiv.org/pdf/2409.07135.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ariel Priarone, Umberto Albertin, Carlo Cena, Mauro Martini, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07135">Unsupervised Novelty Detection Methods Benchmarking with Wavelet Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty detection is a critical task in various engineering fields. Numerous approaches to novelty detection rely on supervised or semi-supervised learning, which requires labelled datasets for training. However, acquiring labelled data, when feasible, can be expensive and time-consuming. For these reasons, unsupervised learning is a powerful alternative that allows performing novelty detection without needing labelled samples. In this study, numerous unsupervised machine learning algorithms for novelty detection are compared, highlighting their strengths and weaknesses in the context of vibration sensing. The proposed framework uses a continuous metric, unlike most traditional methods that merely flag anomalous samples without quantifying the degree of anomaly. Moreover, a new dataset is gathered from an actuator vibrating at specific frequencies to benchmark the algorithms and evaluate the framework. Novel conditions are introduced by altering the input wave signal. Our findings offer valuable insights into the adaptability and robustness of unsupervised learning techniques for real-world novelty detection applications.
<div id='section'>Paperid: <span id='pid'>426, <a href='https://arxiv.org/pdf/2404.08517.pdf' target='_blank'>https://arxiv.org/pdf/2404.08517.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuan Xie, Jiayang Song, Zhehua Zhou, Yuheng Huang, Da Song, Lei Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08517">Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Large Language Models (LLMs) have seen widespread applications across numerous fields, their limited interpretability poses concerns regarding their safe operations from multiple aspects, e.g., truthfulness, robustness, and fairness. Recent research has started developing quality assurance methods for LLMs, introducing techniques such as offline detector-based or uncertainty estimation methods. However, these approaches predominantly concentrate on post-generation analysis, leaving the online safety analysis for LLMs during the generation phase an unexplored area. To bridge this gap, we conduct in this work a comprehensive evaluation of the effectiveness of existing online safety analysis methods on LLMs. We begin with a pilot study that validates the feasibility of detecting unsafe outputs in the early generation process. Following this, we establish the first publicly available benchmark of online safety analysis for LLMs, including a broad spectrum of methods, models, tasks, datasets, and evaluation metrics. Utilizing this benchmark, we extensively analyze the performance of state-of-the-art online safety analysis methods on both open-source and closed-source LLMs. This analysis reveals the strengths and weaknesses of individual methods and offers valuable insights into selecting the most appropriate method based on specific application scenarios and task requirements. Furthermore, we also explore the potential of using hybridization methods, i.e., combining multiple methods to derive a collective safety conclusion, to enhance the efficacy of online safety analysis for LLMs. Our findings indicate a promising direction for the development of innovative and trustworthy quality assurance methodologies for LLMs, facilitating their reliable deployments across diverse domains.
<div id='section'>Paperid: <span id='pid'>427, <a href='https://arxiv.org/pdf/2404.05351.pdf' target='_blank'>https://arxiv.org/pdf/2404.05351.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Umberto Albertin, Alessandro Navone, Mauro Martini, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.05351">Semi-Supervised Novelty Detection for Precise Ultra-Wideband Error Signal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultra-Wideband (UWB) technology is an emerging low-cost solution for localization in a generic environment. However, UWB signal can be affected by signal reflections and non-line-of-sight (NLoS) conditions between anchors; hence, in a broader sense, the specific geometry of the environment and the disposition of obstructing elements in the map may drastically hinder the reliability of UWB for precise robot localization. This work aims to mitigate this problem by learning a map-specific characterization of the UWB quality signal with a fingerprint semi-supervised novelty detection methodology. An unsupervised autoencoder neural network is trained on nominal UWB map conditions, and then it is used to predict errors derived from the introduction of perturbing novelties in the environment. This work poses a step change in the understanding of UWB localization and its reliability in evolving environmental conditions. The resulting performance of the proposed method is proved by fine-grained experiments obtained with a visual tracking ground truth.
<div id='section'>Paperid: <span id='pid'>428, <a href='https://arxiv.org/pdf/2404.04971.pdf' target='_blank'>https://arxiv.org/pdf/2404.04971.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianghao Wu, Dong Guo, Guotai Wang, Qiang Yue, Huijun Yu, Kang Li, Shaoting Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04971">FPL+: Filtered Pseudo Label-based Unsupervised Cross-Modality Adaptation for 3D Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adapting a medical image segmentation model to a new domain is important for improving its cross-domain transferability, and due to the expensive annotation process, Unsupervised Domain Adaptation (UDA) is appealing where only unlabeled images are needed for the adaptation. Existing UDA methods are mainly based on image or feature alignment with adversarial training for regularization, and they are limited by insufficient supervision in the target domain. In this paper, we propose an enhanced Filtered Pseudo Label (FPL+)-based UDA method for 3D medical image segmentation. It first uses cross-domain data augmentation to translate labeled images in the source domain to a dual-domain training set consisting of a pseudo source-domain set and a pseudo target-domain set. To leverage the dual-domain augmented images to train a pseudo label generator, domain-specific batch normalization layers are used to deal with the domain shift while learning the domain-invariant structure features, generating high-quality pseudo labels for target-domain images. We then combine labeled source-domain images and target-domain images with pseudo labels to train a final segmentor, where image-level weighting based on uncertainty estimation and pixel-level weighting based on dual-domain consensus are proposed to mitigate the adverse effect of noisy pseudo labels. Experiments on three public multi-modal datasets for Vestibular Schwannoma, brain tumor and whole heart segmentation show that our method surpassed ten state-of-the-art UDA methods, and it even achieved better results than fully supervised learning in the target domain in some cases.
<div id='section'>Paperid: <span id='pid'>429, <a href='https://arxiv.org/pdf/2312.02615.pdf' target='_blank'>https://arxiv.org/pdf/2312.02615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sungik Choi, Hankook Lee, Honglak Lee, Moontae Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.02615">Projection Regret: Reducing Background Bias for Novelty Detection via Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty detection is a fundamental task of machine learning which aims to detect abnormal ($\textit{i.e.}$ out-of-distribution (OOD)) samples. Since diffusion models have recently emerged as the de facto standard generative framework with surprising generation results, novelty detection via diffusion models has also gained much attention. Recent methods have mainly utilized the reconstruction property of in-distribution samples. However, they often suffer from detecting OOD samples that share similar background information to the in-distribution data. Based on our observation that diffusion models can \emph{project} any sample to an in-distribution sample with similar background information, we propose \emph{Projection Regret (PR)}, an efficient novelty detection method that mitigates the bias of non-semantic information. To be specific, PR computes the perceptual distance between the test image and its diffusion-based projection to detect abnormality. Since the perceptual distance often fails to capture semantic changes when the background information is dominant, we cancel out the background bias by comparing it against recursive projections. Extensive experiments demonstrate that PR outperforms the prior art of generative-model-based novelty detection methods by a significant margin.
<div id='section'>Paperid: <span id='pid'>430, <a href='https://arxiv.org/pdf/2308.04025.pdf' target='_blank'>https://arxiv.org/pdf/2308.04025.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Pan, Yuguang Yang, Yuheng Huang, Jixun Yao, Jingjing Yin, Yanni Hu, Heng Lu, Lei Ma, Jianjun Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04025">MSAC: Multiple Speech Attribute Control Method for Reliable Speech Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite notable progress, speech emotion recognition (SER) remains challenging due to the intricate and ambiguous nature of speech emotion, particularly in wild world. While current studies primarily focus on recognition and generalization abilities, our research pioneers an investigation into the reliability of SER methods in the presence of semantic data shifts and explores how to exert fine-grained control over various attributes inherent in speech signals to enhance speech emotion modeling. In this paper, we first introduce MSAC-SERNet, a novel unified SER framework capable of simultaneously handling both single-corpus and cross-corpus SER. Specifically, concentrating exclusively on the speech emotion attribute, a novel CNN-based SER model is presented to extract discriminative emotional representations, guided by additive margin softmax loss. Considering information overlap between various speech attributes, we propose a novel learning paradigm based on correlations of different speech attributes, termed Multiple Speech Attribute Control (MSAC), which empowers the proposed SER model to simultaneously capture fine-grained emotion-related features while mitigating the negative impact of emotion-agnostic representations. Furthermore, we make a first attempt to examine the reliability of the MSAC-SERNet framework using out-of-distribution detection methods. Experiments on both single-corpus and cross-corpus SER scenarios indicate that MSAC-SERNet not only consistently outperforms the baseline in all aspects, but achieves superior performance compared to state-of-the-art SER approaches.
<div id='section'>Paperid: <span id='pid'>431, <a href='https://arxiv.org/pdf/2307.10236.pdf' target='_blank'>https://arxiv.org/pdf/2307.10236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuheng Huang, Jiayang Song, Zhijie Wang, Shengming Zhao, Huaming Chen, Felix Juefei-Xu, Lei Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.10236">Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent performance leap of Large Language Models (LLMs) opens up new opportunities across numerous industrial applications and domains. However, erroneous generations, such as false predictions, misinformation, and hallucination made by LLMs, have also raised severe concerns for the trustworthiness of LLMs', especially in safety-, security- and reliability-sensitive scenarios, potentially hindering real-world adoptions. While uncertainty estimation has shown its potential for interpreting the prediction risks made by general machine learning (ML) models, little is known about whether and to what extent it can help explore an LLM's capabilities and counteract its undesired behavior. To bridge the gap, in this paper, we initiate an exploratory study on the risk assessment of LLMs from the lens of uncertainty. In particular, we experiment with twelve uncertainty estimation methods and four LLMs on four prominent natural language processing (NLP) tasks to investigate to what extent uncertainty estimation techniques could help characterize the prediction risks of LLMs. Our findings validate the effectiveness of uncertainty estimation for revealing LLMs' uncertain/non-factual predictions. In addition to general NLP tasks, we extensively conduct experiments with four LLMs for code generation on two datasets. We find that uncertainty estimation can potentially uncover buggy programs generated by LLMs. Insights from our study shed light on future design and development for reliable LLMs, facilitating further research toward enhancing the trustworthiness of LLMs.
<div id='section'>Paperid: <span id='pid'>432, <a href='https://arxiv.org/pdf/2306.08495.pdf' target='_blank'>https://arxiv.org/pdf/2306.08495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Miguel SÃ¡nchez SÃ¡nchez, Alberto Huertas CeldrÃ¡n, GÃ©rÃ´me Bovet, Gregorio MartÃ­nez PÃ©rez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08495">Single-board Device Individual Authentication based on Hardware Performance and Autoencoder Transformer Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The proliferation of the Internet of Things (IoT) has led to the emergence of crowdsensing applications, where a multitude of interconnected devices collaboratively collect and analyze data. Ensuring the authenticity and integrity of the data collected by these devices is crucial for reliable decision-making and maintaining trust in the system. Traditional authentication methods are often vulnerable to attacks or can be easily duplicated, posing challenges to securing crowdsensing applications. Besides, current solutions leveraging device behavior are mostly focused on device identification, which is a simpler task than authentication. To address these issues, an individual IoT device authentication framework based on hardware behavior fingerprinting and Transformer autoencoders is proposed in this work. This solution leverages the inherent imperfections and variations in IoT device hardware to differentiate between devices with identical specifications. By monitoring and analyzing the behavior of key hardware components, such as the CPU, GPU, RAM, and Storage on devices, unique fingerprints for each device are created. The performance samples are considered as time series data and used to train outlier detection transformer models, one per device and aiming to model its normal data distribution. Then, the framework is validated within a spectrum crowdsensing system leveraging Raspberry Pi devices. After a pool of experiments, the model from each device is able to individually authenticate it between the 45 devices employed for validation. An average True Positive Rate (TPR) of 0.74+-0.13 and an average maximum False Positive Rate (FPR) of 0.06+-0.09 demonstrate the effectiveness of this approach in enhancing authentication, security, and trust in crowdsensing applications.
<div id='section'>Paperid: <span id='pid'>433, <a href='https://arxiv.org/pdf/2110.11334.pdf' target='_blank'>https://arxiv.org/pdf/2110.11334.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingkang Yang, Kaiyang Zhou, Yixuan Li, Ziwei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.11334">Generalized Out-of-Distribution Detection: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical to ensuring the reliability and safety of machine learning systems. For instance, in autonomous driving, we would like the driving system to issue an alert and hand over the control to humans when it detects unusual scenes or objects that it has never seen during training time and cannot make a safe decision. The term, OOD detection, first emerged in 2017 and since then has received increasing attention from the research community, leading to a plethora of methods developed, ranging from classification-based to density-based to distance-based ones. Meanwhile, several other problems, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD), are closely related to OOD detection in terms of motivation and methodology. Despite common goals, these topics develop in isolation, and their subtle differences in definition and problem setting often confuse readers and practitioners. In this survey, we first present a unified framework called generalized OOD detection, which encompasses the five aforementioned problems, i.e., AD, ND, OSR, OOD detection, and OD. Under our framework, these five problems can be seen as special cases or sub-tasks, and are easier to distinguish. We then review each of these five areas by summarizing their recent technical developments, with a special focus on OOD detection methodologies. We conclude this survey with open challenges and potential research directions.
<div id='section'>Paperid: <span id='pid'>434, <a href='https://arxiv.org/pdf/2506.16590.pdf' target='_blank'>https://arxiv.org/pdf/2506.16590.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeyun Deng, Jasorsi Ghosh, Fiona Xie, Yuzhe Lu, Katia Sycara, Joseph Campbell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16590">Energy-Based Transfer for Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning algorithms often suffer from poor sample efficiency, making them challenging to apply in multi-task or continual learning settings. Efficiency can be improved by transferring knowledge from a previously trained teacher policy to guide exploration in new but related tasks. However, if the new task sufficiently differs from the teacher's training task, the transferred guidance may be sub-optimal and bias exploration toward low-reward behaviors. We propose an energy-based transfer learning method that uses out-of-distribution detection to selectively issue guidance, enabling the teacher to intervene only in states within its training distribution. We theoretically show that energy scores reflect the teacher's state-visitation density and empirically demonstrate improved sample efficiency and performance across both single-task and multi-task settings.
<div id='section'>Paperid: <span id='pid'>435, <a href='https://arxiv.org/pdf/2405.19320.pdf' target='_blank'>https://arxiv.org/pdf/2405.19320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shicong Cen, Jincheng Mei, Katayoon Goshvadi, Hanjun Dai, Tong Yang, Sherry Yang, Dale Schuurmans, Yuejie Chi, Bo Dai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19320">Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning from human feedback (RLHF) has demonstrated great promise in aligning large language models (LLMs) with human preference. Depending on the availability of preference data, both online and offline RLHF are active areas of investigation. A key bottleneck is understanding how to incorporate uncertainty estimation in the reward function learned from the preference data for RLHF, regardless of how the preference data is collected. While the principles of optimism or pessimism under uncertainty are well-established in standard reinforcement learning (RL), a practically-implementable and theoretically-grounded form amenable to large language models is not yet available, as standard techniques for constructing confidence intervals become intractable under arbitrary policy parameterizations.
  In this paper, we introduce a unified approach to online and offline RLHF -- value-incentivized preference optimization (VPO) -- which regularizes the maximum-likelihood estimate of the reward function with the corresponding value function, modulated by a $\textit{sign}$ to indicate whether the optimism or pessimism is chosen. VPO also directly optimizes the policy with implicit reward modeling, and therefore shares a simpler RLHF pipeline similar to direct preference optimization. Theoretical guarantees of VPO are provided for both online and offline settings, matching the rates of their standard RL counterparts. Moreover, experiments on text summarization and dialog verify the practicality and effectiveness of VPO.
<div id='section'>Paperid: <span id='pid'>436, <a href='https://arxiv.org/pdf/2402.12862.pdf' target='_blank'>https://arxiv.org/pdf/2402.12862.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wen Wu, Bo Li, Chao Zhang, Chung-Cheng Chiu, Qiujia Li, Junwen Bai, Tara N. Sainath, Philip C. Woodland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12862">Handling Ambiguity in Emotion: From Out-of-Domain Detection to Distribution Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The subjective perception of emotion leads to inconsistent labels from human annotators. Typically, utterances lacking majority-agreed labels are excluded when training an emotion classifier, which cause problems when encountering ambiguous emotional expressions during testing. This paper investigates three methods to handle ambiguous emotion. First, we show that incorporating utterances without majority-agreed labels as an additional class in the classifier reduces the classification performance of the other emotion classes. Then, we propose detecting utterances with ambiguous emotions as out-of-domain samples by quantifying the uncertainty in emotion classification using evidential deep learning. This approach retains the classification accuracy while effectively detects ambiguous emotion expressions. Furthermore, to obtain fine-grained distinctions among ambiguous emotions, we propose representing emotion as a distribution instead of a single class label. The task is thus re-framed from classification to distribution estimation where every individual annotation is taken into account, not just the majority opinion. The evidential uncertainty measure is extended to quantify the uncertainty in emotion distribution estimation. Experimental results on the IEMOCAP and CREMA-D datasets demonstrate the superior capability of the proposed method in terms of majority class prediction, emotion distribution estimation, and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>437, <a href='https://arxiv.org/pdf/2401.02611.pdf' target='_blank'>https://arxiv.org/pdf/2401.02611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyao Li, Pengguang Chen, Shaozuo Yu, Shu Liu, Jiaya Jia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02611">MOODv2: Masked Image Modeling for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The crux of effective out-of-distribution (OOD) detection lies in acquiring a robust in-distribution (ID) representation, distinct from OOD samples. While previous methods predominantly leaned on recognition-based techniques for this purpose, they often resulted in shortcut learning, lacking comprehensive representations. In our study, we conducted a comprehensive analysis, exploring distinct pretraining tasks and employing various OOD score functions. The results highlight that the feature representations pre-trained through reconstruction yield a notable enhancement and narrow the performance gap among various score functions. This suggests that even simple score functions can rival complex ones when leveraging reconstruction-based pretext tasks. Reconstruction-based pretext tasks adapt well to various score functions. As such, it holds promising potential for further expansion. Our OOD detection framework, MOODv2, employs the masked image modeling pretext task. Without bells and whistles, MOODv2 impressively enhances 14.30% AUROC to 95.68% on ImageNet and achieves 99.98% on CIFAR-10.
<div id='section'>Paperid: <span id='pid'>438, <a href='https://arxiv.org/pdf/2304.13019.pdf' target='_blank'>https://arxiv.org/pdf/2304.13019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aleksandar Petrov, Francisco Eiras, Amartya Sanyal, Philip H. S. Torr, Adel Bibi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.13019">Certifying Ensembles: A General Certification Theory with S-Lipschitzness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Improving and guaranteeing the robustness of deep learning models has been a topic of intense research. Ensembling, which combines several classifiers to provide a better model, has shown to be beneficial for generalisation, uncertainty estimation, calibration, and mitigating the effects of concept drift. However, the impact of ensembling on certified robustness is less well understood. In this work, we generalise Lipschitz continuity by introducing S-Lipschitz classifiers, which we use to analyse the theoretical robustness of ensembles. Our results are precise conditions when ensembles of robust classifiers are more robust than any constituent classifier, as well as conditions when they are less robust.
<div id='section'>Paperid: <span id='pid'>439, <a href='https://arxiv.org/pdf/2211.04834.pdf' target='_blank'>https://arxiv.org/pdf/2211.04834.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wen Wu, Chao Zhang, Philip C. Woodland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.04834">Distribution-based Emotion Recognition in Conversation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic emotion recognition in conversation (ERC) is crucial for emotion-aware conversational artificial intelligence. This paper proposes a distribution-based framework that formulates ERC as a sequence-to-sequence problem for emotion distribution estimation. The inherent ambiguity of emotions and the subjectivity of human perception lead to disagreements in emotion labels, which is handled naturally in our framework from the perspective of uncertainty estimation in emotion distributions. A Bayesian training loss is introduced to improve the uncertainty estimation by conditioning each emotional state on an utterance-specific Dirichlet prior distribution. Experimental results on the IEMOCAP dataset show that ERC outperformed the single-utterance-based system, and the proposed distribution-based ERC methods have not only better classification accuracy, but also show improved uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>440, <a href='https://arxiv.org/pdf/2203.04443.pdf' target='_blank'>https://arxiv.org/pdf/2203.04443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wen Wu, Chao Zhang, Xixin Wu, Philip C. Woodland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.04443">Estimating the Uncertainty in Emotion Class Labels with Utterance-Specific Dirichlet Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Emotion recognition is a key attribute for artificial intelligence systems that need to naturally interact with humans. However, the task definition is still an open problem due to the inherent ambiguity of emotions. In this paper, a novel Bayesian training loss based on per-utterance Dirichlet prior distributions is proposed for verbal emotion recognition, which models the uncertainty in one-hot labels created when human annotators assign the same utterance to different emotion classes. An additional metric is used to evaluate the performance by detection test utterances with high labelling uncertainty. This removes a major limitation that emotion classification systems only consider utterances with labels where the majority of annotators agree on the emotion class. Furthermore, a frequentist approach is studied to leverage the continuous-valued "soft" labels obtained by averaging the one-hot labels. We propose a two-branch model structure for emotion classification on a per-utterance basis, which achieves state-of-the-art classification results on the widely used IEMOCAP dataset. Based on this, uncertainty estimation experiments were performed. The best performance in terms of the area under the precision-recall curve when detecting utterances with high uncertainty was achieved by interpolating the Bayesian training loss with the Kullback-Leibler divergence training loss for the soft labels. The generality of the proposed approach was verified using the MSP-Podcast dataset which yielded the same pattern of results.
<div id='section'>Paperid: <span id='pid'>441, <a href='https://arxiv.org/pdf/2509.12982.pdf' target='_blank'>https://arxiv.org/pdf/2509.12982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erblin Isaku, Hassan Sartaj, Shaukat Ali, Beatriz Sanguino, Tongtong Wang, Guoyuan Li, Houxiang Zhang, Thomas Peyrucain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12982">Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-adaptive robots (SARs) in complex, uncertain environments must proactively detect and address abnormal behaviors, including out-of-distribution (OOD) cases. To this end, digital twins offer a valuable solution for OOD detection. Thus, we present a digital twin-based approach for OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to forecast SAR states and employs reconstruction error and Monte Carlo dropout for uncertainty quantification. By combining reconstruction error with predictive variance, the digital twin effectively detects OOD behaviors, even in previously unseen conditions. The digital twin also includes an explainability layer that links potential OOD to specific SAR states, offering insights for self-adaptation. We evaluated ODiSAR by creating digital twins of two industrial robots: one navigating an office environment, and another performing maritime ship navigation. In both cases, ODiSAR forecasts SAR behaviors (i.e., robot trajectories and vessel motion) and proactively detects OOD events. Our results showed that ODiSAR achieved high detection performance -- up to 98\% AUROC, 96\% TNR@TPR95, and 95\% F1-score -- while providing interpretable insights to support self-adaptation.
<div id='section'>Paperid: <span id='pid'>442, <a href='https://arxiv.org/pdf/2509.01564.pdf' target='_blank'>https://arxiv.org/pdf/2509.01564.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeguan Xiao, Diyang Dou, Boya Xiong, Yun Chen, Guanhua Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01564">Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have achieved remarkable success across a wide range of natural language tasks, but often exhibit overconfidence and generate plausible yet incorrect answers. This overconfidence, especially in models undergone Reinforcement Learning from Human Feedback (RLHF), poses significant challenges for reliable uncertainty estimation and safe deployment. In this paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel self-evaluation-based calibration method that leverages the internal hidden states of LLMs to derive more accurate confidence scores. Instead of relying on the model's final output, our approach extracts internal beliefs from multiple intermediate layers during self-evaluation. By aggregating these layer-wise beliefs and calculating the expectation over the resulting confidence score distribution, EAGLE produces a refined confidence score that more faithfully reflects the model's internal certainty. Extensive experiments on diverse datasets and LLMs demonstrate that EAGLE significantly improves calibration performance over existing baselines. We also provide an in-depth analysis of EAGLE, including a layer-wise examination of uncertainty patterns, a study of the impact of self-evaluation prompts, and an analysis of the effect of self-evaluation score range.
<div id='section'>Paperid: <span id='pid'>443, <a href='https://arxiv.org/pdf/2505.08685.pdf' target='_blank'>https://arxiv.org/pdf/2505.08685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meritxell Riera-Marin, Sikha O K, Julia Rodriguez-Comas, Matthias Stefan May, Zhaohong Pan, Xiang Zhou, Xiaokun Liang, Franciskus Xaverius Erick, Andrea Prenner, Cedric Hemon, Valentin Boussot, Jean-Louis Dillenseger, Jean-Claude Nunes, Abdul Qayyum, Moona Mazher, Steven A Niederer, Kaisar Kushibar, Carlos Martin-Isla, Petia Radeva, Karim Lekadir, Theodore Barfoot, Luis C. Garcia Peraza Herrera, Ben Glocker, Tom Vercauteren, Lucas Gago, Justin Englemann, Joy-Marie Kleiss, Anton Aubanell, Andreu Antolin, Javier Garcia-Lopez, Miguel A. Gonzalez Ballester, Adrian Galdran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08685">Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL) has become the dominant approach for medical image segmentation, yet ensuring the reliability and clinical applicability of these models requires addressing key challenges such as annotation variability, calibration, and uncertainty estimation. This is why we created the Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS), which highlights the critical role of multiple annotators in establishing a more comprehensive ground truth, emphasizing that segmentation is inherently subjective and that leveraging inter-annotator variability is essential for robust model evaluation. Seven teams participated in the challenge, submitting a variety of DL models evaluated using metrics such as Dice Similarity Coefficient (DSC), Expected Calibration Error (ECE), and Continuous Ranked Probability Score (CRPS). By incorporating consensus and dissensus ground truth, we assess how DL models handle uncertainty and whether their confidence estimates align with true segmentation performance. Our findings reinforce the importance of well-calibrated models, as better calibration is strongly correlated with the quality of the results. Furthermore, we demonstrate that segmentation models trained on diverse datasets and enriched with pre-trained knowledge exhibit greater robustness, particularly in cases deviating from standard anatomical structures. Notably, the best-performing models achieved high DSC and well-calibrated uncertainty estimates. This work underscores the need for multi-annotator ground truth, thorough calibration assessments, and uncertainty-aware evaluations to develop trustworthy and clinically reliable DL-based medical image segmentation models.
<div id='section'>Paperid: <span id='pid'>444, <a href='https://arxiv.org/pdf/2505.08685.pdf' target='_blank'>https://arxiv.org/pdf/2505.08685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meritxell Riera-Marin, Sikha O K, Julia Rodriguez-Comas, Matthias Stefan May, Zhaohong Pan, Xiang Zhou, Xiaokun Liang, Franciskus Xaverius Erick, Andrea Prenner, Cedric Hemon, Valentin Boussot, Jean-Louis Dillenseger, Jean-Claude Nunes, Abdul Qayyum, Moona Mazher, Steven A Niederer, Kaisar Kushibar, Carlos Martin-Isla, Petia Radeva, Karim Lekadir, Theodore Barfoot, Luis C. Garcia Peraza Herrera, Ben Glocker, Tom Vercauteren, Lucas Gago, Justin Englemann, Joy-Marie Kleiss, Anton Aubanell, Andreu Antolin, Javier Garcia-Lopez, Miguel A. Gonzalez Ballester, Adrian Galdran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08685">Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS) challenge results</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL) has become the dominant approach for medical image segmentation, yet ensuring the reliability and clinical applicability of these models requires addressing key challenges such as annotation variability, calibration, and uncertainty estimation. This is why we created the Calibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation (CURVAS), which highlights the critical role of multiple annotators in establishing a more comprehensive ground truth, emphasizing that segmentation is inherently subjective and that leveraging inter-annotator variability is essential for robust model evaluation. Seven teams participated in the challenge, submitting a variety of DL models evaluated using metrics such as Dice Similarity Coefficient (DSC), Expected Calibration Error (ECE), and Continuous Ranked Probability Score (CRPS). By incorporating consensus and dissensus ground truth, we assess how DL models handle uncertainty and whether their confidence estimates align with true segmentation performance. Our findings reinforce the importance of well-calibrated models, as better calibration is strongly correlated with the quality of the results. Furthermore, we demonstrate that segmentation models trained on diverse datasets and enriched with pre-trained knowledge exhibit greater robustness, particularly in cases deviating from standard anatomical structures. Notably, the best-performing models achieved high DSC and well-calibrated uncertainty estimates. This work underscores the need for multi-annotator ground truth, thorough calibration assessments, and uncertainty-aware evaluations to develop trustworthy and clinically reliable DL-based medical image segmentation models.
<div id='section'>Paperid: <span id='pid'>445, <a href='https://arxiv.org/pdf/2504.19816.pdf' target='_blank'>https://arxiv.org/pdf/2504.19816.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erblin Isaku, Hassan Sartaj, Shaukat Ali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19816">Digital Twin-based Out-of-Distribution Detection in Autonomous Vessels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An autonomous vessel (AV) is a complex cyber-physical system (CPS) with software enabling many key functionalities, e.g., navigation software enables an AV to autonomously or semi-autonomously follow a path to its destination. Digital twins of such AVs enable advanced functionalities such as running what-if scenarios, performing predictive maintenance, and enabling fault diagnosis. Due to technological improvements, real-time analyses using continuous data from vessels' real-time operations have become increasingly possible. However, the literature has little explored developing advanced analyses in real-time data in AVs with digital twins built with machine learning techniques. To this end, we present a novel digital twin-based approach (ODDIT) to detect future out-of-distribution (OOD) states of an AV before reaching them, enabling proactive intervention. Such states may indicate anomalies requiring attention (e.g., manual correction by the ship master) and assist testers in scenario-centered testing. The digital twin consists of two machine-learning models predicting future vessel states and whether the predicted state will be OOD. We evaluated ODDIT with five vessels across waypoint and zigzag maneuvering under simulated conditions, including sensor and actuator noise and environmental disturbances i.e., ocean current. ODDIT achieved high accuracy in detecting OOD states, with AUROC and TNR@TPR95 scores reaching 99\% across multiple vessels.
<div id='section'>Paperid: <span id='pid'>446, <a href='https://arxiv.org/pdf/2411.13163.pdf' target='_blank'>https://arxiv.org/pdf/2411.13163.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nabeel Seedat, Caterina Tozzi, Andrea Hita Ardiaca, Mihaela van der Schaar, James Weatherall, Adam Taylor
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13163">Unlocking Historical Clinical Trial Data with ALIGN: A Compositional Large Language Model System for Medical Coding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The reuse of historical clinical trial data has significant potential to accelerate medical research and drug development. However, interoperability challenges, particularly with missing medical codes, hinders effective data integration across studies. While Large Language Models (LLMs) offer a promising solution for automated coding without labeled data, current approaches face challenges on complex coding tasks. We introduce ALIGN, a novel compositional LLM-based system for automated, zero-shot medical coding. ALIGN follows a three-step process: (1) diverse candidate code generation; (2) self-evaluation of codes and (3) confidence scoring and uncertainty estimation enabling human deferral to ensure reliability. We evaluate ALIGN on harmonizing medication terms into Anatomical Therapeutic Chemical (ATC) and medical history terms into Medical Dictionary for Regulatory Activities (MedDRA) codes extracted from 22 immunology trials. ALIGN outperformed the LLM baselines, while also providing capabilities for trustworthy deployment. For MedDRA coding, ALIGN achieved high accuracy across all levels, matching RAG and excelling at the most specific levels (87-90% for HLGT). For ATC coding, ALIGN demonstrated superior performance, particularly at lower hierarchy levels (ATC Level 4), with 72-73% overall accuracy and 86-89% accuracy for common medications, outperforming baselines by 7-22%. ALIGN's uncertainty-based deferral improved accuracy by 17% to 90% accuracy with 30% deferral, notably enhancing performance on uncommon medications. ALIGN achieves this cost-efficiently at \$0.0007 and \$0.02 per code for GPT-4o-mini and GPT-4o, reducing barriers to clinical adoption. ALIGN advances automated medical coding for clinical trial data, contributing to enhanced data interoperability and reusability, positioning it as a promising tool to improve clinical research and accelerate drug development.
<div id='section'>Paperid: <span id='pid'>447, <a href='https://arxiv.org/pdf/2408.12970.pdf' target='_blank'>https://arxiv.org/pdf/2408.12970.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongjian Qiao, Jiafei Lyu, Kechen Jiao, Qi Liu, Xiu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12970">SUMO: Search-Based Uncertainty Estimation for Model-Based Offline Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The performance of offline reinforcement learning (RL) suffers from the limited size and quality of static datasets. Model-based offline RL addresses this issue by generating synthetic samples through a dynamics model to enhance overall performance. To evaluate the reliability of the generated samples, uncertainty estimation methods are often employed. However, model ensemble, the most commonly used uncertainty estimation method, is not always the best choice. In this paper, we propose a \textbf{S}earch-based \textbf{U}ncertainty estimation method for \textbf{M}odel-based \textbf{O}ffline RL (SUMO) as an alternative. SUMO characterizes the uncertainty of synthetic samples by measuring their cross entropy against the in-distribution dataset samples, and uses an efficient search-based method for implementation. In this way, SUMO can achieve trustworthy uncertainty estimation. We integrate SUMO into several model-based offline RL algorithms including MOPO and Adapted MOReL (AMOReL), and provide theoretical analysis for them. Extensive experimental results on D4RL datasets demonstrate that SUMO can provide more accurate uncertainty estimation and boost the performance of base algorithms. These indicate that SUMO could be a better uncertainty estimator for model-based offline RL when used in either reward penalty or trajectory truncation. Our code is available and will be open-source for further research and development.
<div id='section'>Paperid: <span id='pid'>448, <a href='https://arxiv.org/pdf/2405.14039.pdf' target='_blank'>https://arxiv.org/pdf/2405.14039.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, Zhuosheng Zhang, Rui Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14039">Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world data deviating from the independent and identically distributed (i.i.d.) assumption of in-distribution training data poses security threats to deep networks, thus advancing out-of-distribution (OOD) detection algorithms. Detection methods in generative language models (GLMs) mainly focus on uncertainty estimation and embedding distance measurement, with the latter proven to be most effective in traditional linguistic tasks like summarization and translation. However, another complex generative scenario mathematical reasoning poses significant challenges to embedding-based methods due to its high-density feature of output spaces, but this feature causes larger discrepancies in the embedding shift trajectory between different samples in latent spaces. Hence, we propose a trajectory-based method TV score, which uses trajectory volatility for OOD detection in mathematical reasoning. Experiments show that our method outperforms all traditional algorithms on GLMs under mathematical reasoning scenarios and can be extended to more applications with high-density features in output spaces, such as multiple-choice questions.
<div id='section'>Paperid: <span id='pid'>449, <a href='https://arxiv.org/pdf/2402.07320.pdf' target='_blank'>https://arxiv.org/pdf/2402.07320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ross Greer, Mohan Trivedi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07320">Towards Explainable, Safe Autonomous Driving with Language Embeddings for Novelty Identification and Active Learning: Framework and Experimental Analysis with Real-World Data Sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research explores the integration of language embeddings for active learning in autonomous driving datasets, with a focus on novelty detection. Novelty arises from unexpected scenarios that autonomous vehicles struggle to navigate, necessitating higher-level reasoning abilities. Our proposed method employs language-based representations to identify novel scenes, emphasizing the dual purpose of safety takeover responses and active learning. The research presents a clustering experiment using Contrastive Language-Image Pretrained (CLIP) embeddings to organize datasets and detect novelties. We find that the proposed algorithm effectively isolates novel scenes from a collection of subsets derived from two real-world driving datasets, one vehicle-mounted and one infrastructure-mounted. From the generated clusters, we further present methods for generating textual explanations of elements which differentiate scenes classified as novel from other scenes in the data pool, presenting qualitative examples from the clustered results. Our results demonstrate the effectiveness of language-driven embeddings in identifying novel elements and generating explanations of data, and we further discuss potential applications in safe takeovers, data curation, and multi-task active learning.
<div id='section'>Paperid: <span id='pid'>450, <a href='https://arxiv.org/pdf/2306.04663.pdf' target='_blank'>https://arxiv.org/pdf/2306.04663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elisabeth R. M. Heremans, Nabeel Seedat, Bertien Buyse, Dries Testelmans, Mihaela van der Schaar, Maarten De Vos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04663">U-PASS: an Uncertainty-guided deep learning Pipeline for Automated Sleep Staging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As machine learning becomes increasingly prevalent in critical fields such as healthcare, ensuring the safety and reliability of machine learning systems becomes paramount. A key component of reliability is the ability to estimate uncertainty, which enables the identification of areas of high and low confidence and helps to minimize the risk of error. In this study, we propose a machine learning pipeline called U-PASS tailored for clinical applications that incorporates uncertainty estimation at every stage of the process, including data acquisition, training, and model deployment. The training process is divided into a supervised pre-training step and a semi-supervised finetuning step. We apply our uncertainty-guided deep learning pipeline to the challenging problem of sleep staging and demonstrate that it systematically improves performance at every stage. By optimizing the training dataset, actively seeking informative samples, and deferring the most uncertain samples to an expert, we achieve an expert-level accuracy of 85% on a challenging clinical dataset of elderly sleep apnea patients, representing a significant improvement over the baseline accuracy of 75%. U-PASS represents a promising approach to incorporating uncertainty estimation into machine learning pipelines, thereby improving their reliability and unlocking their potential in clinical settings.
<div id='section'>Paperid: <span id='pid'>451, <a href='https://arxiv.org/pdf/2305.01823.pdf' target='_blank'>https://arxiv.org/pdf/2305.01823.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mojdeh Saadati, Aditya Balu, Shivani Chiranjeevi, Talukder Zaki Jubery, Asheesh K Singh, Soumik Sarkar, Arti Singh, Baskar Ganapathysubramanian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.01823">Out-of-distribution detection algorithms for robust insect classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based approaches have produced models with good insect classification accuracy; Most of these models are conducive for application in controlled environmental conditions. One of the primary emphasis of researchers is to implement identification and classification models in the real agriculture fields, which is challenging because input images that are wildly out of the distribution (e.g., images like vehicles, animals, humans, or a blurred image of an insect or insect class that is not yet trained on) can produce an incorrect insect classification. Out-of-distribution (OOD) detection algorithms provide an exciting avenue to overcome these challenge as it ensures that a model abstains from making incorrect classification prediction of non-insect and/or untrained insect class images. We generate and evaluate the performance of state-of-the-art OOD algorithms on insect detection classifiers. These algorithms represent a diversity of methods for addressing an OOD problem. Specifically, we focus on extrusive algorithms, i.e., algorithms that wrap around a well-trained classifier without the need for additional co-training. We compared three OOD detection algorithms: (i) Maximum Softmax Probability, which uses the softmax value as a confidence score, (ii) Mahalanobis distance-based algorithm, which uses a generative classification approach; and (iii) Energy-Based algorithm that maps the input data to a scalar value, called energy. We performed an extensive series of evaluations of these OOD algorithms across three performance axes: (a) \textit{Base model accuracy}: How does the accuracy of the classifier impact OOD performance? (b) How does the \textit{level of dissimilarity to the domain} impact OOD performance? and (c) \textit{Data imbalance}: How sensitive is OOD performance to the imbalance in per-class sample size?
<div id='section'>Paperid: <span id='pid'>452, <a href='https://arxiv.org/pdf/2205.13340.pdf' target='_blank'>https://arxiv.org/pdf/2205.13340.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingjian Li, Pengkun Yang, Yangcheng Gu, Xueying Zhan, Tianyang Wang, Min Xu, Chengzhong Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.13340">Deep Active Learning with Noise Stability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation for unlabeled data is crucial to active learning. With a deep neural network employed as the backbone model, the data selection process is highly challenging due to the potential over-confidence of the model inference. Existing methods resort to special learning fashions (e.g. adversarial) or auxiliary models to address this challenge. This tends to result in complex and inefficient pipelines, which would render the methods impractical. In this work, we propose a novel algorithm that leverages noise stability to estimate data uncertainty. The key idea is to measure the output derivation from the original observation when the model parameters are randomly perturbed by noise. We provide theoretical analyses by leveraging the small Gaussian noise theory and demonstrate that our method favors a subset with large and diverse gradients. Our method is generally applicable in various tasks, including computer vision, natural language processing, and structural data analysis. It achieves competitive performance compared against state-of-the-art active learning baselines.
<div id='section'>Paperid: <span id='pid'>453, <a href='https://arxiv.org/pdf/2509.15934.pdf' target='_blank'>https://arxiv.org/pdf/2509.15934.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingdong Wu, Long Yang, Jin Liu, Weiyao Huang, Lehong Wu, Zelin Chen, Daolin Ma, Hao Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15934">UniTac2Pose: A Unified Approach Learned in Simulation for Category-level Visuotactile In-hand Pose Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate estimation of the in-hand pose of an object based on its CAD model is crucial in both industrial applications and everyday tasks, ranging from positioning workpieces and assembling components to seamlessly inserting devices like USB connectors. While existing methods often rely on regression, feature matching, or registration techniques, achieving high precision and generalizability to unseen CAD models remains a significant challenge. In this paper, we propose a novel three-stage framework for in-hand pose estimation. The first stage involves sampling and pre-ranking pose candidates, followed by iterative refinement of these candidates in the second stage. In the final stage, post-ranking is applied to identify the most likely pose candidates. These stages are governed by a unified energy-based diffusion model, which is trained solely on simulated data. This energy model simultaneously generates gradients to refine pose estimates and produces an energy scalar that quantifies the quality of the pose estimates. Additionally, borrowing the idea from the computer vision domain, we incorporate a render-compare architecture within the energy-based score network to significantly enhance sim-to-real performance, as demonstrated by our ablation studies. We conduct comprehensive experiments to show that our method outperforms conventional baselines based on regression, matching, and registration techniques, while also exhibiting strong intra-category generalization to previously unseen CAD models. Moreover, our approach integrates tactile object pose estimation, pose tracking, and uncertainty estimation into a unified framework, enabling robust performance across a variety of real-world conditions.
<div id='section'>Paperid: <span id='pid'>454, <a href='https://arxiv.org/pdf/2509.11301.pdf' target='_blank'>https://arxiv.org/pdf/2509.11301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthias Wüest, Francis Engelmann, Ondrej Miksik, Marc Pollefeys, Daniel Barath
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11301">UnLoc: Leveraging Depth Uncertainties for Floorplan Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose UnLoc, an efficient data-driven solution for sequential camera localization within floorplans. Floorplan data is readily available, long-term persistent, and robust to changes in visual appearance. We address key limitations of recent methods, such as the lack of uncertainty modeling in depth predictions and the necessity for custom depth networks trained for each environment. We introduce a novel probabilistic model that incorporates uncertainty estimation, modeling depth predictions as explicit probability distributions. By leveraging off-the-shelf pre-trained monocular depth models, we eliminate the need to rely on per-environment-trained depth networks, enhancing generalization to unseen spaces. We evaluate UnLoc on large-scale synthetic and real-world datasets, demonstrating significant improvements over existing methods in terms of accuracy and robustness. Notably, we achieve $2.7$ times higher localization recall on long sequences (100 frames) and $16.7$ times higher on short ones (15 frames) than the state of the art on the challenging LaMAR HGE dataset.
<div id='section'>Paperid: <span id='pid'>455, <a href='https://arxiv.org/pdf/2506.23881.pdf' target='_blank'>https://arxiv.org/pdf/2506.23881.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Reihaneh Zohrabi, Hosein Hasani, Mahdieh Soleymani Baghshah, Anna Rohrbach, Marcus Rohrbach, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23881">Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring the reliability and safety of machine learning models in real-world applications, where they frequently face data distributions unseen during training. Despite progress, existing methods are often vulnerable to spurious correlations that mislead models and compromise robustness. To address this, we propose SPROD, a novel prototype-based OOD detection approach that explicitly addresses the challenge posed by unknown spurious correlations. Our post-hoc method refines class prototypes to mitigate bias from spurious features without additional data or hyperparameter tuning, and is broadly applicable across diverse backbones and OOD detection settings. We conduct a comprehensive spurious correlation OOD detection benchmarking, comparing our method against existing approaches and demonstrating its superior performance across challenging OOD datasets, such as CelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced Animals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3% over the second best.
<div id='section'>Paperid: <span id='pid'>456, <a href='https://arxiv.org/pdf/2503.05245.pdf' target='_blank'>https://arxiv.org/pdf/2503.05245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Johanna P. MÃ¼ller, Robert Wright, Thomas G. Day, Lorenzo Venturini, Samuel F. Budd, Hadrien Reynaud, Joseph V. Hajnal, Reza Razavi, Bernhard Kainz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05245">L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate analysis of prenatal ultrasound (US) is essential for early detection of developmental anomalies. However, operator dependency and technical limitations (e.g. intrinsic artefacts and effects, setting errors) can complicate image interpretation and the assessment of diagnostic uncertainty. We present L-FUSION (Laplacian Fetal US Segmentation with Integrated FoundatiON models), a framework that integrates uncertainty quantification through unsupervised, normative learning and large-scale foundation models for robust segmentation of fetal structures in normal and pathological scans. We propose to utilise the aleatoric logit distributions of Stochastic Segmentation Networks and Laplace approximations with fast Hessian estimations to estimate epistemic uncertainty only from the segmentation head. This enables us to achieve reliable abnormality quantification for instant diagnostic feedback. Combined with an integrated Dropout component, L-FUSION enables reliable differentiation of lesions from normal fetal anatomy with enhanced uncertainty maps and segmentation counterfactuals in US imaging. It improves epistemic and aleatoric uncertainty interpretation and removes the need for manual disease-labelling. Evaluations across multiple datasets show that L-FUSION achieves superior segmentation accuracy and consistent uncertainty quantification, supporting on-site decision-making and offering a scalable solution for advancing fetal ultrasound analysis in clinical settings.
<div id='section'>Paperid: <span id='pid'>457, <a href='https://arxiv.org/pdf/2410.08985.pdf' target='_blank'>https://arxiv.org/pdf/2410.08985.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Ni, Yu Wang, Lu Cheng, Erik Blasch, Tyler Derr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08985">Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, Knowledge Graphs (KGs) have been successfully coupled with Large Language Models (LLMs) to mitigate their hallucinations and enhance their reasoning capability, such as in KG-based retrieval-augmented frameworks. However, current KG-LLM frameworks lack rigorous uncertainty estimation, limiting their reliable deployment in high-stakes applications. Directly incorporating uncertainty quantification into KG-LLM frameworks presents challenges due to their complex architectures and the intricate interactions between the knowledge graph and language model components. To address this gap, we propose a new trustworthy KG-LLM framework, Uncertainty Aware Knowledge-Graph Reasoning (UAG), which incorporates uncertainty quantification into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning framework that leverages conformal prediction to provide a theoretical guarantee on the prediction set. To manage the error rate of the multi-step process, we additionally introduce an error rate control module to adjust the error rate within the individual components. Extensive experiments show that our proposed UAG can achieve any pre-defined coverage rate while reducing the prediction set/interval size by 40% on average over the baselines.
<div id='section'>Paperid: <span id='pid'>458, <a href='https://arxiv.org/pdf/2406.08391.pdf' target='_blank'>https://arxiv.org/pdf/2406.08391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanyam Kapoor, Nate Gruver, Manley Roberts, Katherine Collins, Arka Pal, Umang Bhatt, Adrian Weller, Samuel Dooley, Micah Goldblum, Andrew Gordon Wilson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08391">Large Language Models Must Be Taught to Know What They Don't Know</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When using large language models (LLMs) in high-stakes applications, we need to know when we can trust their predictions. Some works argue that prompting high-performance LLMs is sufficient to produce calibrated uncertainties, while others introduce sampling methods that can be prohibitively expensive. In this work, we first argue that prompting on its own is insufficient to achieve good calibration and then show that fine-tuning on a small dataset of correct and incorrect answers can create an uncertainty estimate with good generalization and small computational overhead. We show that a thousand graded examples are sufficient to outperform baseline methods and that training through the features of a model is necessary for good performance and tractable for large open-source models when using LoRA. We also investigate the mechanisms that enable reliable LLM uncertainty estimation, finding that many models can be used as general-purpose uncertainty estimators, applicable not just to their own uncertainties but also the uncertainty of other models. Lastly, we show that uncertainty estimates inform human use of LLMs in human-AI collaborative settings through a user study.
<div id='section'>Paperid: <span id='pid'>459, <a href='https://arxiv.org/pdf/2404.12862.pdf' target='_blank'>https://arxiv.org/pdf/2404.12862.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fiona Katharina Ewald, Ludwig Bothmann, Marvin N. Wright, Bernd Bischl, Giuseppe Casalicchio, Gunnar KÃ¶nig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12862">A Guide to Feature Importance Methods for Scientific Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While machine learning (ML) models are increasingly used due to their high predictive power, their use in understanding the data-generating process (DGP) is limited. Understanding the DGP requires insights into feature-target associations, which many ML models cannot directly provide due to their opaque internal mechanisms. Feature importance (FI) methods provide useful insights into the DGP under certain conditions. Since the results of different FI methods have different interpretations, selecting the correct FI method for a concrete use case is crucial and still requires expert knowledge. This paper serves as a comprehensive guide to help understand the different interpretations of global FI methods. Through an extensive review of FI methods and providing new proofs regarding their interpretation, we facilitate a thorough understanding of these methods and formulate concrete recommendations for scientific inference. We conclude by discussing options for FI uncertainty estimation and point to directions for future research aiming at full statistical inference from black-box ML models.
<div id='section'>Paperid: <span id='pid'>460, <a href='https://arxiv.org/pdf/2402.11223.pdf' target='_blank'>https://arxiv.org/pdf/2402.11223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Ni, Zhuowen Zou, Wenjun Huang, Hanning Chen, William Youngwoo Chung, Samuel Cho, Ranganath Krishnan, Pietro Mercati, Mohsen Imani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11223">HEAL: Brain-inspired Hyperdimensional Efficient Active Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Drawing inspiration from the outstanding learning capability of our human brains, Hyperdimensional Computing (HDC) emerges as a novel computing paradigm, and it leverages high-dimensional vector presentation and operations for brain-like lightweight Machine Learning (ML). Practical deployments of HDC have significantly enhanced the learning efficiency compared to current deep ML methods on a broad spectrum of applications. However, boosting the data efficiency of HDC classifiers in supervised learning remains an open question. In this paper, we introduce Hyperdimensional Efficient Active Learning (HEAL), a novel Active Learning (AL) framework tailored for HDC classification. HEAL proactively annotates unlabeled data points via uncertainty and diversity-guided acquisition, leading to a more efficient dataset annotation and lowering labor costs. Unlike conventional AL methods that only support classifiers built upon deep neural networks (DNN), HEAL operates without the need for gradient or probabilistic computations. This allows it to be effortlessly integrated with any existing HDC classifier architecture. The key design of HEAL is a novel approach for uncertainty estimation in HDC classifiers through a lightweight HDC ensemble with prior hypervectors. Additionally, by exploiting hypervectors as prototypes (i.e., compact representations), we develop an extra metric for HEAL to select diverse samples within each batch for annotation. Our evaluation shows that HEAL surpasses a diverse set of baselines in AL quality and achieves notably faster acquisition than many BNN-powered or diversity-guided AL methods, recording 11 times to 40,000 times speedup in acquisition runtime per batch.
<div id='section'>Paperid: <span id='pid'>461, <a href='https://arxiv.org/pdf/2312.09148.pdf' target='_blank'>https://arxiv.org/pdf/2312.09148.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anthony Chen, Huanrui Yang, Yulu Gan, Denis A Gudovskiy, Zhen Dong, Haofan Wang, Tomoyuki Okuno, Yohei Nakata, Kurt Keutzer, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09148">Split-Ensemble: Efficient OOD-aware Ensemble via Task and Model Splitting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial for machine learning models to detect out-of-distribution (OOD) inputs. However, the conventional discriminative deep learning classifiers produce uncalibrated closed-set predictions for OOD data. A more robust classifiers with the uncertainty estimation typically require a potentially unavailable OOD dataset for outlier exposure training, or a considerable amount of additional memory and compute to build ensemble models. In this work, we improve on uncertainty estimation without extra OOD data or additional inference costs using an alternative Split-Ensemble method. Specifically, we propose a novel subtask-splitting ensemble training objective, where a common multiclass classification task is split into several complementary subtasks. Then, each subtask's training data can be considered as OOD to the other subtasks. Diverse submodels can therefore be trained on each subtask with OOD-aware objectives. The subtask-splitting objective enables us to share low-level features across submodels to avoid parameter and computational overheads. In particular, we build a tree-like Split-Ensemble architecture by performing iterative splitting and pruning from a shared backbone model, where each branch serves as a submodel corresponding to a subtask. This leads to improved accuracy and uncertainty estimation across submodels under a fixed ensemble computation budget. Empirical study with ResNet-18 backbone shows Split-Ensemble, without additional computation cost, improves accuracy over a single model by 0.8%, 1.8%, and 25.5% on CIFAR-10, CIFAR-100, and Tiny-ImageNet, respectively. OOD detection for the same backbone and in-distribution datasets surpasses a single model baseline by, correspondingly, 2.2%, 8.1%, and 29.6% mean AUROC.
<div id='section'>Paperid: <span id='pid'>462, <a href='https://arxiv.org/pdf/2304.14030.pdf' target='_blank'>https://arxiv.org/pdf/2304.14030.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Han Liu, Zhoubing Xu, Riqiang Gao, Hao Li, Jianing Wang, Guillaume Chabin, Ipek Oguz, Sasa Grbic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.14030">COSST: Multi-organ Segmentation with Partially Labeled Datasets Using Comprehensive Supervisions and Self-training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models have demonstrated remarkable success in multi-organ segmentation but typically require large-scale datasets with all organs of interest annotated. However, medical image datasets are often low in sample size and only partially labeled, i.e., only a subset of organs are annotated. Therefore, it is crucial to investigate how to learn a unified model on the available partially labeled datasets to leverage their synergistic potential. In this paper, we systematically investigate the partial-label segmentation problem with theoretical and empirical analyses on the prior techniques. We revisit the problem from a perspective of partial label supervision signals and identify two signals derived from ground truth and one from pseudo labels. We propose a novel two-stage framework termed COSST, which effectively and efficiently integrates comprehensive supervision signals with self-training. Concretely, we first train an initial unified model using two ground truth-based signals and then iteratively incorporate the pseudo label signal to the initial model using self-training. To mitigate performance degradation caused by unreliable pseudo labels, we assess the reliability of pseudo labels via outlier detection in latent space and exclude the most unreliable pseudo labels from each self-training iteration. Extensive experiments are conducted on one public and three private partial-label segmentation tasks over 12 CT datasets. Experimental results show that our proposed COSST achieves significant improvement over the baseline method, i.e., individual networks trained on each partially labeled dataset. Compared to the state-of-the-art partial-label segmentation methods, COSST demonstrates consistent superior performance on various segmentation tasks and with different training data sizes.
<div id='section'>Paperid: <span id='pid'>463, <a href='https://arxiv.org/pdf/2508.05732.pdf' target='_blank'>https://arxiv.org/pdf/2508.05732.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pinxuan Li, Bing Cao, Changqing Zhang, Qinghua Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05732">Generalized Few-Shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Few-shot Out-of-Distribution (OOD) detection has emerged as a critical research direction in machine learning for practical deployment. Most existing Few-shot OOD detection methods suffer from insufficient generalization capability for the open world. Due to the few-shot learning paradigm, the OOD detection ability is often overfit to the limited training data itself, thus degrading the performance on generalized data and performing inconsistently across different scenarios. To address this challenge, we proposed a Generalized Few-shot OOD Detection (GOOD) framework, which empowers the general knowledge of the OOD detection model with an auxiliary General Knowledge Model (GKM), instead of directly learning from few-shot data. We proceed to reveal the few-shot OOD detection from a generalization perspective and theoretically derive the Generality-Specificity balance (GS-balance) for OOD detection, which provably reduces the upper bound of generalization error with a general knowledge model. Accordingly, we propose a Knowledge Dynamic Embedding (KDE) mechanism to adaptively modulate the guidance of general knowledge. KDE dynamically aligns the output distributions of the OOD detection model to the general knowledge model based on the Generalized Belief (G-Belief) of GKM, thereby boosting the GS-balance. Experiments on real-world OOD benchmarks demonstrate our superiority. Codes will be available.
<div id='section'>Paperid: <span id='pid'>464, <a href='https://arxiv.org/pdf/2503.12847.pdf' target='_blank'>https://arxiv.org/pdf/2503.12847.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Liu, Peike Li, Liying Yang, Dadong Wang, Lincheng Li, Xin Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.12847">Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately localizing audible objects based on audio-visual cues is the core objective of audio-visual segmentation. Most previous methods emphasize spatial or temporal multi-modal modeling, yet overlook challenges from ambiguous audio-visual correspondences such as nearby visually similar but acoustically different objects and frequent shifts in objects' sounding status. Consequently, they may struggle to reliably correlate audio and visual cues, leading to over- or under-segmentation. To address these limitations, we propose a novel framework with two primary components: an audio-guided modality alignment (AMA) module and an uncertainty estimation (UE) module. Instead of indiscriminately correlating audio-visual cues through a global attention mechanism, AMA performs audio-visual interactions within multiple groups and consolidates group features into compact representations based on their responsiveness to audio cues, effectively directing the model's attention to audio-relevant areas. Leveraging contrastive learning, AMA further distinguishes sounding regions from silent areas by treating features with strong audio responses as positive samples and weaker responses as negatives. Additionally, UE integrates spatial and temporal information to identify high-uncertainty regions caused by frequent changes in sound state, reducing prediction errors by lowering confidence in these areas. Experimental results demonstrate that our approach achieves superior accuracy compared to existing state-of-the-art methods, particularly in challenging scenarios where traditional approaches struggle to maintain reliable segmentation.
<div id='section'>Paperid: <span id='pid'>465, <a href='https://arxiv.org/pdf/2502.14429.pdf' target='_blank'>https://arxiv.org/pdf/2502.14429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>VilÃ©m Zouhar, Maike ZÃ¼fle, Beni Egressy, Julius Cheng, Mrinmaya Sachan, Jan Niehues
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14429">Early-Exit and Instant Confidence Translation Quality Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quality estimation is omnipresent in machine translation, for both evaluation and generation. Unfortunately, quality estimation models are often opaque and computationally expensive, making them impractical to be part of large-scale pipelines. In this work, we tackle two connected challenges: (1) reducing the cost of quality estimation at scale, and (2) developing an inexpensive uncertainty estimation method for quality estimation. To address the latter, we introduce Instant Confidence COMET, an uncertainty-aware quality estimation model that matches the performance of previous approaches at a fraction of their costs. We extend this to Early-Exit COMET, a quality estimation model that can compute quality scores and associated confidences already at early model layers, allowing us to early-exit computations and reduce evaluation costs. We also apply our model to machine translation reranking. We combine Early-Exit COMET with an upper confidence bound bandit algorithm to find the best candidate from a large pool without having to run the full evaluation model on all candidates. In both cases (evaluation and reranking) our methods reduce the required compute by 50% with very little degradation in performance. Finally, we show how Instant Confidence COMET can be used to decide which translations a human evaluator should score rather than relying on the COMET score.
<div id='section'>Paperid: <span id='pid'>466, <a href='https://arxiv.org/pdf/2411.14049.pdf' target='_blank'>https://arxiv.org/pdf/2411.14049.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haiyun Yao, Zongbo Han, Huazhu Fu, Xi Peng, Qinghua Hu, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14049">Out-Of-Distribution Detection with Diversification (Provably)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring reliable deployment of machine learning models. Recent advancements focus on utilizing easily accessible auxiliary outliers (e.g., data from the web or other datasets) in training. However, we experimentally reveal that these methods still struggle to generalize their detection capabilities to unknown OOD data, due to the limited diversity of the auxiliary outliers collected. Therefore, we thoroughly examine this problem from the generalization perspective and demonstrate that a more diverse set of auxiliary outliers is essential for enhancing the detection capabilities. However, in practice, it is difficult and costly to collect sufficiently diverse auxiliary outlier data. Therefore, we propose a simple yet practical approach with a theoretical guarantee, termed Diversity-induced Mixup for OOD detection (diverseMix), which enhances the diversity of auxiliary outlier set for training in an efficient way. Extensive experiments show that diverseMix achieves superior performance on commonly used and recent challenging large-scale benchmarks, which further confirm the importance of the diversity of auxiliary outliers.
<div id='section'>Paperid: <span id='pid'>467, <a href='https://arxiv.org/pdf/2405.11337.pdf' target='_blank'>https://arxiv.org/pdf/2405.11337.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Schmidt, Leonard Schenk, Leo Schwinn, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11337">A Unified Approach Towards Active Learning and Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When applying deep learning models in open-world scenarios, active learning (AL) strategies are crucial for identifying label candidates from a nearly infinite amount of unlabeled data. In this context, robust out-of-distribution (OOD) detection mechanisms are essential for handling data outside the target distribution of the application. However, current works investigate both problems separately. In this work, we introduce SISOM as the first unified solution for both AL and OOD detection. By leveraging feature space distance metrics SISOM combines the strengths of the currently independent tasks to solve both effectively. We conduct extensive experiments showing the problems arising when migrating between both tasks. In these evaluations SISOM underlined its effectiveness by achieving first place in two of the widely used OpenOOD benchmarks and second place in the remaining one. In AL, SISOM outperforms others and delivers top-1 performance in three benchmarks
<div id='section'>Paperid: <span id='pid'>468, <a href='https://arxiv.org/pdf/2401.08694.pdf' target='_blank'>https://arxiv.org/pdf/2401.08694.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mauricio Rivera, Jean-FranÃ§ois Godbout, Reihaneh Rabbany, Kellin Pelrine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08694">Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models have emerged as prime candidates to tackle misinformation mitigation. However, existing approaches struggle with hallucinations and overconfident predictions. We propose an uncertainty quantification framework that leverages both direct confidence elicitation and sampled-based consistency methods to provide better calibration for NLP misinformation mitigation solutions. We first investigate the calibration of sample-based consistency methods that exploit distinct features of consistency across sample sizes and stochastic levels. Next, we evaluate the performance and distributional shift of a robust numeric verbalization prompt across single vs. two-step confidence elicitation procedure. We also compare the performance of the same prompt with different versions of GPT and different numerical scales. Finally, we combine the sample-based consistency and verbalized methods to propose a hybrid framework that yields a better uncertainty estimation for GPT models. Overall, our work proposes novel uncertainty quantification methods that will improve the reliability of Large Language Models in misinformation mitigation applications.
<div id='section'>Paperid: <span id='pid'>469, <a href='https://arxiv.org/pdf/2311.10529.pdf' target='_blank'>https://arxiv.org/pdf/2311.10529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yichi Zhang, Shiyao Hu, Sijie Ren, Chen Jiang, Yuan Cheng, Yuan Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.10529">Enhancing the Reliability of Segment Anything Model for Auto-Prompting Medical Image Segmentation with Uncertainty Rectification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Segment Anything Model (SAM) has recently emerged as a groundbreaking foundation model for prompt-driven image segmentation tasks. However, both the original SAM and its medical variants require slice-by-slice manual prompting of target structures, which directly increase the burden for applications. Despite attempts of auto-prompting to turn SAM into a fully automatic manner, it still exhibits subpar performance and lacks of reliability especially in the field of medical imaging. In this paper, we propose UR-SAM, an uncertainty rectified SAM framework to enhance the reliability for auto-prompting medical image segmentation. Building upon a localization framework for automatic prompt generation, our method incorporates a prompt augmentation module to obtain a series of input prompts for SAM for uncertainty estimation and an uncertainty-based rectification module to further utilize the distribution of estimated uncertainty to improve the segmentation performance. Extensive experiments on two public 3D medical datasets covering the segmentation of 35 organs demonstrate that without supplementary training or fine-tuning, our method further improves the segmentation performance with up to 10.7 % and 13.8 % in dice similarity coefficient, demonstrating efficiency and broad capabilities for medical image segmentation without manual prompting.
<div id='section'>Paperid: <span id='pid'>470, <a href='https://arxiv.org/pdf/2311.00774.pdf' target='_blank'>https://arxiv.org/pdf/2311.00774.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nathaniel Diamant, Ehsan Hajiramezanali, Tommaso Biancalani, Gabriele Scalia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00774">Conformalized Deep Splines for Optimal and Efficient Prediction Sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is critical in high-stakes machine learning applications. One effective way to estimate uncertainty is conformal prediction, which can provide predictive inference with statistical coverage guarantees. We present a new conformal regression method, Spline Prediction Intervals via Conformal Estimation (SPICE), that estimates the conditional density using neural-network-parameterized splines. We prove universal approximation and optimality results for SPICE, which are empirically validated by our experiments. SPICE is compatible with two different efficient-to-compute conformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the other asymptotically optimal for conditional coverage (SPICE-HPD). Results on benchmark datasets demonstrate SPICE-ND models achieve the smallest average prediction set sizes, including average size reductions of nearly 50% for some datasets compared to the next best baseline. SPICE-HPD models achieve the best conditional coverage compared to baselines. The SPICE implementation is made available.
<div id='section'>Paperid: <span id='pid'>471, <a href='https://arxiv.org/pdf/2310.07220.pdf' target='_blank'>https://arxiv.org/pdf/2310.07220.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiyao Wang, Ruijie Zheng, Yanchao Sun, Ruonan Jia, Wichayaporn Wongkamjan, Huazhe Xu, Furong Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07220">COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dyna-style model-based reinforcement learning contains two phases: model rollouts to generate sample for policy learning and real environment exploration using current policy for dynamics model learning. However, due to the complex real-world environment, it is inevitable to learn an imperfect dynamics model with model prediction error, which can further mislead policy learning and result in sub-optimal solutions. In this paper, we propose $\texttt{COPlanner}$, a planning-driven framework for model-based methods to address the inaccurately learned dynamics model problem with conservative model rollouts and optimistic environment exploration. $\texttt{COPlanner}$ leverages an uncertainty-aware policy-guided model predictive control (UP-MPC) component to plan for multi-step uncertainty estimation. This estimated uncertainty then serves as a penalty during model rollouts and as a bonus during real environment exploration respectively, to choose actions. Consequently, $\texttt{COPlanner}$ can avoid model uncertain regions through conservative model rollouts, thereby alleviating the influence of model error. Simultaneously, it explores high-reward model uncertain regions to reduce model error actively through optimistic real environment exploration. $\texttt{COPlanner}$ is a plug-and-play framework that can be applied to any dyna-style model-based methods. Experimental results on a series of proprioceptive and visual continuous control tasks demonstrate that both sample efficiency and asymptotic performance of strong model-based methods are significantly improved combined with $\texttt{COPlanner}$.
<div id='section'>Paperid: <span id='pid'>472, <a href='https://arxiv.org/pdf/2309.02476.pdf' target='_blank'>https://arxiv.org/pdf/2309.02476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yong Lin, Chen Liu, Chenlu Ye, Qing Lian, Yuan Yao, Tong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02476">Optimal Sample Selection Through Uncertainty Estimation and Its Application in Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern deep learning heavily relies on large labeled datasets, which often comse with high costs in terms of both manual labeling and computational resources. To mitigate these challenges, researchers have explored the use of informative subset selection techniques, including coreset selection and active learning. Specifically, coreset selection involves sampling data with both input ($\bx$) and output ($\by$), active learning focuses solely on the input data ($\bx$).
  In this study, we present a theoretically optimal solution for addressing both coreset selection and active learning within the context of linear softmax regression. Our proposed method, COPS (unCertainty based OPtimal Sub-sampling), is designed to minimize the expected loss of a model trained on subsampled data. Unlike existing approaches that rely on explicit calculations of the inverse covariance matrix, which are not easily applicable to deep learning scenarios, COPS leverages the model's logits to estimate the sampling ratio. This sampling ratio is closely associated with model uncertainty and can be effectively applied to deep learning tasks. Furthermore, we address the challenge of model sensitivity to misspecification by incorporating a down-weighting approach for low-density samples, drawing inspiration from previous works.
  To assess the effectiveness of our proposed method, we conducted extensive empirical experiments using deep neural networks on benchmark datasets. The results consistently showcase the superior performance of COPS compared to baseline methods, reaffirming its efficacy.
<div id='section'>Paperid: <span id='pid'>473, <a href='https://arxiv.org/pdf/2308.07604.pdf' target='_blank'>https://arxiv.org/pdf/2308.07604.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roy T. Forestano, Konstantin T. Matchev, Katia Matcheva, Eyup B. Unlu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07604">Searching for Novel Chemistry in Exoplanetary Atmospheres using Machine Learning for Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The next generation of telescopes will yield a substantial increase in the availability of high-resolution spectroscopic data for thousands of exoplanets. The sheer volume of data and number of planets to be analyzed greatly motivate the development of new, fast and efficient methods for flagging interesting planets for reobservation and detailed analysis. We advocate the application of machine learning (ML) techniques for anomaly (novelty) detection to exoplanet transit spectra, with the goal of identifying planets with unusual chemical composition and even searching for unknown biosignatures. We successfully demonstrate the feasibility of two popular anomaly detection methods (Local Outlier Factor and One Class Support Vector Machine) on a large public database of synthetic spectra. We consider several test cases, each with different levels of instrumental noise. In each case, we use ROC curves to quantify and compare the performance of the two ML techniques.
<div id='section'>Paperid: <span id='pid'>474, <a href='https://arxiv.org/pdf/2307.14520.pdf' target='_blank'>https://arxiv.org/pdf/2307.14520.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soorena Salari, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.14520">FocalErrorNet: Uncertainty-aware focal modulation network for inter-modal registration error estimation in ultrasound-guided neurosurgery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In brain tumor resection, accurate removal of cancerous tissues while preserving eloquent regions is crucial to the safety and outcomes of the treatment. However, intra-operative tissue deformation (called brain shift) can move the surgical target and render the pre-surgical plan invalid. Intra-operative ultrasound (iUS) has been adopted to provide real-time images to track brain shift, and inter-modal (i.e., MRI-iUS) registration is often required to update the pre-surgical plan. Quality control for the registration results during surgery is important to avoid adverse outcomes, but manual verification faces great challenges due to difficult 3D visualization and the low contrast of iUS. Automatic algorithms are urgently needed to address this issue, but the problem was rarely attempted. Therefore, we propose a novel deep learning technique based on 3D focal modulation in conjunction with uncertainty estimation to accurately assess MRI-iUS registration errors for brain tumor surgery. Developed and validated with the public RESECT clinical database, the resulting algorithm can achieve an estimation error of 0.59+-0.57 mm.
<div id='section'>Paperid: <span id='pid'>475, <a href='https://arxiv.org/pdf/2307.08988.pdf' target='_blank'>https://arxiv.org/pdf/2307.08988.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingyu Chen, Ziyuan Yang, Chenyu Shen, Zhiwen Wang, Yang Qin, Yi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.08988">EVIL: Evidential Inference Learning for Trustworthy Semi-supervised Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, uncertainty-aware methods have attracted increasing attention in semi-supervised medical image segmentation. However, current methods usually suffer from the drawback that it is difficult to balance the computational cost, estimation accuracy, and theoretical support in a unified framework. To alleviate this problem, we introduce the Dempster-Shafer Theory of Evidence (DST) into semi-supervised medical image segmentation, dubbed Evidential Inference Learning (EVIL). EVIL provides a theoretically guaranteed solution to infer accurate uncertainty quantification in a single forward pass. Trustworthy pseudo labels on unlabeled data are generated after uncertainty estimation. The recently proposed consistency regularization-based training paradigm is adopted in our framework, which enforces the consistency on the perturbed predictions to enhance the generalization with few labeled data. Experimental results show that EVIL achieves competitive performance in comparison with several state-of-the-art methods on the public dataset.
<div id='section'>Paperid: <span id='pid'>476, <a href='https://arxiv.org/pdf/2306.06849.pdf' target='_blank'>https://arxiv.org/pdf/2306.06849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqian Ye, Yunsheng Ma, Xu Cao, Kun Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06849">Mitigating Transformer Overconfidence via Lipschitz Regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Though Transformers have achieved promising results in many computer vision tasks, they tend to be over-confident in predictions, as the standard Dot Product Self-Attention (DPSA) can barely preserve distance for the unbounded input domain. In this work, we fill this gap by proposing a novel Lipschitz Regularized Transformer (LRFormer). Specifically, we present a new similarity function with the distance within Banach Space to ensure the Lipschitzness and also regularize the term by a contractive Lipschitz Bound. The proposed method is analyzed with a theoretical guarantee, providing a rigorous basis for its effectiveness and reliability. Extensive experiments conducted on standard vision benchmarks demonstrate that our method outperforms the state-of-the-art single forward pass approaches in prediction, calibration, and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>477, <a href='https://arxiv.org/pdf/2306.02050.pdf' target='_blank'>https://arxiv.org/pdf/2306.02050.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingyang Zhang, Haitao Wu, Changqing Zhang, Qinghua Hu, Huazhu Fu, Joey Tianyi Zhou, Xi Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02050">Provable Dynamic Fusion for Low-Quality Multimodal Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The inherent challenge of multimodal fusion is to precisely capture the cross-modal correlation and flexibly conduct cross-modal interaction. To fully release the value of each modality and mitigate the influence of low-quality multimodal data, dynamic multimodal fusion emerges as a promising learning paradigm. Despite its widespread use, theoretical justifications in this field are still notably lacking. Can we design a provably robust multimodal fusion method? This paper provides theoretical understandings to answer this question under a most popular multimodal fusion framework from the generalization perspective. We proceed to reveal that several uncertainty estimation solutions are naturally available to achieve robust multimodal fusion. Then a novel multimodal fusion framework termed Quality-aware Multimodal Fusion (QMF) is proposed, which can improve the performance in terms of classification accuracy and model robustness. Extensive experimental results on multiple benchmarks can support our findings.
<div id='section'>Paperid: <span id='pid'>478, <a href='https://arxiv.org/pdf/2304.04148.pdf' target='_blank'>https://arxiv.org/pdf/2304.04148.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongbo Han, Zhipeng Liang, Fan Yang, Liu Liu, Lanqing Li, Yatao Bian, Peilin Zhao, Qinghua Hu, Bingzhe Wu, Changqing Zhang, Jianhua Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04148">Reweighted Mixup for Subpopulation Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Subpopulation shift exists widely in many real-world applications, which refers to the training and test distributions that contain the same subpopulation groups but with different subpopulation proportions. Ignoring subpopulation shifts may lead to significant performance degradation and fairness concerns. Importance reweighting is a classical and effective way to handle the subpopulation shift. However, recent studies have recognized that most of these approaches fail to improve the performance especially when applied to over-parameterized neural networks which are capable of fitting any training samples. In this work, we propose a simple yet practical framework, called reweighted mixup (RMIX), to mitigate the overfitting issue in over-parameterized models by conducting importance weighting on the ''mixed'' samples. Benefiting from leveraging reweighting in mixup, RMIX allows the model to explore the vicinal space of minority samples more, thereby obtaining more robust model against subpopulation shift. When the subpopulation memberships are unknown, the training-trajectories-based uncertainty estimation is equipped in the proposed RMIX to flexibly characterize the subpopulation distribution. We also provide insightful theoretical analysis to verify that RMIX achieves better generalization bounds over prior works. Further, we conduct extensive empirical studies across a wide range of tasks to validate the effectiveness of the proposed method.
<div id='section'>Paperid: <span id='pid'>479, <a href='https://arxiv.org/pdf/2303.12091.pdf' target='_blank'>https://arxiv.org/pdf/2303.12091.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Yu, Danruo Deng, Furui Liu, Yueming Jin, Qi Dou, Guangyong Chen, Pheng-Ann Heng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.12091">Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised learning (SSL) methods assume that labeled data, unlabeled data and test data are from the same distribution. Open-set semi-supervised learning (Open-set SSL) considers a more practical scenario, where unlabeled data and test data contain new categories (outliers) not observed in labeled data (inliers). Most previous works focused on outlier detection via binary classifiers, which suffer from insufficient scalability and inability to distinguish different types of uncertainty. In this paper, we propose a novel framework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these limitations. Concretely, we first introduce evidential deep learning (EDL) as an outlier detector to quantify different types of uncertainty, and design different uncertainty metrics for self-training and inference. Furthermore, we propose a novel adaptive negative optimization strategy, making EDL more tailored to the unlabeled dataset containing both inliers and outliers. As demonstrated empirically, our proposed method outperforms existing state-of-the-art methods across four datasets.
<div id='section'>Paperid: <span id='pid'>480, <a href='https://arxiv.org/pdf/2303.04766.pdf' target='_blank'>https://arxiv.org/pdf/2303.04766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florian Jaeckle, Fartash Faghri, Ali Farhadi, Oncel Tuzel, Hadi Pouransari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.04766">FastFill: Efficient Compatible Model Update</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many retrieval systems the original high dimensional data (e.g., images) is mapped to a lower dimensional feature through a learned embedding model. The task of retrieving the most similar data from a gallery set to a given query data is performed through a similarity comparison on features. When the embedding model is updated, it might produce features that are not comparable/compatible with features already in the gallery computed with the old model. Subsequently, all features in the gallery need to be re-computed using the new embedding model -- a computationally expensive process called backfilling. Recently, compatible representation learning methods have been proposed to avoid backfilling. Despite their relative success, there is an inherent trade-off between the new model performance and its compatibility with the old model. In this work, we introduce FastFill: a compatible model update process using feature alignment and policy based partial backfilling to promptly elevate retrieval performance. We show that previous backfilling strategies suffer from decreased performance and demonstrate the importance of both the training objective and the ordering in online partial backfilling. We propose a new training method for feature alignment between old and new embedding models using uncertainty estimation. Compared to previous works, we obtain significantly improved backfilling results on a variety of datasets: mAP on ImageNet (+4.4\%), Places-365 (+2.7\%), and VGG-Face2 (+1.3\%). Further, we demonstrate that when updating a biased model with FastFill, the minority subgroup accuracy gap promptly vanishes with a small fraction of partial backfilling.
<div id='section'>Paperid: <span id='pid'>481, <a href='https://arxiv.org/pdf/2303.02045.pdf' target='_blank'>https://arxiv.org/pdf/2303.02045.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danruo Deng, Guangyong Chen, Yang Yu, Furui Liu, Pheng-Ann Heng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02045">Uncertainty Estimation by Fisher Information-based Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a key factor that makes deep learning reliable in practical applications. Recently proposed evidential neural networks explicitly account for different uncertainties by treating the network's outputs as evidence to parameterize the Dirichlet distribution, and achieve impressive performance in uncertainty estimation. However, for high data uncertainty samples but annotated with the one-hot label, the evidence-learning process for those mislabeled classes is over-penalized and remains hindered. To address this problem, we propose a novel method, Fisher Information-based Evidential Deep Learning ($\mathcal{I}$-EDL). In particular, we introduce Fisher Information Matrix (FIM) to measure the informativeness of evidence carried by each sample, according to which we can dynamically reweight the objective loss terms to make the network more focused on the representation learning of uncertain classes. The generalization ability of our network is further improved by optimizing the PAC-Bayesian bound. As demonstrated empirically, our proposed method consistently outperforms traditional EDL-related algorithms in multiple uncertainty estimation tasks, especially in the more challenging few-shot classification settings.
<div id='section'>Paperid: <span id='pid'>482, <a href='https://arxiv.org/pdf/2507.14180.pdf' target='_blank'>https://arxiv.org/pdf/2507.14180.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14180">Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In line with the AI-native 6G vision, explainability and robustness are crucial for building trust and ensuring reliable performance in millimeter-wave (mmWave) systems. Efficient beam alignment is essential for initial access, but deep learning (DL) solutions face challenges, including high data collection overhead, hardware constraints, lack of explainability, and susceptibility to adversarial attacks. This paper proposes a robust and explainable DL-based beam alignment engine (BAE) for mmWave multiple-input multiple output (MIMO) systems. The BAE uses received signal strength indicator (RSSI) measurements from wide beams to predict the best narrow beam, reducing the overhead of exhaustive beam sweeping. To overcome the challenge of real-world data collection, this work leverages a site-specific digital twin (DT) to generate synthetic channel data closely resembling real-world environments. A model refinement via transfer learning is proposed to fine-tune the pre-trained model residing in the DT with minimal real-world data, effectively bridging mismatches between the digital replica and real-world environments. To reduce beam training overhead and enhance transparency, the framework uses deep Shapley additive explanations (SHAP) to rank input features by importance, prioritizing key spatial directions and minimizing beam sweeping. It also incorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a credibility metric for detecting out-of-distribution inputs and ensuring robust, transparent decision-making. Experimental results show that the proposed framework reduces real-world data needs by 70%, beam training overhead by 62%, and improves outlier detection robustness by up to 8.5x, achieving near-optimal spectral efficiency and transparent decision making compared to traditional softmax based DL models.
<div id='section'>Paperid: <span id='pid'>483, <a href='https://arxiv.org/pdf/2506.13474.pdf' target='_blank'>https://arxiv.org/pdf/2506.13474.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Bani-Harouni, Chantal Pellegrini, Ege Ãzsoy, Matthias Keicher, Nassir Navab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13474">Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clinical decision-making is a dynamic, interactive, and cyclic process where doctors have to repeatedly decide on which clinical action to perform and consider newly uncovered information for diagnosis and treatment. Large Language Models (LLMs) have the potential to support clinicians in this process, however, most applications of LLMs in clinical decision support suffer from one of two limitations: Either they assume the unrealistic scenario of immediate availability of all patient information and do not model the interactive and iterative investigation process, or they restrict themselves to the limited "out-of-the-box" capabilities of large pre-trained models without performing task-specific training. In contrast to this, we propose to model clinical decision-making for diagnosis with a hypothesis-driven uncertainty-aware language agent, LA-CDM, that converges towards a diagnosis via repeatedly requesting and interpreting relevant tests. Using a hybrid training paradigm combining supervised and reinforcement learning, we train LA-CDM with three objectives targeting critical aspects of clinical decision-making: accurate hypothesis generation, hypothesis uncertainty estimation, and efficient decision-making. We evaluate our methodology on MIMIC-CDM, a real-world dataset covering four abdominal diseases containing various clinical tests and show the benefit of explicitly training clinical decision-making for increasing diagnostic performance and efficiency.
<div id='section'>Paperid: <span id='pid'>484, <a href='https://arxiv.org/pdf/2505.14064.pdf' target='_blank'>https://arxiv.org/pdf/2505.14064.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cosmin I. Bercea, Jun Li, Philipp Raffler, Evamaria O. Riedel, Lena Schmitzer, Angela Kurz, Felix Bitzer, Paula RoÃmÃ¼ller, Julian Canisius, Mirjam L. Beyrle, Che Liu, Wenjia Bai, Bernhard Kainz, Julia A. Schnabel, Benedikt Wiestler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14064">NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many real-world applications, deployed models encounter inputs that differ from the data seen during training. Out-of-distribution detection identifies whether an input stems from an unseen distribution, while open-world recognition flags such inputs to ensure the system remains robust as ever-emerging, previously $unknown$ categories appear and must be addressed without retraining. Foundation and vision-language models are pre-trained on large and diverse datasets with the expectation of broad generalization across domains, including medical imaging. However, benchmarking these models on test sets with only a few common outlier types silently collapses the evaluation back to a closed-set problem, masking failures on rare or truly novel conditions encountered in clinical use.
  We therefore present $NOVA$, a challenging, real-life $evaluation-only$ benchmark of $\sim$900 brain MRI scans that span 281 rare pathologies and heterogeneous acquisition protocols. Each case includes rich clinical narratives and double-blinded expert bounding-box annotations. Together, these enable joint assessment of anomaly localisation, visual captioning, and diagnostic reasoning. Because NOVA is never used for training, it serves as an $extreme$ stress-test of out-of-distribution generalisation: models must bridge a distribution gap both in sample appearance and in semantic space. Baseline results with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B) reveal substantial performance drops across all tasks, establishing NOVA as a rigorous testbed for advancing models that can detect, localize, and reason about truly unknown anomalies.
<div id='section'>Paperid: <span id='pid'>485, <a href='https://arxiv.org/pdf/2501.17883.pdf' target='_blank'>https://arxiv.org/pdf/2501.17883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17883">Explainable and Robust Millimeter Wave Beam Alignment for AI-Native 6G Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Integrated artificial intelligence (AI) and communication has been recognized as a key pillar of 6G and beyond networks. In line with AI-native 6G vision, explainability and robustness in AI-driven systems are critical for establishing trust and ensuring reliable performance in diverse and evolving environments. This paper addresses these challenges by developing a robust and explainable deep learning (DL)-based beam alignment engine (BAE) for millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems. The proposed convolutional neural network (CNN)-based BAE utilizes received signal strength indicator (RSSI) measurements over a set of wide beams to accurately predict the best narrow beam for each UE, significantly reducing the overhead associated with exhaustive codebook-based narrow beam sweeping for initial access (IA) and data transmission. To ensure transparency and resilience, the Deep k-Nearest Neighbors (DkNN) algorithm is employed to assess the internal representations of the network via nearest neighbor approach, providing human-interpretable explanations and confidence metrics for detecting out-of-distribution inputs. Experimental results demonstrate that the proposed DL-based BAE exhibits robustness to measurement noise, reduces beam training overhead by 75% compared to the exhaustive search while maintaining near-optimal performance in terms of spectral efficiency. Moreover, the proposed framework improves outlier detection robustness by up to 5x and offers clearer insights into beam prediction decisions compared to traditional softmax-based classifiers.
<div id='section'>Paperid: <span id='pid'>486, <a href='https://arxiv.org/pdf/2410.00054.pdf' target='_blank'>https://arxiv.org/pdf/2410.00054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheng Zhang, Hossein Amiri, Dazhou Yu, Yuntong Hu, Liang Zhao, Andreas Zufle
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00054">Transferable Unsupervised Outlier Detection Framework for Human Semantic Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic trajectories, which enrich spatial-temporal data with textual information such as trip purposes or location activities, are key for identifying outlier behaviors critical to healthcare, social security, and urban planning. Traditional outlier detection relies on heuristic rules, which requires domain knowledge and limits its ability to identify unseen outliers. Besides, there lacks a comprehensive approach that can jointly consider multi-modal data across spatial, temporal, and textual dimensions. Addressing the need for a domain-agnostic model, we propose the Transferable Outlier Detection for Human Semantic Trajectories (TOD4Traj) framework.TOD4Traj first introduces a modality feature unification module to align diverse data feature representations, enabling the integration of multi-modal information and enhancing transferability across different datasets. A contrastive learning module is further pro-posed for identifying regular mobility patterns both temporally and across populations, allowing for a joint detection of outliers based on individual consistency and group majority patterns. Our experimental results have shown TOD4Traj's superior performance over existing models, demonstrating its effectiveness and adaptability in detecting human trajectory outliers across various datasets.
<div id='section'>Paperid: <span id='pid'>487, <a href='https://arxiv.org/pdf/2408.15580.pdf' target='_blank'>https://arxiv.org/pdf/2408.15580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinglun Li, Xinyu Zhou, Pinxue Guo, Yixuan Sun, Yiwen Huang, Weifeng Ge, Wenqiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15580">Hierarchical Visual Categories Modeling: A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution inputs for visual recognition models has become critical in safe deep learning. This paper proposes a novel hierarchical visual category modeling scheme to separate out-of-distribution data from in-distribution data through joint representation learning and statistical modeling. We learn a mixture of Gaussian models for each in-distribution category. There are many Gaussian mixture models to model different visual categories. With these Gaussian models, we design an in-distribution score function by aggregating multiple Mahalanobis-based metrics. We don't use any auxiliary outlier data as training samples, which may hurt the generalization ability of out-of-distribution detection algorithms. We split the ImageNet-1k dataset into ten folds randomly. We use one fold as the in-distribution dataset and the others as out-of-distribution datasets to evaluate the proposed method. We also conduct experiments on seven popular benchmarks, including CIFAR, iNaturalist, SUN, Places, Textures, ImageNet-O, and OpenImage-O. Extensive experiments indicate that the proposed method outperforms state-of-the-art algorithms clearly. Meanwhile, we find that our visual representation has a competitive performance when compared with features learned by classical methods. These results demonstrate that the proposed method hasn't weakened the discriminative ability of visual recognition models and keeps high efficiency in detecting out-of-distribution samples.
<div id='section'>Paperid: <span id='pid'>488, <a href='https://arxiv.org/pdf/2405.16460.pdf' target='_blank'>https://arxiv.org/pdf/2405.16460.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongwei Bran Li, Cheng Ouyang, Tamaz Amiranashvili, Matthew S. Rosen, Bjoern Menze, Juan Eugenio Iglesias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16460">Probabilistic Contrastive Learning with Explicit Concentration on the Hypersphere</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised contrastive learning has predominantly adopted deterministic methods, which are not suited for environments characterized by uncertainty and noise. This paper introduces a new perspective on incorporating uncertainty into contrastive learning by embedding representations within a spherical space, inspired by the von Mises-Fisher distribution (vMF). We introduce an unnormalized form of vMF and leverage the concentration parameter, kappa, as a direct, interpretable measure to quantify uncertainty explicitly. This approach not only provides a probabilistic interpretation of the embedding space but also offers a method to calibrate model confidence against varying levels of data corruption and characteristics. Our empirical results demonstrate that the estimated concentration parameter correlates strongly with the degree of unforeseen data corruption encountered at test time, enables failure analysis, and enhances existing out-of-distribution detection methods.
<div id='section'>Paperid: <span id='pid'>489, <a href='https://arxiv.org/pdf/2404.04865.pdf' target='_blank'>https://arxiv.org/pdf/2404.04865.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Fang, Yixuan Li, Feng Liu, Bo Han, Jie Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04865">On the Learnability of Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms, and corresponding learning theory is still an open problem. To study the generalization of OOD detection, this paper investigates the probably approximately correct (PAC) learning theory of OOD detection that fits the commonly used evaluation metrics in the literature. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we offer theoretical support for representative OOD detection works based on our OOD theory.
<div id='section'>Paperid: <span id='pid'>490, <a href='https://arxiv.org/pdf/2312.10390.pdf' target='_blank'>https://arxiv.org/pdf/2312.10390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>ChuXin Wang, Wenfei Yang, Tianzhu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10390">Not Every Side Is Equal: Localization Uncertainty Estimation for Semi-Supervised 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised 3D object detection from point cloud aims to train a detector with a small number of labeled data and a large number of unlabeled data. The core of existing methods lies in how to select high-quality pseudo-labels using the designed quality evaluation criterion. However, these methods treat each pseudo bounding box as a whole and assign equal importance to each side during training, which is detrimental to model performance due to many sides having poor localization quality. Besides, existing methods filter out a large number of low-quality pseudo-labels, which also contain some correct regression values that can help with model training. To address the above issues, we propose a side-aware framework for semi-supervised 3D object detection consisting of three key designs: a 3D bounding box parameterization method, an uncertainty estimation module, and a pseudo-label selection strategy. These modules work together to explicitly estimate the localization quality of each side and assign different levels of importance during the training phase. Extensive experiment results demonstrate that the proposed method can consistently outperform baseline models under different scenes and evaluation criteria. Moreover, our method achieves state-of-the-art performance on three datasets with different labeled ratios.
<div id='section'>Paperid: <span id='pid'>491, <a href='https://arxiv.org/pdf/2311.01796.pdf' target='_blank'>https://arxiv.org/pdf/2311.01796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qizhou Wang, Zhen Fang, Yonggang Zhang, Feng Liu, Yixuan Li, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.01796">Learning to Augment Distributions for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open-world classification systems should discern out-of-distribution (OOD) data whose labels deviate from those of in-distribution (ID) cases, motivating recent studies in OOD detection. Advanced works, despite their promising progress, may still fail in the open world, owing to the lack of knowledge about unseen OOD data in advance. Although one can access auxiliary OOD data (distinct from unseen ones) for model training, it remains to analyze how such auxiliary data will work in the open world. To this end, we delve into such a problem from a learning theory perspective, finding that the distribution discrepancy between the auxiliary and the unseen real OOD data is the key to affecting the open-world detection performance. Accordingly, we propose Distributional-Augmented OOD Learning (DAL), alleviating the OOD distribution discrepancy by crafting an OOD distribution set that contains all distributions in a Wasserstein ball centered on the auxiliary OOD distribution. We justify that the predictor trained over the worst OOD data in the ball can shrink the OOD distribution discrepancy, thus improving the open-world detection performance given only the auxiliary OOD data. We conduct extensive evaluations across representative OOD detection setups, demonstrating the superiority of our DAL over its advanced counterparts.
<div id='section'>Paperid: <span id='pid'>492, <a href='https://arxiv.org/pdf/2309.08925.pdf' target='_blank'>https://arxiv.org/pdf/2309.08925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao-Yin Liu, Xiao-Hu Zhou, Mei-Jiang Gui, Guo-Tao Li, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Qi-Chao Zhang, Biao Luo, Zeng-Guang Hou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.08925">DOMAIN: MilDly COnservative Model-BAsed OfflINe Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model-based reinforcement learning (RL), which learns an environment model from the offline dataset and generates more out-of-distribution model data, has become an effective approach to the problem of distribution shift in offline RL. Due to the gap between the learned and actual environment, conservatism should be incorporated into the algorithm to balance accurate offline data and imprecise model data. The conservatism of current algorithms mostly relies on model uncertainty estimation. However, uncertainty estimation is unreliable and leads to poor performance in certain scenarios, and the previous methods ignore differences between the model data, which brings great conservatism. To address the above issues, this paper proposes a milDly cOnservative Model-bAsed offlINe RL algorithm (DOMAIN) without estimating model uncertainty, and designs the adaptive sampling distribution of model samples, which can adaptively adjust the model data penalty. In this paper, we theoretically demonstrate that the Q value learned by the DOMAIN outside the region is a lower bound of the true Q value, the DOMAIN is less conservative than previous model-based offline RL algorithms, and has the guarantee of safety policy improvement. The results of extensive experiments show that DOMAIN outperforms prior RL algorithms and the average performance has improved by 1.8% on the D4RL benchmark.
<div id='section'>Paperid: <span id='pid'>493, <a href='https://arxiv.org/pdf/2210.14707.pdf' target='_blank'>https://arxiv.org/pdf/2210.14707.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Fang, Yixuan Li, Jie Lu, Jiahua Dong, Bo Han, Feng Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.14707">Is Out-of-Distribution Detection Learnable?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms. To study the generalization of OOD detection, in this paper, we investigate the probably approximately correct (PAC) learning theory of OOD detection, which is proposed by researchers as an open problem. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we also offer theoretical supports for several representative OOD detection works based on our OOD theory.
<div id='section'>Paperid: <span id='pid'>494, <a href='https://arxiv.org/pdf/2206.14502.pdf' target='_blank'>https://arxiv.org/pdf/2206.14502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H. S. Torr, Puneet K. Dokania
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.14502">RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy and Out Distribution Robustness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We show that the effectiveness of the well celebrated Mixup [Zhang et al., 2018] can be further improved if instead of using it as the sole learning objective, it is utilized as an additional regularizer to the standard cross-entropy loss. This simple change not only provides much improved accuracy but also significantly improves the quality of the predictive uncertainty estimation of Mixup in most cases under various forms of covariate shifts and out-of-distribution detection experiments. In fact, we observe that Mixup yields much degraded performance on detecting out-of-distribution samples possibly, as we show empirically, because of its tendency to learn models that exhibit high-entropy throughout; making it difficult to differentiate in-distribution samples from out-distribution ones. To show the efficacy of our approach (RegMixup), we provide thorough analyses and experiments on vision datasets (ImageNet & CIFAR-10/100) and compare it with a suite of recent approaches for reliable uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>495, <a href='https://arxiv.org/pdf/2206.03698.pdf' target='_blank'>https://arxiv.org/pdf/2206.03698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cosmin I. Bercea, Daniel Rueckert, Julia A. Schnabel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.03698">What do we learn? Debunking the Myth of Unsupervised Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Even though auto-encoders (AEs) have the desirable property of learning compact representations without labels and have been widely applied to out-of-distribution (OoD) detection, they are generally still poorly understood and are used incorrectly in detecting outliers where the normal and abnormal distributions are strongly overlapping. In general, the learned manifold is assumed to contain key information that is only important for describing samples within the training distribution, and that the reconstruction of outliers leads to high residual errors. However, recent work suggests that AEs are likely to be even better at reconstructing some types of OoD samples. In this work, we challenge this assumption and investigate what auto-encoders actually learn when they are posed to solve two different tasks. First, we propose two metrics based on the FrÃ©chet inception distance (FID) and confidence scores of a trained classifier to assess whether AEs can learn the training distribution and reliably recognize samples from other domains. Second, we investigate whether AEs are able to synthesize normal images from samples with abnormal regions, on a more challenging lung pathology detection task. We have found that state-of-the-art (SOTA) AEs are either unable to constrain the latent manifold and allow reconstruction of abnormal patterns, or they are failing to accurately restore the inputs from their latent distribution, resulting in blurred or misaligned reconstructions. We propose novel deformable auto-encoders (MorphAEus) to learn perceptually aware global image priors and locally adapt their morphometry based on estimated dense deformation fields. We demonstrate superior performance over unsupervised methods in detecting OoD and pathology.
<div id='section'>Paperid: <span id='pid'>496, <a href='https://arxiv.org/pdf/2507.13835.pdf' target='_blank'>https://arxiv.org/pdf/2507.13835.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin V. Vejling, Shashi Raj Pandey, Christophe A. N. Biscio, Petar Popovski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13835">Conformal Data Contamination Tests for Trading or Sharing of Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The amount of quality data in many machine learning tasks is limited to what is available locally to data owners. The set of quality data can be expanded through trading or sharing with external data agents. However, data buyers need quality guarantees before purchasing, as external data may be contaminated or irrelevant to their specific learning task. Previous works primarily rely on distributional assumptions about data from different agents, relegating quality checks to post-hoc steps involving costly data valuation procedures. We propose a distribution-free, contamination-aware data-sharing framework that identifies external data agents whose data is most valuable for model personalization. To achieve this, we introduce novel two-sample testing procedures, grounded in rigorous theoretical foundations for conformal outlier detection, to determine whether an agent's data exceeds a contamination threshold. The proposed tests, termed conformal data contamination tests, remain valid under arbitrary contamination levels while enabling false discovery rate control via the Benjamini-Hochberg procedure. Empirical evaluations across diverse collaborative learning scenarios demonstrate the robustness and effectiveness of our approach. Overall, the conformal data contamination test distinguishes itself as a generic procedure for aggregating data with statistically rigorous quality guarantees.
<div id='section'>Paperid: <span id='pid'>497, <a href='https://arxiv.org/pdf/2506.09548.pdf' target='_blank'>https://arxiv.org/pdf/2506.09548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taku Okawara, Kenji Koide, Aoki Takanose, Shuji Oishi, Masashi Yokozuka, Kentaro Uno, Kazuya Yoshida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09548">Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which is robust to challenging conditions such as featureless environments and deformable terrains. We developed an online learning-based leg kinematics model named the neural leg kinematics model, which incorporates tactile information (foot reaction force) to implicitly express the nonlinear dynamics between robot feet and the ground. Online training of this model enhances its adaptability to weight load changes of a robot (e.g., assuming delivery or transportation tasks) and terrain conditions. According to the \textit{neural adaptive leg odometry factor} and online uncertainty estimation of the leg kinematics model-based motion predictions, we jointly solve online training of this kinematics model and odometry estimation on a unified factor graph to retain the consistency of both. The proposed method was verified through real experiments using a quadruped robot in two challenging situations: 1) a sandy beach, representing an extremely featureless area with a deformable terrain, and 2) a campus, including multiple featureless areas and terrain types of asphalt, gravel (deformable terrain), and grass. Experimental results showed that our odometry estimation incorporating the \textit{neural leg kinematics model} outperforms state-of-the-art works. Our project page is available for further details: https://takuokawara.github.io/RAL2025_project_page/
<div id='section'>Paperid: <span id='pid'>498, <a href='https://arxiv.org/pdf/2505.19073.pdf' target='_blank'>https://arxiv.org/pdf/2505.19073.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Li, Jing Long, Muge Qi, Heming Xia, Lei Sha, Peiyi Wang, Zhifang Sui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19073">Towards Harmonized Uncertainty Estimation for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To facilitate robust and trustworthy deployment of large language models (LLMs), it is essential to quantify the reliability of their generations through uncertainty estimation. While recent efforts have made significant advancements by leveraging the internal logic and linguistic features of LLMs to estimate uncertainty scores, our empirical analysis highlights the pitfalls of these methods to strike a harmonized estimation between indication, balance, and calibration, which hinders their broader capability for accurate uncertainty estimation. To address this challenge, we propose CUE (Corrector for Uncertainty Estimation): A straightforward yet effective method that employs a lightweight model trained on data aligned with the target LLM's performance to adjust uncertainty scores. Comprehensive experiments across diverse models and tasks demonstrate its effectiveness, which achieves consistent improvements of up to 60% over existing methods.
<div id='section'>Paperid: <span id='pid'>499, <a href='https://arxiv.org/pdf/2505.17048.pdf' target='_blank'>https://arxiv.org/pdf/2505.17048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Agam Shah, Siddhant Sukhani, Huzaifa Pardawala, Saketh Budideti, Riya Bhadani, Rudra Gopal, Siddhartha Somani, Michael Galarnyk, Soungmin Lee, Arnav Hiray, Akshar Ravichandran, Eric Kim, Pranav Aluru, Joshua Zhang, Sebastian Jaskowski, Veer Guda, Meghaj Tarte, Liqin Ye, Spencer Gosden, Rutwik Routu, Rachel Yuh, Sloka Chava, Sahasra Chava, Dylan Patrick Kelly, Aiden Chiang, Harsit Mittal, Sudheer Chava
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17048">Words That Unite The World: A Unified Framework for Deciphering Central Bank Communications Globally</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Central banks around the world play a crucial role in maintaining economic stability. Deciphering policy implications in their communications is essential, especially as misinterpretations can disproportionately impact vulnerable populations. To address this, we introduce the World Central Banks (WCB) dataset, the most comprehensive monetary policy corpus to date, comprising over 380k sentences from 25 central banks across diverse geographic regions, spanning 28 years of historical data. After uniformly sampling 1k sentences per bank (25k total) across all available years, we annotate and review each sentence using dual annotators, disagreement resolutions, and secondary expert reviews. We define three tasks: Stance Detection, Temporal Classification, and Uncertainty Estimation, with each sentence annotated for all three. We benchmark seven Pretrained Language Models (PLMs) and nine Large Language Models (LLMs) (Zero-Shot, Few-Shot, and with annotation guide) on these tasks, running 15,075 benchmarking experiments. We find that a model trained on aggregated data across banks significantly surpasses a model trained on an individual bank's data, confirming the principle "the whole is greater than the sum of its parts." Additionally, rigorous human evaluations, error analyses, and predictive tasks validate our framework's economic utility. Our artifacts are accessible through the HuggingFace and GitHub under the CC-BY-NC-SA 4.0 license.
<div id='section'>Paperid: <span id='pid'>500, <a href='https://arxiv.org/pdf/2503.00325.pdf' target='_blank'>https://arxiv.org/pdf/2503.00325.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Ling, Yachen Chang, Hailiang Zhao, Xinkui Zhao, Kingsum Chow, Shuiguang Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00325">CADRef: Robust Out-of-Distribution Detection via Class-Aware Decoupled Relative Feature Leveraging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) have been widely criticized for their overconfidence when dealing with out-of-distribution (OOD) samples, highlighting the critical need for effective OOD detection to ensure the safe deployment of DNNs in real-world settings. Existing post-hoc OOD detection methods primarily enhance the discriminative power of logit-based approaches by reshaping sample features, yet they often neglect critical information inherent in the features themselves. In this paper, we propose the Class-Aware Relative Feature-based method (CARef), which utilizes the error between a sample's feature and its class-aware average feature as a discriminative criterion. To further refine this approach, we introduce the Class-Aware Decoupled Relative Feature-based method (CADRef), which decouples sample features based on the alignment of signs between the relative feature and corresponding model weights, enhancing the discriminative capabilities of CARef. Extensive experimental results across multiple datasets and models demonstrate that both proposed methods exhibit effectiveness and robustness in OOD detection compared to state-of-the-art methods. Specifically, our two methods outperform the best baseline by 2.82% and 3.27% in AUROC, with improvements of 4.03% and 6.32% in FPR95, respectively.
<div id='section'>Paperid: <span id='pid'>501, <a href='https://arxiv.org/pdf/2412.09333.pdf' target='_blank'>https://arxiv.org/pdf/2412.09333.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan-Lucas Uslu, Alexey Nekrasov, Alexander Hermans, Bernd Beschoten, Bastian Leibe, Lutz Waldecker, Christoph Stampfer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09333">MaskTerial: A Foundation Model for Automated 2D Material Flake Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection and classification of exfoliated two-dimensional (2D) material flakes from optical microscope images can be automated using computer vision algorithms. This has the potential to increase the accuracy and objectivity of classification and the efficiency of sample fabrication, and it allows for large-scale data collection. Existing algorithms often exhibit challenges in identifying low-contrast materials and typically require large amounts of training data. Here, we present a deep learning model, called MaskTerial, that uses an instance segmentation network to reliably identify 2D material flakes. The model is extensively pre-trained using a synthetic data generator, that generates realistic microscopy images from unlabeled data. This results in a model that can to quickly adapt to new materials with as little as 5 to 10 images. Furthermore, an uncertainty estimation model is used to finally classify the predictions based on optical contrast. We evaluate our method on eight different datasets comprising five different 2D materials and demonstrate significant improvements over existing techniques in the detection of low-contrast materials such as hexagonal boron nitride.
<div id='section'>Paperid: <span id='pid'>502, <a href='https://arxiv.org/pdf/2412.03792.pdf' target='_blank'>https://arxiv.org/pdf/2412.03792.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Li, Anouck Girard, Ilya Kolmanovsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03792">Safe Adaptive Cruise Control Under Perception Uncertainty: A Deep Ensemble and Conformal Tube Model Predictive Control Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving heavily relies on perception systems to interpret the environment for decision-making. To enhance robustness in these safety critical applications, this paper considers a Deep Ensemble of Deep Neural Network regressors integrated with Conformal Prediction to predict and quantify uncertainties. In the Adaptive Cruise Control setting, the proposed method performs state and uncertainty estimation from RGB images, informing the downstream controller of the DNN perception uncertainties. An adaptive cruise controller using Conformal Tube Model Predictive Control is designed to ensure probabilistic safety. Evaluations with a high-fidelity simulator demonstrate the algorithm's effectiveness in speed tracking and safe distance maintaining, including in Out-Of-Distribution scenarios.
<div id='section'>Paperid: <span id='pid'>503, <a href='https://arxiv.org/pdf/2411.09553.pdf' target='_blank'>https://arxiv.org/pdf/2411.09553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junwen Wang, Zhonghao Wang, Oscar MacCormac, Jonathan Shapey, Tom Vercauteren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09553">OOD-SEG: Exploiting out-of-distribution detection techniques for learning image segmentation from sparse multi-class positive-only annotations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite significant advancements, segmentation based on deep neural networks in medical and surgical imaging faces several challenges, two of which we aim to address in this work. First, acquiring complete pixel-level segmentation labels for medical images is time-consuming and requires domain expertise. Second, typical segmentation pipelines cannot detect out-of-distribution (OOD) pixels, leaving them prone to spurious outputs during deployment. In this work, we propose a novel segmentation approach which broadly falls within the positive-unlabelled (PU) learning paradigm and exploits tools from OOD detection techniques. Our framework learns only from sparsely annotated pixels from multiple positive-only classes and does not use any annotation for the background class. These multi-class positive annotations naturally fall within the in-distribution (ID) set. Unlabelled pixels may contain positive classes but also negative ones, including what is typically referred to as \emph{background} in standard segmentation formulations. Here, we forgo the need for background annotation and consider these together with any other unseen classes as part of the OOD set. Our framework can integrate, at a pixel-level, any OOD detection approaches designed for classification tasks. To address the lack of existing OOD datasets and established evaluation metric for medical image segmentation, we propose a cross-validation strategy that treats held-out labelled classes as OOD. Extensive experiments on both multi-class hyperspectral and RGB surgical imaging datasets demonstrate the robustness and generalisation capability of our proposed framework.
<div id='section'>Paperid: <span id='pid'>504, <a href='https://arxiv.org/pdf/2408.10885.pdf' target='_blank'>https://arxiv.org/pdf/2408.10885.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomoyasu Nanaumi, Kazuhiko Kawamoto, Hiroshi Kera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10885">Low-Quality Image Detection by Hierarchical VAE</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To make an employee roster, photo album, or training dataset of generative models, one needs to collect high-quality images while dismissing low-quality ones. This study addresses a new task of unsupervised detection of low-quality images. We propose a method that not only detects low-quality images with various types of degradation but also provides visual clues of them based on an observation that partial reconstruction by hierarchical variational autoencoders fails for low-quality images. The experiments show that our method outperforms several unsupervised out-of-distribution detection methods and also gives visual clues for low-quality images that help humans recognize them even in thumbnail view.
<div id='section'>Paperid: <span id='pid'>505, <a href='https://arxiv.org/pdf/2408.06742.pdf' target='_blank'>https://arxiv.org/pdf/2408.06742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yina He, Lei Peng, Yongcun Zhang, Juanjuan Weng, Zhiming Luo, Shaozi Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06742">Long-Tailed Out-of-Distribution Detection: Prioritizing Attention to Tail</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current out-of-distribution (OOD) detection methods typically assume balanced in-distribution (ID) data, while most real-world data follow a long-tailed distribution. Previous approaches to long-tailed OOD detection often involve balancing the ID data by reducing the semantics of head classes. However, this reduction can severely affect the classification accuracy of ID data. The main challenge of this task lies in the severe lack of features for tail classes, leading to confusion with OOD data. To tackle this issue, we introduce a novel Prioritizing Attention to Tail (PATT) method using augmentation instead of reduction. Our main intuition involves using a mixture of von Mises-Fisher (vMF) distributions to model the ID data and a temperature scaling module to boost the confidence of ID data. This enables us to generate infinite contrastive pairs, implicitly enhancing the semantics of ID classes while promoting differentiation between ID and OOD data. To further strengthen the detection of OOD data without compromising the classification performance of ID data, we propose feature calibration during the inference phase. By extracting an attention weight from the training set that prioritizes the tail classes and reduces the confidence in OOD data, we improve the OOD detection capability. Extensive experiments verified that our method outperforms the current state-of-the-art methods on various benchmarks.
<div id='section'>Paperid: <span id='pid'>506, <a href='https://arxiv.org/pdf/2402.07403.pdf' target='_blank'>https://arxiv.org/pdf/2402.07403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiyi Wang, Yang Nan, Felder Federico N, Sheng Zhang, Walsh Simon L F, Guang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07403">Make it more specific: A novel uncertainty based airway segmentation application on 3D U-Net and its variants</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Each medical segmentation task should be considered with a specific AI algorithm based on its scenario so that the most accurate prediction model can be obtained. The most popular algorithms in medical segmentation, 3D U-Net and its variants, can directly implement the task of lung trachea segmentation, but its failure to consider the special tree-like structure of the trachea suggests that there is much room for improvement in its segmentation accuracy. Therefore, a research gap exists because a great amount of state-of-the-art DL algorithms are vanilla 3D U-Net structures, which do not introduce the various performance-enhancing modules that come with special natural image modality in lung airway segmentation. In this paper, we proposed two different network structures Branch-Level U-Net (B-UNet) and Branch-Level CE-UNet (B-CE-UNet) which are based on U-Net structure and compared the prediction results with the same dataset. Specially, both of the two networks add branch loss and central line loss to learn the feature of fine branch endings of the airways. Uncertainty estimation algorithms are also included to attain confident predictions and thereby, increase the overall trustworthiness of our whole model. In addition, predictions of the lung trachea based on the maximum connectivity rate were calculated and extracted during post-processing for segmentation refinement and pruning.
<div id='section'>Paperid: <span id='pid'>507, <a href='https://arxiv.org/pdf/2309.16364.pdf' target='_blank'>https://arxiv.org/pdf/2309.16364.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Songlin Wei, Jiazhao Zhang, Yang Wang, Fanbo Xiang, Hao Su, He Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16364">FG-NeRF: Flow-GAN based Probabilistic Neural Radiance Field for Independence-Assumption-Free Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural radiance fields with stochasticity have garnered significant interest by enabling the sampling of plausible radiance fields and quantifying uncertainty for downstream tasks. Existing works rely on the independence assumption of points in the radiance field or the pixels in input views to obtain tractable forms of the probability density function. However, this assumption inadvertently impacts performance when dealing with intricate geometry and texture. In this work, we propose an independence-assumption-free probabilistic neural radiance field based on Flow-GAN. By combining the generative capability of adversarial learning and the powerful expressivity of normalizing flow, our method explicitly models the density-radiance distribution of the whole scene. We represent our probabilistic NeRF as a mean-shifted probabilistic residual neural model. Our model is trained without an explicit likelihood function, thereby avoiding the independence assumption. Specifically, We downsample the training images with different strides and centers to form fixed-size patches which are used to train the generator with patch-based adversarial learning. Through extensive experiments, our method demonstrates state-of-the-art performance by predicting lower rendering errors and more reliable uncertainty on both synthetic and real-world datasets.
<div id='section'>Paperid: <span id='pid'>508, <a href='https://arxiv.org/pdf/2307.04651.pdf' target='_blank'>https://arxiv.org/pdf/2307.04651.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aixuan Li, Jing Zhang, Yunqiu Lv, Tong Zhang, Yiran Zhong, Mingyi He, Yuchao Dai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.04651">Joint Salient Object Detection and Camouflaged Object Detection via Uncertainty-aware Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Salient objects attract human attention and usually stand out clearly from their surroundings. In contrast, camouflaged objects share similar colors or textures with the environment. In this case, salient objects are typically non-camouflaged, and camouflaged objects are usually not salient. Due to this inherent contradictory attribute, we introduce an uncertainty-aware learning pipeline to extensively explore the contradictory information of salient object detection (SOD) and camouflaged object detection (COD) via data-level and task-wise contradiction modeling. We first exploit the dataset correlation of these two tasks and claim that the easy samples in the COD dataset can serve as hard samples for SOD to improve the robustness of the SOD model. Based on the assumption that these two models should lead to activation maps highlighting different regions of the same input image, we further introduce a contrastive module with a joint-task contrastive learning framework to explicitly model the contradictory attributes of these two tasks. Different from conventional intra-task contrastive learning for unsupervised representation learning, our contrastive module is designed to model the task-wise correlation, leading to cross-task representation learning. To better understand the two tasks from the perspective of uncertainty, we extensively investigate the uncertainty estimation techniques for modeling the main uncertainties of the two tasks, namely task uncertainty (for SOD) and data uncertainty (for COD), and aiming to effectively estimate the challenging regions for each task to achieve difficulty-aware learning. Experimental results on benchmark datasets demonstrate that our solution leads to both state-of-the-art performance and informative uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>509, <a href='https://arxiv.org/pdf/2301.12386.pdf' target='_blank'>https://arxiv.org/pdf/2301.12386.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harikrishna Narasimhan, Aditya Krishna Menon, Wittawat Jitkrittum, Sanjiv Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12386">Plugin estimators for selective classification with out-of-distribution detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world classifiers can benefit from the option of abstaining from predicting on samples where they have low confidence. Such abstention is particularly useful on samples which are close to the learned decision boundary, or which are outliers with respect to the training sample. These settings have been the subject of extensive but disjoint study in the selective classification (SC) and out-of-distribution (OOD) detection literature. Recent work on selective classification with OOD detection (SCOD) has argued for the unified study of these problems; however, the formal underpinnings of this problem are still nascent, and existing techniques are heuristic in nature. In this paper, we propose new plugin estimators for SCOD that are theoretically grounded, effective, and generalise existing approaches from the SC and OOD detection literature. In the course of our analysis, we formally explicate how naÃ¯ve use of existing SC and OOD detection baselines may be inadequate for SCOD. We empirically demonstrate that our approaches yields competitive SC and OOD detection performance compared to baselines from both literatures.
<div id='section'>Paperid: <span id='pid'>510, <a href='https://arxiv.org/pdf/2207.06055.pdf' target='_blank'>https://arxiv.org/pdf/2207.06055.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Bogdoll, Meng Zhang, Maximilian Nitsche, J. Marius ZÃ¶llner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.06055">Experiments on Anomaly Detection in Autonomous Driving by Forward-Backward Style Transfers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Great progress has been achieved in the community of autonomous driving in the past few years. As a safety-critical problem, however, anomaly detection is a huge hurdle towards a large-scale deployment of autonomous vehicles in the real world. While many approaches, such as uncertainty estimation or segmentation-based image resynthesis, are extremely promising, there is more to be explored. Especially inspired by works on anomaly detection based on image resynthesis, we propose a novel approach for anomaly detection through style transfer. We leverage generative models to map an image from its original style domain of road traffic to an arbitrary one and back to generate pixelwise anomaly scores. However, our experiments have proven our hypothesis wrong, and we were unable to produce significant results. Nevertheless, we want to share our findings, so that others can learn from our experiments.
<div id='section'>Paperid: <span id='pid'>511, <a href='https://arxiv.org/pdf/2010.02613.pdf' target='_blank'>https://arxiv.org/pdf/2010.02613.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Neha Das, Jonas Umlauft, Armin Lederer, Thomas Beckers, Sandra Hirche
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2010.02613">Deep Learning based Uncertainty Decomposition for Real-time Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven control in unknown environments requires a clear understanding of the involved uncertainties for ensuring safety and efficient exploration. While aleatoric uncertainty that arises from measurement noise can often be explicitly modeled given a parametric description, it can be harder to model epistemic uncertainty, which describes the presence or absence of training data. The latter can be particularly useful for implementing exploratory control strategies when system dynamics are unknown. We propose a novel method for detecting the absence of training data using deep learning, which gives a continuous valued scalar output between $0$ (indicating low uncertainty) and $1$ (indicating high uncertainty). We utilize this detector as a proxy for epistemic uncertainty and show its advantages over existing approaches on synthetic and real-world datasets. Our approach can be directly combined with aleatoric uncertainty estimates and allows for uncertainty estimation in real-time as the inference is sample-free unlike existing approaches for uncertainty modeling. We further demonstrate the practicality of this uncertainty estimate in deploying online data-efficient control on a simulated quadcopter acted upon by an unknown disturbance model.
<div id='section'>Paperid: <span id='pid'>512, <a href='https://arxiv.org/pdf/2509.15735.pdf' target='_blank'>https://arxiv.org/pdf/2509.15735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Davide Ettori, Nastaran Darabi, Sina Tayebati, Ranganath Krishnan, Mahesh Subedar, Omesh Tickoo, Amit Ranjan Trivedi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15735">EigenTrack: Spectral Activation Feature Tracking for Hallucination and Out-of-Distribution Detection in LLMs and VLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) offer broad utility but remain prone to hallucination and out-of-distribution (OOD) errors. We propose EigenTrack, an interpretable real-time detector that uses the spectral geometry of hidden activations, a compact global signature of model dynamics. By streaming covariance-spectrum statistics such as entropy, eigenvalue gaps, and KL divergence from random baselines into a lightweight recurrent classifier, EigenTrack tracks temporal shifts in representation structure that signal hallucination and OOD drift before surface errors appear. Unlike black- and grey-box methods, it needs only a single forward pass without resampling. Unlike existing white-box detectors, it preserves temporal context, aggregates global signals, and offers interpretable accuracy-latency trade-offs.
<div id='section'>Paperid: <span id='pid'>513, <a href='https://arxiv.org/pdf/2509.15735.pdf' target='_blank'>https://arxiv.org/pdf/2509.15735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Davide Ettori, Nastaran Darabi, Sina Tayebati, Ranganath Krishnan, Mahesh Subedar, Omesh Tickoo, Amit Ranjan Trivedi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15735">EigenTrack: Spectral Activation Feature Tracking for Hallucination and Out-of-Distribution Detection in LLMs and VLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) offer broad utility but remain prone to hallucination and out-of-distribution (OOD) errors. We propose EigenTrack, an interpretable real-time detector that uses the spectral geometry of hidden activations, a compact global signature of model dynamics. By streaming covariance-spectrum statistics such as entropy, eigenvalue gaps, and KL divergence from random baselines into a lightweight recurrent classifier, EigenTrack tracks temporal shifts in representation structure that signal hallucination and OOD drift before surface errors appear. Unlike black- and grey-box methods, it needs only a single forward pass without resampling. Unlike existing white-box detectors, it preserves temporal context, aggregates global signals, and offers interpretable accuracy-latency trade-offs.
<div id='section'>Paperid: <span id='pid'>514, <a href='https://arxiv.org/pdf/2509.13464.pdf' target='_blank'>https://arxiv.org/pdf/2509.13464.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Onat Gungor, Ishaan Kale, Jiasheng Zhou, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13464">LIGHT-HIDS: A Lightweight and Effective Machine Learning-Based Framework for Robust Host Intrusion Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The expansion of edge computing has increased the attack surface, creating an urgent need for robust, real-time machine learning (ML)-based host intrusion detection systems (HIDS) that balance accuracy and efficiency. In such settings, inference latency poses a critical security risk, as delays may provide exploitable opportunities for attackers. However, many state-of-the-art ML-based HIDS solutions rely on computationally intensive architectures with high inference costs, limiting their practical deployment. This paper proposes LIGHT-HIDS, a lightweight machine learning framework that combines a compressed neural network feature extractor trained via Deep Support Vector Data Description (DeepSVDD) with an efficient novelty detection model. This hybrid approach enables the learning of compact, meaningful representations of normal system call behavior for accurate anomaly detection. Experimental results on multiple datasets demonstrate that LIGHT-HIDS consistently enhances detection accuracy while reducing inference time by up to 75x compared to state-of-the-art methods. These findings highlight its effectiveness and scalability as a machine learning-based solution for real-time host intrusion detection.
<div id='section'>Paperid: <span id='pid'>515, <a href='https://arxiv.org/pdf/2508.19450.pdf' target='_blank'>https://arxiv.org/pdf/2508.19450.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elvin Li, Onat Gungor, Zhengli Shang, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19450">CITADEL: Continual Anomaly Detection for Enhanced Learning in IoT Intrusion Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Internet of Things (IoT), with its high degree of interconnectivity and limited computational resources, is particularly vulnerable to a wide range of cyber threats. Intrusion detection systems (IDS) have been extensively studied to enhance IoT security, and machine learning-based IDS (ML-IDS) show considerable promise for detecting malicious activity. However, their effectiveness is often constrained by poor adaptability to emerging threats and the issue of catastrophic forgetting during continuous learning. To address these challenges, we propose CITADEL, a self-supervised continual learning framework designed to extract robust representations from benign data while preserving long-term knowledge through optimized memory consolidation mechanisms. CITADEL integrates a tabular-to-image transformation module, a memory-aware masked autoencoder for self-supervised representation learning, and a novelty detection component capable of identifying anomalies without dependence on labeled attack data. Our design enables the system to incrementally adapt to emerging behaviors while retaining its ability to detect previously observed threats. Experiments on multiple intrusion datasets demonstrate that CITADEL achieves up to a 72.9% improvement over the VAE-based lifelong anomaly detector (VLAD) in key detection and retention metrics, highlighting its effectiveness in dynamic IoT environments.
<div id='section'>Paperid: <span id='pid'>516, <a href='https://arxiv.org/pdf/2505.23223.pdf' target='_blank'>https://arxiv.org/pdf/2505.23223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyuan Pan, Chenlu Ye, Joseph Melkonian, Jiaqi W. Ma, Tong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23223">Daunce: Data Attribution through Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training data attribution (TDA) methods aim to identify which training examples influence a model's predictions on specific test data most. By quantifying these influences, TDA supports critical applications such as data debugging, curation, and valuation. Gradient-based TDA methods rely on gradients and second-order information, limiting their applicability at scale. While recent random projection-based methods improve scalability, they often suffer from degraded attribution accuracy. Motivated by connections between uncertainty and influence functions, we introduce Daunce - a simple yet effective data attribution approach through uncertainty estimation. Our method operates by fine-tuning a collection of perturbed models and computing the covariance of per-example losses across these models as the attribution score. Daunce is scalable to large language models (LLMs) and achieves more accurate attribution compared to existing TDA methods. We validate Daunce on tasks ranging from vision tasks to LLM fine-tuning, and further demonstrate its compatibility with black-box model access. Applied to OpenAI's GPT models, our method achieves, to our knowledge, the first instance of data attribution on proprietary LLMs.
<div id='section'>Paperid: <span id='pid'>517, <a href='https://arxiv.org/pdf/2505.22152.pdf' target='_blank'>https://arxiv.org/pdf/2505.22152.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dominik Fuchsgruber, Tom WollschlÃ¤ger, Johannes Bordne, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22152">Uncertainty Estimation for Heterophilic Graphs Through the Lens of Information Theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While uncertainty estimation for graphs recently gained traction, most methods rely on homophily and deteriorate in heterophilic settings. We address this by analyzing message passing neural networks from an information-theoretic perspective and developing a suitable analog to data processing inequality to quantify information throughout the model's layers. In contrast to non-graph domains, information about the node-level prediction target can increase with model depth if a node's features are semantically different from its neighbors. Therefore, on heterophilic graphs, the latent embeddings of an MPNN each provide different information about the data distribution - different from homophilic settings. This reveals that considering all node representations simultaneously is a key design principle for epistemic uncertainty estimation on graphs beyond homophily. We empirically confirm this with a simple post-hoc density estimator on the joint node embedding space that provides state-of-the-art uncertainty on heterophilic graphs. At the same time, it matches prior work on homophilic graphs without explicitly exploiting homophily through post-processing.
<div id='section'>Paperid: <span id='pid'>518, <a href='https://arxiv.org/pdf/2503.23775.pdf' target='_blank'>https://arxiv.org/pdf/2503.23775.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Heublein, Nisha L. Raichur, Tobias Feigl, Tobias Brieger, Fin Heuer, Lennart Asbach, Alexander RÃ¼gamer, Felix Ott
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23775">Evaluation of (Un-)Supervised Machine Learning Methods for GNSS Interference Classification with Real-World Data Discrepancies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The accuracy and reliability of vehicle localization on roads are crucial for applications such as self-driving cars, toll systems, and digital tachographs. To achieve accurate positioning, vehicles typically use global navigation satellite system (GNSS) receivers to validate their absolute positions. However, GNSS-based positioning can be compromised by interference signals, necessitating the identification, classification, determination of purpose, and localization of such interference to mitigate or eliminate it. Recent approaches based on machine learning (ML) have shown superior performance in monitoring interference. However, their feasibility in real-world applications and environments has yet to be assessed. Effective implementation of ML techniques requires training datasets that incorporate realistic interference signals, including real-world noise and potential multipath effects that may occur between transmitter, receiver, and satellite in the operational area. Additionally, these datasets require reference labels. Creating such datasets is often challenging due to legal restrictions, as causing interference to GNSS sources is strictly prohibited. Consequently, the performance of ML-based methods in practical applications remains unclear. To address this gap, we describe a series of large-scale measurement campaigns conducted in real-world settings at two highway locations in Germany and the Seetal Alps in Austria, and in large-scale controlled indoor environments. We evaluate the latest supervised ML-based methods to report on their performance in real-world settings and present the applicability of pseudo-labeling for unsupervised learning. We demonstrate the challenges of combining datasets due to data discrepancies and evaluate outlier detection, domain adaptation, and data augmentation techniques to present the models' capabilities to adapt to changes in the datasets.
<div id='section'>Paperid: <span id='pid'>519, <a href='https://arxiv.org/pdf/2503.12600.pdf' target='_blank'>https://arxiv.org/pdf/2503.12600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Feng, Yihang Sun, Jiaxuan You
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.12600">GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The powerful capabilities of Large Language Models (LLMs) have led to their growing use in evaluating human-generated content, particularly in evaluating research ideas within academic settings. Existing solutions primarily rely on prompt-based LLM methods or fine-tuned lightweight language models for idea evaluation. However, these methods are often unstable and struggle to comprehend the complex semantic information embedded in the ideas, impeding their ability to perform high-quality evaluations. To address the above challenges, we propose GraphEval, a lightweight graph-based LLM framework for idea evaluation. Our insight is that a complex idea can be broken down into comprehensible viewpoint nodes using prompts from small LLMs. These viewpoint nodes can then be linked together through edges created from LLM-based relation extraction and/or BERT similarity scores. The created viewpoint-graph can be used to conveniently propagate scores across view-nodes to improve the robustness of the idea evaluations. In particular, we propose two lightweight graph-based methods for idea evaluation: (1) GraphEval-LP: a training-free label propagation algorithm that propagates evaluation scores from known view-nodes to unknown nodes; (2) GraphEval-GNN: a Graph Neural Networks (GNN) that is trained to predict the evaluation scores given the observed graph with minimal computation resources. Moreover, to overcome LLM's limitation in objectively assessing the novelty of ideas, we further propose a novelty detection model to GraphEval-GNN to enhance its capability in judging idea novelty. Experiments on two datasets show GraphEval improves F1 scores by at least 14% with low computation and API costs. Additionally, GraphEval can effectively detect plagiarized ideas.
<div id='section'>Paperid: <span id='pid'>520, <a href='https://arxiv.org/pdf/2503.04441.pdf' target='_blank'>https://arxiv.org/pdf/2503.04441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohit Menon, Nils Dengler, Sicong Pan, Gokul Krishna Chenchani, Maren Bennewitz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04441">EvidMTL: Evidential Multi-Task Learning for Uncertainty-Aware Semantic Surface Mapping from Monocular RGB Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For scene understanding in unstructured environments, an accurate and uncertainty-aware metric-semantic mapping is required to enable informed action selection by autonomous systems. Existing mapping methods often suffer from overconfident semantic predictions, and sparse and noisy depth sensing, leading to inconsistent map representations. In this paper, we therefore introduce EvidMTL, a multi-task learning framework that uses evidential heads for depth estimation and semantic segmentation, enabling uncertainty-aware inference from monocular RGB images. To enable uncertainty-calibrated evidential multi-task learning, we propose a novel evidential depth loss function that jointly optimizes the belief strength of the depth prediction in conjunction with evidential segmentation loss. Building on this, we present EvidKimera, an uncertainty-aware semantic surface mapping framework, which uses evidential depth and semantics prediction for improved 3D metric-semantic consistency. We train and evaluate EvidMTL on the NYUDepthV2 and assess its zero-shot performance on ScanNetV2, demonstrating superior uncertainty estimation compared to conventional approaches while maintaining comparable depth estimation and semantic segmentation. In zero-shot mapping tests on ScanNetV2, EvidKimera outperforms Kimera in semantic surface mapping accuracy and consistency, highlighting the benefits of uncertainty-aware mapping and underscoring its potential for real-world robotic applications.
<div id='section'>Paperid: <span id='pid'>521, <a href='https://arxiv.org/pdf/2502.15901.pdf' target='_blank'>https://arxiv.org/pdf/2502.15901.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Onat Gungor, Amanda Sofie Rios, Nilesh Ahuja, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15901">TS-OOD: Evaluating Time-Series Out-of-Distribution Detection and Prospective Directions for Progress</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) data is a fundamental challenge in the deployment of machine learning models. From a security standpoint, this is particularly important because OOD test data can result in misleadingly confident yet erroneous predictions, which undermine the reliability of the deployed model. Although numerous models for OOD detection have been developed in computer vision and language, their adaptability to the time-series data domain remains limited and under-explored. Yet, time-series data is ubiquitous across manufacturing and security applications for which OOD is essential. This paper seeks to address this research gap by conducting a comprehensive analysis of modality-agnostic OOD detection algorithms. We evaluate over several multivariate time-series datasets, deep learning architectures, time-series specific data augmentations, and loss functions. Our results demonstrate that: 1) the majority of state-of-the-art OOD methods exhibit limited performance on time-series data, and 2) OOD methods based on deep feature modeling may offer greater advantages for time-series OOD detection, highlighting a promising direction for future time-series OOD detection algorithm development.
<div id='section'>Paperid: <span id='pid'>522, <a href='https://arxiv.org/pdf/2502.14094.pdf' target='_blank'>https://arxiv.org/pdf/2502.14094.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sean Fuhrman, Onat Gungor, Tajana Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14094">CND-IDS: Continual Novelty Detection for Intrusion Detection Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intrusion detection systems (IDS) play a crucial role in IoT and network security by monitoring system data and alerting to suspicious activities. Machine learning (ML) has emerged as a promising solution for IDS, offering highly accurate intrusion detection. However, ML-IDS solutions often overlook two critical aspects needed to build reliable systems: continually changing data streams and a lack of attack labels. Streaming network traffic and associated cyber attacks are continually changing, which can degrade the performance of deployed ML models. Labeling attack data, such as zero-day attacks, in real-world intrusion scenarios may not be feasible, making the use of ML solutions that do not rely on attack labels necessary. To address both these challenges, we propose CND-IDS, a continual novelty detection IDS framework which consists of (i) a learning-based feature extractor that continuously updates new feature representations of the system data, and (ii) a novelty detector that identifies new cyber attacks by leveraging principal component analysis (PCA) reconstruction. Our results on realistic intrusion datasets show that CND-IDS achieves up to 6.1x F-score improvement, and up to 6.5x improved forward transfer over the SOTA unsupervised continual learning algorithm. Our code will be released upon acceptance.
<div id='section'>Paperid: <span id='pid'>523, <a href='https://arxiv.org/pdf/2410.10894.pdf' target='_blank'>https://arxiv.org/pdf/2410.10894.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingyang Zhang, Yatao Bian, Xinke Kong, Peilin Zhao, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10894">COME: Test-time adaption by Conservatively Minimizing Entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models must continuously self-adjust themselves for novel data distribution in the open world. As the predominant principle, entropy minimization (EM) has been proven to be a simple yet effective cornerstone in existing test-time adaption (TTA) methods. While unfortunately its fatal limitation (i.e., overconfidence) tends to result in model collapse. For this issue, we propose to Conservatively Minimize the Entropy (COME), which is a simple drop-in replacement of traditional EM to elegantly address the limitation. In essence, COME explicitly models the uncertainty by characterizing a Dirichlet prior distribution over model predictions during TTA. By doing so, COME naturally regularizes the model to favor conservative confidence on unreliable samples. Theoretically, we provide a preliminary analysis to reveal the ability of COME in enhancing the optimization stability by introducing a data-adaptive lower bound on the entropy. Empirically, our method achieves state-of-the-art performance on commonly used benchmarks, showing significant improvements in terms of classification accuracy and uncertainty estimation under various settings including standard, life-long and open-world TTA, i.e., up to $34.5\%$ improvement on accuracy and $15.1\%$ on false positive rate.
<div id='section'>Paperid: <span id='pid'>524, <a href='https://arxiv.org/pdf/2407.05521.pdf' target='_blank'>https://arxiv.org/pdf/2407.05521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zehuan Zhang, Matej Genci, Hongxiang Fan, Andreas Wetscherek, Wayne Luk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.05521">Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and reliable Magnetic Resonance Imaging (MRI) analysis is particularly important for adaptive radiotherapy, a recent medical advance capable of improving cancer diagnosis and treatment. Recent studies have shown that IVIM-NET, a deep neural network (DNN), can achieve high accuracy in MRI analysis, indicating the potential of deep learning to enhance diagnostic capabilities in healthcare. However, IVIM-NET does not provide calibrated uncertainty information needed for reliable and trustworthy predictions in healthcare. Moreover, the expensive computation and memory demands of IVIM-NET reduce hardware performance, hindering widespread adoption in realistic scenarios. To address these challenges, this paper proposes an algorithm-hardware co-optimization flow for high-performance and reliable MRI analysis. At the algorithm level, a transformation design flow is introduced to convert IVIM-NET to a mask-based Bayesian Neural Network (BayesNN), facilitating reliable and efficient uncertainty estimation. At the hardware level, we propose an FPGA-based accelerator with several hardware optimizations, such as mask-zero skipping and operation reordering. Experimental results demonstrate that our co-design approach can satisfy the uncertainty requirements of MRI analysis, while achieving 7.5 times and 32.5 times speedup on an Xilinx VU13P FPGA compared to GPU and CPU implementations with reduced power consumption.
<div id='section'>Paperid: <span id='pid'>525, <a href='https://arxiv.org/pdf/2406.16198.pdf' target='_blank'>https://arxiv.org/pdf/2406.16198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zehuan Zhang, Hongxiang Fan, Hao Mark Chen, Lukasz Dudziak, Wayne Luk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16198">Hardware-Aware Neural Dropout Search for Reliable Uncertainty Prediction on FPGA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The increasing deployment of artificial intelligence (AI) for critical decision-making amplifies the necessity for trustworthy AI, where uncertainty estimation plays a pivotal role in ensuring trustworthiness. Dropout-based Bayesian Neural Networks (BayesNNs) are prominent in this field, offering reliable uncertainty estimates. Despite their effectiveness, existing dropout-based BayesNNs typically employ a uniform dropout design across different layers, leading to suboptimal performance. Moreover, as diverse applications require tailored dropout strategies for optimal performance, manually optimizing dropout configurations for various applications is both error-prone and labor-intensive. To address these challenges, this paper proposes a novel neural dropout search framework that automatically optimizes both the dropout-based BayesNNs and their hardware implementations on FPGA. We leverage one-shot supernet training with an evolutionary algorithm for efficient dropout optimization. A layer-wise dropout search space is introduced to enable the automatic design of dropout-based BayesNNs with heterogeneous dropout configurations. Extensive experiments demonstrate that our proposed framework can effectively find design configurations on the Pareto frontier. Compared to manually-designed dropout-based BayesNNs on GPU, our search approach produces FPGA designs that can achieve up to 33X higher energy efficiency. Compared to state-of-the-art FPGA designs of BayesNN, the solutions from our approach can achieve higher algorithmic performance and energy efficiency.
<div id='section'>Paperid: <span id='pid'>526, <a href='https://arxiv.org/pdf/2406.10107.pdf' target='_blank'>https://arxiv.org/pdf/2406.10107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Genc Hoxha, Gencer Sumbul, Julia Henkel, Lars MÃ¶llenbrok, BegÃ¼m Demir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10107">Annotation Cost-Efficient Active Learning for Deep Metric Learning Driven Remote Sensing Image Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep metric learning (DML) has shown to be effective for content-based image retrieval (CBIR) in remote sensing (RS). Most of DML methods for CBIR rely on a high number of annotated images to accurately learn model parameters of deep neural networks (DNNs). However, gathering such data is time-consuming and costly. To address this, we propose an annotation cost-efficient active learning (ANNEAL) method tailored to DML-driven CBIR in RS. ANNEAL aims to create a small but informative training set made up of similar and dissimilar image pairs to be utilized for accurately learning a metric space. The informativeness of image pairs is evaluated by combining uncertainty and diversity criteria. To assess the uncertainty of image pairs, we introduce two algorithms: 1) metric-guided uncertainty estimation (MGUE); and 2) binary classifier guided uncertainty estimation (BCGUE). MGUE algorithm automatically estimates a threshold value that acts as a boundary between similar and dissimilar image pairs based on the distances in the metric space. The closer the similarity between image pairs is to the estimated threshold value the higher their uncertainty. BCGUE algorithm estimates the uncertainty of the image pairs based on the confidence of the classifier in assigning correct similarity labels. The diversity criterion is assessed through a clustering-based strategy. ANNEAL combines either MGUE or BCGUE algorithm with the clustering-based strategy to select the most informative image pairs, which are then labelled by expert annotators as similar or dissimilar. This way of annotating images significantly reduces the annotation cost compared to annotating images with land-use land-cover class labels. Experimental results on two RS benchmark datasets demonstrate the effectiveness of our method. The code of this work is publicly available at \url{https://git.tu-berlin.de/rsim/anneal_tgrs}.
<div id='section'>Paperid: <span id='pid'>527, <a href='https://arxiv.org/pdf/2405.01462.pdf' target='_blank'>https://arxiv.org/pdf/2405.01462.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dominik Fuchsgruber, Tom WollschlÃ¤ger, Bertrand Charpentier, Antonio Oroz, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01462">Uncertainty for Active Learning on Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty Sampling is an Active Learning strategy that aims to improve the data efficiency of machine learning models by iteratively acquiring labels of data points with the highest uncertainty. While it has proven effective for independent data its applicability to graphs remains under-explored. We propose the first extensive study of Uncertainty Sampling for node classification: (1) We benchmark Uncertainty Sampling beyond predictive uncertainty and highlight a significant performance gap to other Active Learning strategies. (2) We develop ground-truth Bayesian uncertainty estimates in terms of the data generating process and prove their effectiveness in guiding Uncertainty Sampling toward optimal queries. We confirm our results on synthetic data and design an approximate approach that consistently outperforms other uncertainty estimators on real datasets. (3) Based on this analysis, we relate pitfalls in modeling uncertainty to existing methods. Our analysis enables and informs the development of principled uncertainty estimation on graphs.
<div id='section'>Paperid: <span id='pid'>528, <a href='https://arxiv.org/pdf/2312.03782.pdf' target='_blank'>https://arxiv.org/pdf/2312.03782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luigi Riz, Cristiano Saltori, Yiming Wang, Elisa Ricci, Fabio Poiesi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03782">Novel class discovery meets foundation models for 3D semantic segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The task of Novel Class Discovery (NCD) in semantic segmentation entails training a model able to accurately segment unlabelled (novel) classes, relying on the available supervision from annotated (base) classes. Although extensively investigated in 2D image data, the extension of the NCD task to the domain of 3D point clouds represents a pioneering effort, characterized by assumptions and challenges that are not present in the 2D case. This paper represents an advancement in the analysis of point cloud data in four directions. Firstly, it introduces the novel task of NCD for point cloud semantic segmentation. Secondly, it demonstrates that directly transposing the only existing NCD method for 2D image semantic segmentation to 3D data yields suboptimal results. Thirdly, a new NCD approach based on online clustering, uncertainty estimation, and semantic distillation is presented. Lastly, a novel evaluation protocol is proposed to rigorously assess the performance of NCD in point cloud semantic segmentation. Through comprehensive evaluations on the SemanticKITTI, SemanticPOSS, and S3DIS datasets, the paper demonstrates substantial superiority of the proposed method over the considered baselines.
<div id='section'>Paperid: <span id='pid'>529, <a href='https://arxiv.org/pdf/2310.17163.pdf' target='_blank'>https://arxiv.org/pdf/2310.17163.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingwen Wu, Tao Li, Xinwen Cheng, Jie Yang, Xiaolin Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.17163">Low-Dimensional Gradient Helps Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is essential for ensuring the reliability of deep neural networks (DNNs) in real-world scenarios. While previous research has predominantly investigated the disparity between in-distribution (ID) and OOD data through forward information analysis, the discrepancy in parameter gradients during the backward process of DNNs has received insufficient attention. Existing studies on gradient disparities mainly focus on the utilization of gradient norms, neglecting the wealth of information embedded in gradient directions. To bridge this gap, in this paper, we conduct a comprehensive investigation into leveraging the entirety of gradient information for OOD detection. The primary challenge arises from the high dimensionality of gradients due to the large number of network parameters. To solve this problem, we propose performing linear dimension reduction on the gradient using a designated subspace that comprises principal components. This innovative technique enables us to obtain a low-dimensional representation of the gradient with minimal information loss. Subsequently, by integrating the reduced gradient with various existing detection score functions, our approach demonstrates superior performance across a wide range of detection tasks. For instance, on the ImageNet benchmark with ResNet50 model, our method achieves an average reduction of 11.15$\%$ in the false positive rate at 95$\%$ recall (FPR95) compared to the current state-of-the-art approach. The code would be released.
<div id='section'>Paperid: <span id='pid'>530, <a href='https://arxiv.org/pdf/2307.15615.pdf' target='_blank'>https://arxiv.org/pdf/2307.15615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyu Chen, Yihao Liu, Shuwen Wei, Zhangxing Bian, Shalini Subramanian, Aaron Carass, Jerry L. Prince, Yong Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.15615">A survey on deep learning in medical image registration: new technologies, uncertainty, evaluation metrics, and beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning technologies have dramatically reshaped the field of medical image registration over the past decade. The initial developments, such as regression-based and U-Net-based networks, established the foundation for deep learning in image registration. Subsequent progress has been made in various aspects of deep learning-based registration, including similarity measures, deformation regularizations, network architectures, and uncertainty estimation. These advancements have not only enriched the field of image registration but have also facilitated its application in a wide range of tasks, including atlas construction, multi-atlas segmentation, motion estimation, and 2D-3D registration. In this paper, we present a comprehensive overview of the most recent advancements in deep learning-based image registration. We begin with a concise introduction to the core concepts of deep learning-based image registration. Then, we delve into innovative network architectures, loss functions specific to registration, and methods for estimating registration uncertainty. Additionally, this paper explores appropriate evaluation metrics for assessing the performance of deep learning models in registration tasks. Finally, we highlight the practical applications of these novel techniques in medical imaging and discuss the future prospects of deep learning-based image registration.
<div id='section'>Paperid: <span id='pid'>531, <a href='https://arxiv.org/pdf/2306.14916.pdf' target='_blank'>https://arxiv.org/pdf/2306.14916.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tom WollschlÃ¤ger, Nicholas Gao, Bertrand Charpentier, Mohamed Amine Ketata, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14916">Uncertainty Estimation for Molecules: Desiderata and Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) are promising surrogates for quantum mechanical calculations as they establish unprecedented low errors on collections of molecular dynamics (MD) trajectories. Thanks to their fast inference times they promise to accelerate computational chemistry applications. Unfortunately, despite low in-distribution (ID) errors, such GNNs might be horribly wrong for out-of-distribution (OOD) samples. Uncertainty estimation (UE) may aid in such situations by communicating the model's certainty about its prediction. Here, we take a closer look at the problem and identify six key desiderata for UE in molecular force fields, three 'physics-informed' and three 'application-focused' ones. To overview the field, we survey existing methods from the field of UE and analyze how they fit to the set desiderata. By our analysis, we conclude that none of the previous works satisfies all criteria. To fill this gap, we propose Localized Neural Kernel (LNK) a Gaussian Process (GP)-based extension to existing GNNs satisfying the desiderata. In our extensive experimental evaluation, we test four different UE with three different backbones and two datasets. In out-of-equilibrium detection, we find LNK yielding up to 2.5 and 2.1 times lower errors in terms of AUC-ROC score than dropout or evidential regression-based methods while maintaining high predictive performance.
<div id='section'>Paperid: <span id='pid'>532, <a href='https://arxiv.org/pdf/2302.14031.pdf' target='_blank'>https://arxiv.org/pdf/2302.14031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Baturalp Buyukates, Chaoyang He, Shanshan Han, Zhiyong Fang, Yupeng Zhang, Jieyi Long, Ali Farahanchi, Salman Avestimehr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.14031">Proof-of-Contribution-Based Design for Collaborative Machine Learning on Blockchain</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider a project (model) owner that would like to train a model by utilizing the local private data and compute power of interested data owners, i.e., trainers. Our goal is to design a data marketplace for such decentralized collaborative/federated learning applications that simultaneously provides i) proof-of-contribution based reward allocation so that the trainers are compensated based on their contributions to the trained model; ii) privacy-preserving decentralized model training by avoiding any data movement from data owners; iii) robustness against malicious parties (e.g., trainers aiming to poison the model); iv) verifiability in the sense that the integrity, i.e., correctness, of all computations in the data market protocol including contribution assessment and outlier detection are verifiable through zero-knowledge proofs; and v) efficient and universal design. We propose a blockchain-based marketplace design to achieve all five objectives mentioned above. In our design, we utilize a distributed storage infrastructure and an aggregator aside from the project owner and the trainers. The aggregator is a processing node that performs certain computations, including assessing trainer contributions, removing outliers, and updating hyper-parameters. We execute the proposed data market through a blockchain smart contract. The deployed smart contract ensures that the project owner cannot evade payment, and honest trainers are rewarded based on their contributions at the end of training. Finally, we implement the building blocks of the proposed data market and demonstrate their applicability in practical scenarios through extensive experiments.
<div id='section'>Paperid: <span id='pid'>533, <a href='https://arxiv.org/pdf/2301.09740.pdf' target='_blank'>https://arxiv.org/pdf/2301.09740.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Onat Gungor, Tajana Rosing, Baris Aksanli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.09740">DODEM: DOuble DEfense Mechanism Against Adversarial Attacks Towards Secure Industrial Internet of Things Analytics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Industrial Internet of Things (I-IoT) is a collaboration of devices, sensors, and networking equipment to monitor and collect data from industrial operations. Machine learning (ML) methods use this data to make high-level decisions with minimal human intervention. Data-driven predictive maintenance (PDM) is a crucial ML-based I-IoT application to find an optimal maintenance schedule for industrial assets. The performance of these ML methods can seriously be threatened by adversarial attacks where an adversary crafts perturbed data and sends it to the ML model to deteriorate its prediction performance. The models should be able to stay robust against these attacks where robustness is measured by how much perturbation in input data affects model performance. Hence, there is a need for effective defense mechanisms that can protect these models against adversarial attacks. In this work, we propose a double defense mechanism to detect and mitigate adversarial attacks in I-IoT environments. We first detect if there is an adversarial attack on a given sample using novelty detection algorithms. Then, based on the outcome of our algorithm, marking an instance as attack or normal, we select adversarial retraining or standard training to provide a secondary defense layer. If there is an attack, adversarial retraining provides a more robust model, while we apply standard training for regular samples. Since we may not know if an attack will take place, our adaptive mechanism allows us to consider irregular changes in data. The results show that our double defense strategy is highly efficient where we can improve model robustness by up to 64.6% and 52% compared to standard and adversarial retraining, respectively.
<div id='section'>Paperid: <span id='pid'>534, <a href='https://arxiv.org/pdf/2507.08711.pdf' target='_blank'>https://arxiv.org/pdf/2507.08711.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andreas Lolos, Stergios Christodoulidis, Maria Vakalopoulou, Jose Dolz, Aris Moustakas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08711">SGPMIL: Sparse Gaussian Process Multiple Instance Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiple Instance Learning (MIL) offers a natural solution for settings where only coarse, bag-level labels are available, without having access to instance-level annotations. This is usually the case in digital pathology, which consists of gigapixel sized images. While deterministic attention-based MIL approaches achieve strong bag-level performance, they often overlook the uncertainty inherent in instance relevance. In this paper, we address the lack of uncertainty quantification in instance-level attention scores by introducing \textbf{SGPMIL}, a new probabilistic attention-based MIL framework grounded in Sparse Gaussian Processes (SGP). By learning a posterior distribution over attention scores, SGPMIL enables principled uncertainty estimation, resulting in more reliable and calibrated instance relevance maps. Our approach not only preserves competitive bag-level performance but also significantly improves the quality and interpretability of instance-level predictions under uncertainty. SGPMIL extends prior work by introducing feature scaling in the SGP predictive mean function, leading to faster training, improved efficiency, and enhanced instance-level performance. Extensive experiments on multiple well-established digital pathology datasets highlight the effectiveness of our approach across both bag- and instance-level evaluations. Our code will be made publicly available.
<div id='section'>Paperid: <span id='pid'>535, <a href='https://arxiv.org/pdf/2507.04385.pdf' target='_blank'>https://arxiv.org/pdf/2507.04385.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steven Braun, Sahil Sidheekh, Antonio Vergari, Martin Mundt, Sriraam Natarajan, Kristian Kersting
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04385">Tractable Representation Learning with Probabilistic Circuits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Probabilistic circuits (PCs) are powerful probabilistic models that enable exact and tractable inference, making them highly suitable for probabilistic reasoning and inference tasks. While dominant in neural networks, representation learning with PCs remains underexplored, with prior approaches relying on external neural embeddings or activation-based encodings. To address this gap, we introduce autoencoding probabilistic circuits (APCs), a novel framework leveraging the tractability of PCs to model probabilistic embeddings explicitly. APCs extend PCs by jointly modeling data and embeddings, obtaining embedding representations through tractable probabilistic inference. The PC encoder allows the framework to natively handle arbitrary missing data and is seamlessly integrated with a neural decoder in a hybrid, end-to-end trainable architecture enabled by differentiable sampling. Our empirical evaluation demonstrates that APCs outperform existing PC-based autoencoding methods in reconstruction quality, generate embeddings competitive with, and exhibit superior robustness in handling missing data compared to neural autoencoders. These results highlight APCs as a powerful and flexible representation learning method that exploits the probabilistic inference capabilities of PCs, showing promising directions for robust inference, out-of-distribution detection, and knowledge distillation.
<div id='section'>Paperid: <span id='pid'>536, <a href='https://arxiv.org/pdf/2506.21892.pdf' target='_blank'>https://arxiv.org/pdf/2506.21892.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Goodge, Xun Xu, Bryan Hooi, Wee Siong Ng, Jingyi Liao, Yongyi Su, Xulei Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21892">SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As point cloud data increases in prevalence in a variety of applications, the ability to detect out-of-distribution (OOD) point cloud objects becomes critical for ensuring model safety and reliability. However, this problem remains under-explored in existing research. Inspired by success in the image domain, we propose to exploit advances in 3D vision-language models (3D VLMs) for OOD detection in point cloud objects. However, a major challenge is that point cloud datasets used to pre-train 3D VLMs are drastically smaller in size and object diversity than their image-based counterparts. Critically, they often contain exclusively computer-designed synthetic objects. This leads to a substantial domain shift when the model is transferred to practical tasks involving real objects scanned from the physical environment. In this paper, our empirical experiments show that synthetic-to-real domain shift significantly degrades the alignment of point cloud with their associated text embeddings in the 3D VLM latent space, hindering downstream performance. To address this, we propose a novel methodology called SODA which improves the detection of OOD point clouds through a neighborhood-based score propagation scheme. SODA is inference-based, requires no additional model training, and achieves state-of-the-art performance over existing approaches across datasets and problem settings.
<div id='section'>Paperid: <span id='pid'>537, <a href='https://arxiv.org/pdf/2506.09024.pdf' target='_blank'>https://arxiv.org/pdf/2506.09024.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Wagner, Pramit Saha, Harry Anthony, J. Alison Noble, Konstantinos Kamnitsas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09024">DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safe deployment of machine learning (ML) models in safety-critical domains such as medical imaging requires detecting inputs with characteristics not seen during training, known as out-of-distribution (OOD) detection, to prevent unreliable predictions. Effective OOD detection after deployment could benefit from access to the training data, enabling direct comparison between test samples and the training data distribution to identify differences. State-of-the-art OOD detection methods, however, either discard training data after deployment or assume that test samples and training data are centrally stored together, an assumption that rarely holds in real-world settings. This is because shipping training data with the deployed model is usually impossible due to the size of training databases, as well as proprietary or privacy constraints. We introduce the Isolation Network, an OOD detection framework that quantifies the difficulty of separating a target test sample from the training data by solving a binary classification task. We then propose Decentralized Isolation Networks (DIsoN), which enables the comparison of training and test data when data-sharing is impossible, by exchanging only model parameters between the remote computational nodes of training and deployment. We further extend DIsoN with class-conditioning, comparing a target sample solely with training data of its predicted class. We evaluate DIsoN on four medical imaging datasets (dermatology, chest X-ray, breast ultrasound, histopathology) across 12 OOD detection tasks. DIsoN performs favorably against existing methods while respecting data-privacy. This decentralized OOD detection framework opens the way for a new type of service that ML developers could provide along with their models: providing remote, secure utilization of their training data for OOD detection services. Code will be available upon acceptance at: *****
<div id='section'>Paperid: <span id='pid'>538, <a href='https://arxiv.org/pdf/2505.17773.pdf' target='_blank'>https://arxiv.org/pdf/2505.17773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amir Hossein Rahmati, Sanket Jantre, Weifeng Zhang, Yucheng Wang, Byung-Jun Yoon, Nathan M. Urban, Xiaoning Qian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17773">C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Low-Rank Adaptation (LoRA) offers a cost-effective solution for fine-tuning large language models (LLMs), but it often produces overconfident predictions in data-scarce few-shot settings. To address this issue, several classical statistical learning approaches have been repurposed for scalable uncertainty-aware LoRA fine-tuning. However, these approaches neglect how input characteristics affect the predictive uncertainty estimates. To address this limitation, we propose Contextual Low-Rank Adaptation (\textbf{C-LoRA}) as a novel uncertainty-aware and parameter efficient fine-tuning approach, by developing new lightweight LoRA modules contextualized to each input data sample to dynamically adapt uncertainty estimates. Incorporating data-driven contexts into the parameter posteriors, C-LoRA mitigates overfitting, achieves well-calibrated uncertainties, and yields robust predictions. Extensive experiments demonstrate that C-LoRA consistently outperforms the state-of-the-art uncertainty-aware LoRA methods in both uncertainty quantification and model generalization. Ablation studies further confirm the critical role of our contextual modules in capturing sample-specific uncertainties. C-LoRA sets a new standard for robust, uncertainty-aware LLM fine-tuning in few-shot regimes.
<div id='section'>Paperid: <span id='pid'>539, <a href='https://arxiv.org/pdf/2504.01849.pdf' target='_blank'>https://arxiv.org/pdf/2504.01849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohin Shah, Alex Irpan, Alexander Matt Turner, Anna Wang, Arthur Conmy, David Lindner, Jonah Brown-Cohen, Lewis Ho, Neel Nanda, Raluca Ada Popa, Rishub Jain, Rory Greig, Samuel Albanie, Scott Emmons, Sebastian Farquhar, SÃ©bastien Krier, Senthooran Rajamanoharan, Sophie Bridgers, Tobi Ijitoye, Tom Everitt, Victoria Krakovna, Vikrant Varma, Vladimir Mikulik, Zachary Kenton, Dave Orr, Shane Legg, Noah Goodman, Allan Dafoe, Four Flynn, Anca Dragan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01849">An Approach to Technical AGI Safety and Security</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial General Intelligence (AGI) promises transformative benefits but also presents significant risks. We develop an approach to address the risk of harms consequential enough to significantly harm humanity. We identify four areas of risk: misuse, misalignment, mistakes, and structural risks. Of these, we focus on technical approaches to misuse and misalignment. For misuse, our strategy aims to prevent threat actors from accessing dangerous capabilities, by proactively identifying dangerous capabilities, and implementing robust security, access restrictions, monitoring, and model safety mitigations. To address misalignment, we outline two lines of defense. First, model-level mitigations such as amplified oversight and robust training can help to build an aligned model. Second, system-level security measures such as monitoring and access control can mitigate harm even if the model is misaligned. Techniques from interpretability, uncertainty estimation, and safer design patterns can enhance the effectiveness of these mitigations. Finally, we briefly outline how these ingredients could be combined to produce safety cases for AGI systems.
<div id='section'>Paperid: <span id='pid'>540, <a href='https://arxiv.org/pdf/2412.09718.pdf' target='_blank'>https://arxiv.org/pdf/2412.09718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Morales-Ãlvarez, Stergios Christodoulidis, Maria Vakalopoulou, Pablo Piantanida, Jose Dolz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09718">BayesAdapter: enhanced uncertainty estimation in CLIP few-shot adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The emergence of large pre-trained vision-language models (VLMs) represents a paradigm shift in machine learning, with unprecedented results in a broad span of visual recognition tasks. CLIP, one of the most popular VLMs, has exhibited remarkable zero-shot and transfer learning capabilities in classification. To transfer CLIP to downstream tasks, adapters constitute a parameter-efficient approach that avoids backpropagation through the large model (unlike related prompt learning methods). However, CLIP adapters have been developed to target discriminative performance, and the quality of their uncertainty estimates has been overlooked. In this work we show that the discriminative performance of state-of-the-art CLIP adapters does not always correlate with their uncertainty estimation capabilities, which are essential for a safe deployment in real-world scenarios. We also demonstrate that one of such adapters is obtained through MAP inference from a more general probabilistic framework. Based on this observation we introduce BayesAdapter, which leverages Bayesian inference to estimate a full probability distribution instead of a single point, better capturing the variability inherent in the parameter space. In a comprehensive empirical evaluation we show that our approach obtains high quality uncertainty estimates in the predictions, standing out in calibration and selective classification. Our code will be publicly available upon acceptance of the paper.
<div id='section'>Paperid: <span id='pid'>541, <a href='https://arxiv.org/pdf/2411.04962.pdf' target='_blank'>https://arxiv.org/pdf/2411.04962.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Guanhua Chen, Anoop Mayampurath, Matthew Churpek, Majid Afshar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04962">Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) are being explored for diagnostic decision support, yet their ability to estimate pre-test probabilities, vital for clinical decision-making, remains limited. This study evaluates two LLMs, Mistral-7B and Llama3-70B, using structured electronic health record data on three diagnosis tasks. We examined three current methods of extracting LLM probability estimations and revealed their limitations. We aim to highlight the need for improved techniques in LLM confidence estimation.
<div id='section'>Paperid: <span id='pid'>542, <a href='https://arxiv.org/pdf/2410.14746.pdf' target='_blank'>https://arxiv.org/pdf/2410.14746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anthony Sicilia, Mert Inan, Malihe Alikhani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14746">Accounting for Sycophancy in Language Model Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective human-machine collaboration requires machine learning models to externalize uncertainty, so users can reflect and intervene when necessary. For language models, these representations of uncertainty may be impacted by sycophancy bias: proclivity to agree with users, even if they are wrong. For instance, models may be over-confident in (incorrect) problem solutions suggested by a user. We study the relationship between sycophancy and uncertainty estimation for the first time. We propose a generalization of the definition of sycophancy bias to measure downstream impacts on uncertainty estimation, and also propose a new algorithm (SyRoUP) to account for sycophancy in the uncertainty estimation process. Unlike previous works on sycophancy, we study a broad array of user behaviors, varying both correctness and confidence of user suggestions to see how model answers (and their certainty) change. Our experiments across conversation forecasting and question-answering tasks show that user confidence plays a critical role in modulating the effects of sycophancy, and that SyRoUP can better predict these effects. From these results, we argue that externalizing both model and user uncertainty can help to mitigate the impacts of sycophancy bias.
<div id='section'>Paperid: <span id='pid'>543, <a href='https://arxiv.org/pdf/2409.09249.pdf' target='_blank'>https://arxiv.org/pdf/2409.09249.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Ai, Ziwei Gong, Harshsaiprasad Deshpande, Alexander Johnson, Emmy Phung, Ahmad Emami, Julia Hirschberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09249">NovAScore: A New Automated Metric for Evaluating Document Level Novelty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid expansion of online content has intensified the issue of information redundancy, underscoring the need for solutions that can identify genuinely new information. Despite this challenge, the research community has seen a decline in focus on novelty detection, particularly with the rise of large language models (LLMs). Additionally, previous approaches have relied heavily on human annotation, which is time-consuming, costly, and particularly challenging when annotators must compare a target document against a vast number of historical documents. In this work, we introduce NovAScore (Novelty Evaluation in Atomicity Score), an automated metric for evaluating document-level novelty. NovAScore aggregates the novelty and salience scores of atomic information, providing high interpretability and a detailed analysis of a document's novelty. With its dynamic weight adjustment scheme, NovAScore offers enhanced flexibility and an additional dimension to assess both the novelty level and the importance of information within a document. Our experiments show that NovAScore strongly correlates with human judgments of novelty, achieving a 0.626 Point-Biserial correlation on the TAP-DLND 1.0 dataset and a 0.920 Pearson correlation on an internal human-annotated dataset.
<div id='section'>Paperid: <span id='pid'>544, <a href='https://arxiv.org/pdf/2406.18067.pdf' target='_blank'>https://arxiv.org/pdf/2406.18067.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaqian Hao, Chenguang Hu, Yingying Gao, Shilei Zhang, Junlan Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18067">Exploring Energy-Based Models for Out-of-Distribution Detection in Dialect Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The diverse nature of dialects presents challenges for models trained on specific linguistic patterns, rendering them susceptible to errors when confronted with unseen or out-of-distribution (OOD) data. This study introduces a novel margin-enhanced joint energy model (MEJEM) tailored specifically for OOD detection in dialects. By integrating a generative model and the energy margin loss, our approach aims to enhance the robustness of dialect identification systems. Furthermore, we explore two OOD scores for OOD dialect detection, and our findings conclusively demonstrate that the energy score outperforms the softmax score. Leveraging Sharpness-Aware Minimization to optimize the training process of the joint model, we enhance model generalization by minimizing both loss and sharpness. Experiments conducted on dialect identification tasks validate the efficacy of Energy-Based Models and provide valuable insights into their performance.
<div id='section'>Paperid: <span id='pid'>545, <a href='https://arxiv.org/pdf/2405.12223.pdf' target='_blank'>https://arxiv.org/pdf/2405.12223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinchi Zhou, Tianqi Chen, Jun Hou, Huidong Xie, Nicha C. Dvornek, S. Kevin Zhou, David L. Wilson, James S. Duncan, Chi Liu, Bo Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12223">Cascaded Multi-path Shortcut Diffusion Model for Medical Image Translation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image-to-image translation is a vital component in medical imaging processing, with many uses in a wide range of imaging modalities and clinical scenarios. Previous methods include Generative Adversarial Networks (GANs) and Diffusion Models (DMs), which offer realism but suffer from instability and lack uncertainty estimation. Even though both GAN and DM methods have individually exhibited their capability in medical image translation tasks, the potential of combining a GAN and DM to further improve translation performance and to enable uncertainty estimation remains largely unexplored. In this work, we address these challenges by proposing a Cascade Multi-path Shortcut Diffusion Model (CMDM) for high-quality medical image translation and uncertainty estimation. To reduce the required number of iterations and ensure robust performance, our method first obtains a conditional GAN-generated prior image that will be used for the efficient reverse translation with a DM in the subsequent step. Additionally, a multi-path shortcut diffusion strategy is employed to refine translation results and estimate uncertainty. A cascaded pipeline further enhances translation quality, incorporating residual averaging between cascades. We collected three different medical image datasets with two sub-tasks for each dataset to test the generalizability of our approach. Our experimental results found that CMDM can produce high-quality translations comparable to state-of-the-art methods while providing reasonable uncertainty estimations that correlate well with the translation error.
<div id='section'>Paperid: <span id='pid'>546, <a href='https://arxiv.org/pdf/2402.05939.pdf' target='_blank'>https://arxiv.org/pdf/2402.05939.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufei Li, Simin Chen, Yanghong Guo, Wei Yang, Yue Dong, Cong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05939">Uncertainty Awareness of Large Language Models Under Code Distribution Shifts: A Benchmark Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have been widely employed in programming language analysis to enhance human productivity. Yet, their reliability can be compromised by various code distribution shifts, leading to inconsistent outputs. While probabilistic methods are known to mitigate such impact through uncertainty calibration and estimation, their efficacy in the language domain remains underexplored compared to their application in image-based tasks. In this work, we first introduce a large-scale benchmark dataset, incorporating three realistic patterns of code distribution shifts at varying intensities. Then we thoroughly investigate state-of-the-art probabilistic methods applied to CodeLlama using these shifted code snippets. We observe that these methods generally improve the uncertainty awareness of CodeLlama, with increased calibration quality and higher uncertainty estimation~(UE) precision. However, our study further reveals varied performance dynamics across different criteria (e.g., calibration error vs misclassification detection) and trade-off between efficacy and efficiency, highlighting necessary methodological selection tailored to specific contexts.
<div id='section'>Paperid: <span id='pid'>547, <a href='https://arxiv.org/pdf/2311.00469.pdf' target='_blank'>https://arxiv.org/pdf/2311.00469.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Divyanshu Mishra, He Zhao, Pramit Saha, Aris T. Papageorghiou, J. Alison Noble
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00469">Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-based OOD detection. This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution. The proposed model outperforms reference methods with a 12% improvement in accuracy, 22% higher precision, and an 8% better F1 score.
<div id='section'>Paperid: <span id='pid'>548, <a href='https://arxiv.org/pdf/2308.09887.pdf' target='_blank'>https://arxiv.org/pdf/2308.09887.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Li, Xiaoling Hu, Shahira Abousamra, Chao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09887">Calibrating Uncertainty for Semi-Supervised Crowd Counting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised crowd counting is an important yet challenging task. A popular approach is to iteratively generate pseudo-labels for unlabeled data and add them to the training set. The key is to use uncertainty to select reliable pseudo-labels. In this paper, we propose a novel method to calibrate model uncertainty for crowd counting. Our method takes a supervised uncertainty estimation strategy to train the model through a surrogate function. This ensures the uncertainty is well controlled throughout the training. We propose a matching-based patch-wise surrogate function to better approximate uncertainty for crowd counting tasks. The proposed method pays a sufficient amount of attention to details, while maintaining a proper granularity. Altogether our method is able to generate reliable uncertainty estimation, high quality pseudolabels, and achieve state-of-the-art performance in semisupervised crowd counting.
<div id='section'>Paperid: <span id='pid'>549, <a href='https://arxiv.org/pdf/2307.03243.pdf' target='_blank'>https://arxiv.org/pdf/2307.03243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jie Zhang, Masanori Suganuma, Takayuki Okatani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.03243">That's BAD: Blind Anomaly Detection by Implicit Local Feature Clustering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent studies on visual anomaly detection (AD) of industrial objects/textures have achieved quite good performance. They consider an unsupervised setting, specifically the one-class setting, in which we assume the availability of a set of normal (\textit{i.e.}, anomaly-free) images for training. In this paper, we consider a more challenging scenario of unsupervised AD, in which we detect anomalies in a given set of images that might contain both normal and anomalous samples. The setting does not assume the availability of known normal data and thus is completely free from human annotation, which differs from the standard AD considered in recent studies. For clarity, we call the setting blind anomaly detection (BAD). We show that BAD can be converted into a local outlier detection problem and propose a novel method named PatchCluster that can accurately detect image- and pixel-level anomalies. Experimental results show that PatchCluster shows a promising performance without the knowledge of normal data, even comparable to the SOTA methods applied in the one-class setting needing it.
<div id='section'>Paperid: <span id='pid'>550, <a href='https://arxiv.org/pdf/2306.02879.pdf' target='_blank'>https://arxiv.org/pdf/2306.02879.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yibing Liu, Chris Xing Tian, Haoliang Li, Lei Ma, Shiqi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02879">Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The out-of-distribution (OOD) problem generally arises when neural networks encounter data that significantly deviates from the training data distribution, i.e., in-distribution (InD). In this paper, we study the OOD problem from a neuron activation view. We first formulate neuron activation states by considering both the neuron output and its influence on model decisions. Then, to characterize the relationship between neurons and OOD issues, we introduce the \textit{neuron activation coverage} (NAC) -- a simple measure for neuron behaviors under InD data. Leveraging our NAC, we show that 1) InD and OOD inputs can be largely separated based on the neuron behavior, which significantly eases the OOD detection problem and beats the 21 previous methods over three benchmarks (CIFAR-10, CIFAR-100, and ImageNet-1K). 2) a positive correlation between NAC and model generalization ability consistently holds across architectures and datasets, which enables a NAC-based criterion for evaluating model robustness. Compared to prevalent InD validation criteria, we show that NAC not only can select more robust models, but also has a stronger correlation with OOD test performance.
<div id='section'>Paperid: <span id='pid'>551, <a href='https://arxiv.org/pdf/2305.14696.pdf' target='_blank'>https://arxiv.org/pdf/2305.14696.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dheeraj Mekala, Adithya Samavedhi, Chengyu Dong, Jingbo Shang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.14696">SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to Rank</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural classifiers trained with cross-entropy loss (CE loss) often suffer from poor calibration, necessitating the task of out-of-distribution (OOD) detection. Traditional supervised OOD detection methods require expensive manual annotation of in-distribution and OOD samples. To address the annotation bottleneck, we introduce SELFOOD, a self-supervised OOD detection method that requires only in-distribution samples as supervision. We cast OOD detection as an inter-document intra-label (IDIL) ranking problem and train the classifier with our pairwise ranking loss, referred to as IDIL loss. Specifically, given a set of in-distribution documents and their labels, for each label, we train the classifier to rank the softmax scores of documents belonging to that label to be higher than the scores of documents that belong to other labels. Unlike CE loss, our IDIL loss function reaches zero when the desired confidence ranking is achieved and gradients are backpropagated to decrease probabilities associated with incorrect labels rather than continuously increasing the probability of the correct label. Extensive experiments with several classifiers on multiple classification datasets demonstrate the effectiveness of our method in both coarse- and fine-grained settings.
<div id='section'>Paperid: <span id='pid'>552, <a href='https://arxiv.org/pdf/2301.12649.pdf' target='_blank'>https://arxiv.org/pdf/2301.12649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>L. Mars Gao, Urban Fasel, Steven L. Brunton, J. Nathan Kutz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12649">Convergence of uncertainty estimates in Ensemble and Bayesian sparse model discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sparse model identification enables nonlinear dynamical system discovery from data. However, the control of false discoveries for sparse model identification is challenging, especially in the low-data and high-noise limit. In this paper, we perform a theoretical study on ensemble sparse model discovery, which shows empirical success in terms of accuracy and robustness to noise. In particular, we analyse the bootstrapping-based sequential thresholding least-squares estimator. We show that this bootstrapping-based ensembling technique can perform a provably correct variable selection procedure with an exponential convergence rate of the error rate. In addition, we show that the ensemble sparse model discovery method can perform computationally efficient uncertainty estimation, compared to expensive Bayesian uncertainty quantification methods via MCMC. We demonstrate the convergence properties and connection to uncertainty quantification in various numerical studies on synthetic sparse linear regression and sparse model discovery. The experiments on sparse linear regression support that the bootstrapping-based sequential thresholding least-squares method has better performance for sparse variable selection compared to LASSO, thresholding least-squares, and bootstrapping-based LASSO. In the sparse model discovery experiment, we show that the bootstrapping-based sequential thresholding least-squares method can provide valid uncertainty quantification, converging to a delta measure centered around the true value with increased sample sizes. Finally, we highlight the improved robustness to hyperparameter selection under shifting noise and sparsity levels of the bootstrapping-based sequential thresholding least-squares method compared to other sparse regression methods.
<div id='section'>Paperid: <span id='pid'>553, <a href='https://arxiv.org/pdf/2507.18944.pdf' target='_blank'>https://arxiv.org/pdf/2507.18944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guanyi Qin, Ziyue Wang, Daiyun Shen, Haofeng Liu, Hantao Zhou, Junde Wu, Runze Hu, Yueming Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18944">Structure Matters: Revisiting Boundary Refinement in Video Object Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given an object mask, Semi-supervised Video Object Segmentation (SVOS) technique aims to track and segment the object across video frames, serving as a fundamental task in computer vision. Although recent memory-based methods demonstrate potential, they often struggle with scenes involving occlusion, particularly in handling object interactions and high feature similarity. To address these issues and meet the real-time processing requirements of downstream applications, in this paper, we propose a novel bOundary Amendment video object Segmentation method with Inherent Structure refinement, hereby named OASIS. Specifically, a lightweight structure refinement module is proposed to enhance segmentation accuracy. With the fusion of rough edge priors captured by the Canny filter and stored object features, the module can generate an object-level structure map and refine the representations by highlighting boundary features. Evidential learning for uncertainty estimation is introduced to further address challenges in occluded regions. The proposed method, OASIS, maintains an efficient design, yet extensive experiments on challenging benchmarks demonstrate its superior performance and competitive inference speed compared to other state-of-the-art methods, i.e., achieving the F values of 91.6 (vs. 89.7 on DAVIS-17 validation set) and G values of 86.6 (vs. 86.2 on YouTubeVOS 2019 validation set) while maintaining a competitive speed of 48 FPS on DAVIS.
<div id='section'>Paperid: <span id='pid'>554, <a href='https://arxiv.org/pdf/2506.13265.pdf' target='_blank'>https://arxiv.org/pdf/2506.13265.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohit Mohan, Julia Hindel, Florian Drews, Claudius Gläser, Daniele Cattaneo, Abhinav Valada
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13265">Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous vehicles that navigate in open-world environments may encounter previously unseen object classes. However, most existing LiDAR panoptic segmentation models rely on closed-set assumptions, failing to detect unknown object instances. In this work, we propose ULOPS, an uncertainty-guided open-set panoptic segmentation framework that leverages Dirichlet-based evidential learning to model predictive uncertainty. Our architecture incorporates separate decoders for semantic segmentation with uncertainty estimation, embedding with prototype association, and instance center prediction. During inference, we leverage uncertainty estimates to identify and segment unknown instances. To strengthen the model's ability to differentiate between known and unknown objects, we introduce three uncertainty-driven loss functions. Uniform Evidence Loss to encourage high uncertainty in unknown regions. Adaptive Uncertainty Separation Loss ensures a consistent difference in uncertainty estimates between known and unknown objects at a global scale. Contrastive Uncertainty Loss refines this separation at the fine-grained level. To evaluate open-set performance, we extend benchmark settings on KITTI-360 and introduce a new open-set evaluation for nuScenes. Extensive experiments demonstrate that ULOPS consistently outperforms existing open-set LiDAR panoptic segmentation methods.
<div id='section'>Paperid: <span id='pid'>555, <a href='https://arxiv.org/pdf/2505.22538.pdf' target='_blank'>https://arxiv.org/pdf/2505.22538.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Hofman, Yusuf Sale, Eyke HÃ¼llermeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22538">Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to Prediction Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We address the problem of uncertainty quantification and propose measures of total, aleatoric, and epistemic uncertainty based on a known decomposition of (strictly) proper scoring rules, a specific type of loss function, into a divergence and an entropy component. This leads to a flexible framework for uncertainty quantification that can be instantiated with different losses (scoring rules), which makes it possible to tailor uncertainty quantification to the use case at hand. We show that this flexibility is indeed advantageous. In particular, we analyze the task of selective prediction and show that the scoring rule should ideally match the task loss. In addition, we perform experiments on two other common tasks. For out-of-distribution detection, our results confirm that a widely used measure of epistemic uncertainty, mutual information, performs best. Moreover, in the setting of active learning, our measure of epistemic uncertainty based on the zero-one-loss consistently outperforms other uncertainty measures.
<div id='section'>Paperid: <span id='pid'>556, <a href='https://arxiv.org/pdf/2504.03342.pdf' target='_blank'>https://arxiv.org/pdf/2504.03342.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guide Yang, Chao Hou, Weilong Peng, Xiang Fang, Yongwei Nie, Peican Zhu, Keke Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03342">EOOD: Entropy-based Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) often exhibit overconfidence when encountering out-of-distribution (OOD) samples, posing significant challenges for deployment. Since DNNs are trained on in-distribution (ID) datasets, the information flow of ID samples through DNNs inevitably differs from that of OOD samples. In this paper, we propose an Entropy-based Out-Of-distribution Detection (EOOD) framework. EOOD first identifies specific block where the information flow differences between ID and OOD samples are more pronounced, using both ID and pseudo-OOD samples. It then calculates the conditional entropy on the selected block as the OOD confidence score. Comprehensive experiments conducted across various ID and OOD settings demonstrate the effectiveness of EOOD in OOD detection and its superiority over state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>557, <a href='https://arxiv.org/pdf/2501.03932.pdf' target='_blank'>https://arxiv.org/pdf/2501.03932.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fusang Wang, Hala Djeghim, Nathan Piasco, Moussab Bennehar, Luis RoldÃ£o, Dzmitry Tsishkou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03932">CoStruction: Conjoint radiance field optimization for urban scene reconStruction with limited image overlap</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing the surrounding surface geometry from recorded driving sequences poses a significant challenge due to the limited image overlap and complex topology of urban environments. SoTA neural implicit surface reconstruction methods often struggle in such setting, either failing due to small vision overlap or exhibiting suboptimal performance in accurately reconstructing both the surface and fine structures. To address these limitations, we introduce CoStruction, a novel hybrid implicit surface reconstruction method tailored for large driving sequences with limited camera overlap. CoStruction leverages cross-representation uncertainty estimation to filter out ambiguous geometry caused by limited observations. Our method performs joint optimization of both radiance fields in addition to guided sampling achieving accurate reconstruction of large areas along with fine structures in complex urban scenarios. Extensive evaluation on major driving datasets demonstrates the superiority of our approach in reconstructing large driving sequences with limited image overlap, outperforming concurrent SoTA methods.
<div id='section'>Paperid: <span id='pid'>558, <a href='https://arxiv.org/pdf/2501.03932.pdf' target='_blank'>https://arxiv.org/pdf/2501.03932.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fusang Wang, Hala Djeghim, Nathan Piasco, Moussab Bennehar, Luis Roldão, Yizhe WU, Fabien Moutarde, Désiré Sidibé, Dzmitry Tsishkou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03932">J-NeuS: Joint field optimization for Neural Surface reconstruction in urban scenes with limited image overlap</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing the surrounding surface geometry from recorded driving sequences poses a significant challenge due to the limited image overlap and complex topology of urban environments. SoTA neural implicit surface reconstruction methods often struggle in such setting, either failing due to small vision overlap or exhibiting suboptimal performance in accurately reconstructing both the surface and fine structures. To address these limitations, we introduce J-NeuS, a novel hybrid implicit surface reconstruction method for large driving sequences with outward facing camera poses. J-NeuS cross-representation uncertainty estimation to tackle ambiguous geometry caused by limited observations. Our method performs joint optimization of two radiance fields in addition to guided sampling achieving accurate reconstruction of large areas along with fine structures in complex urban scenarios. Extensive evaluation on major driving datasets demonstrates the superiority of our approach in reconstructing large driving sequences with limited image overlap, outperforming concurrent SoTA methods.
<div id='section'>Paperid: <span id='pid'>559, <a href='https://arxiv.org/pdf/2409.09130.pdf' target='_blank'>https://arxiv.org/pdf/2409.09130.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jialuo Chen, Jingyi Wang, Xiyue Zhang, Youcheng Sun, Marta Kwiatkowska, Jiming Chen, Peng Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09130">FAST: Boosting Uncertainty-based Test Prioritization Methods for Neural Networks via Feature Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the vast testing space, the increasing demand for effective and efficient testing of deep neural networks (DNNs) has led to the development of various DNN test case prioritization techniques. However, the fact that DNNs can deliver high-confidence predictions for incorrectly predicted examples, known as the over-confidence problem, causes these methods to fail to reveal high-confidence errors. To address this limitation, in this work, we propose FAST, a method that boosts existing prioritization methods through guided FeAture SelecTion. FAST is based on the insight that certain features may introduce noise that affects the model's output confidence, thereby contributing to high-confidence errors. It quantifies the importance of each feature for the model's correct predictions, and then dynamically prunes the information from the noisy features during inference to derive a new probability vector for the uncertainty estimation. With the help of FAST, the high-confidence errors and correctly classified examples become more distinguishable, resulting in higher APFD (Average Percentage of Fault Detection) values for test prioritization, and higher generalization ability for model enhancement. We conduct extensive experiments to evaluate FAST across a diverse set of model structures on multiple benchmark datasets to validate the effectiveness, efficiency, and scalability of FAST compared to the state-of-the-art prioritization techniques.
<div id='section'>Paperid: <span id='pid'>560, <a href='https://arxiv.org/pdf/2409.04766.pdf' target='_blank'>https://arxiv.org/pdf/2409.04766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shijing Wang, Yaping Huang, Jun Xie, Yi Tian, Feng Chen, Zhepeng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04766">Cross-Dataset Gaze Estimation by Evidential Inter-intra Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Achieving accurate and reliable gaze predictions in complex and diverse environments remains challenging. Fortunately, it is straightforward to access diverse gaze datasets in real-world applications. We discover that training these datasets jointly can significantly improve the generalization of gaze estimation, which is overlooked in previous works. However, due to the inherent distribution shift across different datasets, simply mixing multiple dataset decreases the performance in the original domain despite gaining better generalization abilities. To address the problem of ``cross-dataset gaze estimation'', we propose a novel Evidential Inter-intra Fusion EIF framework, for training a cross-dataset model that performs well across all source and unseen domains. Specifically, we build independent single-dataset branches for various datasets where the data space is partitioned into overlapping subspaces within each dataset for local regression, and further create a cross-dataset branch to integrate the generalizable features from single-dataset branches. Furthermore, evidential regressors based on the Normal and Inverse-Gamma (NIG) distribution are designed to additionally provide uncertainty estimation apart from predicting gaze. Building upon this foundation, our proposed framework achieves both intra-evidential fusion among multiple local regressors within each dataset and inter-evidential fusion among multiple branches by Mixture \textbfof Normal Inverse-Gamma (MoNIG distribution. Experiments demonstrate that our method consistently achieves notable improvements in both source domains and unseen domains.
<div id='section'>Paperid: <span id='pid'>561, <a href='https://arxiv.org/pdf/2409.03060.pdf' target='_blank'>https://arxiv.org/pdf/2409.03060.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Min Wu, Xiaofu Li, Haoze Wu, Clark Barrett
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03060">Better Verified Explanations with Applications to Incorrectness and Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Building on VeriX (Verified eXplainability, arXiv:2212.01051), a system for producing optimal verified explanations for machine learning model outputs, we present VeriX+, which significantly improves both the size and the generation time of verified explanations. We introduce a bound propagation-based sensitivity technique to improve the size, and a binary search-based traversal with confidence ranking for improving time -- the two techniques are orthogonal and can be used independently or together. We also show how to adapt the QuickXplain (Junker 2004) algorithm to our setting to provide a trade-off between size and time. Experimental evaluations on standard benchmarks demonstrate significant improvements on both metrics, e.g., a size reduction of 38% on the GTSRB dataset and a time reduction of 90% on MNIST. We also explore applications of our verified explanations and show that explanation size is a useful proxy for both incorrectness detection and out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>562, <a href='https://arxiv.org/pdf/2407.09658.pdf' target='_blank'>https://arxiv.org/pdf/2407.09658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ning Wang, Shanghao Shi, Yang Xiao, Yimin Chen, Y. Thomas Hou, Wenjing Lou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09658">BoBa: Boosting Backdoor Detection through Data Distribution Inference in Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning, while being a promising approach for collaborative model training, is susceptible to poisoning attacks due to its decentralized nature. Backdoor attacks, in particular, have shown remarkable stealthiness, as they selectively compromise predictions for inputs containing triggers. Previous endeavors to detect and mitigate such attacks are based on the Independent and Identically Distributed (IID) data assumption where benign model updates exhibit high-level similarity in multiple feature spaces due to IID data. Thus, outliers are detected as backdoor attacks. Nevertheless, non-IID data presents substantial challenges in backdoor attack detection, as the data variety introduces variance among benign models, making outlier detection-based mechanisms less effective.
  We propose a novel distribution-aware anomaly detection mechanism, BoBa, to address this problem. In order to differentiate outliers arising from data variety versus backdoor attack, we propose to break down the problem into two steps: clustering clients utilizing their data distribution followed by a voting-based detection. Based on the intuition that clustering and subsequent backdoor detection can drastically benefit from knowing client data distributions, we propose a novel data distribution inference mechanism. To improve detection robustness, we introduce an overlapping clustering method, where each client is associated with multiple clusters, ensuring that the trustworthiness of a model update is assessed collectively by multiple clusters rather than a single cluster. Through extensive evaluations, we demonstrate that BoBa can reduce the attack success rate to lower than 0.001 while maintaining high main task accuracy across various attack strategies and experimental settings.
<div id='section'>Paperid: <span id='pid'>563, <a href='https://arxiv.org/pdf/2407.08662.pdf' target='_blank'>https://arxiv.org/pdf/2407.08662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08662">Uncertainty Estimation of Large Language Models in Medical Question Answering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) show promise for natural language generation in healthcare, but risk hallucinating factually incorrect information. Deploying LLMs for medical question answering necessitates reliable uncertainty estimation (UE) methods to detect hallucinations. In this work, we benchmark popular UE methods with different model sizes on medical question-answering datasets. Our results show that current approaches generally perform poorly in this domain, highlighting the challenge of UE for medical applications. We also observe that larger models tend to yield better results, suggesting a correlation between model size and the reliability of UE. To address these challenges, we propose Two-phase Verification, a probability-free Uncertainty Estimation approach. First, an LLM generates a step-by-step explanation alongside its initial answer, followed by formulating verification questions to check the factual claims in the explanation. The model then answers these questions twice: first independently, and then referencing the explanation. Inconsistencies between the two sets of answers measure the uncertainty in the original response. We evaluate our approach on three biomedical question-answering datasets using Llama 2 Chat models and compare it against the benchmarked baseline methods. The results show that our Two-phase Verification method achieves the best overall accuracy and stability across various datasets and model sizes, and its performance scales as the model size increases.
<div id='section'>Paperid: <span id='pid'>564, <a href='https://arxiv.org/pdf/2405.10757.pdf' target='_blank'>https://arxiv.org/pdf/2405.10757.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Zhang, Minhua Lin, Enyan Dai, Suhang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.10757">Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) have shown remarkable performance in various tasks. However, recent works reveal that GNNs are vulnerable to backdoor attacks. Generally, backdoor attack poisons the graph by attaching backdoor triggers and the target class label to a set of nodes in the training graph. A GNN trained on the poisoned graph will then be misled to predict test nodes attached with trigger to the target class. Despite their effectiveness, our empirical analysis shows that triggers generated by existing methods tend to be out-of-distribution (OOD), which significantly differ from the clean data. Hence, these injected triggers can be easily detected and pruned with widely used outlier detection methods in real-world applications. Therefore, in this paper, we study a novel problem of unnoticeable graph backdoor attacks with in-distribution (ID) triggers. To generate ID triggers, we introduce an OOD detector in conjunction with an adversarial learning strategy to generate the attributes of the triggers within distribution. To ensure a high attack success rate with ID triggers, we introduce novel modules designed to enhance trigger memorization by the victim model trained on poisoned graph. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed method in generating in distribution triggers that can by-pass various defense strategies while maintaining a high attack success rate.
<div id='section'>Paperid: <span id='pid'>565, <a href='https://arxiv.org/pdf/2402.17653.pdf' target='_blank'>https://arxiv.org/pdf/2402.17653.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David S. W. Williams, Daniele De Martini, Matthew Gadd, Paul Newman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17653">Mitigating Distributional Shift in Semantic Segmentation via Uncertainty Estimation from Unlabelled Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowing when a trained segmentation model is encountering data that is different to its training data is important. Understanding and mitigating the effects of this play an important part in their application from a performance and assurance perspective - this being a safety concern in applications such as autonomous vehicles (AVs). This work presents a segmentation network that can detect errors caused by challenging test domains without any additional annotation in a single forward pass. As annotation costs limit the diversity of labelled datasets, we use easy-to-obtain, uncurated and unlabelled data to learn to perform uncertainty estimation by selectively enforcing consistency over data augmentation. To this end, a novel segmentation benchmark based on the SAX Dataset is used, which includes labelled test data spanning three autonomous-driving domains, ranging in appearance from dense urban to off-road. The proposed method, named Gamma-SSL, consistently outperforms uncertainty estimation and Out-of-Distribution (OoD) techniques on this difficult benchmark - by up to 10.7% in area under the receiver operating characteristic (ROC) curve and 19.2% in area under the precision-recall (PR) curve in the most challenging of the three scenarios.
<div id='section'>Paperid: <span id='pid'>566, <a href='https://arxiv.org/pdf/2402.17622.pdf' target='_blank'>https://arxiv.org/pdf/2402.17622.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David S. W. Williams, Matthew Gadd, Paul Newman, Daniele De Martini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17622">Masked Gamma-SSL: Learning Uncertainty Estimation via Masked Image Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work proposes a semantic segmentation network that produces high-quality uncertainty estimates in a single forward pass. We exploit general representations from foundation models and unlabelled datasets through a Masked Image Modeling (MIM) approach, which is robust to augmentation hyper-parameters and simpler than previous techniques. For neural networks used in safety-critical applications, bias in the training data can lead to errors; therefore it is crucial to understand a network's limitations at run time and act accordingly. To this end, we test our proposed method on a number of test domains including the SAX Segmentation benchmark, which includes labelled test data from dense urban, rural and off-road driving domains. The proposed method consistently outperforms uncertainty estimation and Out-of-Distribution (OoD) techniques on this difficult benchmark.
<div id='section'>Paperid: <span id='pid'>567, <a href='https://arxiv.org/pdf/2402.12664.pdf' target='_blank'>https://arxiv.org/pdf/2402.12664.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Zhang, Kamalika Das, Sricharan Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12664">Discriminant Distance-Aware Representation on Deterministic Uncertainty Quantification Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a crucial aspect of deploying dependable deep learning models in safety-critical systems. In this study, we introduce a novel and efficient method for deterministic uncertainty estimation called Discriminant Distance-Awareness Representation (DDAR). Our approach involves constructing a DNN model that incorporates a set of prototypes in its latent representations, enabling us to analyze valuable feature information from the input data. By leveraging a distinction maximization layer over optimal trainable prototypes, DDAR can learn a discriminant distance-awareness representation. We demonstrate that DDAR overcomes feature collapse by relaxing the Lipschitz constraint that hinders the practicality of deterministic uncertainty methods (DUMs) architectures. Our experiments show that DDAR is a flexible and architecture-agnostic method that can be easily integrated as a pluggable layer with distance-sensitive metrics, outperforming state-of-the-art uncertainty estimation methods on multiple benchmark problems.
<div id='section'>Paperid: <span id='pid'>568, <a href='https://arxiv.org/pdf/2401.03341.pdf' target='_blank'>https://arxiv.org/pdf/2401.03341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangkai Wu, Longbing Cao, Qi Zhang, Junxian Zhou, Hui Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03341">Weakly Augmented Variational Autoencoder in Time Series Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to their unsupervised training and uncertainty estimation, deep Variational Autoencoders (VAEs) have become powerful tools for reconstruction-based Time Series Anomaly Detection (TSAD). Existing VAE-based TSAD methods, either statistical or deep, tune meta-priors to estimate the likelihood probability for effectively capturing spatiotemporal dependencies in the data. However, these methods confront the challenge of inherent data scarcity, which is often the case in anomaly detection tasks. Such scarcity easily leads to latent holes, discontinuous regions in latent space, resulting in non-robust reconstructions on these discontinuous spaces. We propose a novel generative framework that combines VAEs with self-supervised learning (SSL) to address this issue.
<div id='section'>Paperid: <span id='pid'>569, <a href='https://arxiv.org/pdf/2310.14979.pdf' target='_blank'>https://arxiv.org/pdf/2310.14979.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinpeng Wang, Barbara Plank
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14979">ACTOR: Active Learning with Annotator-specific Classification Heads to Embrace Human Label Variation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Label aggregation such as majority voting is commonly used to resolve annotator disagreement in dataset creation. However, this may disregard minority values and opinions. Recent studies indicate that learning from individual annotations outperforms learning from aggregated labels, though they require a considerable amount of annotation. Active learning, as an annotation cost-saving strategy, has not been fully explored in the context of learning from disagreement. We show that in the active learning setting, a multi-head model performs significantly better than a single-head model in terms of uncertainty estimation. By designing and evaluating acquisition functions with annotator-specific heads on two datasets, we show that group-level entropy works generally well on both datasets. Importantly, it achieves performance in terms of both prediction and uncertainty estimation comparable to full-scale training from disagreement, while saving up to 70% of the annotation budget.
<div id='section'>Paperid: <span id='pid'>570, <a href='https://arxiv.org/pdf/2310.04874.pdf' target='_blank'>https://arxiv.org/pdf/2310.04874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuheng Qiu, Chen Wang, Can Xu, Yutian Chen, Xunfei Zhou, Youjie Xia, Sebastian Scherer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04874">AirIMU: Learning Uncertainty Propagation for Inertial Odometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inertial odometry (IO) using strap-down inertial measurement units (IMUs) is critical in many robotic applications where precise orientation and position tracking are essential. Prior kinematic motion model-based IO methods often use a simplified linearized IMU noise model and thus usually encounter difficulties in modeling non-deterministic errors arising from environmental disturbances and mechanical defects. In contrast, data-driven IO methods struggle to accurately model the sensor motions, often leading to generalizability and interoperability issues. To address these challenges, we present AirIMU, a hybrid approach to estimate the uncertainty, especially the non-deterministic errors, by data-driven methods and increase the generalization abilities using model-based methods. We demonstrate the adaptability of AirIMU using a full spectrum of IMUs, from low-cost automotive grades to high-end navigation grades. We also validate its effectiveness on various platforms, including hand-held devices, vehicles, and a helicopter that covers a trajectory of 262 kilometers. In the ablation study, we validate the effectiveness of our learned uncertainty in an IMU-GPS pose graph optimization experiment, achieving a 31.6\% improvement in accuracy. Experiments demonstrate that jointly training the IMU noise correction and uncertainty estimation synergistically benefits both tasks.
<div id='section'>Paperid: <span id='pid'>571, <a href='https://arxiv.org/pdf/2308.00310.pdf' target='_blank'>https://arxiv.org/pdf/2308.00310.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sima Behpour, Thang Doan, Xin Li, Wenbin He, Liang Gou, Liu Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.00310">GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) data is crucial for ensuring the safe deployment of machine learning models in real-world applications. However, existing OOD detection approaches primarily rely on the feature maps or the full gradient space information to derive OOD scores neglecting the role of most important parameters of the pre-trained network over in-distribution (ID) data. In this study, we propose a novel approach called GradOrth to facilitate OOD detection based on one intriguing observation that the important features to identify OOD data lie in the lower-rank subspace of in-distribution (ID) data. In particular, we identify OOD data by computing the norm of gradient projection on the subspaces considered important for the in-distribution data. A large orthogonal projection value (i.e. a small projection value) indicates the sample as OOD as it captures a weak correlation of the ID data. This simple yet effective method exhibits outstanding performance, showcasing a notable reduction in the average false positive rate at a 95% true positive rate (FPR95) of up to 8% when compared to the current state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>572, <a href='https://arxiv.org/pdf/2307.04536.pdf' target='_blank'>https://arxiv.org/pdf/2307.04536.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jens Decke, Christian Gruhl, Lukas Rauch, Bernhard Sick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.04536">DADO -- Low-Cost Query Strategies for Deep Active Design Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this experience report, we apply deep active learning to the field of design optimization to reduce the number of computationally expensive numerical simulations. We are interested in optimizing the design of structural components, where the shape is described by a set of parameters. If we can predict the performance based on these parameters and consider only the promising candidates for simulation, there is an enormous potential for saving computing power. We present two selection strategies for self-optimization to reduce the computational cost in multi-objective design optimization problems. Our proposed methodology provides an intuitive approach that is easy to apply, offers significant improvements over random sampling, and circumvents the need for uncertainty estimation. We evaluate our strategies on a large dataset from the domain of fluid dynamics and introduce two new evaluation metrics to determine the model's performance. Findings from our evaluation highlights the effectiveness of our selection strategies in accelerating design optimization. We believe that the introduced method is easily transferable to other self-optimization problems.
<div id='section'>Paperid: <span id='pid'>573, <a href='https://arxiv.org/pdf/2306.12556.pdf' target='_blank'>https://arxiv.org/pdf/2306.12556.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianhao Yuan, Paul Newman, Matthew Gadd
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.12556">Off the Radar: Uncertainty-Aware Radar Place Recognition with Introspective Querying and Map Maintenance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Localisation with Frequency-Modulated Continuous-Wave (FMCW) radar has gained increasing interest due to its inherent resistance to challenging environments. However, complex artefacts of the radar measurement process require appropriate uncertainty estimation to ensure the safe and reliable application of this promising sensor modality. In this work, we propose a multi-session map management system which constructs the best maps for further localisation based on learned variance properties in an embedding space. Using the same variance properties, we also propose a new way to introspectively reject localisation queries that are likely to be incorrect. For this, we apply robust noise-aware metric learning, which both leverages the short-timescale variability of radar data along a driven path (for data augmentation) and predicts the downstream uncertainty in metric-space-based place recognition. We prove the effectiveness of our method over extensive cross-validated tests of the Oxford Radar RobotCar and MulRan dataset. In this, we outperform the current state-of-the-art in radar place recognition and other uncertainty-aware methods when using only single nearest-neighbour queries. We also show consistent performance increases when rejecting queries based on uncertainty over a difficult test environment, which we did not observe for a competing uncertainty-aware place recognition system.
<div id='section'>Paperid: <span id='pid'>574, <a href='https://arxiv.org/pdf/2305.05079.pdf' target='_blank'>https://arxiv.org/pdf/2305.05079.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Neeraj Varshney, Himanshu Gupta, Eric Robertson, Bing Liu, Chitta Baral
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.05079">A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State-of-the-art natural language processing models have been shown to achieve remarkable performance in 'closed-world' settings where all the labels in the evaluation set are known at training time. However, in real-world settings, 'novel' instances that do not belong to any known class are often observed. This renders the ability to deal with novelties crucial. To initiate a systematic research in this important area of 'dealing with novelties', we introduce 'NoveltyTask', a multi-stage task to evaluate a system's performance on pipelined novelty 'detection' and 'accommodation' tasks. We provide mathematical formulation of NoveltyTask and instantiate it with the authorship attribution task that pertains to identifying the correct author of a given text. We use Amazon reviews corpus and compile a large dataset (consisting of 250k instances across 200 authors/labels) for NoveltyTask. We conduct comprehensive experiments and explore several baseline methods for the task. Our results show that the methods achieve considerably low performance making the task challenging and leaving sufficient room for improvement. Finally, we believe our work will encourage research in this underexplored area of dealing with novelties, an important step en route to developing robust systems.
<div id='section'>Paperid: <span id='pid'>575, <a href='https://arxiv.org/pdf/2302.14208.pdf' target='_blank'>https://arxiv.org/pdf/2302.14208.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tung Thai, Ming Shen, Mayank Garg, Ayush Kalani, Nakul Vaidya, Utkarsh Soni, Mudit Verma, Sriram Gopalakrishnan, Neeraj Varshney, Chitta Baral, Subbarao Kambhampati, Jivko Sinapov, Matthias Scheutz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.14208">Methods and Mechanisms for Interactive Novelty Handling in Adversarial Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning to detect, characterize and accommodate novelties is a challenge that agents operating in open-world domains need to address to be able to guarantee satisfactory task performance. Certain novelties (e.g., changes in environment dynamics) can interfere with the performance or prevent agents from accomplishing task goals altogether. In this paper, we introduce general methods and architectural mechanisms for detecting and characterizing different types of novelties, and for building an appropriate adaptive model to accommodate them utilizing logical representations and reasoning methods. We demonstrate the effectiveness of the proposed methods in evaluations performed by a third party in the adversarial multi-agent board game Monopoly. The results show high novelty detection and accommodation rates across a variety of novelty types, including changes to the rules of the game, as well as changes to the agent's action capabilities.
<div id='section'>Paperid: <span id='pid'>576, <a href='https://arxiv.org/pdf/2302.05914.pdf' target='_blank'>https://arxiv.org/pdf/2302.05914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Illia Oleksiienko, Paraskevi Nousi, Nikolaos Passalis, Anastasios Tefas, Alexandros Iosifidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05914">Variational Voxel Pseudo Image Tracking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is an important task for critical problems, such as robotics and autonomous driving, because it allows creating statistically better perception models and signaling the model's certainty in its predictions to the decision method or a human supervisor. In this paper, we propose a Variational Neural Network-based version of a Voxel Pseudo Image Tracking (VPIT) method for 3D Single Object Tracking. The Variational Feature Generation Network of the proposed Variational VPIT computes features for target and search regions and the corresponding uncertainties, which are later combined using an uncertainty-aware cross-correlation module in one of two ways: by computing similarity between the corresponding uncertainties and adding it to the regular cross-correlation values, or by penalizing the uncertain feature channels to increase influence of the certain features. In experiments, we show that both methods improve tracking performance, while penalization of uncertain features provides the best uncertainty quality.
<div id='section'>Paperid: <span id='pid'>577, <a href='https://arxiv.org/pdf/2206.09522.pdf' target='_blank'>https://arxiv.org/pdf/2206.09522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshayaa Magesh, Venugopal V. Veeravalli, Anirban Roy, Susmit Jha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.09522">Multiple Testing Framework for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the problem of Out-of-Distribution (OOD) detection, that is, detecting whether a learning algorithm's output can be trusted at inference time. While a number of tests for OOD detection have been proposed in prior work, a formal framework for studying this problem is lacking. We propose a definition for the notion of OOD that includes both the input distribution and the learning algorithm, which provides insights for the construction of powerful tests for OOD detection. We propose a multiple hypothesis testing inspired procedure to systematically combine any number of different statistics from the learning algorithm using conformal p-values. We further provide strong guarantees on the probability of incorrectly classifying an in-distribution sample as OOD. In our experiments, we find that threshold-based tests proposed in prior work perform well in specific settings, but not uniformly well across different types of OOD instances. In contrast, our proposed method that combines multiple statistics performs uniformly well across different datasets and neural networks.
<div id='section'>Paperid: <span id='pid'>578, <a href='https://arxiv.org/pdf/2510.05949.pdf' target='_blank'>https://arxiv.org/pdf/2510.05949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Randall Balestriero, Nicolas Ballas, Mike Rabbat, Yann LeCun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05949">Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Joint Embedding Predictive Architectures (JEPAs) learn representations able to solve numerous downstream tasks out-of-the-box. JEPAs combine two objectives: (i) a latent-space prediction term, i.e., the representation of a slightly perturbed sample must be predictable from the original sample's representation, and (ii) an anti-collapse term, i.e., not all samples should have the same representation. While (ii) is often considered as an obvious remedy to representation collapse, we uncover that JEPAs' anti-collapse term does much more--it provably estimates the data density. In short, any successfully trained JEPA can be used to get sample probabilities, e.g., for data curation, outlier detection, or simply for density estimation. Our theoretical finding is agnostic of the dataset and architecture used--in any case one can compute the learned probabilities of sample $x$ efficiently and in closed-form using the model's Jacobian matrix at $x$. Our findings are empirically validated across datasets (synthetic, controlled, and Imagenet) and across different Self Supervised Learning methods falling under the JEPA family (I-JEPA and DINOv2) and on multimodal models, such as MetaCLIP. We denote the method extracting the JEPA learned density as {\bf JEPA-SCORE}.
<div id='section'>Paperid: <span id='pid'>579, <a href='https://arxiv.org/pdf/2508.17690.pdf' target='_blank'>https://arxiv.org/pdf/2508.17690.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danny Wang, Ruihong Qiu, Guangdong Bai, Zi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17690">Text Meets Topology: Rethinking Out-of-distribution Detection in Text-Rich Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection remains challenging in text-rich networks, where textual features intertwine with topological structures. Existing methods primarily address label shifts or rudimentary domain-based splits, overlooking the intricate textual-structural diversity. For example, in social networks, where users represent nodes with textual features (name, bio) while edges indicate friendship status, OOD may stem from the distinct language patterns between bot and normal users. To address this gap, we introduce the TextTopoOOD framework for evaluating detection across diverse OOD scenarios: (1) attribute-level shifts via text augmentations and embedding perturbations; (2) structural shifts through edge rewiring and semantic connections; (3) thematically-guided label shifts; and (4) domain-based divisions. Furthermore, we propose TNT-OOD to model the complex interplay between Text aNd Topology using: 1) a novel cross-attention module to fuse local structure into node-level text representations, and 2) a HyperNetwork to generate node-specific transformation parameters. This aligns topological and semantic features of ID nodes, enhancing ID/OOD distinction across structural and textual shifts. Experiments on 11 datasets across four OOD scenarios demonstrate the nuanced challenge of TextTopoOOD for evaluating OOD detection in text-rich networks.
<div id='section'>Paperid: <span id='pid'>580, <a href='https://arxiv.org/pdf/2508.16832.pdf' target='_blank'>https://arxiv.org/pdf/2508.16832.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yannik Hahn, Jan Voets, Antonin Koenigsfeld, Hasan Tercan, Tobias Meisen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16832">Out of Distribution Detection for Efficient Continual Learning in Quality Prediction for Arc Welding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern manufacturing relies heavily on fusion welding processes, including gas metal arc welding (GMAW). Despite significant advances in machine learning-based quality prediction, current models exhibit critical limitations when confronted with the inherent distribution shifts that occur in dynamic manufacturing environments. In this work, we extend the VQ-VAE Transformer architecture - previously demonstrating state-of-the-art performance in weld quality prediction - by leveraging its autoregressive loss as a reliable out-of-distribution (OOD) detection mechanism. Our approach exhibits superior performance compared to conventional reconstruction methods, embedding error-based techniques, and other established baselines. By integrating OOD detection with continual learning strategies, we optimize model adaptation, triggering updates only when necessary and thereby minimizing costly labeling requirements. We introduce a novel quantitative metric that simultaneously evaluates OOD detection capability while interpreting in-distribution performance. Experimental validation in real-world welding scenarios demonstrates that our framework effectively maintains robust quality prediction capabilities across significant distribution shifts, addressing critical challenges in dynamic manufacturing environments where process parameters frequently change. This research makes a substantial contribution to applied artificial intelligence by providing an explainable and at the same time adaptive solution for quality assurance in dynamic manufacturing processes - a crucial step towards robust, practical AI systems in the industrial environment.
<div id='section'>Paperid: <span id='pid'>581, <a href='https://arxiv.org/pdf/2505.11737.pdf' target='_blank'>https://arxiv.org/pdf/2505.11737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tunyu Zhang, Haizhou Shi, Yibin Wang, Hengyi Wang, Xiaoxiao He, Zhuowei Li, Haoxian Chen, Ligong Han, Kai Xu, Huan Zhang, Dimitris Metaxas, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11737">TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Large Language Models (LLMs) have demonstrated impressive capabilities, their output quality remains inconsistent across various application scenarios, making it difficult to identify trustworthy responses, especially in complex tasks requiring multi-step reasoning. In this paper, we propose a Token-level Uncertainty estimation framework for Reasoning (TokUR) to enable LLMs to self-assess and self-improve their generation quality in mathematical reasoning. Specifically, we introduce low-rank random weight perturbation to LLM decoding, generating predictive distributions that we use to estimate token-level uncertainties. We then aggregate these uncertainties to reflect semantic uncertainty of the generated sequences. Experiments on mathematical reasoning datasets of varying difficulty demonstrate that our token-level uncertainty metrics strongly correlate with answer correctness and model robustness. Additionally, we explore using uncertainty to directly enhance the model's reasoning performance through multiple generations and the particle filtering algorithm. Our approach consistently outperforms existing uncertainty estimation methods, establishing effective uncertainty estimation as a valuable tool for both evaluating and improving reasoning generation in LLMs.
<div id='section'>Paperid: <span id='pid'>582, <a href='https://arxiv.org/pdf/2505.11737.pdf' target='_blank'>https://arxiv.org/pdf/2505.11737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tunyu Zhang, Haizhou Shi, Yibin Wang, Hengyi Wang, Xiaoxiao He, Zhuowei Li, Haoxian Chen, Ligong Han, Kai Xu, Huan Zhang, Dimitris Metaxas, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11737">TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Large Language Models (LLMs) have demonstrated impressive capabilities, their output quality remains inconsistent across various application scenarios, making it difficult to identify trustworthy responses, especially in complex tasks requiring multi-step reasoning. In this paper, we propose a Token-level Uncertainty estimation framework for Reasoning (TokUR) that enables LLMs to self-assess and self-improve their responses in mathematical reasoning. Specifically, we introduce low-rank random weight perturbation during LLM decoding to generate predictive distributions for token-level uncertainty estimation, and we aggregate these uncertainty quantities to capture the semantic uncertainty of generated responses. Experiments on mathematical reasoning datasets of varying difficulty demonstrate that TokUR exhibits a strong correlation with answer correctness and model robustness, and the uncertainty signals produced by TokUR can be leveraged to enhance the model's reasoning performance at test time. These results highlight the effectiveness of TokUR as a principled and scalable approach for improving the reliability and interpretability of LLMs in challenging reasoning tasks.
<div id='section'>Paperid: <span id='pid'>583, <a href='https://arxiv.org/pdf/2505.06898.pdf' target='_blank'>https://arxiv.org/pdf/2505.06898.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honglong Yang, Shanshan Song, Yi Qin, Lehan Wang, Haonan Wang, Xinpeng Ding, Qixiang Zhang, Bodong Du, Xiaomeng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06898">Multi-Modal Explainable Medical AI Assistant for Trustworthy Human-AI Collaboration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generalist Medical AI (GMAI) systems have demonstrated expert-level performance in biomedical perception tasks, yet their clinical utility remains limited by inadequate multi-modal explainability and suboptimal prognostic capabilities. Here, we present XMedGPT, a clinician-centric, multi-modal AI assistant that integrates textual and visual interpretability to support transparent and trustworthy medical decision-making. XMedGPT not only produces accurate diagnostic and descriptive outputs, but also grounds referenced anatomical sites within medical images, bridging critical gaps in interpretability and enhancing clinician usability. To support real-world deployment, we introduce a reliability indexing mechanism that quantifies uncertainty through consistency-based assessment via interactive question-answering. We validate XMedGPT across four pillars: multi-modal interpretability, uncertainty quantification, and prognostic modeling, and rigorous benchmarking. The model achieves an IoU of 0.703 across 141 anatomical regions, and a Kendall's tau-b of 0.479, demonstrating strong alignment between visual rationales and clinical outcomes. For uncertainty estimation, it attains an AUC of 0.862 on visual question answering and 0.764 on radiology report generation. In survival and recurrence prediction for lung and glioma cancers, it surpasses prior leading models by 26.9%, and outperforms GPT-4o by 25.0%. Rigorous benchmarking across 347 datasets covers 40 imaging modalities and external validation spans 4 anatomical systems confirming exceptional generalizability, with performance gains surpassing existing GMAI by 20.7% for in-domain evaluation and 16.7% on 11,530 in-house data evaluation. Together, XMedGPT represents a significant leap forward in clinician-centric AI integration, offering trustworthy and scalable support for diverse healthcare applications.
<div id='section'>Paperid: <span id='pid'>584, <a href='https://arxiv.org/pdf/2505.03774.pdf' target='_blank'>https://arxiv.org/pdf/2505.03774.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Yin, Chen Zhao, Xiaoyan Liu, Minglai Shao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03774">Out-of-Distribution Detection in Heterogeneous Graphs via Energy Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph neural networks (GNNs) are proven effective in extracting complex node and structural information from graph data. While current GNNs perform well in node classification tasks within in-distribution (ID) settings, real-world scenarios often present distribution shifts, leading to the presence of out-of-distribution (OOD) nodes. OOD detection in graphs is a crucial and challenging task. Most existing research focuses on homogeneous graphs, but real-world graphs are often heterogeneous, consisting of diverse node and edge types. This heterogeneity adds complexity and enriches the informational content. To the best of our knowledge, OOD detection in heterogeneous graphs remains an underexplored area. In this context, we propose a novel methodology for OOD detection in heterogeneous graphs (OODHG) that aims to achieve two main objectives: 1) detecting OOD nodes and 2) classifying all ID nodes based on the first task's results. Specifically, we learn representations for each node in the heterogeneous graph, calculate energy values to determine whether nodes are OOD, and then classify ID nodes. To leverage the structural information of heterogeneous graphs, we introduce a meta-path-based energy propagation mechanism and an energy constraint to enhance the distinction between ID and OOD nodes. Extensive experimental findings substantiate the simplicity and effectiveness of OODHG, demonstrating its superiority over baseline models in OOD detection tasks and its accuracy in ID node classification.
<div id='section'>Paperid: <span id='pid'>585, <a href='https://arxiv.org/pdf/2504.04841.pdf' target='_blank'>https://arxiv.org/pdf/2504.04841.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Schmidt, Julius KÃ¶rner, Dominik Fuchsgruber, Stefano Gasperini, Federico Tombari, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04841">Prior2Former -- Evidential Modeling of Mask Transformers for Assumption-Free Open-World Panoptic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In panoptic segmentation, individual instances must be separated within semantic classes. As state-of-the-art methods rely on a pre-defined set of classes, they struggle with novel categories and out-of-distribution (OOD) data. This is particularly problematic in safety-critical applications, such as autonomous driving, where reliability in unseen scenarios is essential. We address the gap between outstanding benchmark performance and reliability by proposing Prior2Former (P2F), the first approach for segmentation vision transformers rooted in evidential learning. P2F extends the mask vision transformer architecture by incorporating a Beta prior for computing model uncertainty in pixel-wise binary mask assignments. This design enables high-quality uncertainty estimation that effectively detects novel and OOD objects enabling state-of-the-art anomaly instance segmentation and open-world panoptic segmentation. Unlike most segmentation models addressing unknown classes, P2F operates without access to OOD data samples or contrastive training on void (i.e., unlabeled) classes, making it highly applicable in real-world scenarios where such prior information is unavailable. Additionally, P2F can be flexibly applied to anomaly instance and panoptic segmentation. Through comprehensive experiments on the Cityscapes, COCO, SegmentMeIfYouCan, and OoDIS datasets, P2F demonstrates state-of-the-art performance across the board.
<div id='section'>Paperid: <span id='pid'>586, <a href='https://arxiv.org/pdf/2502.11021.pdf' target='_blank'>https://arxiv.org/pdf/2502.11021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tuo Zhang, Asal Mehradfar, Dimitrios Dimitriadis, Salman Avestimehr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11021">Leveraging Uncertainty Estimation for Efficient LLM Routing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying large language models (LLMs) in edge-cloud environments requires an efficient routing strategy to balance cost and response quality. Traditional approaches prioritize either human-preference data or accuracy metrics from benchmark datasets as routing criteria, but these methods suffer from rigidity and subjectivity. Moreover, existing routing frameworks primarily focus on accuracy and cost, neglecting response quality from a human preference perspective. In this work, we propose the Confidence-Driven LLM Router, a novel framework that leverages uncertainty estimation to optimize routing decisions. To comprehensively assess routing performance, we evaluate both system cost efficiency and response quality. In particular, we introduce the novel use of LLM-as-a-Judge to simulate human rating preferences, providing the first systematic assessment of response quality across different routing strategies. Extensive experiments on MT-Bench, GSM8K, and MMLU demonstrate that our approach outperforms state-of-the-art routing methods, achieving superior response quality while maintaining cost efficiency.
<div id='section'>Paperid: <span id='pid'>587, <a href='https://arxiv.org/pdf/2502.05780.pdf' target='_blank'>https://arxiv.org/pdf/2502.05780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danny Wang, Ruihong Qiu, Guangdong Bai, Zi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05780">GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite graph neural networks' (GNNs) great success in modelling graph-structured data, out-of-distribution (OOD) test instances still pose a great challenge for current GNNs. One of the most effective techniques to detect OOD nodes is to expose the detector model with an additional OOD node-set, yet the extra OOD instances are often difficult to obtain in practice. Recent methods for image data address this problem using OOD data synthesis, typically relying on pre-trained generative models like Stable Diffusion. However, these approaches require vast amounts of additional data, as well as one-for-all pre-trained generative models, which are not available for graph data. Therefore, we propose the GOLD framework for graph OOD detection, an implicit adversarial learning pipeline with synthetic OOD exposure without pre-trained models. The implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model to regularly imitate the in-distribution (ID) embeddings from an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately classify ID data while increasing the energy divergence between the ID embeddings and the generative model's synthetic embeddings. This novel approach implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, effectively simulating exposure to OOD scenarios without auxiliary data. Extensive OOD detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of GOLD without using real OOD data compared with the state-of-the-art OOD exposure and non-exposure baselines.
<div id='section'>Paperid: <span id='pid'>588, <a href='https://arxiv.org/pdf/2501.08286.pdf' target='_blank'>https://arxiv.org/pdf/2501.08286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ke Wu, Zicheng Zhang, Muer Tie, Ziqing Ai, Zhongxue Gan, Wenchao Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08286">VINGS-Mono: Visual-Inertial Gaussian Splatting Monocular SLAM in Large Scenes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>VINGS-Mono is a monocular (inertial) Gaussian Splatting (GS) SLAM framework designed for large scenes. The framework comprises four main components: VIO Front End, 2D Gaussian Map, NVS Loop Closure, and Dynamic Eraser. In the VIO Front End, RGB frames are processed through dense bundle adjustment and uncertainty estimation to extract scene geometry and poses. Based on this output, the mapping module incrementally constructs and maintains a 2D Gaussian map. Key components of the 2D Gaussian Map include a Sample-based Rasterizer, Score Manager, and Pose Refinement, which collectively improve mapping speed and localization accuracy. This enables the SLAM system to handle large-scale urban environments with up to 50 million Gaussian ellipsoids. To ensure global consistency in large-scale scenes, we design a Loop Closure module, which innovatively leverages the Novel View Synthesis (NVS) capabilities of Gaussian Splatting for loop closure detection and correction of the Gaussian map. Additionally, we propose a Dynamic Eraser to address the inevitable presence of dynamic objects in real-world outdoor scenes. Extensive evaluations in indoor and outdoor environments demonstrate that our approach achieves localization performance on par with Visual-Inertial Odometry while surpassing recent GS/NeRF SLAM methods. It also significantly outperforms all existing methods in terms of mapping and rendering quality. Furthermore, we developed a mobile app and verified that our framework can generate high-quality Gaussian maps in real time using only a smartphone camera and a low-frequency IMU sensor. To the best of our knowledge, VINGS-Mono is the first monocular Gaussian SLAM method capable of operating in outdoor environments and supporting kilometer-scale large scenes.
<div id='section'>Paperid: <span id='pid'>589, <a href='https://arxiv.org/pdf/2412.06014.pdf' target='_blank'>https://arxiv.org/pdf/2412.06014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Baumann, Rui Li, Marcus Klasson, Santeri Mentu, Shyamgopal Karthik, Zeynep Akata, Arno Solin, Martin Trapp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06014">Post-hoc Probabilistic Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs), such as CLIP and SigLIP, have found remarkable success in classification, retrieval, and generative tasks. For this, VLMs deterministically map images and text descriptions to a joint latent space in which their similarity is assessed using the cosine similarity. However, a deterministic mapping of inputs fails to capture uncertainties over concepts arising from domain shifts when used in downstream tasks. In this work, we propose post-hoc uncertainty estimation in VLMs that does not require additional training. Our method leverages a Bayesian posterior approximation over the last layers in VLMs and analytically quantifies uncertainties over cosine similarities. We demonstrate its effectiveness for uncertainty quantification and support set selection in active learning. Compared to baselines, we obtain improved and well-calibrated predictive uncertainties, interpretable uncertainty estimates, and sample-efficient active learning. Our results show promise for safety-critical applications of large-scale models.
<div id='section'>Paperid: <span id='pid'>590, <a href='https://arxiv.org/pdf/2412.06014.pdf' target='_blank'>https://arxiv.org/pdf/2412.06014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Baumann, Rui Li, Marcus Klasson, Santeri Mentu, Shyamgopal Karthik, Zeynep Akata, Arno Solin, Martin Trapp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06014">Post-hoc Probabilistic Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs), such as CLIP and SigLIP, have found remarkable success in classification, retrieval, and generative tasks. For this, VLMs deterministically map images and text descriptions to a joint latent space in which their similarity is assessed using the cosine similarity. However, a deterministic mapping of inputs fails to capture uncertainties over concepts arising from domain shifts when used in downstream tasks. In this work, we propose post-hoc uncertainty estimation in VLMs that does not require additional training. Our method leverages a Bayesian posterior approximation over the last layers in VLMs and analytically quantifies uncertainties over cosine similarities. We demonstrate its effectiveness for uncertainty quantification and support set selection in active learning. Compared to baselines, we obtain improved and well-calibrated predictive uncertainties, interpretable uncertainty estimates, and sample-efficient active learning. Our results show promise for safety-critical applications of large-scale models.
<div id='section'>Paperid: <span id='pid'>591, <a href='https://arxiv.org/pdf/2411.08537.pdf' target='_blank'>https://arxiv.org/pdf/2411.08537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabian Bongratz, Markus Karmann, Adrian Holz, Moritz Bonhoeffer, Viktor Neumaier, Sarah Deli, Benita Schmitz-Koep, Claus Zimmer, Christian Sorg, Melissa Thalhammer, Dennis M Hedderich, Christian Wachinger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08537">MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal Lymphatic Vessel Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste products from the human brain. An impairment in their functionality has been associated with aging as well as brain disorders like multiple sclerosis and Alzheimer's disease. However, MLVs have only recently been described for the first time in magnetic resonance imaging (MRI), and their ramified structure renders manual segmentation particularly difficult. Further, as there is no consistent notion of their appearance, human-annotated MLV structures contain a high inter-rater variability that most automatic segmentation methods cannot take into account. In this work, we propose a new rater-aware training scheme for the popular nnU-Net model, and we explore rater-based ensembling strategies for accurate and consistent segmentation of MLVs. This enables us to boost nnU-Net's performance while obtaining explicit predictions in different annotation styles and a rater-based uncertainty estimation. Our final model, MLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to the human reference standard. The model further matches the human inter-rater reliability and replicates age-related associations with MLV volume.
<div id='section'>Paperid: <span id='pid'>592, <a href='https://arxiv.org/pdf/2408.03746.pdf' target='_blank'>https://arxiv.org/pdf/2408.03746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Xu, Zhiqi Lin, Shigui Li, Min Chen, Junmei Yang, Delu Zeng, John Paisley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.03746">Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Last Layer (BLL) models focus solely on uncertainty in the output layer of neural networks, demonstrating comparable performance to more complex Bayesian models. However, the use of Gaussian priors for last layer weights in Bayesian Last Layer (BLL) models limits their expressive capacity when faced with non-Gaussian, outlier-rich, or high-dimensional datasets. To address this shortfall, we introduce a novel approach that combines diffusion techniques and implicit priors for variational learning of Bayesian last layer weights. This method leverages implicit distributions for modeling weight priors in BLL, coupled with diffusion samplers for approximating true posterior predictions, thereby establishing a comprehensive Bayesian prior and posterior estimation strategy. By delivering an explicit and computationally efficient variational lower bound, our method aims to augment the expressive abilities of BLL models, enhancing model accuracy, calibration, and out-of-distribution detection proficiency. Through detailed exploration and experimental validation, We showcase the method's potential for improving predictive accuracy and uncertainty quantification while ensuring computational efficiency.
<div id='section'>Paperid: <span id='pid'>593, <a href='https://arxiv.org/pdf/2407.05382.pdf' target='_blank'>https://arxiv.org/pdf/2407.05382.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhonghang Liu, Panzhong Lu, Guoyang Xie, Zhichao Lu, Wen-Yan Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.05382">Rethinking Unsupervised Outlier Detection via Multiple Thresholding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the realm of unsupervised image outlier detection, assigning outlier scores holds greater significance than its subsequent task: thresholding for predicting labels. This is because determining the optimal threshold on non-separable outlier score functions is an ill-posed problem. However, the lack of predicted labels not only hiders some real applications of current outlier detectors but also causes these methods not to be enhanced by leveraging the dataset's self-supervision. To advance existing scoring methods, we propose a multiple thresholding (Multi-T) module. It generates two thresholds that isolate inliers and outliers from the unlabelled target dataset, whereas outliers are employed to obtain better feature representation while inliers provide an uncontaminated manifold. Extensive experiments verify that Multi-T can significantly improve proposed outlier scoring methods. Moreover, Multi-T contributes to a naive distance-based method being state-of-the-art.
<div id='section'>Paperid: <span id='pid'>594, <a href='https://arxiv.org/pdf/2407.04022.pdf' target='_blank'>https://arxiv.org/pdf/2407.04022.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Doorenbos, Raphael Sznitman, Pablo MÃ¡rquez-Neila
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04022">Learning Non-Linear Invariants for Unsupervised Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The inability of deep learning models to handle data drawn from unseen distributions has sparked much interest in unsupervised out-of-distribution (U-OOD) detection, as it is crucial for reliable deep learning models. Despite considerable attention, theoretically-motivated approaches are few and far between, with most methods building on top of some form of heuristic. Recently, U-OOD was formalized in the context of data invariants, allowing a clearer understanding of how to characterize U-OOD, and methods leveraging affine invariants have attained state-of-the-art results on large-scale benchmarks. Nevertheless, the restriction to affine invariants hinders the expressiveness of the approach. In this work, we broaden the affine invariants formulation to a more general case and propose a framework consisting of a normalizing flow-like architecture capable of learning non-linear invariants. Our novel approach achieves state-of-the-art results on an extensive U-OOD benchmark, and we demonstrate its further applicability to tabular data. Finally, we show our method has the same desirable properties as those based on affine invariants.
<div id='section'>Paperid: <span id='pid'>595, <a href='https://arxiv.org/pdf/2406.20042.pdf' target='_blank'>https://arxiv.org/pdf/2406.20042.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haykel Snoussi, Davood Karimi, Onur Afacan, Mustafa Utkur, Ali Gholipour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.20042">HAITCH: A Framework for Distortion and Motion Correction in Fetal Multi-Shell Diffusion-Weighted MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion magnetic resonance imaging (dMRI) is pivotal for probing the microstructure of the rapidly-developing fetal brain. However, fetal motion during scans and its interaction with magnetic field inhomogeneities result in artifacts and data scattering across spatial and angular domains. The effects of those artifacts are more pronounced in high-angular resolution fetal dMRI, where signal-to-noise ratio is very low. Those effects lead to biased estimates and compromise the consistency and reliability of dMRI analysis. This work presents HAITCH, the first and the only publicly available tool to correct and reconstruct multi-shell high-angular resolution fetal dMRI data. HAITCH offers several technical advances that include a blip-reversed dual-echo acquisition for dynamic distortion correction, advanced motion correction for model-free and robust reconstruction, optimized multi-shell design for enhanced information capture and increased tolerance to motion, and outlier detection for improved reconstruction fidelity. The framework is open-source, flexible, and can be used to process any type of fetal dMRI data including single-echo or single-shell acquisitions, but is most effective when used with multi-shell multi-echo fetal dMRI data that cannot be processed with any of the existing tools. Validation experiments on real fetal dMRI scans demonstrate significant improvements and accurate correction across diverse fetal ages and motion levels. HAITCH successfully removes artifacts and reconstructs high-fidelity fetal dMRI data suitable for advanced diffusion modeling, including fiber orientation distribution function estimation. These advancements pave the way for more reliable analysis of the fetal brain microstructure and tractography under challenging imaging conditions.
<div id='section'>Paperid: <span id='pid'>596, <a href='https://arxiv.org/pdf/2406.11675.pdf' target='_blank'>https://arxiv.org/pdf/2406.11675.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yibin Wang, Haizhou Shi, Ligong Han, Dimitris Metaxas, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11675">BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) often suffer from overconfidence during inference, particularly when adapted to downstream domain-specific tasks with limited data. Previous work addresses this issue by employing approximate Bayesian estimation after the LLMs are trained, enabling them to quantify uncertainty. However, such post-training approaches' performance is severely limited by the parameters learned during training. In this paper, we go beyond post-training Bayesianization and propose Bayesian Low-Rank Adaptation by Backpropagation (BLoB), an algorithm that continuously and jointly adjusts both the mean and covariance of LLM parameters throughout the whole fine-tuning process. Our empirical results verify the effectiveness of BLoB in terms of generalization and uncertainty estimation, when evaluated on both in-distribution and out-of-distribution data.
<div id='section'>Paperid: <span id='pid'>597, <a href='https://arxiv.org/pdf/2406.02327.pdf' target='_blank'>https://arxiv.org/pdf/2406.02327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Doorenbos, Raphael Sznitman, Pablo MÃ¡rquez-Neila
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02327">Iterative Deployment Exposure for Unsupervised Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models are vulnerable to performance degradation when encountering out-of-distribution (OOD) images, potentially leading to misdiagnoses and compromised patient care. These shortcomings have led to great interest in the field of OOD detection. Existing unsupervised OOD (U-OOD) detection methods typically assume that OOD samples originate from an unconcentrated distribution complementary to the training distribution, neglecting the reality that deployed models passively accumulate task-specific OOD samples over time. To better reflect this real-world scenario, we introduce Iterative Deployment Exposure (IDE), a novel and more realistic setting for U-OOD detection. We propose CSO, a method for IDE that starts from a U-OOD detector that is agnostic to the OOD distribution and slowly refines it during deployment using observed unlabeled data. CSO uses a new U-OOD scoring function that combines the Mahalanobis distance with a nearest-neighbor approach, along with a novel confidence-scaled few-shot OOD detector to effectively learn from limited OOD examples. We validate our approach on a dedicated benchmark, showing that our method greatly improves upon strong baselines on three medical imaging modalities.
<div id='section'>Paperid: <span id='pid'>598, <a href='https://arxiv.org/pdf/2403.02311.pdf' target='_blank'>https://arxiv.org/pdf/2403.02311.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yidong Zhao, Joao Tourais, Iain Pierce, Christian Nitsche, Thomas A. Treibel, Sebastian WeingÃ¤rtner, Artur M. Schweidtmann, Qian Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.02311">Bayesian Uncertainty Estimation by Hamiltonian Monte Carlo: Applications to Cardiac MRI Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL)-based methods have achieved state-of-the-art performance for many medical image segmentation tasks. Nevertheless, recent studies show that deep neural networks (DNNs) can be miscalibrated and overconfident, leading to "silent failures" that are risky for clinical applications. Bayesian DL provides an intuitive approach to DL failure detection, based on posterior probability estimation. However, the posterior is intractable for large medical image segmentation DNNs. To tackle this challenge, we propose a Bayesian learning framework using Hamiltonian Monte Carlo (HMC), tempered by cold posterior (CP) to accommodate medical data augmentation, named HMC-CP. For HMC computation, we further propose a cyclical annealing strategy, capturing both local and global geometries of the posterior distribution, enabling highly efficient Bayesian DNN training with the same computational budget as training a single DNN. The resulting Bayesian DNN outputs an ensemble segmentation along with the segmentation uncertainty. We evaluate the proposed HMC-CP extensively on cardiac magnetic resonance image (MRI) segmentation, using in-domain steady-state free precession (SSFP) cine images as well as out-of-domain datasets of quantitative T1 and T2 mapping. Our results show that the proposed method improves both segmentation accuracy and uncertainty estimation for in- and out-of-domain data, compared with well-established baseline methods such as Monte Carlo Dropout and Deep Ensembles. Additionally, we establish a conceptual link between HMC and the commonly known stochastic gradient descent (SGD) and provide general insight into the uncertainty of DL. This uncertainty is implicitly encoded in the training dynamics but often overlooked. With reliable uncertainty estimation, our method provides a promising direction toward trustworthy DL in clinical applications.
<div id='section'>Paperid: <span id='pid'>599, <a href='https://arxiv.org/pdf/2403.01165.pdf' target='_blank'>https://arxiv.org/pdf/2403.01165.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linhai Zhang, Jialong Wu, Deyu Zhou, Guoqiang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01165">STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the uncertainty gap, we introduce a dynamic uncertainty measurement that combines the uncertainty of the base model and the uncertainty of the full model during the iteration of active learning. For poor model calibration, we incorporate the regularization method during LoRA training to keep the model from being over-confident, and the Monte-Carlo dropout mechanism is employed to enhance the uncertainty estimation. Experimental results show that the proposed approach outperforms existing baseline models on three complex reasoning tasks.
<div id='section'>Paperid: <span id='pid'>600, <a href='https://arxiv.org/pdf/2402.18162.pdf' target='_blank'>https://arxiv.org/pdf/2402.18162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weilin Wan, Weizhong Zhang, Quan Zhou, Fan Yi, Cheng Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18162">Out-of-Distribution Detection using Neural Activation Prior</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution detection (OOD) is a crucial technique for deploying machine learning models in the real world to handle the unseen scenarios. In this paper, we first propose a simple yet effective Neural Activation Prior (NAP) for OOD detection. Our neural activation prior is based on a key observation that, for a channel before the global pooling layer of a fully trained neural network, the probability of a few neurons being activated with a large response by an in-distribution (ID) sample is significantly higher than that by an OOD sample. An intuitive explanation is that for a model fully trained on ID dataset, each channel would play a role in detecting a certain pattern in the ID dataset, and a few neurons can be activated with a large response when the pattern is detected in an input sample. Then, a new scoring function based on this prior is proposed to highlight the role of these strongly activated neurons in OOD detection. Our approach is plug-and-play and does not lead to any performance degradation on ID data classification and requires no extra training or statistics from training or external datasets. Notice that previous methods primarily rely on post-global-pooling features of the neural networks, while the within-channel distribution information we leverage would be discarded by the global pooling operator. Consequently, our method is orthogonal to existing approaches and can be effectively combined with them in various applications. Experimental results show that our method achieves the state-of-the-art performance on CIFAR benchmark and ImageNet dataset, which demonstrates the power of the proposed prior. Finally, we extend our method to Transformers and the experimental findings indicate that NAP can also significantly enhance the performance of OOD detection on Transformers, thereby demonstrating the broad applicability of this prior knowledge.
<div id='section'>Paperid: <span id='pid'>601, <a href='https://arxiv.org/pdf/2402.10062.pdf' target='_blank'>https://arxiv.org/pdf/2402.10062.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Chen, Zhihang Fu, Kai Liu, Ze Chen, Mingyuan Tao, Jieping Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10062">Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For a machine learning model deployed in real world scenarios, the ability of detecting out-of-distribution (OOD) samples is indispensable and challenging. Most existing OOD detection methods focused on exploring advanced training skills or training-free tricks to prevent the model from yielding overconfident confidence score for unknown samples. The training-based methods require expensive training cost and rely on OOD samples which are not always available, while most training-free methods can not efficiently utilize the prior information from the training data. In this work, we propose an \textbf{O}ptimal \textbf{P}arameter and \textbf{N}euron \textbf{P}runing (\textbf{OPNP}) approach, which aims to identify and remove those parameters and neurons that lead to over-fitting. The main method is divided into two steps. In the first step, we evaluate the sensitivity of the model parameters and neurons by averaging gradients over all training samples. In the second step, the parameters and neurons with exceptionally large or close to zero sensitivities are removed for prediction. Our proposal is training-free, compatible with other post-hoc methods, and exploring the information from all training data. Extensive experiments are performed on multiple OOD detection tasks and model architectures, showing that our proposed OPNP consistently outperforms the existing methods by a large margin.
<div id='section'>Paperid: <span id='pid'>602, <a href='https://arxiv.org/pdf/2402.03744.pdf' target='_blank'>https://arxiv.org/pdf/2402.03744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, Mingyuan Tao, Zhihang Fu, Jieping Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03744">INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge hallucination have raised widespread concerns for the security and reliability of deployed LLMs. Previous efforts in detecting hallucinations have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, where the semantic information is inevitably lost during the token-decoding procedure. Thus, we propose to explore the dense semantic information retained within LLMs' \textbf{IN}ternal \textbf{S}tates for halluc\textbf{I}nation \textbf{DE}tection (\textbf{INSIDE}). In particular, a simple yet effective \textbf{EigenScore} metric is proposed to better evaluate responses' self-consistency, which exploits the eigenvalues of responses' covariance matrix to measure the semantic consistency/diversity in the dense embedding space. Furthermore, from the perspective of self-consistent hallucination detection, a test time feature clipping approach is explored to truncate extreme activations in the internal states, which reduces overconfident generations and potentially benefits the detection of overconfident hallucinations. Extensive experiments and ablation studies are performed on several popular LLMs and question-answering (QA) benchmarks, showing the effectiveness of our proposal.
<div id='section'>Paperid: <span id='pid'>603, <a href='https://arxiv.org/pdf/2310.09831.pdf' target='_blank'>https://arxiv.org/pdf/2310.09831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zian Jia, Yun Xiong, Yuhong Nan, Yao Zhang, Jinjing Zhao, Mi Wen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.09831">MAGIC: Detecting Advanced Persistent Threats via Masked Graph Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advance Persistent Threats (APTs), adopted by most delicate attackers, are becoming increasing common and pose great threat to various enterprises and institutions. Data provenance analysis on provenance graphs has emerged as a common approach in APT detection. However, previous works have exhibited several shortcomings: (1) requiring attack-containing data and a priori knowledge of APTs, (2) failing in extracting the rich contextual information buried within provenance graphs and (3) becoming impracticable due to their prohibitive computation overhead and memory consumption.
  In this paper, we introduce MAGIC, a novel and flexible self-supervised APT detection approach capable of performing multi-granularity detection under different level of supervision. MAGIC leverages masked graph representation learning to model benign system entities and behaviors, performing efficient deep feature extraction and structure abstraction on provenance graphs. By ferreting out anomalous system behaviors via outlier detection methods, MAGIC is able to perform both system entity level and batched log level APT detection. MAGIC is specially designed to handle concept drift with a model adaption mechanism and successfully applies to universal conditions and detection scenarios. We evaluate MAGIC on three widely-used datasets, including both real-world and simulated attacks. Evaluation results indicate that MAGIC achieves promising detection results in all scenarios and shows enormous advantage over state-of-the-art APT detection approaches in performance overhead.
<div id='section'>Paperid: <span id='pid'>604, <a href='https://arxiv.org/pdf/2305.16216.pdf' target='_blank'>https://arxiv.org/pdf/2305.16216.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenxi Zhang, Ran Ran, Chunna Tian, Heng Zhou, Fan Yang, Xin Li, Zhicheng Jiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.16216">Cross-supervised Dual Classifiers for Semi-supervised Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised medical image segmentation offers a promising solution for large-scale medical image analysis by significantly reducing the annotation burden while achieving comparable performance. Employing this method exhibits a high degree of potential for optimizing the segmentation process and increasing its feasibility in clinical settings during translational investigations. Recently, cross-supervised training based on different co-training sub-networks has become a standard paradigm for this task. Still, the critical issues of sub-network disagreement and label-noise suppression require further attention and progress in cross-supervised training. This paper proposes a cross-supervised learning framework based on dual classifiers (DC-Net), including an evidential classifier and a vanilla classifier. The two classifiers exhibit complementary characteristics, enabling them to handle disagreement effectively and generate more robust and accurate pseudo-labels for unlabeled data. We also incorporate the uncertainty estimation from the evidential classifier into cross-supervised training to alleviate the negative effect of the error supervision signal. The extensive experiments on LA and Pancreas-CT dataset illustrate that DC-Net outperforms other state-of-the-art methods for semi-supervised segmentation. The code will be released soon.
<div id='section'>Paperid: <span id='pid'>605, <a href='https://arxiv.org/pdf/2304.05040.pdf' target='_blank'>https://arxiv.org/pdf/2304.05040.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alain Jungo, Lars Doorenbos, Tommaso Da Col, Maarten Beelen, Martin Zinkernagel, Pablo MÃ¡rquez-Neila, Raphael Sznitman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.05040">Unsupervised out-of-distribution detection for safer robotically guided retinal microsurgery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose: A fundamental problem in designing safe machine learning systems is identifying when samples presented to a deployed model differ from those observed at training time. Detecting so-called out-of-distribution (OoD) samples is crucial in safety-critical applications such as robotically guided retinal microsurgery, where distances between the instrument and the retina are derived from sequences of 1D images that are acquired by an instrument-integrated optical coherence tomography (iiOCT) probe.
  Methods: This work investigates the feasibility of using an OoD detector to identify when images from the iiOCT probe are inappropriate for subsequent machine learning-based distance estimation. We show how a simple OoD detector based on the Mahalanobis distance can successfully reject corrupted samples coming from real-world ex vivo porcine eyes.
  Results: Our results demonstrate that the proposed approach can successfully detect OoD samples and help maintain the performance of the downstream task within reasonable levels. MahaAD outperformed a supervised approach trained on the same kind of corruptions and achieved the best performance in detecting OoD cases from a collection of iiOCT samples with real-world corruptions.
  Conclusion: The results indicate that detecting corrupted iiOCT data through OoD detection is feasible and does not need prior knowledge of possible corruptions. Consequently, MahaAD could aid in ensuring patient safety during robotically guided microsurgery by preventing deployed prediction models from estimating distances that put the patient at risk.
<div id='section'>Paperid: <span id='pid'>606, <a href='https://arxiv.org/pdf/2212.06278.pdf' target='_blank'>https://arxiv.org/pdf/2212.06278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yidong Zhao, Changchun Yang, Artur Schweidtmann, Qian Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.06278">Efficient Bayesian Uncertainty Estimation for nnU-Net</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The self-configuring nnU-Net has achieved leading performance in a large range of medical image segmentation challenges. It is widely considered as the model of choice and a strong baseline for medical image segmentation. However, despite its extraordinary performance, nnU-Net does not supply a measure of uncertainty to indicate its possible failure. This can be problematic for large-scale image segmentation applications, where data are heterogeneous and nnU-Net may fail without notice. In this work, we introduce a novel method to estimate nnU-Net uncertainty for medical image segmentation. We propose a highly effective scheme for posterior sampling of weight space for Bayesian uncertainty estimation. Different from previous baseline methods such as Monte Carlo Dropout and mean-field Bayesian Neural Networks, our proposed method does not require a variational architecture and keeps the original nnU-Net architecture intact, thereby preserving its excellent performance and ease of use. Additionally, we boost the segmentation performance over the original nnU-Net via marginalizing multi-modal posterior models. We applied our method on the public ACDC and M&M datasets of cardiac MRI and demonstrated improved uncertainty estimation over a range of baseline methods. The proposed method further strengthens nnU-Net for medical image segmentation in terms of both segmentation accuracy and quality control.
<div id='section'>Paperid: <span id='pid'>607, <a href='https://arxiv.org/pdf/2508.20812.pdf' target='_blank'>https://arxiv.org/pdf/2508.20812.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lorenzo Busellato, Federico Cunico, Diego Dall'Alba, Marco Emporio, Andrea Giachetti, Riccardo Muradore, Marco Cristani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20812">Uncertainty Aware-Predictive Control Barrier Functions: Safer Human Robot Interaction through Probabilistic Motion Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To enable flexible, high-throughput automation in settings where people and robots share workspaces, collaborative robotic cells must reconcile stringent safety guarantees with the need for responsive and effective behavior. A dynamic obstacle is the stochastic, task-dependent variability of human motion: when robots fall back on purely reactive or worst-case envelopes, they brake unnecessarily, stall task progress, and tamper with the fluidity that true Human-Robot Interaction demands. In recent years, learning-based human-motion prediction has rapidly advanced, although most approaches produce worst-case scenario forecasts that often do not treat prediction uncertainty in a well-structured way, resulting in over-conservative planning algorithms, limiting their flexibility. We introduce Uncertainty-Aware Predictive Control Barrier Functions (UA-PCBFs), a unified framework that fuses probabilistic human hand motion forecasting with the formal safety guarantees of Control Barrier Functions. In contrast to other variants, our framework allows for dynamic adjustment of the safety margin thanks to the human motion uncertainty estimation provided by a forecasting module. Thanks to uncertainty estimation, UA-PCBFs empower collaborative robots with a deeper understanding of future human states, facilitating more fluid and intelligent interactions through informed motion planning. We validate UA-PCBFs through comprehensive real-world experiments with an increasing level of realism, including automated setups (to perform exactly repeatable motions) with a robotic hand and direct human-robot interactions (to validate promptness, usability, and human confidence). Relative to state-of-the-art HRI architectures, UA-PCBFs show better performance in task-critical metrics, significantly reducing the number of violations of the robot's safe space during interaction with respect to the state-of-the-art.
<div id='section'>Paperid: <span id='pid'>608, <a href='https://arxiv.org/pdf/2508.07625.pdf' target='_blank'>https://arxiv.org/pdf/2508.07625.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junxiao Xue, Xiaozhen Liu, Jie Wang, Xuecheng Wu, Bin Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07625">A Trustworthy Method for Multimodal Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing emotion recognition methods mainly focus on enhancing performance by employing complex deep models, typically resulting in significantly higher model complexity. Although effective, it is also crucial to ensure the reliability of the final decision, especially for noisy, corrupted and out-of-distribution data. To this end, we propose a novel emotion recognition method called trusted emotion recognition (TER), which utilizes uncertainty estimation to calculate the confidence value of predictions. TER combines the results from multiple modalities based on their confidence values to output the trusted predictions. We also provide a new evaluation criterion to assess the reliability of predictions. Specifically, we incorporate trusted precision and trusted recall to determine the trusted threshold and formulate the trusted Acc. and trusted F1 score to evaluate the model's trusted performance. The proposed framework combines the confidence module that accordingly endows the model with reliability and robustness against possible noise or corruption. The extensive experimental results validate the effectiveness of our proposed model. The TER achieves state-of-the-art performance on the Music-video, achieving 82.40% Acc. In terms of trusted performance, TER outperforms other methods on the IEMOCAP and Music-video, achieving trusted F1 scores of 0.7511 and 0.9035, respectively.
<div id='section'>Paperid: <span id='pid'>609, <a href='https://arxiv.org/pdf/2507.23411.pdf' target='_blank'>https://arxiv.org/pdf/2507.23411.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lemar Abdi, Francisco Caetano, Amaan Valiuddin, Christiaan Viviers, Hamdi Joudeh, Fons van der Sommen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.23411">Out-of-Distribution Detection in Medical Imaging via Diffusion Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In medical imaging, unsupervised out-of-distribution (OOD) detection offers an attractive approach for identifying pathological cases with extremely low incidence rates. In contrast to supervised methods, OOD-based approaches function without labels and are inherently robust to data imbalances. Current generative approaches often rely on likelihood estimation or reconstruction error, but these methods can be computationally expensive, unreliable, and require retraining if the inlier data changes. These limitations hinder their ability to distinguish nominal from anomalous inputs efficiently, consistently, and robustly. We propose a reconstruction-free OOD detection method that leverages the forward diffusion trajectories of a Stein score-based denoising diffusion model (SBDDM). By capturing trajectory curvature via the estimated Stein score, our approach enables accurate anomaly scoring with only five diffusion steps. A single SBDDM pre-trained on a large, semantically aligned medical dataset generalizes effectively across multiple Near-OOD and Far-OOD benchmarks, achieving state-of-the-art performance while drastically reducing computational cost during inference. Compared to existing methods, SBDDM achieves a relative improvement of up to 10.43% and 18.10% for Near-OOD and Far-OOD detection, making it a practical building block for real-time, reliable computer-aided diagnosis.
<div id='section'>Paperid: <span id='pid'>610, <a href='https://arxiv.org/pdf/2507.15036.pdf' target='_blank'>https://arxiv.org/pdf/2507.15036.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lyes Saad Saoud, Irfan Hussain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15036">EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Underwater image enhancement is vital for marine conservation, particularly coral reef monitoring. However, AI-based enhancement models often face dataset bias, high computational costs, and lack of transparency, leading to potential misinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware AI framework to address these challenges. EBA-AI leverages CLIP embeddings to detect and mitigate dataset bias, ensuring balanced representation across varied underwater environments. It also integrates adaptive processing to optimize energy efficiency, significantly reducing GPU usage while maintaining competitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100 show that while PSNR drops by a controlled 1.0 dB, computational savings enable real-time feasibility for large-scale marine monitoring. Additionally, uncertainty estimation and explainability techniques enhance trust in AI-driven environmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet, WaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing efficiency, fairness, and interpretability in underwater image processing. By addressing key limitations of AI-driven enhancement, this work contributes to sustainable, bias-aware, and computationally efficient marine conservation efforts. For interactive visualizations, animations, source code, and access to the preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/
<div id='section'>Paperid: <span id='pid'>611, <a href='https://arxiv.org/pdf/2505.15284.pdf' target='_blank'>https://arxiv.org/pdf/2505.15284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Fang, Qinghua Tao, Mingzhen He, Kexin Lv, Runze Yang, Haibo Hu, Xiaolin Huang, Jie Yang, Longbin Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15284">Kernel PCA for Out-of-Distribution Detection: Non-Linear Kernel Selections and Approximations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OoD) detection is vital for the reliability of deep neural networks, the key of which lies in effectively characterizing the disparities between OoD and In-Distribution (InD) data. In this work, such disparities are exploited through a fresh perspective of non-linear feature subspace. That is, a discriminative non-linear subspace is learned from InD features to capture representative patterns of InD, while informative patterns of OoD features cannot be well captured in such a subspace due to their different distribution. Grounded on this perspective, we exploit the deviations of InD and OoD features in such a non-linear subspace for effective OoD detection. To be specific, we leverage the framework of Kernel Principal Component Analysis (KPCA) to attain the discriminative non-linear subspace and deploy the reconstruction error on such subspace to distinguish InD and OoD data. Two challenges emerge: (i) the learning of an effective non-linear subspace, i.e., the selection of kernel function in KPCA, and (ii) the computation of the kernel matrix with large-scale InD data. For the former, we reveal two vital non-linear patterns that closely relate to the InD-OoD disparity, leading to the establishment of a Cosine-Gaussian kernel for constructing the subspace. For the latter, we introduce two techniques to approximate the Cosine-Gaussian kernel with significantly cheap computations. In particular, our approximation is further tailored by incorporating the InD data confidence, which is demonstrated to promote the learning of discriminative subspaces for OoD data. Our study presents new insights into the non-linear feature subspace for OoD detection and contributes practical explorations on the associated kernel design and efficient computations, yielding a KPCA detection method with distinctively improved efficacy and efficiency.
<div id='section'>Paperid: <span id='pid'>612, <a href='https://arxiv.org/pdf/2505.07309.pdf' target='_blank'>https://arxiv.org/pdf/2505.07309.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07309">Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) often generate fluent but factually incorrect outputs, known as hallucinations, which undermine their reliability in real-world applications. While uncertainty estimation has emerged as a promising strategy for detecting such errors, current metrics offer limited interpretability and lack clarity about the types of uncertainty they capture. In this paper, we present a systematic framework for decomposing LLM uncertainty into four distinct sources, inspired by previous research. We develop a source-specific estimation pipeline to quantify these uncertainty types and evaluate how existing metrics relate to each source across tasks and models. Our results show that metrics, task, and model exhibit systematic variation in uncertainty characteristic. Building on this, we propose a method for task specific metric/model selection guided by the alignment or divergence between their uncertainty characteristics and that of a given task. Our experiments across datasets and models demonstrate that our uncertainty-aware selection strategy consistently outperforms baseline strategies, helping us select appropriate models or uncertainty metrics, and contributing to more reliable and efficient deployment in uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>613, <a href='https://arxiv.org/pdf/2501.14894.pdf' target='_blank'>https://arxiv.org/pdf/2501.14894.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiaojie Zheng, Jiucai Zhang, Xiaoli Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14894">Enhancing accuracy of uncertainty estimation in appearance-based gaze tracking with probabilistic evaluation and calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately knowing uncertainties in appearance-based gaze tracking is critical for ensuring reliable downstream applications. Due to the lack of individual uncertainty labels, current uncertainty-aware approaches adopt probabilistic models to acquire uncertainties by following distributions in the training dataset. Without regulations, this approach lets the uncertainty model build biases and overfits the training data, leading to poor performance when deployed. We first presented a strict proper evaluation metric from the probabilistic perspective based on comparing the coverage probability between prediction and observation to provide quantitative evaluation for better assessment on the inferred uncertainties. We then proposed a correction strategy based on probability calibration to mitigate biases in the estimated uncertainties of the trained models. Finally, we demonstrated the effectiveness of the correction strategy with experiments performed on two popular gaze estimation datasets with distinctive image characteristics caused by data collection settings.
<div id='section'>Paperid: <span id='pid'>614, <a href='https://arxiv.org/pdf/2501.08005.pdf' target='_blank'>https://arxiv.org/pdf/2501.08005.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francisco Caetano, Christiaan Viviers, Luis A. Zavala-MondragÃ³n, Peter H. N. de With, Fons van der Sommen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08005">DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code is publicly available.
<div id='section'>Paperid: <span id='pid'>615, <a href='https://arxiv.org/pdf/2501.08005.pdf' target='_blank'>https://arxiv.org/pdf/2501.08005.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francisco Caetano, Christiaan Viviers, Luis A. Zavala-Mondragón, Peter H. N. de With, Fons van der Sommen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08005">DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code is publicly available.
<div id='section'>Paperid: <span id='pid'>616, <a href='https://arxiv.org/pdf/2411.16189.pdf' target='_blank'>https://arxiv.org/pdf/2411.16189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihua Duan, Jialin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16189">Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) still face challenges when dealing with complex reasoning tasks, often resulting in hallucinations, which limit the practical application of LLMs. To alleviate this issue, this paper proposes a new method that integrates different LLMs to expand the knowledge boundary, reduce dependence on a single model, and promote in-depth debate among agents. The main contributions include: 1) Introducing third-party LLMs to adjust the attention weights of agents through uncertainty estimation and confidence analysis, optimizing consensus formation in multi-agent systems; 2) Experiments on arithmetic datasets have validated the effectiveness of the method, surpassing traditional multi-agent baselines. This research provides a new perspective for large models to alleviate hallucination phenomena when dealing with complex tasks.
<div id='section'>Paperid: <span id='pid'>617, <a href='https://arxiv.org/pdf/2411.08227.pdf' target='_blank'>https://arxiv.org/pdf/2411.08227.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shawn Li, Huixian Gong, Hao Dong, Tiankai Yang, Zhengzhong Tu, Yue Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08227">DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for ensuring the robustness of machine learning models by identifying samples that deviate from the training distribution. While traditional OOD detection has primarily focused on single-modality inputs, such as images, recent advances in multimodal models have demonstrated the potential of leveraging multiple modalities (e.g., video, optical flow, audio) to enhance detection performance. However, existing methods often overlook intra-class variability within in-distribution (ID) data, assuming that samples of the same class are perfectly cohesive and consistent. This assumption can lead to performance degradation, especially when prediction discrepancies are uniformly amplified across all samples. To address this issue, we propose Dynamic Prototype Updating (DPU), a novel plug-and-play framework for multimodal OOD detection that accounts for intra-class variations. Our method dynamically updates class center representations for each class by measuring the variance of similar samples within each batch, enabling adaptive adjustments. This approach allows us to amplify prediction discrepancies based on the updated class centers, thereby improving the model's robustness and generalization across different modalities. Extensive experiments on two tasks, five datasets, and nine base OOD algorithms demonstrate that DPU significantly improves OOD detection performance, setting a new state-of-the-art in multimodal OOD detection, with improvements of up to 80 percent in Far-OOD detection. To facilitate accessibility and reproducibility, our code is publicly available on GitHub.
<div id='section'>Paperid: <span id='pid'>618, <a href='https://arxiv.org/pdf/2410.19356.pdf' target='_blank'>https://arxiv.org/pdf/2410.19356.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Li, Zhicheng Xu, Bo Wen, Ruibin Mao, Can Li, Thomas KÃ¤mpfe, Kai Ni, Xunzhao Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19356">FeBiM: Efficient and Compact Bayesian Inference Engine Empowered with Ferroelectric In-Memory Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In scenarios with limited training data or where explainability is crucial, conventional neural network-based machine learning models often face challenges. In contrast, Bayesian inference-based algorithms excel in providing interpretable predictions and reliable uncertainty estimation in these scenarios. While many state-of-the-art in-memory computing (IMC) architectures leverage emerging non-volatile memory (NVM) technologies to offer unparalleled computing capacity and energy efficiency for neural network workloads, their application in Bayesian inference is limited. This is because the core operations in Bayesian inference differ significantly from the multiplication-accumulation (MAC) operations common in neural networks, rendering them generally unsuitable for direct implementation in most existing IMC designs. In this paper, we propose FeBiM, an efficient and compact Bayesian inference engine powered by multi-bit ferroelectric field-effect transistor (FeFET)-based IMC. FeBiM effectively encodes the trained probabilities of a Bayesian inference model within a compact FeFET-based crossbar. It maps quantized logarithmic probabilities to discrete FeFET states. As a result, the accumulated outputs of the crossbar naturally represent the posterior probabilities, i.e., the Bayesian inference model's output given a set of observations. This approach enables efficient in-memory Bayesian inference without the need for additional calculation circuitry. As the first FeFET-based in-memory Bayesian inference engine, FeBiM achieves an impressive storage density of 26.32 Mb/mm$^{2}$ and a computing efficiency of 581.40 TOPS/W in a representative Bayesian classification task. These results demonstrate 10.7$\times$/43.4$\times$ improvement in compactness/efficiency compared to the state-of-the-art hardware implementation of Bayesian inference.
<div id='section'>Paperid: <span id='pid'>619, <a href='https://arxiv.org/pdf/2409.10094.pdf' target='_blank'>https://arxiv.org/pdf/2409.10094.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Fang, Qinghua Tao, Zuopeng Yang, Xiaolin Huang, Jie Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10094">Beyond Perceptual Distances: Rethinking Disparity Assessment for Out-of-Distribution Detection with Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OoD) detection aims to justify whether a given sample is from the training distribution of the classifier-under-protection, i.e., In-Distribution (InD), or from OoD. Diffusion Models (DMs) are recently utilized in OoD detection by using the perceptual distances between the given image and its DM generation. DM-based methods bring fresh insights to the field, yet remain under-explored.
  In this work, we point out two main limitations in DM-based OoD detection methods: (i) the perceptual metrics on the disparities between the given sample and its generation are devised only at human-perceived levels, ignoring the abstract or high-level patterns that help better reflect the intrinsic disparities in distribution; (ii) only the raw image contents are taken to measure the disparities, while other representations, i.e., the features and probabilities from the classifier-under-protection, are easy to access at hand but are ignored. To this end, our proposed detection framework goes beyond the perceptual distances and looks into the deep representations from the classifier-under-protection with our novel metrics devised correspondingly, leading to more informative disparity assessments between InD and OoD. An anomaly-removal strategy is integrated to remove the abnormal OoD information in the generation, further enhancing the distinctiveness of disparities. Our work has demonstrated state-of-the-art detection performances among DM-based methods in extensive experiments.
<div id='section'>Paperid: <span id='pid'>620, <a href='https://arxiv.org/pdf/2409.03021.pdf' target='_blank'>https://arxiv.org/pdf/2409.03021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu-Hsiang Wang, Andrew Bai, Che-Ping Tsai, Cho-Jui Hsieh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03021">CLUE: Concept-Level Uncertainty Estimation for Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have demonstrated remarkable proficiency in various natural language generation (NLG) tasks. Previous studies suggest that LLMs' generation process involves uncertainty. However, existing approaches to uncertainty estimation mainly focus on sequence-level uncertainty, overlooking individual pieces of information within sequences. These methods fall short in separately assessing the uncertainty of each component in a sequence. In response, we propose a novel framework for Concept-Level Uncertainty Estimation (CLUE) for LLMs. We leverage LLMs to convert output sequences into concept-level representations, breaking down sequences into individual concepts and measuring the uncertainty of each concept separately. We conduct experiments to demonstrate that CLUE can provide more interpretable uncertainty estimation results compared with sentence-level uncertainty, and could be a useful tool for various tasks such as hallucination detection and story generation.
<div id='section'>Paperid: <span id='pid'>621, <a href='https://arxiv.org/pdf/2409.01713.pdf' target='_blank'>https://arxiv.org/pdf/2409.01713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Patrick Knab, Sascha Marton, Christian Bartelt, Robert Fuder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01713">Interpreting Outliers in Time Series Data through Decoding Autoencoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection is a crucial analytical tool in various fields. In critical systems like manufacturing, malfunctioning outlier detection can be costly and safety-critical. Therefore, there is a significant need for explainable artificial intelligence (XAI) when deploying opaque models in such environments. This study focuses on manufacturing time series data from a German automotive supply industry. We utilize autoencoders to compress the entire time series and then apply anomaly detection techniques to its latent features. For outlier interpretation, we (i) adopt widely used XAI techniques to the autoencoder's encoder. Additionally, (ii) we propose AEE, Aggregated Explanatory Ensemble, a novel approach that fuses explanations of multiple XAI techniques into a single, more expressive interpretation. For evaluation of explanations, (iii) we propose a technique to measure the quality of encoder explanations quantitatively. Furthermore, we qualitatively assess the effectiveness of outlier explanations with domain expertise.
<div id='section'>Paperid: <span id='pid'>622, <a href='https://arxiv.org/pdf/2407.01623.pdf' target='_blank'>https://arxiv.org/pdf/2407.01623.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgia Papacharalampous, Hristos Tyralis, Nikolaos Doulamis, Anastasios Doulamis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01623">Combinations of distributional regression algorithms with application in uncertainty estimation of corrected satellite precipitation products</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To facilitate effective decision-making, precipitation datasets should include uncertainty estimates. Quantile regression with machine learning has been proposed for issuing such estimates. Distributional regression offers distinct advantages over quantile regression, including the ability to model intermittency as well as a stronger ability to extrapolate beyond the training data, which is critical for predicting extreme precipitation. Therefore, here, we introduce the concept of distributional regression in precipitation dataset creation, specifically for the spatial prediction task of correcting satellite precipitation products. Building upon this concept, we formulated new ensemble learning methods that can be valuable not only for spatial prediction but also for other prediction problems. These methods exploit conditional zero-adjusted probability distributions estimated with generalized additive models for location, scale and shape (GAMLSS), spline-based GAMLSS and distributional regression forests as well as their ensembles (stacking based on quantile regression and equal-weight averaging). To identify the most effective methods for our specific problem, we compared them to benchmarks using a large, multi-source precipitation dataset. Stacking was shown to be superior to individual methods at most quantile levels when evaluated with the quantile loss function. Moreover, while the relative ranking of the methods varied across different quantile levels, stacking methods, and to a lesser extent mean combiners, exhibited lower variance in their performance across different quantiles compared to individual methods that occasionally ranked extremely low. Overall, a task-specific combination of multiple distributional regression algorithms could yield significant benefits in terms of stability.
<div id='section'>Paperid: <span id='pid'>623, <a href='https://arxiv.org/pdf/2406.18902.pdf' target='_blank'>https://arxiv.org/pdf/2406.18902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomohiro Shiraishi, Tatsuya Matsukawa, Shuichi Nishino, Ichiro Takeuchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18902">Statistical Test for Feature Selection Pipelines by Selective Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A data analysis pipeline is a structured sequence of steps that transforms raw data into meaningful insights by integrating various analysis algorithms. In this paper, we propose a novel statistical test to assess the significance of data analysis pipelines in feature selection problems. Our approach enables the systematic development of valid statistical tests applicable to any feature selection pipeline composed of predefined components. We develop this framework based on selective inference, a statistical technique that has recently gained attention for data-driven hypotheses. As a proof of concept, we consider feature selection pipelines for linear models, composed of three missing value imputation algorithms, three outlier detection algorithms, and three feature selection algorithms. We theoretically prove that our statistical test can control the probability of false positive feature selection at any desired level, and demonstrate its validity and effectiveness through experiments on synthetic and real data. Additionally, we present an implementation framework that facilitates testing across any configuration of these feature selection pipelines without extra implementation costs.
<div id='section'>Paperid: <span id='pid'>624, <a href='https://arxiv.org/pdf/2405.13377.pdf' target='_blank'>https://arxiv.org/pdf/2405.13377.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mostafa Jamshidian, Adam Wittek, Saeideh Sekhavat, Karol Miller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13377">Kinematics of Abdominal Aortic Aneurysms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A search in Scopus within "Article title, Abstract, Keywords" unveils 2,444 documents focused on the biomechanics of Abdominal Aortic Aneurysm (AAA), mostly on AAA wall stress. Only 24 documents investigated AAA kinematics, an important topic that could potentially offer significant insights into the biomechanics of AAA. In this paper, we present an image-based approach for patient-specific, in vivo, and non-invasive AAA kinematic analysis using patient's time-resolved 3D computed tomography angiography (4D-CTA) images, with an objective to measure wall displacement and strain during the cardiac cycle. Our approach relies on regularized deformable image registration for estimating wall displacement, estimation of the local wall strain as the ratio of its normal displacement to its local radius of curvature, and local surface fitting with non-deterministic outlier detection for estimating the wall radius of curvature. We verified our approach against synthetic ground truth image data created by warping a 3D-CTA image of AAA using a realistic displacement field obtained from a finite element biomechanical model. We applied our approach to assess AAA wall displacements and strains in ten patients. Our kinematic analysis results indicated that the 99th percentile of circumferential wall strain, among all patients, ranged from 2.62% to 5.54%, with an average of 4.45% and a standard deviation of 0.87%. We also observed that AAA wall strains are significantly lower than those of a healthy aorta. Our work demonstrates that the registration-based measurement of AAA wall displacements in the direction normal to the wall is sufficiently accurate to reliably estimate strain from these displacements.
<div id='section'>Paperid: <span id='pid'>625, <a href='https://arxiv.org/pdf/2404.14933.pdf' target='_blank'>https://arxiv.org/pdf/2404.14933.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dayananda Herurkar, Sebastian Palacio, Ahmed Anwar, Joern Hees, Andreas Dengel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14933">Fin-Fed-OD: Federated Outlier Detection on Financial Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection in real-world scenarios poses challenges due to dynamic and often unknown anomaly distributions, requiring robust methods that operate under an open-world assumption. This challenge is exacerbated in practical settings, where models are employed by private organizations, precluding data sharing due to privacy and competitive concerns. Despite potential benefits, the sharing of anomaly information across organizations is restricted. This paper addresses the question of enhancing outlier detection within individual organizations without compromising data confidentiality. We propose a novel method leveraging representation learning and federated learning techniques to improve the detection of unknown anomalies. Specifically, our approach utilizes latent representations obtained from client-owned autoencoders to refine the decision boundary of inliers. Notably, only model parameters are shared between organizations, preserving data privacy. The efficacy of our proposed method is evaluated on two standard financial tabular datasets and an image dataset for anomaly detection in a distributed setting. The results demonstrate a strong improvement in the classification of unknown outliers during the inference phase for each organization's model.
<div id='section'>Paperid: <span id='pid'>626, <a href='https://arxiv.org/pdf/2404.08195.pdf' target='_blank'>https://arxiv.org/pdf/2404.08195.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Yang, Yucong Meng, Kexue Fu, Shuo Wang, Zhijian Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08195">Tackling Ambiguity from Perspective of Uncertainty Inference and Affinity Diversification for Weakly Supervised Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Weakly supervised semantic segmentation (WSSS) with image-level labels intends to achieve dense tasks without laborious annotations. However, due to the ambiguous contexts and fuzzy regions, the performance of WSSS, especially the stages of generating Class Activation Maps (CAMs) and refining pseudo masks, widely suffers from ambiguity while being barely noticed by previous literature. In this work, we propose UniA, a unified single-staged WSSS framework, to efficiently tackle this issue from the perspective of uncertainty inference and affinity diversification, respectively. When activating class objects, we argue that the false activation stems from the bias to the ambiguous regions during the feature extraction. Therefore, we design a more robust feature representation with a probabilistic Gaussian distribution and introduce the uncertainty estimation to avoid the bias. A distribution loss is particularly proposed to supervise the process, which effectively captures the ambiguity and models the complex dependencies among features. When refining pseudo labels, we observe that the affinity from the prevailing refinement methods intends to be similar among ambiguities. To this end, an affinity diversification module is proposed to promote diversity among semantics. A mutual complementing refinement is proposed to initially rectify the ambiguous affinity with multiple inferred pseudo labels. More importantly, a contrastive affinity loss is further designed to diversify the relations among unrelated semantics, which reliably propagates the diversity into the whole feature representations and helps generate better pseudo masks. Extensive experiments are conducted on PASCAL VOC, MS COCO, and medical ACDC datasets, which validate the efficiency of UniA tackling ambiguity and the superiority over recent single-staged or even most multi-staged competitors.
<div id='section'>Paperid: <span id='pid'>627, <a href='https://arxiv.org/pdf/2403.16732.pdf' target='_blank'>https://arxiv.org/pdf/2403.16732.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Durasov, Doruk Oner, Jonathan Donier, Hieu Le, Pascal Fua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.16732">Enabling Uncertainty Estimation in Iterative Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Turning pass-through network architectures into iterative ones, which use their own output as input, is a well-known approach for boosting performance. In this paper, we argue that such architectures offer an additional benefit: The convergence rate of their successive outputs is highly correlated with the accuracy of the value to which they converge. Thus, we can use the convergence rate as a useful proxy for uncertainty. This results in an approach to uncertainty estimation that provides state-of-the-art estimates at a much lower computational cost than techniques like Ensembles, and without requiring any modifications to the original iterative model. We demonstrate its practical value by embedding it in two application domains: road detection in aerial images and the estimation of aerodynamic properties of 2D and 3D shapes.
<div id='section'>Paperid: <span id='pid'>628, <a href='https://arxiv.org/pdf/2403.11233.pdf' target='_blank'>https://arxiv.org/pdf/2403.11233.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liren Jin, Haofei Kuang, Yue Pan, Cyrill Stachniss, Marija PopoviÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11233">STAIR: Semantic-Targeted Active Implicit Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many autonomous robotic applications require object-level understanding when deployed. Actively reconstructing objects of interest, i.e. objects with specific semantic meanings, is therefore relevant for a robot to perform downstream tasks in an initially unknown environment. In this work, we propose a novel framework for semantic-targeted active reconstruction using posed RGB-D measurements and 2D semantic labels as input. The key components of our framework are a semantic implicit neural representation and a compatible planning utility function based on semantic rendering and uncertainty estimation, enabling adaptive view planning to target objects of interest. Our planning approach achieves better reconstruction performance in terms of mesh and novel view rendering quality compared to implicit reconstruction baselines that do not consider semantics for view planning. Our framework further outperforms a state-of-the-art semantic-targeted active reconstruction pipeline based on explicit maps, justifying our choice of utilising implicit neural representations to tackle semantic-targeted active reconstruction problems.
<div id='section'>Paperid: <span id='pid'>629, <a href='https://arxiv.org/pdf/2403.10567.pdf' target='_blank'>https://arxiv.org/pdf/2403.10567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgia Papacharalampous, Hristos Tyralis, Nikolaos Doulamis, Anastasios Doulamis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10567">Ensemble learning for uncertainty estimation with application to the correction of satellite precipitation products</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictions in the form of probability distributions are crucial for effective decision-making. Quantile regression enables such predictions within spatial prediction settings that aim to create improved precipitation datasets by merging remote sensing and gauge data. However, ensemble learning of quantile regression algorithms remains unexplored in this context and, at the same time, it has not been substantially developed so far in the broader machine learning research landscape. Here, we introduce nine quantile-based ensemble learners and address the aforementioned gap in precipitation dataset creation by presenting the first application of these learners to large precipitation datasets. We employed a novel feature engineering strategy, which reduces the number of predictors by using distance-weighted satellite precipitation at relevant locations, combined with location elevation. Our ensemble learners include six that are based on stacking ideas and three simple methods (mean, median, best combiner). Each of them combines the following six individual algorithms: quantile regression (QR), quantile regression forests (QRF), generalized random forests (GRF), gradient boosting machines (GBM), light gradient boosting machines (LightGBM), and quantile regression neural networks (QRNN). These algorithms serve as both base learners and combiners within different ensemble learning methods. We evaluated performance against a reference method (i.e., QR) using quantile scoring functions and a large dataset. The latter comprises 15 years of monthly gauge-measured and satellite precipitation in the contiguous United States (CONUS). Ensemble learning with QR and QRNN yielded the best results across the various investigated quantile levels, which range from 0.025 to 0.975, outperforming the reference method by 3.91% to 8.95%...
<div id='section'>Paperid: <span id='pid'>630, <a href='https://arxiv.org/pdf/2402.11406.pdf' target='_blank'>https://arxiv.org/pdf/2402.11406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Min Zhang, Jianfeng He, Taoran Ji, Chang-Tien Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11406">Don't Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The fairness and trustworthiness of Large Language Models (LLMs) are receiving increasing attention. Implicit hate speech, which employs indirect language to convey hateful intentions, occupies a significant portion of practice. However, the extent to which LLMs effectively address this issue remains insufficiently examined. This paper delves into the capability of LLMs to detect implicit hate speech (Classification Task) and express confidence in their responses (Calibration Task). Our evaluation meticulously considers various prompt patterns and mainstream uncertainty estimation methods. Our findings highlight that LLMs exhibit two extremes: (1) LLMs display excessive sensitivity towards groups or topics that may cause fairness issues, resulting in misclassifying benign statements as hate speech. (2) LLMs' confidence scores for each method excessively concentrate on a fixed range, remaining unchanged regardless of the dataset's complexity. Consequently, the calibration performance is heavily reliant on primary classification accuracy. These discoveries unveil new limitations of LLMs, underscoring the need for caution when optimizing models to ensure they do not veer towards extremes. This serves as a reminder to carefully consider sensitivity and confidence in the pursuit of model fairness.
<div id='section'>Paperid: <span id='pid'>631, <a href='https://arxiv.org/pdf/2402.02949.pdf' target='_blank'>https://arxiv.org/pdf/2402.02949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Fang, Qinghua Tao, Kexin Lv, Mingzhen He, Xiaolin Huang, Jie Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.02949">Kernel PCA for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper non-linear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, and seek suitable non-linear kernels that advocate the separability between InD and OoD data in the subspace spanned by the principal components. Besides, explicit feature mappings induced from the devoted task-specific kernels are adopted so that the KPCA reconstruction error for new test samples can be efficiently obtained with large-scale data. Extensive theoretical and empirical results on multiple OoD data sets and network structures verify the superiority of our KPCA detector in efficiency and efficacy with state-of-the-art detection performance.
<div id='section'>Paperid: <span id='pid'>632, <a href='https://arxiv.org/pdf/2311.07511.pdf' target='_blank'>https://arxiv.org/pdf/2311.07511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgia Papacharalampous, Hristos Tyralis, Nikolaos Doulamis, Anastasios Doulamis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.07511">Uncertainty estimation of machine learning spatial precipitation predictions from satellite data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Merging satellite and gauge data with machine learning produces high-resolution precipitation datasets, but uncertainty estimates are often missing. We addressed the gap of how to optimally provide such estimates by benchmarking six algorithms, mostly novel even for the more general task of quantifying predictive uncertainty in spatial prediction settings. On 15 years of monthly data from over the contiguous United States (CONUS), we compared quantile regression (QR), quantile regression forests (QRF), generalized random forests (GRF), gradient boosting machines (GBM), light gradient boosting machine (LightGBM), and quantile regression neural networks (QRNN). Their ability to issue predictive precipitation quantiles at nine quantile levels (0.025, 0.050, 0.100, 0.250, 0.500, 0.750, 0.900, 0.950, 0.975), approximating the full probability distribution, was evaluated using quantile scoring functions and the quantile scoring rule. Predictors at a site were nearby values from two satellite precipitation retrievals, namely PERSIANN (Precipitation Estimation from Remotely Sensed Information using Artificial Neural Networks) and IMERG (Integrated Multi-satellitE Retrievals), and the site's elevation. The dependent variable was the monthly mean gauge precipitation. With respect to QR, LightGBM showed improved performance in terms of the quantile scoring rule by 11.10%, also surpassing QRF (7.96%), GRF (7.44%), GBM (4.64%) and QRNN (1.73%). Notably, LightGBM outperformed all random forest variants, the current standard in spatial prediction with machine learning. To conclude, we propose a suite of machine learning algorithms for estimating uncertainty in spatial data prediction, supported with a formal evaluation framework based on scoring functions and scoring rules.
<div id='section'>Paperid: <span id='pid'>633, <a href='https://arxiv.org/pdf/2311.07383.pdf' target='_blank'>https://arxiv.org/pdf/2311.07383.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ekaterina Fadeeva, Roman Vashurin, Akim Tsvigun, Artem Vazhentsev, Sergey Petrakov, Kirill Fedyanin, Daniil Vasilev, Elizaveta Goncharova, Alexander Panchenko, Maxim Panov, Timothy Baldwin, Artem Shelmanov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.07383">LM-Polygraph: Uncertainty Estimation for Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in the capabilities of large language models (LLMs) have paved the way for a myriad of groundbreaking applications in various fields. However, a significant challenge arises as these models often "hallucinate", i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements. Uncertainty estimation (UE) methods are one path to safer, more responsible, and more effective use of LLMs. However, to date, research on UE methods for LLMs has been focused primarily on theoretical rather than engineering contributions. In this work, we tackle this issue by introducing LM-Polygraph, a framework with implementations of a battery of state-of-the-art UE methods for LLMs in text generation tasks, with unified program interfaces in Python. Additionally, it introduces an extendable benchmark for consistent evaluation of UE techniques by researchers, and a demo web application that enriches the standard chat dialog with confidence scores, empowering end-users to discern unreliable responses. LM-Polygraph is compatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and GPT-4, and is designed to support future releases of similarly-styled LMs.
<div id='section'>Paperid: <span id='pid'>634, <a href='https://arxiv.org/pdf/2310.14227.pdf' target='_blank'>https://arxiv.org/pdf/2310.14227.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Fang, Qinghua Tao, Xiaolin Huang, Jie Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14227">Revisiting Deep Ensemble for Out-of-Distribution Detection: A Loss Landscape Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing Out-of-Distribution (OoD) detection methods address to detect OoD samples from In-Distribution (InD) data mainly by exploring differences in features, logits and gradients in Deep Neural Networks (DNNs). We in this work propose a new perspective upon loss landscape and mode ensemble to investigate OoD detection. In the optimization of DNNs, there exist many local optima in the parameter space, or namely modes. Interestingly, we observe that these independent modes, which all reach low-loss regions with InD data (training and test data), yet yield significantly different loss landscapes with OoD data. Such an observation provides a novel view to investigate the OoD detection from the loss landscape, and further suggests significantly fluctuating OoD detection performance across these modes. For instance, FPR values of the RankFeat method can range from 46.58% to 84.70% among 5 modes, showing uncertain detection performance evaluations across independent modes. Motivated by such diversities on OoD loss landscape across modes, we revisit the deep ensemble method for OoD detection through mode ensemble, leading to improved performance and benefiting the OoD detector with reduced variances. Extensive experiments covering varied OoD detectors and network structures illustrate high variances across modes and validate the superiority of mode ensemble in boosting OoD detection. We hope this work could attract attention in the view of independent modes in the loss landscape of OoD data and more reliable evaluations on OoD detectors.
<div id='section'>Paperid: <span id='pid'>635, <a href='https://arxiv.org/pdf/2308.12679.pdf' target='_blank'>https://arxiv.org/pdf/2308.12679.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ario Sadafi, Raheleh Salehi, Armin Gruber, Sayedali Shetab Boushehri, Pascal Giehr, Nassir Navab, Carsten Marr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12679">A Continual Learning Approach for Cross-Domain White Blood Cell Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate classification of white blood cells in peripheral blood is essential for diagnosing hematological diseases. Due to constantly evolving clinical settings, data sources, and disease classifications, it is necessary to update machine learning classification models regularly for practical real-world use. Such models significantly benefit from sequentially learning from incoming data streams without forgetting previously acquired knowledge. However, models can suffer from catastrophic forgetting, causing a drop in performance on previous tasks when fine-tuned on new data. Here, we propose a rehearsal-based continual learning approach for class incremental and domain incremental scenarios in white blood cell classification. To choose representative samples from previous tasks, we employ exemplar set selection based on the model's predictions. This involves selecting the most confident samples and the most challenging samples identified through uncertainty estimation of the model. We thoroughly evaluated our proposed approach on three white blood cell classification datasets that differ in color, resolution, and class composition, including scenarios where new domains or new classes are introduced to the model with every task. We also test a long class incremental experiment with both new domains and new classes. Our results demonstrate that our approach outperforms established baselines in continual learning, including existing iCaRL and EWC methods for classifying white blood cells in cross-domain environments.
<div id='section'>Paperid: <span id='pid'>636, <a href='https://arxiv.org/pdf/2308.06882.pdf' target='_blank'>https://arxiv.org/pdf/2308.06882.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dhruv Desai, Ashmita Dhiman, Tushar Sharma, Deepika Sharma, Dhagash Mehta, Stefano Pasquali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06882">Quantifying Outlierness of Funds from their Categories using Supervised Similarity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mutual fund categorization has become a standard tool for the investment management industry and is extensively used by allocators for portfolio construction and manager selection, as well as by fund managers for peer analysis and competitive positioning. As a result, a (unintended) miscategorization or lack of precision can significantly impact allocation decisions and investment fund managers. Here, we aim to quantify the effect of miscategorization of funds utilizing a machine learning based approach. We formulate the problem of miscategorization of funds as a distance-based outlier detection problem, where the outliers are the data-points that are far from the rest of the data-points in the given feature space. We implement and employ a Random Forest (RF) based method of distance metric learning, and compute the so-called class-wise outlier measures for each data-point to identify outliers in the data. We test our implementation on various publicly available data sets, and then apply it to mutual fund data. We show that there is a strong relationship between the outlier measures of the funds and their future returns and discuss the implications of our findings.
<div id='section'>Paperid: <span id='pid'>637, <a href='https://arxiv.org/pdf/2308.00231.pdf' target='_blank'>https://arxiv.org/pdf/2308.00231.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sadhana Lolla, Iaroslav Elistratov, Alejandro Perez, Elaheh Ahmadi, Daniela Rus, Alexander Amini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.00231">Capsa: A Unified Framework for Quantifying Risk in Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The modern pervasiveness of large-scale deep neural networks (NNs) is driven by their extraordinary performance on complex problems but is also plagued by their sudden, unexpected, and often catastrophic failures, particularly on challenging scenarios. Existing algorithms that provide risk-awareness to NNs are complex and ad-hoc. Specifically, these methods require significant engineering changes, are often developed only for particular settings, and are not easily composable. Here we present capsa, a framework for extending models with risk-awareness. Capsa provides a methodology for quantifying multiple forms of risk and composing different algorithms together to quantify different risk metrics in parallel. We validate capsa by implementing state-of-the-art uncertainty estimation algorithms within the capsa framework and benchmarking them on complex perception datasets. We demonstrate capsa's ability to easily compose aleatoric uncertainty, epistemic uncertainty, and bias estimation together in a single procedure, and show how this approach provides a comprehensive awareness of NN risk.
<div id='section'>Paperid: <span id='pid'>638, <a href='https://arxiv.org/pdf/2306.09269.pdf' target='_blank'>https://arxiv.org/pdf/2306.09269.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew Baugh, James Batten, Johanna P. MÃ¼ller, Bernhard Kainz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09269">Zero-Shot Anomaly Detection with Pre-trained Segmentation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This technical report outlines our submission to the zero-shot track of the Visual Anomaly and Novelty Detection (VAND) 2023 Challenge. Building on the performance of the WINCLIP framework, we aim to enhance the system's localization capabilities by integrating zero-shot segmentation models. In addition, we perform foreground instance segmentation which enables the model to focus on the relevant parts of the image, thus allowing the models to better identify small or subtle deviations. Our pipeline requires no external data or information, allowing for it to be directly applied to new datasets. Our team (Variance Vigilance Vanguard) ranked third in the zero-shot track of the VAND challenge, and achieve an average F1-max score of 81.5/24.2 at a sample/pixel level on the VisA dataset.
<div id='section'>Paperid: <span id='pid'>639, <a href='https://arxiv.org/pdf/2306.07485.pdf' target='_blank'>https://arxiv.org/pdf/2306.07485.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Jiang, Jiayu Qin, Lingyu Wu, Changyou Chen, Tianbao Yang, Lijun Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.07485">Learning Unnormalized Statistical Models via Compositional Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning unnormalized statistical models (e.g., energy-based models) is computationally challenging due to the complexity of handling the partition function. To eschew this complexity, noise-contrastive estimation~(NCE) has been proposed by formulating the objective as the logistic loss of the real data and the artificial noise. However, as found in previous works, NCE may perform poorly in many tasks due to its flat loss landscape and slow convergence. In this paper, we study it a direct approach for optimizing the negative log-likelihood of unnormalized models from the perspective of compositional optimization. To tackle the partition function, a noise distribution is introduced such that the log partition function can be written as a compositional function whose inner function can be estimated with stochastic samples. Hence, the objective can be optimized by stochastic compositional optimization algorithms. Despite being a simple method, we demonstrate that it is more favorable than NCE by (1) establishing a fast convergence rate and quantifying its dependence on the noise distribution through the variance of stochastic estimators; (2) developing better results for one-dimensional Gaussian mean estimation by showing our objective has a much favorable loss landscape and hence our method enjoys faster convergence; (3) demonstrating better performance on multiple applications, including density estimation, out-of-distribution detection, and real image generation.
<div id='section'>Paperid: <span id='pid'>640, <a href='https://arxiv.org/pdf/2305.12852.pdf' target='_blank'>https://arxiv.org/pdf/2305.12852.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luzhe Huang, Jianing Li, Xiaofu Ding, Yijie Zhang, Hanlong Chen, Aydogan Ozcan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.12852">Cycle Consistency-based Uncertainty Quantification of Neural Networks in Inverse Imaging Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is critical for numerous applications of deep neural networks and draws growing attention from researchers. Here, we demonstrate an uncertainty quantification approach for deep neural networks used in inverse problems based on cycle consistency. We build forward-backward cycles using the physical forward model available and a trained deep neural network solving the inverse problem at hand, and accordingly derive uncertainty estimators through regression analysis on the consistency of these forward-backward cycles. We theoretically analyze cycle consistency metrics and derive their relationship with respect to uncertainty, bias, and robustness of the neural network inference. To demonstrate the effectiveness of these cycle consistency-based uncertainty estimators, we classified corrupted and out-of-distribution input image data using some of the widely used image deblurring and super-resolution neural networks as testbeds. The blind testing of our method outperformed other models in identifying unseen input data corruption and distribution shifts. This work provides a simple-to-implement and rapid uncertainty quantification method that can be universally applied to various neural networks used for solving inverse problems.
<div id='section'>Paperid: <span id='pid'>641, <a href='https://arxiv.org/pdf/2304.07967.pdf' target='_blank'>https://arxiv.org/pdf/2304.07967.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zidong Cao, Hao Ai, Athanasios V. Vasilakos, Lin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.07967">360$^\circ$ High-Resolution Depth Estimation via Uncertainty-aware Structural Knowledge Transfer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To predict high-resolution (HR) omnidirectional depth map, existing methods typically leverage HR omnidirectional image (ODI) as the input via fully-supervised learning. However, in practice, taking HR ODI as input is undesired due to resource-constrained devices. In addition, depth maps are often with lower resolution than color images. Therefore, in this paper, we explore for the first time to estimate the HR omnidirectional depth directly from a low-resolution (LR) ODI, when no HR depth GT map is available. Our key idea is to transfer the scene structural knowledge from the HR image modality and the corresponding LR depth maps to achieve the goal of HR depth estimation without any extra inference cost. Specifically, we introduce ODI super-resolution (SR) as an auxiliary task and train both tasks collaboratively in a weakly supervised manner to boost the performance of HR depth estimation. The ODI SR task extracts the scene structural knowledge via uncertainty estimation. Buttressed by this, a scene structural knowledge transfer (SSKT) module is proposed with two key components. First, we employ a cylindrical implicit interpolation function (CIIF) to learn cylindrical neural interpolation weights for feature up-sampling and share the parameters of CIIFs between the two tasks. Then, we propose a feature distillation (FD) loss that provides extra structural regularization to help the HR depth estimation task learn more scene structural knowledge. Extensive experiments demonstrate that our weakly-supervised method outperforms baseline methods, and even achieves comparable performance with the fully-supervised methods.
<div id='section'>Paperid: <span id='pid'>642, <a href='https://arxiv.org/pdf/2301.03252.pdf' target='_blank'>https://arxiv.org/pdf/2301.03252.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akim Tsvigun, Ivan Lysenko, Danila Sedashov, Ivan Lazichny, Eldar Damirov, Vladimir Karlov, Artemy Belousov, Leonid Sanochkin, Maxim Panov, Alexander Panchenko, Mikhail Burtsev, Artem Shelmanov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.03252">Active Learning for Abstractive Text Summarization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Construction of human-curated annotated datasets for abstractive text summarization (ATS) is very time-consuming and expensive because creating each instance requires a human annotator to read a long document and compose a shorter summary that would preserve the key information relayed by the original document. Active Learning (AL) is a technique developed to reduce the amount of annotation required to achieve a certain level of machine learning model performance. In information extraction and text classification, AL can reduce the amount of labor up to multiple times. Despite its potential for aiding expensive annotation, as far as we know, there were no effective AL query strategies for ATS. This stems from the fact that many AL strategies rely on uncertainty estimation, while as we show in our work, uncertain instances are usually noisy, and selecting them can degrade the model performance compared to passive annotation. We address this problem by proposing the first effective query strategy for AL in ATS based on diversity principles. We show that given a certain annotation budget, using our strategy in AL annotation helps to improve the model performance in terms of ROUGE and consistency scores. Additionally, we analyze the effect of self-learning and show that it can further increase the performance of the model.
<div id='section'>Paperid: <span id='pid'>643, <a href='https://arxiv.org/pdf/2211.11435.pdf' target='_blank'>https://arxiv.org/pdf/2211.11435.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Durasov, Nik Dorndorf, Hieu Le, Pascal Fua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.11435">ZigZag: Universal Sampling-free Uncertainty Estimation Through Two-Step Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Whereas the ability of deep networks to produce useful predictions has been amply demonstrated, estimating the reliability of these predictions remains challenging. Sampling approaches such as MC-Dropout and Deep Ensembles have emerged as the most popular ones for this purpose. Unfortunately, they require many forward passes at inference time, which slows them down. Sampling-free approaches can be faster but suffer from other drawbacks, such as lower reliability of uncertainty estimates, difficulty of use, and limited applicability to different types of tasks and data.
  In this work, we introduce a sampling-free approach that is generic and easy to deploy, while producing reliable uncertainty estimates on par with state-of-the-art methods at a significantly lower computational cost. It is predicated on training the network to produce the same output with and without additional information about it. At inference time, when no prior information is given, we use the network's own prediction as the additional information. We then take the distance between the predictions with and without prior information as our uncertainty measure.
  We demonstrate our approach on several classification and regression tasks. We show that it delivers results on par with those of Ensembles but at a much lower computational cost.
<div id='section'>Paperid: <span id='pid'>644, <a href='https://arxiv.org/pdf/2209.08307.pdf' target='_blank'>https://arxiv.org/pdf/2209.08307.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hristos Tyralis, Georgia Papacharalampous
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.08307">A review of predictive uncertainty estimation with machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictions and forecasts of machine learning models should take the form of probability distributions, aiming to increase the quantity of information communicated to end users. Although applications of probabilistic prediction and forecasting with machine learning models in academia and industry are becoming more frequent, related concepts and methods have not been formalized and structured under a holistic view of the entire field. Here, we review the topic of predictive uncertainty estimation with machine learning algorithms, as well as the related metrics (consistent scoring functions and proper scoring rules) for assessing probabilistic predictions. The review covers a time period spanning from the introduction of early statistical (linear regression and time series models, based on Bayesian statistics or quantile regression) to recent machine learning algorithms (including generalized additive models for location, scale and shape, random forests, boosting and deep learning algorithms) that are more flexible by nature. The review of the progress in the field, expedites our understanding on how to develop new algorithms tailored to users' needs, since the latest advancements are based on some fundamental concepts applied to more complex algorithms. We conclude by classifying the material and discussing challenges that are becoming a hot topic of research.
<div id='section'>Paperid: <span id='pid'>645, <a href='https://arxiv.org/pdf/2110.05649.pdf' target='_blank'>https://arxiv.org/pdf/2110.05649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>HanQin Cai, Jialin Liu, Wotao Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.05649">Learned Robust PCA: A Scalable Deep Unfolding Approach for High-Dimensional Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robust principal component analysis (RPCA) is a critical tool in modern machine learning, which detects outliers in the task of low-rank matrix reconstruction. In this paper, we propose a scalable and learnable non-convex approach for high-dimensional RPCA problems, which we call Learned Robust PCA (LRPCA). LRPCA is highly efficient, and its free parameters can be effectively learned to optimize via deep unfolding. Moreover, we extend deep unfolding from finite iterations to infinite iterations via a novel feedforward-recurrent-mixed neural network model. We establish the recovery guarantee of LRPCA under mild assumptions for RPCA. Numerical experiments show that LRPCA outperforms the state-of-the-art RPCA algorithms, such as ScaledGD and AltProj, on both synthetic datasets and real-world applications.
<div id='section'>Paperid: <span id='pid'>646, <a href='https://arxiv.org/pdf/2509.25459.pdf' target='_blank'>https://arxiv.org/pdf/2509.25459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haozhou Xu, Dongxia Wu, Matteo Chinazzi, Ruijia Niu, Rose Yu, Yi-An Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25459">SimulRAG: Simulator-based RAG for Grounding LLMs in Long-form Scientific QA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) show promise in solving scientific problems. They can help generate long-form answers for scientific questions, which are crucial for comprehensive understanding of complex phenomena that require detailed explanations spanning multiple interconnected concepts and evidence. However, LLMs often suffer from hallucination, especially in the challenging task of long-form scientific question answering. Retrieval-Augmented Generation (RAG) approaches can ground LLMs by incorporating external knowledge sources to improve trustworthiness. In this context, scientific simulators, which play a vital role in validating hypotheses, offer a particularly promising retrieval source to mitigate hallucination and enhance answer factuality. However, existing RAG approaches cannot be directly applied for scientific simulation-based retrieval due to two fundamental challenges: how to retrieve from scientific simulators, and how to efficiently verify and update long-form answers. To overcome these challenges, we propose the simulator-based RAG framework (SimulRAG) and provide a long-form scientific QA benchmark covering climate science and epidemiology with ground truth verified by both simulations and human annotators. In this framework, we propose a generalized simulator retrieval interface to transform between textual and numerical modalities. We further design a claim-level generation method that utilizes uncertainty estimation scores and simulator boundary assessment (UE+SBA) to efficiently verify and update claims. Extensive experiments demonstrate SimulRAG outperforms traditional RAG baselines by 30.4% in informativeness and 16.3% in factuality. UE+SBA further improves efficiency and quality for claim-level generation.
<div id='section'>Paperid: <span id='pid'>647, <a href='https://arxiv.org/pdf/2508.18630.pdf' target='_blank'>https://arxiv.org/pdf/2508.18630.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weide Liu, Xiaoyang Zhong, Lu Wang, Jingwen Hou, Yuemei Luo, Jiebin Yan, Yuming Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18630">Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised domain adaptation methods seek to generalize effectively on unlabeled test data, especially when encountering the common challenge in time series data that distribution shifts occur between training and testing datasets. In this paper, we propose incorporating multi-scale feature extraction and uncertainty estimation to improve the model's generalization and robustness across domains. Our approach begins with a multi-scale mixed input architecture that captures features at different scales, increasing training diversity and reducing feature discrepancies between the training and testing domains. Based on the mixed input architecture, we further introduce an uncertainty awareness mechanism based on evidential learning by imposing a Dirichlet prior on the labels to facilitate both target prediction and uncertainty estimation. The uncertainty awareness mechanism enhances domain adaptation by aligning features with the same labels across different domains, which leads to significant performance improvements in the target domain. Additionally, our uncertainty-aware model demonstrates a much lower Expected Calibration Error (ECE), indicating better-calibrated prediction confidence. Our experimental results show that this combined approach of mixed input architecture with the uncertainty awareness mechanism achieves state-of-the-art performance across multiple benchmark datasets, underscoring its effectiveness in unsupervised domain adaptation for time series data.
<div id='section'>Paperid: <span id='pid'>648, <a href='https://arxiv.org/pdf/2507.14178.pdf' target='_blank'>https://arxiv.org/pdf/2507.14178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhang Liu, Yuefei Wu, Bin Shi, Bo Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14178">Feature Bank Enhancement for Distance-based Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical to ensuring the reliability of deep learning applications and has attracted significant attention in recent years. A rich body of literature has emerged to develop efficient score functions that assign high scores to in-distribution (ID) samples and low scores to OOD samples, thereby helping distinguish OOD samples. Among these methods, distance-based score functions are widely used because of their efficiency and ease of use. However, deep learning often leads to a biased distribution of data features, and extreme features are inevitable. These extreme features make the distance-based methods tend to assign too low scores to ID samples. This limits the OOD detection capabilities of such methods. To address this issue, we propose a simple yet effective method, Feature Bank Enhancement (FBE), that uses statistical characteristics from dataset to identify and constrain extreme features to the separation boundaries, therapy making the distance between samples inside and outside the distribution farther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10 respectively, and the results show that our method achieves state-of-the-art performance on both benchmark. Additionally, theoretical analysis and supplementary experiments are conducted to provide more insights into our method.
<div id='section'>Paperid: <span id='pid'>649, <a href='https://arxiv.org/pdf/2507.09209.pdf' target='_blank'>https://arxiv.org/pdf/2507.09209.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Liang, Di Wang, Zhicheng Jiao, Ronghan Li, Pengfei Yang, Quan Wang, Tat-Seng Chua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09209">Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid advancements in Vision Language Models (VLMs) have prompted the development of multi-modal medical assistant systems. Despite this progress, current models still have inherent probabilistic uncertainties, often producing erroneous or unverified responses-an issue with serious implications in medical applications. Existing methods aim to enhance the performance of Medical Vision Language Model (MedVLM) by adjusting model structure, fine-tuning with high-quality data, or through preference fine-tuning. However, these training-dependent strategies are costly and still lack sufficient alignment with clinical expertise. To address these issues, we propose an expert-in-the-loop framework named Expert-Controlled Classifier-Free Guidance (Expert-CFG) to align MedVLM with clinical expertise without additional training. This framework introduces an uncertainty estimation strategy to identify unreliable outputs. It then retrieves relevant references to assist experts in highlighting key terms and applies classifier-free guidance to refine the token embeddings of MedVLM, ensuring that the adjusted outputs are correct and align with expert highlights. Evaluations across three medical visual question answering benchmarks demonstrate that the proposed Expert-CFG, with 4.2B parameters and limited expert annotations, outperforms state-of-the-art models with 13B parameters. The results demonstrate the feasibility of deploying such a system in resource-limited settings for clinical use.
<div id='section'>Paperid: <span id='pid'>650, <a href='https://arxiv.org/pdf/2507.01831.pdf' target='_blank'>https://arxiv.org/pdf/2507.01831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yucen Lily Li, Daohan Lu, Polina Kirichenko, Shikai Qiu, Tim G. J. Rudner, C. Bayan Bruss, Andrew Gordon Wilson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01831">Out-of-Distribution Detection Methods Answer the Wrong Questions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To detect distribution shifts and improve model safety, many out-of-distribution (OOD) detection methods rely on the predictive uncertainty or features of supervised models trained on in-distribution data. In this paper, we critically re-examine this popular family of OOD detection procedures, and we argue that these methods are fundamentally answering the wrong questions for OOD detection. There is no simple fix to this misalignment, since a classifier trained only on in-distribution classes cannot be expected to identify OOD points; for instance, a cat-dog classifier may confidently misclassify an airplane if it contains features that distinguish cats from dogs, despite generally appearing nothing alike. We find that uncertainty-based methods incorrectly conflate high uncertainty with being OOD, while feature-based methods incorrectly conflate far feature-space distance with being OOD. We show how these pathologies manifest as irreducible errors in OOD detection and identify common settings where these methods are ineffective. Additionally, interventions to improve OOD detection such as feature-logit hybrid methods, scaling of model and data size, epistemic uncertainty representation, and outlier exposure also fail to address this fundamental misalignment in objectives. We additionally consider unsupervised density estimation and generative models for OOD detection, which we show have their own fundamental limitations.
<div id='section'>Paperid: <span id='pid'>651, <a href='https://arxiv.org/pdf/2506.08541.pdf' target='_blank'>https://arxiv.org/pdf/2506.08541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Yan, Brian Zhang, Yutong Zhang, Daniel Yang, Joshua White, Di Chen, Jiachao Liu, Langechuan Liu, Binnan Zhuang, Shaoshuai Shi, Renjie Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08541">TrajFlow: Multi-modal Motion Prediction via Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient and accurate motion prediction is crucial for ensuring safety and informed decision-making in autonomous driving, particularly under dynamic real-world conditions that necessitate multi-modal forecasts. We introduce TrajFlow, a novel flow matching-based motion prediction framework that addresses the scalability and efficiency challenges of existing generative trajectory prediction methods. Unlike conventional generative approaches that employ i.i.d. sampling and require multiple inference passes to capture diverse outcomes, TrajFlow predicts multiple plausible future trajectories in a single pass, significantly reducing computational overhead while maintaining coherence across predictions. Moreover, we propose a ranking loss based on the Plackett-Luce distribution to improve uncertainty estimation of predicted trajectories. Additionally, we design a self-conditioning training technique that reuses the model's own predictions to construct noisy inputs during a second forward pass, thereby improving generalization and accelerating inference. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across various key metrics, underscoring its effectiveness for safety-critical autonomous driving applications. The code and other details are available on the project website https://traj-flow.github.io/.
<div id='section'>Paperid: <span id='pid'>652, <a href='https://arxiv.org/pdf/2505.24615.pdf' target='_blank'>https://arxiv.org/pdf/2505.24615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Liu, Zonglin Yang, Soujanya Poria, Thanh-Son Nguyen, Erik Cambria
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.24615">Harnessing Large Language Models for Scientific Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In an era of exponential scientific growth, identifying novel research ideas is crucial and challenging in academia. Despite potential, the lack of an appropriate benchmark dataset hinders the research of novelty detection. More importantly, simply adopting existing NLP technologies, e.g., retrieving and then cross-checking, is not a one-size-fits-all solution due to the gap between textual similarity and idea conception. In this paper, we propose to harness large language models (LLMs) for scientific novelty detection (ND), associated with two new datasets in marketing and NLP domains. To construct the considerate datasets for ND, we propose to extract closure sets of papers based on their relationship, and then summarize their main ideas based on LLMs. To capture idea conception, we propose to train a lightweight retriever by distilling the idea-level knowledge from LLMs to align ideas with similar conception, enabling efficient and accurate idea retrieval for LLM novelty detection. Experiments show our method consistently outperforms others on the proposed benchmark datasets for idea retrieval and ND tasks. Codes and data are available at https://anonymous.4open.science/r/NoveltyDetection-10FB/.
<div id='section'>Paperid: <span id='pid'>653, <a href='https://arxiv.org/pdf/2505.23448.pdf' target='_blank'>https://arxiv.org/pdf/2505.23448.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pirzada Suhail, Rehna Afroz, Amit Sethi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23448">Network Inversion for Uncertainty-Aware Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection and uncertainty estimation (UE) are critical components for building safe machine learning systems, especially in real-world scenarios where unexpected inputs are inevitable. In this work, we propose a novel framework that combines network inversion with classifier training to simultaneously address both OOD detection and uncertainty estimation. For a standard n-class classification task, we extend the classifier to an (n+1)-class model by introducing a "garbage" class, initially populated with random gaussian noise to represent outlier inputs. After each training epoch, we use network inversion to reconstruct input images corresponding to all output classes that initially appear as noisy and incoherent and are therefore excluded to the garbage class for retraining the classifier. This cycle of training, inversion, and exclusion continues iteratively till the inverted samples begin to resemble the in-distribution data more closely, suggesting that the classifier has learned to carve out meaningful decision boundaries while sanitising the class manifolds by pushing OOD content into the garbage class. During inference, this training scheme enables the model to effectively detect and reject OOD samples by classifying them into the garbage class. Furthermore, the confidence scores associated with each prediction can be used to estimate uncertainty for both in-distribution and OOD inputs. Our approach is scalable, interpretable, and does not require access to external OOD datasets or post-hoc calibration techniques while providing a unified solution to the dual challenges of OOD detection and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>654, <a href='https://arxiv.org/pdf/2505.20236.pdf' target='_blank'>https://arxiv.org/pdf/2505.20236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weihao Xuan, Qingcheng Zeng, Heli Qi, Junjue Wang, Naoto Yokoya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20236">Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is essential for assessing the reliability and trustworthiness of modern AI systems. Among existing approaches, verbalized uncertainty, where models express their confidence through natural language, has emerged as a lightweight and interpretable solution in large language models (LLMs). However, its effectiveness in vision-language models (VLMs) remains insufficiently studied. In this work, we conduct a comprehensive evaluation of verbalized confidence in VLMs, spanning three model categories, four task domains, and three evaluation scenarios. Our results show that current VLMs often display notable miscalibration across diverse tasks and settings. Notably, visual reasoning models (i.e., thinking with images) consistently exhibit better calibration, suggesting that modality-specific reasoning is critical for reliable uncertainty estimation. To further address calibration challenges, we introduce Visual Confidence-Aware Prompting, a two-stage prompting strategy that improves confidence alignment in multimodal settings. Overall, our study highlights the inherent miscalibration in VLMs across modalities. More broadly, our findings underscore the fundamental importance of modality alignment and model faithfulness in advancing reliable multimodal systems.
<div id='section'>Paperid: <span id='pid'>655, <a href='https://arxiv.org/pdf/2505.11731.pdf' target='_blank'>https://arxiv.org/pdf/2505.11731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harshil Vejendla, Haizhou Shi, Yibin Wang, Tunyu Zhang, Huan Zhang, Hao Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11731">Efficient Uncertainty Estimation via Distillation of Bayesian Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in uncertainty estimation for Large Language Models (LLMs) during downstream adaptation have addressed key challenges of reliability and simplicity. However, existing Bayesian methods typically require multiple sampling iterations during inference, creating significant efficiency issues that limit practical deployment. In this paper, we investigate the possibility of eliminating the need for test-time sampling for LLM uncertainty estimation. Specifically, when given an off-the-shelf Bayesian LLM, we distill its aligned confidence into a non-Bayesian student LLM by minimizing the divergence between their predictive distributions. Unlike typical calibration methods, our distillation is carried out solely on the training dataset without the need of an additional validation dataset. This simple yet effective approach achieves N-times more efficient uncertainty estimation during testing, where N is the number of samples traditionally required by Bayesian LLMs. Our extensive experiments demonstrate that uncertainty estimation capabilities on training data can successfully generalize to unseen test data through our distillation technique, consistently producing results comparable to (or even better than) state-of-the-art Bayesian LLMs.
<div id='section'>Paperid: <span id='pid'>656, <a href='https://arxiv.org/pdf/2505.08604.pdf' target='_blank'>https://arxiv.org/pdf/2505.08604.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu-Jen Chen, Xueyang Li, Yiyu Shi, Tsung-Yi Ho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08604">Unsupervised Out-of-Distribution Detection in Medical Imaging Using Multi-Exit Class Activation Maps and Feature Masking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for ensuring the reliability of deep learning models in medical imaging applications. This work is motivated by the observation that class activation maps (CAMs) for in-distribution (ID) data typically emphasize regions that are highly relevant to the model's predictions, whereas OOD data often lacks such focused activations. By masking input images with inverted CAMs, the feature representations of ID data undergo more substantial changes compared to those of OOD data, offering a robust criterion for differentiation. In this paper, we introduce a novel unsupervised OOD detection framework, Multi-Exit Class Activation Map (MECAM), which leverages multi-exit CAMs and feature masking. By utilizing mult-exit networks that combine CAMs from varying resolutions and depths, our method captures both global and local feature representations, thereby enhancing the robustness of OOD detection. We evaluate MECAM on multiple ID datasets, including ISIC19 and PathMNIST, and test its performance against three medical OOD datasets, RSNA Pneumonia, COVID-19, and HeadCT, and one natural image OOD dataset, iSUN. Comprehensive comparisons with state-of-the-art OOD detection methods validate the effectiveness of our approach. Our findings emphasize the potential of multi-exit networks and feature masking for advancing unsupervised OOD detection in medical imaging, paving the way for more reliable and interpretable models in clinical practice.
<div id='section'>Paperid: <span id='pid'>657, <a href='https://arxiv.org/pdf/2504.19820.pdf' target='_blank'>https://arxiv.org/pdf/2504.19820.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yoonhyuk Choi, Jiho Choi, Taewook Ko, Chong-Kwon Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19820">Hierarchical Uncertainty-Aware Graph Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent research on graph neural networks (GNNs) has explored mechanisms for capturing local uncertainty and exploiting graph hierarchies to mitigate data sparsity and leverage structural properties. However, the synergistic integration of these two approaches remains underexplored. This work introduces a novel architecture, the Hierarchical Uncertainty-Aware Graph Neural Network (HU-GNN), which unifies multi-scale representation learning, principled uncertainty estimation, and self-supervised embedding diversity within a single end-to-end framework. Specifically, HU-GNN adaptively forms node clusters and estimates uncertainty at multiple structural scales from individual nodes to higher levels. These uncertainty estimates guide a robust message-passing mechanism and attention weighting, effectively mitigating noise and adversarial perturbations while preserving predictive accuracy on semi-supervised classification tasks. We also offer key theoretical contributions, including a probabilistic formulation, rigorous uncertainty-calibration guarantees, and formal robustness bounds. Extensive experiments on standard benchmarks demonstrate that our model achieves state-of-the-art robustness and interpretability.
<div id='section'>Paperid: <span id='pid'>658, <a href='https://arxiv.org/pdf/2504.11944.pdf' target='_blank'>https://arxiv.org/pdf/2504.11944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuyang Chen, Guojian Wang, Keyu Yan, Lin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11944">VIPO: Value Function Inconsistency Penalized Offline Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline reinforcement learning (RL) learns effective policies from pre-collected datasets, offering a practical solution for applications where online interactions are risky or costly. Model-based approaches are particularly advantageous for offline RL, owing to their data efficiency and generalizability. However, due to inherent model errors, model-based methods often artificially introduce conservatism guided by heuristic uncertainty estimation, which can be unreliable. In this paper, we introduce VIPO, a novel model-based offline RL algorithm that incorporates self-supervised feedback from value estimation to enhance model training. Specifically, the model is learned by additionally minimizing the inconsistency between the value learned directly from the offline data and the one estimated from the model. We perform comprehensive evaluations from multiple perspectives to show that VIPO can learn a highly accurate model efficiently and consistently outperform existing methods. It offers a general framework that can be readily integrated into existing model-based offline RL algorithms to systematically enhance model accuracy. As a result, VIPO achieves state-of-the-art performance on almost all tasks in both D4RL and NeoRL benchmarks.
<div id='section'>Paperid: <span id='pid'>659, <a href='https://arxiv.org/pdf/2504.11944.pdf' target='_blank'>https://arxiv.org/pdf/2504.11944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuyang Chen, Guojian Wang, Keyu Yan, Lin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11944">VIPO: Value Function Inconsistency Penalized Offline Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline reinforcement learning (RL) learns effective policies from pre-collected datasets, offering a practical solution for applications where online interactions are risky or costly. Model-based approaches are particularly advantageous for offline RL, owing to their data efficiency and generalizability. However, due to inherent model errors, model-based methods often artificially introduce conservatism guided by heuristic uncertainty estimation, which can be unreliable. In this paper, we introduce VIPO, a novel model-based offline RL algorithm that incorporates self-supervised feedback from value estimation to enhance model training. Specifically, the model is learned by additionally minimizing the inconsistency between the value learned directly from the offline data and the one estimated from the model. We perform comprehensive evaluations from multiple perspectives to show that VIPO can learn a highly accurate model efficiently and consistently outperform existing methods. In particular, it achieves state-of-the-art performance on almost all tasks in both D4RL and NeoRL benchmarks. Overall, VIPO offers a general framework that can be readily integrated into existing model-based offline RL algorithms to systematically enhance model accuracy.
<div id='section'>Paperid: <span id='pid'>660, <a href='https://arxiv.org/pdf/2503.22097.pdf' target='_blank'>https://arxiv.org/pdf/2503.22097.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoyan Xu, Zhengtao Yao, Yushun Dong, Ziyi Wang, Ryan A. Rossi, Mengyuan Li, Yue Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22097">Few-Shot Graph Out-of-Distribution Detection with LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing methods for graph out-of-distribution (OOD) detection typically depend on training graph neural network (GNN) classifiers using a substantial amount of labeled in-distribution (ID) data. However, acquiring high-quality labeled nodes in text-attributed graphs (TAGs) is challenging and costly due to their complex textual and structural characteristics. Large language models (LLMs), known for their powerful zero-shot capabilities in textual tasks, show promise but struggle to naturally capture the critical structural information inherent to TAGs, limiting their direct effectiveness.
  To address these challenges, we propose LLM-GOOD, a general framework that effectively combines the strengths of LLMs and GNNs to enhance data efficiency in graph OOD detection. Specifically, we first leverage LLMs' strong zero-shot capabilities to filter out likely OOD nodes, significantly reducing the human annotation burden. To minimize the usage and cost of the LLM, we employ it only to annotate a small subset of unlabeled nodes. We then train a lightweight GNN filter using these noisy labels, enabling efficient predictions of ID status for all other unlabeled nodes by leveraging both textual and structural information. After obtaining node embeddings from the GNN filter, we can apply informativeness-based methods to select the most valuable nodes for precise human annotation. Finally, we train the target ID classifier using these accurately annotated ID nodes. Extensive experiments on four real-world TAG datasets demonstrate that LLM-GOOD significantly reduces human annotation costs and outperforms state-of-the-art baselines in terms of both ID classification accuracy and OOD detection performance.
<div id='section'>Paperid: <span id='pid'>661, <a href='https://arxiv.org/pdf/2503.20187.pdf' target='_blank'>https://arxiv.org/pdf/2503.20187.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pirzada Suhail, Pravesh Khaparde, Amit Sethi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20187">Network Inversion for Generating Confidently Classified Counterfeits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In vision classification, generating inputs that elicit confident predictions is key to understanding model behavior and reliability, especially under adversarial or out-of-distribution (OOD) conditions. While traditional adversarial methods rely on perturbing existing inputs to fool a model, they are inherently input-dependent and often fail to ensure both high confidence and meaningful deviation from the training data. In this work, we extend network inversion techniques to generate Confidently Classified Counterfeits (CCCs), synthetic samples that are confidently classified by the model despite being significantly different from the training distribution and independent of any specific input. We alter inversion technique by replacing soft vector conditioning with one-hot class conditioning and introducing a Kullback-Leibler divergence loss between the one-hot label and the classifier's output distribution. CCCs offer a model-centric perspective on confidence, revealing that models can assign high confidence to entirely synthetic, out-of-distribution inputs. This challenges the core assumption behind many OOD detection techniques based on thresholding prediction confidence, which assume that high-confidence outputs imply in-distribution data, and highlights the need for more robust uncertainty estimation in safety-critical applications.
<div id='section'>Paperid: <span id='pid'>662, <a href='https://arxiv.org/pdf/2503.10468.pdf' target='_blank'>https://arxiv.org/pdf/2503.10468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifeng Yang, Lin Zhu, Zewen Sun, Hengyu Liu, Qinying Gu, Nanyang Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10468">OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection remains challenging for deep learning models, particularly when test-time OOD samples differ significantly from training outliers. We propose OODD, a novel test-time OOD detection method that dynamically maintains and updates an OOD dictionary without fine-tuning. Our approach leverages a priority queue-based dictionary that accumulates representative OOD features during testing, combined with an informative inlier sampling strategy for in-distribution (ID) samples. To ensure stable performance during early testing, we propose a dual OOD stabilization mechanism that leverages strategically generated outliers derived from ID data. To our best knowledge, extensive experiments on the OpenOOD benchmark demonstrate that OODD significantly outperforms existing methods, achieving a 26.0% improvement in FPR95 on CIFAR-100 Far OOD detection compared to the state-of-the-art approach. Furthermore, we present an optimized variant of the KNN-based OOD detection framework that achieves a 3x speedup while maintaining detection performance.
<div id='section'>Paperid: <span id='pid'>663, <a href='https://arxiv.org/pdf/2503.07330.pdf' target='_blank'>https://arxiv.org/pdf/2503.07330.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changshun Wu, Weicheng He, Chih-Hong Cheng, Xiaowei Huang, Saddek Bensalem
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07330">Revisiting Out-of-Distribution Detection in Real-time Object Detection: From Benchmark Pitfalls to a New Mitigation Paradigm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OoD) inputs pose a persistent challenge to deep learning models, often triggering overconfident predictions on non-target objects. While prior work has primarily focused on refining scoring functions and adjusting test-time thresholds, such algorithmic improvements offer only incremental gains. We argue that a rethinking of the entire development lifecycle is needed to mitigate these risks effectively. This work addresses two overlooked dimensions of OoD detection in object detection. First, we reveal fundamental flaws in widely used evaluation benchmarks: contrary to their design intent, up to 13% of objects in the OoD test sets actually belong to in-distribution classes, and vice versa. These quality issues severely distort the reported performance of existing methods and contribute to their high false positive rates. Second, we introduce a novel training-time mitigation paradigm that operates independently of external OoD detectors. Instead of relying solely on post-hoc scoring, we fine-tune the detector using a carefully synthesized OoD dataset that semantically resembles in-distribution objects. This process shapes a defensive decision boundary by suppressing objectness on OoD objects, leading to a 91% reduction in hallucination error of a YOLO model on BDD-100K. Our methodology generalizes across detection paradigms such as YOLO, Faster R-CNN, and RT-DETR, and supports few-shot adaptation. Together, these contributions offer a principled and effective way to reduce OoD-induced hallucination in object detectors. Code and data are available at: https://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood.
<div id='section'>Paperid: <span id='pid'>664, <a href='https://arxiv.org/pdf/2501.02616.pdf' target='_blank'>https://arxiv.org/pdf/2501.02616.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amol Khanna, Chenyi Ling, Derek Everett, Edward Raff, Nathan Inkawhich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02616">Multi-layer Radial Basis Function Networks for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing methods for out-of-distribution (OOD) detection use various techniques to produce a score, separate from classification, that determines how ``OOD'' an input is. Our insight is that OOD detection can be simplified by using a neural network architecture which can effectively merge classification and OOD detection into a single step. Radial basis function networks (RBFNs) inherently link classification confidence and OOD detection; however, these networks have lost popularity due to the difficult of training them in a multi-layer fashion. In this work, we develop a multi-layer radial basis function network (MLRBFN) which can be easily trained. To ensure that these networks are also effective for OOD detection, we develop a novel depression mechanism. We apply MLRBFNs as standalone classifiers and as heads on top of pretrained feature extractors, and find that they are competitive with commonly used methods for OOD detection. Our MLRBFN architecture demonstrates a promising new direction for OOD detection methods.
<div id='section'>Paperid: <span id='pid'>665, <a href='https://arxiv.org/pdf/2411.17777.pdf' target='_blank'>https://arxiv.org/pdf/2411.17777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pirzada Suhail, Hao Tang, Amit Sethi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17777">Network Inversion and Its Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks have emerged as powerful tools across various applications, yet their decision-making process often remains opaque, leading to them being perceived as "black boxes." This opacity raises concerns about their interpretability and reliability, especially in safety-critical scenarios. Network inversion techniques offer a solution by allowing us to peek inside these black boxes, revealing the features and patterns learned by the networks behind their decision-making processes and thereby provide valuable insights into how neural networks arrive at their conclusions, making them more interpretable and trustworthy. This paper presents a simple yet effective approach to network inversion using a meticulously conditioned generator that learns the data distribution in the input space of the trained neural network, enabling the reconstruction of inputs that would most likely lead to the desired outputs. To capture the diversity in the input space for a given output, instead of simply revealing the conditioning labels to the generator, we encode the conditioning label information into vectors and intermediate matrices and further minimize the cosine similarity between features of the generated images. Additionally, we incorporate feature orthogonality as a regularization term to boost image diversity which penalises the deviations of the Gram matrix of the features from the identity matrix, ensuring orthogonality and promoting distinct, non-redundant representations for each label. The paper concludes by exploring immediate applications of the proposed network inversion approach in interpretability, out-of-distribution detection, and training data reconstruction.
<div id='section'>Paperid: <span id='pid'>666, <a href='https://arxiv.org/pdf/2406.14301.pdf' target='_blank'>https://arxiv.org/pdf/2406.14301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rasika Vijithasena, Rafaela Scaciota, Mehdi Bennis, Sumudu Samarakoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14301">Resource Optimization for Tail-Based Control in Wireless Networked Control Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Achieving control stability is one of the key design challenges of scalable Wireless Networked Control Systems (WNCS) under limited communication and computing resources. This paper explores the use of an alternative control concept defined as tail-based control, which extends the classical Linear Quadratic Regulator (LQR) cost function for multiple dynamic control systems over a shared wireless network. We cast the control of multiple control systems as a network-wide optimization problem and decouple it in terms of sensor scheduling, plant state prediction, and control policies. Toward this, we propose a solution consisting of a scheduling algorithm based on Lyapunov optimization for sensing, a mechanism based on Gaussian Process Regression (GPR) for state prediction and uncertainty estimation, and a control policy based on Reinforcement Learning (RL) to ensure tail-based control stability. A set of discrete time-invariant mountain car control systems is used to evaluate the proposed solution and is compared against four variants that use state-of-the-art scheduling, prediction, and control methods. The experimental results indicate that the proposed method yields 22% reduction in overall cost in terms of communication and control resource utilization compared to state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>667, <a href='https://arxiv.org/pdf/2406.06999.pdf' target='_blank'>https://arxiv.org/pdf/2406.06999.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junfei Yi, Jianxu Mao, Tengfei Liu, Mingjie Li, Hanyu Gu, Hui Zhang, Xiaojun Chang, Yaonan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06999">Teaching with Uncertainty: Unleashing the Potential of Knowledge Distillation in Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge distillation (KD) is a widely adopted and effective method for compressing models in object detection tasks. Particularly, feature-based distillation methods have shown remarkable performance. Existing approaches often ignore the uncertainty in the teacher model's knowledge, which stems from data noise and imperfect training. This limits the student model's ability to learn latent knowledge, as it may overly rely on the teacher's imperfect guidance. In this paper, we propose a novel feature-based distillation paradigm with knowledge uncertainty for object detection, termed "Uncertainty Estimation-Discriminative Knowledge Extraction-Knowledge Transfer (UET)", which can seamlessly integrate with existing distillation methods. By leveraging the Monte Carlo dropout technique, we introduce knowledge uncertainty into the training process of the student model, facilitating deeper exploration of latent knowledge. Our method performs effectively during the KD process without requiring intricate structures or extensive computational resources. Extensive experiments validate the effectiveness of our proposed approach across various distillation strategies, detectors, and backbone architectures. Specifically, following our proposed paradigm, the existing FGD method achieves state-of-the-art (SoTA) performance, with ResNet50-based GFL achieving 44.1% mAP on the COCO dataset, surpassing the baselines by 3.9%.
<div id='section'>Paperid: <span id='pid'>668, <a href='https://arxiv.org/pdf/2403.18476.pdf' target='_blank'>https://arxiv.org/pdf/2403.18476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luca Savant, Diego Valsesia, Enrico Magli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18476">Modeling uncertainty for Gaussian Splatting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Stochastic Gaussian Splatting (SGS): the first framework for uncertainty estimation using Gaussian Splatting (GS). GS recently advanced the novel-view synthesis field by achieving impressive reconstruction quality at a fraction of the computational cost of Neural Radiance Fields (NeRF). However, contrary to the latter, it still lacks the ability to provide information about the confidence associated with their outputs. To address this limitation, in this paper, we introduce a Variational Inference-based approach that seamlessly integrates uncertainty prediction into the common rendering pipeline of GS. Additionally, we introduce the Area Under Sparsification Error (AUSE) as a new term in the loss function, enabling optimization of uncertainty estimation alongside image reconstruction. Experimental results on the LLFF dataset demonstrate that our method outperforms existing approaches in terms of both image rendering quality and uncertainty estimation accuracy. Overall, our framework equips practitioners with valuable insights into the reliability of synthesized views, facilitating safer decision-making in real-world applications.
<div id='section'>Paperid: <span id='pid'>669, <a href='https://arxiv.org/pdf/2403.15260.pdf' target='_blank'>https://arxiv.org/pdf/2403.15260.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alvaro Gonzalez-Jimenez, Simone Lionetti, Dena Bazazian, Philippe Gottfrois, Fabian GrÃ¶ger, Marc Pouly, Alexander Navarini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15260">Hyperbolic Metric Learning for Visual Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-Of-Distribution (OOD) detection is critical to deploy deep learning models in safety-critical applications. However, the inherent hierarchical concept structure of visual data, which is instrumental to OOD detection, is often poorly captured by conventional methods based on Euclidean geometry. This work proposes a metric framework that leverages the strengths of Hyperbolic geometry for OOD detection. Inspired by previous works that refine the decision boundary for OOD data with synthetic outliers, we extend this method to Hyperbolic space. Interestingly, we find that synthetic outliers do not benefit OOD detection in Hyperbolic space as they do in Euclidean space. Furthermore we explore the relationship between OOD detection performance and Hyperbolic embedding dimension, addressing practical concerns in resource-constrained environments. Extensive experiments show that our framework improves the FPR95 for OOD detection from 22\% to 15\% and from 49% to 28% on CIFAR-10 and CIFAR-100 respectively compared to Euclidean methods.
<div id='section'>Paperid: <span id='pid'>670, <a href='https://arxiv.org/pdf/2402.01476.pdf' target='_blank'>https://arxiv.org/pdf/2402.01476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingyi Chen, Qinghua Tao, Francesco Tonin, Johan A. K. Suykens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01476">Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While the great capability of Transformers significantly boosts prediction accuracy, it could also yield overconfident predictions and require calibrated uncertainty estimation, which can be commonly tackled by Gaussian processes (GPs). Existing works apply GPs with symmetric kernels under variational inference to the attention kernel; however, omitting the fact that attention kernels are in essence asymmetric. Moreover, the complexity of deriving the GP posteriors remains high for large-scale data. In this work, we propose Kernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for building uncertainty-aware self-attention where the asymmetry of attention kernels is tackled by Kernel SVD (KSVD) and a reduced complexity is acquired. Through KEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors from KSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) using only a small set of adjoint eigenfunctions from KSVD, the derivation of SVGP posteriors can be based on the inversion of a diagonal matrix containing singular values, contributing to a reduction in time complexity; iii) an evidence lower bound is derived so that variational parameters and network weights can be optimized with it. Experiments verify our excellent performances and efficiency on in-distribution, distribution-shift and out-of-distribution benchmarks.
<div id='section'>Paperid: <span id='pid'>671, <a href='https://arxiv.org/pdf/2401.08777.pdf' target='_blank'>https://arxiv.org/pdf/2401.08777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhijith Gandrakota, Lily Zhang, Aahlad Puli, Kyle Cranmer, Jennifer Ngadiuba, Rajesh Ranganath, Nhan Tran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08777">Robust Anomaly Detection for Particle Physics Using Multi-Background Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly, or out-of-distribution, detection is a promising tool for aiding discoveries of new particles or processes in particle physics. In this work, we identify and address two overlooked opportunities to improve anomaly detection for high-energy physics. First, rather than train a generative model on the single most dominant background process, we build detection algorithms using representation learning from multiple background types, thus taking advantage of more information to improve estimation of what is relevant for detection. Second, we generalize decorrelation to the multi-background setting, thus directly enforcing a more complete definition of robustness for anomaly detection. We demonstrate the benefit of the proposed robust multi-background anomaly detection algorithms on a high-dimensional dataset of particle decays at the Large Hadron Collider.
<div id='section'>Paperid: <span id='pid'>672, <a href='https://arxiv.org/pdf/2311.09469.pdf' target='_blank'>https://arxiv.org/pdf/2311.09469.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael J. Q. Zhang, Eunsol Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09469">Clarify When Necessary: Resolving Ambiguity Through Interaction with LMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Resolving ambiguities through interaction is a hallmark of natural language, and modeling this behavior is a core challenge in crafting AI assistants. In this work, we study such behavior in LMs by proposing a task-agnostic framework for resolving ambiguity by asking users clarifying questions. Our framework breaks down this objective into three subtasks: (1) determining when clarification is needed, (2) determining what clarifying question to ask, and (3) responding accurately with the new information gathered through clarification. We evaluate systems across three NLP applications: question answering, machine translation and natural language inference. For the first subtask, we present a novel uncertainty estimation approach, intent-sim, that determines the utility of querying for clarification by estimating the entropy over user intents. Our method consistently outperforms existing uncertainty estimation approaches at identifying predictions that will benefit from clarification. When only allowed to ask for clarification on 10% of examples, our system is able to double the performance gains over randomly selecting examples to clarify. Furthermore, we find that intent-sim is robust, demonstrating improvements across a wide range of NLP tasks and LMs. Together, our work lays foundation for studying clarifying interactions with LMs.
<div id='section'>Paperid: <span id='pid'>673, <a href='https://arxiv.org/pdf/2310.13027.pdf' target='_blank'>https://arxiv.org/pdf/2310.13027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiyu Shen, Bin Pan, Tianyang Shi, Tao Li, Zhenwei Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13027">Be Bayesian by Attachments to Catch More Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Neural Networks (BNNs) have become one of the promising approaches for uncertainty estimation due to the solid theorical foundations. However, the performance of BNNs is affected by the ability of catching uncertainty. Instead of only seeking the distribution of neural network weights by in-distribution (ID) data, in this paper, we propose a new Bayesian Neural Network with an Attached structure (ABNN) to catch more uncertainty from out-of-distribution (OOD) data. We first construct a mathematical description for the uncertainty of OOD data according to the prior distribution, and then develop an attached Bayesian structure to integrate the uncertainty of OOD data into the backbone network. ABNN is composed of an expectation module and several distribution modules. The expectation module is a backbone deep network which focuses on the original task, and the distribution modules are mini Bayesian structures which serve as attachments of the backbone. In particular, the distribution modules aim at extracting the uncertainty from both ID and OOD data. We further provide theoretical analysis for the convergence of ABNN, and experimentally validate its superiority by comparing with some state-of-the-art uncertainty estimation methods Code will be made available.
<div id='section'>Paperid: <span id='pid'>674, <a href='https://arxiv.org/pdf/2310.05401.pdf' target='_blank'>https://arxiv.org/pdf/2310.05401.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bolian Li, Ruqi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05401">Entropy-MCMC: Sampling from Flat Basins with Ease</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian deep learning counts on the quality of posterior distribution estimation. However, the posterior of deep neural networks is highly multi-modal in nature, with local modes exhibiting varying generalization performance. Given a practical budget, targeting at the original posterior can lead to suboptimal performance, as some samples may become trapped in "bad" modes and suffer from overfitting. Leveraging the observation that "good" modes with low generalization error often reside in flat basins of the energy landscape, we propose to bias sampling on the posterior toward these flat regions. Specifically, we introduce an auxiliary guiding variable, the stationary distribution of which resembles a smoothed posterior free from sharp modes, to lead the MCMC sampler to flat basins. By integrating this guiding variable with the model parameter, we create a simple joint distribution that enables efficient sampling with minimal computational overhead. We prove the convergence of our method and further show that it converges faster than several existing flatness-aware methods in the strongly convex setting. Empirical results demonstrate that our method can successfully sample from flat basins of the posterior, and outperforms all compared baselines on multiple benchmarks including classification, calibration, and out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>675, <a href='https://arxiv.org/pdf/2302.02628.pdf' target='_blank'>https://arxiv.org/pdf/2302.02628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ailin Deng, Shen Li, Miao Xiong, Zhirui Chen, Bryan Hooi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02628">Trust, but Verify: Using Self-Supervised Probing to Improve Trustworthiness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trustworthy machine learning is of primary importance to the practical deployment of deep learning models. While state-of-the-art models achieve astonishingly good performance in terms of accuracy, recent literature reveals that their predictive confidence scores unfortunately cannot be trusted: e.g., they are often overconfident when wrong predictions are made, or so even for obvious outliers. In this paper, we introduce a new approach of self-supervised probing, which enables us to check and mitigate the overconfidence issue for a trained model, thereby improving its trustworthiness. We provide a simple yet effective framework, which can be flexibly applied to existing trustworthiness-related methods in a plug-and-play manner. Extensive experiments on three trustworthiness-related tasks (misclassification detection, calibration and out-of-distribution detection) across various benchmarks verify the effectiveness of our proposed probing framework.
<div id='section'>Paperid: <span id='pid'>676, <a href='https://arxiv.org/pdf/2210.07612.pdf' target='_blank'>https://arxiv.org/pdf/2210.07612.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liam Hodgkinson, Chris van der Heide, Fred Roosta, Michael W. Mahoney
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.07612">Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite their importance for assessing reliability of predictions, uncertainty quantification (UQ) measures for machine learning models have only recently begun to be rigorously characterized. One prominent issue is the curse of dimensionality: it is commonly believed that the marginal likelihood should be reminiscent of cross-validation metrics and that both should deteriorate with larger input dimensions. We prove that by tuning hyperparameters to maximize marginal likelihood (the empirical Bayes procedure), the performance, as measured by the marginal likelihood, improves monotonically} with the input dimension. On the other hand, we prove that cross-validation metrics exhibit qualitatively different behavior that is characteristic of double descent. Cold posteriors, which have recently attracted interest due to their improved performance in certain settings, appear to exacerbate these phenomena. We verify empirically that our results hold for real data, beyond our considered assumptions, and we explore consequences involving synthetic covariates.
<div id='section'>Paperid: <span id='pid'>677, <a href='https://arxiv.org/pdf/2209.15558.pdf' target='_blank'>https://arxiv.org/pdf/2209.15558.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jie Ren, Jiaming Luo, Yao Zhao, Kundan Krishna, Mohammad Saleh, Balaji Lakshminarayanan, Peter J. Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.15558">Out-of-Distribution Detection and Selective Generation for Conditional Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning algorithms typically assume independent and identically distributed samples in training and at test time. Much work has shown that high-performing ML classifiers can degrade significantly and provide overly-confident, wrong classification predictions, particularly for out-of-distribution (OOD) inputs. Conditional language models (CLMs) are predominantly trained to classify the next token in an output sequence, and may suffer even worse degradation on OOD inputs as the prediction is done auto-regressively over many steps. Furthermore, the space of potential low-quality outputs is larger as arbitrary text can be generated and it is important to know when to trust the generated output. We present a highly accurate and lightweight OOD detection method for CLMs, and demonstrate its effectiveness on abstractive summarization and translation. We also show how our method can be used under the common and realistic setting of distribution shift for selective generation (analogous to selective prediction for classification) of high-quality outputs, while automatically abstaining from low-quality ones, enabling safer deployment of generative language models.
<div id='section'>Paperid: <span id='pid'>678, <a href='https://arxiv.org/pdf/2206.09387.pdf' target='_blank'>https://arxiv.org/pdf/2206.09387.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhilin Zhao, Longbing Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.09387">Dual Representation Learning for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To classify in-distribution samples, deep neural networks explore strongly label-related information and discard weakly label-related information according to the information bottleneck. Out-of-distribution samples drawn from distributions differing from that of in-distribution samples could be assigned with unexpected high-confidence predictions because they could obtain minimum strongly label-related information. To distinguish in- and out-of-distribution samples, Dual Representation Learning (DRL) makes out-of-distribution samples harder to have high-confidence predictions by exploring both strongly and weakly label-related information from in-distribution samples. For a pretrained network exploring strongly label-related information to learn label-discriminative representations, DRL trains its auxiliary network exploring the remaining weakly label-related information to learn distribution-discriminative representations. Specifically, for a label-discriminative representation, DRL constructs its complementary distribution-discriminative representation by integrating diverse representations less similar to the label-discriminative representation. Accordingly, DRL combines label- and distribution-discriminative representations to detect out-of-distribution samples. Experiments show that DRL outperforms the state-of-the-art methods for out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>679, <a href='https://arxiv.org/pdf/2206.09385.pdf' target='_blank'>https://arxiv.org/pdf/2206.09385.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhilin Zhao, Longbing Cao, Kun-Yu Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.09385">Out-of-distribution Detection by Cross-class Vicinity Distribution of In-distribution Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks for image classification only learn to map in-distribution inputs to their corresponding ground truth labels in training without differentiating out-of-distribution samples from in-distribution ones. This results from the assumption that all samples are independent and identically distributed (IID) without distributional distinction. Therefore, a pretrained network learned from in-distribution samples treats out-of-distribution samples as in-distribution and makes high-confidence predictions on them in the test phase. To address this issue, we draw out-of-distribution samples from the vicinity distribution of training in-distribution samples for learning to reject the prediction on out-of-distribution inputs. A \textit{Cross-class Vicinity Distribution} is introduced by assuming that an out-of-distribution sample generated by mixing multiple in-distribution samples does not share the same classes of its constituents. We thus improve the discriminability of a pretrained network by finetuning it with out-of-distribution samples drawn from the cross-class vicinity distribution, where each out-of-distribution input corresponds to a complementary label. Experiments on various in-/out-of-distribution datasets show that the proposed method significantly outperforms the existing methods in improving the capacity of discriminating between in- and out-of-distribution samples.
<div id='section'>Paperid: <span id='pid'>680, <a href='https://arxiv.org/pdf/2206.09380.pdf' target='_blank'>https://arxiv.org/pdf/2206.09380.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhilin Zhao, Longbing Cao, Kun-Yu Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.09380">Supervision Adaptation Balancing In-distribution Generalization and Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The discrepancy between in-distribution (ID) and out-of-distribution (OOD) samples can lead to \textit{distributional vulnerability} in deep neural networks, which can subsequently lead to high-confidence predictions for OOD samples. This is mainly due to the absence of OOD samples during training, which fails to constrain the network properly. To tackle this issue, several state-of-the-art methods include adding extra OOD samples to training and assign them with manually-defined labels. However, this practice can introduce unreliable labeling, negatively affecting ID classification. The distributional vulnerability presents a critical challenge for non-IID deep learning, which aims for OOD-tolerant ID classification by balancing ID generalization and OOD detection. In this paper, we introduce a novel \textit{supervision adaptation} approach to generate adaptive supervision information for OOD samples, making them more compatible with ID samples. Firstly, we measure the dependency between ID samples and their labels using mutual information, revealing that the supervision information can be represented in terms of negative probabilities across all classes. Secondly, we investigate data correlations between ID and OOD samples by solving a series of binary regression problems, with the goal of refining the supervision information for more distinctly separable ID classes. Our extensive experiments on four advanced network architectures, two ID datasets, and eleven diversified OOD datasets demonstrate the efficacy of our supervision adaptation approach in improving both ID classification and OOD detection capabilities.
<div id='section'>Paperid: <span id='pid'>681, <a href='https://arxiv.org/pdf/2112.10558.pdf' target='_blank'>https://arxiv.org/pdf/2112.10558.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Galke, Iacopo Vagliano, Benedikt Franke, Tobias Zielke, Marcel Hoffmann, Ansgar Scherp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.10558">Lifelong Learning on Evolving Graphs Under the Constraints of Imbalanced Classes and New Classes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lifelong graph learning deals with the problem of continually adapting graph neural network (GNN) models to changes in evolving graphs. We address two critical challenges of lifelong graph learning in this work: dealing with new classes and tackling imbalanced class distributions. The combination of these two challenges is particularly relevant since newly emerging classes typically resemble only a tiny fraction of the data, adding to the already skewed class distribution. We make several contributions: First, we show that the amount of unlabeled data does not influence the results, which is an essential prerequisite for lifelong learning on a sequence of tasks. Second, we experiment with different label rates and show that our methods can perform well with only a tiny fraction of annotated nodes. Third, we propose the gDOC method to detect new classes under the constraint of having an imbalanced class distribution. The critical ingredient is a weighted binary cross-entropy loss function to account for the class imbalance. Moreover, we demonstrate combinations of gDOC with various base GNN models such as GraphSAGE, Simplified Graph Convolution, and Graph Attention Networks. Lastly, our k-neighborhood time difference measure provably normalizes the temporal changes across different graph datasets. With extensive experimentation, we find that the proposed gDOC method is consistently better than a naive adaption of DOC to graphs. Specifically, in experiments using the smallest history size, the out-of-distribution detection score of gDOC is 0.09 compared to 0.01 for DOC. Furthermore, gDOC achieves an Open-F1 score, a combined measure of in-distribution classification and out-of-distribution detection, of 0.33 compared to 0.25 of DOC (32% increase).
<div id='section'>Paperid: <span id='pid'>682, <a href='https://arxiv.org/pdf/2510.02279.pdf' target='_blank'>https://arxiv.org/pdf/2510.02279.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mykyta Ielanskyi, Kajetan Schweighofer, Lukas Aichberger, Sepp Hochreiter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02279">Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hallucinations are a common issue that undermine the reliability of large language models (LLMs). Recent studies have identified a specific subset of hallucinations, known as confabulations, which arise due to predictive uncertainty of LLMs. To detect confabulations, various methods for estimating predictive uncertainty in natural language generation (NLG) have been developed. These methods are typically evaluated by correlating uncertainty estimates with the correctness of generated text, with question-answering (QA) datasets serving as the standard benchmark. However, commonly used approximate correctness functions have substantial disagreement between each other and, consequently, in the ranking of the uncertainty estimation methods. This allows one to inflate the apparent performance of uncertainty estimation methods. We propose using several alternative risk indicators for risk correlation experiments that improve robustness of empirical assessment of UE algorithms for NLG. For QA tasks, we show that marginalizing over multiple LLM-as-a-judge variants leads to reducing the evaluation biases. Furthermore, we explore structured tasks as well as out of distribution and perturbation detection tasks which provide robust and controllable risk indicators. Finally, we propose to use an Elo rating of uncertainty estimation methods to give an objective summarization over extensive evaluation settings.
<div id='section'>Paperid: <span id='pid'>683, <a href='https://arxiv.org/pdf/2509.20193.pdf' target='_blank'>https://arxiv.org/pdf/2509.20193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fahmida Islam, Adnan Mahmood, Noorain Mukhtiar, Kasun Eranda Wijethilake, Quan Z. Sheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20193">FairEquityFL -- A Fair and Equitable Client Selection in Federated Learning for Heterogeneous IoV Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated Learning (FL) has been extensively employed for a number of applications in machine learning, i.e., primarily owing to its privacy preserving nature and efficiency in mitigating the communication overhead. Internet of Vehicles (IoV) is one of the promising applications, wherein FL can be utilized to train a model more efficiently. Since only a subset of the clients can participate in each FL training round, challenges arise pertinent to fairness in the client selection process. Over the years, a number of researchers from both academia and industry have proposed numerous FL frameworks. However, to the best of our knowledge, none of them have employed fairness for FL-based client selection in a dynamic and heterogeneous IoV environment. Accordingly, in this paper, we envisage a FairEquityFL framework to ensure an equitable opportunity for all the clients to participate in the FL training process. In particular, we have introduced a sampling equalizer module within the selector component for ensuring fairness in terms of fair collaboration opportunity for all the clients in the client selection process. The selector is additionally responsible for both monitoring and controlling the clients' participation in each FL training round. Moreover, an outlier detection mechanism is enforced for identifying malicious clients based on the model performance in terms of considerable fluctuation in either accuracy or loss minimization. The selector flags suspicious clients and temporarily suspend such clients from participating in the FL training process. We further evaluate the performance of FairEquityFL on a publicly available dataset, FEMNIST. Our simulation results depict that FairEquityFL outperforms baseline models to a considerable extent.
<div id='section'>Paperid: <span id='pid'>684, <a href='https://arxiv.org/pdf/2509.05993.pdf' target='_blank'>https://arxiv.org/pdf/2509.05993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junjie Li, Kong Aik Lee, Duc-Tuan Truong, Tianchi Liu, Man-Wai Mak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05993">Xi+: Uncertainty Supervision for Robust Speaker Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There are various factors that can influence the performance of speaker recognition systems, such as emotion, language and other speaker-related or context-related variations. Since individual speech frames do not contribute equally to the utterance-level representation, it is essential to estimate the importance or reliability of each frame. The xi-vector model addresses this by assigning different weights to frames based on uncertainty estimation. However, its uncertainty estimation model is implicitly trained through classification loss alone and does not consider the temporal relationships between frames, which may lead to suboptimal supervision. In this paper, we propose an improved architecture, xi+. Compared to xi-vector, xi+ incorporates a temporal attention module to capture frame-level uncertainty in a context-aware manner. In addition, we introduce a novel loss function, Stochastic Variance Loss, which explicitly supervises the learning of uncertainty. Results demonstrate consistent performance improvements of about 10\% on the VoxCeleb1-O set and 11\% on the NIST SRE 2024 evaluation set.
<div id='section'>Paperid: <span id='pid'>685, <a href='https://arxiv.org/pdf/2509.05993.pdf' target='_blank'>https://arxiv.org/pdf/2509.05993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junjie Li, Kong Aik Lee, Duc-Tuan Truong, Tianchi Liu, Man-Wai Mak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05993">Xi+: Uncertainty Supervision for Robust Speaker Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There are various factors that can influence the performance of speaker recognition systems, such as emotion, language and other speaker-related or context-related variations. Since individual speech frames do not contribute equally to the utterance-level representation, it is essential to estimate the importance or reliability of each frame. The xi-vector model addresses this by assigning different weights to frames based on uncertainty estimation. However, its uncertainty estimation model is implicitly trained through classification loss alone and does not consider the temporal relationships between frames, which may lead to suboptimal supervision. In this paper, we propose an improved architecture, xi+. Compared to xi-vector, xi+ incorporates a temporal attention module to capture frame-level uncertainty in a context-aware manner. In addition, we introduce a novel loss function, Stochastic Variance Loss, which explicitly supervises the learning of uncertainty. Results demonstrate consistent performance improvements of about 10\% on the VoxCeleb1-O set and 11\% on the NIST SRE 2024 evaluation set.
<div id='section'>Paperid: <span id='pid'>686, <a href='https://arxiv.org/pdf/2508.17174.pdf' target='_blank'>https://arxiv.org/pdf/2508.17174.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeng-Lin Li, Ming-Ching Chang, Wei-Chao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17174">Sharpness-Aware Geometric Defense for Robust Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection ensures safe and reliable model deployment. Contemporary OOD algorithms using geometry projection can detect OOD or adversarial samples from clean in-distribution (ID) samples. However, this setting regards adversarial ID samples as OOD, leading to incorrect OOD predictions. Existing efforts on OOD detection with ID and OOD data under attacks are minimal. In this paper, we develop a robust OOD detection method that distinguishes adversarial ID samples from OOD ones. The sharp loss landscape created by adversarial training hinders model convergence, impacting the latent embedding quality for OOD score calculation. Therefore, we introduce a {\bf Sharpness-aware Geometric Defense (SaGD)} framework to smooth out the rugged adversarial loss landscape in the projected latent geometry. Enhanced geometric embedding convergence enables accurate ID data characterization, benefiting OOD detection against adversarial attacks. We use Jitter-based perturbation in adversarial training to extend the defense ability against unseen attacks. Our SaGD framework significantly improves FPR and AUC over the state-of-the-art defense approaches in differentiating CIFAR-100 from six other OOD datasets under various attacks. We further examine the effects of perturbations at various adversarial training levels, revealing the relationship between the sharp loss landscape and adversarial OOD detection.
<div id='section'>Paperid: <span id='pid'>687, <a href='https://arxiv.org/pdf/2508.12776.pdf' target='_blank'>https://arxiv.org/pdf/2508.12776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Rajabinasab, Farhad Pakdaman, Moncef Gabbouj, Peter Schneider-Kamp, Arthur Zimek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12776">Randomized PCA Forest for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel unsupervised outlier detection method based on Randomized Principal Component Analysis (PCA). Inspired by the performance of Randomized PCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a novel unsupervised outlier detection method that utilizes RPCA Forest for outlier detection. Experimental results showcase the superiority of the proposed approach compared to the classical and state-of-the-art methods in performing the outlier detection task on several datasets while performing competitively on the rest. The extensive analysis of the proposed method reflects it high generalization power and its computational efficiency, highlighting it as a good choice for unsupervised outlier detection.
<div id='section'>Paperid: <span id='pid'>688, <a href='https://arxiv.org/pdf/2506.15404.pdf' target='_blank'>https://arxiv.org/pdf/2506.15404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anju Chhetri, Jari Korhonen, Prashnna Gyawali, Binod Bhattarai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15404">NERO: Explainable Out-of-Distribution Detection with Neuron-level Relevance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensuring reliability is paramount in deep learning, particularly within the domain of medical imaging, where diagnostic decisions often hinge on model outputs. The capacity to separate out-of-distribution (OOD) samples has proven to be a valuable indicator of a model's reliability in research. In medical imaging, this is especially critical, as identifying OOD inputs can help flag potential anomalies that might otherwise go undetected. While many OOD detection methods rely on feature or logit space representations, recent works suggest these approaches may not fully capture OOD diversity. To address this, we propose a novel OOD scoring mechanism, called NERO, that leverages neuron-level relevance at the feature layer. Specifically, we cluster neuron-level relevance for each in-distribution (ID) class to form representative centroids and introduce a relevance distance metric to quantify a new sample's deviation from these centroids, enhancing OOD separability. Additionally, we refine performance by incorporating scaled relevance in the bias term and combining feature norms. Our framework also enables explainable OOD detection. We validate its effectiveness across multiple deep learning architectures on the gastrointestinal imaging benchmarks Kvasir and GastroVision, achieving improvements over state-of-the-art OOD detection methods.
<div id='section'>Paperid: <span id='pid'>689, <a href='https://arxiv.org/pdf/2505.02448.pdf' target='_blank'>https://arxiv.org/pdf/2505.02448.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaohua Li, Enhao Zhang, Chuanxing Geng, Songcan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02448">Recent Advances in Out-of-Distribution Detection with CLIP-Like Models: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution detection (OOD) is a pivotal task for real-world applications that trains models to identify samples that are distributionally different from the in-distribution (ID) data during testing. Recent advances in AI, particularly Vision-Language Models (VLMs) like CLIP, have revolutionized OOD detection by shifting from traditional unimodal image detectors to multimodal image-text detectors. This shift has inspired extensive research; however, existing categorization schemes (e.g., few- or zero-shot types) still rely solely on the availability of ID images, adhering to a unimodal paradigm. To better align with CLIP's cross-modal nature, we propose a new categorization framework rooted in both image and text modalities. Specifically, we categorize existing methods based on how visual and textual information of OOD data is utilized within image + text modalities, and further divide them into four groups: OOD Images (i.e., outliers) Seen or Unseen, and OOD Texts (i.e., learnable vectors or class names) Known or Unknown, across two training strategies (i.e., train-free or training-required). More importantly, we discuss open problems in CLIP-like OOD detection and highlight promising directions for future research, including cross-domain integration, practical applications, and theoretical understanding.
<div id='section'>Paperid: <span id='pid'>690, <a href='https://arxiv.org/pdf/2504.13429.pdf' target='_blank'>https://arxiv.org/pdf/2504.13429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shenzhi Yang, Bin Liang, An Liu, Lin Gui, Xingkai Yao, Xiaofang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13429">Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).
<div id='section'>Paperid: <span id='pid'>691, <a href='https://arxiv.org/pdf/2503.16978.pdf' target='_blank'>https://arxiv.org/pdf/2503.16978.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruoqi Zhang, Ziwei Luo, Jens SjÃ¶lund, Per Mattsson, Linus GisslÃ©n, Alessandro Sestini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16978">Real-Time Diffusion Policies for Games: Enhancing Consistency Policies with Q-Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have shown impressive performance in capturing complex and multi-modal action distributions for game agents, but their slow inference speed prevents practical deployment in real-time game environments. While consistency models offer a promising approach for one-step generation, they often suffer from training instability and performance degradation when applied to policy learning. In this paper, we present CPQE (Consistency Policy with Q-Ensembles), which combines consistency models with Q-ensembles to address these challenges.CPQE leverages uncertainty estimation through Q-ensembles to provide more reliable value function approximations, resulting in better training stability and improved performance compared to classic double Q-network methods. Our extensive experiments across multiple game scenarios demonstrate that CPQE achieves inference speeds of up to 60 Hz -- a significant improvement over state-of-the-art diffusion policies that operate at only 20 Hz -- while maintaining comparable performance to multi-step diffusion approaches. CPQE consistently outperforms state-of-the-art consistency model approaches, showing both higher rewards and enhanced training stability throughout the learning process. These results indicate that CPQE offers a practical solution for deploying diffusion-based policies in games and other real-time applications where both multi-modal behavior modeling and rapid inference are critical requirements.
<div id='section'>Paperid: <span id='pid'>692, <a href='https://arxiv.org/pdf/2503.10959.pdf' target='_blank'>https://arxiv.org/pdf/2503.10959.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshat Ramachandran, Mingyu Lee, Huan Xu, Souvik Kundu, Tushar Krishna
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10959">OuroMamba: A Data-Free Quantization Framework for Vision Mamba Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present OuroMamba, the first data-free post-training quantization (DFQ) method for vision Mamba-based models (VMMs). We identify two key challenges in enabling DFQ for VMMs, (1) VMM's recurrent state transitions restricts capturing of long-range interactions and leads to semantically weak synthetic data, (2) VMM activations exhibit dynamic outlier variations across time-steps, rendering existing static PTQ techniques ineffective. To address these challenges, OuroMamba presents a two-stage framework: (1) OuroMamba-Gen to generate semantically rich and meaningful synthetic data. It applies contrastive learning on patch level VMM features generated through neighborhood interactions in the latent state space, (2) OuroMamba-Quant to employ mixed-precision quantization with lightweight dynamic outlier detection during inference. In specific, we present a thresholding based outlier channel selection strategy for activations that gets updated every time-step. Extensive experiments across vision and generative tasks show that our data-free OuroMamba surpasses existing data-driven PTQ techniques, achieving state-of-the-art performance across diverse quantization settings. Additionally, we implement efficient GPU kernels to achieve practical latency speedup of up to 2.36x. Code will be released soon.
<div id='section'>Paperid: <span id='pid'>693, <a href='https://arxiv.org/pdf/2503.06442.pdf' target='_blank'>https://arxiv.org/pdf/2503.06442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Liu, Hao Tang, Haiqi Zhang, Jing Qin, Zechao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06442">OT-DETECTOR: Delving into Optimal Transport for Zero-shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring the reliability and safety of machine learning models in real-world applications. While zero-shot OOD detection, which requires no training on in-distribution (ID) data, has become feasible with the emergence of vision-language models like CLIP, existing methods primarily focus on semantic matching and fail to fully capture distributional discrepancies. To address these limitations, we propose OT-DETECTOR, a novel framework that employs Optimal Transport (OT) to quantify both semantic and distributional discrepancies between test samples and ID labels. Specifically, we introduce cross-modal transport mass and transport cost as semantic-wise and distribution-wise OOD scores, respectively, enabling more robust detection of OOD samples. Additionally, we present a semantic-aware content refinement (SaCR) module, which utilizes semantic cues from ID labels to amplify the distributional discrepancy between ID and hard OOD samples. Extensive experiments on several benchmarks demonstrate that OT-DETECTOR achieves state-of-the-art performance across various OOD detection tasks, particularly in challenging hard-OOD scenarios.
<div id='section'>Paperid: <span id='pid'>694, <a href='https://arxiv.org/pdf/2503.00699.pdf' target='_blank'>https://arxiv.org/pdf/2503.00699.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunsu Kim, Giung Nam, Chulhee Yun, Hongseok Yang, Juho Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00699">Parameter Expanded Stochastic Gradient Markov Chain Monte Carlo</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Neural Networks (BNNs) provide a promising framework for modeling predictive uncertainty and enhancing out-of-distribution robustness (OOD) by estimating the posterior distribution of network parameters. Stochastic Gradient Markov Chain Monte Carlo (SGMCMC) is one of the most powerful methods for scalable posterior sampling in BNNs, achieving efficiency by combining stochastic gradient descent with second-order Langevin dynamics. However, SGMCMC often suffers from limited sample diversity in practice, which affects uncertainty estimation and model performance. We propose a simple yet effective approach to enhance sample diversity in SGMCMC without the need for tempering or running multiple chains. Our approach reparameterizes the neural network by decomposing each of its weight matrices into a product of matrices, resulting in a sampling trajectory that better explores the target parameter space. This approach produces a more diverse set of samples, allowing faster mixing within the same computational budget. Notably, our sampler achieves these improvements without increasing the inference cost compared to the standard SGMCMC. Extensive experiments on image classification tasks, including OOD robustness, diversity, loss surface analyses, and a comparative study with Hamiltonian Monte Carlo, demonstrate the superiority of the proposed approach.
<div id='section'>Paperid: <span id='pid'>695, <a href='https://arxiv.org/pdf/2502.14115.pdf' target='_blank'>https://arxiv.org/pdf/2502.14115.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shailik Sarkar, Raquib Bin Yousuf, Linhan Wang, Brian Mayer, Thomas Mortier, Victor Deklerck, Jakub Truszkowski, John C. Simeone, Marigold Norman, Jade Saunders, Chang-Tien Lu, Naren Ramakrishnan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14115">Chasing the Timber Trail: Machine Learning to Reveal Harvest Location Misrepresentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Illegal logging poses a significant threat to global biodiversity, climate stability, and depresses international prices for legal wood harvesting and responsible forest products trade, affecting livelihoods and communities across the globe. Stable isotope ratio analysis (SIRA) is rapidly becoming an important tool for determining the harvest location of traded, organic, products. The spatial pattern in stable isotope ratio values depends on factors such as atmospheric and environmental conditions and can thus be used for geographic origin identification. We present here the results of a deployed machine learning pipeline where we leverage both isotope values and atmospheric variables to determine timber harvest location. Additionally, the pipeline incorporates uncertainty estimation to facilitate the interpretation of harvest location determination for analysts. We present our experiments on a collection of oak (Quercus spp.) tree samples from its global range. Our pipeline outperforms comparable state-of-the-art models determining geographic harvest origin of commercially traded wood products, and has been used by European enforcement agencies to identify harvest location misrepresentation. We also identify opportunities for further advancement of our framework and how it can be generalized to help identify the origin of falsely labeled organic products throughout the supply chain.
<div id='section'>Paperid: <span id='pid'>696, <a href='https://arxiv.org/pdf/2502.11948.pdf' target='_blank'>https://arxiv.org/pdf/2502.11948.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Min-Hsuan Yeh, Max Kamachee, Seongheon Park, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11948">HalluEntity: Benchmarking and Understanding Entity-Level Hallucination Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To mitigate the impact of hallucination nature of LLMs, many studies propose detecting hallucinated generation through uncertainty estimation. However, these approaches predominantly operate at the sentence or paragraph level, failing to pinpoint specific spans or entities responsible for hallucinated content. This lack of granularity is especially problematic for long-form outputs that mix accurate and fabricated information. To address this limitation, we explore entity-level hallucination detection. We propose a new data set, HalluEntity, which annotates hallucination at the entity level. Based on the dataset, we comprehensively evaluate uncertainty-based hallucination detection approaches across 17 modern LLMs. Our experimental results show that uncertainty estimation approaches focusing on individual token probabilities tend to over-predict hallucinations, while context-aware methods show better but still suboptimal performance. Through an in-depth qualitative study, we identify relationships between hallucination tendencies and linguistic properties and highlight important directions for future research. HalluEntity: https://huggingface.co/datasets/samuelyeh/HalluEntity
<div id='section'>Paperid: <span id='pid'>697, <a href='https://arxiv.org/pdf/2412.15176.pdf' target='_blank'>https://arxiv.org/pdf/2412.15176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Aichberger, Kajetan Schweighofer, Sepp Hochreiter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15176">Rethinking Uncertainty Estimation in Natural Language Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are increasingly employed in real-world applications, driving the need to evaluate the trustworthiness of their generated text. To this end, reliable uncertainty estimation is essential. Since current LLMs generate text autoregressively through a stochastic process, the same prompt can lead to varying outputs. Consequently, leading uncertainty estimation methods generate and analyze multiple output sequences to determine the LLM's uncertainty. However, generating output sequences is computationally expensive, making these methods impractical at scale. In this work, we inspect the theoretical foundations of the leading methods and explore new directions to enhance their computational efficiency. Building on the framework of proper scoring rules, we find that the negative log-likelihood of the most likely output sequence constitutes a theoretically grounded uncertainty measure. To approximate this alternative measure, we propose G-NLL, which has the advantage of being obtained using only a single output sequence generated by greedy decoding. This makes uncertainty estimation more efficient and straightforward, while preserving theoretical rigor. Empirical results demonstrate that G-NLL achieves state-of-the-art performance across various LLMs and tasks. Our work lays the foundation for efficient and reliable uncertainty estimation in natural language generation, challenging the necessity of more computationally involved methods currently leading the field.
<div id='section'>Paperid: <span id='pid'>698, <a href='https://arxiv.org/pdf/2412.07255.pdf' target='_blank'>https://arxiv.org/pdf/2412.07255.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinhong Lin, Linna Zhou, Zhongliang Yang, Yuang Cai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07255">Label-Confidence-Aware Uncertainty Estimation in Natural Language Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) display formidable capabilities in generative tasks but also pose potential risks due to their tendency to generate hallucinatory responses. Uncertainty Quantification (UQ), the evaluation of model output reliability, is crucial for ensuring the safety and robustness of AI systems. Recent studies have concentrated on model uncertainty by analyzing the relationship between output entropy under various sampling conditions and the corresponding labels. However, these methods primarily focus on measuring model entropy with precision to capture response characteristics, often neglecting the uncertainties associated with greedy decoding results-the sources of model labels, which can lead to biased classification outcomes. In this paper, we explore the biases introduced by greedy decoding and propose a label-confidence-aware (LCA) uncertainty estimation based on Kullback-Leibler (KL) divergence bridging between samples and label source, thus enhancing the reliability and stability of uncertainty assessments. Our empirical evaluations across a range of popular LLMs and NLP datasets reveal that different label sources can indeed affect classification, and that our approach can effectively capture differences in sampling results and label sources, demonstrating more effective uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>699, <a href='https://arxiv.org/pdf/2412.01250.pdf' target='_blank'>https://arxiv.org/pdf/2412.01250.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesco Taioli, Edoardo Zorzi, Gianni Franchi, Alberto Castellini, Alessandro Farinelli, Marco Cristani, Yiming Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01250">Collaborative Instance Object Navigation: Leveraging Uncertainty-Awareness to Minimize Human-Agent Dialogues</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language-driven instance object navigation assumes that human users initiate the task by providing a detailed description of the target instance to the embodied agent. While this description is crucial for distinguishing the target from visually similar instances in a scene, providing it prior to navigation can be demanding for human. To bridge this gap, we introduce Collaborative Instance object Navigation (CoIN), a new task setting where the agent actively resolve uncertainties about the target instance during navigation in natural, template-free, open-ended dialogues with human. We propose a novel training-free method, Agent-user Interaction with UncerTainty Awareness (AIUTA), which operates independently from the navigation policy, and focuses on the human-agent interaction reasoning with Vision-Language Models (VLMs) and Large Language Models (LLMs). First, upon object detection, a Self-Questioner model initiates a self-dialogue within the agent to obtain a complete and accurate observation description with a novel uncertainty estimation technique. Then, an Interaction Trigger module determines whether to ask a question to the human, continue or halt navigation, minimizing user input. For evaluation, we introduce CoIN-Bench, with a curated dataset designed for challenging multi-instance scenarios. CoIN-Bench supports both online evaluation with humans and reproducible experiments with simulated user-agent interactions. On CoIN-Bench, we show that AIUTA serves as a competitive baseline, while existing language-driven instance navigation methods struggle in complex multi-instance scenes. Code and benchmark will be available upon acceptance at https://intelligolabs.github.io/CoIN/
<div id='section'>Paperid: <span id='pid'>700, <a href='https://arxiv.org/pdf/2411.08488.pdf' target='_blank'>https://arxiv.org/pdf/2411.08488.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Wan, Lin Liu, Haoran Wang, Liangwei Li, Wei Li, Shuheng Kou, Runtian Li, Jiayi Tang, Juanxiu Liu, Jing Zhang, Xiaohui Du, Ruqian Hao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08488">UNSCT-HRNet: Modeling Anatomical Uncertainty for Landmark Detection in Total Hip Arthroplasty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Total hip arthroplasty (THA) relies on accurate landmark detection from radiographic images, but unstructured data caused by irregular patient postures or occluded anatomical markers pose significant challenges for existing methods. To address this, we propose UNSCT-HRNet (Unstructured CT - High-Resolution Net), a deep learning-based framework that integrates a Spatial Relationship Fusion (SRF) module and an Uncertainty Estimation (UE) module. The SRF module, utilizing coordinate convolution and polarized attention, enhances the model's ability to capture complex spatial relationships. Meanwhile, the UE module which based on entropy ensures predictions are anatomically relevant. For unstructured data, the proposed method can predict landmarks without relying on the fixed number of points, which shows higher accuracy and better robustness comparing with the existing methods. Our UNSCT-HRNet demonstrates over a 60% improvement across multiple metrics in unstructured data. The experimental results also reveal that our approach maintains good performance on the structured dataset. Overall, the proposed UNSCT-HRNet has the potential to be used as a new reliable, automated solution for THA surgical planning and postoperative monitoring.
<div id='section'>Paperid: <span id='pid'>701, <a href='https://arxiv.org/pdf/2411.02444.pdf' target='_blank'>https://arxiv.org/pdf/2411.02444.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoliang Wang, Chen Zhao, Feng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02444">MADOD: Generalizing OOD Detection to Unseen Domains via G-Invariance Meta-Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world machine learning applications often face simultaneous covariate and semantic shifts, challenging traditional domain generalization and out-of-distribution (OOD) detection methods. We introduce Meta-learned Across Domain Out-of-distribution Detection (MADOD), a novel framework designed to address both shifts concurrently. MADOD leverages meta-learning and G-invariance to enhance model generalizability and OOD detection in unseen domains. Our key innovation lies in task construction: we randomly designate in-distribution classes as pseudo-OODs within each meta-learning task, simulating OOD scenarios using existing data. This approach, combined with energy-based regularization, enables the learning of robust, domain-invariant features while calibrating decision boundaries for effective OOD detection. Operating in a test domain-agnostic setting, MADOD eliminates the need for adaptation during inference, making it suitable for scenarios where test data is unavailable. Extensive experiments on real-world and synthetic datasets demonstrate MADOD's superior performance in semantic OOD detection across unseen domains, achieving an AUPR improvement of 8.48% to 20.81%, while maintaining competitive in-distribution classification accuracy, representing a significant advancement in handling both covariate and semantic shifts.
<div id='section'>Paperid: <span id='pid'>702, <a href='https://arxiv.org/pdf/2410.19288.pdf' target='_blank'>https://arxiv.org/pdf/2410.19288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyuan Dong, Zhuotong Cai, Gilbert Hangel, Wolfgang Bogner, Georg Widhalm, Yaqing Huang, Qinghao Liang, Chenyu You, Chathura Kumaragamage, Robert K. Fulbright, Amit Mahajan, Amin Karbasi, John A. Onofrey, Robin A. de Graaf, James S. Duncan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19288">A Flow-based Truncated Denoising Diffusion Model for Super-resolution Magnetic Resonance Spectroscopic Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic Resonance Spectroscopic Imaging (MRSI) is a non-invasive imaging technique for studying metabolism and has become a crucial tool for understanding neurological diseases, cancers and diabetes. High spatial resolution MRSI is needed to characterize lesions, but in practice MRSI is acquired at low resolution due to time and sensitivity restrictions caused by the low metabolite concentrations. Therefore, there is an imperative need for a post-processing approach to generate high-resolution MRSI from low-resolution data that can be acquired fast and with high sensitivity. Deep learning-based super-resolution methods provided promising results for improving the spatial resolution of MRSI, but they still have limited capability to generate accurate and high-quality images. Recently, diffusion models have demonstrated superior learning capability than other generative models in various tasks, but sampling from diffusion models requires iterating through a large number of diffusion steps, which is time-consuming. This work introduces a Flow-based Truncated Denoising Diffusion Model (FTDDM) for super-resolution MRSI, which shortens the diffusion process by truncating the diffusion chain, and the truncated steps are estimated using a normalizing flow-based network. The network is conditioned on upscaling factors to enable multi-scale super-resolution. To train and evaluate the deep learning models, we developed a 1H-MRSI dataset acquired from 25 high-grade glioma patients. We demonstrate that FTDDM outperforms existing generative models while speeding up the sampling process by over 9-fold compared to the baseline diffusion model. Neuroradiologists' evaluations confirmed the clinical advantages of our method, which also supports uncertainty estimation and sharpness adjustment, extending its potential clinical applications.
<div id='section'>Paperid: <span id='pid'>703, <a href='https://arxiv.org/pdf/2410.15326.pdf' target='_blank'>https://arxiv.org/pdf/2410.15326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hsiu-Yuan Huang, Yutong Yang, Zhaoxi Zhang, Sanwoo Lee, Yunfang Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15326">A Survey of Uncertainty Estimation in LLMs: Theory Meets Practice</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As large language models (LLMs) continue to evolve, understanding and quantifying the uncertainty in their predictions is critical for enhancing application credibility. However, the existing literature relevant to LLM uncertainty estimation often relies on heuristic approaches, lacking systematic classification of the methods. In this survey, we clarify the definitions of uncertainty and confidence, highlighting their distinctions and implications for model predictions. On this basis, we integrate theoretical perspectives, including Bayesian inference, information theory, and ensemble strategies, to categorize various classes of uncertainty estimation methods derived from heuristic approaches. Additionally, we address challenges that arise when applying these methods to LLMs. We also explore techniques for incorporating uncertainty into diverse applications, including out-of-distribution detection, data annotation, and question clarification. Our review provides insights into uncertainty estimation from both definitional and theoretical angles, contributing to a comprehensive understanding of this critical aspect in LLMs. We aim to inspire the development of more reliable and effective uncertainty estimation approaches for LLMs in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>704, <a href='https://arxiv.org/pdf/2410.07617.pdf' target='_blank'>https://arxiv.org/pdf/2410.07617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ao Ke, Wenlong Chen, Chuanwen Feng, Yukun Cao, Xike Xie, S. Kevin Zhou, Lei Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07617">Prototype-based Optimal Transport for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting Out-of-Distribution (OOD) inputs is crucial for improving the reliability of deep neural networks in the real-world deployment. In this paper, inspired by the inherent distribution shift between ID and OOD data, we propose a novel method that leverages optimal transport to measure the distribution discrepancy between test inputs and ID prototypes. The resulting transport costs are used to quantify the individual contribution of each test input to the overall discrepancy, serving as a desirable measure for OOD detection. To address the issue that solely relying on the transport costs to ID prototypes is inadequate for identifying OOD inputs closer to ID data, we generate virtual outliers to approximate the OOD region via linear extrapolation. By combining the transport costs to ID prototypes with the costs to virtual outliers, the detection of OOD data near ID data is emphasized, thereby enhancing the distinction between ID and OOD inputs. Experiments demonstrate the superiority of our method over state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>705, <a href='https://arxiv.org/pdf/2410.01534.pdf' target='_blank'>https://arxiv.org/pdf/2410.01534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Tu, Weijian Deng, Tom Gedeon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01534">Toward a Holistic Evaluation of Robustness in CLIP Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contrastive Language-Image Pre-training (CLIP) models have shown significant potential, particularly in zero-shot classification across diverse distribution shifts. Building on existing evaluations of overall classification robustness, this work aims to provide a more comprehensive assessment of CLIP by introducing several new perspectives. First, we investigate their robustness to variations in specific visual factors. Second, we assess two critical safety objectives--confidence uncertainty and out-of-distribution detection--beyond mere classification accuracy. Third, we evaluate the finesse with which CLIP models bridge the image and text modalities. Fourth, we extend our examination to 3D awareness in CLIP models, moving beyond traditional 2D image understanding. Finally, we explore the interaction between vision and language encoders within modern large multimodal models (LMMs) that utilize CLIP as the visual backbone, focusing on how this interaction impacts classification robustness. In each aspect, we consider the impact of six factors on CLIP models: model architecture, training distribution, training set size, fine-tuning, contrastive loss, and test-time prompts. Our study uncovers several previously unknown insights into CLIP. For instance, the architecture of the visual encoder in CLIP plays a significant role in their robustness against 3D corruption. CLIP models tend to exhibit a bias towards shape when making predictions. Moreover, this bias tends to diminish after fine-tuning on ImageNet. Vision-language models like LLaVA, leveraging the CLIP vision encoder, could exhibit benefits in classification performance for challenging categories over CLIP alone. Our findings are poised to offer valuable guidance for enhancing the robustness and reliability of CLIP models.
<div id='section'>Paperid: <span id='pid'>706, <a href='https://arxiv.org/pdf/2410.01534.pdf' target='_blank'>https://arxiv.org/pdf/2410.01534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Tu, Weijian Deng, Tom Gedeon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01534">Toward a Holistic Evaluation of Robustness in CLIP Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contrastive Language-Image Pre-training (CLIP) models have shown significant potential, particularly in zero-shot classification across diverse distribution shifts. Building on existing evaluations of overall classification robustness, this work aims to provide a more comprehensive assessment of CLIP by introducing several new perspectives. First, we investigate their robustness to variations in specific visual factors. Second, we assess two critical safety objectives--confidence uncertainty and out-of-distribution detection--beyond mere classification accuracy. Third, we evaluate the finesse with which CLIP models bridge the image and text modalities. Fourth, we extend our examination to 3D awareness in CLIP models, moving beyond traditional 2D image understanding. Finally, we explore the interaction between vision and language encoders within modern large multimodal models (LMMs) that utilize CLIP as the visual backbone, focusing on how this interaction impacts classification robustness. In each aspect, we consider the impact of six factors on CLIP models: model architecture, training distribution, training set size, fine-tuning, contrastive loss, and test-time prompts. Our study uncovers several previously unknown insights into CLIP. For instance, the architecture of the visual encoder in CLIP plays a significant role in their robustness against 3D corruption. CLIP models tend to exhibit a bias towards shape when making predictions. Moreover, this bias tends to diminish after fine-tuning on ImageNet. Vision-language models like LLaVA, leveraging the CLIP vision encoder, could exhibit benefits in classification performance for challenging categories over CLIP alone. Our findings are poised to offer valuable guidance for enhancing the robustness and reliability of CLIP models.
<div id='section'>Paperid: <span id='pid'>707, <a href='https://arxiv.org/pdf/2409.12479.pdf' target='_blank'>https://arxiv.org/pdf/2409.12479.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeng-Lin Li, Ming-Ching Chang, Wei-Chao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.12479">Learning Multi-Manifold Embedding for Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is crucial for trustworthy AI in real-world applications. Leveraging recent advances in representation learning and latent embeddings, Various scoring algorithms estimate distributions beyond the training data. However, a single embedding space falls short in characterizing in-distribution data and defending against diverse OOD conditions. This paper introduces a novel Multi-Manifold Embedding Learning (MMEL) framework, optimizing hypersphere and hyperbolic spaces jointly for enhanced OOD detection. MMEL generates representative embeddings and employs a prototype-aware scoring function to differentiate OOD samples. It operates with very few OOD samples and requires no model retraining. Experiments on six open datasets demonstrate MMEL's significant reduction in FPR while maintaining a high AUC compared to state-of-the-art distance-based OOD detection methods. We analyze the effects of learning multiple manifolds and visualize OOD score distributions across datasets. Notably, enrolling ten OOD samples without retraining achieves comparable FPR and AUC to modern outlier exposure methods using 80 million outlier samples for model training.
<div id='section'>Paperid: <span id='pid'>708, <a href='https://arxiv.org/pdf/2409.07942.pdf' target='_blank'>https://arxiv.org/pdf/2409.07942.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guangxuan Song, Dongmei Fu, Zhongwei Qiu, Jintao Meng, Dawei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07942">Taylor-Sensus Network: Embracing Noise to Enlighten Uncertainty for Scientific Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial in scientific data for machine learning. Current uncertainty estimation methods mainly focus on the model's inherent uncertainty, while neglecting the explicit modeling of noise in the data. Furthermore, noise estimation methods typically rely on temporal or spatial dependencies, which can pose a significant challenge in structured scientific data where such dependencies among samples are often absent. To address these challenges in scientific research, we propose the Taylor-Sensus Network (TSNet). TSNet innovatively uses a Taylor series expansion to model complex, heteroscedastic noise and proposes a deep Taylor block for aware noise distribution. TSNet includes a noise-aware contrastive learning module and a data density perception module for aleatoric and epistemic uncertainty. Additionally, an uncertainty combination operator is used to integrate these uncertainties, and the network is trained using a novel heteroscedastic mean square error loss. TSNet demonstrates superior performance over mainstream and state-of-the-art methods in experiments, highlighting its potential in scientific research and noise resistance. It will be open-source to facilitate the community of "AI for Science".
<div id='section'>Paperid: <span id='pid'>709, <a href='https://arxiv.org/pdf/2407.14024.pdf' target='_blank'>https://arxiv.org/pdf/2407.14024.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sandesh Pokhrel, Sanjay Bhandari, Eduard Vazquez, Tryphon Lambrou, Prashnna Gyawali, Binod Bhattarai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14024">TTA-OOD: Test-time Augmentation for Improving Out-of-Distribution Detection in Gastrointestinal Vision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has significantly advanced the field of gastrointestinal vision, enhancing disease diagnosis capabilities. One major challenge in automating diagnosis within gastrointestinal settings is the detection of abnormal cases in endoscopic images. Due to the sparsity of data, this process of distinguishing normal from abnormal cases has faced significant challenges, particularly with rare and unseen conditions. To address this issue, we frame abnormality detection as an out-of-distribution (OOD) detection problem. In this setup, a model trained on In-Distribution (ID) data, which represents a healthy GI tract, can accurately identify healthy cases, while abnormalities are detected as OOD, regardless of their class. We introduce a test-time augmentation segment into the OOD detection pipeline, which enhances the distinction between ID and OOD examples, thereby improving the effectiveness of existing OOD methods with the same model. This augmentation shifts the pixel space, which translates into a more distinct semantic representation for OOD examples compared to ID examples. We evaluated our method against existing state-of-the-art OOD scores, showing improvements with test-time augmentation over the baseline approach.
<div id='section'>Paperid: <span id='pid'>710, <a href='https://arxiv.org/pdf/2406.12815.pdf' target='_blank'>https://arxiv.org/pdf/2406.12815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikolas Koutsoubis, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12815">Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable advancements, particularly in healthcare. Within medical imaging, ML models hold the promise of improving disease diagnoses, treatment planning, and post-treatment monitoring. Various computer vision tasks like image classification, object detection, and image segmentation are poised to become routine in clinical analysis. However, privacy concerns surrounding patient data hinder the assembly of large training datasets needed for developing and training accurate, robust, and generalizable models. Federated Learning (FL) emerges as a compelling solution, enabling organizations to collaborate on ML model training by sharing model training information (gradients) rather than data (e.g., medical images). FL's distributed learning framework facilitates inter-institutional collaboration while preserving patient privacy. However, FL, while robust in privacy preservation, faces several challenges. Sensitive information can still be gleaned from shared gradients that are passed on between organizations during model training. Additionally, in medical imaging, quantifying model confidence\uncertainty accurately is crucial due to the noise and artifacts present in the data. Uncertainty estimation in FL encounters unique hurdles due to data heterogeneity across organizations. This paper offers a comprehensive review of FL, privacy preservation, and uncertainty estimation, with a focus on medical imaging. Alongside a survey of current research, we identify gaps in the field and suggest future directions for FL research to enhance privacy and address noisy medical imaging data challenges.
<div id='section'>Paperid: <span id='pid'>711, <a href='https://arxiv.org/pdf/2406.09486.pdf' target='_blank'>https://arxiv.org/pdf/2406.09486.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shenghua Wan, Ziyuan Chen, Le Gan, Shuai Feng, De-Chuan Zhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09486">SeMOPO: Learning High-quality Model and Policy from Low-quality Offline Visual Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model-based offline reinforcement Learning (RL) is a promising approach that leverages existing data effectively in many real-world applications, especially those involving high-dimensional inputs like images and videos. To alleviate the distribution shift issue in offline RL, existing model-based methods heavily rely on the uncertainty of learned dynamics. However, the model uncertainty estimation becomes significantly biased when observations contain complex distractors with non-trivial dynamics. To address this challenge, we propose a new approach - \emph{Separated Model-based Offline Policy Optimization} (SeMOPO) - decomposing latent states into endogenous and exogenous parts via conservative sampling and estimating model uncertainty on the endogenous states only. We provide a theoretical guarantee of model uncertainty and performance bound of SeMOPO. To assess the efficacy, we construct the Low-Quality Vision Deep Data-Driven Datasets for RL (LQV-D4RL), where the data are collected by non-expert policy and the observations include moving distractors. Experimental results show that our method substantially outperforms all baseline methods, and further analytical experiments validate the critical designs in our method. The project website is \href{https://sites.google.com/view/semopo}{https://sites.google.com/view/semopo}.
<div id='section'>Paperid: <span id='pid'>712, <a href='https://arxiv.org/pdf/2406.08839.pdf' target='_blank'>https://arxiv.org/pdf/2406.08839.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenhui Xiao, Rodrigo Santa Cruz, David Ahmedt-Aristizabal, Olivier Salvado, Clinton Fookes, Leo Lebrat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08839">NeRF Director: Revisiting View Selection in Neural Volume Rendering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Rendering representations have significantly contributed to the field of 3D computer vision. Given their potential, considerable efforts have been invested to improve their performance. Nonetheless, the essential question of selecting training views is yet to be thoroughly investigated. This key aspect plays a vital role in achieving high-quality results and aligns with the well-known tenet of deep learning: "garbage in, garbage out". In this paper, we first illustrate the importance of view selection by demonstrating how a simple rotation of the test views within the most pervasive NeRF dataset can lead to consequential shifts in the performance rankings of state-of-the-art techniques. To address this challenge, we introduce a unified framework for view selection methods and devise a thorough benchmark to assess its impact. Significant improvements can be achieved without leveraging error or uncertainty estimation but focusing on uniform view coverage of the reconstructed object, resulting in a training-free approach. Using this technique, we show that high-quality renderings can be achieved faster by using fewer views. We conduct extensive experiments on both synthetic datasets and realistic data to demonstrate the effectiveness of our proposed method compared with random, conventional error-based, and uncertainty-guided view selection.
<div id='section'>Paperid: <span id='pid'>713, <a href='https://arxiv.org/pdf/2406.04306.pdf' target='_blank'>https://arxiv.org/pdf/2406.04306.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Aichberger, Kajetan Schweighofer, Mykyta Ielanskyi, Sepp Hochreiter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04306">Semantically Diverse Language Generation for Uncertainty Estimation in Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) can suffer from hallucinations when generating text. These hallucinations impede various applications in society and industry by making LLMs untrustworthy. Current LLMs generate text in an autoregressive fashion by predicting and appending text tokens. When an LLM is uncertain about the semantic meaning of the next tokens to generate, it is likely to start hallucinating. Thus, it has been suggested that hallucinations stem from predictive uncertainty. We introduce Semantically Diverse Language Generation (SDLG) to quantify predictive uncertainty in LLMs. SDLG steers the LLM to generate semantically diverse yet likely alternatives for an initially generated text. This approach provides a precise measure of aleatoric semantic uncertainty, detecting whether the initial text is likely to be hallucinated. Experiments on question-answering tasks demonstrate that SDLG consistently outperforms existing methods while being the most computationally efficient, setting a new standard for uncertainty estimation in LLMs.
<div id='section'>Paperid: <span id='pid'>714, <a href='https://arxiv.org/pdf/2406.00529.pdf' target='_blank'>https://arxiv.org/pdf/2406.00529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vivek Narayanaswamy, Kowshik Thopalli, Rushil Anirudh, Yamen Mubarka, Wesam Sakla, Jayaraman J. Thiagarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00529">On the Use of Anchoring for Training Vision Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anchoring is a recent, architecture-agnostic principle for training deep neural networks that has been shown to significantly improve uncertainty estimation, calibration, and extrapolation capabilities. In this paper, we systematically explore anchoring as a general protocol for training vision models, providing fundamental insights into its training and inference processes and their implications for generalization and safety. Despite its promise, we identify a critical problem in anchored training that can lead to an increased risk of learning undesirable shortcuts, thereby limiting its generalization capabilities. To address this, we introduce a new anchored training protocol that employs a simple regularizer to mitigate this issue and significantly enhances generalization. We empirically evaluate our proposed approach across datasets and architectures of varying scales and complexities, demonstrating substantial performance gains in generalization and safety metrics compared to the standard training protocol.
<div id='section'>Paperid: <span id='pid'>715, <a href='https://arxiv.org/pdf/2405.16146.pdf' target='_blank'>https://arxiv.org/pdf/2405.16146.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyi Chen, Yaohui Li, Haoxing Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16146">Dual-Adapter: Training-free Dual Adaptation for Few-shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the problem of few-shot out-of-distribution (OOD) detection, which aims to detect OOD samples from unseen categories during inference time with only a few labeled in-domain (ID) samples. Existing methods mainly focus on training task-aware prompts for OOD detection. However, training on few-shot data may cause severe overfitting and textual prompts alone may not be enough for effective detection. To tackle these problems, we propose a prior-based Training-free Dual Adaptation method (Dual-Adapter) to detect OOD samples from both textual and visual perspectives. Specifically, Dual-Adapter first extracts the most significant channels as positive features and designates the remaining less relevant channels as negative features. Then, it constructs both a positive adapter and a negative adapter from a dual perspective, thereby better leveraging previously outlooked or interfering features in the training dataset. In this way, Dual-Adapter can inherit the advantages of CLIP not having to train, but also excels in distinguishing between ID and OOD samples. Extensive experimental results on four benchmark datasets demonstrate the superiority of Dual-Adapter.
<div id='section'>Paperid: <span id='pid'>716, <a href='https://arxiv.org/pdf/2405.01691.pdf' target='_blank'>https://arxiv.org/pdf/2405.01691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenjiang Mao, Dong-You Jhong, Ao Wang, Ivan Ruchkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01691">Language-Enhanced Latent Representations for Out-of-Distribution Detection in Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential in autonomous driving, to determine when learning-based components encounter unexpected inputs. Traditional detectors typically use encoder models with fixed settings, thus lacking effective human interaction capabilities. With the rise of large foundation models, multimodal inputs offer the possibility of taking human language as a latent representation, thus enabling language-defined OOD detection. In this paper, we use the cosine similarity of image and text representations encoded by the multimodal model CLIP as a new representation to improve the transparency and controllability of latent encodings used for visual anomaly detection. We compare our approach with existing pre-trained encoders that can only produce latent representations that are meaningless from the user's standpoint. Our experiments on realistic driving data show that the language-based latent representation performs better than the traditional representation of the vision encoder and helps improve the detection performance when combined with standard representations.
<div id='section'>Paperid: <span id='pid'>717, <a href='https://arxiv.org/pdf/2404.18279.pdf' target='_blank'>https://arxiv.org/pdf/2404.18279.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zesheng Hong, Yubiao Yue, Yubin Chen, Lele Cong, Huanjie Lin, Yuanmei Luo, Mini Han Wang, Weidong Wang, Jialong Xu, Xiaoqi Yang, Hechang Chen, Zhenzhang Li, Sihong Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.18279">Out-of-distribution Detection in Medical Image Analysis: A survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computer-aided diagnostics has benefited from the development of deep learning-based computer vision techniques in these years. Traditional supervised deep learning methods assume that the test sample is drawn from the identical distribution as the training data. However, it is possible to encounter out-of-distribution samples in real-world clinical scenarios, which may cause silent failure in deep learning-based medical image analysis tasks. Recently, research has explored various out-of-distribution (OOD) detection situations and techniques to enable a trustworthy medical AI system. In this survey, we systematically review the recent advances in OOD detection in medical image analysis. We first explore several factors that may cause a distributional shift when using a deep-learning-based model in clinic scenarios, with three different types of distributional shift well defined on top of these factors. Then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy. Our discussion also includes evaluation protocols and metrics, as well as the challenge and a research direction lack of exploration.
<div id='section'>Paperid: <span id='pid'>718, <a href='https://arxiv.org/pdf/2404.15993.pdf' target='_blank'>https://arxiv.org/pdf/2404.15993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linyu Liu, Yu Pan, Xiaocheng Li, Guanting Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15993">Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we study the problem of uncertainty estimation and calibration for LLMs. We begin by formulating the uncertainty estimation problem, a relevant yet underexplored area in existing literature. We then propose a supervised approach that leverages labeled datasets to estimate the uncertainty in LLMs' responses. Based on the formulation, we illustrate the difference between the uncertainty estimation for LLMs and that for standard ML models and explain why the hidden neurons of the LLMs may contain uncertainty information. Our designed approach demonstrates the benefits of utilizing hidden activations to enhance uncertainty estimation across various tasks and shows robust transferability in out-of-distribution settings. We distinguish the uncertainty estimation task from the uncertainty calibration task and show that better uncertainty estimation leads to better calibration performance. Furthermore, our method is easy to implement and adaptable to different levels of model accessibility including black box, grey box, and white box.
<div id='section'>Paperid: <span id='pid'>719, <a href='https://arxiv.org/pdf/2404.07099.pdf' target='_blank'>https://arxiv.org/pdf/2404.07099.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linas Nasvytis, Kai Sandbrink, Jakob Foerster, Tim Franzmeyer, Christian Schroeder de Witt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07099">Rethinking Out-of-Distribution Detection for Reinforcement Learning: Advancing Methods for Evaluation and Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While reinforcement learning (RL) algorithms have been successfully applied across numerous sequential decision-making problems, their generalization to unforeseen testing environments remains a significant concern. In this paper, we study the problem of out-of-distribution (OOD) detection in RL, which focuses on identifying situations at test time that RL agents have not encountered in their training environments. We first propose a clarification of terminology for OOD detection in RL, which aligns it with the literature from other machine learning domains. We then present new benchmark scenarios for OOD detection, which introduce anomalies with temporal autocorrelation into different components of the agent-environment loop. We argue that such scenarios have been understudied in the current literature, despite their relevance to real-world situations. Confirming our theoretical predictions, our experimental results suggest that state-of-the-art OOD detectors are not able to identify such anomalies. To address this problem, we propose a novel method for OOD detection, which we call DEXTER (Detection via Extraction of Time Series Representations). By treating environment observations as time series data, DEXTER extracts salient time series features, and then leverages an ensemble of isolation forest algorithms to detect anomalies. We find that DEXTER can reliably identify anomalies across benchmark scenarios, exhibiting superior performance compared to both state-of-the-art OOD detectors and high-dimensional changepoint detectors adopted from statistics.
<div id='section'>Paperid: <span id='pid'>720, <a href='https://arxiv.org/pdf/2402.07452.pdf' target='_blank'>https://arxiv.org/pdf/2402.07452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinyu Ye, Shijing Chen, Dong Ni, Ruobing Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07452">TriAug: Out-of-Distribution Detection for Imbalanced Breast Lesion in Ultrasound</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Different diseases, such as histological subtypes of breast lesions, have severely varying incidence rates. Even trained with substantial amount of in-distribution (ID) data, models often encounter out-of-distribution (OOD) samples belonging to unseen classes in clinical reality. To address this, we propose a novel framework built upon a long-tailed OOD detection task for breast ultrasound images. It is equipped with a triplet state augmentation (TriAug) which improves ID classification accuracy while maintaining a promising OOD detection performance. Meanwhile, we designed a balanced sphere loss to handle the class imbalanced problem. Experimental results show that the model outperforms state-of-art OOD approaches both in ID classification (F1-score=42.12%) and OOD detection (AUROC=78.06%).
<div id='section'>Paperid: <span id='pid'>721, <a href='https://arxiv.org/pdf/2402.07417.pdf' target='_blank'>https://arxiv.org/pdf/2402.07417.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Tu, Weijian Deng, Dylan Campbell, Stephen Gould, Tom Gedeon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07417">An Empirical Study Into What Matters for Calibrating Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) have emerged as the dominant approach for zero-shot recognition, adept at handling diverse scenarios and significant distribution changes. However, their deployment in risk-sensitive areas requires a deeper understanding of their uncertainty estimation capabilities, a relatively uncharted area. In this study, we explore the calibration properties of VLMs across different architectures, datasets, and training strategies. In particular, we analyze the uncertainty estimation performance of VLMs when calibrated in one domain, label set or hierarchy level, and tested in a different one. Our findings reveal that while VLMs are not inherently calibrated for uncertainty, temperature scaling significantly and consistently improves calibration, even across shifts in distribution and changes in label set. Moreover, VLMs can be calibrated with a very small set of examples. Through detailed experimentation, we highlight the potential applications and importance of our insights, aiming for more reliable and effective use of VLMs in critical, real-world scenarios.
<div id='section'>Paperid: <span id='pid'>722, <a href='https://arxiv.org/pdf/2401.03350.pdf' target='_blank'>https://arxiv.org/pdf/2401.03350.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Puja Trivedi, Mark Heimann, Rushil Anirudh, Danai Koutra, Jayaraman J. Thiagarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03350">Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While graph neural networks (GNNs) are widely used for node and graph representation learning tasks, the reliability of GNN uncertainty estimates under distribution shifts remains relatively under-explored. Indeed, while post-hoc calibration strategies can be used to improve in-distribution calibration, they need not also improve calibration under distribution shift. However, techniques which produce GNNs with better intrinsic uncertainty estimates are particularly valuable, as they can always be combined with post-hoc strategies later. Therefore, in this work, we propose G-$Î$UQ, a novel training framework designed to improve intrinsic GNN uncertainty estimates. Our framework adapts the principle of stochastic data centering to graph data through novel graph anchoring strategies, and is able to support partially stochastic GNNs. While, the prevalent wisdom is that fully stochastic networks are necessary to obtain reliable estimates, we find that the functional diversity induced by our anchoring strategies when sampling hypotheses renders this unnecessary and allows us to support G-$Î$UQ on pretrained models. Indeed, through extensive evaluation under covariate, concept and graph size shifts, we show that G-$Î$UQ leads to better calibrated GNNs for node and graph classification. Further, it also improves performance on the uncertainty-based tasks of out-of-distribution detection and generalization gap estimation. Overall, our work provides insights into uncertainty estimation for GNNs, and demonstrates the utility of G-$Î$UQ in obtaining reliable estimates.
<div id='section'>Paperid: <span id='pid'>723, <a href='https://arxiv.org/pdf/2312.14452.pdf' target='_blank'>https://arxiv.org/pdf/2312.14452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soumya Suvra Ghosal, Yiyou Sun, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.14452">How to Overcome Curse-of-Dimensionality for Out-of-Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models deployed in the wild can be challenged by out-of-distribution (OOD) data from unknown classes. Recent advances in OOD detection rely on distance measures to distinguish samples that are relatively far away from the in-distribution (ID) data. Despite the promise, distance-based methods can suffer from the curse-of-dimensionality problem, which limits the efficacy in high-dimensional feature space. To combat this problem, we propose a novel framework, Subspace Nearest Neighbor (SNN), for OOD detection. In training, our method regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e. subspace). Subspace learning yields highly distinguishable distance measures between ID and OOD data. We provide comprehensive experiments and ablations to validate the efficacy of SNN. Compared to the current best distance-based method, SNN reduces the average FPR95 by 15.96% on the CIFAR-100 benchmark.
<div id='section'>Paperid: <span id='pid'>724, <a href='https://arxiv.org/pdf/2312.00836.pdf' target='_blank'>https://arxiv.org/pdf/2312.00836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoran Zhang, Daniel H. Pak, Shawn S. Ahn, Xiaoxiao Li, Chenyu You, Lawrence H. Staib, Albert J. Sinusas, Alex Wong, James S. Duncan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00836">Heteroscedastic Uncertainty Estimation Framework for Unsupervised Registration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning methods for unsupervised registration often rely on objectives that assume a uniform noise level across the spatial domain (e.g. mean-squared error loss), but noise distributions are often heteroscedastic and input-dependent in real-world medical images. Thus, this assumption often leads to degradation in registration performance, mainly due to the undesired influence of noise-induced outliers. To mitigate this, we propose a framework for heteroscedastic image uncertainty estimation that can adaptively reduce the influence of regions with high uncertainty during unsupervised registration. The framework consists of a collaborative training strategy for the displacement and variance estimators, and a novel image fidelity weighting scheme utilizing signal-to-noise ratios. Our approach prevents the model from being driven away by spurious gradients caused by the simplified homoscedastic assumption, leading to more accurate displacement estimation. To illustrate its versatility and effectiveness, we tested our framework on two representative registration architectures across three medical image datasets. Our method consistently outperforms baselines and produces sensible uncertainty estimates. The code is publicly available at \url{https://voldemort108x.github.io/hetero_uncertainty/}.
<div id='section'>Paperid: <span id='pid'>725, <a href='https://arxiv.org/pdf/2311.13374.pdf' target='_blank'>https://arxiv.org/pdf/2311.13374.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Winter, Nicolas Jourdan, Tristan Wirth, Volker Knauthe, Arjan Kuijper
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13374">An Empirical Study of Uncertainty Estimation Techniques for Detecting Drift in Data Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In safety-critical domains such as autonomous driving and medical diagnosis, the reliability of machine learning models is crucial. One significant challenge to reliability is concept drift, which can cause model deterioration over time. Traditionally, drift detectors rely on true labels, which are often scarce and costly. This study conducts a comprehensive empirical evaluation of using uncertainty values as substitutes for error rates in detecting drifts, aiming to alleviate the reliance on labeled post-deployment data. We examine five uncertainty estimation methods in conjunction with the ADWIN detector across seven real-world datasets. Our results reveal that while the SWAG method exhibits superior calibration, the overall accuracy in detecting drifts is not notably impacted by the choice of uncertainty estimation method, with even the most basic method demonstrating competitive performance. These findings offer valuable insights into the practical applicability of uncertainty-based drift detection in real-world, safety-critical applications.
<div id='section'>Paperid: <span id='pid'>726, <a href='https://arxiv.org/pdf/2308.07687.pdf' target='_blank'>https://arxiv.org/pdf/2308.07687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiyuan Gao, Chenchen Zhao, Lanqing Hong, Qiang Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07687">DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given a classifier, the inherent property of semantic Out-of-Distribution (OOD) samples is that their contents differ from all legal classes in terms of semantics, namely semantic mismatch. There is a recent work that directly applies it to OOD detection, which employs a conditional Generative Adversarial Network (cGAN) to enlarge semantic mismatch in the image space. While achieving remarkable OOD detection performance on small datasets, it is not applicable to ImageNet-scale datasets due to the difficulty in training cGANs with both input images and labels as conditions. As diffusion models are much easier to train and amenable to various conditions compared to cGANs, in this work, we propose to directly use pre-trained diffusion models for semantic mismatch-guided OOD detection, named DiffGuard. Specifically, given an OOD input image and the predicted label from the classifier, we try to enlarge the semantic difference between the reconstructed OOD image under these conditions and the original input image. We also present several test-time techniques to further strengthen such differences. Experimental results show that DiffGuard is effective on both Cifar-10 and hard cases of the large-scale ImageNet, and it can be easily combined with existing OOD detection techniques to achieve state-of-the-art OOD detection results.
<div id='section'>Paperid: <span id='pid'>727, <a href='https://arxiv.org/pdf/2308.00346.pdf' target='_blank'>https://arxiv.org/pdf/2308.00346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruoxi Qin, Linyuan Wang, Xuehui Du, Xingyuan Chen, Bin Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.00346">Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The deep neural network has attained significant efficiency in image recognition. However, it has vulnerable recognition robustness under extensive data uncertainty in practical applications. The uncertainty is attributed to the inevitable ambient noise and, more importantly, the possible adversarial attack. Dynamic methods can effectively improve the defense initiative in the arms race of attack and defense of adversarial examples. Different from the previous dynamic method depend on input or decision, this work explore the dynamic attributes in model level through dynamic ensemble selection technology to further protect the model from white-box attacks and improve the robustness. Specifically, in training phase the Dirichlet distribution is apply as prior of sub-models' predictive distribution, and the diversity constraint in parameter space is introduced under the lightweight sub-models to construct alternative ensembel model spaces. In test phase, the certain sub-models are dynamically selected based on their rank of uncertainty value for the final prediction to ensure the majority accurate principle in ensemble robustness and accuracy. Compared with the previous dynamic method and staic adversarial traning model, the presented approach can achieve significant robustness results without damaging accuracy by combining dynamics and diversity property.
<div id='section'>Paperid: <span id='pid'>728, <a href='https://arxiv.org/pdf/2306.09192.pdf' target='_blank'>https://arxiv.org/pdf/2306.09192.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chandramouli Sastry, Sri Harsha Dumpala, Sageev Oore
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09192">DiffAug: A Diffuse-and-Denoise Augmentation for Training Robust Classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce DiffAug, a simple and efficient diffusion-based augmentation technique to train image classifiers for the crucial yet challenging goal of improved classifier robustness. Applying DiffAug to a given example consists of one forward-diffusion step followed by one reverse-diffusion step. Using both ResNet-50 and Vision Transformer architectures, we comprehensively evaluate classifiers trained with DiffAug and demonstrate the surprising effectiveness of single-step reverse diffusion in improving robustness to covariate shifts, certified adversarial accuracy and out of distribution detection. When we combine DiffAug with other augmentations such as AugMix and DeepAugment we demonstrate further improved robustness. Finally, building on this approach, we also improve classifier-guided diffusion wherein we observe improvements in: (i) classifier-generalization, (ii) gradient quality (i.e., improved perceptual alignment) and (iii) image generation performance. We thus introduce a computationally efficient technique for training with improved robustness that does not require any additional data, and effectively complements existing augmentation approaches.
<div id='section'>Paperid: <span id='pid'>729, <a href='https://arxiv.org/pdf/2305.09610.pdf' target='_blank'>https://arxiv.org/pdf/2305.09610.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Denis Gudovskiy, Tomoyuki Okuno, Yohei Nakata
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09610">Concurrent Misclassification and Out-of-Distribution Detection for Semantic Segmentation via Energy-Based Normalizing Flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent semantic segmentation models accurately classify test-time examples that are similar to a training dataset distribution. However, their discriminative closed-set approach is not robust in practical data setups with distributional shifts and out-of-distribution (OOD) classes. As a result, the predicted probabilities can be very imprecise when used as confidence scores at test time. To address this, we propose a generative model for concurrent in-distribution misclassification (IDM) and OOD detection that relies on a normalizing flow framework. The proposed flow-based detector with an energy-based inputs (FlowEneDet) can extend previously deployed segmentation models without their time-consuming retraining. Our FlowEneDet results in a low-complexity architecture with marginal increase in the memory footprint. FlowEneDet achieves promising results on Cityscapes, Cityscapes-C, FishyScapes and SegmentMeIfYouCan benchmarks in IDM/OOD detection when applied to pretrained DeepLabV3+ and SegFormer semantic segmentation models.
<div id='section'>Paperid: <span id='pid'>730, <a href='https://arxiv.org/pdf/2304.09426.pdf' target='_blank'>https://arxiv.org/pdf/2304.09426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giung Nam, Sunguk Jang, Juho Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.09426">Decoupled Training for Long-Tailed Classification With Stochastic Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Decoupling representation learning and classifier learning has been shown to be effective in classification with long-tailed data. There are two main ingredients in constructing a decoupled learning scheme; 1) how to train the feature extractor for representation learning so that it provides generalizable representations and 2) how to re-train the classifier that constructs proper decision boundaries by handling class imbalances in long-tailed data. In this work, we first apply Stochastic Weight Averaging (SWA), an optimization technique for improving the generalization of deep neural networks, to obtain better generalizing feature extractors for long-tailed classification. We then propose a novel classifier re-training algorithm based on stochastic representation obtained from the SWA-Gaussian, a Gaussian perturbed SWA, and a self-distillation strategy that can harness the diverse stochastic representations based on uncertainty estimates to build more robust classifiers. Extensive experiments on CIFAR10/100-LT, ImageNet-LT, and iNaturalist-2018 benchmarks show that our proposed method improves upon previous methods both in terms of prediction accuracy and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>731, <a href='https://arxiv.org/pdf/2303.01284.pdf' target='_blank'>https://arxiv.org/pdf/2303.01284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liren Jin, Xieyuanli Chen, Julius RÃ¼ckin, Marija PopoviÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01284">NeU-NBV: Next Best View Planning Using Uncertainty Estimation in Image-Based Neural Rendering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous robotic tasks require actively perceiving the environment to achieve application-specific goals. In this paper, we address the problem of positioning an RGB camera to collect the most informative images to represent an unknown scene, given a limited measurement budget. We propose a novel mapless planning framework to iteratively plan the next best camera view based on collected image measurements. A key aspect of our approach is a new technique for uncertainty estimation in image-based neural rendering, which guides measurement acquisition at the most uncertain view among view candidates, thus maximising the information value during data collection. By incrementally adding new measurements into our image collection, our approach efficiently explores an unknown scene in a mapless manner. We show that our uncertainty estimation is generalisable and valuable for view planning in unknown scenes. Our planning experiments using synthetic and real-world data verify that our uncertainty-guided approach finds informative images leading to more accurate scene representations when compared against baselines.
<div id='section'>Paperid: <span id='pid'>732, <a href='https://arxiv.org/pdf/2302.09574.pdf' target='_blank'>https://arxiv.org/pdf/2302.09574.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Idan Achituve, Gal Chechik, Ethan Fetaya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.09574">Guided Deep Kernel Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Combining Gaussian processes with the expressive power of deep neural networks is commonly done nowadays through deep kernel learning (DKL). Unfortunately, due to the kernel optimization process, this often results in losing their Bayesian benefits. In this study, we present a novel approach for learning deep kernels by utilizing infinite-width neural networks. We propose to use the Neural Network Gaussian Process (NNGP) model as a guide to the DKL model in the optimization process. Our approach harnesses the reliable uncertainty estimation of the NNGPs to adapt the DKL target confidence when it encounters novel data points. As a result, we get the best of both worlds, we leverage the Bayesian behavior of the NNGP, namely its robustness to overfitting, and accurate uncertainty estimation, while maintaining the generalization abilities, scalability, and flexibility of deep kernels. Empirically, we show on multiple benchmark datasets of varying sizes and dimensionality, that our method is robust to overfitting, has good predictive performance, and provides reliable uncertainty estimations.
<div id='section'>Paperid: <span id='pid'>733, <a href='https://arxiv.org/pdf/2301.04421.pdf' target='_blank'>https://arxiv.org/pdf/2301.04421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenbo Shao, Yanchao Xu, Liang Peng, Jun Li, Hong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.04421">Failure Detection for Motion Prediction of Autonomous Driving: An Uncertainty Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motion prediction is essential for safe and efficient autonomous driving. However, the inexplicability and uncertainty of complex artificial intelligence models may lead to unpredictable failures of the motion prediction module, which may mislead the system to make unsafe decisions. Therefore, it is necessary to develop methods to guarantee reliable autonomous driving, where failure detection is a potential direction. Uncertainty estimates can be used to quantify the degree of confidence a model has in its predictions and may be valuable for failure detection. We propose a framework of failure detection for motion prediction from the uncertainty perspective, considering both motion uncertainty and model uncertainty, and formulate various uncertainty scores according to different prediction stages. The proposed approach is evaluated based on different motion prediction algorithms, uncertainty estimation methods, uncertainty scores, etc., and the results show that uncertainty is promising for failure detection for motion prediction but should be used with caution.
<div id='section'>Paperid: <span id='pid'>734, <a href='https://arxiv.org/pdf/2301.04414.pdf' target='_blank'>https://arxiv.org/pdf/2301.04414.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenbo Shao, Yanchao Xu, Jun Li, Chen Lv, Weida Wang, Hong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.04414">How Does Traffic Environment Quantitatively Affect the Autonomous Driving Prediction?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An accurate trajectory prediction is crucial for safe and efficient autonomous driving in complex traffic environments. In recent years, artificial intelligence has shown strong capabilities in improving prediction accuracy. However, its characteristics of inexplicability and uncertainty make it challenging to determine the traffic environmental effect on prediction explicitly, posing significant challenges to safety-critical decision-making. To address these challenges, this study proposes a trajectory prediction framework with the epistemic uncertainty estimation ability that outputs high uncertainty when confronting unforeseeable or unknown scenarios. The proposed framework is used to analyze the environmental effect on the prediction algorithm performance. In the analysis, the traffic environment is considered in terms of scenario features and shifts, respectively, where features are divided into kinematic features of a target agent, features of its surrounding traffic participants, and other features. In addition, feature correlation and importance analyses are performed to study the above features' influence on the prediction error and epistemic uncertainty. Further, a cross-dataset case study is conducted using multiple intersection datasets to investigate the impact of unavoidable distributional shifts in the real world on trajectory prediction. The results indicate that the deep ensemble-based method has advantages in improving prediction robustness and estimating epistemic uncertainty. The consistent conclusions are obtained by the feature correlation and importance analyses, including the conclusion that kinematic features of the target agent have relatively strong effects on the prediction error and epistemic uncertainty. Furthermore, the prediction failure caused by distributional shifts and the potential of the deep ensemble-based method are analyzed.
<div id='section'>Paperid: <span id='pid'>735, <a href='https://arxiv.org/pdf/2301.04257.pdf' target='_blank'>https://arxiv.org/pdf/2301.04257.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongha Kim, Jaesung Hwang, Jongjin Lee, Kunwoong Kim, Yongdai Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.04257">ODIM: Outlier Detection via Likelihood of Under-Fitted Generative Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The unsupervised outlier detection (UOD) problem refers to a task to identify inliers given training data which contain outliers as well as inliers, without any labeled information about inliers and outliers. It has been widely recognized that using fully-trained likelihood-based deep generative models (DGMs) often results in poor performance in distinguishing inliers from outliers. In this study, we claim that the likelihood itself could serve as powerful evidence for identifying inliers in UOD tasks, provided that DGMs are carefully under-fitted. Our approach begins with a novel observation called the inlier-memorization (IM) effect-when training a deep generative model with data including outliers, the model initially memorizes inliers before outliers. Based on this finding, we develop a new method called the outlier detection via the IM effect (ODIM). Remarkably, the ODIM requires only a few updates, making it computationally efficient-at least tens of times faster than other deep-learning-based algorithms. Also, the ODIM filters out outliers excellently, regardless of the data type, including tabular, image, and text data. To validate the superiority and efficiency of our method, we provide extensive empirical analyses on close to 60 datasets.
<div id='section'>Paperid: <span id='pid'>736, <a href='https://arxiv.org/pdf/2210.14037.pdf' target='_blank'>https://arxiv.org/pdf/2210.14037.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andreas Nugaard Holm, Dustin Wright, Isabelle Augenstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.14037">Revisiting Softmax for Uncertainty Approximation in Text Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty approximation in text classification is an important area with applications in domain adaptation and interpretability. One of the most widely used uncertainty approximation methods is Monte Carlo (MC) Dropout, which is computationally expensive as it requires multiple forward passes through the model. A cheaper alternative is to simply use the softmax based on a single forward pass without dropout to estimate model uncertainty. However, prior work has indicated that these predictions tend to be overconfident. In this paper, we perform a thorough empirical analysis of these methods on five datasets with two base neural architectures in order to identify the trade-offs between the two. We compare both softmax and an efficient version of MC Dropout on their uncertainty approximations and downstream text classification performance, while weighing their runtime (cost) against performance (benefit). We find that, while MC dropout produces the best uncertainty approximations, using a simple softmax leads to competitive and in some cases better uncertainty estimation for text classification at a much lower computational cost, suggesting that softmax can in fact be a sufficient uncertainty estimate when computational resources are a concern.
<div id='section'>Paperid: <span id='pid'>737, <a href='https://arxiv.org/pdf/2210.01742.pdf' target='_blank'>https://arxiv.org/pdf/2210.01742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charles Guille-Escuret, Pau Rodriguez, David Vazquez, Ioannis Mitliagkas, Joao Monteiro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.01742">CADet: Fully Self-Supervised Out-Of-Distribution Detection With Contrastive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Handling out-of-distribution (OOD) samples has become a major stake in the real-world deployment of machine learning systems. This work explores the use of self-supervised contrastive learning to the simultaneous detection of two types of OOD samples: unseen classes and adversarial perturbations. First, we pair self-supervised contrastive learning with the maximum mean discrepancy (MMD) two-sample test. This approach enables us to robustly test whether two independent sets of samples originate from the same distribution, and we demonstrate its effectiveness by discriminating between CIFAR-10 and CIFAR-10.1 with higher confidence than previous work. Motivated by this success, we introduce CADet (Contrastive Anomaly Detection), a novel method for OOD detection of single samples. CADet draws inspiration from MMD, but leverages the similarity between contrastive transformations of a same sample. CADet outperforms existing adversarial detection methods in identifying adversarially perturbed samples on ImageNet and achieves comparable performance to unseen label detection methods on two challenging benchmarks: ImageNet-O and iNaturalist. Significantly, CADet is fully self-supervised and requires neither labels for in-distribution samples nor access to OOD examples.
<div id='section'>Paperid: <span id='pid'>738, <a href='https://arxiv.org/pdf/2206.00794.pdf' target='_blank'>https://arxiv.org/pdf/2206.00794.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanket Jantre, Shrijita Bhattacharya, Nathan M. Urban, Byung-Jun Yoon, Tapabrata Maiti, Prasanna Balaprakash, Sandeep Madireddy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.00794">Sequential Bayesian Neural Subnetwork Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep ensembles have emerged as a powerful technique for improving predictive performance and enhancing model robustness across various applications by leveraging model diversity. However, traditional deep ensemble methods are often computationally expensive and rely on deterministic models, which may limit their flexibility. Additionally, while sparse subnetworks of dense models have shown promise in matching the performance of their dense counterparts and even enhancing robustness, existing methods for inducing sparsity typically incur training costs comparable to those of training a single dense model, as they either gradually prune the network during training or apply thresholding post-training. In light of these challenges, we propose an approach for sequential ensembling of dynamic Bayesian neural subnetworks that consistently maintains reduced model complexity throughout the training process while generating diverse ensembles in a single forward pass. Our approach involves an initial exploration phase to identify high-performing regions within the parameter space, followed by multiple exploitation phases that take advantage of the compactness of the sparse model. These exploitation phases quickly converge to different minima in the energy landscape, corresponding to high-performing subnetworks that together form a diverse and robust ensemble. We empirically demonstrate that our proposed approach outperforms traditional dense and sparse deterministic and Bayesian ensemble models in terms of prediction accuracy, uncertainty estimation, out-of-distribution detection, and adversarial robustness.
<div id='section'>Paperid: <span id='pid'>739, <a href='https://arxiv.org/pdf/2205.10650.pdf' target='_blank'>https://arxiv.org/pdf/2205.10650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mark S Graham, Petru-Daniel Tudosiu, Paul Wright, Walter Hugo Lopez Pinaya, U Jean-Marie, Yee Mah, James Teo, Rolf H JÃ¤ger, David Werring, Parashkev Nachev, Sebastien Ourselin, M Jorge Cardoso
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.10650">Transformer-based out-of-distribution detection for clinically safe segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In a clinical setting it is essential that deployed image processing systems are robust to the full range of inputs they might encounter and, in particular, do not make confidently wrong predictions. The most popular approach to safe processing is to train networks that can provide a measure of their uncertainty, but these tend to fail for inputs that are far outside the training data distribution. Recently, generative modelling approaches have been proposed as an alternative; these can quantify the likelihood of a data sample explicitly, filtering out any out-of-distribution (OOD) samples before further processing is performed. In this work, we focus on image segmentation and evaluate several approaches to network uncertainty in the far-OOD and near-OOD cases for the task of segmenting haemorrhages in head CTs. We find all of these approaches are unsuitable for safe segmentation as they provide confidently wrong predictions when operating OOD. We propose performing full 3D OOD detection using a VQ-GAN to provide a compressed latent representation of the image and a transformer to estimate the data likelihood. Our approach successfully identifies images in both the far- and near-OOD cases. We find a strong relationship between image likelihood and the quality of a model's segmentation, making this approach viable for filtering images unsuitable for segmentation. To our knowledge, this is the first time transformers have been applied to perform OOD detection on 3D image data. Code is available at github.com/marksgraham/transformer-ood.
<div id='section'>Paperid: <span id='pid'>740, <a href='https://arxiv.org/pdf/2203.06618.pdf' target='_blank'>https://arxiv.org/pdf/2203.06618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matias Quintana, Till Stoeckmann, June Young Park, Marian Turowski, Veit Hagenmeyer, Clayton Miller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.06618">ALDI++: Automatic and parameter-less discord and outlier detection for building energy load profiles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven building energy prediction is an integral part of the process for measurement and verification, building benchmarking, and building-to-grid interaction. The ASHRAE Great Energy Predictor III (GEPIII) machine learning competition used an extensive meter data set to crowdsource the most accurate machine learning workflow for whole building energy prediction. A significant component of the winning solutions was the pre-processing phase to remove anomalous training data. Contemporary pre-processing methods focus on filtering statistical threshold values or deep learning methods requiring training data and multiple hyper-parameters. A recent method named ALDI (Automated Load profile Discord Identification) managed to identify these discords using matrix profile, but the technique still requires user-defined parameters. We develop ALDI++, a method based on the previous work that bypasses user-defined parameters and takes advantage of discord similarity. We evaluate ALDI++ against a statistical threshold, variational auto-encoder, and the original ALDI as baselines in classifying discords and energy forecasting scenarios. Our results demonstrate that while the classification performance improvement over the original method is marginal, ALDI++ helps achieve the best forecasting error improving 6% over the winning's team approach with six times less computation time.
<div id='section'>Paperid: <span id='pid'>741, <a href='https://arxiv.org/pdf/2510.07569.pdf' target='_blank'>https://arxiv.org/pdf/2510.07569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prabhant Singh, Pieter Gijsbers, Elif Ceren Gok Yildirim, Murat Onur Yildirim, Joaquin Vanschoren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.07569">Automated Machine Learning for Unsupervised Tabular Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present LOTUS (Learning to Learn with Optimal Transport for Unsupervised Scenarios), a simple yet effective method to perform model selection for multiple unsupervised machine learning(ML) tasks such as outlier detection and clustering. Our intuition behind this work is that a machine learning pipeline will perform well in a new dataset if it previously worked well on datasets with a similar underlying data distribution. We use Optimal Transport distances to find this similarity between unlabeled tabular datasets and recommend machine learning pipelines with one unified single method on two downstream unsupervised tasks: outlier detection and clustering. We present the effectiveness of our approach with experiments against strong baselines and show that LOTUS is a very promising first step toward model selection for multiple unsupervised ML tasks.
<div id='section'>Paperid: <span id='pid'>742, <a href='https://arxiv.org/pdf/2509.08280.pdf' target='_blank'>https://arxiv.org/pdf/2509.08280.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyeonseok Kim, Byeongkeun Kang, Yeejin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08280">Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generalized zero-shot semantic segmentation of 3D point clouds aims to classify each point into both seen and unseen classes. A significant challenge with these models is their tendency to make biased predictions, often favoring the classes encountered during training. This problem is more pronounced in 3D applications, where the scale of the training data is typically smaller than in image-based tasks. To address this problem, we propose a novel method called E3DPC-GZSL, which reduces overconfident predictions towards seen classes without relying on separate classifiers for seen and unseen data. E3DPC-GZSL tackles the overconfidence problem by integrating an evidence-based uncertainty estimator into a classifier. This estimator is then used to adjust prediction probabilities using a dynamic calibrated stacking factor that accounts for pointwise prediction uncertainty. In addition, E3DPC-GZSL introduces a novel training strategy that improves uncertainty estimation by refining the semantic space. This is achieved by merging learnable parameters with text-derived features, thereby improving model optimization for unseen data. Extensive experiments demonstrate that the proposed approach achieves state-of-the-art performance on generalized zero-shot semantic segmentation datasets, including ScanNet v2 and S3DIS.
<div id='section'>Paperid: <span id='pid'>743, <a href='https://arxiv.org/pdf/2509.05778.pdf' target='_blank'>https://arxiv.org/pdf/2509.05778.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arantxa Urrea-Castaño, Nicolás Segura-Kunsagi, Juan Luis Suárez-Díaz, Rosana Montes, Francisco Herrera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05778">DCV-ROOD Evaluation Framework: Dual Cross-Validation for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection plays a key role in enhancing the robustness of artificial intelligence systems by identifying inputs that differ significantly from the training distribution, thereby preventing unreliable predictions and enabling appropriate fallback mechanisms. Developing reliable OOD detection methods is a significant challenge, and rigorous evaluation of these techniques is essential for ensuring their effectiveness, as it allows researchers to assess their performance under diverse conditions and to identify potential limitations or failure modes. Cross-validation (CV) has proven to be a highly effective tool for providing a reasonable estimate of the performance of a learning algorithm. Although OOD scenarios exhibit particular characteristics, an appropriate adaptation of CV can lead to a suitable evaluation framework for this setting. This work proposes a dual CV framework for robust evaluation of OOD detection models, aimed at improving the reliability of their assessment. The proposed evaluation framework aims to effectively integrate in-distribution (ID) and OOD data while accounting for their differing characteristics. To achieve this, ID data are partitioned using a conventional approach, whereas OOD data are divided by grouping samples based on their classes. Furthermore, we analyze the context of data with class hierarchy to propose a data splitting that considers the entire class hierarchy to obtain fair ID-OOD partitions to apply the proposed evaluation framework. This framework is called Dual Cross-Validation for Robust Out-of-Distribution Detection (DCV-ROOD). To test the validity of the evaluation framework, we selected a set of state-of-the-art OOD detection methods, both with and without outlier exposure. The results show that the method achieves very fast convergence to the true performance.
<div id='section'>Paperid: <span id='pid'>744, <a href='https://arxiv.org/pdf/2508.15529.pdf' target='_blank'>https://arxiv.org/pdf/2508.15529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiyuan Tan, Yingying Shen, Haohui Zhu, Zhiwei Zhan, Shan Zhao, Mingfei Tu, Hongcheng Luo, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15529">ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Synthesizing extrapolated views from recorded driving logs is critical for simulating driving scenes for autonomous driving vehicles, yet it remains a challenging task. Recent methods leverage generative priors as pseudo ground truth, but often lead to poor geometric consistency and over-smoothed renderings. To address these limitations, we propose ExtraGS, a holistic framework for trajectory extrapolation that integrates both geometric and generative priors. At the core of ExtraGS is a novel Road Surface Gaussian(RSG) representation based on a hybrid Gaussian-Signed Distance Function (SDF) design, and Far Field Gaussians (FFG) that use learnable scaling factors to efficiently handle distant objects. Furthermore, we develop a self-supervised uncertainty estimation framework based on spherical harmonics that enables selective integration of generative priors only where extrapolation artifacts occur. Extensive experiments on multiple datasets, diverse multi-camera setups, and various generative priors demonstrate that ExtraGS significantly enhances the realism and geometric consistency of extrapolated views, while preserving high fidelity along the original trajectory.
<div id='section'>Paperid: <span id='pid'>745, <a href='https://arxiv.org/pdf/2508.06101.pdf' target='_blank'>https://arxiv.org/pdf/2508.06101.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yachun Mi, Xingyang He, Shixin Sun, Yu Li, Yanting Li, Zhixuan Li, Jian Jin, Chen Hui, Shaohui Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06101">UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the digital age, advanced image editing tools pose a serious threat to the integrity of visual content, making image forgery detection and localization a key research focus. Most existing Image Manipulation Localization (IML) methods rely on discriminative learning and require large, high-quality annotated datasets. However, current datasets lack sufficient scale and diversity, limiting model performance in real-world scenarios. To overcome this, recent studies have explored Constrained IML (CIML), which generates pixel-level annotations through algorithmic supervision. However, existing CIML approaches often depend on complex multi-stage pipelines, making the annotation process inefficient. In this work, we propose a novel generative framework based on diffusion models, named UGD-IML, which for the first time unifies both IML and CIML tasks within a single framework. By learning the underlying data distribution, generative diffusion models inherently reduce the reliance on large-scale labeled datasets, allowing our approach to perform effectively even under limited data conditions. In addition, by leveraging a class embedding mechanism and a parameter-sharing design, our model seamlessly switches between IML and CIML modes without extra components or training overhead. Furthermore, the end-to-end design enables our model to avoid cumbersome steps in the data annotation process. Extensive experimental results on multiple datasets demonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and 4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the proposed method also excels in uncertainty estimation, visualization and robustness.
<div id='section'>Paperid: <span id='pid'>746, <a href='https://arxiv.org/pdf/2508.00568.pdf' target='_blank'>https://arxiv.org/pdf/2508.00568.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingchao Xie, Oussema Dhaouadi, Weirong Chen, Johannes Meier, Jacques Kaiser, Daniel Cremers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00568">CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and augmented reality, with unsupervised approaches eliminating the need for expensive ground-truth labels. However, these methods struggle when dynamic objects violate the static scene assumption, leading to erroneous pose estimations. We tackle this problem by uncertainty modeling, which is a commonly used technique that creates robust masks to filter out dynamic objects and occlusions without requiring explicit motion segmentation. Traditional uncertainty modeling considers only single-frame information, overlooking the uncertainties across consecutive frames. Our key insight is that uncertainty must be propagated and combined across temporal frames to effectively identify unreliable regions, particularly in dynamic scenes. To address this challenge, we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end approach that combines target frame uncertainty with projected reference frame uncertainty using a principled probabilistic formulation. Built upon vision transformer backbones, our model simultaneously learns depth, uncertainty estimation, and camera poses. Consequently, experiments on the KITTI and nuScenes datasets demonstrate significant improvements over previous unsupervised monocular end-to-end two-frame-based methods and exhibit strong performance in challenging highway scenes where other approaches often fail. Additionally, comprehensive ablation studies validate the effectiveness of cross-frame uncertainty propagation.
<div id='section'>Paperid: <span id='pid'>747, <a href='https://arxiv.org/pdf/2507.22429.pdf' target='_blank'>https://arxiv.org/pdf/2507.22429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erwin de Gelder, Maren Buermann, Olaf Op den Camp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22429">Comparing Normalizing Flows with Kernel Density Estimation in Estimating Risk of Automated Driving Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of safety validation methods is essential for the safe deployment and operation of Automated Driving Systems (ADSs). One of the goals of safety validation is to prospectively evaluate the risk of an ADS dealing with real-world traffic. Scenario-based assessment is a widely-used approach, where test cases are derived from real-world driving data. To allow for a quantitative analysis of the system performance, the exposure of the scenarios must be accurately estimated. The exposure of scenarios at parameter level is expressed using a Probability Density Function (PDF). However, assumptions about the PDF, such as parameter independence, can introduce errors, while avoiding assumptions often leads to oversimplified models with limited parameters to mitigate the curse of dimensionality.
  This paper considers the use of Normalizing Flows (NF) for estimating the PDF of the parameters. NF are a class of generative models that transform a simple base distribution into a complex one using a sequence of invertible and differentiable mappings, enabling flexible, high-dimensional density estimation without restrictive assumptions on the PDF's shape. We demonstrate the effectiveness of NF in quantifying risk and risk uncertainty of an ADS, comparing its performance with Kernel Density Estimation (KDE), a traditional method for non-parametric PDF estimation. While NF require more computational resources compared to KDE, NF is less sensitive to the curse of dimensionality. As a result, NF can improve risk uncertainty estimation, offering a more precise assessment of an ADS's safety.
  This work illustrates the potential of NF in scenario-based safety. Future work involves experimenting more with using NF for scenario generation and optimizing the NF architecture, transformation types, and training hyperparameters to further enhance their applicability.
<div id='section'>Paperid: <span id='pid'>748, <a href='https://arxiv.org/pdf/2507.19418.pdf' target='_blank'>https://arxiv.org/pdf/2507.19418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiwei Lou, Yuanpeng He, Rongchao Zhang, Yongzhi Cao, Hanpin Wang, Yu Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19418">DEFNet: Multitasks-based Deep Evidential Fusion Network for Blind Image Quality Assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Blind image quality assessment (BIQA) methods often incorporate auxiliary tasks to improve performance. However, existing approaches face limitations due to insufficient integration and a lack of flexible uncertainty estimation, leading to suboptimal performance. To address these challenges, we propose a multitasks-based Deep Evidential Fusion Network (DEFNet) for BIQA, which performs multitask optimization with the assistance of scene and distortion type classification tasks. To achieve a more robust and reliable representation, we design a novel trustworthy information fusion strategy. It first combines diverse features and patterns across sub-regions to enhance information richness, and then performs local-global information fusion by balancing fine-grained details with coarse-grained context. Moreover, DEFNet exploits advanced uncertainty estimation technique inspired by evidential learning with the help of normal-inverse gamma distribution mixture. Extensive experiments on both synthetic and authentic distortion datasets demonstrate the effectiveness and robustness of the proposed framework. Additional evaluation and analysis are carried out to highlight its strong generalization capability and adaptability to previously unseen scenarios.
<div id='section'>Paperid: <span id='pid'>749, <a href='https://arxiv.org/pdf/2506.17633.pdf' target='_blank'>https://arxiv.org/pdf/2506.17633.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Fang, Arvind Easwaran, Blaise Genest
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17633">Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection attempts to distinguish outlier samples to prevent models trained on the in-distribution (ID) dataset from producing unavailable outputs. Most OOD detection methods require many IID samples for training, which seriously limits their real-world applications. To this end, we target a challenging setting: few-shot OOD detection, where {Only a few {\em labeled ID} samples are available.} Therefore, few-shot OOD detection is much more challenging than the traditional OOD detection setting. Previous few-shot OOD detection works ignore the distinct diversity between different classes. In this paper, we propose a novel network: Adaptive Multi-prompt Contrastive Network (AMCN), which adapts the ID-OOD separation boundary by learning inter- and intra-class distribution. To compensate for the absence of OOD and scarcity of ID {\em image samples}, we leverage CLIP, connecting text with images, engineering learnable ID and OOD {\em textual prompts}. Specifically, we first generate adaptive prompts (learnable ID prompts, label-fixed OOD prompts and label-adaptive OOD prompts). Then, we generate an adaptive class boundary for each class by introducing a class-wise threshold. Finally, we propose a prompt-guided ID-OOD separation module to control the margin between ID and OOD prompts. Experimental results show that AMCN outperforms other state-of-the-art works.
<div id='section'>Paperid: <span id='pid'>750, <a href='https://arxiv.org/pdf/2506.17564.pdf' target='_blank'>https://arxiv.org/pdf/2506.17564.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lakshita Dodeja, Karl Schmeckpeper, Shivam Vats, Thomas Weng, Mingxi Jia, George Konidaris, Stefanie Tellex
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17564">Accelerating Residual Reinforcement Learning with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Residual Reinforcement Learning (RL) is a popular approach for adapting pretrained policies by learning a lightweight residual policy that provides corrective actions. While Residual RL is more sample-efficient than finetuning the entire base policy, existing methods struggle with sparse rewards and are designed for deterministic base policies. We propose two improvements to Residual RL that further enhance its sample efficiency and make it suitable for stochastic base policies. First, we leverage uncertainty estimates of the base policy to focus exploration on regions in which the base policy is not confident. Second, we propose a simple modification to off-policy residual learning that allows it to observe base actions and better handle stochastic base policies. We evaluate our method with both Gaussian-based and Diffusion-based stochastic base policies on tasks from Robosuite and D4RL, and compare against state-of-the-art finetuning methods, demo-augmented RL methods, and other residual RL methods. Our algorithm significantly outperforms existing baselines in a variety of simulation benchmark environments. We also deploy our learned polices in the real world to demonstrate their robustness with zero-shot sim-to-real transfer.
<div id='section'>Paperid: <span id='pid'>751, <a href='https://arxiv.org/pdf/2506.10718.pdf' target='_blank'>https://arxiv.org/pdf/2506.10718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefan Roth, Aydin Sezgin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10718">Anomaly Detection for Sensing Security</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Various approaches in the field of physical layer security involve anomaly detection, such as physical layer authentication, sensing attacks, and anti-tampering solutions. Depending on the context in which these approaches are applied, anomaly detection needs to be computationally lightweight, resilient to changes in temperature and environment, and robust against phase noise. We adapt moving average filters, autoregression filters and Kalman filters to provide predictions of feature vectors that fulfill the above criteria. Different hypothesis test designs are employed that allow omnidirectional and unidirectional outlier detection. In a case study, a sensing attack is investigated that employs the described algorithms with various channel features based on commodity WiFi devices. Thereby, various combinations of algorithms and channel features show effectiveness for motion detection by an attacker. Countermeasures only utilizing transmit power randomization are shown insufficient to mitigate such attacks if the attacker has access to channel state information (CSI) measurements, suggesting that mitigation solutions might require frequency-variant randomization.
<div id='section'>Paperid: <span id='pid'>752, <a href='https://arxiv.org/pdf/2505.22199.pdf' target='_blank'>https://arxiv.org/pdf/2505.22199.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyue Hu, Zhibin Duan, Bo Chen, Mingyuan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22199">Enhancing Uncertainty Estimation and Interpretability via Bayesian Non-negative Decision Layer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although deep neural networks have demonstrated significant success due to their powerful expressiveness, most models struggle to meet practical requirements for uncertainty estimation. Concurrently, the entangled nature of deep neural networks leads to a multifaceted problem, where various localized explanation techniques reveal that multiple unrelated features influence the decisions, thereby undermining interpretability. To address these challenges, we develop a Bayesian Non-negative Decision Layer (BNDL), which reformulates deep neural networks as a conditional Bayesian non-negative factor analysis. By leveraging stochastic latent variables, the BNDL can model complex dependencies and provide robust uncertainty estimation. Moreover, the sparsity and non-negativity of the latent variables encourage the model to learn disentangled representations and decision layers, thereby improving interpretability. We also offer theoretical guarantees that BNDL can achieve effective disentangled learning. In addition, we developed a corresponding variational inference method utilizing a Weibull variational inference network to approximate the posterior distribution of the latent variables. Our experimental results demonstrate that with enhanced disentanglement capabilities, BNDL not only improves the model's accuracy but also provides reliable uncertainty estimation and improved interpretability.
<div id='section'>Paperid: <span id='pid'>753, <a href='https://arxiv.org/pdf/2505.04253.pdf' target='_blank'>https://arxiv.org/pdf/2505.04253.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maria Marina, Nikolay Ivanov, Sergey Pletenev, Mikhail Salnikov, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04253">LLM-Independent Adaptive RAG: Let the Question Speak for Itself</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models~(LLMs) are prone to hallucinations, and Retrieval-Augmented Generation (RAG) helps mitigate this, but at a high computational cost while risking misinformation. Adaptive retrieval aims to retrieve only when necessary, but existing approaches rely on LLM-based uncertainty estimation, which remain inefficient and impractical. In this study, we introduce lightweight LLM-independent adaptive retrieval methods based on external information. We investigated 27 features, organized into 7 groups, and their hybrid combinations. We evaluated these methods on 6 QA datasets, assessing the QA performance and efficiency. The results show that our approach matches the performance of complex LLM-based methods while achieving significant efficiency gains, demonstrating the potential of external information for adaptive retrieval.
<div id='section'>Paperid: <span id='pid'>754, <a href='https://arxiv.org/pdf/2504.18421.pdf' target='_blank'>https://arxiv.org/pdf/2504.18421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars Ullrich, Zurab Mujirishvili, Knut Graichen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18421">Enhancing System Self-Awareness and Trust of AI: A Case Study in Trajectory Prediction and Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the trajectory planning of automated driving, data-driven statistical artificial intelligence (AI) methods are increasingly established for predicting the emergent behavior of other road users. While these methods achieve exceptional performance in defined datasets, they usually rely on the independent and identically distributed (i.i.d.) assumption and thus tend to be vulnerable to distribution shifts that occur in the real world. In addition, these methods lack explainability due to their black box nature, which poses further challenges in terms of the approval process and social trustworthiness. Therefore, in order to use the capabilities of data-driven statistical AI methods in a reliable and trustworthy manner, the concept of TrustMHE is introduced and investigated in this paper. TrustMHE represents a complementary approach, independent of the underlying AI systems, that combines AI-driven out-of-distribution detection with control-driven moving horizon estimation (MHE) to enable not only detection and monitoring, but also intervention. The effectiveness of the proposed TrustMHE is evaluated and proven in three simulation scenarios.
<div id='section'>Paperid: <span id='pid'>755, <a href='https://arxiv.org/pdf/2504.16680.pdf' target='_blank'>https://arxiv.org/pdf/2504.16680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhao Li, Andreas Krause, Marco Hutter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16680">Offline Robotic World Model: Learning Robotic Policies without a Physics Simulator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement Learning (RL) has demonstrated impressive capabilities in robotic control but remains challenging due to high sample complexity, safety concerns, and the sim-to-real gap. While offline RL eliminates the need for risky real-world exploration by learning from pre-collected data, it suffers from distributional shift, limiting policy generalization. Model-Based RL (MBRL) addresses this by leveraging predictive models for synthetic rollouts, yet existing approaches often lack robust uncertainty estimation, leading to compounding errors in offline settings. We introduce Offline Robotic World Model (RWM-O), a model-based approach that explicitly estimates epistemic uncertainty to improve policy learning without reliance on a physics simulator. By integrating these uncertainty estimates into policy optimization, our approach penalizes unreliable transitions, reducing overfitting to model errors and enhancing stability. Experimental results show that RWM-O improves generalization and safety, enabling policy learning purely from real-world data and advancing scalable, data-efficient RL for robotics.
<div id='section'>Paperid: <span id='pid'>756, <a href='https://arxiv.org/pdf/2504.16262.pdf' target='_blank'>https://arxiv.org/pdf/2504.16262.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junn Yong Loo, Michelle Adeline, Julia Kaiwen Lau, Fang Yu Leong, Hwa Hui Tew, Arghya Pal, Vishnu Monn Baskaran, Chee-Ming Ting, RaphaÃ«l C. -W. Phan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16262">Learning Energy-Based Generative Models via Potential Flow: A Variational Principle Approach to Probability Density Homotopy Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Energy-based models (EBMs) are a powerful class of probabilistic generative models due to their flexibility and interpretability. However, relationships between potential flows and explicit EBMs remain underexplored, while contrastive divergence training via implicit Markov chain Monte Carlo (MCMC) sampling is often unstable and expensive in high-dimensional settings. In this paper, we propose Variational Potential Flow Bayes (VPFB), a new energy-based generative framework that eliminates the need for implicit MCMC sampling and does not rely on auxiliary networks or cooperative training. VPFB learns an energy-parameterized potential flow by constructing a flow-driven density homotopy that is matched to the data distribution through a variational loss minimizing the Kullback-Leibler divergence between the flow-driven and marginal homotopies. This principled formulation enables robust and efficient generative modeling while preserving the interpretability of EBMs. Experimental results on image generation, interpolation, out-of-distribution detection, and compositional generation confirm the effectiveness of VPFB, showing that our method performs competitively with existing approaches in terms of sample quality and versatility across diverse generative modeling tasks.
<div id='section'>Paperid: <span id='pid'>757, <a href='https://arxiv.org/pdf/2504.13569.pdf' target='_blank'>https://arxiv.org/pdf/2504.13569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Djohan Bonnet, Kellian Cottart, Tifenn Hirtzlin, Tarcisius Januel, Thomas Dalgaty, Elisa Vianello, Damien Querlioz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13569">Bayesian continual learning and forgetting in neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological synapses effortlessly balance memory retention and flexibility, yet artificial neural networks still struggle with the extremes of catastrophic forgetting and catastrophic remembering. Here, we introduce Metaplasticity from Synaptic Uncertainty (MESU), a Bayesian framework that updates network parameters according their uncertainty. This approach allows a principled combination of learning and forgetting that ensures that critical knowledge is preserved while unused or outdated information is gradually released. Unlike standard Bayesian approaches -- which risk becoming overly constrained, and popular continual-learning methods that rely on explicit task boundaries, MESU seamlessly adapts to streaming data. It further provides reliable epistemic uncertainty estimates, allowing out-of-distribution detection, the only computational cost being to sample the weights multiple times to provide proper output statistics. Experiments on image-classification benchmarks demonstrate that MESU mitigates catastrophic forgetting, while maintaining plasticity for new tasks. When training 200 sequential permuted MNIST tasks, MESU outperforms established continual learning techniques in terms of accuracy, capability to learn additional tasks, and out-of-distribution data detection. Additionally, due to its non-reliance on task boundaries, MESU outperforms conventional learning techniques on the incremental training of CIFAR-100 tasks consistently in a wide range of scenarios. Our results unify ideas from metaplasticity, Bayesian inference, and Hessian-based regularization, offering a biologically-inspired pathway to robust, perpetual learning.
<div id='section'>Paperid: <span id='pid'>758, <a href='https://arxiv.org/pdf/2504.03440.pdf' target='_blank'>https://arxiv.org/pdf/2504.03440.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mirko Borszukovszki, Ivo Pascal de Jong, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03440">Know What You do Not Know: Verbalized Uncertainty Estimation Robustness on Corrupted Images in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To leverage the full potential of Large Language Models (LLMs) it is crucial to have some information on their answers' uncertainty. This means that the model has to be able to quantify how certain it is in the correctness of a given response. Bad uncertainty estimates can lead to overconfident wrong answers undermining trust in these models. Quite a lot of research has been done on language models that work with text inputs and provide text outputs. Still, since the visual capabilities have been added to these models recently, there has not been much progress on the uncertainty of Visual Language Models (VLMs). We tested three state-of-the-art VLMs on corrupted image data. We found that the severity of the corruption negatively impacted the models' ability to estimate their uncertainty and the models also showed overconfidence in most of the experiments.
<div id='section'>Paperid: <span id='pid'>759, <a href='https://arxiv.org/pdf/2503.14665.pdf' target='_blank'>https://arxiv.org/pdf/2503.14665.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Parker Ewen, Hao Chen, Seth Isaacson, Joey Wilson, Katherine A. Skinner, Ram Vasudevan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14665">These Magic Moments: Differentiable Uncertainty Quantification of Radiance Field Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel approach to uncertainty quantification for radiance fields by leveraging higher-order moments of the rendering equation. Uncertainty quantification is crucial for downstream tasks including view planning and scene understanding, where safety and robustness are paramount. However, the high dimensionality and complexity of radiance fields pose significant challenges for uncertainty quantification, limiting the use of these uncertainty quantification methods in high-speed decision-making. We demonstrate that the probabilistic nature of the rendering process enables efficient and differentiable computation of higher-order moments for radiance field outputs, including color, depth, and semantic predictions. Our method outperforms existing radiance field uncertainty estimation techniques while offering a more direct, computationally efficient, and differentiable formulation without the need for post-processing. Beyond uncertainty quantification, we also illustrate the utility of our approach in downstream applications such as next-best-view (NBV) selection and active ray sampling for neural radiance field training. Extensive experiments on synthetic and real-world scenes confirm the efficacy of our approach, which achieves state-of-the-art performance while maintaining simplicity.
<div id='section'>Paperid: <span id='pid'>760, <a href='https://arxiv.org/pdf/2503.13317.pdf' target='_blank'>https://arxiv.org/pdf/2503.13317.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Enrico Foglia, Benjamin Bobbia, Nikita Durasov, Michael Bauerheim, Pascal Fua, Stephane Moreau, Thierry Jardin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13317">Do you understand epistemic uncertainty? Think again! Rigorous frequentist epistemic uncertainty estimation in regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantifying model uncertainty is critical for understanding prediction reliability, yet distinguishing between aleatoric and epistemic uncertainty remains challenging. We extend recent work from classification to regression to provide a novel frequentist approach to epistemic and aleatoric uncertainty estimation. We train models to generate conditional predictions by feeding their initial output back as an additional input. This method allows for a rigorous measurement of model uncertainty by observing how prediction responses change when conditioned on the model's previous answer. We provide a complete theoretical framework to analyze epistemic uncertainty in regression in a frequentist way, and explain how it can be exploited in practice to gauge a model's uncertainty, with minimal changes to the original architecture.
<div id='section'>Paperid: <span id='pid'>761, <a href='https://arxiv.org/pdf/2503.11339.pdf' target='_blank'>https://arxiv.org/pdf/2503.11339.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moritz A. Zanger, Pascal R. Van der Vaart, Wendelin BÃ¶hmer, Matthijs T. J. Spaan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.11339">Contextual Similarity Distillation: Ensemble Uncertainties with a Single Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is a critical aspect of reinforcement learning and deep learning, with numerous applications ranging from efficient exploration and stable offline reinforcement learning to outlier detection in medical diagnostics. The scale of modern neural networks, however, complicates the use of many theoretically well-motivated approaches such as full Bayesian inference. Approximate methods like deep ensembles can provide reliable uncertainty estimates but still remain computationally expensive. In this work, we propose contextual similarity distillation, a novel approach that explicitly estimates the variance of an ensemble of deep neural networks with a single model, without ever learning or evaluating such an ensemble in the first place. Our method builds on the predictable learning dynamics of wide neural networks, governed by the neural tangent kernel, to derive an efficient approximation of the predictive variance of an infinite ensemble. Specifically, we reinterpret the computation of ensemble variance as a supervised regression problem with kernel similarities as regression targets. The resulting model can estimate predictive variance at inference time with a single forward pass, and can make use of unlabeled target-domain data or data augmentations to refine its uncertainty estimates. We empirically validate our method across a variety of out-of-distribution detection benchmarks and sparse-reward reinforcement learning environments. We find that our single-model method performs competitively and sometimes superior to ensemble-based baselines and serves as a reliable signal for efficient exploration. These results, we believe, position contextual similarity distillation as a principled and scalable alternative for uncertainty quantification in reinforcement learning and general deep learning.
<div id='section'>Paperid: <span id='pid'>762, <a href='https://arxiv.org/pdf/2502.10691.pdf' target='_blank'>https://arxiv.org/pdf/2502.10691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Yousuf Harun, Jhair Gallardo, Christopher Kanan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.10691">Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection and OOD generalization are widely studied in Deep Neural Networks (DNNs), yet their relationship remains poorly understood. We empirically show that the degree of Neural Collapse (NC) in a network layer is inversely related with these objectives: stronger NC improves OOD detection but degrades generalization, while weaker NC enhances generalization at the cost of detection. This trade-off suggests that a single feature space cannot simultaneously achieve both tasks. To address this, we develop a theoretical framework linking NC to OOD detection and generalization. We show that entropy regularization mitigates NC to improve generalization, while a fixed Simplex Equiangular Tight Frame (ETF) projector enforces NC for better detection. Based on these insights, we propose a method to control NC at different DNN layers. In experiments, our method excels at both tasks across OOD datasets and DNN architectures. Code for our experiments is available at: https://yousuf907.github.io/ncoodg
<div id='section'>Paperid: <span id='pid'>763, <a href='https://arxiv.org/pdf/2502.01035.pdf' target='_blank'>https://arxiv.org/pdf/2502.01035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiuhong Xiao, Giuseppe Loianno
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01035">UASTHN: Uncertainty-Aware Deep Homography Estimation for UAV Satellite-Thermal Geo-localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geo-localization is an essential component of Unmanned Aerial Vehicle (UAV) navigation systems to ensure precise absolute self-localization in outdoor environments. To address the challenges of GPS signal interruptions or low illumination, Thermal Geo-localization (TG) employs aerial thermal imagery to align with reference satellite maps to accurately determine the UAV's location. However, existing TG methods lack uncertainty measurement in their outputs, compromising system robustness in the presence of textureless or corrupted thermal images, self-similar or outdated satellite maps, geometric noises, or thermal images exceeding satellite maps. To overcome these limitations, this paper presents UASTHN, a novel approach for Uncertainty Estimation (UE) in Deep Homography Estimation (DHE) tasks for TG applications. Specifically, we introduce a novel Crop-based Test-Time Augmentation (CropTTA) strategy, which leverages the homography consensus of cropped image views to effectively measure data uncertainty. This approach is complemented by Deep Ensembles (DE) employed for model uncertainty, offering comparable performance with improved efficiency and seamless integration with any DHE model. Extensive experiments across multiple DHE models demonstrate the effectiveness and efficiency of CropTTA in TG applications. Analysis of detected failure cases underscores the improved reliability of CropTTA under challenging conditions. Finally, we demonstrate the capability of combining CropTTA and DE for a comprehensive assessment of both data and model uncertainty. Our research provides profound insights into the broader intersection of localization and uncertainty estimation. The code and models are publicly available.
<div id='section'>Paperid: <span id='pid'>764, <a href='https://arxiv.org/pdf/2502.00662.pdf' target='_blank'>https://arxiv.org/pdf/2502.00662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yimu Wang, Evelien Riddell, Adrian Chow, Sean Sedwards, Krzysztof Czarnecki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00662">Mitigating the Modality Gap: Few-Shot Out-of-Distribution Detection with Multi-modal Prototypes and Image Bias Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing vision-language model (VLM)-based methods for out-of-distribution (OOD) detection typically rely on similarity scores between input images and in-distribution (ID) text prototypes. However, the modality gap between image and text often results in high false positive rates, as OOD samples can exhibit high similarity to ID text prototypes. To mitigate the impact of this modality gap, we propose incorporating ID image prototypes along with ID text prototypes. We present theoretical analysis and empirical evidence indicating that this approach enhances VLM-based OOD detection performance without any additional training. To further reduce the gap between image and text, we introduce a novel few-shot tuning framework, SUPREME, comprising biased prompts generation (BPG) and image-text consistency (ITC) modules. BPG enhances image-text fusion and improves generalization by conditioning ID text prototypes on the Gaussian-based estimated image domain bias; ITC reduces the modality gap by minimizing intra- and inter-modal distances. Moreover, inspired by our theoretical and empirical findings, we introduce a novel OOD score $S_{\textit{GMP}}$, leveraging uni- and cross-modal similarities. Finally, we present extensive experiments to demonstrate that SUPREME consistently outperforms existing VLM-based OOD detection methods.
<div id='section'>Paperid: <span id='pid'>765, <a href='https://arxiv.org/pdf/2502.00290.pdf' target='_blank'>https://arxiv.org/pdf/2502.00290.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huan Ma, Jingdong Chen, Joey Tianyi Zhou, Guangyu Wang, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00290">Estimating LLM Uncertainty with Evidence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the past few years, Large Language Models (LLMs) have developed rapidly and are widely applied in various domains. However, LLMs face the issue of hallucinations, generating responses that may be unreliable when the models lack relevant knowledge. To be aware of potential hallucinations, uncertainty estimation methods have been introduced, and most of them have confirmed that reliability lies in critical tokens. However, probability-based methods perform poorly in identifying token reliability, limiting their practical utility. In this paper, we reveal that the probability-based method fails to estimate token reliability due to the loss of evidence strength information which is accumulated in the training stage. Therefore, we present Logits-induced token uncertainty (LogTokU), a framework for estimating decoupled token uncertainty in LLMs, enabling real-time uncertainty estimation without requiring multiple sampling processes. We employ evidence modeling to implement LogTokU and use the estimated uncertainty to guide downstream tasks. The experimental results demonstrate that LogTokU has significant effectiveness and promise.
<div id='section'>Paperid: <span id='pid'>766, <a href='https://arxiv.org/pdf/2412.15668.pdf' target='_blank'>https://arxiv.org/pdf/2412.15668.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Fang, Arvind Easwaran, Blaise Genest, Ponnuthurai Nagaratnam Suganthan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15668">Adaptive Hierarchical Graph Cut for Multi-granularity Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper focuses on a significant yet challenging task: out-of-distribution detection (OOD detection), which aims to distinguish and reject test samples with semantic shifts, so as to prevent models trained on in-distribution (ID) data from producing unreliable predictions. Although previous works have made decent success, they are ineffective for real-world challenging applications since these methods simply regard all unlabeled data as OOD data and ignore the case that different datasets have different label granularity. For example, "cat" on CIFAR-10 and "tabby cat" on Tiny-ImageNet share the same semantics but have different labels due to various label granularity. To this end, in this paper, we propose a novel Adaptive Hierarchical Graph Cut network (AHGC) to deeply explore the semantic relationship between different images. Specifically, we construct a hierarchical KNN graph to evaluate the similarities between different images based on the cosine similarity. Based on the linkage and density information of the graph, we cut the graph into multiple subgraphs to integrate these semantics-similar samples. If the labeled percentage in a subgraph is larger than a threshold, we will assign the label with the highest percentage to unlabeled images. To further improve the model generalization, we augment each image into two augmentation versions, and maximize the similarity between the two versions. Finally, we leverage the similarity score for OOD detection. Extensive experiments on two challenging benchmarks (CIFAR- 10 and CIFAR-100) illustrate that in representative cases, AHGC outperforms state-of-the-art OOD detection methods by 81.24% on CIFAR-100 and by 40.47% on CIFAR-10 in terms of "FPR95", which shows the effectiveness of our AHGC.
<div id='section'>Paperid: <span id='pid'>767, <a href='https://arxiv.org/pdf/2412.06284.pdf' target='_blank'>https://arxiv.org/pdf/2412.06284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Fang, Arvind Easwaran, Blaise Genest, Ponnuthurai Nagaratnam Suganthan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06284">Your Data Is Not Perfect: Towards Cross-Domain Out-of-Distribution Detection in Class-Imbalanced Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Previous OOD detection systems only focus on the semantic gap between ID and OOD samples. Besides the semantic gap, we are faced with two additional gaps: the domain gap between source and target domains, and the class-imbalance gap between different classes. In fact, similar objects from different domains should belong to the same class. In this paper, we introduce a realistic yet challenging setting: class-imbalanced cross-domain OOD detection (CCOD), which contains a well-labeled (but usually small) source set for training and conducts OOD detection on an unlabeled (but usually larger) target set for testing. We do not assume that the target domain contains only OOD classes or that it is class-balanced: the distribution among classes of the target dataset need not be the same as the source dataset. To tackle this challenging setting with an OOD detection system, we propose a novel uncertainty-aware adaptive semantic alignment (UASA) network based on a prototype-based alignment strategy. Specifically, we first build label-driven prototypes in the source domain and utilize these prototypes for target classification to close the domain gap. Rather than utilizing fixed thresholds for OOD detection, we generate adaptive sample-wise thresholds to handle the semantic gap. Finally, we conduct uncertainty-aware clustering to group semantically similar target samples to relieve the class-imbalance gap. Extensive experiments on three challenging benchmarks demonstrate that our proposed UASA outperforms state-of-the-art methods by a large margin.
<div id='section'>Paperid: <span id='pid'>768, <a href='https://arxiv.org/pdf/2410.23910.pdf' target='_blank'>https://arxiv.org/pdf/2410.23910.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Durasov, Rafid Mahmood, Jiwoong Choi, Marc T. Law, James Lucas, Pascal Fua, Jose M. Alvarez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.23910">Uncertainty Estimation for 3D Object Detection via Evidential Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>3D object detection is an essential task for computer vision applications in autonomous vehicles and robotics. However, models often struggle to quantify detection reliability, leading to poor performance on unfamiliar scenes. We introduce a framework for quantifying uncertainty in 3D object detection by leveraging an evidential learning loss on Bird's Eye View representations in the 3D detector. These uncertainty estimates require minimal computational overhead and are generalizable across different architectures. We demonstrate both the efficacy and importance of these uncertainty estimates on identifying out-of-distribution scenes, poorly localized objects, and missing (false negative) detections; our framework consistently improves over baselines by 10-20% on average. Finally, we integrate this suite of tasks into a system where a 3D object detector auto-labels driving scenes and our uncertainty estimates verify label correctness before the labels are used to train a second model. Here, our uncertainty-driven verification results in a 1% improvement in mAP and a 1-2% improvement in NDS.
<div id='section'>Paperid: <span id='pid'>769, <a href='https://arxiv.org/pdf/2410.19996.pdf' target='_blank'>https://arxiv.org/pdf/2410.19996.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxin Chen, Zijian Wu, Adam Schmidt, Septimiu E. Salcudean
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19996">A-MFST: Adaptive Multi-Flow Sparse Tracker for Real-Time Tissue Tracking Under Occlusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose: Tissue tracking is critical for downstream tasks in robot-assisted surgery. The Sparse Efficient Neural Depth and Deformation (SENDD) model has previously demonstrated accurate and real-time sparse point tracking, but struggled with occlusion handling. This work extends SENDD to enhance occlusion detection and tracking consistency while maintaining real-time performance. Methods: We use the Segment Anything Model2 (SAM2) to detect and mask occlusions by surgical tools, and we develop and integrate into SENDD an Adaptive Multi-Flow Sparse Tracker (A-MFST) with forward-backward consistency metrics, to enhance occlusion and uncertainty estimation. A-MFST is an unsupervised variant of the Multi-Flow Dense Tracker (MFT). Results: We evaluate our approach on the STIR dataset and demonstrate a significant improvement in tracking accuracy under occlusion, reducing average tracking errors by 12 percent in Mean Endpoint Error (MEE) and showing a 6 percent improvement in the averaged accuracy over thresholds of 4, 8, 16, 32, and 64 pixels. The incorporation of forward-backward consistency further improves the selection of optimal tracking paths, reducing drift and enhancing robustness. Notably, these improvements were achieved without compromising the model's real-time capabilities. Conclusions: Using A-MFST and SAM2, we enhance SENDD's ability to track tissue in real time under instrument and tissue occlusions.
<div id='section'>Paperid: <span id='pid'>770, <a href='https://arxiv.org/pdf/2410.06422.pdf' target='_blank'>https://arxiv.org/pdf/2410.06422.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael J. Kenney, Katerina G. Malollari, Sergei V. Kalinin, Maxim Ziatdinov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06422">Predicting Battery Capacity Fade Using Probabilistic Machine Learning Models With and Without Pre-Trained Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lithium-ion batteries are a key energy storage technology driving revolutions in mobile electronics, electric vehicles and renewable energy storage. Capacity retention is a vital performance measure that is frequently utilized to assess whether these batteries have approached their end-of-life. Machine learning (ML) offers a powerful tool for predicting capacity degradation based on past data, and, potentially, prior physical knowledge, but the degree to which an ML prediction can be trusted is of significant practical importance in situations where consequential decisions must be made based on battery state of health. This study explores the efficacy of fully Bayesian machine learning in forecasting battery health with the quantification of uncertainty in its predictions. Specifically, we implemented three probabilistic ML approaches and evaluated the accuracy of their predictions and uncertainty estimates: a standard Gaussian process (GP), a structured Gaussian process (sGP), and a fully Bayesian neural network (BNN). In typical applications of GP and sGP, their hyperparameters are learned from a single sample while, in contrast, BNNs are typically pre-trained on an existing dataset to learn the weight distributions before being used for inference. This difference in methodology gives the BNN an advantage in learning global trends in a dataset and makes BNNs a good choice when training data is available. However, we show that pre-training can also be leveraged for GP and sGP approaches to learn the prior distributions of the hyperparameters and that in the case of the pre-trained sGP, similar accuracy and improved uncertainty estimation compared to the BNN can be achieved. This approach offers a framework for a broad range of probabilistic machine learning scenarios where past data is available and can be used to learn priors for (hyper)parameters of probabilistic ML models.
<div id='section'>Paperid: <span id='pid'>771, <a href='https://arxiv.org/pdf/2409.06407.pdf' target='_blank'>https://arxiv.org/pdf/2409.06407.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcus Klasson, Riccardo Mereu, Juho Kannala, Arno Solin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06407">Sources of Uncertainty in 3D Scene Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The process of 3D scene reconstruction can be affected by numerous uncertainty sources in real-world scenes. While Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (GS) achieve high-fidelity rendering, they lack built-in mechanisms to directly address or quantify uncertainties arising from the presence of noise, occlusions, confounding outliers, and imprecise camera pose inputs. In this paper, we introduce a taxonomy that categorizes different sources of uncertainty inherent in these methods. Moreover, we extend NeRF- and GS-based methods with uncertainty estimation techniques, including learning uncertainty outputs and ensembles, and perform an empirical study to assess their ability to capture the sensitivity of the reconstruction. Our study highlights the need for addressing various uncertainty aspects when designing NeRF/GS-based methods for uncertainty-aware 3D reconstruction.
<div id='section'>Paperid: <span id='pid'>772, <a href='https://arxiv.org/pdf/2409.02770.pdf' target='_blank'>https://arxiv.org/pdf/2409.02770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mazen Soufi, Yoshito Otake, Makoto Iwasa, Keisuke Uemura, Tomoki Hakotani, Masahiro Hashimoto, Yoshitake Yamada, Minoru Yamada, Yoichi Yokoyama, Masahiro Jinzaki, Suzushi Kusano, Masaki Takao, Seiji Okada, Nobuhiko Sugano, Yoshinobu Sato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02770">Validation of musculoskeletal segmentation model with uncertainty estimation for bone and muscle assessment in hip-to-knee clinical CT images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based image segmentation has allowed for the fully automated, accurate, and rapid analysis of musculoskeletal (MSK) structures from medical images. However, current approaches were either applied only to 2D cross-sectional images, addressed few structures, or were validated on small datasets, which limit the application in large-scale databases. This study aimed to validate an improved deep learning model for volumetric MSK segmentation of the hip and thigh with uncertainty estimation from clinical computed tomography (CT) images. Databases of CT images from multiple manufacturers/scanners, disease status, and patient positioning were used. The segmentation accuracy, and accuracy in estimating the structures volume and density, i.e., mean HU, were evaluated. An approach for segmentation failure detection based on predictive uncertainty was also investigated. The model has shown an overall improvement with respect to all segmentation accuracy and structure volume/density evaluation metrics. The predictive uncertainty yielded large areas under the receiver operating characteristic (AUROC) curves (AUROCs>=.95) in detecting inaccurate and failed segmentations. The high segmentation and muscle volume/density estimation accuracy, along with the high accuracy in failure detection based on the predictive uncertainty, exhibited the model's reliability for analyzing individual MSK structures in large-scale CT databases.
<div id='section'>Paperid: <span id='pid'>773, <a href='https://arxiv.org/pdf/2407.21740.pdf' target='_blank'>https://arxiv.org/pdf/2407.21740.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhibin Duan, Tiansheng Wen, Yifei Wang, Chen Zhu, Bo Chen, Mingyuan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21740">Contrastive Factor Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Factor analysis, often regarded as a Bayesian variant of matrix factorization, offers superior capabilities in capturing uncertainty, modeling complex dependencies, and ensuring robustness. As the deep learning era arrives, factor analysis is receiving less and less attention due to their limited expressive ability. On the contrary, contrastive learning has emerged as a potent technique with demonstrated efficacy in unsupervised representational learning. While the two methods are different paradigms, recent theoretical analysis has revealed the mathematical equivalence between contrastive learning and matrix factorization, providing a potential possibility for factor analysis combined with contrastive learning. Motivated by the interconnectedness of contrastive learning, matrix factorization, and factor analysis, this paper introduces a novel Contrastive Factor Analysis framework, aiming to leverage factor analysis's advantageous properties within the realm of contrastive learning. To further leverage the interpretability properties of non-negative factor analysis, which can learn disentangled representations, contrastive factor analysis is extended to a non-negative version. Finally, extensive experimental validation showcases the efficacy of the proposed contrastive (non-negative) factor analysis methodology across multiple key properties, including expressiveness, robustness, interpretability, and accurate uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>774, <a href='https://arxiv.org/pdf/2406.11278.pdf' target='_blank'>https://arxiv.org/pdf/2406.11278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Duygu Nur Yaldiz, Yavuz Faruk Bakman, Baturalp Buyukates, Chenyang Tao, Anil Ramakrishna, Dimitrios Dimitriadis, Jieyu Zhao, Salman Avestimehr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11278">Do Not Design, Learn: A Trainable Scoring Function for Uncertainty Estimation in Generative LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation (UE) of generative large language models (LLMs) is crucial for evaluating the reliability of generated sequences. A significant subset of UE methods utilize token probabilities to assess uncertainty, aggregating multiple token probabilities into a single UE score using a scoring function. Existing scoring functions for probability-based UE, such as length-normalized scoring and semantic contribution-based weighting, are designed to solve certain aspects of the problem but exhibit limitations, including the inability to handle biased probabilities and complex semantic dependencies between tokens. To address these issues, in this work, we propose Learnable Response Scoring (LARS) function, a novel scoring function that leverages supervised data to capture complex dependencies between tokens and probabilities, thereby producing more reliable and calibrated response scores in computing the uncertainty of LLM generations. Our comprehensive experiments across question-answering and arithmetical reasoning tasks with various datasets demonstrate that LARS significantly outperforms existing scoring functions, achieving improvements of up to 16\% AUROC score.
<div id='section'>Paperid: <span id='pid'>775, <a href='https://arxiv.org/pdf/2405.20003.pdf' target='_blank'>https://arxiv.org/pdf/2405.20003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Nikitin, Jannik Kossen, Yarin Gal, Pekka Marttinen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.20003">Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification in Large Language Models (LLMs) is crucial for applications where safety and reliability are important. In particular, uncertainty can be used to improve the trustworthiness of LLMs by detecting factually incorrect model responses, commonly called hallucinations. Critically, one should seek to capture the model's semantic uncertainty, i.e., the uncertainty over the meanings of LLM outputs, rather than uncertainty over lexical or syntactic variations that do not affect answer correctness. To address this problem, we propose Kernel Language Entropy (KLE), a novel method for uncertainty estimation in white- and black-box LLMs. KLE defines positive semidefinite unit trace kernels to encode the semantic similarities of LLM outputs and quantifies uncertainty using the von Neumann entropy. It considers pairwise semantic dependencies between answers (or semantic clusters), providing more fine-grained uncertainty estimates than previous methods based on hard clustering of answers. We theoretically prove that KLE generalizes the previous state-of-the-art method called semantic entropy and empirically demonstrate that it improves uncertainty quantification performance across multiple natural language generation datasets and LLM architectures.
<div id='section'>Paperid: <span id='pid'>776, <a href='https://arxiv.org/pdf/2405.11533.pdf' target='_blank'>https://arxiv.org/pdf/2405.11533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shani Goren, Ido Galil, Ran El-Yaniv
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11533">Hierarchical Selective Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying deep neural networks for risk-sensitive tasks necessitates an uncertainty estimation mechanism. This paper introduces hierarchical selective classification, extending selective classification to a hierarchical setting. Our approach leverages the inherent structure of class relationships, enabling models to reduce the specificity of their predictions when faced with uncertainty. In this paper, we first formalize hierarchical risk and coverage, and introduce hierarchical risk-coverage curves. Next, we develop algorithms for hierarchical selective classification (which we refer to as "inference rules"), and propose an efficient algorithm that guarantees a target accuracy constraint with high probability. Lastly, we conduct extensive empirical studies on over a thousand ImageNet classifiers, revealing that training regimes such as CLIP, pretraining on ImageNet21k and knowledge distillation boost hierarchical selective performance.
<div id='section'>Paperid: <span id='pid'>777, <a href='https://arxiv.org/pdf/2404.08476.pdf' target='_blank'>https://arxiv.org/pdf/2404.08476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hai-Vy Nguyen, Fabrice Gamboa, Reda Chhaibi, Sixin Zhang, Serge Gratton, Thierry Giaccone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08476">Combining Statistical Depth and Fermat Distance for Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We measure the Out-of-domain uncertainty in the prediction of Neural Networks using a statistical notion called ``Lens Depth'' (LD) combined with Fermat Distance, which is able to capture precisely the ``depth'' of a point with respect to a distribution in feature space, without any assumption about the form of distribution. Our method has no trainable parameter. The method is applicable to any classification model as it is applied directly in feature space at test time and does not intervene in training process. As such, it does not impact the performance of the original model. The proposed method gives excellent qualitative result on toy datasets and can give competitive or better uncertainty estimation on standard deep learning datasets compared to strong baseline methods.
<div id='section'>Paperid: <span id='pid'>778, <a href='https://arxiv.org/pdf/2403.07514.pdf' target='_blank'>https://arxiv.org/pdf/2403.07514.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anastasios Arsenos, Dimitrios Kollias, Evangelos Petrongonas, Christos Skliros, Stefanos Kollias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07514">Uncertainty-guided Contrastive Learning for Single Source Domain Generalisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the context of single domain generalisation, the objective is for models that have been exclusively trained on data from a single domain to demonstrate strong performance when confronted with various unfamiliar domains. In this paper, we introduce a novel model referred to as Contrastive Uncertainty Domain Generalisation Network (CUDGNet). The key idea is to augment the source capacity in both input and label spaces through the fictitious domain generator and jointly learn the domain invariant representation of each class through contrastive learning. Extensive experiments on two Single Source Domain Generalisation (SSDG) datasets demonstrate the effectiveness of our approach, which surpasses the state-of-the-art single-DG methods by up to $7.08\%$. Our method also provides efficient uncertainty estimation at inference time from a single forward pass through the generator subnetwork.
<div id='section'>Paperid: <span id='pid'>779, <a href='https://arxiv.org/pdf/2403.05171.pdf' target='_blank'>https://arxiv.org/pdf/2403.05171.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoying Zhang, Jean-Francois Ton, Wei Shen, Hongning Wang, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.05171">Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Adversarial Policy Optimization (AdvPO), a novel solution to the pervasive issue of reward over-optimization in Reinforcement Learning from Human Feedback (RLHF) for Large Language Models (LLMs). Over-optimization occurs when a reward model serves as an imperfect proxy for human preference, and RL-driven policy optimization erroneously exploits reward inaccuracies. In this paper, we begin by introducing a lightweight way to quantify uncertainties in rewards, relying solely on the last layer embeddings of the reward model, without the need for computationally expensive reward ensembles. AdvPO then addresses a distributionally robust optimization problem centred around the confidence interval of the reward model's predictions for policy improvement. Through comprehensive experiments on the Anthropic HH and TL;DR summarization datasets, we illustrate the efficacy of AdvPO in mitigating the overoptimization issue, consequently resulting in enhanced performance as evaluated through human-assisted evaluation.
<div id='section'>Paperid: <span id='pid'>780, <a href='https://arxiv.org/pdf/2402.06160.pdf' target='_blank'>https://arxiv.org/pdf/2402.06160.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maohao Shen, J. Jon Ryu, Soumya Ghosh, Yuheng Bu, Prasanna Sattigeri, Subhro Das, Gregory W. Wornell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06160">Are Uncertainty Quantification Capabilities of Evidential Deep Learning a Mirage?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called \emph{evidential deep learning} (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.
<div id='section'>Paperid: <span id='pid'>781, <a href='https://arxiv.org/pdf/2401.01881.pdf' target='_blank'>https://arxiv.org/pdf/2401.01881.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ersin Das, Joel W. Burdick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01881">Robust Control Barrier Functions using Uncertainty Estimation with Application to Mobile Robots</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a safety-critical control design approach for nonlinear control affine systems in the presence of matched and unmatched uncertainties. Our constructive framework couples control barrier function (CBF) theory with a new uncertainty estimator to ensure robust safety. We use the estimated uncertainty, along with a derived upper bound on the estimation error, for synthesizing CBFs and safety-critical controllers via a quadratic program-based feedback control law that rigorously ensures robust safety while improving disturbance rejection performance. We extend the method to higher-order CBFs (HOCBFs) to achieve safety under unmatched uncertainty, which may cause relative degree differences with respect to control input and disturbances. We assume the relative degree difference is at most one, resulting in a second-order cone constraint. We demonstrate the proposed robust HOCBF method through a simulation of an uncertain elastic actuator control problem and experimentally validate the efficacy of our robust CBF framework on a tracked robot with slope-induced matched and unmatched perturbations.
<div id='section'>Paperid: <span id='pid'>782, <a href='https://arxiv.org/pdf/2401.00159.pdf' target='_blank'>https://arxiv.org/pdf/2401.00159.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masachika Masuda, Mazen Soufi, Yoshito Otake, Keisuke Uemura, Sotaro Kono, Kazuma Takashima, Hidetoshi Hamada, Yi Gu, Masaki Takao, Seiji Okada, Nobuhiko Sugano, Yoshinobu Sato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00159">Automatic hip osteoarthritis grading with uncertainty estimation from computed tomography using digitally-reconstructed radiographs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Progression of hip osteoarthritis (hip OA) leads to pain and disability, likely leading to surgical treatment such as hip arthroplasty at the terminal stage. The severity of hip OA is often classified using the Crowe and Kellgren-Lawrence (KL) classifications. However, as the classification is subjective, we aimed to develop an automated approach to classify the disease severity based on the two grades using digitally-reconstructed radiographs (DRRs) from CT images. Automatic grading of the hip OA severity was performed using deep learning-based models. The models were trained to predict the disease grade using two grading schemes, i.e., predicting the Crowe and KL grades separately, and predicting a new ordinal label combining both grades and representing the disease progression of hip OA. The models were trained in classification and regression settings. In addition, the model uncertainty was estimated and validated as a predictor of classification accuracy. The models were trained and validated on a database of 197 hip OA patients, and externally validated on 52 patients. The model accuracy was evaluated using exact class accuracy (ECA), one-neighbor class accuracy (ONCA), and balanced accuracy.The deep learning models produced a comparable accuracy of approximately 0.65 (ECA) and 0.95 (ONCA) in the classification and regression settings. The model uncertainty was significantly larger in cases with large classification errors (P<6e-3). In this study, an automatic approach for grading hip OA severity from CT images was developed. The models have shown comparable performance with high ONCA, which facilitates automated grading in large-scale CT databases and indicates the potential for further disease progression analysis. Classification accuracy was correlated with the model uncertainty, which would allow for the prediction of classification errors.
<div id='section'>Paperid: <span id='pid'>783, <a href='https://arxiv.org/pdf/2312.10469.pdf' target='_blank'>https://arxiv.org/pdf/2312.10469.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wang Zhang, Ziwen Ma, Subhro Das, Tsui-Wei Weng, Alexandre Megretski, Luca Daniel, Lam M. Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10469">One step closer to unbiased aleatoric uncertainty estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks are powerful tools in various applications, and quantifying their uncertainty is crucial for reliable decision-making. In the deep learning field, the uncertainties are usually categorized into aleatoric (data) and epistemic (model) uncertainty. In this paper, we point out that the existing popular variance attenuation method highly overestimates aleatoric uncertainty. To address this issue, we propose a new estimation method by actively de-noising the observed data. By conducting a broad range of experiments, we demonstrate that our proposed approach provides a much closer approximation to the actual data uncertainty than the standard method.
<div id='section'>Paperid: <span id='pid'>784, <a href='https://arxiv.org/pdf/2312.03213.pdf' target='_blank'>https://arxiv.org/pdf/2312.03213.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Polina Turishcheva, Jason Ramapuram, Sinead Williamson, Dan Busbridge, Eeshan Dhekane, Russ Webb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03213">Bootstrap Your Own Variance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding model uncertainty is important for many applications. We propose Bootstrap Your Own Variance (BYOV), combining Bootstrap Your Own Latent (BYOL), a negative-free Self-Supervised Learning (SSL) algorithm, with Bayes by Backprop (BBB), a Bayesian method for estimating model posteriors. We find that the learned predictive std of BYOV vs. a supervised BBB model is well captured by a Gaussian distribution, providing preliminary evidence that the learned parameter posterior is useful for label free uncertainty estimation. BYOV improves upon the deterministic BYOL baseline (+2.83% test ECE, +1.03% test Brier) and presents better calibration and reliability when tested with various augmentations (eg: +2.4% test ECE, +1.2% test Brier for Salt & Pepper noise).
<div id='section'>Paperid: <span id='pid'>785, <a href='https://arxiv.org/pdf/2310.05316.pdf' target='_blank'>https://arxiv.org/pdf/2310.05316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaewoo Park, Jacky Chen Long Chai, Jaeho Yoon, Andrew Beng Jin Teoh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05316">Understanding the Feature Norm for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A neural network trained on a classification dataset often exhibits a higher vector norm of hidden layer features for in-distribution (ID) samples, while producing relatively lower norm values on unseen instances from out-of-distribution (OOD). Despite this intriguing phenomenon being utilized in many applications, the underlying cause has not been thoroughly investigated. In this study, we demystify this very phenomenon by scrutinizing the discriminative structures concealed in the intermediate layers of a neural network. Our analysis leads to the following discoveries: (1) The feature norm is a confidence value of a classifier hidden in the network layer, specifically its maximum logit. Hence, the feature norm distinguishes OOD from ID in the same manner that a classifier confidence does. (2) The feature norm is class-agnostic, thus it can detect OOD samples across diverse discriminative models. (3) The conventional feature norm fails to capture the deactivation tendency of hidden layer neurons, which may lead to misidentification of ID samples as OOD instances. To resolve this drawback, we propose a novel negative-aware norm (NAN) that can capture both the activation and deactivation tendencies of hidden layer neurons. We conduct extensive experiments on NAN, demonstrating its efficacy and compatibility with existing OOD detectors, as well as its capability in label-free environments.
<div id='section'>Paperid: <span id='pid'>786, <a href='https://arxiv.org/pdf/2310.02832.pdf' target='_blank'>https://arxiv.org/pdf/2310.02832.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fran JeleniÄ, Josip JukiÄ, Martin Tutek, Mate Puljiz, Jan Å najder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02832">Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective out-of-distribution (OOD) detection is crucial for reliable machine learning models, yet most current methods are limited in practical use due to requirements like access to training data or intervention in training. We present a novel method for detecting OOD data in Transformers based on transformation smoothness between intermediate layers of a network (BLOOD), which is applicable to pre-trained models without access to training data. BLOOD utilizes the tendency of between-layer representation transformations of in-distribution (ID) data to be smoother than the corresponding transformations of OOD data, a property that we also demonstrate empirically. We evaluate BLOOD on several text classification tasks with Transformer networks and demonstrate that it outperforms methods with comparable resource requirements. Our analysis also suggests that when learning simpler tasks, OOD data transformations maintain their original sharpness, whereas sharpness increases with more complex tasks.
<div id='section'>Paperid: <span id='pid'>787, <a href='https://arxiv.org/pdf/2309.14502.pdf' target='_blank'>https://arxiv.org/pdf/2309.14502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kishansingh Rajput, Malachi Schram, Karthik Somayaji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14502">Uncertainty Aware Deep Learning for Particle Accelerators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard deep learning models for classification and regression applications are ideal for capturing complex system dynamics. However, their predictions can be arbitrarily inaccurate when the input samples are not similar to the training data. Implementation of distance aware uncertainty estimation can be used to detect these scenarios and provide a level of confidence associated with their predictions. In this paper, we present results from using Deep Gaussian Process Approximation (DGPA) methods for errant beam prediction at Spallation Neutron Source (SNS) accelerator (classification) and we provide an uncertainty aware surrogate model for the Fermi National Accelerator Lab (FNAL) Booster Accelerator Complex (regression).
<div id='section'>Paperid: <span id='pid'>788, <a href='https://arxiv.org/pdf/2309.11053.pdf' target='_blank'>https://arxiv.org/pdf/2309.11053.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tran Duc Luong, Vuong Minh Tien, Nguyen Huu Quyen, Do Thi Thu Hien, Phan The Duy, Van-Hau Pham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.11053">Fed-LSAE: Thwarting Poisoning Attacks against Federated Cyber Threat Detection System via Autoencoder-based Latent Space Inspection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The significant rise of security concerns in conventional centralized learning has promoted federated learning (FL) adoption in building intelligent applications without privacy breaches. In cybersecurity, the sensitive data along with the contextual information and high-quality labeling in each enterprise organization play an essential role in constructing high-performance machine learning (ML) models for detecting cyber threats. Nonetheless, the risks coming from poisoning internal adversaries against FL systems have raised discussions about designing robust anti-poisoning frameworks. Whereas defensive mechanisms in the past were based on outlier detection, recent approaches tend to be more concerned with latent space representation. In this paper, we investigate a novel robust aggregation method for FL, namely Fed-LSAE, which takes advantage of latent space representation via the penultimate layer and Autoencoder to exclude malicious clients from the training process. The experimental results on the CIC-ToN-IoT and N-BaIoT datasets confirm the feasibility of our defensive mechanism against cutting-edge poisoning attacks for developing a robust FL-based threat detector in the context of IoT. More specifically, the FL evaluation witnesses an upward trend of approximately 98% across all metrics when integrating with our Fed-LSAE defense.
<div id='section'>Paperid: <span id='pid'>789, <a href='https://arxiv.org/pdf/2309.02048.pdf' target='_blank'>https://arxiv.org/pdf/2309.02048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amirhossein Vahidi, Simon SchoÃer, Lisa Wimmer, Yawei Li, Bernd Bischl, Eyke HÃ¼llermeier, Mina Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02048">Probabilistic Self-supervised Learning via Scoring Rules Minimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel probabilistic self-supervised learning via Scoring Rule Minimization (ProSMIN), which leverages the power of probabilistic models to enhance representation quality and mitigate collapsing representations. Our proposed approach involves two neural networks; the online network and the target network, which collaborate and learn the diverse distribution of representations from each other through knowledge distillation. By presenting the input samples in two augmented formats, the online network is trained to predict the target network representation of the same sample under a different augmented view. The two networks are trained via our new loss function based on proper scoring rules. We provide a theoretical justification for ProSMIN's convergence, demonstrating the strict propriety of its modified scoring rule. This insight validates the method's optimization process and contributes to its robustness and effectiveness in improving representation quality. We evaluate our probabilistic model on various downstream tasks, such as in-distribution generalization, out-of-distribution detection, dataset corruption, low-shot learning, and transfer learning. Our method achieves superior accuracy and calibration, surpassing the self-supervised baseline in a wide range of experiments on large-scale datasets like ImageNet-O and ImageNet-C, ProSMIN demonstrates its scalability and real-world applicability.
<div id='section'>Paperid: <span id='pid'>790, <a href='https://arxiv.org/pdf/2308.14705.pdf' target='_blank'>https://arxiv.org/pdf/2308.14705.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amirhossein Vahidi, Lisa Wimmer, HÃ¼seyin Anil GÃ¼ndÃ¼z, Bernd Bischl, Eyke HÃ¼llermeier, Mina Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.14705">Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensembling a neural network is a widely recognized approach to enhance model performance, estimate uncertainty, and improve robustness in deep supervised learning. However, deep ensembles often come with high computational costs and memory demands. In addition, the efficiency of a deep ensemble is related to diversity among the ensemble members which is challenging for large, over-parameterized deep neural networks. Moreover, ensemble learning has not yet seen such widespread adoption, and it remains a challenging endeavor for self-supervised or unsupervised representation learning. Motivated by these challenges, we present a novel self-supervised training regime that leverages an ensemble of independent sub-networks, complemented by a new loss function designed to encourage diversity. Our method efficiently builds a sub-model ensemble with high diversity, leading to well-calibrated estimates of model uncertainty, all achieved with minimal computational overhead compared to traditional deep self-supervised ensembles. To evaluate the effectiveness of our approach, we conducted extensive experiments across various tasks, including in-distribution generalization, out-of-distribution detection, dataset corruption, and semi-supervised settings. The results demonstrate that our method significantly improves prediction reliability. Our approach not only achieves excellent accuracy but also enhances calibration, surpassing baseline performance across a wide range of self-supervised architectures in computer vision, natural language processing, and genomics data.
<div id='section'>Paperid: <span id='pid'>791, <a href='https://arxiv.org/pdf/2308.08032.pdf' target='_blank'>https://arxiv.org/pdf/2308.08032.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jesse Roberts, Kyle Moore, Drew Wilenzick, Doug Fisher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08032">Using Artificial Populations to Study Psychological Phenomena in Neural Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent proliferation of research into transformer based natural language processing has led to a number of studies which attempt to detect the presence of human-like cognitive behavior in the models. We contend that, as is true of human psychology, the investigation of cognitive behavior in language models must be conducted in an appropriate population of an appropriate size for the results to be meaningful. We leverage work in uncertainty estimation in a novel approach to efficiently construct experimental populations. The resultant tool, PopulationLM, has been made open source. We provide theoretical grounding in the uncertainty estimation literature and motivation from current cognitive work regarding language models. We discuss the methodological lessons from other scientific communities and attempt to demonstrate their application to two artificial population studies. Through population based experimentation we find that language models exhibit behavior consistent with typicality effects among categories highly represented in training. However, we find that language models don't tend to exhibit structural priming effects. Generally, our results show that single models tend to over estimate the presence of cognitive behaviors in neural models.
<div id='section'>Paperid: <span id='pid'>792, <a href='https://arxiv.org/pdf/2307.10586.pdf' target='_blank'>https://arxiv.org/pdf/2307.10586.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anthony Corso, David Karamadian, Romeo Valentin, Mary Cooper, Mykel J. Kochenderfer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.10586">A Holistic Assessment of the Reliability of Machine Learning Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As machine learning (ML) systems increasingly permeate high-stakes settings such as healthcare, transportation, military, and national security, concerns regarding their reliability have emerged. Despite notable progress, the performance of these systems can significantly diminish due to adversarial attacks or environmental changes, leading to overconfident predictions, failures to detect input faults, and an inability to generalize in unexpected scenarios. This paper proposes a holistic assessment methodology for the reliability of ML systems. Our framework evaluates five key properties: in-distribution accuracy, distribution-shift robustness, adversarial robustness, calibration, and out-of-distribution detection. A reliability score is also introduced and used to assess the overall system reliability. To provide insights into the performance of different algorithmic approaches, we identify and categorize state-of-the-art techniques, then evaluate a selection on real-world tasks using our proposed reliability metrics and reliability score. Our analysis of over 500 models reveals that designing for one metric does not necessarily constrain others but certain algorithmic techniques can improve reliability across multiple metrics simultaneously. This study contributes to a more comprehensive understanding of ML reliability and provides a roadmap for future research and development.
<div id='section'>Paperid: <span id='pid'>793, <a href='https://arxiv.org/pdf/2306.16991.pdf' target='_blank'>https://arxiv.org/pdf/2306.16991.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weide Liu, Xiaoyang Zhong, Jingwen Hou, Shaohua Li, Haozhe Huang, Yuming Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.16991">Integrating Large Pre-trained Models into Multimodal Named Entity Recognition with Evidential Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal Named Entity Recognition (MNER) is a crucial task for information extraction from social media platforms such as Twitter. Most current methods rely on attention weights to extract information from both text and images but are often unreliable and lack interpretability. To address this problem, we propose incorporating uncertainty estimation into the MNER task, producing trustworthy predictions. Our proposed algorithm models the distribution of each modality as a Normal-inverse Gamma distribution, and fuses them into a unified distribution with an evidential fusion mechanism, enabling hierarchical characterization of uncertainties and promotion of prediction accuracy and trustworthiness. Additionally, we explore the potential of pre-trained large foundation models in MNER and propose an efficient fusion approach that leverages their robust feature representations. Experiments on two datasets demonstrate that our proposed method outperforms the baselines and achieves new state-of-the-art performance.
<div id='section'>Paperid: <span id='pid'>794, <a href='https://arxiv.org/pdf/2306.10376.pdf' target='_blank'>https://arxiv.org/pdf/2306.10376.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeongeun Park, Seungwon Lim, Joonhyung Lee, Sangbeom Park, Minsuk Chang, Youngjae Yu, Sungjoon Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.10376">CLARA: Classifying and Disambiguating User Commands for Reliable Interactive Robotic Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we focus on inferring whether the given user command is clear, ambiguous, or infeasible in the context of interactive robotic agents utilizing large language models (LLMs). To tackle this problem, we first present an uncertainty estimation method for LLMs to classify whether the command is certain (i.e., clear) or not (i.e., ambiguous or infeasible). Once the command is classified as uncertain, we further distinguish it between ambiguous or infeasible commands leveraging LLMs with situational aware context in a zero-shot manner. For ambiguous commands, we disambiguate the command by interacting with users via question generation with LLMs. We believe that proper recognition of the given commands could lead to a decrease in malfunction and undesired actions of the robot, enhancing the reliability of interactive robot agents. We present a dataset for robotic situational awareness, consisting pair of high-level commands, scene descriptions, and labels of command type (i.e., clear, ambiguous, or infeasible). We validate the proposed method on the collected dataset, pick-and-place tabletop simulation. Finally, we demonstrate the proposed approach in real-world human-robot interaction experiments, i.e., handover scenarios.
<div id='section'>Paperid: <span id='pid'>795, <a href='https://arxiv.org/pdf/2306.09441.pdf' target='_blank'>https://arxiv.org/pdf/2306.09441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amin Yousefpour, Mehdi Shishehbor, Zahra Zanjani Foumani, Ramin Bostanabad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09441">Unsupervised Anomaly Detection via Nonlinear Manifold Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomalies are samples that significantly deviate from the rest of the data and their detection plays a major role in building machine learning models that can be reliably used in applications such as data-driven design and novelty detection. The majority of existing anomaly detection methods either are exclusively developed for (semi) supervised settings, or provide poor performance in unsupervised applications where there is no training data with labeled anomalous samples. To bridge this research gap, we introduce a robust, efficient, and interpretable methodology based on nonlinear manifold learning to detect anomalies in unsupervised settings. The essence of our approach is to learn a low-dimensional and interpretable latent representation (aka manifold) for all the data points such that normal samples are automatically clustered together and hence can be easily and robustly identified. We learn this low-dimensional manifold by designing a learning algorithm that leverages either a latent map Gaussian process (LMGP) or a deep autoencoder (AE). Our LMGP-based approach, in particular, provides a probabilistic perspective on the learning task and is ideal for high-dimensional applications with scarce data. We demonstrate the superior performance of our approach over existing technologies via multiple analytic examples and real-world datasets.
<div id='section'>Paperid: <span id='pid'>796, <a href='https://arxiv.org/pdf/2306.07124.pdf' target='_blank'>https://arxiv.org/pdf/2306.07124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moritz A. Zanger, Wendelin BÃ¶hmer, Matthijs T. J. Spaan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.07124">Diverse Projection Ensembles for Distributional Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In contrast to classical reinforcement learning (RL), distributional RL algorithms aim to learn the distribution of returns rather than their expected value. Since the nature of the return distribution is generally unknown a priori or arbitrarily complex, a common approach finds approximations within a set of representable, parametric distributions. Typically, this involves a projection of the unconstrained distribution onto the set of simplified distributions. We argue that this projection step entails a strong inductive bias when coupled with neural networks and gradient descent, thereby profoundly impacting the generalization behavior of learned models. In order to facilitate reliable uncertainty estimation through diversity, we study the combination of several different projections and representations in a distributional ensemble. We establish theoretical properties of such projection ensembles and derive an algorithm that uses ensemble disagreement, measured by the average 1-Wasserstein distance, as a bonus for deep exploration. We evaluate our algorithm on the behavior suite benchmark and VizDoom and find that diverse projection ensembles lead to significant performance improvements over existing methods on a variety of tasks with the most pronounced gains in directed exploration problems.
<div id='section'>Paperid: <span id='pid'>797, <a href='https://arxiv.org/pdf/2306.03331.pdf' target='_blank'>https://arxiv.org/pdf/2306.03331.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ranya Almohsen, Shivang Patel, Donald A. Adjeroh, Gianfranco Doretto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03331">A Robust Likelihood Model for Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current approaches to novelty or anomaly detection are based on deep neural networks. Despite their effectiveness, neural networks are also vulnerable to imperceptible deformations of the input data. This is a serious issue in critical applications, or when data alterations are generated by an adversarial attack. While this is a known problem that has been studied in recent years for the case of supervised learning, the case of novelty detection has received very limited attention. Indeed, in this latter setting the learning is typically unsupervised because outlier data is not available during training, and new approaches for this case need to be investigated. We propose a new prior that aims at learning a robust likelihood for the novelty test, as a defense against attacks. We also integrate the same prior with a state-of-the-art novelty detection approach. Because of the geometric properties of that approach, the resulting robust training is computationally very efficient. An initial evaluation of the method indicates that it is effective at improving performance with respect to the standard models in the absence and presence of attacks.
<div id='section'>Paperid: <span id='pid'>798, <a href='https://arxiv.org/pdf/2305.17854.pdf' target='_blank'>https://arxiv.org/pdf/2305.17854.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Zhang, Mengting Hu, Shiwan Zhao, Minlie Huang, Haotian Wang, Lemao Liu, Zhirui Zhang, Zhe Liu, Bingzhe Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.17854">E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most named entity recognition (NER) systems focus on improving model performance, ignoring the need to quantify model uncertainty, which is critical to the reliability of NER systems in open environments. Evidential deep learning (EDL) has recently been proposed as a promising solution to explicitly model predictive uncertainty for classification tasks. However, directly applying EDL to NER applications faces two challenges, i.e., the problems of sparse entities and OOV/OOD entities in NER tasks. To address these challenges, we propose a trustworthy NER framework named E-NER by introducing two uncertainty-guided loss terms to the conventional EDL, along with a series of uncertainty-guided training strategies. Experiments show that E-NER can be applied to multiple NER paradigms to obtain accurate uncertainty estimation. Furthermore, compared to state-of-the-art baselines, the proposed method achieves a better OOV/OOD detection performance and better generalization ability on OOV entities.
<div id='section'>Paperid: <span id='pid'>799, <a href='https://arxiv.org/pdf/2305.11029.pdf' target='_blank'>https://arxiv.org/pdf/2305.11029.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Sun, Kun Huang, Xiaocui Yang, Pengfei Hong, Kun Zhang, Soujanya Poria
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.11029">Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Document-level relation extraction (DocRE) aims to infer complex semantic relations among entities in a document. Distant supervision (DS) is able to generate massive auto-labeled data, which can improve DocRE performance. Recent works leverage pseudo labels generated by the pre-denoising model to reduce noise in DS data. However, unreliable pseudo labels bring new noise, e.g., adding false pseudo labels and losing correct DS labels. Therefore, how to select effective pseudo labels to denoise DS data is still a challenge in document-level distant relation extraction. To tackle this issue, we introduce uncertainty estimation technology to determine whether pseudo labels can be trusted. In this work, we propose a Document-level distant Relation Extraction framework with Uncertainty Guided label denoising, UGDRE. Specifically, we propose a novel instance-level uncertainty estimation method, which measures the reliability of the pseudo labels with overlapping relations. By further considering the long-tail problem, we design dynamic uncertainty thresholds for different types of relations to filter high-uncertainty pseudo labels. We conduct experiments on two public datasets. Our framework outperforms strong baselines by 1.91 F1 and 2.28 Ign F1 on the RE-DocRED dataset.
<div id='section'>Paperid: <span id='pid'>800, <a href='https://arxiv.org/pdf/2304.10038.pdf' target='_blank'>https://arxiv.org/pdf/2304.10038.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, Bing Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10038">Open-World Continual Learning: Unifying Novelty Detection and Continual Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As AI agents are increasingly used in the real open world with unknowns or novelties, they need the ability to (1) recognize objects that (a) they have learned before and (b) detect items that they have never seen or learned, and (2) learn the new items incrementally to become more and more knowledgeable and powerful. (1) is called novelty detection or out-of-distribution (OOD) detection and (2) is called class incremental learning (CIL), which is a setting of continual learning (CL). In existing research, OOD detection and CIL are regarded as two completely different problems. This paper first provides a theoretical proof that good OOD detection for each task within the set of learned tasks (called closed-world OOD detection) is necessary for successful CIL. We show this by decomposing CIL into two sub-problems: within-task prediction (WP) and task-id prediction (TP), and proving that TP is correlated with closed-world OOD detection. The key theoretical result is that regardless of whether WP and OOD detection (or TP) are defined explicitly or implicitly by a CIL algorithm, good WP and good closed-world OOD detection are necessary and sufficient conditions for good CIL, which unifies novelty or OOD detection and continual learning (CIL, in particular). We call this traditional CIL the closed-world CIL as it does not detect future OOD data in the open world. The paper then proves that the theory can be generalized or extended to open-world CIL, which is the proposed open-world continual learning, that can perform CIL in the open world and detect future or open-world OOD data. Based on the theoretical results, new CIL methods are also designed, which outperform strong baselines in CIL accuracy and in continual OOD detection by a large margin.
<div id='section'>Paperid: <span id='pid'>801, <a href='https://arxiv.org/pdf/2303.14961.pdf' target='_blank'>https://arxiv.org/pdf/2303.14961.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicola Franco, Daniel Korth, Jeanette Miriam Lorenz, Karsten Roscher, Stephan Guennemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14961">Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As the use of machine learning continues to expand, the importance of ensuring its safety cannot be overstated. A key concern in this regard is the ability to identify whether a given sample is from the training distribution, or is an "Out-Of-Distribution" (OOD) sample. In addition, adversaries can manipulate OOD samples in ways that lead a classifier to make a confident prediction. In this study, we present a novel approach for certifying the robustness of OOD detection within a $\ell_2$-norm around the input, regardless of network architecture and without the need for specific components or additional training. Further, we improve current techniques for detecting adversarial attacks on OOD samples, while providing high levels of certified and adversarial robustness on in-distribution samples. The average of all OOD detection metrics on CIFAR10/100 shows an increase of $\sim 13 \% / 5\%$ relative to previous approaches.
<div id='section'>Paperid: <span id='pid'>802, <a href='https://arxiv.org/pdf/2303.09843.pdf' target='_blank'>https://arxiv.org/pdf/2303.09843.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steven Landgraf, Kira Wursthorn, Markus Hillemann, Markus Ulrich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.09843">DUDES: Deep Uncertainty Distillation using Ensembles for Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks lack interpretability and tend to be overconfident, which poses a serious problem in safety-critical applications like autonomous driving, medical imaging, or machine vision tasks with high demands on reliability. Quantifying the predictive uncertainty is a promising endeavour to open up the use of deep neural networks for such applications. Unfortunately, current available methods are computationally expensive. In this work, we present a novel approach for efficient and reliable uncertainty estimation which we call Deep Uncertainty Distillation using Ensembles for Segmentation (DUDES). DUDES applies student-teacher distillation with a Deep Ensemble to accurately approximate predictive uncertainties with a single forward pass while maintaining simplicity and adaptability. Experimentally, DUDES accurately captures predictive uncertainties without sacrificing performance on the segmentation task and indicates impressive capabilities of identifying wrongly classified pixels and out-of-domain samples on the Cityscapes dataset. With DUDES, we manage to simultaneously simplify and outperform previous work on Deep Ensemble-based Uncertainty Distillation.
<div id='section'>Paperid: <span id='pid'>803, <a href='https://arxiv.org/pdf/2303.07836.pdf' target='_blank'>https://arxiv.org/pdf/2303.07836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Morilla-Cabello, Lorenzo Mur-Labadia, Ruben Martinez-Cantin, Eduardo Montijano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07836">Robust Fusion for Bayesian Semantic Mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of semantic information in a map allows robots to understand better their environment and make high-level decisions. In the last few years, neural networks have shown enormous progress in their perception capabilities. However, when fusing multiple observations from a neural network in a semantic map, its inherent overconfidence with unknown data gives too much weight to the outliers and decreases the robustness. To mitigate this issue we propose a novel robust fusion method to combine multiple Bayesian semantic predictions. Our method uses the uncertainty estimation provided by a Bayesian neural network to calibrate the way in which the measurements are fused. This is done by regularizing the observations to mitigate the problem of overconfident outlier predictions and using the epistemic uncertainty to weigh their influence in the fusion, resulting in a different formulation of the probability distributions. We validate our robust fusion strategy by performing experiments on photo-realistic simulated environments and real scenes. In both cases, we use a network trained on different data to expose the model to varying data distributions. The results show that considering the model's uncertainty and regularizing the probability distribution of the observations distribution results in a better semantic segmentation performance and more robustness to outliers, compared with other methods. Video - https://youtu.be/5xVGm7z9c-0
<div id='section'>Paperid: <span id='pid'>804, <a href='https://arxiv.org/pdf/2303.00973.pdf' target='_blank'>https://arxiv.org/pdf/2303.00973.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Scarlett Raine, Ross Marchant, Brano Kusy, Frederic Maire, Tobias Fischer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00973">Image Labels Are All You Need for Coarse Seagrass Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Seagrass meadows serve as critical carbon sinks, but estimating the amount of carbon they store requires knowledge of the seagrass species present. Underwater and surface vehicles equipped with machine learning algorithms can help to accurately estimate the composition and extent of seagrass meadows at scale. However, previous approaches for seagrass detection and classification have required supervision from patch-level labels. In this paper, we reframe seagrass classification as a weakly supervised coarse segmentation problem where image-level labels are used during training (25 times fewer labels compared to patch-level labeling) and patch-level outputs are obtained at inference time. To this end, we introduce SeaFeats, an architecture that uses unsupervised contrastive pre-training and feature similarity, and SeaCLIP, a model that showcases the effectiveness of large language models as a supervisory signal in domain-specific applications. We demonstrate that an ensemble of SeaFeats and SeaCLIP leads to highly robust performance. Our method outperforms previous approaches that require patch-level labels on the multi-species 'DeepSeagrass' dataset by 6.8% (absolute) for the class-weighted F1 score, and by 12.1% (absolute) for the seagrass presence/absence F1 score on the 'Global Wetlands' dataset. We also present two case studies for real-world deployment: outlier detection on the Global Wetlands dataset, and application of our method on imagery collected by the FloatyBoat autonomous surface vehicle.
<div id='section'>Paperid: <span id='pid'>805, <a href='https://arxiv.org/pdf/2302.11874.pdf' target='_blank'>https://arxiv.org/pdf/2302.11874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ido Galil, Mohammed Dabbah, Ran El-Yaniv
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11874">What Can We Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When deployed for risk-sensitive tasks, deep neural networks must include an uncertainty estimation mechanism. Here we examine the relationship between deep architectures and their respective training regimes, with their corresponding selective prediction and uncertainty estimation performance. We consider some of the most popular estimation performance metrics previously proposed including AUROC, ECE, AURC as well as coverage for selective accuracy constraint. We present a novel and comprehensive study of selective prediction and the uncertainty estimation performance of 523 existing pretrained deep ImageNet classifiers that are available in popular repositories. We identify numerous and previously unknown factors that affect uncertainty estimation and examine the relationships between the different metrics. We find that distillation-based training regimes consistently yield better uncertainty estimations than other training schemes such as vanilla training, pretraining on a larger dataset and adversarial training. Moreover, we find a subset of ViT models that outperform any other models in terms of uncertainty estimation performance. For example, we discovered an unprecedented 99% top-1 selective accuracy on ImageNet at 47% coverage (and 95% top-1 accuracy at 80%) for a ViT model, whereas a competing EfficientNet-V2-XL cannot obtain these accuracy constraints at any level of coverage. Our companion paper, also published in ICLR 2023 (A framework for benchmarking class-out-of-distribution detection and its application to ImageNet), examines the performance of these classifiers in a class-out-of-distribution setting.
<div id='section'>Paperid: <span id='pid'>806, <a href='https://arxiv.org/pdf/2302.11012.pdf' target='_blank'>https://arxiv.org/pdf/2302.11012.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Uddeshya Upadhyay, Jae Myung Kim, Cordelia Schmidt, Bernhard SchÃ¶lkopf, Zeynep Akata
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11012">Likelihood Annealing: Fast Calibrated Uncertainty for Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in deep learning have shown that uncertainty estimation is becoming increasingly important in applications such as medical imaging, natural language processing, and autonomous systems. However, accurately quantifying uncertainty remains a challenging problem, especially in regression tasks where the output space is continuous. Deep learning approaches that allow uncertainty estimation for regression problems often converge slowly and yield poorly calibrated uncertainty estimates that can not be effectively used for quantification. Recently proposed post hoc calibration techniques are seldom applicable to regression problems and often add overhead to an already slow model training phase. This work presents a fast calibrated uncertainty estimation method for regression tasks called Likelihood Annealing, that consistently improves the convergence of deep regression models and yields calibrated uncertainty without any post hoc calibration phase. Unlike previous methods for calibrated uncertainty in regression that focus only on low-dimensional regression problems, our method works well on a broad spectrum of regression problems, including high-dimensional regression.Our empirical analysis shows that our approach is generalizable to various network architectures, including multilayer perceptrons, 1D/2D convolutional networks, and graph neural networks, on five vastly diverse tasks, i.e., chaotic particle trajectory denoising, physical property prediction of molecules using 3D atomistic representation, natural image super-resolution, and medical image translation using MRI.
<div id='section'>Paperid: <span id='pid'>807, <a href='https://arxiv.org/pdf/2302.08287.pdf' target='_blank'>https://arxiv.org/pdf/2302.08287.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhang Zhang, Weihong Deng, Liang Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08287">Unsupervised Evaluation of Out-of-distribution Detection: A Data-centric Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection methods assume that they have test ground truths, i.e., whether individual test samples are in-distribution (IND) or OOD. However, in the real world, we do not always have such ground truths, and thus do not know which sample is correctly detected and cannot compute the metric like AUROC to evaluate the performance of different OOD detection methods. In this paper, we are the first to introduce the unsupervised evaluation problem in OOD detection, which aims to evaluate OOD detection methods in real-world changing environments without OOD labels. We propose three methods to compute Gscore as an unsupervised indicator of OOD detection performance. We further introduce a new benchmark Gbench, which has 200 real-world OOD datasets of various label spaces to train and evaluate our method. Through experiments, we find a strong quantitative correlation betwwen Gscore and the OOD detection performance. Extensive experiments demonstrate that our Gscore achieves state-of-the-art performance. Gscore also generalizes well with different IND/OOD datasets, OOD detection methods, backbones and dataset sizes. We further provide interesting analyses of the effects of backbones and IND/OOD datasets on OOD detection performance. The data and code will be available.
<div id='section'>Paperid: <span id='pid'>808, <a href='https://arxiv.org/pdf/2302.05923.pdf' target='_blank'>https://arxiv.org/pdf/2302.05923.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Illia Oleksiienko, Alexandros Iosifidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05923">Uncertainty-Aware AB3DMOT by Variational 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving needs to rely on high-quality 3D object detection to ensure safe navigation in the world. Uncertainty estimation is an effective tool to provide statistically accurate predictions, while the associated detection uncertainty can be used to implement a more safe navigation protocol or include the user in the loop. In this paper, we propose a Variational Neural Network-based TANet 3D object detector to generate 3D object detections with uncertainty and introduce these detections to an uncertainty-aware AB3DMOT tracker. This is done by applying a linear transformation to the estimated uncertainty matrix, which is subsequently used as a measurement noise for the adopted Kalman filter. We implement two ways to estimate output uncertainty, i.e., internally, by computing the variance of the CNN outputs and then propagating the uncertainty through the post-processing, and externally, by associating the final predictions of different samples and computing the covariance of each predicted box. In experiments, we show that the external uncertainty estimation leads to better results, outperforming both internal uncertainty estimation and classical tracking approaches. Furthermore, we propose a method to initialize the Variational 3D object detector with a pretrained TANet model, which leads to the best performing models.
<div id='section'>Paperid: <span id='pid'>809, <a href='https://arxiv.org/pdf/2211.05421.pdf' target='_blank'>https://arxiv.org/pdf/2211.05421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benjamin Lambert, Florence Forbes, Senan Doyle, Alan Tucholka, Michel Dojat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.05421">Improving Uncertainty-based Out-of-Distribution Detection for Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Learning models are easily disturbed by variations in the input images that were not seen during training, resulting in unpredictable behaviours. Such Out-of-Distribution (OOD) images represent a significant challenge in the context of medical image analysis, where the range of possible abnormalities is extremely wide, including artifacts, unseen pathologies, or different imaging protocols. In this work, we evaluate various uncertainty frameworks to detect OOD inputs in the context of Multiple Sclerosis lesions segmentation. By implementing a comprehensive evaluation scheme including 14 sources of OOD of various nature and strength, we show that methods relying on the predictive uncertainty of binary segmentation models often fails in detecting outlying inputs. On the contrary, learning to segment anatomical labels alongside lesions highly improves the ability to detect OOD inputs.
<div id='section'>Paperid: <span id='pid'>810, <a href='https://arxiv.org/pdf/2211.00372.pdf' target='_blank'>https://arxiv.org/pdf/2211.00372.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prabhant Singh, Joaquin Vanschoren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.00372">Meta-Learning for Unsupervised Outlier Detection with Optimal Transport</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated machine learning has been widely researched and adopted in the field of supervised classification and regression, but progress in unsupervised settings has been limited. We propose a novel approach to automate outlier detection based on meta-learning from previous datasets with outliers. Our premise is that the selection of the optimal outlier detection technique depends on the inherent properties of the data distribution. We leverage optimal transport in particular, to find the dataset with the most similar underlying distribution, and then apply the outlier detection techniques that proved to work best for that data distribution. We evaluate the robustness of our approach and find that it outperforms the state of the art methods in unsupervised outlier detection. This approach can also be easily generalized to automate other unsupervised settings.
<div id='section'>Paperid: <span id='pid'>811, <a href='https://arxiv.org/pdf/2210.13455.pdf' target='_blank'>https://arxiv.org/pdf/2210.13455.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaniv Oren, Villiam Vadocz, Matthijs T. J. Spaan, Wendelin BÃ¶hmer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.13455">Epistemic Monte Carlo Tree Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The AlphaZero/MuZero (A/MZ) family of algorithms has achieved remarkable success across various challenging domains by integrating Monte Carlo Tree Search (MCTS) with learned models. Learned models introduce epistemic uncertainty, which is caused by learning from limited data and is useful for exploration in sparse reward environments. MCTS does not account for the propagation of this uncertainty however. To address this, we introduce Epistemic MCTS (EMCTS): a theoretically motivated approach to account for the epistemic uncertainty in search and harness the search for deep exploration. In the challenging sparse-reward task of writing code in the Assembly language {\sc subleq}, AZ paired with our method achieves significantly higher sample efficiency over baseline AZ. Search with EMCTS solves variations of the commonly used hard-exploration benchmark Deep Sea - which baseline A/MZ are practically unable to solve - much faster than an otherwise equivalent method that does not use search for uncertainty estimation, demonstrating significant benefits from search for epistemic uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>812, <a href='https://arxiv.org/pdf/2210.04882.pdf' target='_blank'>https://arxiv.org/pdf/2210.04882.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Illia Oleksiienko, Alexandros Iosifidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.04882">Layer Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Ensembles, as a type of Bayesian Neural Networks, can be used to estimate uncertainty on the prediction of multiple neural networks by collecting votes from each network and computing the difference in those predictions. In this paper, we introduce a method for uncertainty estimation that considers a set of independent categorical distributions for each layer of the network, giving many more possible samples with overlapped layers than in the regular Deep Ensembles. We further introduce an optimized inference procedure that reuses common layer outputs, achieving up to 19x speed up and reducing memory usage quadratically. We also show that the method can be further improved by ranking samples, resulting in models that require less memory and time to run while achieving higher uncertainty quality than Deep Ensembles.
<div id='section'>Paperid: <span id='pid'>813, <a href='https://arxiv.org/pdf/2207.01524.pdf' target='_blank'>https://arxiv.org/pdf/2207.01524.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Illia Oleksiienko, Dat Thanh Tran, Alexandros Iosifidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.01524">Variational Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Neural Networks (BNNs) provide a tool to estimate the uncertainty of a neural network by considering a distribution over weights and sampling different models for each input. In this paper, we propose a method for uncertainty estimation in neural networks which, instead of considering a distribution over weights, samples outputs of each layer from a corresponding Gaussian distribution, parametrized by the predictions of mean and variance sub-layers. In uncertainty quality estimation experiments, we show that the proposed method achieves better uncertainty quality than other single-bin Bayesian Model Averaging methods, such as Monte Carlo Dropout or Bayes By Backpropagation methods.
<div id='section'>Paperid: <span id='pid'>814, <a href='https://arxiv.org/pdf/2206.02152.pdf' target='_blank'>https://arxiv.org/pdf/2206.02152.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ido Galil, Mohammed Dabbah, Ran El-Yaniv
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.02152">Which models are innately best at uncertainty estimation?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the comprehensive nature of this paper, it has been updated and split into two separate papers: "A Framework For Benchmarking Class-out-of-distribution Detection And Its Application To ImageNet" and "What Can We Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers". We recommend reading them instead.
  Deep neural networks must be equipped with an uncertainty estimation mechanism when deployed for risk-sensitive tasks. This paper studies the relationship between deep architectures and their training regimes with their corresponding selective prediction and uncertainty estimation performance. We consider both in-distribution uncertainties and class-out-of-distribution ones. Moreover, we consider some of the most popular estimation performance metrics previously proposed including AUROC, ECE, AURC, and coverage for selective accuracy constraint. We present a novel and comprehensive study of selective prediction and the uncertainty estimation performance of 484 existing pretrained deep ImageNet classifiers that are available at popular repositories. We identify numerous and previously unknown factors that affect uncertainty estimation and examine the relationships between the different metrics. We find that distillation-based training regimes consistently yield better uncertainty estimations than other training schemes such as vanilla training, pretraining on a larger dataset and adversarial training. We also provide strong empirical evidence showing that ViT is by far the most superior architecture in terms of uncertainty estimation performance, judging by any aspect, in both in-distribution and class-out-of-distribution scenarios.
<div id='section'>Paperid: <span id='pid'>815, <a href='https://arxiv.org/pdf/2508.21695.pdf' target='_blank'>https://arxiv.org/pdf/2508.21695.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>BarÄ±Å ZÃ¶ngÃ¼r, Robin Hesse, Stefan Roth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21695">Activation Subspaces for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To ensure the reliability of deep models in real-world applications, out-of-distribution (OOD) detection methods aim to distinguish samples close to the training distribution (in-distribution, ID) from those farther away (OOD). In this work, we propose a novel OOD detection method that utilizes singular value decomposition of the weight matrix of the classification head to decompose the model's activations into decisive and insignificant components, which contribute maximally, respectively minimally, to the final classifier output. We find that the subspace of insignificant components more effectively distinguishes ID from OOD data than raw activations in regimes of large distribution shifts (Far-OOD). This occurs because the classification objective leaves the insignificant subspace largely unaffected, yielding features that are ''untainted'' by the target classification task. Conversely, in regimes of smaller distribution shifts (Near-OOD), we find that activation shaping methods profit from only considering the decisive subspace, as the insignificant component can cause interference in the activation space. By combining two findings into a single approach, termed ActSub, we achieve state-of-the-art results in various standard OOD benchmarks.
<div id='section'>Paperid: <span id='pid'>816, <a href='https://arxiv.org/pdf/2508.21695.pdf' target='_blank'>https://arxiv.org/pdf/2508.21695.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Barış Zöngür, Robin Hesse, Stefan Roth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21695">Activation Subspaces for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To ensure the reliability of deep models in real-world applications, out-of-distribution (OOD) detection methods aim to distinguish samples close to the training distribution (in-distribution, ID) from those farther away (OOD). In this work, we propose a novel OOD detection method that utilizes singular value decomposition of the weight matrix of the classification head to decompose the model's activations into decisive and insignificant components, which contribute maximally, respectively minimally, to the final classifier output. We find that the subspace of insignificant components more effectively distinguishes ID from OOD data than raw activations in regimes of large distribution shifts (Far-OOD). This occurs because the classification objective leaves the insignificant subspace largely unaffected, yielding features that are ''untainted'' by the target classification task. Conversely, in regimes of smaller distribution shifts (Near-OOD), we find that activation shaping methods profit from only considering the decisive subspace, as the insignificant component can cause interference in the activation space. By combining two findings into a single approach, termed ActSub, we achieve state-of-the-art results in various standard OOD benchmarks.
<div id='section'>Paperid: <span id='pid'>817, <a href='https://arxiv.org/pdf/2508.17667.pdf' target='_blank'>https://arxiv.org/pdf/2508.17667.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Runhe Lai, Xinhua Lu, Kanghao Chen, Qichao Chen, Wei-Shi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17667">Hierarchical Vision-Language Learning for Medical Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In trustworthy medical diagnosis systems, integrating out-of-distribution (OOD) detection aims to identify unknown diseases in samples, thereby mitigating the risk of misdiagnosis. In this study, we propose a novel OOD detection framework based on vision-language models (VLMs), which integrates hierarchical visual information to cope with challenging unknown diseases that resemble known diseases. Specifically, a cross-scale visual fusion strategy is proposed to couple visual embeddings from multiple scales. This enriches the detailed representation of medical images and thus improves the discrimination of unknown diseases. Moreover, a cross-scale hard pseudo-OOD sample generation strategy is proposed to benefit OOD detection maximally. Experimental evaluations on three public medical datasets support that the proposed framework achieves superior OOD detection performance compared to existing methods. The source code is available at https://openi.pcl.ac.cn/OpenMedIA/HVL.
<div id='section'>Paperid: <span id='pid'>818, <a href='https://arxiv.org/pdf/2508.03890.pdf' target='_blank'>https://arxiv.org/pdf/2508.03890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanghun Jung, Daehoon Gwak, Byron Boots, James Hays
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03890">Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Terrain elevation modeling for off-road navigation aims to accurately estimate changes in terrain geometry in real-time and quantify the corresponding uncertainties. Having precise estimations and uncertainties plays a crucial role in planning and control algorithms to explore safe and reliable maneuver strategies. However, existing approaches, such as Gaussian Processes (GPs) and neural network-based methods, often fail to meet these needs. They are either unable to perform in real-time due to high computational demands, underestimating sharp geometry changes, or harming elevation accuracy when learned with uncertainties. Recently, Neural Processes (NPs) have emerged as a promising approach that integrates the Bayesian uncertainty estimation of GPs with the efficiency and flexibility of neural networks. Inspired by NPs, we propose an effective NP-based method that precisely estimates sharp elevation changes and quantifies the corresponding predictive uncertainty without losing elevation accuracy. Our method leverages semantic features from LiDAR and camera sensors to improve interpolation and extrapolation accuracy in unobserved regions. Also, we introduce a local ball-query attention mechanism to effectively reduce the computational complexity of global attention by 17\% while preserving crucial local and spatial information. We evaluate our method on off-road datasets having interesting geometric features, collected from trails, deserts, and hills. Our results demonstrate superior performance over baselines and showcase the potential of neural processes for effective and expressive terrain modeling in complex off-road environments.
<div id='section'>Paperid: <span id='pid'>819, <a href='https://arxiv.org/pdf/2508.02443.pdf' target='_blank'>https://arxiv.org/pdf/2508.02443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Gottwald, Edgar Heinert, Matthias Rottmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02443">Uncertainty Estimation for Novel Views in Gaussian Splatting from Primitive-Based Representations of Error and Visibility</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present a novel method for uncertainty estimation (UE) in Gaussian Splatting. UE is crucial for using Gaussian Splatting in critical applications such as robotics and medicine. Previous methods typically estimate the variance of Gaussian primitives and use the rendering process to obtain pixel-wise uncertainties. Our method establishes primitive representations of error and visibility of trainings views, which carries meaningful uncertainty information. This representation is obtained by projection of training error and visibility onto the primitives. Uncertainties of novel views are obtained by rendering the primitive representations of uncertainty for those novel views, yielding uncertainty feature maps. To aggregate these uncertainty feature maps of novel views, we perform a pixel-wise regression on holdout data. In our experiments, we analyze the different components of our method, investigating various combinations of uncertainty feature maps and regression models. Furthermore, we considered the effect of separating splatting into foreground and background. Our UEs show high correlations to true errors, outperforming state-of-the-art methods, especially on foreground objects. The trained regression models show generalization capabilities to new scenes, allowing uncertainty estimation without the need for holdout data.
<div id='section'>Paperid: <span id='pid'>820, <a href='https://arxiv.org/pdf/2507.17796.pdf' target='_blank'>https://arxiv.org/pdf/2507.17796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicholas A. Pearson, Francesca Zanello, Davide Russo, Luca Bortolussi, Francesca Cairoli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.17796">CoCAI: Copula-based Conformal Anomaly Identification for Multivariate Time-Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel framework that harnesses the power of generative artificial intelligence and copula-based modeling to address two critical challenges in multivariate time-series analysis: delivering accurate predictions and enabling robust anomaly detection. Our method, Copula-based Conformal Anomaly Identification for Multivariate Time-Series (CoCAI), leverages a diffusion-based model to capture complex dependencies within the data, enabling high quality forecasting. The model's outputs are further calibrated using a conformal prediction technique, yielding predictive regions which are statistically valid, i.e., cover the true target values with a desired confidence level. Starting from these calibrated forecasts, robust outlier detection is performed by combining dimensionality reduction techniques with copula-based modeling, providing a statistically grounded anomaly score. CoCAI benefits from an offline calibration phase that allows for minimal overhead during deployment and delivers actionable results rooted in established theoretical foundations. Empirical tests conducted on real operational data derived from water distribution and sewerage systems confirm CoCAI's effectiveness in accurately forecasting target sequences of data and in identifying anomalous segments within them.
<div id='section'>Paperid: <span id='pid'>821, <a href='https://arxiv.org/pdf/2507.17796.pdf' target='_blank'>https://arxiv.org/pdf/2507.17796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicholas A. Pearson, Francesca Zanello, Davide Russo, Luca Bortolussi, Francesca Cairoli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.17796">CoCAI: Copula-based Conformal Anomaly Identification for Multivariate Time-Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel framework that harnesses the power of generative artificial intelligence and copula-based modeling to address two critical challenges in multivariate time-series analysis: delivering accurate predictions and enabling robust anomaly detection. Our method, Copula-based Conformal Anomaly Identification for Multivariate Time-Series (CoCAI), leverages a diffusion-based model to capture complex dependencies within the data, enabling high quality forecasting. The model's outputs are further calibrated using a conformal prediction technique, yielding predictive regions which are statistically valid, i.e., cover the true target values with a desired confidence level. Starting from these calibrated forecasts, robust outlier detection is performed by combining dimensionality reduction techniques with copula-based modeling, providing a statistically grounded anomaly score. CoCAI benefits from an offline calibration phase that allows for minimal overhead during deployment and delivers actionable results rooted in established theoretical foundations. Empirical tests conducted on real operational data derived from water distribution and sewerage systems confirm CoCAI's effectiveness in accurately forecasting target sequences of data and in identifying anomalous segments within them.
<div id='section'>Paperid: <span id='pid'>822, <a href='https://arxiv.org/pdf/2507.16219.pdf' target='_blank'>https://arxiv.org/pdf/2507.16219.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Da Fan, David John Gagne, Steven J. Greybush, Eugene E. Clothiaux, John S. Schreck, Chaopeng Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16219">Bayesian Deep Learning for Convective Initiation Nowcasting Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study evaluated the probability and uncertainty forecasts of five recently proposed Bayesian deep learning methods relative to a deterministic residual neural network (ResNet) baseline for 0-1 h convective initiation (CI) nowcasting using GOES-16 satellite infrared observations. Uncertainty was assessed by how well probabilistic forecasts were calibrated and how well uncertainty separated forecasts with large and small errors. Most of the Bayesian deep learning methods produced probabilistic forecasts that outperformed the deterministic ResNet, with one, the initial-weights ensemble + Monte Carlo (MC) dropout, an ensemble of deterministic ResNets with different initial weights to start training and dropout activated during inference, producing the most skillful and well-calibrated forecasts. The initial-weights ensemble + MC dropout benefited from generating multiple solutions that more thoroughly sampled the hypothesis space. The Bayesian ResNet ensemble was the only one that performed worse than the deterministic ResNet at longer lead times, likely due to the challenge of optimizing a larger number of parameters. To address this issue, the Bayesian-MOPED (MOdel Priors with Empirical Bayes using Deep neural network) ResNet ensemble was adopted, and it enhanced forecast skill by constraining the hypothesis search near the deterministic ResNet hypothesis. All Bayesian methods demonstrated well-calibrated uncertainty and effectively separated cases with large and small errors. In case studies, the initial-weights ensemble + MC dropout demonstrated better forecast skill than the Bayesian-MOPED ensemble and the deterministic ResNet on selected CI events in clear-sky regions. However, the initial-weights ensemble + MC dropout exhibited poorer generalization in clear-sky and anvil cloud regions without CI occurrence compared to the deterministic ResNet and Bayesian-MOPED ensemble.
<div id='section'>Paperid: <span id='pid'>823, <a href='https://arxiv.org/pdf/2507.09980.pdf' target='_blank'>https://arxiv.org/pdf/2507.09980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhipeng Xue, Yan Zhang, Ming Li, Chun Li, Yue Liu, Fei Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09980">Uncertainty Quantification for Incomplete Multi-View Data Using Divergence Measures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing multi-view classification and clustering methods typically improve task accuracy by leveraging and fusing information from different views. However, ensuring the reliability of multi-view integration and final decisions is crucial, particularly when dealing with noisy or corrupted data. Current methods often rely on Kullback-Leibler (KL) divergence to estimate uncertainty of network predictions, ignoring domain gaps between different modalities. To address this issue, KPHD-Net, based on HÃ¶lder divergence, is proposed for multi-view classification and clustering tasks. Generally, our KPHD-Net employs a variational Dirichlet distribution to represent class probability distributions, models evidences from different views, and then integrates it with Dempster-Shafer evidence theory (DST) to improve uncertainty estimation effects. Our theoretical analysis demonstrates that Proper HÃ¶lder divergence offers a more effective measure of distribution discrepancies, ensuring enhanced performance in multi-view learning. Moreover, Dempster-Shafer evidence theory, recognized for its superior performance in multi-view fusion tasks, is introduced and combined with the Kalman filter to provide future state estimations. This integration further enhances the reliability of the final fusion results. Extensive experiments show that the proposed KPHD-Net outperforms the current state-of-the-art methods in both classification and clustering tasks regarding accuracy, robustness, and reliability, with theoretical guarantees.
<div id='section'>Paperid: <span id='pid'>824, <a href='https://arxiv.org/pdf/2505.18280.pdf' target='_blank'>https://arxiv.org/pdf/2505.18280.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tsai Hor Chan, Dora Yan Zhang, Guosheng Yin, Lequan Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18280">Feature Preserving Shrinkage on Bayesian Neural Networks via the R2D2 Prior</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian neural networks (BNNs) treat neural network weights as random variables, which aim to provide posterior uncertainty estimates and avoid overfitting by performing inference on the posterior weights. However, the selection of appropriate prior distributions remains a challenging task, and BNNs may suffer from catastrophic inflated variance or poor predictive performance when poor choices are made for the priors. Existing BNN designs apply different priors to weights, while the behaviours of these priors make it difficult to sufficiently shrink noisy signals or they are prone to overshrinking important signals in the weights. To alleviate this problem, we propose a novel R2D2-Net, which imposes the R^2-induced Dirichlet Decomposition (R2D2) prior to the BNN weights. The R2D2-Net can effectively shrink irrelevant coefficients towards zero, while preventing key features from over-shrinkage. To approximate the posterior distribution of weights more accurately, we further propose a variational Gibbs inference algorithm that combines the Gibbs updating procedure and gradient-based optimization. This strategy enhances stability and consistency in estimation when the variational objective involving the shrinkage parameters is non-convex. We also analyze the evidence lower bound (ELBO) and the posterior concentration rates from a theoretical perspective. Experiments on both natural and medical image classification and uncertainty estimation tasks demonstrate satisfactory performance of our method.
<div id='section'>Paperid: <span id='pid'>825, <a href='https://arxiv.org/pdf/2504.07522.pdf' target='_blank'>https://arxiv.org/pdf/2504.07522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Cribeiro-Ramallo, Federico Matteucci, Paul Enciu, Alexander Jenke, Vadim Arzamasov, Thorsten Strufe, Klemens BÃ¶hm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07522">Adversarial Subspace Generation for Outlier Detection in High-Dimensional Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection in high-dimensional tabular data is challenging since data is often distributed across multiple lower-dimensional subspaces -- a phenomenon known as the Multiple Views effect (MV). This effect led to a large body of research focused on mining such subspaces, known as subspace selection. However, as the precise nature of the MV effect was not well understood, traditional methods had to rely on heuristic-driven search schemes that struggle to accurately capture the true structure of the data. Properly identifying these subspaces is critical for unsupervised tasks such as outlier detection or clustering, where misrepresenting the underlying data structure can hinder the performance. We introduce Myopic Subspace Theory (MST), a new theoretical framework that mathematically formulates the Multiple Views effect and writes subspace selection as a stochastic optimization problem. Based on MST, we introduce V-GAN, a generative method trained to solve such an optimization problem. This approach avoids any exhaustive search over the feature space while ensuring that the intrinsic data structure is preserved. Experiments on 42 real-world datasets show that using V-GAN subspaces to build ensemble methods leads to a significant increase in one-class classification performance -- compared to existing subspace selection, feature selection, and embedding methods. Further experiments on synthetic data show that V-GAN identifies subspaces more accurately while scaling better than other relevant subspace selection methods. These results confirm the theoretical guarantees of our approach and also highlight its practical viability in high-dimensional settings.
<div id='section'>Paperid: <span id='pid'>826, <a href='https://arxiv.org/pdf/2503.18562.pdf' target='_blank'>https://arxiv.org/pdf/2503.18562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nariman Naderi, Seyed Amir Ahmad Safavi-Naini, Thomas Savage, Zahra Atf, Peter Lewis, Girish Nadkarni, Ali Soroush
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18562">Self-Reported Confidence of Large Language Models in Gastroenterology: Analysis of Commercial, Open-Source, and Quantized Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study evaluated self-reported response certainty across several large language models (GPT, Claude, Llama, Phi, Mistral, Gemini, Gemma, and Qwen) using 300 gastroenterology board-style questions. The highest-performing models (GPT-o1 preview, GPT-4o, and Claude-3.5-Sonnet) achieved Brier scores of 0.15-0.2 and AUROC of 0.6. Although newer models demonstrated improved performance, all exhibited a consistent tendency towards overconfidence. Uncertainty estimation presents a significant challenge to the safe use of LLMs in healthcare. Keywords: Large Language Models; Confidence Elicitation; Artificial Intelligence; Gastroenterology; Uncertainty Quantification
<div id='section'>Paperid: <span id='pid'>827, <a href='https://arxiv.org/pdf/2503.05274.pdf' target='_blank'>https://arxiv.org/pdf/2503.05274.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sajad Marvi, Christoph Rist, Julian Schmidt, Julian Jordan, Abhinav Valada
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05274">Evidential Uncertainty Estimation for Multi-Modal Trajectory Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate trajectory prediction is crucial for autonomous driving, yet uncertainty in agent behavior and perception noise makes it inherently challenging. While multi-modal trajectory prediction models generate multiple plausible future paths with associated probabilities, effectively quantifying uncertainty remains an open problem. In this work, we propose a novel multi-modal trajectory prediction approach based on evidential deep learning that estimates both positional and mode probability uncertainty in real time. Our approach leverages a Normal Inverse Gamma distribution for positional uncertainty and a Dirichlet distribution for mode uncertainty. Unlike sampling-based methods, it infers both types of uncertainty in a single forward pass, significantly improving efficiency. Additionally, we experimented with uncertainty-driven importance sampling to improve training efficiency by prioritizing underrepresented high-uncertainty samples over redundant ones. We perform extensive evaluations of our method on the Argoverse 1 and Argoverse 2 datasets, demonstrating that it provides reliable uncertainty estimates while maintaining high trajectory prediction accuracy.
<div id='section'>Paperid: <span id='pid'>828, <a href='https://arxiv.org/pdf/2503.05088.pdf' target='_blank'>https://arxiv.org/pdf/2503.05088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changhong Lin, Jiarong Lin, Zhiqiang Sui, XiaoZhi Qu, Rui Wang, Kehua Sheng, Bo Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05088">An End-to-End Learning-Based Multi-Sensor Fusion for Autonomous Vehicle Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-sensor fusion is essential for autonomous vehicle localization, as it is capable of integrating data from various sources for enhanced accuracy and reliability. The accuracy of the integrated location and orientation depends on the precision of the uncertainty modeling. Traditional methods of uncertainty modeling typically assume a Gaussian distribution and involve manual heuristic parameter tuning. However, these methods struggle to scale effectively and address long-tail scenarios. To address these challenges, we propose a learning-based method that encodes sensor information using higher-order neural network features, thereby eliminating the need for uncertainty estimation. This method significantly eliminates the need for parameter fine-tuning by developing an end-to-end neural network that is specifically designed for multi-sensor fusion. In our experiments, we demonstrate the effectiveness of our approach in real-world autonomous driving scenarios. Results show that the proposed method outperforms existing multi-sensor fusion methods in terms of both accuracy and robustness. A video of the results can be viewed at https://youtu.be/q4iuobMbjME.
<div id='section'>Paperid: <span id='pid'>829, <a href='https://arxiv.org/pdf/2503.03241.pdf' target='_blank'>https://arxiv.org/pdf/2503.03241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Hou, He Zhu, Ruomei Liu, Yingke Su, Jinxiang Xia, Junran Wu, Ke Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.03241">Structural Entropy Guided Unsupervised Graph Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the emerging of huge amount of unlabeled data, unsupervised out-of-distribution (OOD) detection is vital for ensuring the reliability of graph neural networks (GNNs) by identifying OOD samples from in-distribution (ID) ones during testing, where encountering novel or unknown data is inevitable. Existing methods often suffer from compromised performance due to redundant information in graph structures, which impairs their ability to effectively differentiate between ID and OOD data. To address this challenge, we propose SEGO, an unsupervised framework that integrates structural entropy into OOD detection regarding graph classification. Specifically, within the architecture of contrastive learning, SEGO introduces an anchor view in the form of coding tree by minimizing structural entropy. The obtained coding tree effectively removes redundant information from graphs while preserving essential structural information, enabling the capture of distinct graph patterns between ID and OOD samples. Furthermore, we present a multi-grained contrastive learning scheme at local, global, and tree levels using triplet views, where coding trees with essential information serve as the anchor view. Extensive experiments on real-world datasets validate the effectiveness of SEGO, demonstrating superior performance over state-of-the-art baselines in OOD detection. Specifically, our method achieves the best performance on 9 out of 10 dataset pairs, with an average improvement of 3.7\% on OOD detection datasets, significantly surpassing the best competitor by 10.8\% on the FreeSolv/ToxCast dataset pair.
<div id='section'>Paperid: <span id='pid'>830, <a href='https://arxiv.org/pdf/2502.18285.pdf' target='_blank'>https://arxiv.org/pdf/2502.18285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Morteza Rohanian, Roya M. HÃ¼ppi, Farhad Nooralahzadeh, Noemi Dannecker, Yves Pauli, Werner Surbeck, Iris Sommer, Wolfram Hinzen, Nicolas Langer, Michael Krauthammer, Philipp Homan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18285">Uncertainty Modeling in Multimodal Speech Analysis Across the Psychosis Spectrum</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Capturing subtle speech disruptions across the psychosis spectrum is challenging because of the inherent variability in speech patterns. This variability reflects individual differences and the fluctuating nature of symptoms in both clinical and non-clinical populations. Accounting for uncertainty in speech data is essential for predicting symptom severity and improving diagnostic precision. Speech disruptions characteristic of psychosis appear across the spectrum, including in non-clinical individuals. We develop an uncertainty-aware model integrating acoustic and linguistic features to predict symptom severity and psychosis-related traits. Quantifying uncertainty in specific modalities allows the model to address speech variability, improving prediction accuracy. We analyzed speech data from 114 participants, including 32 individuals with early psychosis and 82 with low or high schizotypy, collected through structured interviews, semi-structured autobiographical tasks, and narrative-driven interactions in German. The model improved prediction accuracy, reducing RMSE and achieving an F1-score of 83% with ECE = 4.5e-2, showing robust performance across different interaction contexts. Uncertainty estimation improved model interpretability by identifying reliability differences in speech markers such as pitch variability, fluency disruptions, and spectral instability. The model dynamically adjusted to task structures, weighting acoustic features more in structured settings and linguistic features in unstructured contexts. This approach strengthens early detection, personalized assessment, and clinical decision-making in psychosis-spectrum research.
<div id='section'>Paperid: <span id='pid'>831, <a href='https://arxiv.org/pdf/2502.15833.pdf' target='_blank'>https://arxiv.org/pdf/2502.15833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alessandro Canevaro, Julian Schmidt, Mohammad Sajad Marvi, Hang Yu, Georg Martius, Julian Jordan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15833">Advancing Out-of-Distribution Detection via Local Neuroplasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the domain of machine learning, the assumption that training and test data share the same distribution is often violated in real-world scenarios, requiring effective out-of-distribution (OOD) detection. This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs). Unlike traditional multilayer perceptrons, KANs exhibit local plasticity, allowing them to preserve learned information while adapting to new tasks. Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples. We validate our approach on benchmarks from image and medical domains, demonstrating superior performance and robustness compared to state-of-the-art techniques. These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.
<div id='section'>Paperid: <span id='pid'>832, <a href='https://arxiv.org/pdf/2502.11864.pdf' target='_blank'>https://arxiv.org/pdf/2502.11864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Natalie Grabowsky, Annika MÃ¼tze, Joshua Wendland, Nils Jansen, Matthias Rottmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11864">Does Knowledge About Perceptual Uncertainty Help an Agent in Automated Driving?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Agents in real-world scenarios like automated driving deal with uncertainty in their environment, in particular due to perceptual uncertainty. Although, reinforcement learning is dedicated to autonomous decision-making under uncertainty these algorithms are typically not informed about the uncertainty currently contained in their environment. On the other hand, uncertainty estimation for perception itself is typically directly evaluated in the perception domain, e.g., in terms of false positive detection rates or calibration errors based on camera images. Its use for deciding on goal-oriented actions remains largely unstudied. In this paper, we investigate how an agent's behavior is influenced by an uncertain perception and how this behavior changes if information about this uncertainty is available. Therefore, we consider a proxy task, where the agent is rewarded for driving a route as fast as possible without colliding with other road users. For controlled experiments, we introduce uncertainty in the observation space by perturbing the perception of the given agent while informing the latter. Our experiments show that an unreliable observation space modeled by a perturbed perception leads to a defensive driving behavior of the agent. Furthermore, when adding the information about the current uncertainty directly to the observation space, the agent adapts to the specific situation and in general accomplishes its task faster while, at the same time, accounting for risks.
<div id='section'>Paperid: <span id='pid'>833, <a href='https://arxiv.org/pdf/2502.09824.pdf' target='_blank'>https://arxiv.org/pdf/2502.09824.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Onur Bagoren, Marc Micatka, Katherine A. Skinner, Aaron Marburg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09824">PUGS: Perceptual Uncertainty for Grasp Selection in Underwater Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When navigating and interacting in challenging environments where sensory information is imperfect and incomplete, robots must make decisions that account for these shortcomings. We propose a novel method for quantifying and representing such perceptual uncertainty in 3D reconstruction through occupancy uncertainty estimation. We develop a framework to incorporate it into grasp selection for autonomous manipulation in underwater environments. Instead of treating each measurement equally when deciding which location to grasp from, we present a framework that propagates uncertainty inherent in the multi-view reconstruction process into the grasp selection. We evaluate our method with both simulated and the real world data, showing that by accounting for uncertainty, the grasp selection becomes robust against partial and noisy measurements. Code will be made available at https://onurbagoren.github.io/PUGS/
<div id='section'>Paperid: <span id='pid'>834, <a href='https://arxiv.org/pdf/2502.09780.pdf' target='_blank'>https://arxiv.org/pdf/2502.09780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Yang, Bo Dai, Lin Xiao, Yuejie Chi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09780">Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-agent reinforcement learning (MARL) lies at the heart of a plethora of applications involving the interaction of a group of agents in a shared unknown environment. A prominent framework for studying MARL is Markov games, with the goal of finding various notions of equilibria in a sample-efficient manner, such as the Nash equilibrium (NE) and the coarse correlated equilibrium (CCE). However, existing sample-efficient approaches either require tailored uncertainty estimation under function approximation, or careful coordination of the players. In this paper, we propose a novel model-based algorithm, called VMG, that incentivizes exploration via biasing the empirical estimate of the model parameters towards those with a higher collective best-response values of all the players when fixing the other players' policies, thus encouraging the policy to deviate from its current equilibrium for more exploration. VMG is oblivious to different forms of function approximation, and permits simultaneous and uncoupled policy updates of all players. Theoretically, we also establish that VMG achieves a near-optimal regret for finding both the NEs of two-player zero-sum Markov games and CCEs of multi-player general-sum Markov games under linear function approximation in an online environment, which nearly match their counterparts with sophisticated uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>835, <a href='https://arxiv.org/pdf/2502.08445.pdf' target='_blank'>https://arxiv.org/pdf/2502.08445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yining Jiao, Sreekalyani Bhamidi, Huaizhi Qu, Carlton Zdanski, Julia Kimbell, Andrew Prince, Cameron Worden, Samuel Kirse, Christopher Rutter, Benjamin Shields, William Dunn, Jisan Mahmud, Tianlong Chen, Marc Niethammer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08445">LucidAtlas$: Learning Uncertainty-Aware, Covariate-Disentangled, Individualized Atlas Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of this work is to develop principled techniques to extract information from high dimensional data sets with complex dependencies in areas such as medicine that can provide insight into individual as well as population level variation. We develop $\texttt{LucidAtlas}$, an approach that can represent spatially varying information, and can capture the influence of covariates as well as population uncertainty. As a versatile atlas representation, $\texttt{LucidAtlas}$ offers robust capabilities for covariate interpretation, individualized prediction, population trend analysis, and uncertainty estimation, with the flexibility to incorporate prior knowledge. Additionally, we discuss the trustworthiness and potential risks of neural additive models for analyzing dependent covariates and then introduce a marginalization approach to explain the dependence of an individual predictor on the models' response (the atlas). To validate our method, we demonstrate its generalizability on two medical datasets. Our findings underscore the critical role of by-construction interpretable models in advancing scientific discovery. Our code will be publicly available upon acceptance.
<div id='section'>Paperid: <span id='pid'>836, <a href='https://arxiv.org/pdf/2502.04126.pdf' target='_blank'>https://arxiv.org/pdf/2502.04126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alejandro AntÃ³n Ruiz, John Kvarnstrand, Klas Arvidsson, AndrÃ©s AlayÃ³n Glazunov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04126">RC Measurement Uncertainty Estimation Method for Directive Antennas and Turntable Stirring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates measurement uncertainty in a Reverberation Chamber (RC) within the lower FR2 bands (24.25-29.5 GHz). The study focuses on the impact of several factors contributing to RC measurement uncertainty, including finite sample size, polarization imbalance, and spatial non-uniformity. A series of 24 measurements were conducted using a horn antenna, known for its directivity in mmWave frequencies, varying antenna parameters such as height, orientation, position on the turntable, and polarization within a predefined chamber volume. The measurement uncertainty was evaluated by a method based on the standardized 3GPP and CTIA approaches, incorporating uncorrelated measurements and analyzing Pearson correlation coefficients between measurement pairs. An analysis of variance (ANOVA) was performed on the frequency-averaged power transfer function to identify the significance and impact of each variable on measurement variability. Additionally, the K-factor was estimated for each measurement set as part of the RC characterization, using an alternative approach to account for the turntable stirring effect. The findings highlight which variables most significantly influence measurement uncertainty, where the antenna orientation emerges as the most significant factor for the mmWave directive antenna setup.
<div id='section'>Paperid: <span id='pid'>837, <a href='https://arxiv.org/pdf/2502.02657.pdf' target='_blank'>https://arxiv.org/pdf/2502.02657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifu Tao, Maurice Fallon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.02657">SiLVR: Scalable Lidar-Visual Radiance Field Reconstruction with Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a neural radiance field (NeRF) based large-scale reconstruction system that fuses lidar and vision data to generate high-quality reconstructions that are geometrically accurate and capture photorealistic texture. Our system adopts the state-of-the-art NeRF representation to incorporate lidar. Adding lidar data adds strong geometric constraints on the depth and surface normals, which is particularly useful when modelling uniform texture surfaces which contain ambiguous visual reconstruction cues. A key contribution of this work is a novel method to quantify the epistemic uncertainty of the lidar-visual NeRF reconstruction by estimating the spatial variance of each point location in the radiance field given the sensor observations from the cameras and lidar. This provides a principled approach to evaluate the contribution of each sensor modality to the final reconstruction. In this way, reconstructions that are uncertain (due to e.g. uniform visual texture, limited observation viewpoints, or little lidar coverage) can be identified and removed. Our system is integrated with a real-time lidar SLAM system which is used to bootstrap a Structure-from-Motion (SfM) reconstruction procedure. It also helps to properly constrain the overall metric scale which is essential for the lidar depth loss. The refined SLAM trajectory can then be divided into submaps using Spectral Clustering to group sets of co-visible images together. This submapping approach is more suitable for visual reconstruction than distance-based partitioning. Our uncertainty estimation is particularly effective when merging submaps as their boundaries often contain artefacts due to limited observations. We demonstrate the reconstruction system using a multi-camera, lidar sensor suite in experiments involving both robot-mounted and handheld scanning. Our test datasets cover a total area of more than 20,000 square metres.
<div id='section'>Paperid: <span id='pid'>838, <a href='https://arxiv.org/pdf/2502.02657.pdf' target='_blank'>https://arxiv.org/pdf/2502.02657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifu Tao, Maurice Fallon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.02657">SiLVR: Scalable Lidar-Visual Radiance Field Reconstruction with Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a neural radiance field (NeRF) based large-scale reconstruction system that fuses lidar and vision data to generate high-quality reconstructions that are geometrically accurate and capture photorealistic texture. Our system adopts the state-of-the-art NeRF representation to incorporate lidar. Adding lidar data adds strong geometric constraints on the depth and surface normals, which is particularly useful when modelling uniform texture surfaces which contain ambiguous visual reconstruction cues. A key contribution of this work is a novel method to quantify the epistemic uncertainty of the lidar-visual NeRF reconstruction by estimating the spatial variance of each point location in the radiance field given the sensor observations from the cameras and lidar. This provides a principled approach to evaluate the contribution of each sensor modality to the final reconstruction. In this way, reconstructions that are uncertain (due to e.g. uniform visual texture, limited observation viewpoints, or little lidar coverage) can be identified and removed. Our system is integrated with a real-time lidar SLAM system which is used to bootstrap a Structure-from-Motion (SfM) reconstruction procedure. It also helps to properly constrain the overall metric scale which is essential for the lidar depth loss. The refined SLAM trajectory can then be divided into submaps using Spectral Clustering to group sets of co-visible images together. This submapping approach is more suitable for visual reconstruction than distance-based partitioning. Our uncertainty estimation is particularly effective when merging submaps as their boundaries often contain artefacts due to limited observations. We demonstrate the reconstruction system using a multi-camera, lidar sensor suite in experiments involving both robot-mounted and handheld scanning. Our test datasets cover a total area of more than 20,000 square metres.
<div id='section'>Paperid: <span id='pid'>839, <a href='https://arxiv.org/pdf/2501.08440.pdf' target='_blank'>https://arxiv.org/pdf/2501.08440.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabri Mustafa Kahya, Boran Hamdi Sivrikaya, Muhammet Sami Yavuz, Eckehard Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08440">FARE: A Deep Learning-Based Framework for Radar-based Face Recognition and Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose a novel pipeline for face recognition and out-of-distribution (OOD) detection using short-range FMCW radar. The proposed system utilizes Range-Doppler and micro Range-Doppler Images. The architecture features a primary path (PP) responsible for the classification of in-distribution (ID) faces, complemented by intermediate paths (IPs) dedicated to OOD detection. The network is trained in two stages: first, the PP is trained using triplet loss to optimize ID face classification. In the second stage, the PP is frozen, and the IPs-comprising simple linear autoencoder networks-are trained specifically for OOD detection. Using our dataset generated with a 60 GHz FMCW radar, our method achieves an ID classification accuracy of 99.30% and an OOD detection AUROC of 96.91%.
<div id='section'>Paperid: <span id='pid'>840, <a href='https://arxiv.org/pdf/2412.01705.pdf' target='_blank'>https://arxiv.org/pdf/2412.01705.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anuja Vats, Ivar Farup, Marius Pedersen, Kiran Raja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01705">Uncertainty-Aware Regularization for Image-to-Image Translation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The importance of quantifying uncertainty in deep networks has become paramount for reliable real-world applications. In this paper, we propose a method to improve uncertainty estimation in medical Image-to-Image (I2I) translation. Our model integrates aleatoric uncertainty and employs Uncertainty-Aware Regularization (UAR) inspired by simple priors to refine uncertainty estimates and enhance reconstruction quality. We show that by leveraging simple priors on parameters, our approach captures more robust uncertainty maps, effectively refining them to indicate precisely where the network encounters difficulties, while being less affected by noise. Our experiments demonstrate that UAR not only improves translation performance, but also provides better uncertainty estimations, particularly in the presence of noise and artifacts. We validate our approach using two medical imaging datasets, showcasing its effectiveness in maintaining high confidence in familiar regions while accurately identifying areas of uncertainty in novel/ambiguous scenarios.
<div id='section'>Paperid: <span id='pid'>841, <a href='https://arxiv.org/pdf/2411.05619.pdf' target='_blank'>https://arxiv.org/pdf/2411.05619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhilong Zhang, Ruifeng Chen, Junyin Ye, Yihao Sun, Pengyuan Wang, Jingcheng Pang, Kaiyuan Li, Tianshuo Liu, Haoxin Lin, Yang Yu, Zhi-Hua Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05619">WHALE: Towards Generalizable and Scalable World Models for Embodied Decision-making</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>World models play a crucial role in decision-making within embodied environments, enabling cost-free explorations that would otherwise be expensive in the real world. To facilitate effective decision-making, world models must be equipped with strong generalizability to support faithful imagination in out-of-distribution (OOD) regions and provide reliable uncertainty estimation to assess the credibility of the simulated experiences, both of which present significant challenges for prior scalable approaches. This paper introduces WHALE, a framework for learning generalizable world models, consisting of two key techniques: behavior-conditioning and retracing-rollout. Behavior-conditioning addresses the policy distribution shift, one of the primary sources of the world model generalization error, while retracing-rollout enables efficient uncertainty estimation without the necessity of model ensembles. These techniques are universal and can be combined with any neural network architecture for world model learning. Incorporating these two techniques, we present Whale-ST, a scalable spatial-temporal transformer-based world model with enhanced generalizability. We demonstrate the superiority of Whale-ST in simulation tasks by evaluating both value estimation accuracy and video generation fidelity. Additionally, we examine the effectiveness of our uncertainty estimation technique, which enhances model-based policy optimization in fully offline scenarios. Furthermore, we propose Whale-X, a 414M parameter world model trained on 970K trajectories from Open X-Embodiment datasets. We show that Whale-X exhibits promising scalability and strong generalizability in real-world manipulation scenarios using minimal demonstrations.
<div id='section'>Paperid: <span id='pid'>842, <a href='https://arxiv.org/pdf/2411.00826.pdf' target='_blank'>https://arxiv.org/pdf/2411.00826.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Zhang, Ming Li, Chun Li, Zhaoxia Liu, Ye Zhang, Fei Richard Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00826">Uncertainty Quantification via HÃ¶lder Divergence for Multi-View Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evidence-based deep learning represents a burgeoning paradigm for uncertainty estimation, offering reliable predictions with negligible extra computational overheads. Existing methods usually adopt Kullback-Leibler divergence to estimate the uncertainty of network predictions, ignoring domain gaps among various modalities. To tackle this issue, this paper introduces a novel algorithm based on HÃ¶lder Divergence (HD) to enhance the reliability of multi-view learning by addressing inherent uncertainty challenges from incomplete or noisy data. Generally, our method extracts the representations of multiple modalities through parallel network branches, and then employs HD to estimate the prediction uncertainties. Through the Dempster-Shafer theory, integration of uncertainty from different modalities, thereby generating a comprehensive result that considers all available representations. Mathematically, HD proves to better measure the ``distance'' between real data distribution and predictive distribution of the model and improve the performances of multi-class recognition tasks.
  Specifically, our method surpass the existing state-of-the-art counterparts on all evaluating benchmarks.
  We further conduct extensive experiments on different backbones to verify our superior robustness. It is demonstrated that our method successfully pushes the corresponding performance boundaries. Finally, we perform experiments on more challenging scenarios, \textit{i.e.}, learning with incomplete or noisy data, revealing that our method exhibits a high tolerance to such corrupted data.
<div id='section'>Paperid: <span id='pid'>843, <a href='https://arxiv.org/pdf/2409.11373.pdf' target='_blank'>https://arxiv.org/pdf/2409.11373.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edgar Heinert, Stephan Tilgner, Timo Palm, Matthias Rottmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11373">Uncertainty and Prediction Quality Estimation for Semantic Segmentation via Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When employing deep neural networks (DNNs) for semantic segmentation in safety-critical applications like automotive perception or medical imaging, it is important to estimate their performance at runtime, e.g. via uncertainty estimates or prediction quality estimates. Previous works mostly performed uncertainty estimation on pixel-level. In a line of research, a connected-component-wise (segment-wise) perspective was taken, approaching uncertainty estimation on an object-level by performing so-called meta classification and regression to estimate uncertainty and prediction quality, respectively. In those works, each predicted segment is considered individually to estimate its uncertainty or prediction quality. However, the neighboring segments may provide additional hints on whether a given predicted segment is of high quality, which we study in the present work. On the basis of uncertainty indicating metrics on segment-level, we use graph neural networks (GNNs) to model the relationship of a given segment's quality as a function of the given segment's metrics as well as those of its neighboring segments. We compare different GNN architectures and achieve a notable performance improvement.
<div id='section'>Paperid: <span id='pid'>844, <a href='https://arxiv.org/pdf/2409.04720.pdf' target='_blank'>https://arxiv.org/pdf/2409.04720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyu Gao, Mengyuan Chen, Liangyu Xiang, Changsheng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04720">A Comprehensive Survey on Evidential Deep Learning and Its Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation has become a crucial requirement for the industrial deployment of deep learning algorithms, particularly in high-risk applications such as autonomous driving and medical diagnosis. However, mainstream uncertainty estimation methods, based on deep ensembling or Bayesian neural networks, generally impose substantial computational overhead. To address this challenge, a novel paradigm called Evidential Deep Learning (EDL) has emerged, providing reliable uncertainty estimation with minimal additional computation in a single forward pass. This survey provides a comprehensive overview of the current research on EDL, designed to offer readers a broad introduction to the field without assuming prior knowledge. Specifically, we first delve into the theoretical foundation of EDL, the subjective logic theory, and discuss its distinctions from other uncertainty estimation frameworks. We further present existing theoretical advancements in EDL from four perspectives: reformulating the evidence collection process, improving uncertainty estimation via OOD samples, delving into various training strategies, and evidential regression networks. Thereafter, we elaborate on its extensive applications across various machine learning paradigms and downstream tasks. In the end, an outlook on future directions for better performances and broader adoption of EDL is provided, highlighting potential research avenues.
<div id='section'>Paperid: <span id='pid'>845, <a href='https://arxiv.org/pdf/2408.16469.pdf' target='_blank'>https://arxiv.org/pdf/2408.16469.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Jiang, Sicheng Zhao, Jiankun Zhu, Wenbo Tang, Zhaopan Xu, Jidong Yang, Guoping Liu, Tengfei Xing, Pengfei Xu, Hongxun Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16469">Multi-source Domain Adaptation for Panoramic Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised domain adaptation methods for panoramic semantic segmentation utilize real pinhole images or low-cost synthetic panoramic images to transfer segmentation models to real panoramic images. However, these methods struggle to understand the panoramic structure using only real pinhole images and lack real-world scene perception with only synthetic panoramic images. Therefore, in this paper, we propose a new task, Multi-source Domain Adaptation for Panoramic Semantic Segmentation (MSDA4PASS), which leverages both real pinhole and synthetic panoramic images to improve segmentation on unlabeled real panoramic images. There are two key issues in the MSDA4PASS task: (1) distortion gaps between the pinhole and panoramic domains -- panoramic images exhibit global and local distortions absent in pinhole images; (2) texture gaps between the source and target domains -- scenes and styles differ across domains. To address these two issues, we propose a novel framework, Deformation Transform Aligner for Panoramic Semantic Segmentation (DTA4PASS), which converts all pinhole images in the source domains into distorted images and aligns the source distorted and panoramic images with the target panoramic images. Specifically, DTA4PASS consists of two main components: Unpaired Semantic Morphing (USM) and Distortion Gating Alignment (DGA). First, in USM, the Dual-view Discriminator (DvD) assists in training the diffeomorphic deformation network at the image and pixel level, enabling the effective deformation transformation of pinhole images without paired panoramic views, alleviating distortion gaps. Second, DGA assigns pinhole-like (pin-like) and panoramic-like (pan-like) features to each image by gating, and aligns these two features through uncertainty estimation, reducing texture gaps.
<div id='section'>Paperid: <span id='pid'>846, <a href='https://arxiv.org/pdf/2406.04546.pdf' target='_blank'>https://arxiv.org/pdf/2406.04546.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabri Mustafa Kahya, Boran Hamdi Sivrikaya, Muhammet Sami Yavuz, Eckehard Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04546">FOOD: Facial Authentication and Out-of-Distribution Detection with Short-Range FMCW Radar</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a short-range FMCW radar-based facial authentication and out-of-distribution (OOD) detection framework. Our pipeline jointly estimates the correct classes for the in-distribution (ID) samples and detects the OOD samples to prevent their inaccurate prediction. Our reconstruction-based architecture consists of a main convolutional block with one encoder and multi-decoder configuration, and intermediate linear encoder-decoder parts. Together, these elements form an accurate human face classifier and a robust OOD detector. For our dataset, gathered using a 60 GHz short-range FMCW radar, our network achieves an average classification accuracy of 98.07% in identifying in-distribution human faces. As an OOD detector, it achieves an average Area Under the Receiver Operating Characteristic (AUROC) curve of 98.50% and an average False Positive Rate at 95% True Positive Rate (FPR95) of 6.20%. Also, our extensive experiments show that the proposed approach outperforms previous OOD detectors in terms of common OOD detection metrics.
<div id='section'>Paperid: <span id='pid'>847, <a href='https://arxiv.org/pdf/2405.05286.pdf' target='_blank'>https://arxiv.org/pdf/2405.05286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soyed Tuhin Ahmed, Michael Hefenbrock, Mehdi B. Tahoori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.05286">Tiny Deep Ensemble: Uncertainty Estimation in Edge AI Accelerators via Ensembling Normalization Layers with Shared Weights</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The applications of artificial intelligence (AI) are rapidly evolving, and they are also commonly used in safety-critical domains, such as autonomous driving and medical diagnosis, where functional safety is paramount. In AI-driven systems, uncertainty estimation allows the user to avoid overconfidence predictions and achieve functional safety. Therefore, the robustness and reliability of model predictions can be improved. However, conventional uncertainty estimation methods, such as the deep ensemble method, impose high computation and, accordingly, hardware (latency and energy) overhead because they require the storage and processing of multiple models. Alternatively, Monte Carlo dropout (MC-dropout) methods, although having low memory overhead, necessitate numerous ($\sim 100$) forward passes, leading to high computational overhead and latency. Thus, these approaches are not suitable for battery-powered edge devices with limited computing and memory resources. In this paper, we propose the Tiny-Deep Ensemble approach, a low-cost approach for uncertainty estimation on edge devices. In our approach, only normalization layers are ensembled $M$ times, with all ensemble members sharing common weights and biases, leading to a significant decrease in storage requirements and latency. Moreover, our approach requires only one forward pass in a hardware architecture that allows batch processing for inference and uncertainty estimation. Furthermore, it has approximately the same memory overhead compared to a single model. Therefore, latency and memory overhead are reduced by a factor of up to $\sim M\times$. Nevertheless, our method does not compromise accuracy, with an increase in inference accuracy of up to $\sim 1\%$ and a reduction in RMSE of $17.17\%$ in various benchmark datasets, tasks, and state-of-the-art architectures.
<div id='section'>Paperid: <span id='pid'>848, <a href='https://arxiv.org/pdf/2405.03953.pdf' target='_blank'>https://arxiv.org/pdf/2405.03953.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixing Zhang, Tao Pang, Jing Han, BjÃ¶rn W. Schuller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.03953">Intelligent Cardiac Auscultation for Murmur Detection via Parallel-Attentive Models with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Heart murmurs are a common manifestation of cardiovascular diseases and can provide crucial clues to early cardiac abnormalities. While most current research methods primarily focus on the accuracy of models, they often overlook other important aspects such as the interpretability of machine learning algorithms and the uncertainty of predictions. This paper introduces a heart murmur detection method based on a parallel-attentive model, which consists of two branches: One is based on a self-attention module and the other one is based on a convolutional network. Unlike traditional approaches, this structure is better equipped to handle long-term dependencies in sequential data, and thus effectively captures the local and global features of heart murmurs. Additionally, we acknowledge the significance of understanding the uncertainty of model predictions in the medical field for clinical decision-making. Therefore, we have incorporated an effective uncertainty estimation method based on Monte Carlo Dropout into our model. Furthermore, we have employed temperature scaling to calibrate the predictions of our probabilistic model, enhancing its reliability. In experiments conducted on the CirCor Digiscope dataset for heart murmur detection, our proposed method achieves a weighted accuracy of 79.8% and an F1 of 65.1%, representing state-of-the-art results.
<div id='section'>Paperid: <span id='pid'>849, <a href='https://arxiv.org/pdf/2405.03060.pdf' target='_blank'>https://arxiv.org/pdf/2405.03060.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhaiming Shen, Menglun Wang, Guang Cheng, Ming-Jun Lai, Lin Mu, Ruihao Huang, Qi Liu, Hao Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.03060">Tree-based Ensemble Learning for Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Being able to successfully determine whether the testing samples has similar distribution as the training samples is a fundamental question to address before we can safely deploy most of the machine learning models into practice. In this paper, we propose TOOD detection, a simple yet effective tree-based out-of-distribution (TOOD) detection mechanism to determine if a set of unseen samples will have similar distribution as of the training samples. The TOOD detection mechanism is based on computing pairwise hamming distance of testing samples' tree embeddings, which are obtained by fitting a tree-based ensemble model through in-distribution training samples. Our approach is interpretable and robust for its tree-based nature. Furthermore, our approach is efficient, flexible to various machine learning tasks, and can be easily generalized to unsupervised setting. Extensive experiments are conducted to show the proposed method outperforms other state-of-the-art out-of-distribution detection methods in distinguishing the in-distribution from out-of-distribution on various tabular, image, and text data.
<div id='section'>Paperid: <span id='pid'>850, <a href='https://arxiv.org/pdf/2404.15390.pdf' target='_blank'>https://arxiv.org/pdf/2404.15390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Josefina Catoni, Domonkos Martos, Ferenc Csikor, Enzo Ferrante, Diego H. Milone, BalÃ¡zs MeszÃ©na, GergÅ OrbÃ¡n, Rodrigo Echeveste
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15390">Uncertainty in latent representations of variational autoencoders optimized for visual tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Generative Models (DGMs) can learn flexible latent variable representations of images while avoiding intractable computations, common in Bayesian inference. However, investigating the properties of inference in Variational Autoencoders (VAEs), a major class of DGMs, reveals severe problems in their uncertainty representations. Here we draw inspiration from classical computer vision to introduce an inductive bias into the VAE by incorporating a global explaining-away latent variable, which remedies defective inference in VAEs. Unlike standard VAEs, the Explaing-Away VAE (EA-VAE) provides uncertainty estimates that align with normative requirements across a wide spectrum of perceptual tasks, including image corruption, interpolation, and out-of-distribution detection. We find that restored inference capabilities are delivered by developing a motif in the inference network (the encoder) which is widespread in biological neural networks: divisive normalization. Our results establish EA-VAEs as reliable tools to perform inference under deep generative models with appropriate estimates of uncertainty.
<div id='section'>Paperid: <span id='pid'>851, <a href='https://arxiv.org/pdf/2404.14451.pdf' target='_blank'>https://arxiv.org/pdf/2404.14451.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Cribeiro-Ramallo, Vadim Arzamasov, Federico Matteucci, Denis Wambold, Klemens BÃ¶hm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14451">Generative Subspace Adversarial Active Learning for Outlier Detection in Multiple Views of High-dimensional Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection in high-dimensional tabular data is an important task in data mining, essential for many downstream tasks and applications. Existing unsupervised outlier detection algorithms face one or more problems, including inlier assumption (IA), curse of dimensionality (CD), and multiple views (MV). To address these issues, we introduce Generative Subspace Adversarial Active Learning (GSAAL), a novel approach that uses a Generative Adversarial Network with multiple adversaries. These adversaries learn the marginal class probability functions over different data subspaces, while a single generator in the full space models the entire distribution of the inlier class. GSAAL is specifically designed to address the MV limitation while also handling the IA and CD, being the only method to do so. We provide a comprehensive mathematical formulation of MV, convergence guarantees for the discriminators, and scalability results for GSAAL. Our extensive experiments demonstrate the effectiveness and scalability of GSAAL, highlighting its superior performance compared to other popular OD methods, especially in MV scenarios.
<div id='section'>Paperid: <span id='pid'>852, <a href='https://arxiv.org/pdf/2404.06421.pdf' target='_blank'>https://arxiv.org/pdf/2404.06421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christian Marius Lillelund, Martin Magris, Christian Fischer Pedersen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06421">Efficient Training of Probabilistic Neural Networks for Survival Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Variational Inference (VI) is a commonly used technique for approximate Bayesian inference and uncertainty estimation in deep learning models, yet it comes at a computational cost, as it doubles the number of trainable parameters to represent uncertainty. This rapidly becomes challenging in high-dimensional settings and motivates the use of alternative techniques for inference, such as Monte Carlo Dropout (MCD) or Spectral-normalized Neural Gaussian Process (SNGP). However, such methods have seen little adoption in survival analysis, and VI remains the prevalent approach for training probabilistic neural networks. In this paper, we investigate how to train deep probabilistic survival models in large datasets without introducing additional overhead in model complexity. To achieve this, we adopt three probabilistic approaches, namely VI, MCD, and SNGP, and evaluate them in terms of their prediction performance, calibration performance, and model complexity. In the context of probabilistic survival analysis, we investigate whether non-VI techniques can offer comparable or possibly improved prediction performance and uncertainty calibration compared to VI. In the MIMIC-IV dataset, we find that MCD aligns with VI in terms of the concordance index (0.748 vs. 0.743) and mean absolute error (254.9 vs. 254.7) using hinge loss, while providing C-calibrated uncertainty estimates. Moreover, our SNGP implementation provides D-calibrated survival functions in all datasets compared to VI (4/4 vs. 2/4, respectively). Our work encourages the use of techniques alternative to VI for survival analysis in high-dimensional datasets, where computational efficiency and overhead are of concern.
<div id='section'>Paperid: <span id='pid'>853, <a href='https://arxiv.org/pdf/2404.06144.pdf' target='_blank'>https://arxiv.org/pdf/2404.06144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fatima Ezzeddine, Mirna Saad, Omran Ayoub, Davide Andreoletti, Martin Gjoreski, Ihab Sbeity, Marc Langheinrich, Silvia Giordano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06144">Differential Privacy for Anomaly Detection: Analyzing the Trade-off Between Privacy and Explainability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection (AD), also referred to as outlier detection, is a statistical process aimed at identifying observations within a dataset that significantly deviate from the expected pattern of the majority of the data. Such a process finds wide application in various fields, such as finance and healthcare. While the primary objective of AD is to yield high detection accuracy, the requirements of explainability and privacy are also paramount. The first ensures the transparency of the AD process, while the second guarantees that no sensitive information is leaked to untrusted parties. In this work, we exploit the trade-off of applying Explainable AI (XAI) through SHapley Additive exPlanations (SHAP) and differential privacy (DP). We perform AD with different models and on various datasets, and we thoroughly evaluate the cost of privacy in terms of decreased accuracy and explainability. Our results show that the enforcement of privacy through DP has a significant impact on detection accuracy and explainability, which depends on both the dataset and the considered AD model. We further show that the visual interpretation of explanations is also influenced by the choice of the AD algorithm.
<div id='section'>Paperid: <span id='pid'>854, <a href='https://arxiv.org/pdf/2404.04663.pdf' target='_blank'>https://arxiv.org/pdf/2404.04663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arne Schmidt, Pablo Morales-Ãlvarez, Lee A. D. Cooper, Lee A. Newberg, Andinet Enquobahrie, Aggelos K. Katsaggelos, Rafael Molina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04663">Focused Active Learning for Histopathological Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active Learning (AL) has the potential to solve a major problem of digital pathology: the efficient acquisition of labeled data for machine learning algorithms. However, existing AL methods often struggle in realistic settings with artifacts, ambiguities, and class imbalances, as commonly seen in the medical field. The lack of precise uncertainty estimations leads to the acquisition of images with a low informative value. To address these challenges, we propose Focused Active Learning (FocAL), which combines a Bayesian Neural Network with Out-of-Distribution detection to estimate different uncertainties for the acquisition function. Specifically, the weighted epistemic uncertainty accounts for the class imbalance, aleatoric uncertainty for ambiguous images, and an OoD score for artifacts. We perform extensive experiments to validate our method on MNIST and the real-world Panda dataset for the classification of prostate cancer. The results confirm that other AL methods are 'distracted' by ambiguities and artifacts which harm the performance. FocAL effectively focuses on the most informative images, avoiding ambiguities and artifacts during acquisition. For both experiments, FocAL outperforms existing AL approaches, reaching a Cohen's kappa of 0.764 with only 0.69% of the labeled Panda data.
<div id='section'>Paperid: <span id='pid'>855, <a href='https://arxiv.org/pdf/2403.15011.pdf' target='_blank'>https://arxiv.org/pdf/2403.15011.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Timo Kaiser, Maximilian Schier, Bodo Rosenhahn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15011">Cell Tracking according to Biological Needs -- Strong Mitosis-aware Multi-Hypothesis Tracker with Aleatoric Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cell tracking and segmentation assist biologists in extracting insights from large-scale microscopy time-lapse data. Driven by local accuracy metrics, current tracking approaches often suffer from a lack of long-term consistency and the ability to reconstruct lineage trees correctly. To address this issue, we introduce an uncertainty estimation technique for motion estimation frameworks and extend the multi-hypothesis tracking framework. Our uncertainty estimation lifts motion representations into probabilistic spatial densities using problem-specific test-time augmentations. Moreover, we introduce a novel mitosis-aware assignment problem formulation that allows multi-hypothesis trackers to model cell splits and to resolve false associations and mitosis detections based on long-term conflicts. In our framework, explicit biological knowledge is modeled in assignment costs. We evaluate our approach on nine competitive datasets and demonstrate that we outperform the current state-of-the-art on biologically inspired metrics substantially, achieving improvements by a factor of approximately 6 and uncover new insights into the behavior of motion estimation uncertainty.
<div id='section'>Paperid: <span id='pid'>856, <a href='https://arxiv.org/pdf/2402.17888.pdf' target='_blank'>https://arxiv.org/pdf/2402.17888.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Peng, Yadan Luo, Yonggang Zhang, Yixuan Li, Zhen Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17888">ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Post-hoc out-of-distribution (OOD) detection has garnered intensive attention in reliable machine learning. Many efforts have been dedicated to deriving score functions based on logits, distances, or rigorous data distribution assumptions to identify low-scoring OOD samples. Nevertheless, these estimate scores may fail to accurately reflect the true data density or impose impractical constraints. To provide a unified perspective on density-based score design, we propose a novel theoretical framework grounded in Bregman divergence, which extends distribution considerations to encompass an exponential family of distributions. Leveraging the conjugation constraint revealed in our theorem, we introduce a \textsc{ConjNorm} method, reframing density function design as a search for the optimal norm coefficient $p$ against the given dataset. In light of the computational challenges of normalization, we devise an unbiased and analytically tractable estimator of the partition function using the Monte Carlo-based importance sampling technique. Extensive experiments across OOD detection benchmarks empirically demonstrate that our proposed \textsc{ConjNorm} has established a new state-of-the-art in a variety of OOD detection setups, outperforming the current best method by up to 13.25$\%$ and 28.19$\%$ (FPR95) on CIFAR-100 and ImageNet-1K, respectively.
<div id='section'>Paperid: <span id='pid'>857, <a href='https://arxiv.org/pdf/2402.16255.pdf' target='_blank'>https://arxiv.org/pdf/2402.16255.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinqian Chen, Jihua Zhu, Qinghai Zheng, Zhongyu Li, Zhiqiang Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16255">Watch Your Head: Assembling Projection Heads to Save the Reliability of Federated Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning encounters substantial challenges with heterogeneous data, leading to performance degradation and convergence issues. While considerable progress has been achieved in mitigating such an impact, the reliability aspect of federated models has been largely disregarded. In this study, we conduct extensive experiments to investigate the reliability of both generic and personalized federated models. Our exploration uncovers a significant finding: \textbf{federated models exhibit unreliability when faced with heterogeneous data}, demonstrating poor calibration on in-distribution test data and low uncertainty levels on out-of-distribution data. This unreliability is primarily attributed to the presence of biased projection heads, which introduce miscalibration into the federated models. Inspired by this observation, we propose the "Assembled Projection Heads" (APH) method for enhancing the reliability of federated models. By treating the existing projection head parameters as priors, APH randomly samples multiple initialized parameters of projection heads from the prior and further performs targeted fine-tuning on locally available data under varying learning rates. Such a head ensemble introduces parameter diversity into the deterministic model, eliminating the bias and producing reliable predictions via head averaging. We evaluate the effectiveness of the proposed APH method across three prominent federated benchmarks. Experimental results validate the efficacy of APH in model calibration and uncertainty estimation. Notably, APH can be seamlessly integrated into various federated approaches but only requires less than 30\% additional computation cost for 100$\times$ inferences within large models.
<div id='section'>Paperid: <span id='pid'>858, <a href='https://arxiv.org/pdf/2402.11245.pdf' target='_blank'>https://arxiv.org/pdf/2402.11245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liming Huang, Yulei Wu, Juan Marcelo Parra-Ullauri, Reza Nejabati, Dimitra Simeonidou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11245">AI Model Placement for 6G Networks under Epistemic Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The adoption of Artificial Intelligence (AI) based Virtual Network Functions (VNFs) has witnessed significant growth, posing a critical challenge in orchestrating AI models within next-generation 6G networks. Finding optimal AI model placement is significantly more challenging than placing traditional software-based VNFs, due to the introduction of numerous uncertain factors by AI models, such as varying computing resource consumption, dynamic storage requirements, and changing model performance. To address the AI model placement problem under uncertainties, this paper presents a novel approach employing a sequence-to-sequence (S2S) neural network which considers uncertainty estimations. The S2S model, characterized by its encoding-decoding architecture, is designed to take the service chain with a number of AI models as input and produce the corresponding placement of each AI model. To address the introduced uncertainties, our methodology incorporates the orthonormal certificate module for uncertainty estimation and utilizes fuzzy logic for uncertainty representation, thereby enhancing the capabilities of the S2S model. Experiments demonstrate that the proposed method achieves competitive results across diverse AI model profiles, network environments, and service chain requests.
<div id='section'>Paperid: <span id='pid'>859, <a href='https://arxiv.org/pdf/2402.03846.pdf' target='_blank'>https://arxiv.org/pdf/2402.03846.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Cribeiro-Ramallo, Vadim Arzamasov, Klemens BÃ¶hm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03846">Efficient Generation of Hidden Outliers for Improved Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier generation is a popular technique used for solving important outlier detection tasks. Generating outliers with realistic behavior is challenging. Popular existing methods tend to disregard the 'multiple views' property of outliers in high-dimensional spaces. The only existing method accounting for this property falls short in efficiency and effectiveness. We propose BISECT, a new outlier generation method that creates realistic outliers mimicking said property. To do so, BISECT employs a novel proposition introduced in this article stating how to efficiently generate said realistic outliers. Our method has better guarantees and complexity than the current methodology for recreating 'multiple views'. We use the synthetic outliers generated by BISECT to effectively enhance outlier detection in diverse datasets, for multiple use cases. For instance, oversampling with BISECT reduced the error by up to 3 times when compared with the baselines.
<div id='section'>Paperid: <span id='pid'>860, <a href='https://arxiv.org/pdf/2401.04744.pdf' target='_blank'>https://arxiv.org/pdf/2401.04744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soyed Tuhin Ahmed, Michael Hefenbrock, Guillaume Prenat, Lorena Anghel, Mehdi B. Tahoori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04744">Testing Spintronics Implemented Monte Carlo Dropout-Based Bayesian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Neural Networks (BayNNs) can inherently estimate predictive uncertainty, facilitating informed decision-making. Dropout-based BayNNs are increasingly implemented in spintronics-based computation-in-memory architectures for resource-constrained yet high-performance safety-critical applications. Although uncertainty estimation is important, the reliability of Dropout generation and BayNN computation is equally important for target applications but is overlooked in existing works. However, testing BayNNs is significantly more challenging compared to conventional NNs, due to their stochastic nature. In this paper, we present for the first time the model of the non-idealities of the spintronics-based Dropout module and analyze their impact on uncertainty estimates and accuracy. Furthermore, we propose a testing framework based on repeatability ranking for Dropout-based BayNN with up to $100\%$ fault coverage while using only $0.2\%$ of training data as test vectors.
<div id='section'>Paperid: <span id='pid'>861, <a href='https://arxiv.org/pdf/2312.08894.pdf' target='_blank'>https://arxiv.org/pdf/2312.08894.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabri Mustafa Kahya, Muhammet Sami Yavuz, Eckehard Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.08894">HAROOD: Human Activity Classification and Out-of-Distribution Detection with Short-Range FMCW Radar</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose HAROOD as a short-range FMCW radar-based human activity classifier and out-of-distribution (OOD) detector. It aims to classify human sitting, standing, and walking activities and to detect any other moving or stationary object as OOD. We introduce a two-stage network. The first stage is trained with a novel loss function that includes intermediate reconstruction loss, intermediate contrastive loss, and triplet loss. The second stage uses the first stage's output as its input and is trained with cross-entropy loss. It creates a simple classifier that performs the activity classification. On our dataset collected by 60 GHz short-range FMCW radar, we achieve an average classification accuracy of 96.51%. Also, we achieve an average AUROC of 95.04% as an OOD detector. Additionally, our extensive evaluations demonstrate the superiority of HAROOD over the state-of-the-art OOD detection methods in terms of standard OOD detection metrics.
<div id='section'>Paperid: <span id='pid'>862, <a href='https://arxiv.org/pdf/2312.08785.pdf' target='_blank'>https://arxiv.org/pdf/2312.08785.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcos Barcina-Blanco, Jesus L. Lobo, Pablo Garcia-Bringas, Javier Del Ser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.08785">Managing the unknown: a survey on Open Set Recognition and tangential areas</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world scenarios classification models are often required to perform robustly when predicting samples belonging to classes that have not appeared during its training stage. Open Set Recognition addresses this issue by devising models capable of detecting unknown classes from samples arriving during the testing phase, while maintaining a good level of performance in the classification of samples belonging to known classes. This review comprehensively overviews the recent literature related to Open Set Recognition, identifying common practices, limitations, and connections of this field with other machine learning research areas, such as continual learning, out-of-distribution detection, novelty detection, and uncertainty estimation. Our work also uncovers open problems and suggests several research directions that may motivate and articulate future efforts towards more safe Artificial Intelligence methods.
<div id='section'>Paperid: <span id='pid'>863, <a href='https://arxiv.org/pdf/2311.15816.pdf' target='_blank'>https://arxiv.org/pdf/2311.15816.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soyed Tuhin Ahmed, Kamal Danouchi, Michael Hefenbrock, Guillaume Prenat, Lorena Anghel, Mehdi B. Tahoori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.15816">Scale-Dropout: Estimating Uncertainty in Deep Neural Networks Using Stochastic Scale</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation in Neural Networks (NNs) is vital in improving reliability and confidence in predictions, particularly in safety-critical applications. Bayesian Neural Networks (BayNNs) with Dropout as an approximation offer a systematic approach to quantifying uncertainty, but they inherently suffer from high hardware overhead in terms of power, memory, and computation. Thus, the applicability of BayNNs to edge devices with limited resources or to high-performance applications is challenging. Some of the inherent costs of BayNNs can be reduced by accelerating them in hardware on a Computation-In-Memory (CIM) architecture with spintronic memories and binarizing their parameters. However, numerous stochastic units are required to implement conventional dropout-based BayNN. In this paper, we propose the Scale Dropout, a novel regularization technique for Binary Neural Networks (BNNs), and Monte Carlo-Scale Dropout (MC-Scale Dropout)-based BayNNs for efficient uncertainty estimation. Our approach requires only one stochastic unit for the entire model, irrespective of the model size, leading to a highly scalable Bayesian NN. Furthermore, we introduce a novel Spintronic memory-based CIM architecture for the proposed BayNN that achieves more than $100\times$ energy savings compared to the state-of-the-art. We validated our method to show up to a $1\%$ improvement in predictive performance and superior uncertainty estimates compared to related works.
<div id='section'>Paperid: <span id='pid'>864, <a href='https://arxiv.org/pdf/2311.11096.pdf' target='_blank'>https://arxiv.org/pdf/2311.11096.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Duy Minh Ho Nguyen, Tan Ngoc Pham, Nghiem Tuong Diep, Nghi Quoc Phan, Quang Pham, Vinh Tong, Binh T. Nguyen, Ngan Hoang Le, Nhat Ho, Pengtao Xie, Daniel Sonntag, Mathias Niepert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.11096">On the Out of Distribution Robustness of Foundation Models in Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing a robust model that can effectively generalize to test samples under distribution shifts remains a significant challenge in the field of medical imaging. The foundational models for vision and language, pre-trained on extensive sets of natural image and text data, have emerged as a promising approach. It showcases impressive learning abilities across different tasks with the need for only a limited amount of annotated samples. While numerous techniques have focused on developing better fine-tuning strategies to adapt these models for specific domains, we instead examine their robustness to domain shifts in the medical image segmentation task. To this end, we compare the generalization performance to unseen domains of various pre-trained models after being fine-tuned on the same in-distribution dataset and show that foundation-based models enjoy better robustness than other architectures. From here, we further developed a new Bayesian uncertainty estimation for frozen models and used them as an indicator to characterize the model's performance on out-of-distribution (OOD) data, proving particularly beneficial for real-world applications. Our experiments not only reveal the limitations of current indicators like accuracy on the line or agreement on the line commonly used in natural image applications but also emphasize the promise of the introduced Bayesian uncertainty. Specifically, lower uncertainty predictions usually tend to higher out-of-distribution (OOD) performance.
<div id='section'>Paperid: <span id='pid'>865, <a href='https://arxiv.org/pdf/2310.19359.pdf' target='_blank'>https://arxiv.org/pdf/2310.19359.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Morales-Ãlvarez, Arne Schmidt, JosÃ© Miguel HernÃ¡ndez-Lobato, Rafael Molina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19359">Introducing instance label correlation in multiple instance learning. Application to cancer detection on histopathological images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the last years, the weakly supervised paradigm of multiple instance learning (MIL) has become very popular in many different areas. A paradigmatic example is computational pathology, where the lack of patch-level labels for whole-slide images prevents the application of supervised models. Probabilistic MIL methods based on Gaussian Processes (GPs) have obtained promising results due to their excellent uncertainty estimation capabilities. However, these are general-purpose MIL methods that do not take into account one important fact: in (histopathological) images, the labels of neighboring patches are expected to be correlated. In this work, we extend a state-of-the-art GP-based MIL method, which is called VGPMIL-PR, to exploit such correlation. To do so, we develop a novel coupling term inspired by the statistical physics Ising model. We use variational inference to estimate all the model parameters. Interestingly, the VGPMIL-PR formulation is recovered when the weight that regulates the strength of the Ising term vanishes. The performance of the proposed method is assessed in two real-world problems of prostate cancer detection. We show that our model achieves better results than other state-of-the-art probabilistic MIL methods. We also provide different visualizations and analysis to gain insights into the influence of the novel Ising term. These insights are expected to facilitate the application of the proposed model to other research areas.
<div id='section'>Paperid: <span id='pid'>866, <a href='https://arxiv.org/pdf/2310.18080.pdf' target='_blank'>https://arxiv.org/pdf/2310.18080.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Denis Janiak, Jakub Binkowski, Piotr Bielak, Tomasz Kajdanowicz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18080">Unveiling the Potential of Probabilistic Embeddings in Self-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, self-supervised learning has played a pivotal role in advancing machine learning by allowing models to acquire meaningful representations from unlabeled data. An intriguing research avenue involves developing self-supervised models within an information-theoretic framework, but many studies often deviate from the stochasticity assumptions made when deriving their objectives. To gain deeper insights into this issue, we propose to explicitly model the representation with stochastic embeddings and assess their effects on performance, information compression and potential for out-of-distribution detection. From an information-theoretic perspective, we seek to investigate the impact of probabilistic modeling on the information bottleneck, shedding light on a trade-off between compression and preservation of information in both representation and loss space. Emphasizing the importance of distinguishing between these two spaces, we demonstrate how constraining one can affect the other, potentially leading to performance degradation. Moreover, our findings suggest that introducing an additional bottleneck in the loss space can significantly enhance the ability to detect out-of-distribution examples, only leveraging either representation features or the variance of their underlying distribution.
<div id='section'>Paperid: <span id='pid'>867, <a href='https://arxiv.org/pdf/2310.03388.pdf' target='_blank'>https://arxiv.org/pdf/2310.03388.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paolo Rabino, Antonio Alliegro, Francesco Cappio Borlino, Tatiana Tommasi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03388">OpenPatch: a 3D patchwork for Out-Of-Distribution detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Moving deep learning models from the laboratory setting to the open world entails preparing them to handle unforeseen conditions. In several applications the occurrence of novel classes during deployment poses a significant threat, thus it is crucial to effectively detect them. Ideally, this skill should be used when needed without requiring any further computational training effort at every new task. Out-of-distribution detection has attracted significant attention in the last years, however the majority of the studies deal with 2D images ignoring the inherent 3D nature of the real-world and often confusing between domain and semantic novelty. In this work, we focus on the latter, considering the objects geometric structure captured by 3D point clouds regardless of the specific domain. We advance the field by introducing OpenPatch that builds on a large pre-trained model and simply extracts from its intermediate features a set of patch representations that describe each known class. For any new sample, we obtain a novelty score by evaluating whether it can be recomposed mainly by patches of a single known class or rather via the contribution of multiple classes. We present an extensive experimental evaluation of our approach for the task of semantic novelty detection on real-world point cloud samples when the reference known data are synthetic. We demonstrate that OpenPatch excels in both the full and few-shot known sample scenarios, showcasing its robustness across varying pre-training objectives and network backbones. The inherent training-free nature of our method allows for its immediate application to a wide array of real-world tasks, offering a compelling advantage over approaches that need expensive retraining efforts.
<div id='section'>Paperid: <span id='pid'>868, <a href='https://arxiv.org/pdf/2310.00952.pdf' target='_blank'>https://arxiv.org/pdf/2310.00952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aldi Piroli, Vinzenz Dallabetta, Johannes Kopp, Marc Walessa, Daniel Meissner, Klaus Dietmayer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00952">LS-VOS: Identifying Outliers in 3D Object Detections Using Latent Space Virtual Outlier Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based 3D object detectors have achieved unprecedented speed and accuracy in autonomous driving applications. However, similar to other neural networks, they are often biased toward high-confidence predictions or return detections where no real object is present. These types of detections can lead to a less reliable environment perception, severely affecting the functionality and safety of autonomous vehicles. We address this problem by proposing LS-VOS, a framework for identifying outliers in 3D object detections. Our approach builds on the idea of Virtual Outlier Synthesis (VOS), which incorporates outlier knowledge during training, enabling the model to learn more compact decision boundaries. In particular, we propose a new synthesis approach that relies on the latent space of an auto-encoder network to generate outlier features with a parametrizable degree of similarity to in-distribution features. In extensive experiments, we show that our approach improves the outlier detection capabilities of a state-of-the-art object detector while maintaining high 3D object detection performance.
<div id='section'>Paperid: <span id='pid'>869, <a href='https://arxiv.org/pdf/2308.07324.pdf' target='_blank'>https://arxiv.org/pdf/2308.07324.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Vasiliuk, Daria Frolova, Mikhail Belyaev, Boris Shirokikh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07324">Redesigning Out-of-Distribution Detection on 3D Medical Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples for trusted medical image segmentation remains a significant challenge. The critical issue here is the lack of a strict definition of abnormal data, which often results in artificial problem settings without measurable clinical impact. In this paper, we redesign the OOD detection problem according to the specifics of volumetric medical imaging and related downstream tasks (e.g., segmentation). We propose using the downstream model's performance as a pseudometric between images to define abnormal samples. This approach enables us to weigh different samples based on their performance impact without an explicit ID/OOD distinction. We incorporate this weighting in a new metric called Expected Performance Drop (EPD). EPD is our core contribution to the new problem design, allowing us to rank methods based on their clinical impact. We demonstrate the effectiveness of EPD-based evaluation in 11 CT and MRI OOD detection challenges.
<div id='section'>Paperid: <span id='pid'>870, <a href='https://arxiv.org/pdf/2308.05075.pdf' target='_blank'>https://arxiv.org/pdf/2308.05075.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leo Benac, Sonali Parbhoo, Finale Doshi-Velez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05075">Bayesian Inverse Transition Learning for Offline Settings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline Reinforcement learning is commonly used for sequential decision-making in domains such as healthcare and education, where the rewards are known and the transition dynamics $T$ must be estimated on the basis of batch data. A key challenge for all tasks is how to learn a reliable estimate of the transition dynamics $T$ that produce near-optimal policies that are safe enough so that they never take actions that are far away from the best action with respect to their value functions and informative enough so that they communicate the uncertainties they have. Using data from an expert, we propose a new constraint-based approach that captures our desiderata for reliably learning a posterior distribution of the transition dynamics $T$ that is free from gradients. Our results demonstrate that by using our constraints, we learn a high-performing policy, while considerably reducing the policy's variance over different datasets. We also explain how combining uncertainty estimation with these constraints can help us infer a partial ranking of actions that produce higher returns, and helps us infer safer and more informative policies for planning.
<div id='section'>Paperid: <span id='pid'>871, <a href='https://arxiv.org/pdf/2308.04653.pdf' target='_blank'>https://arxiv.org/pdf/2308.04653.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Cesar Quihui-Rubio, Daniel Flores-Araiza, Gilberto Ochoa-Ruiz, Miguel Gonzalez-Mendoza, Christian Mata
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04653">Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study focuses on comparing deep learning methods for the segmentation and quantification of uncertainty in prostate segmentation from MRI images. The aim is to improve the workflow of prostate cancer detection and diagnosis. Seven different U-Net-based architectures, augmented with Monte-Carlo dropout, are evaluated for automatic segmentation of the central zone, peripheral zone, transition zone, and tumor, with uncertainty estimation. The top-performing model in this study is the Attention R2U-Net, achieving a mean Intersection over Union (IoU) of 76.3% and Dice Similarity Coefficient (DSC) of 85% for segmenting all zones. Additionally, Attention R2U-Net exhibits the lowest uncertainty values, particularly in the boundaries of the transition zone and tumor, when compared to the other models.
<div id='section'>Paperid: <span id='pid'>872, <a href='https://arxiv.org/pdf/2308.02396.pdf' target='_blank'>https://arxiv.org/pdf/2308.02396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabri Mustafa Kahya, Muhammet Sami Yavuz, Eckehard Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02396">HOOD: Real-Time Human Presence and Out-of-Distribution Detection Using FMCW Radar</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting human presence indoors with millimeter-wave frequency-modulated continuous-wave (FMCW) radar faces challenges from both moving and stationary clutter. This work proposes a robust and real-time capable human presence and out-of-distribution (OOD) detection method using 60 GHz short-range FMCW radar. HOOD solves the human presence and OOD detection problems simultaneously in a single pipeline. Our solution relies on a reconstruction-based architecture and works with radar macro and micro range-Doppler images (RDIs). HOOD aims to accurately detect the presence of humans in the presence or absence of moving and stationary disturbers. Since HOOD is also an OOD detector, it aims to detect moving or stationary clutters as OOD in humans' absence and predicts the current scene's output as "no presence." HOOD performs well in diverse scenarios, demonstrating its effectiveness across different human activities and situations. On our dataset collected with a 60 GHz short-range FMCW radar, we achieve an average AUROC of 94.36%. Additionally, our extensive evaluations and experiments demonstrate that HOOD outperforms state-of-the-art (SOTA) OOD detection methods in terms of common OOD detection metrics. Importantly, HOOD also perfectly fits on Raspberry Pi 3B+ with an ARM Cortex-A53 CPU, which showcases its versatility across different hardware environments. Videos of our human presence detection experiments are available at: https://muskahya.github.io/HOOD
<div id='section'>Paperid: <span id='pid'>873, <a href='https://arxiv.org/pdf/2306.10185.pdf' target='_blank'>https://arxiv.org/pdf/2306.10185.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soyed Tuhin Ahmed, Kamal Danouchi, Michael Hefenbrock, Guillaume Prenat, Lorena Anghel, Mehdi B. Tahoori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.10185">Spatial-SpinDrop: Spatial Dropout-based Binary Bayesian Neural Network with Spintronics Implementation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, machine learning systems have gained prominence in real-time, critical decision-making domains, such as autonomous driving and industrial automation. Their implementations should avoid overconfident predictions through uncertainty estimation. Bayesian Neural Networks (BayNNs) are principled methods for estimating predictive uncertainty. However, their computational costs and power consumption hinder their widespread deployment in edge AI. Utilizing Dropout as an approximation of the posterior distribution, binarizing the parameters of BayNNs, and further to that implementing them in spintronics-based computation-in-memory (CiM) hardware arrays provide can be a viable solution. However, designing hardware Dropout modules for convolutional neural network (CNN) topologies is challenging and expensive, as they may require numerous Dropout modules and need to use spatial information to drop certain elements. In this paper, we introduce MC-SpatialDropout, a spatial dropout-based approximate BayNNs with spintronics emerging devices. Our method utilizes the inherent stochasticity of spintronic devices for efficient implementation of the spatial dropout module compared to existing implementations. Furthermore, the number of dropout modules per network layer is reduced by a factor of $9\times$ and energy consumption by a factor of $94.11\times$, while still achieving comparable predictive performance and uncertainty estimates compared to related works.
<div id='section'>Paperid: <span id='pid'>874, <a href='https://arxiv.org/pdf/2306.06048.pdf' target='_blank'>https://arxiv.org/pdf/2306.06048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifei Ming, Yixuan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06048">How Does Fine-Tuning Impact Out-of-Distribution Detection for Vision-Language Models?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent large vision-language models such as CLIP have shown remarkable out-of-distribution (OOD) detection and generalization performance. However, their zero-shot in-distribution (ID) accuracy is often limited for downstream datasets. Recent CLIP-based fine-tuning methods such as prompt learning have demonstrated significant improvements in ID classification and OOD generalization where OOD labels are available. Nonetheless, it remains unclear whether the model is reliable to semantic shifts without OOD labels. In this paper, we aim to bridge the gap and present a comprehensive study to understand how fine-tuning impact OOD detection for few-shot downstream tasks. By framing OOD detection as multi-modal concept matching, we establish a connection between fine-tuning methods and various OOD scores. Our results suggest that a proper choice of OOD scores is essential for CLIP-based fine-tuning. In particular, the maximum concept matching (MCM) score provides a promising solution consistently. We also show that prompt learning demonstrates the state-of-the-art OOD detection performance over the zero-shot counterpart.
<div id='section'>Paperid: <span id='pid'>875, <a href='https://arxiv.org/pdf/2306.03522.pdf' target='_blank'>https://arxiv.org/pdf/2306.03522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eduardo Dadalto, Pierre Colombo, Guillaume Staerman, Nathan Noiry, Pablo Piantanida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03522">A Functional Data Perspective and Baseline On Multi-Layer Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A key feature of out-of-distribution (OOD) detection is to exploit a trained neural network by extracting statistical patterns and relationships through the multi-layer classifier to detect shifts in the expected input data distribution. Despite achieving solid results, several state-of-the-art methods rely on the penultimate or last layer outputs only, leaving behind valuable information for OOD detection. Methods that explore the multiple layers either require a special architecture or a supervised objective to do so. This work adopts an original approach based on a functional view of the network that exploits the sample's trajectories through the various layers and their statistical dependencies. It goes beyond multivariate features aggregation and introduces a baseline rooted in functional anomaly detection. In this new framework, OOD detection translates into detecting samples whose trajectories differ from the typical behavior characterized by the training set. We validate our method and empirically demonstrate its effectiveness in OOD detection compared to strong state-of-the-art baselines on computer vision benchmarks.
<div id='section'>Paperid: <span id='pid'>876, <a href='https://arxiv.org/pdf/2305.17382.pdf' target='_blank'>https://arxiv.org/pdf/2305.17382.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuhai Chen, Yue Han, Jiangning Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.17382">APRIL-GAN: A Zero-/Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challenge Tracks 1&2: 1st Place on Zero-shot AD and 4th Place on Few-shot AD</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this technical report, we briefly introduce our solution for the Zero/Few-shot Track of the Visual Anomaly and Novelty Detection (VAND) 2023 Challenge. For industrial visual inspection, building a single model that can be rapidly adapted to numerous categories without or with only a few normal reference images is a promising research direction. This is primarily because of the vast variety of the product types. For the zero-shot track, we propose a solution based on the CLIP model by adding extra linear layers. These layers are used to map the image features to the joint embedding space, so that they can compare with the text features to generate the anomaly maps. Besides, when the reference images are available, we utilize multiple memory banks to store their features and compare them with the features of the test images during the testing phase. In this challenge, our method achieved first place in the zero-shot track, especially excelling in segmentation with an impressive F1 score improvement of 0.0489 over the second-ranked participant. Furthermore, in the few-shot track, we secured the fourth position overall, with our classification F1 score of 0.8687 ranking first among all participating teams.
<div id='section'>Paperid: <span id='pid'>877, <a href='https://arxiv.org/pdf/2305.16129.pdf' target='_blank'>https://arxiv.org/pdf/2305.16129.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aldi Piroli, Vinzenz Dallabetta, Johannes Kopp, Marc Walessa, Daniel Meissner, Klaus Dietmayer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.16129">Energy-based Detection of Adverse Weather Effects in LiDAR Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous vehicles rely on LiDAR sensors to perceive the environment. Adverse weather conditions like rain, snow, and fog negatively affect these sensors, reducing their reliability by introducing unwanted noise in the measurements. In this work, we tackle this problem by proposing a novel approach for detecting adverse weather effects in LiDAR data. We reformulate this problem as an outlier detection task and use an energy-based framework to detect outliers in point clouds. More specifically, our method learns to associate low energy scores with inlier points and high energy scores with outliers allowing for robust detection of adverse weather effects. In extensive experiments, we show that our method performs better in adverse weather detection and has higher robustness to unseen weather effects than previous state-of-the-art methods. Furthermore, we show how our method can be used to perform simultaneous outlier detection and semantic segmentation. Finally, to help expand the research field of LiDAR perception in adverse weather, we release the SemanticSpray dataset, which contains labeled vehicle spray data in highway-like scenarios. The dataset is available at https://semantic-spray-dataset.github.io .
<div id='section'>Paperid: <span id='pid'>878, <a href='https://arxiv.org/pdf/2305.14735.pdf' target='_blank'>https://arxiv.org/pdf/2305.14735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vyoma Raman, Eve Fleisig, Dan Klein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.14735">Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The impact of AI models on marginalized communities has traditionally been measured by identifying performance differences between specified demographic subgroups. Though this approach aims to center vulnerable groups, it risks obscuring patterns of harm faced by intersectional subgroups or shared across multiple groups. To address this, we draw on theories of marginalization from disability studies and related disciplines, which state that people farther from the norm face greater adversity, to consider the "margins" in the domain of toxicity detection. We operationalize the "margins" of a dataset by employing outlier detection to identify text about people with demographic attributes distant from the "norm". We find that model performance is consistently worse for demographic outliers, with mean squared error (MSE) between outliers and non-outliers up to 70.4% worse across toxicity types. It is also worse for text outliers, with a MSE up to 68.4% higher for outliers than non-outliers. We also find text and demographic outliers to be particularly susceptible to errors in the classification of severe toxicity and identity attacks. Compared to analysis of disparities using traditional demographic breakdowns, we find that our outlier analysis frequently surfaces greater harms faced by a larger, more intersectional group, which suggests that outlier analysis is particularly beneficial for identifying harms against those groups.
<div id='section'>Paperid: <span id='pid'>879, <a href='https://arxiv.org/pdf/2305.07883.pdf' target='_blank'>https://arxiv.org/pdf/2305.07883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuai Wang, Zipei Yan, Daoan Zhang, Zhongsen Li, Sirui Wu, Wenxuan Chen, Rui Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.07883">Towards Generalizable Medical Image Segmentation with Pixel-wise Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) achieve promising performance in visual recognition under the independent and identically distributed (IID) hypothesis. In contrast, the IID hypothesis is not universally guaranteed in numerous real-world applications, especially in medical image analysis. Medical image segmentation is typically formulated as a pixel-wise classification task in which each pixel is classified into a category. However, this formulation ignores the hard-to-classified pixels, e.g., some pixels near the boundary area, as they usually confuse DNNs. In this paper, we first explore that hard-to-classified pixels are associated with high uncertainty. Based on this, we propose a novel framework that utilizes uncertainty estimation to highlight hard-to-classified pixels for DNNs, thereby improving its generalization. We evaluate our method on two popular benchmarks: prostate and fundus datasets. The results of the experiment demonstrate that our method outperforms state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>880, <a href='https://arxiv.org/pdf/2303.15850.pdf' target='_blank'>https://arxiv.org/pdf/2303.15850.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kilian Zepf, Eike Petersen, Jes Frellsen, Aasa Feragen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15850">That Label's Got Style: Handling Label Style Bias for Uncertain Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Segmentation uncertainty models predict a distribution over plausible segmentations for a given input, which they learn from the annotator variation in the training set. However, in practice these annotations can differ systematically in the way they are generated, for example through the use of different labeling tools. This results in datasets that contain both data variability and differing label styles. In this paper, we demonstrate that applying state-of-the-art segmentation uncertainty models on such datasets can lead to model bias caused by the different label styles. We present an updated modelling objective conditioning on labeling style for aleatoric uncertainty estimation, and modify two state-of-the-art-architectures for segmentation uncertainty accordingly. We show with extensive experiments that this method reduces label style bias, while improving segmentation performance, increasing the applicability of segmentation uncertainty models in the wild. We curate two datasets, with annotations in different label styles, which we will make publicly available along with our code upon publication.
<div id='section'>Paperid: <span id='pid'>881, <a href='https://arxiv.org/pdf/2303.07940.pdf' target='_blank'>https://arxiv.org/pdf/2303.07940.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jesus L. Lobo, Ibai LaÃ±a, Eneko Osaba, Javier Del Ser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07940">On the Connection between Concept Drift and Uncertainty in Industrial Artificial Intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI-based digital twins are at the leading edge of the Industry 4.0 revolution, which are technologically empowered by the Internet of Things and real-time data analysis. Information collected from industrial assets is produced in a continuous fashion, yielding data streams that must be processed under stringent timing constraints. Such data streams are usually subject to non-stationary phenomena, causing that the data distribution of the streams may change, and thus the knowledge captured by models used for data analysis may become obsolete (leading to the so-called concept drift effect). The early detection of the change (drift) is crucial for updating the model's knowledge, which is challenging especially in scenarios where the ground truth associated to the stream data is not readily available. Among many other techniques, the estimation of the model's confidence has been timidly suggested in a few studies as a criterion for detecting drifts in unsupervised settings. The goal of this manuscript is to confirm and expose solidly the connection between the model's confidence in its output and the presence of a concept drift, showcasing it experimentally and advocating for a major consideration of uncertainty estimation in comparative studies to be reported in the future.
<div id='section'>Paperid: <span id='pid'>882, <a href='https://arxiv.org/pdf/2303.06261.pdf' target='_blank'>https://arxiv.org/pdf/2303.06261.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Wang, Lei Cao, Yizhou Yan, Samuel Madden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.06261">Interpretable Outlier Summarization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection is critical in real applications to prevent financial fraud, defend network intrusions, or detecting imminent device failures. To reduce the human effort in evaluating outlier detection results and effectively turn the outliers into actionable insights, the users often expect a system to automatically produce interpretable summarizations of subgroups of outlier detection results. Unfortunately, to date no such systems exist. To fill this gap, we propose STAIR which learns a compact set of human understandable rules to summarize and explain the anomaly detection results. Rather than use the classical decision tree algorithms to produce these rules, STAIR proposes a new optimization objective to produce a small number of rules with least complexity, hence strong interpretability, to accurately summarize the detection results. The learning algorithm of STAIR produces a rule set by iteratively splitting the large rules and is optimal in maximizing this objective in each iteration. Moreover, to effectively handle high dimensional, highly complex data sets which are hard to summarize with simple rules, we propose a localized STAIR approach, called L-STAIR. Taking data locality into consideration, it simultaneously partitions data and learns a set of localized rules for each partition. Our experimental study on many outlier benchmark datasets shows that STAIR significantly reduces the complexity of the rules required to summarize the outlier detection results, thus more amenable for humans to understand and evaluate, compared to the decision tree methods.
<div id='section'>Paperid: <span id='pid'>883, <a href='https://arxiv.org/pdf/2303.06232.pdf' target='_blank'>https://arxiv.org/pdf/2303.06232.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabri Mustafa Kahya, Muhammet Sami Yavuz, Eckehard Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.06232">MCROOD: Multi-Class Radar Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection has recently received special attention due to its critical role in safely deploying modern deep learning (DL) architectures. This work proposes a reconstruction-based multi-class OOD detector that operates on radar range doppler images (RDIs). The detector aims to classify any moving object other than a person sitting, standing, or walking as OOD. We also provide a simple yet effective pre-processing technique to detect minor human body movements like breathing. The simple idea is called respiration detector (RESPD) and eases the OOD detection, especially for human sitting and standing classes. On our dataset collected by 60GHz short-range FMCW Radar, we achieve AUROCs of 97.45%, 92.13%, and 96.58% for sitting, standing, and walking classes, respectively. We perform extensive experiments and show that our method outperforms state-of-the-art (SOTA) OOD detection methods. Also, our pipeline performs 24 times faster than the second-best method and is very suitable for real-time processing.
<div id='section'>Paperid: <span id='pid'>884, <a href='https://arxiv.org/pdf/2303.05796.pdf' target='_blank'>https://arxiv.org/pdf/2303.05796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bertrand Charpentier, Chenxiang Zhang, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.05796">Training, Architecture, and Prior for Deterministic Uncertainty Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and efficient uncertainty estimation is crucial to build reliable Machine Learning (ML) models capable to provide calibrated uncertainty estimates, generalize and detect Out-Of-Distribution (OOD) datasets. To this end, Deterministic Uncertainty Methods (DUMs) is a promising model family capable to perform uncertainty estimation in a single forward pass. This work investigates important design choices in DUMs: (1) we show that training schemes decoupling the core architecture and the uncertainty head schemes can significantly improve uncertainty performances. (2) we demonstrate that the core architecture expressiveness is crucial for uncertainty performance and that additional architecture constraints to avoid feature collapse can deteriorate the trade-off between OOD generalization and detection. (3) Contrary to other Bayesian models, we show that the prior defined by DUMs do not have a strong effect on the final performances.
<div id='section'>Paperid: <span id='pid'>885, <a href='https://arxiv.org/pdf/2302.14192.pdf' target='_blank'>https://arxiv.org/pdf/2302.14192.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabri Mustafa Kahya, Muhammet Sami Yavuz, Eckehard Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.14192">Reconstruction-based Out-of-Distribution Detection for Short-Range FMCW Radar</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection recently has drawn attention due to its critical role in the safe deployment of modern neural network architectures in real-world applications. The OOD detectors aim to distinguish samples that lie outside the training distribution in order to avoid the overconfident predictions of machine learning models on OOD data. Existing detectors, which mainly rely on the logit, intermediate feature space, softmax score, or reconstruction loss, manage to produce promising results. However, most of these methods are developed for the image domain. In this study, we propose a novel reconstruction-based OOD detector to operate on the radar domain. Our method exploits an autoencoder (AE) and its latent representation to detect the OOD samples. We propose two scores incorporating the patch-based reconstruction loss and the energy value calculated from the latent representations of each patch. We achieve an AUROC of 90.72% on our dataset collected by using 60 GHz short-range FMCW Radar. The experiments demonstrate that, in terms of AUROC and AUPR, our method outperforms the baseline (AE) and the other state-of-the-art methods. Also, thanks to its model size of 641 kB, our detector is suitable for embedded usage.
<div id='section'>Paperid: <span id='pid'>886, <a href='https://arxiv.org/pdf/2302.10185.pdf' target='_blank'>https://arxiv.org/pdf/2302.10185.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel D Kim, Rajat S Chandra, Jian Peng, Jing Wu, Xue Feng, Michael Atalay, Chetan Bettegowda, Craig Jones, Haris Sair, Wei-hua Liao, Chengzhang Zhu, Beiji Zou, Li Yang, Anahita Fathi Kazerooni, Ali Nabavizadeh, Harrison X Bai, Zhicheng Jiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10185">Active Learning in Brain Tumor Segmentation with Uncertainty Sampling, Annotation Redundancy Restriction, and Data Initialization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models have demonstrated great potential in medical 3D imaging, but their development is limited by the expensive, large volume of annotated data required. Active learning (AL) addresses this by training a model on a subset of the most informative data samples without compromising performance. We compared different AL strategies and propose a framework that minimizes the amount of data needed for state-of-the-art performance. 638 multi-institutional brain tumor MRI images were used to train a 3D U-net model and compare AL strategies. We investigated uncertainty sampling, annotation redundancy restriction, and initial dataset selection techniques. Uncertainty estimation techniques including Bayesian estimation with dropout, bootstrapping, and margins sampling were compared to random query. Strategies to avoid annotation redundancy by removing similar images within the to-be-annotated subset were considered as well. We determined the minimum amount of data necessary to achieve similar performance to the model trained on the full dataset (Î± = 0.1). A variance-based selection strategy using radiomics to identify the initial training dataset is also proposed. Bayesian approximation with dropout at training and testing showed similar results to that of the full data model with less than 20% of the training data (p=0.293) compared to random query achieving similar performance at 56.5% of the training data (p=0.814). Annotation redundancy restriction techniques achieved state-of-the-art performance at approximately 40%-50% of the training data. Radiomics dataset initialization had higher Dice with initial dataset sizes of 20 and 80 images, but improvements were not significant. In conclusion, we investigated various AL strategies with dropout uncertainty estimation achieving state-of-the-art performance with the least annotated data.
<div id='section'>Paperid: <span id='pid'>887, <a href='https://arxiv.org/pdf/2302.05304.pdf' target='_blank'>https://arxiv.org/pdf/2302.05304.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan Ernsting, Nils R. Winter, Ramona Leenings, Kelvin Sarink, Carlotta B. C. Barkhau, Lukas Fisch, Daniel Emden, Vincent Holstein, Jonathan Repple, Dominik Grotegerd, Susanne Meinert, NAKO Investigators, Klaus Berger, Benjamin Risse, Udo Dannlowski, Tim Hahn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05304">From Group-Differences to Single-Subject Probability: Conformal Prediction-based Uncertainty Estimation for Brain-Age Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The brain-age gap is one of the most investigated risk markers for brain changes across disorders. While the field is progressing towards large-scale models, recently incorporating uncertainty estimates, no model to date provides the single-subject risk assessment capability essential for clinical application. In order to enable the clinical use of brain-age as a biomarker, we here combine uncertainty-aware deep Neural Networks with conformal prediction theory. This approach provides statistical guarantees with respect to single-subject uncertainty estimates and allows for the calculation of an individual's probability for accelerated brain-aging. Building on this, we show empirically in a sample of N=16,794 participants that 1. a lower or comparable error as state-of-the-art, large-scale brain-age models, 2. the statistical guarantees regarding single-subject uncertainty estimation indeed hold for every participant, and 3. that the higher individual probabilities of accelerated brain-aging derived from our model are associated with Alzheimer's Disease, Bipolar Disorder and Major Depressive Disorder.
<div id='section'>Paperid: <span id='pid'>888, <a href='https://arxiv.org/pdf/2301.01054.pdf' target='_blank'>https://arxiv.org/pdf/2301.01054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hendrik A. Mehrtens, Alexander Kurz, Tabea-Clara Bucher, Titus J. Brinker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.01054">Benchmarking common uncertainty estimation methods with histopathological images under domain shift and label noise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the past years, deep learning has seen an increase in usage in the domain of histopathological applications. However, while these approaches have shown great potential, in high-risk environments deep learning models need to be able to judge their uncertainty and be able to reject inputs when there is a significant chance of misclassification. In this work, we conduct a rigorous evaluation of the most commonly used uncertainty and robustness methods for the classification of Whole Slide Images, with a focus on the task of selective classification, where the model should reject the classification in situations in which it is uncertain. We conduct our experiments on tile-level under the aspects of domain shift and label noise, as well as on slide-level. In our experiments, we compare Deep Ensembles, Monte-Carlo Dropout, Stochastic Variational Inference, Test-Time Data Augmentation as well as ensembles of the latter approaches. We observe that ensembles of methods generally lead to better uncertainty estimates as well as an increased robustness towards domain shifts and label noise, while contrary to results from classical computer vision benchmarks no systematic gain of the other methods can be shown. Across methods, a rejection of the most uncertain samples reliably leads to a significant increase in classification accuracy on both in-distribution as well as out-of-distribution data. Furthermore, we conduct experiments comparing these methods under varying conditions of label noise. Lastly, we publish our code framework to facilitate further research on uncertainty estimation on histopathological data.
<div id='section'>Paperid: <span id='pid'>889, <a href='https://arxiv.org/pdf/2212.06506.pdf' target='_blank'>https://arxiv.org/pdf/2212.06506.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daria Frolova, Anton Vasiliuk, Mikhail Belyaev, Boris Shirokikh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.06506">Solving Sample-Level Out-of-Distribution Detection on 3D Medical Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Learning (DL) models tend to perform poorly when the data comes from a distribution different from the training one. In critical applications such as medical imaging, out-of-distribution (OOD) detection helps to identify such data samples, increasing the model's reliability. Recent works have developed DL-based OOD detection that achieves promising results on 2D medical images. However, scaling most of these approaches on 3D images is computationally intractable. Furthermore, the current 3D solutions struggle to achieve acceptable results in detecting even synthetic OOD samples. Such limited performance might indicate that DL often inefficiently embeds large volumetric images. We argue that using the intensity histogram of the original CT or MRI scan as embedding is descriptive enough to run OOD detection. Therefore, we propose a histogram-based method that requires no DL and achieves almost perfect results in this domain. Our proposal is supported two-fold. We evaluate the performance on the publicly available datasets, where our method scores 1.0 AUROC in most setups. And we score second in the Medical Out-of-Distribution challenge without fine-tuning and exploiting task-specific knowledge. Carefully discussing the limitations, we conclude that our method solves the sample-level OOD detection on 3D medical images in the current setting.
<div id='section'>Paperid: <span id='pid'>890, <a href='https://arxiv.org/pdf/2212.00214.pdf' target='_blank'>https://arxiv.org/pdf/2212.00214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hansang Lee, Haeil Lee, Helen Hong, Junmo Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.00214">Test-Time Mixup Augmentation for Data and Class-Specific Uncertainty Estimation in Deep Learning Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation of trained deep learning networks is valuable for optimizing learning efficiency and evaluating the reliability of network predictions. In this paper, we propose a method for estimating uncertainty in deep learning image classification using test-time mixup augmentation (TTMA). To improve the ability to distinguish correct and incorrect predictions in existing aleatoric uncertainty, we introduce TTMA data uncertainty (TTMA-DU) by applying mixup augmentation to test data and measuring the entropy of the predicted label histogram. In addition to TTMA-DU, we propose TTMA class-specific uncertainty (TTMA-CSU), which captures aleatoric uncertainty specific to individual classes and provides insight into class confusion and class similarity within the trained network. We validate our proposed methods on the ISIC-18 skin lesion diagnosis dataset and the CIFAR-100 real-world image classification dataset. Our experiments show that (1) TTMA-DU more effectively differentiates correct and incorrect predictions compared to existing uncertainty measures due to mixup perturbation, and (2) TTMA-CSU provides information on class confusion and class similarity for both datasets.
<div id='section'>Paperid: <span id='pid'>891, <a href='https://arxiv.org/pdf/2211.08624.pdf' target='_blank'>https://arxiv.org/pdf/2211.08624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kuan-Lin Chen, Daniel D. E. Wong, Ke Tan, Buye Xu, Anurag Kumar, Vamsi Krishna Ithapu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.08624">Leveraging Heteroscedastic Uncertainty in Learning Complex Spectral Mapping for Single-channel Speech Enhancement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most speech enhancement (SE) models learn a point estimate and do not make use of uncertainty estimation in the learning process. In this paper, we show that modeling heteroscedastic uncertainty by minimizing a multivariate Gaussian negative log-likelihood (NLL) improves SE performance at no extra cost. During training, our approach augments a model learning complex spectral mapping with a temporary submodel to predict the covariance of the enhancement error at each time-frequency bin. Due to unrestricted heteroscedastic uncertainty, the covariance introduces an undersampling effect, detrimental to SE performance. To mitigate undersampling, our approach inflates the uncertainty lower bound and weights each loss component with their uncertainty, effectively compensating severely undersampled components with more penalties. Our multivariate setting reveals common covariance assumptions such as scalar and diagonal matrices. By weakening these assumptions, we show that the NLL achieves superior performance compared to popular loss functions including the mean squared error (MSE), mean absolute error (MAE), and scale-invariant signal-to-distortion ratio (SI-SDR).
<div id='section'>Paperid: <span id='pid'>892, <a href='https://arxiv.org/pdf/2208.07655.pdf' target='_blank'>https://arxiv.org/pdf/2208.07655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chulong Zhang, Yuming Jiang, Na Li, Zhicheng Zhang, Md Tauhidul Islam, Jingjing Dai, Lin Liu, Wenfeng He, Wenjian Qin, Jing Xiong, Yaoqin Xie, Xiaokun Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.07655">A Hybrid Deep Feature-Based Deformable Image Registration Method for Pathology Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pathologists need to combine information from differently stained pathology slices for accurate diagnosis. Deformable image registration is a necessary technique for fusing multi-modal pathology slices. This paper proposes a hybrid deep feature-based deformable image registration framework for stained pathology samples. We first extract dense feature points via the detector-based and detector-free deep learning feature networks and perform points matching. Then, to further reduce false matches, an outlier detection method combining the isolation forest statistical model and the local affine correction model is proposed. Finally, the interpolation method generates the deformable vector field for pathology image registration based on the above matching points. We evaluate our method on the dataset of the Non-rigid Histology Image Registration (ANHIR) challenge, which is co-organized with the IEEE ISBI 2019 conference. Our technique outperforms the traditional approaches by 17% with the Average-Average registration target error (rTRE) reaching 0.0034. The proposed method achieved state-of-the-art performance and ranked 1st in evaluating the test dataset. The proposed hybrid deep feature-based registration method can potentially become a reliable method for pathology image registration.
<div id='section'>Paperid: <span id='pid'>893, <a href='https://arxiv.org/pdf/2208.01077.pdf' target='_blank'>https://arxiv.org/pdf/2208.01077.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alessandro Wollek, Theresa Willem, Michael Ingrisch, Bastian Sabel, Tobias Lasser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.01077">A knee cannot have lung disease: out-of-distribution detection with in-distribution voting using the medical example of chest X-ray classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To investigate the impact of OOD radiographs on existing chest X-ray classification models and to increase their robustness against OOD data. The study employed the commonly used chest X-ray classification model, CheXnet, trained on the chest X-ray 14 data set, and tested its robustness against OOD data using three public radiography data sets: IRMA, Bone Age, and MURA, and the ImageNet data set. To detect OOD data for multi-label classification, we proposed in-distribution voting (IDV). The OOD detection performance is measured across data sets using the area under the receiver operating characteristic curve (AUC) analysis and compared with Mahalanobis-based OOD detection, MaxLogit, MaxEnergy and self-supervised OOD detection (SS OOD). Without additional OOD detection, the chest X-ray classifier failed to discard any OOD images, with an AUC of 0.5. The proposed IDV approach trained on ID (chest X-ray 14) and OOD data (IRMA and ImageNet) achieved, on average, 0.999 OOD AUC across the three data sets, surpassing all other OOD detection methods. Mahalanobis-based OOD detection achieved an average OOD detection AUC of 0.982. IDV trained solely with a few thousand ImageNet images had an AUC 0.913, which was higher than MaxLogit (0.726), MaxEnergy (0.724), and SS OOD (0.476). The performance of all tested OOD detection methods did not translate well to radiography data sets, except Mahalanobis-based OOD detection and the proposed IDV method. Training solely on ID data led to incorrect classification of OOD images as ID, resulting in increased false positive rates. IDV substantially improved the model's ID classification performance, even when trained with data that will not occur in the intended use case or test set, without additional inference overhead.
<div id='section'>Paperid: <span id='pid'>894, <a href='https://arxiv.org/pdf/2006.05534.pdf' target='_blank'>https://arxiv.org/pdf/2006.05534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chieh-Hsin Lai, Dongmian Zou, Gilad Lerman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2006.05534">Novelty Detection via Robust Variational Autoencoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a new method for novelty detection that can tolerate high corruption of the training points, whereas previous works assumed either no or very low corruption. Our method trains a robust variational autoencoder (VAE), which aims to generate a model for the uncorrupted training points. To gain robustness to high corruption, we incorporate the following four changes to the common VAE: 1. Extracting crucial features of the latent code by a carefully designed dimension reduction component for distributions; 2. Modeling the latent distribution as a mixture of Gaussian low-rank inliers and full-rank outliers, where the testing only uses the inlier model; 3. Applying the Wasserstein-1 metric for regularization, instead of the Kullback-Leibler (KL) divergence; and 4. Using a robust error for reconstruction. We establish both robustness to outliers and suitability to low-rank modeling of the Wasserstein metric as opposed to the KL divergence. We illustrate state-of-the-art results on standard benchmarks.
<div id='section'>Paperid: <span id='pid'>895, <a href='https://arxiv.org/pdf/1709.03690.pdf' target='_blank'>https://arxiv.org/pdf/1709.03690.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui She, Shanyun Liu, Pingyi Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1709.03690">Amplifying Inter-message Distance: On Information Divergence Measures in Big Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Message identification (M-I) divergence is an important measure of the information distance between probability distributions, similar to Kullback-Leibler (K-L) and Renyi divergence. In fact, M-I divergence with a variable parameter can make an effect on characterization of distinction between two distributions. Furthermore, by choosing an appropriate parameter of M-I divergence, it is possible to amplify the information distance between adjacent distributions while maintaining enough gap between two nonadjacent ones. Therefore, M-I divergence can play a vital role in distinguishing distributions more clearly. In this paper, we first define a parametric M-I divergence in the view of information theory and then present its major properties. In addition, we design a M-I divergence estimation algorithm by means of the ensemble estimator of the proposed weight kernel estimators, which can improve the convergence of mean squared error from ${O(\varGamma^{-j/d})}$ to ${O(\varGamma^{-1})}$ $({j\in (0,d]})$. We also discuss the decision with M-I divergence for clustering or classification, and investigate its performance in a statistical sequence model of big data for the outlier detection problem.
<div id='section'>Paperid: <span id='pid'>896, <a href='https://arxiv.org/pdf/2510.07030.pdf' target='_blank'>https://arxiv.org/pdf/2510.07030.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhinav Kumar, Fan Yang, Sergio Aguilera Marinovic, Soshi Iba, Rana Soltani Zarrin, Dmitry Berenson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.07030">Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-fingered hands are emerging as powerful platforms for performing fine manipulation tasks, including tool use. However, environmental perturbations or execution errors can impede task performance, motivating the use of recovery behaviors that enable normal task execution to resume. In this work, we take advantage of recent advances in diffusion models to construct a framework that autonomously identifies when recovery is necessary and optimizes contact-rich trajectories to recover. We use a diffusion model trained on the task to estimate when states are not conducive to task execution, framed as an out-of-distribution detection problem. We then use diffusion sampling to project these states in-distribution and use trajectory optimization to plan contact-rich recovery trajectories. We also propose a novel diffusion-based approach that distills this process to efficiently diffuse the full parameterization, including constraints, goal state, and initialization, of the recovery trajectory optimization problem, saving time during online execution. We compare our method to a reinforcement learning baseline and other methods that do not explicitly plan contact interactions, including on a hardware screwdriver-turning task where we show that recovering using our method improves task performance by 96% and that ours is the only method evaluated that can attempt recovery without causing catastrophic task failure. Videos can be found at https://dtourrecovery.github.io/.
<div id='section'>Paperid: <span id='pid'>897, <a href='https://arxiv.org/pdf/2510.06754.pdf' target='_blank'>https://arxiv.org/pdf/2510.06754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christian Maurer, Snehal Jauhri, Sophie Lueth, Georgia Chalvatzaki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06754">UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Comprehensive visual, geometric, and semantic understanding of a 3D scene is crucial for successful execution of robotic tasks, especially in unstructured and complex environments. Additionally, to make robust decisions, it is necessary for the robot to evaluate the reliability of perceived information. While recent advances in 3D neural feature fields have enabled robots to leverage features from pretrained foundation models for tasks such as language-guided manipulation and navigation, existing methods suffer from two critical limitations: (i) they are typically scene-specific, and (ii) they lack the ability to model uncertainty in their predictions. We present UniFField, a unified uncertainty-aware neural feature field that combines visual, semantic, and geometric features in a single generalizable representation while also predicting uncertainty in each modality. Our approach, which can be applied zero shot to any new environment, incrementally integrates RGB-D images into our voxel-based feature representation as the robot explores the scene, simultaneously updating uncertainty estimation. We evaluate our uncertainty estimations to accurately describe the model prediction errors in scene reconstruction and semantic feature prediction. Furthermore, we successfully leverage our feature predictions and their respective uncertainty for an active object search task using a mobile manipulator robot, demonstrating the capability for robust decision-making.
<div id='section'>Paperid: <span id='pid'>898, <a href='https://arxiv.org/pdf/2510.03181.pdf' target='_blank'>https://arxiv.org/pdf/2510.03181.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ha Manh Bui, Felix Parker, Kimia Ghobadi, Anqi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03181">Q-Learning with Shift-Aware Upper Confidence Bound in Non-Stationary Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the Non-Stationary Reinforcement Learning (RL) under distribution shifts in both finite-horizon episodic and infinite-horizon discounted Markov Decision Processes (MDPs). In the finite-horizon case, the transition functions may suddenly change at a particular episode. In the infinite-horizon setting, such changes can occur at an arbitrary time step during the agent's interaction with the environment. While the Q-learning Upper Confidence Bound algorithm (QUCB) can discover a proper policy during learning, due to the distribution shifts, this policy can exploit sub-optimal rewards after the shift happens. To address this issue, we propose Density-QUCB (DQUCB), a shift-aware Q-learning~UCB algorithm, which uses a transition density function to detect distribution shifts, then leverages its likelihood to enhance the uncertainty estimation quality of Q-learning~UCB, resulting in a balance between exploration and exploitation. Theoretically, we prove that our oracle DQUCB achieves a better regret guarantee than QUCB. Empirically, our DQUCB enjoys the computational efficiency of model-free RL and outperforms QUCB baselines by having a lower regret across RL tasks, as well as a real-world COVID-19 patient hospital allocation task using a Deep-Q-learning architecture.
<div id='section'>Paperid: <span id='pid'>899, <a href='https://arxiv.org/pdf/2510.00463.pdf' target='_blank'>https://arxiv.org/pdf/2510.00463.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daofu Zhang, Mehrdad Pournaderi, Hanne M. Clifford, Yu Xiang, Pramod K. Varshney
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00463">On the Adversarial Robustness of Learning-based Conformal Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper studies the adversarial robustness of conformal novelty detection. In particular, we focus on AdaDetect, a powerful learning-based framework for novelty detection with finite-sample false discovery rate (FDR) control. While AdaDetect provides rigorous statistical guarantees under benign conditions, its behavior under adversarial perturbations remains unexplored. We first formulate an oracle attack setting that quantifies the worst-case degradation of FDR, deriving an upper bound that characterizes the statistical cost of attacks. This idealized formulation directly motivates a practical and effective attack scheme that only requires query access to AdaDetect's output labels. Coupling these formulations with two popular and complementary black-box adversarial algorithms, we systematically evaluate the vulnerability of AdaDetect on synthetic and real-world datasets. Our results show that adversarial perturbations can significantly increase the FDR while maintaining high detection power, exposing fundamental limitations of current error-controlled novelty detection methods and motivating the development of more robust alternatives.
<div id='section'>Paperid: <span id='pid'>900, <a href='https://arxiv.org/pdf/2509.25646.pdf' target='_blank'>https://arxiv.org/pdf/2509.25646.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Ma, Ling Guo, Hao Wu, Tao Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25646">Deep set based operator learning with uncertainty quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning operators from data is central to scientific machine learning. While DeepONets are widely used for their ability to handle complex domains, they require fixed sensor numbers and locations, lack mechanisms for uncertainty quantification (UQ), and are thus limited in practical applicability. Recent permutationinvariant extensions, such as the Variable-Input Deep Operator Network (VIDON), relax these sensor constraints but still rely on sufficiently dense observations and cannot capture uncertainties arising from incomplete measurements or from operators with inherent randomness. To address these challenges, we propose UQ-SONet, a permutation-invariant operator learning framework with built-in UQ. Our model integrates a set transformer embedding to handle sparse and variable sensor locations, and employs a conditional variational autoencoder (cVAE) to approximate the conditional distribution of the solution operator. By minimizing the negative ELBO, UQ-SONet provides principled uncertainty estimation while maintaining predictive accuracy. Numerical experiments on deterministic and stochastic PDEs, including the Navier-Stokes equation, demonstrate the robustness and effectiveness of the proposed framework.
<div id='section'>Paperid: <span id='pid'>901, <a href='https://arxiv.org/pdf/2509.23355.pdf' target='_blank'>https://arxiv.org/pdf/2509.23355.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Tian, Xiaoling Hu, Juan Eugenio Iglesias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.23355">Test-time Uncertainty Estimation for Medical Image Registration via Transformation Equivariance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate image registration is essential for downstream applications, yet current deep registration networks provide limited indications of whether and when their predictions are reliable. Existing uncertainty estimation strategies, such as Bayesian methods, ensembles, or MC dropout, require architectural changes or retraining, limiting their applicability to pretrained registration networks. Instead, we propose a test-time uncertainty estimation framework that is compatible with any pretrained networks. Our framework is grounded in the transformation equivariance property of registration, which states that the true mapping between two images should remain consistent under spatial perturbations of the input. By analyzing the variance of network predictions under such perturbations, we derive a theoretical decomposition of perturbation-based uncertainty in registration. This decomposition separates into two terms: (i) an intrinsic spread, reflecting epistemic noise, and (ii) a bias jitter, capturing how systematic error drifts under perturbations. Across four anatomical structures (brain, cardiac, abdominal, and lung) and multiple registration models (uniGradICON, SynthMorph), the uncertainty maps correlate consistently with registration errors and highlight regions requiring caution. Our framework turns any pretrained registration network into a risk-aware tool at test time, placing medical image registration one step closer to safe deployment in clinical and large-scale research settings.
<div id='section'>Paperid: <span id='pid'>902, <a href='https://arxiv.org/pdf/2509.17034.pdf' target='_blank'>https://arxiv.org/pdf/2509.17034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuai Feng, Yuxin Ge, Yuntao Du, Mingcai Chen, Chongjun Wang, Lei Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17034">Long-Tailed Out-of-Distribution Detection with Refined Separate Class Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for deploying robust machine learning models. However, when training data follows a long-tailed distribution, the model's ability to accurately detect OOD samples is significantly compromised, due to the confusion between OOD samples and head/tail classes. To distinguish OOD samples from both head and tail classes, the separate class learning (SCL) approach has emerged as a promising solution, which separately conduct head-specific and tail-specific class learning. To this end, we examine the limitations of existing works of SCL and reveal that the OOD detection performance is notably influenced by the use of static scaling temperature value and the presence of uninformative outliers. To mitigate these limitations, we propose a novel approach termed Refined Separate Class Learning (RSCL), which leverages dynamic class-wise temperature adjustment to modulate the temperature parameter for each in-distribution class and informative outlier mining to identify diverse types of outliers based on their affinity with head and tail classes. Extensive experiments demonstrate that RSCL achieves superior OOD detection performance while improving the classification accuracy on in-distribution data.
<div id='section'>Paperid: <span id='pid'>903, <a href='https://arxiv.org/pdf/2509.13681.pdf' target='_blank'>https://arxiv.org/pdf/2509.13681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Li, Dianmo Sheng, Qiankun Dong, Zichun Wang, Zhiwei Xu, Tao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13681">FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a cornerstone technique for autonomous driving, Bird's Eye View (BEV) segmentation has recently achieved remarkable progress with pinhole cameras. However, it is non-trivial to extend the existing methods to fisheye cameras with severe geometric distortion, ambiguous multi-view correspondences and unstable temporal dynamics, all of which significantly degrade BEV performance. To address these challenges, we propose FishBEV, a novel BEV segmentation framework specifically tailored for fisheye cameras. This framework introduces three complementary innovations, including a Distortion-Resilient Multi-scale Extraction (DRME) backbone that learns robust features under distortion while preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention (U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that adaptively balances near field details and far field context to ensure temporal coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that FishBEV consistently outperforms SOTA baselines, regarding the performance evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.
<div id='section'>Paperid: <span id='pid'>904, <a href='https://arxiv.org/pdf/2509.11800.pdf' target='_blank'>https://arxiv.org/pdf/2509.11800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ang Nan Gu, Michael Tsang, Hooman Vaseli, Purang Abolmaesumi, Teresa Tsang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11800">Pseudo-D: Informing Multi-View Uncertainty Estimation with Calibrated Neural Training Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computer-aided diagnosis systems must make critical decisions from medical images that are often noisy, ambiguous, or conflicting, yet today's models are trained on overly simplistic labels that ignore diagnostic uncertainty. One-hot labels erase inter-rater variability and force models to make overconfident predictions, especially when faced with incomplete or artifact-laden inputs. We address this gap by introducing a novel framework that brings uncertainty back into the label space. Our method leverages neural network training dynamics (NNTD) to assess the inherent difficulty of each training sample. By aggregating and calibrating model predictions during training, we generate uncertainty-aware pseudo-labels that reflect the ambiguity encountered during learning. This label augmentation approach is architecture-agnostic and can be applied to any supervised learning pipeline to enhance uncertainty estimation and robustness. We validate our approach on a challenging echocardiography classification benchmark, demonstrating superior performance over specialized baselines in calibration, selective classification, and multi-view fusion.
<div id='section'>Paperid: <span id='pid'>905, <a href='https://arxiv.org/pdf/2509.11467.pdf' target='_blank'>https://arxiv.org/pdf/2509.11467.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yalei Yu, Matthew Coombes, Wen-Hua Chen, Cong Sun, Myles Flanagan, Jingjing Jiang, Pramod Pashupathy, Masoud Sotoodeh-Bahraini, Peter Kinnell, Niels Lohse
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11467">A Goal-Oriented Approach for Active Object Detection with Exploration-Exploitation Balance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active object detection, which aims to identify objects of interest through controlled camera movements, plays a pivotal role in real-world visual perception for autonomous robotic applications, such as manufacturing tasks (e.g., assembly operations) performed in unknown environments. A dual control for exploration and exploitation (DCEE) algorithm is presented within goal-oriented control systems to achieve efficient active object detection, leveraging active learning by incorporating variance-based uncertainty estimation in the cost function. This novel method employs an exploration-exploitation balanced cost function to actively guide the selection of the next viewpoint. Specifically, active object detection is achieved through the development of a reward function that encodes knowledge about the confidence variation of objects as a function of viewpoint position within a given domain. By identifying the unknown parameters of this function, the system generates an optimal viewpoint planning strategy. DCEE integrates parameter estimation of the reward function and view planning, ensuring a balanced trade-off between the exploitation of learned knowledge and active exploration during the planning process. Moreover, it demonstrates remarkable adaptability across diverse scenarios, effectively handling LEGO brick detection at varying locations. Importantly, the algorithm maintains consistent configuration settings and a fixed number of parameters across various scenarios, underscoring its efficiency and robustness. To validate the proposed approach, extensive numerical studies, high-fidelity virtual simulations, and real-world experiments under various scenarios were conducted. The results confirm the effectiveness of DCEE in active object detection, showcasing superior performance compared to existing methods, including model predictive control (MPC) and entropy approaches.
<div id='section'>Paperid: <span id='pid'>906, <a href='https://arxiv.org/pdf/2509.03551.pdf' target='_blank'>https://arxiv.org/pdf/2509.03551.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shubham Mishra, The Anh Han, Bruno Silvester Lopes, Shatha Ghareeb, Zia Ush Shamszaman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03551">Predicting Antimicrobial Resistance (AMR) in Campylobacter, a Foodborne Pathogen, and Cost Burden Analysis Using Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Antimicrobial resistance (AMR) poses a significant public health and economic challenge, increasing treatment costs and reducing antibiotic effectiveness. This study employs machine learning to analyze genomic and epidemiological data from the public databases for molecular typing and microbial genome diversity (PubMLST), incorporating data from UK government-supported AMR surveillance by the Food Standards Agency and Food Standards Scotland. We identify AMR patterns in Campylobacter jejuni and Campylobacter coli isolates collected in the UK from 2001 to 2017. The research integrates whole-genome sequencing (WGS) data, epidemiological metadata, and economic projections to identify key resistance determinants and forecast future resistance trends and healthcare costs. We investigate gyrA mutations for fluoroquinolone resistance and the tet(O) gene for tetracycline resistance, training a Random Forest model validated with bootstrap resampling (1,000 samples, 95% confidence intervals), achieving 74% accuracy in predicting AMR phenotypes. Time-series forecasting models (SARIMA, SIR, and Prophet) predict a rise in campylobacteriosis cases, potentially exceeding 130 cases per 100,000 people by 2050, with an economic burden projected to surpass 1.9 billion GBP annually if left unchecked. An enhanced Random Forest system, analyzing 6,683 isolates, refines predictions by incorporating temporal patterns, uncertainty estimation, and resistance trend modeling, indicating sustained high beta-lactam resistance, increasing fluoroquinolone resistance, and fluctuating tetracycline resistance.
<div id='section'>Paperid: <span id='pid'>907, <a href='https://arxiv.org/pdf/2509.02327.pdf' target='_blank'>https://arxiv.org/pdf/2509.02327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>I. Shavindra Jayasekera, Jacob Si, Filippo Valdettaro, Wenlong Chen, A. Aldo Faisal, Yingzhen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02327">Variational Uncertainty Decomposition for In-Context Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As large language models (LLMs) gain popularity in conducting prediction tasks in-context, understanding the sources of uncertainty in in-context learning becomes essential to ensuring reliability. The recent hypothesis of in-context learning performing predictive Bayesian inference opens the avenue for Bayesian uncertainty estimation, particularly for decomposing uncertainty into epistemic uncertainty due to lack of in-context data and aleatoric uncertainty inherent in the in-context prediction task. However, the decomposition idea remains under-explored due to the intractability of the latent parameter posterior from the underlying Bayesian model. In this work, we introduce a variational uncertainty decomposition framework for in-context learning without explicitly sampling from the latent parameter posterior, by optimising auxiliary queries as probes to obtain an upper bound to the aleatoric uncertainty of an LLM's in-context learning procedure, which also induces a lower bound to the epistemic uncertainty. Through experiments on synthetic and real-world tasks, we show quantitatively and qualitatively that the decomposed uncertainties obtained from our method exhibit desirable properties of epistemic and aleatoric uncertainty.
<div id='section'>Paperid: <span id='pid'>908, <a href='https://arxiv.org/pdf/2509.02273.pdf' target='_blank'>https://arxiv.org/pdf/2509.02273.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhao Wang, Yingrui Ji, Yu Meng, Yunjian Zhang, Yao Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02273">RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection represents a critical challenge in remote sensing applications, where reliable identification of novel or anomalous patterns is essential for autonomous monitoring, disaster response, and environmental assessment. Despite remarkable progress in OOD detection for natural images, existing methods and benchmarks remain poorly suited to remote sensing imagery due to data scarcity, complex multi-scale scene structures, and pronounced distribution shifts. To this end, we propose RS-OOD, a novel framework that leverages remote sensing-specific vision-language modeling to enable robust few-shot OOD detection. Our approach introduces three key innovations: spatial feature enhancement that improved scene discrimination, a dual-prompt alignment mechanism that cross-verifies scene context against fine-grained semantics for spatial-semantic consistency, and a confidence-guided self-training loop that dynamically mines pseudo-labels to expand training data without manual annotation. RS-OOD consistently outperforms existing methods across multiple remote sensing benchmarks and enables efficient adaptation with minimal labeled data, demonstrating the critical value of spatial-semantic integration.
<div id='section'>Paperid: <span id='pid'>909, <a href='https://arxiv.org/pdf/2508.19112.pdf' target='_blank'>https://arxiv.org/pdf/2508.19112.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aneesh Rangnekar, Harini Veeraraghavan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19112">Random forest-based out-of-distribution detection for robust lung cancer segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate detection and segmentation of cancerous lesions from computed tomography (CT) scans is essential for automated treatment planning and cancer treatment response assessment. Transformer-based models with self-supervised pretraining can produce reliably accurate segmentation from in-distribution (ID) data but degrade when applied to out-of-distribution (OOD) datasets. We address this challenge with RF-Deep, a random forest classifier that utilizes deep features from a pretrained transformer encoder of the segmentation model to detect OOD scans and enhance segmentation reliability. The segmentation model comprises a Swin Transformer encoder, pretrained with masked image modeling (SimMIM) on 10,432 unlabeled 3D CT scans covering cancerous and non-cancerous conditions, with a convolution decoder, trained to segment lung cancers in 317 3D scans. Independent testing was performed on 603 3D CT public datasets that included one ID dataset and four OOD datasets comprising chest CTs with pulmonary embolism (PE) and COVID-19, and abdominal CTs with kidney cancers and healthy volunteers. RF-Deep detected OOD cases with a FPR95 of 18.26%, 27.66%, and less than 0.1% on PE, COVID-19, and abdominal CTs, consistently outperforming established OOD approaches. The RF-Deep classifier provides a simple and effective approach to enhance reliability of cancer segmentation in ID and OOD scenarios.
<div id='section'>Paperid: <span id='pid'>910, <a href='https://arxiv.org/pdf/2507.21423.pdf' target='_blank'>https://arxiv.org/pdf/2507.21423.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Monninger, Zihan Zhang, Zhipeng Mo, Md Zafar Anwar, Steffen Staab, Sihao Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21423">MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving requires an understanding of the static environment from sensor data. Learned Bird's-Eye View (BEV) encoders are commonly used to fuse multiple inputs, and a vector decoder predicts a vectorized map representation from the latent BEV grid. However, traditional map construction models provide deterministic point estimates, failing to capture uncertainty and the inherent ambiguities of real-world environments, such as occlusions and missing lane markings. We propose MapDiffusion, a novel generative approach that leverages the diffusion paradigm to learn the full distribution of possible vectorized maps. Instead of predicting a single deterministic output from learned queries, MapDiffusion iteratively refines randomly initialized queries, conditioned on a BEV latent grid, to generate multiple plausible map samples. This allows aggregating samples to improve prediction accuracy and deriving uncertainty estimates that directly correlate with scene ambiguity. Extensive experiments on the nuScenes dataset demonstrate that MapDiffusion achieves state-of-the-art performance in online map construction, surpassing the baseline by 5% in single-sample performance. We further show that aggregating multiple samples consistently improves performance along the ROC curve, validating the benefit of distribution modeling. Additionally, our uncertainty estimates are significantly higher in occluded areas, reinforcing their value in identifying regions with ambiguous sensor input. By modeling the full map distribution, MapDiffusion enhances the robustness and reliability of online vectorized HD map construction, enabling uncertainty-aware decision-making for autonomous vehicles in complex environments.
<div id='section'>Paperid: <span id='pid'>911, <a href='https://arxiv.org/pdf/2507.04529.pdf' target='_blank'>https://arxiv.org/pdf/2507.04529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philipp Reis, Joshua Ransiek, David Petri, Jacob Langner, Eric Sax
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04529">A Data-Driven Novelty Score for Diverse In-Vehicle Data Recording</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-quality datasets are essential for training robust perception systems in autonomous driving. However, real-world data collection is often biased toward common scenes and objects, leaving novel cases underrepresented. This imbalance hinders model generalization and compromises safety. The core issue is the curse of rarity. Over time, novel events occur infrequently, and standard logging methods fail to capture them effectively. As a result, large volumes of redundant data are stored, while critical novel cases are diluted, leading to biased datasets. This work presents a real-time data selection method focused on object-level novelty detection to build more balanced and diverse datasets. The method assigns a data-driven novelty score to image frames using a novel dynamic Mean Shift algorithm. It models normal content based on mean and covariance statistics to identify frames with novel objects, discarding those with redundant elements. The main findings show that reducing the training dataset size with this method can improve model performance, whereas higher redundancy tends to degrade it. Moreover, as data redundancy increases, more aggressive filtering becomes both possible and beneficial. While random sampling can offer some gains, it often leads to overfitting and unpredictability in outcomes. The proposed method supports real-time deployment with 32 frames per second and is constant over time. By continuously updating the definition of normal content, it enables efficient detection of novelties in a continuous data stream.
<div id='section'>Paperid: <span id='pid'>912, <a href='https://arxiv.org/pdf/2505.16923.pdf' target='_blank'>https://arxiv.org/pdf/2505.16923.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhui Zhang, Dongshen Wu, Yuichiro Wada, Takafumi Kanamori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16923">TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A reliable uncertainty estimation method is the foundation of many modern out-of-distribution (OOD) detectors, which are critical for safe deployments of deep learning models in the open world. In this work, we propose TULiP, a theoretically-driven post-hoc uncertainty estimator for OOD detection. Our approach considers a hypothetical perturbation applied to the network before convergence. Based on linearized training dynamics, we bound the effect of such perturbation, resulting in an uncertainty score computable by perturbing model parameters. Ultimately, our approach computes uncertainty from a set of sampled predictions. We visualize our bound on synthetic regression and classification datasets. Furthermore, we demonstrate the effectiveness of TULiP using large-scale OOD detection benchmarks for image classification. Our method exhibits state-of-the-art performance, particularly for near-distribution samples.
<div id='section'>Paperid: <span id='pid'>913, <a href='https://arxiv.org/pdf/2505.13273.pdf' target='_blank'>https://arxiv.org/pdf/2505.13273.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Berry, Axel Brando, Wei-Di Chang, Juan Camilo Gamboa Higuera, David Meger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13273">Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating uncertainty in text-to-image diffusion models is challenging because of their large parameter counts (often exceeding 100 million) and operation in complex, high-dimensional spaces with virtually infinite input possibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a novel framework for efficiently estimating epistemic uncertainty in diffusion models. EMoE leverages pre-trained networks without requiring additional training, enabling direct uncertainty estimation from a prompt. We leverage a latent space within the diffusion process that captures epistemic uncertainty better than existing methods. Experimental results on the COCO dataset demonstrate EMoE's effectiveness, showing a strong correlation between uncertainty and image quality. Additionally, EMoE identifies under-sampled languages and regions with higher uncertainty, revealing hidden biases in the training set. This capability demonstrates the relevance of EMoE as a tool for addressing fairness and accountability in AI-generated content.
<div id='section'>Paperid: <span id='pid'>914, <a href='https://arxiv.org/pdf/2505.02277.pdf' target='_blank'>https://arxiv.org/pdf/2505.02277.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maryam Sultana, Neil Yorke-Smith, Kaizheng Wang, Shireen Kudukkil Manchingal, Muhammad Mubashar, Fabio Cuzzolin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02277">Epistemic Wrapping for Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is pivotal in machine learning, especially for classification tasks, as it improves the robustness and reliability of models. We introduce a novel `Epistemic Wrapping' methodology aimed at improving uncertainty estimation in classification. Our approach uses Bayesian Neural Networks (BNNs) as a baseline and transforms their outputs into belief function posteriors, effectively capturing epistemic uncertainty and offering an efficient and general methodology for uncertainty quantification. Comprehensive experiments employing a Bayesian Neural Network (BNN) baseline and an Interval Neural Network for inference on the MNIST, Fashion-MNIST, CIFAR-10 and CIFAR-100 datasets demonstrate that our Epistemic Wrapper significantly enhances generalisation and uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>915, <a href='https://arxiv.org/pdf/2504.15663.pdf' target='_blank'>https://arxiv.org/pdf/2504.15663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ju Yeon Kang, Ji Won Yoon, Semin Kim, Min Hyun Han, Nam Soo Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15663">FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, fake audio detection has gained significant attention, as advancements in speech synthesis and voice conversion have increased the vulnerability of automatic speaker verification (ASV) systems to spoofing attacks. A key challenge in this task is generalizing models to detect unseen, out-of-distribution (OOD) attacks. Although existing approaches have shown promising results, they inherently suffer from overconfidence issues due to the usage of softmax for classification, which can produce unreliable predictions when encountering unpredictable spoofing attempts. To deal with this limitation, we propose a novel framework called fake audio detection with evidential learning (FADEL). By modeling class probabilities with a Dirichlet distribution, FADEL incorporates model uncertainty into its predictions, thereby leading to more robust performance in OOD scenarios. Experimental results on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets indicate that the proposed method significantly improves the performance of baseline models. Furthermore, we demonstrate the validity of uncertainty estimation by analyzing a strong correlation between average uncertainty and equal error rate (EER) across different spoofing algorithms.
<div id='section'>Paperid: <span id='pid'>916, <a href='https://arxiv.org/pdf/2504.12931.pdf' target='_blank'>https://arxiv.org/pdf/2504.12931.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vincent Freiberger, Arthur Fleig, Erik Buchmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12931">Explainable AI in Usable Privacy and Security: Challenges and Opportunities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are increasingly being used for automated evaluations and explaining them. However, concerns about explanation quality, consistency, and hallucinations remain open research challenges, particularly in high-stakes contexts like privacy and security, where user trust and decision-making are at stake. In this paper, we investigate these issues in the context of PRISMe, an interactive privacy policy assessment tool that leverages LLMs to evaluate and explain website privacy policies. Based on a prior user study with 22 participants, we identify key concerns regarding LLM judgment transparency, consistency, and faithfulness, as well as variations in user preferences for explanation detail and engagement. We discuss potential strategies to mitigate these concerns, including structured evaluation criteria, uncertainty estimation, and retrieval-augmented generation (RAG). We identify a need for adaptive explanation strategies tailored to different user profiles for LLM-as-a-judge. Our goal is to showcase the application area of usable privacy and security to be promising for Human-Centered Explainable AI (HCXAI) to make an impact.
<div id='section'>Paperid: <span id='pid'>917, <a href='https://arxiv.org/pdf/2504.04471.pdf' target='_blank'>https://arxiv.org/pdf/2504.04471.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuo Zhi, Qiangqiang Wu, Minghe shen, Wenbo Li, Yinchuan Li, Kun Shao, Kaiwen Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04471">VideoAgent2: Enhancing the LLM-Based Agent System for Long-Form Video Understanding by Uncertainty-Aware CoT</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Long video understanding has emerged as an increasingly important yet challenging task in computer vision. Agent-based approaches are gaining popularity for processing long videos, as they can handle extended sequences and integrate various tools to capture fine-grained information. However, existing methods still face several challenges: (1) they often rely solely on the reasoning ability of large language models (LLMs) without dedicated mechanisms to enhance reasoning in long video scenarios; and (2) they remain vulnerable to errors or noise from external tools. To address these issues, we propose a specialized chain-of-thought (CoT) process tailored for long video analysis. Our proposed CoT with plan-adjust mode enables the LLM to incrementally plan and adapt its information-gathering strategy. We further incorporate heuristic uncertainty estimation of both the LLM and external tools to guide the CoT process. This allows the LLM to assess the reliability of newly collected information, refine its collection strategy, and make more robust decisions when synthesizing final answers. Empirical experiments show that our uncertainty-aware CoT effectively mitigates noise from external tools, leading to more reliable outputs. We implement our approach in a system called VideoAgent2, which also includes additional modules such as general context acquisition and specialized tool design. Evaluation on three dedicated long video benchmarks (and their subsets) demonstrates that VideoAgent2 outperforms the previous state-of-the-art agent-based method, VideoAgent, by an average of 13.1% and achieves leading performance among all zero-shot approaches
<div id='section'>Paperid: <span id='pid'>918, <a href='https://arxiv.org/pdf/2504.02606.pdf' target='_blank'>https://arxiv.org/pdf/2504.02606.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas Teufel, Annika Leinweber, Pascal Friederich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02606">Improving Counterfactual Truthfulness for Molecular Property Prediction through Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explainable AI (xAI) interventions aim to improve interpretability for complex black-box models, not only to improve user trust but also as a means to extract scientific insights from high-performing predictive systems. In molecular property prediction, counterfactual explanations offer a way to understand predictive behavior by highlighting which minimal perturbations in the input molecular structure cause the greatest deviation in the predicted property. However, such explanations only allow for meaningful scientific insights if they reflect the distribution of the true underlying property -- a feature we define as counterfactual truthfulness. To increase this truthfulness, we propose the integration of uncertainty estimation techniques to filter counterfactual candidates with high predicted uncertainty. Through computational experiments with synthetic and real-world datasets, we demonstrate that traditional uncertainty estimation methods, such as ensembles and mean-variance estimation, can already substantially reduce the average prediction error and increase counterfactual truthfulness, especially for out-of-distribution settings. Our results highlight the importance and potential impact of incorporating uncertainty estimation into explainability methods, especially considering the relatively high effectiveness of low-effort interventions like model ensembles.
<div id='section'>Paperid: <span id='pid'>919, <a href='https://arxiv.org/pdf/2503.17125.pdf' target='_blank'>https://arxiv.org/pdf/2503.17125.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chan Kim, Seung-Woo Seo, Seong-Woo Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17125">LaMOuR: Leveraging Language Models for Out-of-Distribution Recovery in Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Reinforcement Learning (DRL) has demonstrated strong performance in robotic control but remains susceptible to out-of-distribution (OOD) states, often resulting in unreliable actions and task failure. While previous methods have focused on minimizing or preventing OOD occurrences, they largely neglect recovery once an agent encounters such states. Although the latest research has attempted to address this by guiding agents back to in-distribution states, their reliance on uncertainty estimation hinders scalability in complex environments. To overcome this limitation, we introduce Language Models for Out-of-Distribution Recovery (LaMOuR), which enables recovery learning without relying on uncertainty estimation. LaMOuR generates dense reward codes that guide the agent back to a state where it can successfully perform its original task, leveraging the capabilities of LVLMs in image description, logical reasoning, and code generation. Experimental results show that LaMOuR substantially enhances recovery efficiency across diverse locomotion tasks and even generalizes effectively to complex environments, including humanoid locomotion and mobile manipulation, where existing methods struggle. The code and supplementary materials are available at https://lamour-rl.github.io/.
<div id='section'>Paperid: <span id='pid'>920, <a href='https://arxiv.org/pdf/2503.09626.pdf' target='_blank'>https://arxiv.org/pdf/2503.09626.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Wu, Yingguang Yang, hao liu, Hao Peng, Buyun He, Yutong Xia, Yong Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.09626">Certainly Bot Or Not? Trustworthy Social Bot Detection via Robust Multi-Modal Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Social bot detection is crucial for mitigating misinformation, online manipulation, and coordinated inauthentic behavior. While existing neural network-based detectors perform well on benchmarks, they struggle with generalization due to distribution shifts across datasets and frequently produce overconfident predictions for out-of-distribution accounts beyond the training data. To address this, we introduce a novel Uncertainty Estimation for Social Bot Detection (UESBD) framework, which quantifies the predictive uncertainty of detectors beyond mere classification. For this task, we propose Robust Multi-modal Neural Processes (RMNP), which aims to enhance the robustness of multi-modal neural processes to modality inconsistencies caused by social bot camouflage. RMNP first learns unimodal representations through modality-specific encoders. Then, unimodal attentive neural processes are employed to encode the Gaussian distribution of unimodal latent variables. Furthermore, to avoid social bots stealing human features to camouflage themselves thus causing certain modalities to provide conflictive information, we introduce an evidential gating network to explicitly model the reliability of modalities. The joint latent distribution is learned through the generalized product of experts, which takes the reliability of each modality into consideration during fusion. The final prediction is obtained through Monte Carlo sampling of the joint latent distribution followed by a decoder. Experiments on three real-world benchmarks show the effectiveness of RMNP in classification and uncertainty estimation, as well as its robustness to modality conflicts.
<div id='section'>Paperid: <span id='pid'>921, <a href='https://arxiv.org/pdf/2503.00136.pdf' target='_blank'>https://arxiv.org/pdf/2503.00136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacopo Teneggi, J Webster Stayman, Jeremias Sulam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00136">Conformal Risk Control for Semantic Uncertainty Quantification in Computed Tomography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is necessary for developers, physicians, and regulatory agencies to build trust in machine learning predictors and improve patient care. Beyond measuring uncertainty, it is crucial to express it in clinically meaningful terms that provide actionable insights. This work introduces a conformal risk control (CRC) procedure for organ-dependent uncertainty estimation, ensuring high-probability coverage of the ground-truth image. We first present a high-dimensional CRC procedure that leverages recent ideas of length minimization. We make this procedure semantically adaptive to each patient's anatomy and positioning of organs. Our method, sem-CRC, provides tighter uncertainty intervals with valid coverage on real-world computed tomography (CT) data while communicating uncertainty with clinically relevant features.
<div id='section'>Paperid: <span id='pid'>922, <a href='https://arxiv.org/pdf/2502.03323.pdf' target='_blank'>https://arxiv.org/pdf/2502.03323.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Momin Abbas, Muneeza Azmat, Raya Horesh, Mikhail Yurochkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03323">Out-of-Distribution Detection using Synthetic Data Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distinguishing in- and out-of-distribution (OOD) inputs is crucial for reliable deployment of classification systems. However, OOD data is typically unavailable or difficult to collect, posing a significant challenge for accurate OOD detection. In this work, we present a method that harnesses the generative capabilities of Large Language Models (LLMs) to create high-quality synthetic OOD proxies, eliminating the dependency on any external OOD data source. We study the efficacy of our method on classical text classification tasks such as toxicity detection and sentiment classification as well as classification tasks arising in LLM development and deployment, such as training a reward model for RLHF and detecting misaligned generations. Extensive experiments on nine InD-OOD dataset pairs and various model sizes show that our approach dramatically lowers false positive rates (achieving a perfect zero in some cases) while maintaining high accuracy on in-distribution tasks, outperforming baseline methods by a significant margin.
<div id='section'>Paperid: <span id='pid'>923, <a href='https://arxiv.org/pdf/2502.03323.pdf' target='_blank'>https://arxiv.org/pdf/2502.03323.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Momin Abbas, Muneeza Azmat, Raya Horesh, Mikhail Yurochkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03323">Out-of-Distribution Detection using Synthetic Data Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distinguishing in- and out-of-distribution (OOD) inputs is crucial for reliable deployment of classification systems. However, OOD data is typically unavailable or difficult to collect, posing a significant challenge for accurate OOD detection. In this work, we present a method that harnesses the generative capabilities of Large Language Models (LLMs) to create high-quality synthetic OOD proxies, eliminating the dependency on any external OOD data source. We study the efficacy of our method on classical text classification tasks such as toxicity detection and sentiment classification as well as classification tasks arising in LLM development and deployment, such as training a reward model for RLHF and detecting misaligned generations. Extensive experiments on nine InD-OOD dataset pairs and various model sizes show that our approach dramatically lowers false positive rates (achieving a perfect zero in some cases) while maintaining high accuracy on in-distribution tasks, outperforming baseline methods by a significant margin.
<div id='section'>Paperid: <span id='pid'>924, <a href='https://arxiv.org/pdf/2502.01800.pdf' target='_blank'>https://arxiv.org/pdf/2502.01800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aidan Curtis, Eric Li, Michael Noseworthy, Nishad Gothoskar, Sachin Chitta, Hui Li, Leslie Pack Kaelbling, Nicole Carey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01800">Flow-based Domain Randomization for Learning and Sequencing Robotic Skills</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain randomization in reinforcement learning is an established technique for increasing the robustness of control policies trained in simulation. By randomizing environment properties during training, the learned policy can become robust to uncertainties along the randomized dimensions. While the environment distribution is typically specified by hand, in this paper we investigate automatically discovering a sampling distribution via entropy-regularized reward maximization of a normalizing-flow-based neural sampling distribution. We show that this architecture is more flexible and provides greater robustness than existing approaches that learn simpler, parameterized sampling distributions, as demonstrated in six simulated and one real-world robotics domain. Lastly, we explore how these learned sampling distributions, combined with a privileged value function, can be used for out-of-distribution detection in an uncertainty-aware multi-step manipulation planner.
<div id='section'>Paperid: <span id='pid'>925, <a href='https://arxiv.org/pdf/2501.11570.pdf' target='_blank'>https://arxiv.org/pdf/2501.11570.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karn N. Watcharasupat, Yiwei Ding, T. Aleksandra Ma, Pavan Seshadri, Alexander Lerch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11570">Uncertainty Estimation in the Real World: A Study on Music Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Any data annotation for subjective tasks shows potential variations between individuals. This is particularly true for annotations of emotional responses to musical stimuli. While older approaches to music emotion recognition systems frequently addressed this uncertainty problem through probabilistic modeling, modern systems based on neural networks tend to ignore the variability and focus only on predicting central tendencies of human subjective responses. In this work, we explore several methods for estimating not only the central tendencies of the subjective responses to a musical stimulus, but also for estimating the uncertainty associated with these responses. In particular, we investigate probabilistic loss functions and inference-time random sampling. Experimental results indicate that while the modeling of the central tendencies is achievable, modeling of the uncertainty in subjective responses proves significantly more challenging with currently available approaches even when empirical estimates of variations in the responses are available.
<div id='section'>Paperid: <span id='pid'>926, <a href='https://arxiv.org/pdf/2501.08285.pdf' target='_blank'>https://arxiv.org/pdf/2501.08285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matias Valdenegro-Toro, Marco Zullich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08285">Can Bayesian Neural Networks Explicitly Model Input Uncertainty?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inputs to machine learning models can have associated noise or uncertainties, but they are often ignored and not modelled. It is unknown if Bayesian Neural Networks and their approximations are able to consider uncertainty in their inputs. In this paper we build a two input Bayesian Neural Network (mean and standard deviation) and evaluate its capabilities for input uncertainty estimation across different methods like Ensembles, MC-Dropout, and Flipout. Our results indicate that only some uncertainty estimation methods for approximate Bayesian NNs can model input uncertainty, in particular Ensembles and Flipout.
<div id='section'>Paperid: <span id='pid'>927, <a href='https://arxiv.org/pdf/2412.20674.pdf' target='_blank'>https://arxiv.org/pdf/2412.20674.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ervin Moore, Ahmed Imteaj, Md Zarif Hossain, Shabnam Rezapour, M. Hadi Amini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20674">Blockchain-Empowered Cyber-Secure Federated Learning for Trustworthy Edge Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated Learning (FL) is a privacy-preserving distributed machine learning scheme, where each participant data remains on the participating devices and only the local model generated utilizing the local computational power is transmitted throughout the database. However, the distributed computational nature of FL creates the necessity to develop a mechanism that can remotely trigger any network agents, track their activities, and prevent threats to the overall process posed by malicious participants. Particularly, the FL paradigm may become vulnerable due to an active attack from the network participants, called a poisonous attack. In such an attack, the malicious participant acts as a benign agent capable of affecting the global model quality by uploading an obfuscated poisoned local model update to the server. This paper presents a cross-device FL model that ensures trustworthiness, fairness, and authenticity in the underlying FL training process. We leverage trustworthiness by constructing a reputation-based trust model based on contributions of agents toward model convergence. We ensure fairness by identifying and removing malicious agents from the training process through an outlier detection technique. Further, we establish authenticity by generating a token for each participating device through a distributed sensing mechanism and storing that unique token in a blockchain smart contract. Further, we insert the trust scores of all agents into a blockchain and validate their reputations using various consensus mechanisms that consider the computational task.
<div id='section'>Paperid: <span id='pid'>928, <a href='https://arxiv.org/pdf/2412.15439.pdf' target='_blank'>https://arxiv.org/pdf/2412.15439.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maniraj Sai Adapa, Marco Zullich, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15439">Uncertainty Estimation for Super-Resolution using ESRGAN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Learning-based image super-resolution (SR) has been gaining traction with the aid of Generative Adversarial Networks. Models like SRGAN and ESRGAN are constantly ranked between the best image SR tools. However, they lack principled ways for estimating predictive uncertainty. In the present work, we enhance these models using Monte Carlo-Dropout and Deep Ensemble, allowing the computation of predictive uncertainty. When coupled with a prediction, uncertainty estimates can provide more information to the model users, highlighting pixels where the SR output might be uncertain, hence potentially inaccurate, if these estimates were to be reliable. Our findings suggest that these uncertainty estimates are decently calibrated and can hence fulfill this goal, while providing no performance drop with respect to the corresponding models without uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>929, <a href='https://arxiv.org/pdf/2412.13738.pdf' target='_blank'>https://arxiv.org/pdf/2412.13738.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Navid Ansari, Hans-Peter Seidel, Vahid Babaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13738">Uncertainty separation via ensemble quantile regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel and scalable framework for uncertainty estimation and separation with applications in data driven modeling in science and engineering tasks where reliable uncertainty quantification is critical. Leveraging an ensemble of quantile regression (E-QR) models, our approach enhances aleatoric uncertainty estimation while preserving the quality of epistemic uncertainty, surpassing competing methods, such as Deep Ensembles (DE) and Monte Carlo (MC) dropout. To address challenges in separating uncertainty types, we propose an algorithm that iteratively improves separation through progressive sampling in regions of high uncertainty. Our framework is scalable to large datasets and demonstrates superior performance on synthetic benchmarks, offering a robust tool for uncertainty quantification in data-driven applications.
<div id='section'>Paperid: <span id='pid'>930, <a href='https://arxiv.org/pdf/2412.08501.pdf' target='_blank'>https://arxiv.org/pdf/2412.08501.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuang Zhang, Liping Wang, Yihong Huang, Yuanxing Zheng, Fan Zhang, Xuemin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.08501">GradStop: Exploring Training Dynamics in Unsupervised Outlier Detection through Gradient</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised Outlier Detection (UOD) is a critical task in data mining and machine learning, aiming to identify instances that significantly deviate from the majority. Without any label, deep UOD methods struggle with the misalignment between the model's direct optimization goal and the final performance goal of Outlier Detection (OD) task. Through the perspective of training dynamics, this paper proposes an early stopping algorithm to optimize the training of deep UOD models, ensuring they perform optimally in OD rather than overfitting the entire contaminated dataset.
  Inspired by UOD mechanism and inlier priority phenomenon, where intuitively models fit inliers more quickly than outliers, we propose GradStop, a sampling-based label-free algorithm to estimate model's real-time performance during training. First, a sampling method generates two sets: one likely containing more outliers and the other more inliers, then a metric based on gradient cohesion is applied to probe into current training dynamics, which reflects model's performance on OD task.
  Experimental results on 4 deep UOD algorithms and 47 real-world datasets and theoretical proofs demonstrate the effectiveness of our proposed early stopping algorithm in enhancing the performance of deep UOD models. Auto Encoder (AE) enhanced by GradStop achieves better performance than itself, other SOTA UOD methods, and even ensemble AEs. Our method provides a robust and effective solution to the problem of performance degradation during training, enabling deep UOD models to achieve better potential in anomaly detection tasks.
<div id='section'>Paperid: <span id='pid'>931, <a href='https://arxiv.org/pdf/2411.11919.pdf' target='_blank'>https://arxiv.org/pdf/2411.11919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiyang Zhang, Hu Zhang, Zhedong Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11919">VL-Uncertainty: Detecting Hallucination in Large Vision-Language Model via Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the higher information load processed by large vision-language models (LVLMs) compared to single-modal LLMs, detecting LVLM hallucinations requires more human and time expense, and thus rise a wider safety concerns. In this paper, we introduce VL-Uncertainty, the first uncertainty-based framework for detecting hallucinations in LVLMs. Different from most existing methods that require ground-truth or pseudo annotations, VL-Uncertainty utilizes uncertainty as an intrinsic metric. We measure uncertainty by analyzing the prediction variance across semantically equivalent but perturbed prompts, including visual and textual data. When LVLMs are highly confident, they provide consistent responses to semantically equivalent queries. However, when uncertain, the responses of the target LVLM become more random. Considering semantically similar answers with different wordings, we cluster LVLM responses based on their semantic content and then calculate the cluster distribution entropy as the uncertainty measure to detect hallucination. Our extensive experiments on 10 LVLMs across four benchmarks, covering both free-form and multi-choice tasks, show that VL-Uncertainty significantly outperforms strong baseline methods in hallucination detection.
<div id='section'>Paperid: <span id='pid'>932, <a href='https://arxiv.org/pdf/2411.04562.pdf' target='_blank'>https://arxiv.org/pdf/2411.04562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marvin Alles, Philip Becker-Ehmck, Patrick van der Smagt, Maximilian Karl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04562">Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In offline reinforcement learning, a policy is learned using a static dataset in the absence of costly feedback from the environment. In contrast to the online setting, only using static datasets poses additional challenges, such as policies generating out-of-distribution samples. Model-based offline reinforcement learning methods try to overcome these by learning a model of the underlying dynamics of the environment and using it to guide policy search. It is beneficial but, with limited datasets, errors in the model and the issue of value overestimation among out-of-distribution states can worsen performance. Current model-based methods apply some notion of conservatism to the Bellman update, often implemented using uncertainty estimation derived from model ensembles. In this paper, we propose Constrained Latent Action Policies (C-LAP) which learns a generative model of the joint distribution of observations and actions. We cast policy learning as a constrained objective to always stay within the support of the latent action distribution, and use the generative capabilities of the model to impose an implicit constraint on the generated actions. Thereby eliminating the need to use additional uncertainty penalties on the Bellman update and significantly decreasing the number of gradient steps required to learn a policy. We empirically evaluate C-LAP on the D4RL and V-D4RL benchmark, and show that C-LAP is competitive to state-of-the-art methods, especially outperforming on datasets with visual observations.
<div id='section'>Paperid: <span id='pid'>933, <a href='https://arxiv.org/pdf/2411.02871.pdf' target='_blank'>https://arxiv.org/pdf/2411.02871.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junhao Dong, Xinghua Qu, Z. Jane Wang, Yew-Soon Ong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02871">Enhancing Adversarial Robustness via Uncertainty-Aware Distributional Adversarial Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite remarkable achievements in deep learning across various domains, its inherent vulnerability to adversarial examples still remains a critical concern for practical deployment. Adversarial training has emerged as one of the most effective defensive techniques for improving model robustness against such malicious inputs. However, existing adversarial training schemes often lead to limited generalization ability against underlying adversaries with diversity due to their overreliance on a point-by-point augmentation strategy by mapping each clean example to its adversarial counterpart during training. In addition, adversarial examples can induce significant disruptions in the statistical information w.r.t. the target model, thereby introducing substantial uncertainty and challenges to modeling the distribution of adversarial examples. To circumvent these issues, in this paper, we propose a novel uncertainty-aware distributional adversarial training method, which enforces adversary modeling by leveraging both the statistical information of adversarial examples and its corresponding uncertainty estimation, with the goal of augmenting the diversity of adversaries. Considering the potentially negative impact induced by aligning adversaries to misclassified clean examples, we also refine the alignment reference based on the statistical proximity to clean examples during adversarial training, thereby reframing adversarial training within a distribution-to-distribution matching framework interacted between the clean and adversarial domains. Furthermore, we design an introspective gradient alignment approach via matching input gradients between these domains without introducing external models. Extensive experiments across four benchmark datasets and various network architectures demonstrate that our approach achieves state-of-the-art adversarial robustness and maintains natural performance.
<div id='section'>Paperid: <span id='pid'>934, <a href='https://arxiv.org/pdf/2410.20783.pdf' target='_blank'>https://arxiv.org/pdf/2410.20783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20783">Graph-based Uncertainty Metrics for Long-form Language Model Outputs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in Large Language Models (LLMs) have significantly improved text generation capabilities, but these systems are still known to hallucinate, and granular uncertainty estimation for long-form LLM generations remains challenging. In this work, we propose Graph Uncertainty -- which represents the relationship between LLM generations and claims within them as a bipartite graph and estimates the claim-level uncertainty with a family of graph centrality metrics. Under this view, existing uncertainty estimation methods based on the concept of self-consistency can be viewed as using degree centrality as an uncertainty measure, and we show that more sophisticated alternatives such as closeness centrality provide consistent gains at claim-level uncertainty estimation. Moreover, we present uncertainty-aware decoding techniques that leverage both the graph structure and uncertainty estimates to improve the factuality of LLM generations by preserving only the most reliable claims. Compared to existing methods, our graph-based uncertainty metrics lead to an average of 6.8% relative gains on AUPRC across various long-form generation settings, and our end-to-end system provides consistent 2-4% gains in factuality over existing decoding techniques while significantly improving the informativeness of generated responses.
<div id='section'>Paperid: <span id='pid'>935, <a href='https://arxiv.org/pdf/2410.14868.pdf' target='_blank'>https://arxiv.org/pdf/2410.14868.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sung-Wook Lee, Xuhui Kang, Yen-Ling Kuo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14868">Diff-DAgger: Uncertainty Estimation with Diffusion Policy for Robotic Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, diffusion policy has shown impressive results in handling multi-modal tasks in robotic manipulation. However, it has fundamental limitations in out-of-distribution failures that persist due to compounding errors and its limited capability to extrapolate. One way to address these limitations is robot-gated DAgger, an interactive imitation learning with a robot query system to actively seek expert help during policy rollout. While robot-gated DAgger has high potential for learning at scale, existing methods like Ensemble-DAgger struggle with highly expressive policies: They often misinterpret policy disagreements as uncertainty at multi-modal decision points. To address this problem, we introduce Diff-DAgger, an efficient robot-gated DAgger algorithm that leverages the training objective of diffusion policy. We evaluate Diff-DAgger across different robot tasks including stacking, pushing, and plugging, and show that Diff-DAgger improves the task failure prediction by 39.0%, the task completion rate by 20.6%, and reduces the wall-clock time by a factor of 7.8. We hope that this work opens up a path for efficiently incorporating expressive yet data-hungry policies into interactive robot learning settings. The project website is available at: https://diffdagger.github.io.
<div id='section'>Paperid: <span id='pid'>936, <a href='https://arxiv.org/pdf/2410.09861.pdf' target='_blank'>https://arxiv.org/pdf/2410.09861.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shizuka Akahori, Satoshi Iizuka, Ken Mawatari, Kazuhiro Fukui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09861">Point Cloud Novelty Detection Based on Latent Representations of a General Feature Extractor</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an effective unsupervised 3D point cloud novelty detection approach, leveraging a general point cloud feature extractor and a one-class classifier. The general feature extractor consists of a graph-based autoencoder and is trained once on a point cloud dataset such as a mathematically generated fractal 3D point cloud dataset that is independent of normal/abnormal categories. The input point clouds are first converted into latent vectors by the general feature extractor, and then one-class classification is performed on the latent vectors. Compared to existing methods measuring the reconstruction error in 3D coordinate space, our approach utilizes latent representations where the shape information is condensed, which allows more direct and effective novelty detection. We confirm that our general feature extractor can extract shape features of unseen categories, eliminating the need for autoencoder re-training and reducing the computational burden. We validate the performance of our method through experiments on several subsets of the ShapeNet dataset and demonstrate that our latent-based approach outperforms the existing methods.
<div id='section'>Paperid: <span id='pid'>937, <a href='https://arxiv.org/pdf/2410.09861.pdf' target='_blank'>https://arxiv.org/pdf/2410.09861.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shizuka Akahori, Satoshi Iizuka, Ken Mawatari, Kazuhiro Fukui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09861">Point Cloud Novelty Detection Based on Latent Representations of a General Feature Extractor</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an effective unsupervised 3D point cloud novelty detection approach, leveraging a general point cloud feature extractor and a one-class classifier. The general feature extractor consists of a graph-based autoencoder and is trained once on a point cloud dataset such as a mathematically generated fractal 3D point cloud dataset that is independent of normal/abnormal categories. The input point clouds are first converted into latent vectors by the general feature extractor, and then one-class classification is performed on the latent vectors. Compared to existing methods measuring the reconstruction error in 3D coordinate space, our approach utilizes latent representations where the shape information is condensed, which allows more direct and effective novelty detection. We confirm that our general feature extractor can extract shape features of unseen categories, eliminating the need for autoencoder re-training and reducing the computational burden. We validate the performance of our method through experiments on several subsets of the ShapeNet dataset and demonstrate that our latent-based approach outperforms the existing methods.
<div id='section'>Paperid: <span id='pid'>938, <a href='https://arxiv.org/pdf/2409.17758.pdf' target='_blank'>https://arxiv.org/pdf/2409.17758.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Thel, Lars Greve, Maximilian Karl, Patrick van der Smagt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17758">Adapting Deep Variational Bayes Filter for Enhanced Confidence Estimation in Finite Element Method Integrated Networks (FEMIN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Finite Element Method (FEM) is a widely used technique for simulating crash scenarios with high accuracy and reliability. To reduce the significant computational costs associated with FEM, the Finite Element Method Integrated Networks (FEMIN) framework integrates neural networks (NNs) with FEM solvers. However, this integration can introduce errors and deviations from full-FEM simulations, highlighting the need for an additional metric to assess prediction confidence, especially when no ground truth data is available. In this study, we adapt the Deep Variational Bayes Filter (DVBF) to the FEMIN framework, incorporating a probabilistic approach to provide qualitative insights into prediction confidence during FEMIN simulations. The adaptation involves using the learned transition model for a predictive decoding step, generating a preliminary force prediction. This predictive force is used alongside the displacement and the velocity data from the FEM solver as input for the encoder model. The decoder reconstructs the likelihood distribution based on the posterior. The mean force of this distribution is applied to the FEM solver, while the predicted standard deviation can be used for uncertainty estimation. Our findings demonstrate that the DVBF outperforms deterministic NN architectures in terms of accuracy. Furthermore, the standard deviation derived from the decoder serves as a valuable qualitative metric for assessing the confidence in FEMIN simulations. This approach enhances the robustness of FEMIN by providing a measure of reliability alongside the simulation results.
<div id='section'>Paperid: <span id='pid'>939, <a href='https://arxiv.org/pdf/2409.13143.pdf' target='_blank'>https://arxiv.org/pdf/2409.13143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Ling, Yiping Xie, Nils Bore, John Folkesson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13143">Score-Based Multibeam Point Cloud Denoising</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multibeam echo-sounder (MBES) is the de-facto sensor for bathymetry mapping. In recent years, cheaper MBES sensors and global mapping initiatives have led to exponential growth of available data. However, raw MBES data contains 1-25% of noise that requires semi-automatic filtering using tools such as Combined Uncertainty and Bathymetric Estimator (CUBE). In this work, we draw inspirations from the 3D point cloud community and adapted a score-based point cloud denoising network for MBES outlier detection and denoising. We trained and evaluated this network on real MBES survey data. The proposed method was found to outperform classical methods, and can be readily integrated into existing MBES standard workflow. To facilitate future research, the code and pretrained model are available online.
<div id='section'>Paperid: <span id='pid'>940, <a href='https://arxiv.org/pdf/2409.02149.pdf' target='_blank'>https://arxiv.org/pdf/2409.02149.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thanh Tung Khuat, Robert Bassett, Ellen Otte, Bogdan Gabrys
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02149">Uncertainty Quantification Using Ensemble Learning and Monte Carlo Sampling for Performance Prediction and Monitoring in Cell Culture Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biopharmaceutical products, particularly monoclonal antibodies (mAbs), have gained prominence in the pharmaceutical market due to their high specificity and efficacy. As these products are projected to constitute a substantial portion of global pharmaceutical sales, the application of machine learning models in mAb development and manufacturing is gaining momentum. This paper addresses the critical need for uncertainty quantification in machine learning predictions, particularly in scenarios with limited training data. Leveraging ensemble learning and Monte Carlo simulations, our proposed method generates additional input samples to enhance the robustness of the model in small training datasets. We evaluate the efficacy of our approach through two case studies: predicting antibody concentrations in advance and real-time monitoring of glucose concentrations during bioreactor runs using Raman spectra data. Our findings demonstrate the effectiveness of the proposed method in estimating the uncertainty levels associated with process performance predictions and facilitating real-time decision-making in biopharmaceutical manufacturing. This contribution not only introduces a novel approach for uncertainty quantification but also provides insights into overcoming challenges posed by small training datasets in bioprocess development. The evaluation demonstrates the effectiveness of our method in addressing key challenges related to uncertainty estimation within upstream cell cultivation, illustrating its potential impact on enhancing process control and product quality in the dynamic field of biopharmaceuticals.
<div id='section'>Paperid: <span id='pid'>941, <a href='https://arxiv.org/pdf/2408.15012.pdf' target='_blank'>https://arxiv.org/pdf/2408.15012.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcel Boersma, Krishna Manoorkar, Alessandra Palmigiano, Mattia Panettiere, Apostolos Tzimoulis, Nachoem Wijnberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15012">Flexible categorization using formal concept analysis and Dempster-Shafer theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The framework developed in the present paper provides a formal ground to generate and study explainable categorizations of sets of entities, based on the epistemic attitudes of individual agents or groups thereof. Based on this framework, we discuss a machine-leaning meta-algorithm for outlier detection and classification which provides local and global explanations of its results.
<div id='section'>Paperid: <span id='pid'>942, <a href='https://arxiv.org/pdf/2408.00619.pdf' target='_blank'>https://arxiv.org/pdf/2408.00619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiyang Zhang, Hu Zhang, Hang Yu, Zhedong Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00619">Harnessing Uncertainty-aware Bounding Boxes for Unsupervised 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised 3D object detection aims to identify objects of interest from unlabeled raw data, such as LiDAR points. Recent approaches usually adopt pseudo 3D bounding boxes (3D bboxes) from clustering algorithm to initialize the model training. However, pseudo bboxes inevitably contain noise, and such inaccuracies accumulate to the final model, compromising the performance. Therefore, in an attempt to mitigate the negative impact of inaccurate pseudo bboxes, we introduce a new uncertainty-aware framework for unsupervised 3D object detection, dubbed UA3D. In particular, our method consists of two phases: uncertainty estimation and uncertainty regularization. (1) In the uncertainty estimation phase, we incorporate an extra auxiliary detection branch alongside the original primary detector. The prediction disparity between the primary and auxiliary detectors could reflect fine-grained uncertainty at the box coordinate level. (2) Based on the assessed uncertainty, we adaptively adjust the weight of every 3D bbox coordinate via uncertainty regularization, refining the training process on pseudo bboxes. For pseudo bbox coordinate with high uncertainty, we assign a relatively low loss weight. Extensive experiments verify that the proposed method is robust against the noisy pseudo bboxes, yielding substantial improvements on nuScenes and Lyft compared to existing approaches, with increases of +6.9% AP$_{BEV}$ and +2.5% AP$_{3D}$ on nuScenes, and +4.1% AP$_{BEV}$ and +2.0% AP$_{3D}$ on Lyft.
<div id='section'>Paperid: <span id='pid'>943, <a href='https://arxiv.org/pdf/2407.14097.pdf' target='_blank'>https://arxiv.org/pdf/2407.14097.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erik B. Terres-Escudero, Javier Del Ser, Aitor MartÃ­nez-Seras, Pablo Garcia-Bringas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14097">Forward-Forward Learning achieves Highly Selective Latent Representations for Out-of-Distribution Detection in Fully Spiking Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, Artificial Intelligence (AI) models have achieved remarkable success across various domains, yet challenges persist in two critical areas: ensuring robustness against uncertain inputs and drastically increasing model efficiency during training and inference. Spiking Neural Networks (SNNs), inspired by biological systems, offer a promising avenue for overcoming these limitations. By operating in an event-driven manner, SNNs achieve low energy consumption and can naturally implement biological methods known for their high noise tolerance. In this work, we explore the potential of the spiking Forward-Forward Algorithm (FFA) to address these challenges, leveraging its representational properties for both Out-of-Distribution (OoD) detection and interpretability. To achieve this, we exploit the sparse and highly specialized neural latent space of FF networks to estimate the likelihood of a sample belonging to the training distribution. Additionally, we propose a novel, gradient-free attribution method to detect features that drive a sample away from class distributions, addressing the challenges posed by the lack of gradients in most visual interpretability methods for spiking models. We evaluate our OoD detection algorithm on well-known image datasets (e.g., Omniglot, Not-MNIST, CIFAR10), outperforming previous methods proposed in the recent literature for OoD detection in spiking networks. Furthermore, our attribution method precisely identifies salient OoD features, such as artifacts or missing regions, hence providing a visual explanatory interface for the user to understand why unknown inputs are identified as such by the proposed method.
<div id='section'>Paperid: <span id='pid'>944, <a href='https://arxiv.org/pdf/2407.13307.pdf' target='_blank'>https://arxiv.org/pdf/2407.13307.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anna M. Wundram, Paul Fischer, Michael Muehlebach, Lisa M. Koch, Christian F. Baumgartner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13307">Conformal Performance Range Prediction for Segmentation Output Quality Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent works have introduced methods to estimate segmentation performance without ground truth, relying solely on neural network softmax outputs. These techniques hold potential for intuitive output quality control. However, such performance estimates rely on calibrated softmax outputs, which is often not the case in modern neural networks. Moreover, the estimates do not take into account inherent uncertainty in segmentation tasks. These limitations may render precise performance predictions unattainable, restricting the practical applicability of performance estimation methods. To address these challenges, we develop a novel approach for predicting performance ranges with statistical guarantees of containing the ground truth with a user specified probability. Our method leverages sampling-based segmentation uncertainty estimation to derive heuristic performance ranges, and applies split conformal prediction to transform these estimates into rigorous prediction ranges that meet the desired guarantees. We demonstrate our approach on the FIVES retinal vessel segmentation dataset and compare five commonly used sampling-based uncertainty estimation techniques. Our results show that it is possible to achieve the desired coverage with small prediction ranges, highlighting the potential of performance range prediction as a valuable tool for output quality control.
<div id='section'>Paperid: <span id='pid'>945, <a href='https://arxiv.org/pdf/2406.18580.pdf' target='_blank'>https://arxiv.org/pdf/2406.18580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Berry, Axel Brando, David Meger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.18580">Shedding Light on Large Generative Networks: Estimating Epistemic Uncertainty in Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative diffusion models, notable for their large parameter count (exceeding 100 million) and operation within high-dimensional image spaces, pose significant challenges for traditional uncertainty estimation methods due to computational demands. In this work, we introduce an innovative framework, Diffusion Ensembles for Capturing Uncertainty (DECU), designed for estimating epistemic uncertainty for diffusion models. The DECU framework introduces a novel method that efficiently trains ensembles of conditional diffusion models by incorporating a static set of pre-trained parameters, drastically reducing the computational burden and the number of parameters that require training. Additionally, DECU employs Pairwise-Distance Estimators (PaiDEs) to accurately measure epistemic uncertainty by evaluating the mutual information between model outputs and weights in high-dimensional spaces. The effectiveness of this framework is demonstrated through experiments on the ImageNet dataset, highlighting its capability to capture epistemic uncertainty, specifically in under-sampled image classes.
<div id='section'>Paperid: <span id='pid'>946, <a href='https://arxiv.org/pdf/2406.03680.pdf' target='_blank'>https://arxiv.org/pdf/2406.03680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atsutoshi Kumagai, Tomoharu Iwata, Yasuhiro Fujiwara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03680">Meta-learning for Positive-unlabeled Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a meta-learning method for positive and unlabeled (PU) classification, which improves the performance of binary classifiers obtained from only PU data in unseen target tasks. PU learning is an important problem since PU data naturally arise in real-world applications such as outlier detection and information retrieval. Existing PU learning methods require many PU data, but sufficient data are often unavailable in practice. The proposed method minimizes the test classification risk after the model is adapted to PU data by using related tasks that consist of positive, negative, and unlabeled data. We formulate the adaptation as an estimation problem of the Bayes optimal classifier, which is an optimal classifier to minimize the classification risk. The proposed method embeds each instance into a task-specific space using neural networks. With the embedded PU data, the Bayes optimal classifier is estimated through density-ratio estimation of PU densities, whose solution is obtained as a closed-form solution. The closed-form solution enables us to efficiently and effectively minimize the test classification risk. We empirically show that the proposed method outperforms existing methods with one synthetic and three real-world datasets.
<div id='section'>Paperid: <span id='pid'>947, <a href='https://arxiv.org/pdf/2405.16766.pdf' target='_blank'>https://arxiv.org/pdf/2405.16766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxiao Lee, Xiaofeng Cao, Jingcai Guo, Wei Ye, Qing Guo, Yi Chang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16766">Concept Matching with Agent for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The remarkable achievements of Large Language Models (LLMs) have captivated the attention of both academia and industry, transcending their initial role in dialogue generation. To expand the usage scenarios of LLM, some works enhance the effectiveness and capabilities of the model by introducing more external information, which is called the agent paradigm. Based on this idea, we propose a new method that integrates the agent paradigm into out-of-distribution (OOD) detection task, aiming to improve its robustness and adaptability. Our proposed method, Concept Matching with Agent (CMA), employs neutral prompts as agents to augment the CLIP-based OOD detection process. These agents function as dynamic observers and communication hubs, interacting with both In-distribution (ID) labels and data inputs to form vector triangle relationships. This triangular framework offers a more nuanced approach than the traditional binary relationship, allowing for better separation and identification of ID and OOD inputs. Our extensive experimental results showcase the superior performance of CMA over both zero-shot and training-required methods in a diverse array of real-world scenarios.
<div id='section'>Paperid: <span id='pid'>948, <a href='https://arxiv.org/pdf/2405.14563.pdf' target='_blank'>https://arxiv.org/pdf/2405.14563.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Loris Giulivi, Giacomo Boracchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14563">Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in multi-modal embeddings, and in particular CLIP, have recently driven several breakthroughs in Computer Vision (CV). CLIP has shown impressive performance on a variety of tasks, yet, its inherently opaque architecture may hinder the application of models employing CLIP as backbone, especially in fields where trust and model explainability are imperative, such as in the medical domain. Current explanation methodologies for CV models rely on Saliency Maps computed through gradient analysis or input perturbation. However, these Saliency Maps can only be computed to explain classes relevant to the end task, often smaller in scope than the backbone training classes. In the context of models implementing CLIP as their vision backbone, a substantial portion of the information embedded within the learned representations is thus left unexplained.
  In this work, we propose Concept Visualization (ConVis), a novel saliency methodology that explains the CLIP embedding of an image by exploiting the multi-modal nature of the embeddings. ConVis makes use of lexical information from WordNet to compute task-agnostic Saliency Maps for any concept, not limited to concepts the end model was trained on. We validate our use of WordNet via an out of distribution detection experiment, and test ConVis on an object localization benchmark, showing that Concept Visualizations correctly identify and localize the image's semantic content. Additionally, we perform a user study demonstrating that our methodology can give users insight on the model's functioning.
<div id='section'>Paperid: <span id='pid'>949, <a href='https://arxiv.org/pdf/2405.12502.pdf' target='_blank'>https://arxiv.org/pdf/2405.12502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, Xuemin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12502">EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised Outlier Detection (UOD) is an important data mining task. With the advance of deep learning, deep Outlier Detection (OD) has received broad interest. Most deep UOD models are trained exclusively on clean datasets to learn the distribution of the normal data, which requires huge manual efforts to clean the real-world data if possible. Instead of relying on clean datasets, some approaches directly train and detect on unlabeled contaminated datasets, leading to the need for methods that are robust to such conditions. Ensemble methods emerged as a superior solution to enhance model robustness against contaminated training sets. However, the training time is greatly increased by the ensemble.
  In this study, we investigate the impact of outliers on the training phase, aiming to halt training on unlabeled contaminated datasets before performance degradation. Initially, we noted that blending normal and anomalous data causes AUC fluctuations, a label-dependent measure of detection accuracy. To circumvent the need for labels, we propose a zero-label entropy metric named Loss Entropy for loss distribution, enabling us to infer optimal stopping points for training without labels. Meanwhile, we theoretically demonstrate negative correlation between entropy metric and the label-based AUC. Based on this, we develop an automated early-stopping algorithm, EntropyStop, which halts training when loss entropy suggests the maximum model detection capability. We conduct extensive experiments on ADBench (including 47 real datasets), and the overall results indicate that AutoEncoder (AE) enhanced by our approach not only achieves better performance than ensemble AEs but also requires under 2\% of training time. Lastly, our proposed metric and early-stopping approach are evaluated on other deep OD models, exhibiting their broad potential applicability.
<div id='section'>Paperid: <span id='pid'>950, <a href='https://arxiv.org/pdf/2405.09697.pdf' target='_blank'>https://arxiv.org/pdf/2405.09697.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jadie Adams, Krithika Iyer, Shireen Elhabian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.09697">Weakly Supervised Bayesian Shape Modeling from Unsegmented Medical Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anatomical shape analysis plays a pivotal role in clinical research and hypothesis testing, where the relationship between form and function is paramount. Correspondence-based statistical shape modeling (SSM) facilitates population-level morphometrics but requires a cumbersome, potentially bias-inducing construction pipeline. Recent advancements in deep learning have streamlined this process in inference by providing SSM prediction directly from unsegmented medical images. However, the proposed approaches are fully supervised and require utilizing a traditional SSM construction pipeline to create training data, thus inheriting the associated burdens and limitations. To address these challenges, we introduce a weakly supervised deep learning approach to predict SSM from images using point cloud supervision. Specifically, we propose reducing the supervision associated with the state-of-the-art fully Bayesian variational information bottleneck DeepSSM (BVIB-DeepSSM) model. BVIB-DeepSSM is an effective, principled framework for predicting probabilistic anatomical shapes from images with quantification of both aleatoric and epistemic uncertainties. Whereas the original BVIB-DeepSSM method requires strong supervision in the form of ground truth correspondence points, the proposed approach utilizes weak supervision via point cloud surface representations, which are more readily obtainable. Furthermore, the proposed approach learns correspondence in a completely data-driven manner without prior assumptions about the expected variability in shape cohort. Our experiments demonstrate that this approach yields similar accuracy and uncertainty estimation to the fully supervised scenario while substantially enhancing the feasibility of model training for SSM construction.
<div id='section'>Paperid: <span id='pid'>951, <a href='https://arxiv.org/pdf/2405.02140.pdf' target='_blank'>https://arxiv.org/pdf/2405.02140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alvaro H. C. Correia, Fabio Valerio Massoli, Christos Louizos, Arash Behboodi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02140">An Information Theoretic Perspective on Conformal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformal Prediction (CP) is a distribution-free uncertainty estimation framework that constructs prediction sets guaranteed to contain the true answer with a user-specified probability. Intuitively, the size of the prediction set encodes a general notion of uncertainty, with larger sets associated with higher degrees of uncertainty. In this work, we leverage information theory to connect conformal prediction to other notions of uncertainty. More precisely, we prove three different ways to upper bound the intrinsic uncertainty, as described by the conditional entropy of the target variable given the inputs, by combining CP with information theoretical inequalities. Moreover, we demonstrate two direct and useful applications of such connection between conformal prediction and information theory: (i) more principled and effective conformal training objectives that generalize previous approaches and enable end-to-end training of machine learning models from scratch, and (ii) a natural mechanism to incorporate side information into conformal prediction. We empirically validate both applications in centralized and federated learning settings, showing our theoretical results translate to lower inefficiency (average prediction set size) for popular CP methods.
<div id='section'>Paperid: <span id='pid'>952, <a href='https://arxiv.org/pdf/2404.09127.pdf' target='_blank'>https://arxiv.org/pdf/2404.09127.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruixin Yang, Dheeraj Rajagopal, Shirley Anugrah Hayati, Bin Hu, Dongyeop Kang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.09127">Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a significant issue for current large language models (LLMs) that are generally poorly calibrated and over-confident, especially with reinforcement learning from human feedback (RLHF). Unlike humans, whose decisions and confidences not only stem from intrinsic beliefs but can also be adjusted through daily observations, existing calibration methods for LLMs focus on estimating or eliciting individual confidence without taking full advantage of the "Collective Wisdom": the interaction among multiple LLMs that can collectively improve both accuracy and calibration. In this work, we propose Collaborative Calibration, a post-hoc training-free calibration strategy that leverages the collaborative and expressive capabilities of multiple tool-augmented LLM agents in a simulated group deliberation process. We demonstrate the effectiveness of Collaborative Calibration on generative QA tasks across various domains, showing its potential in harnessing the rationalization of collectively calibrated confidence assessments and improving the reliability of model predictions.
<div id='section'>Paperid: <span id='pid'>953, <a href='https://arxiv.org/pdf/2403.16260.pdf' target='_blank'>https://arxiv.org/pdf/2403.16260.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhui Xu, Fuxun Yu, Zirui Xu, Nathan Inkawhich, Xiang Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.16260">Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity.
  However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation.
  To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into distinct supervision tasks. This innovative approach, termed Multi-Comprehension (MC) Ensemble, leverages diverse training tasks to generate distinct comprehensions of the data and labels, thereby extending the feature representation field.
  Our experimental results demonstrate the superior performance of the MC Ensemble strategy in OOD detection compared to both the naive Deep Ensemble method and a standalone model of comparable size. This underscores the effectiveness of our proposed approach in enhancing the model's capability to detect instances outside its training distribution.
<div id='section'>Paperid: <span id='pid'>954, <a href='https://arxiv.org/pdf/2403.13452.pdf' target='_blank'>https://arxiv.org/pdf/2403.13452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luca Mozzarelli, Luca Cattaneo, Matteo Corno, Sergio Matteo Savaresi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13452">Mobile Robot Localization: a Modular, Odometry-Improving Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the number of works published in recent years, vehicle localization remains an open, challenging problem. While map-based localization and SLAM algorithms are getting better and better, they remain a single point of failure in typical localization pipelines. This paper proposes a modular localization architecture that fuses sensor measurements with the outputs of off-the-shelf localization algorithms. The fusion filter estimates model uncertainties to improve odometry in case absolute pose measurements are lost entirely. The architecture is validated experimentally on a real robot navigating autonomously proving a reduction of the position error of more than 90% with respect to the odometrical estimate without uncertainty estimation in a two-minute navigation period without position measurements.
<div id='section'>Paperid: <span id='pid'>955, <a href='https://arxiv.org/pdf/2403.10403.pdf' target='_blank'>https://arxiv.org/pdf/2403.10403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marc Lafon, ClÃ©ment Rambour, Nicolas Thome
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10403">Energy Correction Model in the Feature Space for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we study the out-of-distribution (OOD) detection problem through the use of the feature space of a pre-trained deep classifier. We show that learning the density of in-distribution (ID) features with an energy-based models (EBM) leads to competitive detection results. However, we found that the non-mixing of MCMC sampling during the EBM's training undermines its detection performance. To overcome this an energy-based correction of a mixture of class-conditional Gaussian distributions. We obtains favorable results when compared to a strong baseline like the KNN detector on the CIFAR-10/CIFAR-100 OOD detection benchmarks.
<div id='section'>Paperid: <span id='pid'>956, <a href='https://arxiv.org/pdf/2402.16865.pdf' target='_blank'>https://arxiv.org/pdf/2402.16865.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anirudh Prabhakaran, YeKun Xiao, Ching-Yu Cheng, Dianbo Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16865">Enhance Eye Disease Detection using Learnable Probabilistic Discrete Latents in Machine Learning Architectures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ocular diseases, including diabetic retinopathy and glaucoma, present a significant public health challenge due to their high prevalence and potential for causing vision impairment. Early and accurate diagnosis is crucial for effective treatment and management. In recent years, deep learning models have emerged as powerful tools for analysing medical images, such as retina imaging. However, challenges persist in model relibability and uncertainty estimation, which are critical for clinical decision-making. This study leverages the probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over latent discrete dropout masks for the classification and analysis of ocular diseases using fundus images. We develop a robust and generalizable method that utilizes GFlowOut integrated with ResNet18 and ViT models as the backbone in identifying various ocular conditions. This study employs a unique set of dropout masks - none, random, bottomup, and topdown - to enhance model performance in analyzing these fundus images. Our results demonstrate that our learnable probablistic latents significantly improves accuracy, outperforming the traditional dropout approach. We utilize a gradient map calculation method, Grad-CAM, to assess model explainability, observing that the model accurately focuses on critical image regions for predictions. The integration of GFlowOut in neural networks presents a promising advancement in the automated diagnosis of ocular diseases, with implications for improving clinical workflows and patient outcomes.
<div id='section'>Paperid: <span id='pid'>957, <a href='https://arxiv.org/pdf/2402.15374.pdf' target='_blank'>https://arxiv.org/pdf/2402.15374.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anja DeliÄ, Matej GrciÄ, SiniÅ¡a Å egviÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.15374">Outlier detection by ensembling uncertainty with negative objectness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection is an essential capability in safety-critical applications of supervised visual recognition. Most of the existing methods deliver best results by encouraging standard closed-set models to produce low-confidence predictions in negative training data. However, that approach conflates prediction uncertainty with recognition of the negative class. We therefore reconsider direct prediction of K+1 logits that correspond to K groundtruth classes and one outlier class. This setup allows us to formulate a novel anomaly score as an ensemble of in-distribution uncertainty and the posterior of the outlier class which we term negative objectness. Now outliers can be independently detected due to i) high prediction uncertainty or ii) similarity with negative data. We embed our method into a dense prediction architecture with mask-level recognition over K+2 classes. The training procedure encourages the novel K+2-th class to learn negative objectness at pasted negative instances. Our models outperform the current state-of-the art on standard benchmarks for image-wide and pixel-level outlier detection with and without training on real negative data.
<div id='section'>Paperid: <span id='pid'>958, <a href='https://arxiv.org/pdf/2402.01302.pdf' target='_blank'>https://arxiv.org/pdf/2402.01302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aleksandar Armacki, Dragana BajoviÄ, DuÅ¡an JakovetiÄ, Soummya Kar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01302">A Unified Framework for Center-based Clustering of Distributed Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a family of distributed center-based clustering algorithms that work over networks of users. In the proposed scenario, users contain a local dataset and communicate only with their immediate neighbours, with the aim of finding a clustering of the full, joint data. The proposed family, termed Distributed Gradient Clustering (DGC-$\mathcal{F}_Ï$), is parametrized by $Ï\geq 1$, controling the proximity of users' center estimates, with $\mathcal{F}$ determining the clustering loss. Our framework allows for a broad class of smooth convex loss functions, including popular clustering losses like $K$-means and Huber loss. Specialized to popular clustering losses like $K$-means and Huber loss, DGC-$\mathcal{F}_Ï$ gives rise to novel distributed clustering algorithms DGC-KM$_Ï$ and DGC-HL$_Ï$, while novel clustering losses based on Logistic and Fair functions lead to DGC-LL$_Ï$ and DGC-FL$_Ï$. We provide a unified analysis and establish several strong results, under mild assumptions. First, we show that the sequence of centers generated by the methods converges to a well-defined notion of fixed point, under any center initialization and value of $Ï$. Second, we prove that, as $Ï$ increases, the family of fixed points produced by DGC-$\mathcal{F}_Ï$ converges to a notion of consensus fixed points. We show that consensus fixed points of DGC-$\mathcal{F}_Ï$ are equivalent to fixed points of gradient clustering over the full data, guaranteeing a clustering of the full data is produced. For the special case of Bregman losses, we show that our fixed points converge to the set of Lloyd points. Extensive numerical experiments on synthetic and real data confirm our theoretical findings, show strong performance of our methods and demonstrate the usefulness and wide range of potential applications of our general framework, such as outlier detection.
<div id='section'>Paperid: <span id='pid'>959, <a href='https://arxiv.org/pdf/2401.05043.pdf' target='_blank'>https://arxiv.org/pdf/2401.05043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaizheng Wang, Keivan Shariatmadar, Shireen Kudukkil Manchingal, Fabio Cuzzolin, David Moens, Hans Hallez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05043">CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective uncertainty estimation is becoming increasingly attractive for enhancing the reliability of neural networks. This work presents a novel approach, termed Credal-Set Interval Neural Networks (CreINNs), for classification. CreINNs retain the fundamental structure of traditional Interval Neural Networks, capturing weight uncertainty through deterministic intervals. CreINNs are designed to predict an upper and a lower probability bound for each class, rather than a single probability value. The probability intervals can define a credal set, facilitating estimating different types of uncertainties associated with predictions. Experiments on standard multiclass and binary classification tasks demonstrate that the proposed CreINNs can achieve superior or comparable quality of uncertainty estimation compared to variational Bayesian Neural Networks (BNNs) and Deep Ensembles. Furthermore, CreINNs significantly reduce the computational complexity of variational BNNs during inference. Moreover, the effective uncertainty quantification of CreINNs is also verified when the input data are intervals.
<div id='section'>Paperid: <span id='pid'>960, <a href='https://arxiv.org/pdf/2312.17199.pdf' target='_blank'>https://arxiv.org/pdf/2312.17199.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tim G. J. Rudner, Zonghao Chen, Yee Whye Teh, Yarin Gal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.17199">Tractable Function-Space Variational Inference in Bayesian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable predictive uncertainty estimation plays an important role in enabling the deployment of neural networks to safety-critical settings. A popular approach for estimating the predictive uncertainty of neural networks is to define a prior distribution over the network parameters, infer an approximate posterior distribution, and use it to make stochastic predictions. However, explicit inference over neural network parameters makes it difficult to incorporate meaningful prior information about the data-generating process into the model. In this paper, we pursue an alternative approach. Recognizing that the primary object of interest in most settings is the distribution over functions induced by the posterior distribution over neural network parameters, we frame Bayesian inference in neural networks explicitly as inferring a posterior distribution over functions and propose a scalable function-space variational inference method that allows incorporating prior information and results in reliable predictive uncertainty estimates. We show that the proposed method leads to state-of-the-art uncertainty estimation and predictive performance on a range of prediction tasks and demonstrate that it performs well on a challenging safety-critical medical diagnosis task in which reliable uncertainty estimation is essential.
<div id='section'>Paperid: <span id='pid'>961, <a href='https://arxiv.org/pdf/2312.12010.pdf' target='_blank'>https://arxiv.org/pdf/2312.12010.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcel Boersma, Krishna Manoorkar, Alessandra Palmigiano, Mattia Panettiere, Apostolos Tzimoulis, Nachoem Wijnberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.12010">Outlier detection using flexible categorisation and interrogative agendas</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Categorization is one of the basic tasks in machine learning and data analysis. Building on formal concept analysis (FCA), the starting point of the present work is that different ways to categorize a given set of objects exist, which depend on the choice of the sets of features used to classify them, and different such sets of features may yield better or worse categorizations, relative to the task at hand. In their turn, the (a priori) choice of a particular set of features over another might be subjective and express a certain epistemic stance (e.g. interests, relevance, preferences) of an agent or a group of agents, namely, their interrogative agenda. In the present paper, we represent interrogative agendas as sets of features, and explore and compare different ways to categorize objects w.r.t. different sets of features (agendas). We first develop a simple unsupervised FCA-based algorithm for outlier detection which uses categorizations arising from different agendas. We then present a supervised meta-learning algorithm to learn suitable (fuzzy) agendas for categorization as sets of features with different weights or masses. We combine this meta-learning algorithm with the unsupervised outlier detection algorithm to obtain a supervised outlier detection algorithm. We show that these algorithms perform at par with commonly used algorithms for outlier detection on commonly used datasets in outlier detection. These algorithms provide both local and global explanations of their results.
<div id='section'>Paperid: <span id='pid'>962, <a href='https://arxiv.org/pdf/2312.07952.pdf' target='_blank'>https://arxiv.org/pdf/2312.07952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomoharu Iwata, Atsutoshi Kumagai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.07952">Meta-learning to Calibrate Gaussian Processes with Deep Kernels for Regression Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although Gaussian processes (GPs) with deep kernels have been successfully used for meta-learning in regression tasks, its uncertainty estimation performance can be poor. We propose a meta-learning method for calibrating deep kernel GPs for improving regression uncertainty estimation performance with a limited number of training data. The proposed method meta-learns how to calibrate uncertainty using data from various tasks by minimizing the test expected calibration error, and uses the knowledge for unseen tasks. We design our model such that the adaptation and calibration for each task can be performed without iterative procedures, which enables effective meta-learning. In particular, a task-specific uncalibrated output distribution is modeled by a GP with a task-shared encoder network, and it is transformed to a calibrated one using a cumulative density function of a task-specific Gaussian mixture model (GMM). By integrating the GP and GMM into our neural network-based model, we can meta-learn model parameters in an end-to-end fashion. Our experiments demonstrate that the proposed method improves uncertainty estimation performance while keeping high regression performance compared with the existing methods using real-world datasets in few-shot settings.
<div id='section'>Paperid: <span id='pid'>963, <a href='https://arxiv.org/pdf/2312.05946.pdf' target='_blank'>https://arxiv.org/pdf/2312.05946.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Angel Daruna, Yunye Gong, Abhinav Rajvanshi, Han-Pang Chiu, Yi Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.05946">Uncertainty Propagation through Trained Deep Neural Networks Using Factor Graphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictive uncertainty estimation remains a challenging problem precluding the use of deep neural networks as subsystems within safety-critical applications. Aleatoric uncertainty is a component of predictive uncertainty that cannot be reduced through model improvements. Uncertainty propagation seeks to estimate aleatoric uncertainty by propagating input uncertainties to network predictions. Existing uncertainty propagation techniques use one-way information flows, propagating uncertainties layer-by-layer or across the entire neural network while relying either on sampling or analytical techniques for propagation. Motivated by the complex information flows within deep neural networks (e.g. skip connections), we developed and evaluated a novel approach by posing uncertainty propagation as a non-linear optimization problem using factor graphs. We observed statistically significant improvements in performance over prior work when using factor graphs across most of our experiments that included three datasets and two neural network architectures. Our implementation balances the benefits of sampling and analytical propagation techniques, which we believe, is a key factor in achieving performance improvements.
<div id='section'>Paperid: <span id='pid'>964, <a href='https://arxiv.org/pdf/2312.04386.pdf' target='_blank'>https://arxiv.org/pdf/2312.04386.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos E. Luis, Alessandro G. Bottero, Julia Vinogradska, Felix Berkenkamp, Jan Peters
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.04386">Model-Based Epistemic Variance of Values for Risk-Aware Policy Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of quantifying uncertainty over expected cumulative rewards in model-based reinforcement learning. In particular, we focus on characterizing the variance over values induced by a distribution over Markov decision processes (MDPs). Previous work upper bounds the posterior variance over values by solving a so-called uncertainty Bellman equation (UBE), but the over-approximation may result in inefficient exploration. We propose a new UBE whose solution converges to the true posterior variance over values and leads to lower regret in tabular exploration problems. We identify challenges to apply the UBE theory beyond tabular problems and propose a suitable approximation. Based on this approximation, we introduce a general-purpose policy optimization algorithm, Q-Uncertainty Soft Actor-Critic (QU-SAC), that can be applied for either risk-seeking or risk-averse policy optimization with minimal changes. Experiments in both online and offline RL demonstrate improved performance compared to other uncertainty estimation methods.
<div id='section'>Paperid: <span id='pid'>965, <a href='https://arxiv.org/pdf/2312.00232.pdf' target='_blank'>https://arxiv.org/pdf/2312.00232.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander MÃ¶llers, Alexander Immer, Elvin Isufi, Vincent Fortuin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00232">Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph contrastive learning has shown great promise when labeled data is scarce, but large unlabeled datasets are available. However, it often does not take uncertainty estimation into account. We show that a variational Bayesian neural network approach can be used to improve not only the uncertainty estimates but also the downstream performance on semi-supervised node-classification tasks. Moreover, we propose a new measure of uncertainty for contrastive learning, that is based on the disagreement in likelihood due to different positive samples.
<div id='section'>Paperid: <span id='pid'>966, <a href='https://arxiv.org/pdf/2311.14435.pdf' target='_blank'>https://arxiv.org/pdf/2311.14435.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgii Mikriukov, Gesina Schwalbe, Korinna Bade
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.14435">Local Concept Embeddings for Analysis of Concept Distributions in Vision DNN Feature Spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Insights into the learned latent representations are imperative for verifying deep neural networks (DNNs) in critical computer vision (CV) tasks. Therefore, state-of-the-art supervised Concept-based eXplainable Artificial Intelligence (C-XAI) methods associate user-defined concepts like ``car'' each with a single vector in the DNN latent space (concept embedding vector). In the case of concept segmentation, these linearly separate between activation map pixels belonging to a concept and those belonging to background. Existing methods for concept segmentation, however, fall short of capturing implicitly learned sub-concepts (e.g., the DNN might split car into ``proximate car'' and ``distant car''), and overlap of user-defined concepts (e.g., between ``bus'' and ``truck''). In other words, they do not capture the full distribution of concept representatives in latent space. For the first time, this work shows that these simplifications are frequently broken and that distribution information can be particularly useful for understanding DNN-learned notions of sub-concepts, concept confusion, and concept outliers. To allow exploration of learned concept distributions, we propose a novel local concept analysis framework. Instead of optimizing a single global concept vector on the complete dataset, it generates a local concept embedding (LoCE) vector for each individual sample. We use the distribution formed by LoCEs to explore the latent concept distribution by fitting Gaussian mixture models (GMMs), hierarchical clustering, and concept-level information retrieval and outlier detection. Despite its context sensitivity, our method's concept segmentation performance is competitive to global baselines. Analysis results are obtained on three datasets and six diverse vision DNN architectures, including vision transformers (ViTs).
<div id='section'>Paperid: <span id='pid'>967, <a href='https://arxiv.org/pdf/2311.13800.pdf' target='_blank'>https://arxiv.org/pdf/2311.13800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhishek Sebastian, Pragna R, Sudhakaran G, Renjith P N, Leela Karthikeyan H
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13800">Enhancing Intrusion Detection In Internet Of Vehicles Through Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning is a technique of decentralized machine learning. that allows multiple parties to collaborate and learn a shared model without sharing their raw data. Our paper proposes a federated learning framework for intrusion detection in Internet of Vehicles (IOVs) using the CIC-IDS 2017 dataset. The proposed framework employs SMOTE for handling class imbalance, outlier detection for identifying and removing abnormal observations, and hyperparameter tuning to optimize the model's performance. The authors evaluated the proposed framework using various performance metrics and demonstrated its effectiveness in detecting intrusions with other datasets (KDD-Cup 99 and UNSW- NB-15) and conventional classifiers. Furthermore, the proposed framework can protect sensitive data while achieving high intrusion detection performance.
<div id='section'>Paperid: <span id='pid'>968, <a href='https://arxiv.org/pdf/2311.12855.pdf' target='_blank'>https://arxiv.org/pdf/2311.12855.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Romain Xu-Darme, Julien Girard-Satabin, Darryl Hond, Gabriele Incorvaia, Zakaria Chihani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12855">Contextualised Out-of-Distribution Detection using Pattern Identication</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose CODE, an extension of existing work from the field of explainable AI that identifies class-specific recurring patterns to build a robust Out-of-Distribution (OoD) detection method for visual classifiers. CODE does not require any classifier retraining and is OoD-agnostic, i.e., tuned directly to the training dataset. Crucially, pattern identification allows us to provide images from the In-Distribution (ID) dataset as reference data to provide additional context to the confidence scores. In addition, we introduce a new benchmark based on perturbations of the ID dataset that provides a known and quantifiable measure of the discrepancy between the ID and OoD datasets serving as a reference value for the comparison between OoD detection methods.
<div id='section'>Paperid: <span id='pid'>969, <a href='https://arxiv.org/pdf/2311.12153.pdf' target='_blank'>https://arxiv.org/pdf/2311.12153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivo M. Baltruschat, Parvaneh Janbakhshi, Melanie Dohmen, Matthias Lenga
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12153">Uncertainty Estimation in Contrast-Enhanced MR Image Translation with Multi-Axis Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, deep learning has been applied to a wide range of medical imaging and image processing tasks. In this work, we focus on the estimation of epistemic uncertainty for 3D medical image-to-image translation. We propose a novel model uncertainty quantification method, Multi-Axis Fusion (MAF), which relies on the integration of complementary information derived from multiple views on volumetric image data. The proposed approach is applied to the task of synthesizing contrast enhanced T1-weighted images based on native T1, T2 and T2-FLAIR scans. The quantitative findings indicate a strong correlation ($Ï_{\text healthy} = 0.89$) between the mean absolute image synthetization error and the mean uncertainty score for our MAF method. Hence, we consider MAF as a promising approach to solve the highly relevant task of detecting synthetization failures at inference time.
<div id='section'>Paperid: <span id='pid'>970, <a href='https://arxiv.org/pdf/2311.06481.pdf' target='_blank'>https://arxiv.org/pdf/2311.06481.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianxiang Feng, Jongseok Lee, Simon Geisler, Stephan Gunnemann, Rudolph Triebel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.06481">Topology-Matching Normalizing Flows for Out-of-Distribution Detection in Robot Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To facilitate reliable deployments of autonomous robots in the real world, Out-of-Distribution (OOD) detection capabilities are often required. A powerful approach for OOD detection is based on density estimation with Normalizing Flows (NFs). However, we find that prior work with NFs attempts to match the complex target distribution topologically with naive base distributions leading to adverse implications. In this work, we circumvent this topological mismatch using an expressive class-conditional base distribution trained with an information-theoretic objective to match the required topology. The proposed method enjoys the merits of wide compatibility with existing learned models without any performance degradation and minimum computation overhead while enhancing OOD detection capabilities. We demonstrate superior results in density estimation and 2D object detection benchmarks in comparison with extensive baselines. Moreover, we showcase the applicability of the method with a real-robot deployment.
<div id='section'>Paperid: <span id='pid'>971, <a href='https://arxiv.org/pdf/2311.06400.pdf' target='_blank'>https://arxiv.org/pdf/2311.06400.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinsong Xu, Jiaqi Tang, Aidong Men, Qingchao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.06400">EviPrompt: A Training-Free Evidential Prompt Generation Method for Segment Anything Model in Medical Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical image segmentation has immense clinical applicability but remains a challenge despite advancements in deep learning. The Segment Anything Model (SAM) exhibits potential in this field, yet the requirement for expertise intervention and the domain gap between natural and medical images poses significant obstacles. This paper introduces a novel training-free evidential prompt generation method named EviPrompt to overcome these issues. The proposed method, built on the inherent similarities within medical images, requires only a single reference image-annotation pair, making it a training-free solution that significantly reduces the need for extensive labeling and computational resources. First, to automatically generate prompts for SAM in medical images, we introduce an evidential method based on uncertainty estimation without the interaction of clinical experts. Then, we incorporate the human prior into the prompts, which is vital for alleviating the domain gap between natural and medical images and enhancing the applicability and usefulness of SAM in medical scenarios. EviPrompt represents an efficient and robust approach to medical image segmentation, with evaluations across a broad range of tasks and modalities confirming its efficacy.
<div id='section'>Paperid: <span id='pid'>972, <a href='https://arxiv.org/pdf/2310.19686.pdf' target='_blank'>https://arxiv.org/pdf/2310.19686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Margerie Huet-Dastarac, Dan Nguyen, Steve Jiang, John Lee, Ana Barragan Montero
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19686">Can input reconstruction be used to directly estimate uncertainty of a regression U-Net model? -- Application to proton therapy dose prediction for head and neck cancer patients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating the uncertainty of deep learning models in a reliable and efficient way has remained an open problem, where many different solutions have been proposed in the literature. Most common methods are based on Bayesian approximations, like Monte Carlo dropout (MCDO) or Deep ensembling (DE), but they have a high inference time (i.e. require multiple inference passes) and might not work for out-of-distribution detection (OOD) data (i.e. similar uncertainty for in-distribution (ID) and OOD). In safety critical environments, like medical applications, accurate and fast uncertainty estimation methods, able to detect OOD data, are crucial, since wrong predictions can jeopardize patients safety. In this study, we present an alternative direct uncertainty estimation method and apply it for a regression U-Net architecture. The method consists in the addition of a branch from the bottleneck which reconstructs the input. The input reconstruction error can be used as a surrogate of the model uncertainty. For the proof-of-concept, our method is applied to proton therapy dose prediction in head and neck cancer patients. Accuracy, time-gain, and OOD detection are analyzed for our method in this particular application and compared with the popular MCDO and DE. The input reconstruction method showed a higher Pearson correlation coefficient with the prediction error (0.620) than DE and MCDO (between 0.447 and 0.612). Moreover, our method allows an easier identification of OOD (Z-score of 34.05). It estimates the uncertainty simultaneously to the regression task, therefore requires less time or computational resources.
<div id='section'>Paperid: <span id='pid'>973, <a href='https://arxiv.org/pdf/2310.05833.pdf' target='_blank'>https://arxiv.org/pdf/2310.05833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian G. Gruber, Florian Buettner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05833">A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models, like large language models, are becoming increasingly relevant in our daily lives, yet a theoretical framework to assess their generalization behavior and uncertainty does not exist. Particularly, the problem of uncertainty estimation is commonly solved in an ad-hoc and task-dependent manner. For example, natural language approaches cannot be transferred to image generation. In this paper, we introduce the first bias-variance-covariance decomposition for kernel scores. This decomposition represents a theoretical framework from which we derive a kernel-based variance and entropy for uncertainty estimation. We propose unbiased and consistent estimators for each quantity which only require generated samples but not the underlying model itself. Based on the wide applicability of kernels, we demonstrate our framework via generalization and uncertainty experiments for image, audio, and language generation. Specifically, kernel entropy for uncertainty estimation is more predictive of performance on CoQA and TriviaQA question answering datasets than existing baselines and can also be applied to closed-source models.
<div id='section'>Paperid: <span id='pid'>974, <a href='https://arxiv.org/pdf/2309.17074.pdf' target='_blank'>https://arxiv.org/pdf/2309.17074.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengkun Tang, Yaqing Wang, Caiwen Ding, Yi Liang, Yao Li, Dongkuan Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.17074">AdaDiff: Accelerating Diffusion Models through Step-Wise Adaptive Computation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models achieve great success in generating diverse and high-fidelity images, yet their widespread application, especially in real-time scenarios, is hampered by their inherently slow generation speed. The slow generation stems from the necessity of multi-step network inference. While some certain predictions benefit from the full computation of the model in each sampling iteration, not every iteration requires the same amount of computation, potentially leading to inefficient computation. Unlike typical adaptive computation challenges that deal with single-step generation problems, diffusion processes with a multi-step generation need to dynamically adjust their computational resource allocation based on the ongoing assessment of each step's importance to the final image output, presenting a unique set of challenges. In this work, we propose AdaDiff, an adaptive framework that dynamically allocates computation resources in each sampling step to improve the generation efficiency of diffusion models. To assess the effects of changes in computational effort on image quality, we present a timestep-aware uncertainty estimation module (UEM). Integrated at each intermediate layer, the UEM evaluates the predictive uncertainty. This uncertainty measurement serves as an indicator for determining whether to terminate the inference process. Additionally, we introduce an uncertainty-aware layer-wise loss aimed at bridging the performance gap between full models and their adaptive counterparts.
<div id='section'>Paperid: <span id='pid'>975, <a href='https://arxiv.org/pdf/2309.11333.pdf' target='_blank'>https://arxiv.org/pdf/2309.11333.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Isak Meding, Alexander Bodin, Adam Tonderski, Joakim Johnander, Christoffer Petersson, Lennart Svensson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.11333">You can have your ensemble and run it too -- Deep Ensembles Spread Over Time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensembles of independently trained deep neural networks yield uncertainty estimates that rival Bayesian networks in performance. They also offer sizable improvements in terms of predictive performance over single models. However, deep ensembles are not commonly used in environments with limited computational budget -- such as autonomous driving -- since the complexity grows linearly with the number of ensemble members. An important observation that can be made for robotics applications, such as autonomous driving, is that data is typically sequential. For instance, when an object is to be recognized, an autonomous vehicle typically observes a sequence of images, rather than a single image. This raises the question, could the deep ensemble be spread over time?
  In this work, we propose and analyze Deep Ensembles Spread Over Time (DESOT). The idea is to apply only a single ensemble member to each data point in the sequence, and fuse the predictions over a sequence of data points. We implement and experiment with DESOT for traffic sign classification, where sequences of tracked image patches are to be classified. We find that DESOT obtains the benefits of deep ensembles, in terms of predictive and uncertainty estimation performance, while avoiding the added computational cost. Moreover, DESOT is simple to implement and does not require sequences during training. Finally, we find that DESOT, like deep ensembles, outperform single models for out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>976, <a href='https://arxiv.org/pdf/2308.13498.pdf' target='_blank'>https://arxiv.org/pdf/2308.13498.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Berry, David Meger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.13498">Efficient Epistemic Uncertainty Estimation in Regression Ensemble Models Using Pairwise-Distance Estimators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces an efficient novel approach for epistemic uncertainty estimation for ensemble models for regression tasks using pairwise-distance estimators (PaiDEs). Utilizing the pairwise-distance between model components, these estimators establish bounds on entropy. We leverage this capability to enhance the performance of Bayesian Active Learning by Disagreement (BALD). Notably, unlike sample-based Monte Carlo estimators, PaiDEs exhibit a remarkable capability to estimate epistemic uncertainty at speeds up to 100 times faster while covering a significantly larger number of inputs at once and demonstrating superior performance in higher dimensions. To validate our approach, we conducted a varied series of regression experiments on commonly used benchmarks: 1D sinusoidal data, $\textit{Pendulum}$, $\textit{Hopper}$, $\textit{Ant}$ and $\textit{Humanoid}$. For each experimental setting, an active learning framework was applied to demonstrate the advantages of PaiDEs for epistemic uncertainty estimation. We compare our approach to existing active learning methods and find that our approach outperforms on high-dimensional regression tasks.
<div id='section'>Paperid: <span id='pid'>977, <a href='https://arxiv.org/pdf/2308.13498.pdf' target='_blank'>https://arxiv.org/pdf/2308.13498.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Berry, David Meger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.13498">Efficient Epistemic Uncertainty Estimation in Regression Ensemble Models Using Pairwise-Distance Estimators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces an efficient novel approach for epistemic uncertainty estimation for ensemble models for regression tasks using pairwise-distance estimators (PaiDEs). Utilizing the pairwise-distance between model components, these estimators establish bounds on entropy. We leverage this capability to enhance the performance of Bayesian Active Learning by Disagreement (BALD). Notably, unlike sample-based Monte Carlo estimators, PaiDEs exhibit a remarkable capability to estimate epistemic uncertainty at speeds up to 100 times faster while covering a significantly larger number of inputs at once and demonstrating superior performance in higher dimensions. To validate our approach, we conducted a varied series of regression experiments on commonly used benchmarks: 1D sinusoidal data, $\textit{Pendulum}$, $\textit{Hopper}$, $\textit{Ant}$ and $\textit{Humanoid}$. For each experimental setting, an active learning framework was applied to demonstrate the advantages of PaiDEs for epistemic uncertainty estimation. We compare our approach to existing active learning methods and find that our approach outperforms on high-dimensional regression tasks.
<div id='section'>Paperid: <span id='pid'>978, <a href='https://arxiv.org/pdf/2308.11480.pdf' target='_blank'>https://arxiv.org/pdf/2308.11480.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charles Guille-Escuret, Pierre-AndrÃ© NoÃ«l, Ioannis Mitliagkas, David Vazquez, Joao Monteiro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.11480">Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Improving the reliability of deployed machine learning systems often involves developing methods to detect out-of-distribution (OOD) inputs. However, existing research often narrowly focuses on samples from classes that are absent from the training set, neglecting other types of plausible distribution shifts. This limitation reduces the applicability of these methods in real-world scenarios, where systems encounter a wide variety of anomalous inputs. In this study, we categorize five distinct types of distribution shifts and critically evaluate the performance of recent OOD detection methods on each of them. We publicly release our benchmark under the name BROAD (Benchmarking Resilience Over Anomaly Diversity). Our findings reveal that while these methods excel in detecting unknown classes, their performance is inconsistent when encountering other types of distribution shifts. In other words, they only reliably detect unexpected inputs that they have been specifically designed to expect. As a first step toward broad OOD detection, we learn a generative model of existing detection scores with a Gaussian mixture. By doing so, we present an ensemble approach that offers a more consistent and comprehensive solution for broad OOD detection, demonstrating superior performance compared to existing methods. Our code to download BROAD and reproduce our experiments is publicly available.
<div id='section'>Paperid: <span id='pid'>979, <a href='https://arxiv.org/pdf/2307.14701.pdf' target='_blank'>https://arxiv.org/pdf/2307.14701.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergio Naval Marimont, Vasilis Siomos, Giacomo Tarroni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.14701">MIM-OOD: Generative Masked Image Modelling for Out-of-Distribution Detection in Medical Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised Out-of-Distribution (OOD) detection consists in identifying anomalous regions in images leveraging only models trained on images of healthy anatomy. An established approach is to tokenize images and model the distribution of tokens with Auto-Regressive (AR) models. AR models are used to 1) identify anomalous tokens and 2) in-paint anomalous representations with in-distribution tokens. However, AR models are slow at inference time and prone to error accumulation issues which negatively affect OOD detection performance. Our novel method, MIM-OOD, overcomes both speed and error accumulation issues by replacing the AR model with two task-specific networks: 1) a transformer optimized to identify anomalous tokens and 2) a transformer optimized to in-paint anomalous tokens using masked image modelling (MIM). Our experiments with brain MRI anomalies show that MIM-OOD substantially outperforms AR models (DICE 0.458 vs 0.301) while achieving a nearly 25x speedup (9.5s vs 244s).
<div id='section'>Paperid: <span id='pid'>980, <a href='https://arxiv.org/pdf/2307.07753.pdf' target='_blank'>https://arxiv.org/pdf/2307.07753.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dominik Schnaus, Jongseok Lee, Daniel Cremers, Rudolph Triebel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.07753">Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization.
<div id='section'>Paperid: <span id='pid'>981, <a href='https://arxiv.org/pdf/2307.05772.pdf' target='_blank'>https://arxiv.org/pdf/2307.05772.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shireen Kudukkil Manchingal, Muhammad Mubashar, Kaizheng Wang, Keivan Shariatmadar, Fabio Cuzzolin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.05772">Random-Set Neural Networks (RS-NN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning is increasingly deployed in safety-critical domains where erroneous predictions may lead to potentially catastrophic consequences, highlighting the need for learning systems to be aware of how confident they are in their own predictions: in other words, 'to know when they do not know'. In this paper, we propose a novel Random-Set Neural Network (RS-NN) approach to classification which predicts belief functions (rather than classical probability vectors) over the class list using the mathematics of random sets, i.e., distributions over the collection of sets of classes. RS-NN encodes the 'epistemic' uncertainty induced by training sets that are insufficiently representative or limited in size via the size of the convex set of probability vectors associated with a predicted belief function. Our approach outperforms state-of-the-art Bayesian and Ensemble methods in terms of accuracy, uncertainty estimation and out-of-distribution (OoD) detection on multiple benchmarks (CIFAR-10 vs SVHN/Intel-Image, MNIST vs FMNIST/KMNIST, ImageNet vs ImageNet-O). RS-NN also scales up effectively to large-scale architectures (e.g. WideResNet-28-10, VGG16, Inception V3, EfficientNetB2 and ViT-Base-16), exhibits remarkable robustness to adversarial attacks and can provide statistical guarantees in a conformal learning setting.
<div id='section'>Paperid: <span id='pid'>982, <a href='https://arxiv.org/pdf/2306.14079.pdf' target='_blank'>https://arxiv.org/pdf/2306.14079.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>H. J. Terry Suh, Glen Chou, Hongkai Dai, Lujie Yang, Abhishek Gupta, Russ Tedrake
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14079">Fighting Uncertainty with Gradients: Offline Reinforcement Learning via Diffusion Score Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gradient-based methods enable efficient search capabilities in high dimensions. However, in order to apply them effectively in offline optimization paradigms such as offline Reinforcement Learning (RL) or Imitation Learning (IL), we require a more careful consideration of how uncertainty estimation interplays with first-order methods that attempt to minimize them. We study smoothed distance to data as an uncertainty metric, and claim that it has two beneficial properties: (i) it allows gradient-based methods that attempt to minimize uncertainty to drive iterates to data as smoothing is annealed, and (ii) it facilitates analysis of model bias with Lipschitz constants. As distance to data can be expensive to compute online, we consider settings where we need amortize this computation. Instead of learning the distance however, we propose to learn its gradients directly as an oracle for first-order optimizers. We show these gradients can be efficiently learned with score-matching techniques by leveraging the equivalence between distance to data and data likelihood. Using this insight, we propose Score-Guided Planning (SGP), a planning algorithm for offline RL that utilizes score-matching to enable first-order planning in high-dimensional problems, where zeroth-order methods were unable to scale, and ensembles were unable to overcome local minima. Website: https://sites.google.com/view/score-guided-planning/home
<div id='section'>Paperid: <span id='pid'>983, <a href='https://arxiv.org/pdf/2306.11316.pdf' target='_blank'>https://arxiv.org/pdf/2306.11316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siming Zheng, Xin Yuan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11316">Unfolding Framework with Prior of Convolution-Transformer Mixture and Uncertainty Estimation for Video Snapshot Compressive Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of video snapshot compressive imaging (SCI), where sequential high-speed frames are modulated by different masks and captured by a single measurement. The underlying principle of reconstructing multi-frame images from only one single measurement is to solve an ill-posed problem. By combining optimization algorithms and neural networks, deep unfolding networks (DUNs) score tremendous achievements in solving inverse problems. In this paper, our proposed model is under the DUN framework and we propose a 3D Convolution-Transformer Mixture (CTM) module with a 3D efficient and scalable attention model plugged in, which helps fully learn the correlation between temporal and spatial dimensions by virtue of Transformer. To our best knowledge, this is the first time that Transformer is employed to video SCI reconstruction. Besides, to further investigate the high-frequency information during the reconstruction process which are neglected in previous studies, we introduce variance estimation characterizing the uncertainty on a pixel-by-pixel basis. Extensive experimental results demonstrate that our proposed method achieves state-of-the-art (SOTA) (with a 1.2dB gain in PSNR over previous SOTA algorithm) results. We will release the code.
<div id='section'>Paperid: <span id='pid'>984, <a href='https://arxiv.org/pdf/2306.10843.pdf' target='_blank'>https://arxiv.org/pdf/2306.10843.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Javier Naranjo-Alcazar, Jordi Grau-Haro, David Almenar, Pedro Zuccarello
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.10843">Female mosquito detection by means of AI techniques inside release containers in the context of a Sterile Insect Technique program</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Sterile Insect Technique (SIT) is a biological pest control technique based on the release into the environment of sterile males of the insect species whose population is to be controlled. The entire SIT process involves mass-rearing within a biofactory, sorting of the specimens by sex, sterilization, and subsequent release of the sterile males into the environment. The reason for avoiding the release of female specimens is because, unlike males, females bite, with the subsequent risk of disease transmission. In the case of Aedes mosquito biofactories for SIT, the key point of the whole process is sex separation. This process is nowadays performed by a combination of mechanical devices and AI-based vision systems. However, there is still a possibility of false negatives, so a last stage of verification is necessary before releasing them into the environment. It is known that the sound produced by the flapping of adult male mosquitoes is different from that produced by females, so this feature can be used to detect the presence of females in containers prior to environmental release. This paper presents a study for the detection of females in Aedes mosquito release vessels for SIT programs. The containers used consist of PVC a tubular design of 8.8cm diameter and 12.5cm height. The containers were placed in an experimental setup that allowed the recording of the sound of mosquito flight inside of them. Each container was filled with 250 specimens considering the cases of (i) only male mosquitoes, (ii) only female mosquitoes, and (iii) 75% males and 25% females. Case (i) was used for training and testing, whereas cases (ii) and (iii) were used only for testing. Two algorithms were implemented for the detection of female mosquitoes: an unsupervised outlier detection algorithm (iForest) and a one-class SVM trained with male-only recordings.
<div id='section'>Paperid: <span id='pid'>985, <a href='https://arxiv.org/pdf/2306.07835.pdf' target='_blank'>https://arxiv.org/pdf/2306.07835.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tobias Riedlinger, Marius Schubert, Sarina Penquitt, Jan-Marcel Kezmann, Pascal Colling, Karsten Kahl, Lutz Roese-Koerner, Michael Arnold, Urs Zimmermann, Matthias Rottmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.07835">LMD: Light-weight Prediction Quality Estimation for Object Detection in Lidar Point Clouds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Object detection on Lidar point cloud data is a promising technology for autonomous driving and robotics which has seen a significant rise in performance and accuracy during recent years. Particularly uncertainty estimation is a crucial component for down-stream tasks and deep neural networks remain error-prone even for predictions with high confidence. Previously proposed methods for quantifying prediction uncertainty tend to alter the training scheme of the detector or rely on prediction sampling which results in vastly increased inference time. In order to address these two issues, we propose LidarMetaDetect (LMD), a light-weight post-processing scheme for prediction quality estimation. Our method can easily be added to any pre-trained Lidar object detector without altering anything about the base model and is purely based on post-processing, therefore, only leading to a negligible computational overhead. Our experiments show a significant increase of statistical reliability in separating true from false predictions. We propose and evaluate an additional application of our method leading to the detection of annotation errors. Explicit samples and a conservative count of annotation error proposals indicates the viability of our method for large-scale datasets like KITTI and nuScenes. On the widely-used nuScenes test dataset, 43 out of the top 100 proposals of our method indicate, in fact, erroneous annotations.
<div id='section'>Paperid: <span id='pid'>986, <a href='https://arxiv.org/pdf/2306.06221.pdf' target='_blank'>https://arxiv.org/pdf/2306.06221.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chrysoula Zerva, AndrÃ© F. T. Martins
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06221">Conformalizing Machine Translation Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Several uncertainty estimation methods have been recently proposed for machine translation evaluation. While these methods can provide a useful indication of when not to trust model predictions, we show in this paper that the majority of them tend to underestimate model uncertainty, and as a result they often produce misleading confidence intervals that do not cover the ground truth. We propose as an alternative the use of conformal prediction, a distribution-free method to obtain confidence intervals with a theoretically established guarantee on coverage. First, we demonstrate that split conformal prediction can ``correct'' the confidence intervals of previous methods to yield a desired coverage level. Then, we highlight biases in estimated confidence intervals, both in terms of the translation language pairs and the quality of translations. We apply conditional conformal prediction techniques to obtain calibration subsets for each data subgroup, leading to equalized coverage.
<div id='section'>Paperid: <span id='pid'>987, <a href='https://arxiv.org/pdf/2306.04459.pdf' target='_blank'>https://arxiv.org/pdf/2306.04459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengting Hu, Zhen Zhang, Shiwan Zhao, Minlie Huang, Bingzhe Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04459">Uncertainty in Natural Language Processing: Sources, Quantification, and Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a main field of artificial intelligence, natural language processing (NLP) has achieved remarkable success via deep neural networks. Plenty of NLP tasks have been addressed in a unified manner, with various tasks being associated with each other through sharing the same paradigm. However, neural networks are black boxes and rely on probability computation. Making mistakes is inevitable. Therefore, estimating the reliability and trustworthiness (in other words, uncertainty) of neural networks becomes a key research direction, which plays a crucial role in reducing models' risks and making better decisions. Therefore, in this survey, we provide a comprehensive review of uncertainty-relevant works in the NLP field. Considering the data and paradigms characteristics, we first categorize the sources of uncertainty in natural language into three types, including input, system, and output. Then, we systemically review uncertainty quantification approaches and the main applications. Finally, we discuss the challenges of uncertainty estimation in NLP and discuss potential future directions, taking into account recent trends in the field. Though there have been a few surveys about uncertainty estimation, our work is the first to review uncertainty from the NLP perspective.
<div id='section'>Paperid: <span id='pid'>988, <a href='https://arxiv.org/pdf/2306.02031.pdf' target='_blank'>https://arxiv.org/pdf/2306.02031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenyu Jiang, Hao Cheng, Mingcai Chen, Chongjun Wang, Hongxin Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02031">DOS: Diverse Outlier Sampling for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern neural networks are known to give overconfident prediction for out-of-distribution inputs when deployed in the open world. It is common practice to leverage a surrogate outlier dataset to regularize the model during training, and recent studies emphasize the role of uncertainty in designing the sampling strategy for outlier dataset. However, the OOD samples selected solely based on predictive uncertainty can be biased towards certain types, which may fail to capture the full outlier distribution. In this work, we empirically show that diversity is critical in sampling outliers for OOD detection performance. Motivated by the observation, we propose a straightforward and novel sampling strategy named DOS (Diverse Outlier Sampling) to select diverse and informative outliers. Specifically, we cluster the normalized features at each iteration, and the most informative outlier from each cluster is selected for model training with absent category loss. With DOS, the sampled outliers efficiently shape a globally compact decision boundary between ID and OOD data. Extensive experiments demonstrate the superiority of DOS, reducing the average FPR95 by up to 25.79% on CIFAR-100 with TI-300K.
<div id='section'>Paperid: <span id='pid'>989, <a href='https://arxiv.org/pdf/2305.16777.pdf' target='_blank'>https://arxiv.org/pdf/2305.16777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihong Huang, Yuang Zhang, Liping Wang, Xuemin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.16777">Unleashing the Potential of Unsupervised Deep Outlier Detection through Automated Training Stopping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) has received continuous research interests due to its wide applications. With the development of deep learning, increasingly deep OD algorithms are proposed. Despite the availability of numerous deep OD models, existing research has reported that the performance of deep models is extremely sensitive to the configuration of hyperparameters (HPs). However, the selection of HPs for deep OD models remains a notoriously difficult task due to the lack of any labels and long list of HPs. In our study. we shed light on an essential factor, training time, that can introduce significant variation in the performance of deep model. Even the performance is stable across other HPs, training time itself can cause a serious HP sensitivity issue. Motivated by this finding, we are dedicated to formulating a strategy to terminate model training at the optimal iteration. Specifically, we propose a novel metric called loss entropy to internally evaluate the model performance during training while an automated training stopping algorithm is devised. To our knowledge, our approach is the first to enable reliable identification of the optimal training iteration during training without requiring any labels. Our experiments on tabular, image datasets show that our approach can be applied to diverse deep models and datasets. It not only enhances the robustness of deep models to their HPs, but also improves the performance and reduces plenty of training time compared to naive training.
<div id='section'>Paperid: <span id='pid'>990, <a href='https://arxiv.org/pdf/2305.03829.pdf' target='_blank'>https://arxiv.org/pdf/2305.03829.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joshua Durso-Finley, Jean-Pierre Falet, Raghav Mehta, Douglas L. Arnold, Nick Pawlowski, Tal Arbel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.03829">Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image-based precision medicine aims to personalize treatment decisions based on an individual's unique imaging features so as to improve their clinical outcome. Machine learning frameworks that integrate uncertainty estimation as part of their treatment recommendations would be safer and more reliable. However, little work has been done in adapting uncertainty estimation techniques and validation metrics for precision medicine. In this paper, we use Bayesian deep learning for estimating the posterior distribution over factual and counterfactual outcomes on several treatments. This allows for estimating the uncertainty for each treatment option and for the individual treatment effects (ITE) between any two treatments. We train and evaluate this model to predict future new and enlarging T2 lesion counts on a large, multi-center dataset of MR brain images of patients with multiple sclerosis, exposed to several treatments during randomized controlled trials. We evaluate the correlation of the uncertainty estimate with the factual error, and, given the lack of ground truth counterfactual outcomes, demonstrate how uncertainty for the ITE prediction relates to bounds on the ITE error. Lastly, we demonstrate how knowledge of uncertainty could modify clinical decision-making to improve individual patient and clinical trial outcomes.
<div id='section'>Paperid: <span id='pid'>991, <a href='https://arxiv.org/pdf/2304.11396.pdf' target='_blank'>https://arxiv.org/pdf/2304.11396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafayel Darbinyan, Hrant Khachatrian, Rafayel Mkrtchyan, Theofanis P. Raptis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.11396">ML-based Approaches for Wireless NLOS Localization: Input Representations and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The challenging problem of non-line-of-sight (NLOS) localization is critical for many wireless networking applications. The lack of available datasets has made NLOS localization difficult to tackle with ML-driven methods, but recent developments in synthetic dataset generation have provided new opportunities for research. This paper explores three different input representations: (i) single wireless radio path features, (ii) wireless radio link features (multi-path), and (iii) image-based representations. Inspired by the two latter new representations, we design two convolutional neural networks (CNNs) and we demonstrate that, although not significantly improving the NLOS localization performance, they are able to support richer prediction outputs, thus allowing deeper analysis of the predictions. In particular, the richer outputs enable reliable identification of non-trustworthy predictions and support the prediction of the top-K candidate locations for a given instance. We also measure how the availability of various features (such as angles of signal departure and arrival) affects the model's performance, providing insights about the types of data that should be collected for enhanced NLOS localization. Our insights motivate future work on building more efficient neural architectures and input representations for improved NLOS localization performance, along with additional useful application features.
<div id='section'>Paperid: <span id='pid'>992, <a href='https://arxiv.org/pdf/2304.08058.pdf' target='_blank'>https://arxiv.org/pdf/2304.08058.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicolas Pinon, Robin Trombetta, Carole Lartizien
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.08058">One-Class SVM on siamese neural network latent space for Unsupervised Anomaly Detection on brain MRI White Matter Hyperintensities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection remains a challenging task in neuroimaging when little to no supervision is available and when lesions can be very small or with subtle contrast. Patch-based representation learning has shown powerful representation capacities when applied to industrial or medical imaging and outlier detection methods have been applied successfully to these images. In this work, we propose an unsupervised anomaly detection (UAD) method based on a latent space constructed by a siamese patch-based auto-encoder and perform the outlier detection with a One-Class SVM training paradigm tailored to the lesion detection task in multi-modality neuroimaging. We evaluate performances of this model on a public database, the White Matter Hyperintensities (WMH) challenge and show in par performance with the two best performing state-of-the-art methods reported so far.
<div id='section'>Paperid: <span id='pid'>993, <a href='https://arxiv.org/pdf/2304.06867.pdf' target='_blank'>https://arxiv.org/pdf/2304.06867.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dianhao Zhang, Mien Van, Stephen Mcllvanna, Yuzhu Sun, SeÃ¡n McLoone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06867">Adaptive Safety-critical Control with Uncertainty Estimation for Human-robot Collaboration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In advanced manufacturing, strict safety guarantees are required to allow humans and robots to work together in a shared workspace. One of the challenges in this application field is the variety and unpredictability of human behavior, leading to potential dangers for human coworkers. This paper presents a novel control framework by adopting safety-critical control and uncertainty estimation for human-robot collaboration. Additionally, to select the shortest path during collaboration, a novel quadratic penalty method is presented. The innovation of the proposed approach is that the proposed controller will prevent the robot from violating any safety constraints even in cases where humans move accidentally in a collaboration task. This is implemented by the combination of a time-varying integral barrier Lyapunov function (TVIBLF) and an adaptive exponential control barrier function (AECBF) to achieve a flexible mode switch between path tracking and collision avoidance with guaranteed closed-loop system stability. The performance of our approach is demonstrated in simulation studies on a 7-DOF robot manipulator. Additionally, a comparison between the tasks involving static and dynamic targets is provided.
<div id='section'>Paperid: <span id='pid'>994, <a href='https://arxiv.org/pdf/2303.07269.pdf' target='_blank'>https://arxiv.org/pdf/2303.07269.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoran Yu, Yin Li, Yong Jae Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07269">InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent state-of-the-art methods in imbalanced semi-supervised learning (SSL) rely on confidence-based pseudo-labeling with consistency regularization. To obtain high-quality pseudo-labels, a high confidence threshold is typically adopted. However, it has been shown that softmax-based confidence scores in deep networks can be arbitrarily high for samples far from the training data, and thus, the pseudo-labels for even high-confidence unlabeled samples may still be unreliable. In this work, we present a new perspective of pseudo-labeling for imbalanced SSL. Without relying on model confidence, we propose to measure whether an unlabeled sample is likely to be ``in-distribution''; i.e., close to the current training data. To decide whether an unlabeled sample is ``in-distribution'' or ``out-of-distribution'', we adopt the energy score from out-of-distribution detection literature. As training progresses and more unlabeled samples become in-distribution and contribute to training, the combined labeled and pseudo-labeled data can better approximate the true class distribution to improve the model. Experiments demonstrate that our energy-based pseudo-labeling method, \textbf{InPL}, albeit conceptually simple, significantly outperforms confidence-based methods on imbalanced SSL benchmarks. For example, it produces around 3\% absolute accuracy improvement on CIFAR10-LT. When combined with state-of-the-art long-tailed SSL methods, further improvements are attained. In particular, in one of the most challenging scenarios, InPL achieves a 6.9\% accuracy improvement over the best competitor.
<div id='section'>Paperid: <span id='pid'>995, <a href='https://arxiv.org/pdf/2303.05828.pdf' target='_blank'>https://arxiv.org/pdf/2303.05828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikolas Adaloglou, Felix Michels, Tim Kaiser, Markus Kollmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.05828">Adapting Contrastive Language-Image Pretrained (CLIP) Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a comprehensive experimental study on pretrained feature extractors for visual out-of-distribution (OOD) detection, focusing on adapting contrastive language-image pretrained (CLIP) models. Without fine-tuning on the training data, we are able to establish a positive correlation ($R^2\geq0.92$) between in-distribution classification and unsupervised OOD detection for CLIP models in $4$ benchmarks. We further propose a new simple and scalable method called \textit{pseudo-label probing} (PLP) that adapts vision-language models for OOD detection. Given a set of label names of the training set, PLP trains a linear layer using the pseudo-labels derived from the text encoder of CLIP. To test the OOD detection robustness of pretrained models, we develop a novel feature-based adversarial OOD data manipulation approach to create adversarial samples. Intriguingly, we show that (i) PLP outperforms the previous state-of-the-art \citep{ming2022mcm} on all $5$ large-scale benchmarks based on ImageNet, specifically by an average AUROC gain of 3.4\% using the largest CLIP model (ViT-G), (ii) we show that linear probing outperforms fine-tuning by large margins for CLIP architectures (i.e. CLIP ViT-H achieves a mean gain of 7.3\% AUROC on average on all ImageNet-based benchmarks), and (iii) billion-parameter CLIP models still fail at detecting adversarially manipulated OOD images. The code and adversarially created datasets will be made publicly available.
<div id='section'>Paperid: <span id='pid'>996, <a href='https://arxiv.org/pdf/2303.02444.pdf' target='_blank'>https://arxiv.org/pdf/2303.02444.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenlong Chen, Yingzhen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02444">Calibrating Transformers via Sparse Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformer models have achieved profound success in prediction tasks in a wide range of applications in natural language processing, speech recognition and computer vision. Extending Transformer's success to safety-critical domains requires calibrated uncertainty estimation which remains under-explored. To address this, we propose Sparse Gaussian Process attention (SGPA), which performs Bayesian inference directly in the output space of multi-head attention blocks (MHAs) in transformer to calibrate its uncertainty. It replaces the scaled dot-product operation with a valid symmetric kernel and uses sparse Gaussian processes (SGP) techniques to approximate the posterior processes of MHA outputs. Empirically, on a suite of prediction tasks on text, images and graphs, SGPA-based Transformers achieve competitive predictive accuracy, while noticeably improving both in-distribution calibration and out-of-distribution robustness and detection.
<div id='section'>Paperid: <span id='pid'>997, <a href='https://arxiv.org/pdf/2302.11349.pdf' target='_blank'>https://arxiv.org/pdf/2302.11349.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sangnie Bhardwaj, Willie McClinton, Tongzhou Wang, Guillaume Lajoie, Chen Sun, Phillip Isola, Dilip Krishnan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11349">Steerable Equivariant Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained deep image representations are useful for post-training tasks such as classification through transfer learning, image retrieval, and object detection. Data augmentations are a crucial aspect of pre-training robust representations in both supervised and self-supervised settings. Data augmentations explicitly or implicitly promote invariance in the embedding space to the input image transformations. This invariance reduces generalization to those downstream tasks which rely on sensitivity to these particular data augmentations. In this paper, we propose a method of learning representations that are instead equivariant to data augmentations. We achieve this equivariance through the use of steerable representations. Our representations can be manipulated directly in embedding space via learned linear maps. We demonstrate that our resulting steerable and equivariant representations lead to better performance on transfer learning and robustness: e.g. we improve linear probe top-1 accuracy by between 1% to 3% for transfer; and ImageNet-C accuracy by upto 3.4%. We further show that the steerability of our representations provides significant speedup (nearly 50x) for test-time augmentations; by applying a large number of augmentations for out-of-distribution detection, we significantly improve OOD AUC on the ImageNet-C dataset over an invariant representation.
<div id='section'>Paperid: <span id='pid'>998, <a href='https://arxiv.org/pdf/2302.10303.pdf' target='_blank'>https://arxiv.org/pdf/2302.10303.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Romain Xu-Darme, Julien Girard-Satabin, Darryl Hond, Gabriele Incorvaia, Zakaria Chihani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10303">Interpretable Out-Of-Distribution Detection Using Pattern Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OoD) detection for data-based programs is a goal of paramount importance. Common approaches in the literature tend to train detectors requiring inside-of-distribution (in-distribution, or IoD) and OoD validation samples, and/or implement confidence metrics that are often abstract and therefore difficult to interpret. In this work, we propose to use existing work from the field of explainable AI, namely the PARTICUL pattern identification algorithm, in order to build more interpretable and robust OoD detectors for visual classifiers. Crucially, this approach does not require to retrain the classifier and is tuned directly to the IoD dataset, making it applicable to domains where OoD does not have a clear definition. Moreover, pattern identification allows us to provide images from the IoD dataset as reference points to better explain the confidence scores. We demonstrates that the detection capabilities of this approach are on par with existing methods through an extensive benchmark across four datasets and two definitions of OoD. In particular, we introduce a new benchmark based on perturbations of the IoD dataset which provides a known and quantifiable evaluation of the discrepancy between the IoD and OoD datasets that serves as a reference value for the comparison between various OoD detection methods. Our experiments show that the robustness of all metrics under test does not solely depend on the nature of the IoD dataset or the OoD definition, but also on the architecture of the classifier, which stresses the need for thorough experimentations for future work on OoD detection.
<div id='section'>Paperid: <span id='pid'>999, <a href='https://arxiv.org/pdf/2302.09664.pdf' target='_blank'>https://arxiv.org/pdf/2302.09664.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lorenz Kuhn, Yarin Gal, Sebastian Farquhar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.09664">Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of "semantic equivalence" -- different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy -- an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.
<div id='section'>Paperid: <span id='pid'>1000, <a href='https://arxiv.org/pdf/2302.01312.pdf' target='_blank'>https://arxiv.org/pdf/2302.01312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Berry, David Meger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.01312">Normalizing Flow Ensembles for Rich Aleatoric and Epistemic Uncertainty Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we demonstrate how to reliably estimate epistemic uncertainty while maintaining the flexibility needed to capture complicated aleatoric distributions. To this end, we propose an ensemble of Normalizing Flows (NF), which are state-of-the-art in modeling aleatoric uncertainty. The ensembles are created via sets of fixed dropout masks, making them less expensive than creating separate NF models. We demonstrate how to leverage the unique structure of NFs, base distributions, to estimate aleatoric uncertainty without relying on samples, provide a comprehensive set of baselines, and derive unbiased estimates for differential entropy. The methods were applied to a variety of experiments, commonly used to benchmark aleatoric and epistemic uncertainty estimation: 1D sinusoidal data, 2D windy grid-world ($\it{Wet Chicken}$), $\it{Pendulum}$, and $\it{Hopper}$. In these experiments, we setup an active learning framework and evaluate each model's capability at measuring aleatoric and epistemic uncertainty. The results show the advantages of using NF ensembles in capturing complicated aleatoric while maintaining accurate epistemic uncertainty estimates.
<div id='section'>Paperid: <span id='pid'>1001, <a href='https://arxiv.org/pdf/2301.10454.pdf' target='_blank'>https://arxiv.org/pdf/2301.10454.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Azizmalayeri, Arman Zarei, Alireza Isavand, Mohammad Taghi Manzuri, Mohammad Hossein Rohban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.10454">A Data-Centric Approach for Improving Adversarial Training Through the Lens of Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current machine learning models achieve super-human performance in many real-world applications. Still, they are susceptible against imperceptible adversarial perturbations. The most effective solution for this problem is adversarial training that trains the model with adversarially perturbed samples instead of original ones. Various methods have been developed over recent years to improve adversarial training such as data augmentation or modifying training attacks. In this work, we examine the same problem from a new data-centric perspective. For this purpose, we first demonstrate that the existing model-based methods can be equivalent to applying smaller perturbation or optimization weights to the hard training examples. By using this finding, we propose detecting and removing these hard samples directly from the training procedure rather than applying complicated algorithms to mitigate their effects. For detection, we use maximum softmax probability as an effective method in out-of-distribution detection since we can consider the hard samples as the out-of-distribution samples for the whole data distribution. Our results on SVHN and CIFAR-10 datasets show the effectiveness of this method in improving the adversarial training without adding too much computational cost.
<div id='section'>Paperid: <span id='pid'>1002, <a href='https://arxiv.org/pdf/2301.08390.pdf' target='_blank'>https://arxiv.org/pdf/2301.08390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Malik Boudiaf, Etienne Bennequin, Myriam Tami, Antoine Toubhans, Pablo Piantanida, CÃ©line Hudelot, Ismail Ben Ayed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.08390">Open-Set Likelihood Maximization for Few-Shot Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We tackle the Few-Shot Open-Set Recognition (FSOSR) problem, i.e. classifying instances among a set of classes for which we only have a few labeled samples, while simultaneously detecting instances that do not belong to any known class. We explore the popular transductive setting, which leverages the unlabelled query instances at inference. Motivated by the observation that existing transductive methods perform poorly in open-set scenarios, we propose a generalization of the maximum likelihood principle, in which latent scores down-weighing the influence of potential outliers are introduced alongside the usual parametric model. Our formulation embeds supervision constraints from the support set and additional penalties discouraging overconfident predictions on the query set. We proceed with a block-coordinate descent, with the latent scores and parametric model co-optimized alternately, thereby benefiting from each other. We call our resulting formulation \textit{Open-Set Likelihood Optimization} (OSLO). OSLO is interpretable and fully modular; it can be applied on top of any pre-trained model seamlessly. Through extensive experiments, we show that our method surpasses existing inductive and transductive methods on both aspects of open-set recognition, namely inlier classification and outlier detection.
<div id='section'>Paperid: <span id='pid'>1003, <a href='https://arxiv.org/pdf/2301.01837.pdf' target='_blank'>https://arxiv.org/pdf/2301.01837.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erman Acar, Andrea De Domenico, Krishna Manoorkar, Mattia Panettiere
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.01837">A Meta-Learning Algorithm for Interrogative Agendas</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explainability is a key challenge and a major research theme in AI research for developing intelligent systems that are capable of working with humans more effectively. An obvious choice in developing explainable intelligent systems relies on employing knowledge representation formalisms which are inherently tailored towards expressing human knowledge e.g., interrogative agendas. In the scope of this work, we focus on formal concept analysis (FCA), a standard knowledge representation formalism, to express interrogative agendas, and in particular to categorize objects w.r.t. a given set of features. Several FCA-based algorithms have already been in use for standard machine learning tasks such as classification and outlier detection. These algorithms use a single concept lattice for such a task, meaning that the set of features used for the categorization is fixed. Different sets of features may have different importance in that categorization, we call a set of features an agenda. In many applications a correct or good agenda for categorization is not known beforehand. In this paper, we propose a meta-learning algorithm to construct a good interrogative agenda explaining the data. Such algorithm is meant to call existing FCA-based classification and outlier detection algorithms iteratively, to increase their accuracy and reduce their sample complexity. The proposed method assigns a measure of importance to different set of features used in the categorization, hence making the results more explainable.
<div id='section'>Paperid: <span id='pid'>1004, <a href='https://arxiv.org/pdf/2210.12941.pdf' target='_blank'>https://arxiv.org/pdf/2210.12941.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihong Huang, Liping Wang, Fan Zhang, Xuemin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.12941">Unsupervised Graph Outlier Detection: Problem Revisit, New Insight, and Superior Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A large number of studies on Graph Outlier Detection (GOD) have emerged in recent years due to its wide applications, in which Unsupervised Node Outlier Detection (UNOD) on attributed networks is an important area. UNOD focuses on detecting two kinds of typical outliers in graphs: the structural outlier and the contextual outlier. Most existing works conduct experiments based on datasets with injected outliers. However, we find that the most widely-used outlier injection approach has a serious data leakage issue. By only utilizing such data leakage, a simple approach can achieve state-of-the-art performance in detecting outliers. In addition, we observe that existing algorithms have a performance drop with the mitigated data leakage issue. The other major issue is on balanced detection performance between the two types of outliers, which has not been considered by existing studies. In this paper, we analyze the cause of the data leakage issue in depth since the injection approach is a building block to advance UNOD. Moreover, we devise a novel variance-based model to detect structural outliers, which outperforms existing algorithms significantly and is more robust at kinds of injection settings. On top of this, we propose a new framework, Variance based Graph Outlier Detection (VGOD), which combines our variance-based model and attribute reconstruction model to detect outliers in a balanced way. Finally, we conduct extensive experiments to demonstrate the effectiveness and efficiency of VGOD. The results on 5 real-world datasets validate that VGOD achieves not only the best performance in detecting outliers but also a balanced detection performance between structural and contextual outliers.
<div id='section'>Paperid: <span id='pid'>1005, <a href='https://arxiv.org/pdf/2210.12256.pdf' target='_blank'>https://arxiv.org/pdf/2210.12256.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian G. Gruber, Florian Buettner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.12256">Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliably estimating the uncertainty of a prediction throughout the model lifecycle is crucial in many safety-critical applications. The most common way to measure this uncertainty is via the predicted confidence. While this tends to work well for in-domain samples, these estimates are unreliable under domain drift and restricted to classification. Alternatively, proper scores can be used for most predictive tasks but a bias-variance decomposition for model uncertainty does not exist in the current literature. In this work we introduce a general bias-variance decomposition for proper scores, giving rise to the Bregman Information as the variance term. We discover how exponential families and the classification log-likelihood are special cases and provide novel formulations. Surprisingly, we can express the classification case purely in the logit space. We showcase the practical relevance of this decomposition on several downstream tasks, including model ensembles and confidence regions. Further, we demonstrate how different approximations of the instance-level Bregman Information allow reliable out-of-distribution detection for all degrees of domain drift.
<div id='section'>Paperid: <span id='pid'>1006, <a href='https://arxiv.org/pdf/2207.04994.pdf' target='_blank'>https://arxiv.org/pdf/2207.04994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hengrui Zhang, Wei Wayne Chen, Akshay Iyer, Daniel W. Apley, Wei Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.04994">Uncertainty-Aware Mixed-Variable Machine Learning for Materials Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven design shows the promise of accelerating materials discovery but is challenging due to the prohibitive cost of searching the vast design space of chemistry, structure, and synthesis methods. Bayesian Optimization (BO) employs uncertainty-aware machine learning models to select promising designs to evaluate, hence reducing the cost. However, BO with mixed numerical and categorical variables, which is of particular interest in materials design, has not been well studied. In this work, we survey frequentist and Bayesian approaches to uncertainty quantification of machine learning with mixed variables. We then conduct a systematic comparative study of their performances in BO using a popular representative model from each group, the random forest-based Lolo model (frequentist) and the latent variable Gaussian process model (Bayesian). We examine the efficacy of the two models in the optimization of mathematical functions, as well as properties of structural and functional materials, where we observe performance differences as related to problem dimensionality and complexity. By investigating the machine learning models' predictive and uncertainty estimation capabilities, we provide interpretations of the observed performance differences. Our results provide practical guidance on choosing between frequentist and Bayesian uncertainty-aware machine learning models for mixed-variable BO in materials design.
<div id='section'>Paperid: <span id='pid'>1007, <a href='https://arxiv.org/pdf/2206.07459.pdf' target='_blank'>https://arxiv.org/pdf/2206.07459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenyu Jiang, Yuxin Ge, Hao Cheng, Mingcai Chen, Shuai Feng, Chongjun Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.07459">READ: Aggregating Reconstruction Error into Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is crucial to the safe deployment of a classifier in the real world. However, deep neural networks are known to be overconfident for abnormal data. Existing works directly design score function by mining the inconsistency from classifier for in-distribution (ID) and OOD. In this paper, we further complement this inconsistency with reconstruction error, based on the assumption that an autoencoder trained on ID data can not reconstruct OOD as well as ID. We propose a novel method, READ (Reconstruction Error Aggregated Detector), to unify inconsistencies from classifier and autoencoder. Specifically, the reconstruction error of raw pixels is transformed to latent space of classifier. We show that the transformed reconstruction error bridges the semantic gap and inherits detection performance from the original. Moreover, we propose an adjustment strategy to alleviate the overconfidence problem of autoencoder according to a fine-grained characterization of OOD data. Under two scenarios of pre-training and retraining, we respectively present two variants of our method, namely READ-MD (Mahalanobis Distance) only based on pre-trained classifier and READ-ED (Euclidean Distance) which retrains the classifier. Our methods do not require access to test time OOD data for fine-tuning hyperparameters. Finally, we demonstrate the effectiveness of the proposed methods through extensive comparisons with state-of-the-art OOD detection algorithms. On a CIFAR-10 pre-trained WideResNet, our method reduces the average FPR@95TPR by up to 9.8% compared with previous state-of-the-art.
<div id='section'>Paperid: <span id='pid'>1008, <a href='https://arxiv.org/pdf/2203.13716.pdf' target='_blank'>https://arxiv.org/pdf/2203.13716.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Zaigham Zaheer, Jin Ha Lee, Arif Mahmood, Marcella Astrid, Seung-Ik Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.13716">Stabilizing Adversarially Learned One-Class Novelty Detection Using Pseudo Anomalies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, anomaly scores have been formulated using reconstruction loss of the adversarially learned generators and/or classification loss of discriminators. Unavailability of anomaly examples in the training data makes optimization of such networks challenging. Attributed to the adversarial training, performance of such models fluctuates drastically with each training step, making it difficult to halt the training at an optimal point. In the current study, we propose a robust anomaly detection framework that overcomes such instability by transforming the fundamental role of the discriminator from identifying real vs. fake data to distinguishing good vs. bad quality reconstructions. For this purpose, we propose a method that utilizes the current state as well as an old state of the same generator to create good and bad quality reconstruction examples. The discriminator is trained on these examples to detect the subtle distortions that are often present in the reconstructions of anomalous data. In addition, we propose an efficient generic criterion to stop the training of our model, ensuring elevated performance. Extensive experiments performed on six datasets across multiple domains including image and video based anomaly detection, medical diagnosis, and network security, have demonstrated excellent performance of our approach.
<div id='section'>Paperid: <span id='pid'>1009, <a href='https://arxiv.org/pdf/2112.12833.pdf' target='_blank'>https://arxiv.org/pdf/2112.12833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matej GrciÄ, Petra BevandiÄ, Zoran KalafatiÄ, SiniÅ¡a Å egviÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.12833">Dense Out-of-Distribution Detection by Robust Learning on Synthetic Negative Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard machine learning is unable to accommodate inputs which do not belong to the training distribution. The resulting models often give rise to confident incorrect predictions which may lead to devastating consequences. This problem is especially demanding in the context of dense prediction since input images may be only partially anomalous. Previous work has addressed dense out-of-distribution detection by discriminative training with respect to off-the-shelf negative datasets. However, real negative data are unlikely to cover all modes of the entire visual world. To this end, we extend this approach by generating synthetic negative patches along the border of the inlier manifold. We leverage a jointly trained normalizing flow due to coverage-oriented learning objective and the capability to generate samples at different resolutions. We detect anomalies according to a principled information-theoretic criterion which can be consistently applied through training and inference. The resulting models set the new state of the art on benchmarks for out-of-distribution detection in road-driving scenes and remote sensing imagery, in spite of minimal computational overhead.
<div id='section'>Paperid: <span id='pid'>1010, <a href='https://arxiv.org/pdf/2106.08670.pdf' target='_blank'>https://arxiv.org/pdf/2106.08670.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vimukthini Pinto, Cheng Xue, Chathura Nagoda Gamage, Matthew Stephenson, Jochen Renz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2106.08670">The Difficulty of Novelty Detection in Open-World Physical Domains: An Application to Angry Birds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting and responding to novel situations in open-world environments is a key capability of human cognition and is a persistent problem for AI systems. In an open-world, novelties can appear in many different forms and may be easy or hard to detect. Therefore, to accurately evaluate the novelty detection capability of AI systems, it is necessary to investigate how difficult it may be to detect different types of novelty. In this paper, we propose a qualitative physics-based method to quantify the difficulty of novelty detection focusing on open-world physical domains. We apply our method in the popular physics simulation game Angry Birds, and conduct a user study across different novelties to validate our method. Results indicate that our calculated detection difficulties are in line with those of human users.
<div id='section'>Paperid: <span id='pid'>1011, <a href='https://arxiv.org/pdf/2103.03943.pdf' target='_blank'>https://arxiv.org/pdf/2103.03943.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linara Adilova, Siming Chen, Michael Kamp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2103.03943">Novelty Detection in Sequential Data by Informed Clustering and Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Novelty detection in discrete sequences is a challenging task, since deviations from the process generating the normal data are often small or intentionally hidden. Novelties can be detected by modeling normal sequences and measuring the deviations of a new sequence from the model predictions. However, in many applications data is generated by several distinct processes so that models trained on all the data tend to over-generalize and novelties remain undetected. We propose to approach this challenge through decomposition: by clustering the data we break down the problem, obtaining simpler modeling task in each cluster which can be modeled more accurately. However, this comes at a trade-off, since the amount of training data per cluster is reduced. This is a particular problem for discrete sequences where state-of-the-art models are data-hungry. The success of this approach thus depends on the quality of the clustering, i.e., whether the individual learning problems are sufficiently simpler than the joint problem. While clustering discrete sequences automatically is a challenging and domain-specific task, it is often easy for human domain experts, given the right tools. In this paper, we adapt a state-of-the-art visual analytics tool for discrete sequence clustering to obtain informed clusters from domain experts and use LSTMs to model each cluster individually. Our extensive empirical evaluation indicates that this informed clustering outperforms automatic ones and that our approach outperforms state-of-the-art novelty detection methods for discrete sequences in three real-world application scenarios. In particular, decomposition outperforms a global model despite less training data on each individual cluster.
<div id='section'>Paperid: <span id='pid'>1012, <a href='https://arxiv.org/pdf/2002.03328.pdf' target='_blank'>https://arxiv.org/pdf/2002.03328.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufeng Zhang, Jialu Pan, Wanwei Liu, Zhenbang Chen, Ji Wang, Zhiming Liu, Kenli Li, Hongmei Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2002.03328">Kullback-Leibler Divergence-Based Out-of-Distribution Detection with Flow-Based Generative Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent research has revealed that deep generative models including flow-based models and Variational Autoencoders may assign higher likelihoods to out-of-distribution (OOD) data than in-distribution (ID) data. However, we cannot sample OOD data from the model. This counterintuitive phenomenon has not been satisfactorily explained and brings obstacles to OOD detection with flow-based models. In this paper, we prove theorems to investigate the Kullback-Leibler divergence in flow-based model and give two explanations for the above phenomenon. Based on our theoretical analysis, we propose a new method \PADmethod\ to leverage KL divergence and local pixel dependence of representations to perform anomaly detection. Experimental results on prevalent benchmarks demonstrate the effectiveness and robustness of our method. For group anomaly detection, our method achieves 98.1\% AUROC on average with a small batch size of 5. On the contrary, the baseline typicality test-based method only achieves 64.6\% AUROC on average due to its failure on challenging problems. Our method also outperforms the state-of-the-art method by 9.1\% AUROC. For point-wise anomaly detection, our method achieves 90.7\% AUROC on average and outperforms the baseline by 5.2\% AUROC. Besides, our method has the least notable failures and is the most robust one.
<div id='section'>Paperid: <span id='pid'>1013, <a href='https://arxiv.org/pdf/2510.00524.pdf' target='_blank'>https://arxiv.org/pdf/2510.00524.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Baoshan Song, Penggao Yan, Xiao Xia, Yihan Zhong, Weisong Wen, Li-Ta Hsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00524">Two stage GNSS outlier detection for factor graph optimization based GNSS-RTK/INS/odometer fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable GNSS positioning in complex environments remains a critical challenge due to non-line-of-sight (NLOS) propagation, multipath effects, and frequent signal blockages. These effects can easily introduce large outliers into the raw pseudo-range measurements, which significantly degrade the performance of global navigation satellite system (GNSS) real-time kinematic (RTK) positioning and limit the effectiveness of tightly coupled GNSS-based integrated navigation system. To address this issue, we propose a two-stage outlier detection method and apply the method in a tightly coupled GNSS-RTK, inertial navigation system (INS), and odometer integration based on factor graph optimization (FGO). In the first stage, Doppler measurements are employed to detect pseudo-range outliers in a GNSS-only manner, since Doppler is less sensitive to multipath and NLOS effects compared with pseudo-range, making it a more stable reference for detecting sudden inconsistencies. In the second stage, pre-integrated inertial measurement units (IMU) and odometer constraints are used to generate predicted double-difference pseudo-range measurements, which enable a more refined identification and rejection of remaining outliers. By combining these two complementary stages, the system achieves improved robustness against both gross pseudo-range errors and degraded satellite measuring quality. The experimental results demonstrate that the two-stage detection framework significantly reduces the impact of pseudo-range outliers, and leads to improved positioning accuracy and consistency compared with representative baseline approaches. In the deep urban canyon test, the outlier mitigation method has limits the RMSE of GNSS-RTK/INS/odometer fusion from 0.52 m to 0.30 m, with 42.3% improvement.
<div id='section'>Paperid: <span id='pid'>1014, <a href='https://arxiv.org/pdf/2509.17445.pdf' target='_blank'>https://arxiv.org/pdf/2509.17445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaodong Tong, Qi Zhang, Lei Jiang, Yanbing Liu, Nannan Sun, Wei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17445">Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable question answering with large language models (LLMs) is challenged by hallucinations, fluent but factually incorrect outputs arising from epistemic uncertainty. Existing entropy-based semantic-level uncertainty estimation methods are limited by sampling noise and unstable clustering of variable-length answers. We propose Semantic Reformulation Entropy (SRE), which improves uncertainty estimation in two ways. First, input-side semantic reformulations produce faithful paraphrases, expand the estimation space, and reduce biases from superficial decoder tendencies. Second, progressive, energy-based hybrid clustering stabilizes semantic grouping. Experiments on SQuAD and TriviaQA show that SRE outperforms strong baselines, providing more robust and generalizable hallucination detection. These results demonstrate that combining input diversification with multi-signal clustering substantially enhances semantic-level uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1015, <a href='https://arxiv.org/pdf/2509.17445.pdf' target='_blank'>https://arxiv.org/pdf/2509.17445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaodong Tong, Qi Zhang, Lei Jiang, Yanbing Liu, Nannan Sun, Wei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17445">Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable question answering with large language models (LLMs) is challenged by hallucinations, fluent but factually incorrect outputs arising from epistemic uncertainty. Existing entropy-based semantic-level uncertainty estimation methods are limited by sampling noise and unstable clustering of variable-length answers. We propose Semantic Reformulation Entropy (SRE), which improves uncertainty estimation in two ways. First, input-side semantic reformulations produce faithful paraphrases, expand the estimation space, and reduce biases from superficial decoder tendencies. Second, progressive, energy-based hybrid clustering stabilizes semantic grouping. Experiments on SQuAD and TriviaQA show that SRE outperforms strong baselines, providing more robust and generalizable hallucination detection. These results demonstrate that combining input diversification with multi-signal clustering substantially enhances semantic-level uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1016, <a href='https://arxiv.org/pdf/2509.17153.pdf' target='_blank'>https://arxiv.org/pdf/2509.17153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moule Lin, Andrea Patane, Weipeng Jing, Shuhao Guan, Goetz Botterweck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17153">Flow-Induced Diagonal Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Flow-Induced Diagonal Gaussian Processes (FiD-GP), a compression framework that incorporates a compact inducing weight matrix to project a neural network's weight uncertainty into a lower-dimensional subspace. Critically, FiD-GP relies on normalising-flow priors and spectral regularisations to augment its expressiveness and align the inducing subspace with feature-gradient geometry through a numerically stable projection mechanism objective. Furthermore, we demonstrate how the prediction framework in FiD-GP can help to design a single-pass projection for Out-of-Distribution (OoD) detection. Our analysis shows that FiD-GP improves uncertainty estimation ability on various tasks compared with SVGP-based baselines, satisfies tight spectral residual bounds with theoretically guaranteed OoD detection, and significantly compresses the neural network's storage requirements at the cost of increased inference computation dependent on the number of inducing weights employed. Specifically, in a comprehensive empirical study spanning regression, image classification, semantic segmentation, and out-of-distribution detection benchmarks, it cuts Bayesian training cost by several orders of magnitude, compresses parameters by roughly 51%, reduces model size by about 75%, and matches state-of-the-art accuracy and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1017, <a href='https://arxiv.org/pdf/2509.17153.pdf' target='_blank'>https://arxiv.org/pdf/2509.17153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moule Lin, Andrea Patane, Weipeng Jing, Shuhao Guan, Goetz Botterweck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17153">Flow-Induced Diagonal Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Flow-Induced Diagonal Gaussian Processes (FiD-GP), a compression framework that incorporates a compact inducing weight matrix to project a neural network's weight uncertainty into a lower-dimensional subspace. Critically, FiD-GP relies on normalising-flow priors and spectral regularisations to augment its expressiveness and align the inducing subspace with feature-gradient geometry through a numerically stable projection mechanism objective. Furthermore, we demonstrate how the prediction framework in FiD-GP can help to design a single-pass projection for Out-of-Distribution (OoD) detection. Our analysis shows that FiD-GP improves uncertainty estimation ability on various tasks compared with SVGP-based baselines, satisfies tight spectral residual bounds with theoretically guaranteed OoD detection, and significantly compresses the neural network's storage requirements at the cost of increased inference computation dependent on the number of inducing weights employed. Specifically, in a comprehensive empirical study spanning regression, image classification, semantic segmentation, and out-of-distribution detection benchmarks, it cuts Bayesian training cost by several orders of magnitude, compresses parameters by roughly 51%, reduces model size by about 75%, and matches state-of-the-art accuracy and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1018, <a href='https://arxiv.org/pdf/2509.15141.pdf' target='_blank'>https://arxiv.org/pdf/2509.15141.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yigit E. Yildirim, Samet Demir, Zafer Dogan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15141">Benefits of Online Tilted Empirical Risk Minimization: A Case Study of Outlier Detection and Robust Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Empirical Risk Minimization (ERM) is a foundational framework for supervised learning but primarily optimizes average-case performance, often neglecting fairness and robustness considerations. Tilted Empirical Risk Minimization (TERM) extends ERM by introducing an exponential tilt hyperparameter $t$ to balance average-case accuracy with worst-case fairness and robustness. However, in online or streaming settings where data arrive one sample at a time, the classical TERM objective degenerates to standard ERM, losing tilt sensitivity. We address this limitation by proposing an online TERM formulation that removes the logarithm from the classical objective, preserving tilt effects without additional computational or memory overhead. This formulation enables a continuous trade-off controlled by $t$, smoothly interpolating between ERM ($t \to 0$), fairness emphasis ($t > 0$), and robustness to outliers ($t < 0$). We empirically validate online TERM on two representative streaming tasks: robust linear regression with adversarial outliers and minority-class detection in binary classification. Our results demonstrate that negative tilting effectively suppresses outlier influence, while positive tilting improves recall with minimal impact on precision, all at per-sample computational cost equivalent to ERM. Online TERM thus recovers the full robustness-fairness spectrum of classical TERM in an efficient single-sample learning regime.
<div id='section'>Paperid: <span id='pid'>1019, <a href='https://arxiv.org/pdf/2509.02273.pdf' target='_blank'>https://arxiv.org/pdf/2509.02273.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingrui Ji, Jiansheng Chen, Jingbo Chen, Anzhi Yue, Chenhao Wang, Kai Li, Yao Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02273">RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection represents a critical challenge in remote sensing applications, where reliable identification of novel or anomalous patterns is essential for autonomous monitoring, disaster response, and environmental assessment. Despite remarkable progress in OOD detection for natural images, existing methods and benchmarks remain poorly suited to remote sensing imagery due to data scarcity, complex multi-scale scene structures, and pronounced distribution shifts. To this end, we propose RS-OOD, a novel framework that leverages remote sensing-specific vision-language modeling to enable robust few-shot OOD detection. Our approach introduces three key innovations: spatial feature enhancement that improved scene discrimination, a dual-prompt alignment mechanism that cross-verifies scene context against fine-grained semantics for spatial-semantic consistency, and a confidence-guided self-training loop that dynamically mines pseudo-labels to expand training data without manual annotation. RS-OOD consistently outperforms existing methods across multiple remote sensing benchmarks and enables efficient adaptation with minimal labeled data, demonstrating the critical value of spatial-semantic integration.
<div id='section'>Paperid: <span id='pid'>1020, <a href='https://arxiv.org/pdf/2508.13099.pdf' target='_blank'>https://arxiv.org/pdf/2508.13099.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingyu Kim, Daniel Stilwell, Jorge Jimenez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13099">Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a framework for classifying and detecting spatial commission outliers in maritime environments using seabed acoustic sensor networks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as a mixture of normal and outlier processes, we estimate the probability that a newly observed event is an outlier. We propose a second-order approximation of this probability that incorporates both the mean and variance of the normal intensity function, providing improved classification accuracy compared to mean-only approaches. We analytically show that our method yields a tighter bound to the true probability using Jensen's inequality. To enhance detection, we integrate a real-time, near-optimal sensor placement strategy that dynamically adjusts sensor locations based on the evolving outlier intensity. The proposed framework is validated using real ship traffic data near Norfolk, Virginia, where numerical results demonstrate the effectiveness of our approach in improving both classification performance and outlier detection through sensor deployment.
<div id='section'>Paperid: <span id='pid'>1021, <a href='https://arxiv.org/pdf/2508.06452.pdf' target='_blank'>https://arxiv.org/pdf/2508.06452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mattia Litrico, Mario Valerio Giuffrida, Sebastiano Battiato, Devis Tuia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06452">TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent unsupervised domain adaptation (UDA) methods have shown great success in addressing classical domain shifts (e.g., synthetic-to-real), but they still suffer under complex shifts (e.g. geographical shift), where both the background and object appearances differ significantly across domains. Prior works showed that the language modality can help in the adaptation process, exhibiting more robustness to such complex shifts. In this paper, we introduce TRUST, a novel UDA approach that exploits the robustness of the language modality to guide the adaptation of a vision model. TRUST generates pseudo-labels for target samples from their captions and introduces a novel uncertainty estimation strategy that uses normalised CLIP similarity scores to estimate the uncertainty of the generated pseudo-labels. Such estimated uncertainty is then used to reweight the classification loss, mitigating the adverse effects of wrong pseudo-labels obtained from low-quality captions. To further increase the robustness of the vision model, we propose a multimodal soft-contrastive learning loss that aligns the vision and language feature spaces, by leveraging captions to guide the contrastive training of the vision model on target images. In our contrastive loss, each pair of images acts as both a positive and a negative pair and their feature representations are attracted and repulsed with a strength proportional to the similarity of their captions. This solution avoids the need for hardly determining positive and negative pairs, which is critical in the UDA setting. Our approach outperforms previous methods, setting the new state-of-the-art on classical (DomainNet) and complex (GeoNet) domain shifts. The code will be available upon acceptance.
<div id='section'>Paperid: <span id='pid'>1022, <a href='https://arxiv.org/pdf/2507.11960.pdf' target='_blank'>https://arxiv.org/pdf/2507.11960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyein Hong, Sangbong Yoo, SeokHwan Choi, Jisue Kim, Seongbum Seo, Haneol Cho, Chansoo Kim, Yun Jang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11960">d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Approaches to enhancing data quality (DQ) are classified into two main categories: data- and process-driven. However, prior research has predominantly utilized batch data preprocessing within the data-driven framework, which often proves insufficient for optimizing machine learning (ML) model performance and frequently leads to distortions in data characteristics. Existing studies have primarily focused on data preprocessing rather than genuine data quality improvement (DQI). In this paper, we introduce d-DQIVAR, a novel visual analytics system designed to facilitate DQI strategies aimed at improving ML model performance. Our system integrates visual analytics techniques that leverage both data-driven and process-driven approaches. Data-driven techniques tackle DQ issues such as imputation, outlier detection, deletion, format standardization, removal of duplicate records, and feature selection. Process-driven strategies encompass evaluating DQ and DQI procedures by considering DQ dimensions and ML model performance and applying the Kolmogorov-Smirnov test. We illustrate how our system empowers users to harness expert and domain knowledge effectively within a practical workflow through case studies, evaluations, and user studies.
<div id='section'>Paperid: <span id='pid'>1023, <a href='https://arxiv.org/pdf/2507.01694.pdf' target='_blank'>https://arxiv.org/pdf/2507.01694.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanlin Cai, Haofan Dong, Houtianfu Wang, Kai Li, Ozgur B. Akan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01694">Graph Representation-based Model Poisoning on Federated Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated large language models (FedLLMs) enable powerful generative capabilities within wireless networks while preserving data privacy. Nonetheless, FedLLMs remain vulnerable to model poisoning attacks. This article first reviews recent advancements in model poisoning techniques and existing defense mechanisms for FedLLMs, underscoring critical limitations, especially when dealing with non-IID textual data distributions. Current defense strategies predominantly employ distance or similarity-based outlier detection mechanisms, relying on the assumption that malicious updates markedly differ from benign statistical patterns. However, this assumption becomes inadequate against adaptive adversaries targeting billion-parameter LLMs. The article further investigates graph representation-based model poisoning (GRMP), an emerging attack paradigm that exploits higher-order correlations among benign client gradients to craft malicious updates indistinguishable from legitimate ones. GRMP can effectively circumvent advanced defense systems, causing substantial degradation in model accuracy and overall performance. Moreover, the article outlines a forward-looking research roadmap that emphasizes the necessity of graph-aware secure aggregation methods, specialized vulnerability metrics tailored for FedLLMs, and evaluation frameworks to enhance the robustness of federated language model deployments.
<div id='section'>Paperid: <span id='pid'>1024, <a href='https://arxiv.org/pdf/2507.01417.pdf' target='_blank'>https://arxiv.org/pdf/2507.01417.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Gu, Ziyue Qiao, Zechao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01417">Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is critical for safely deploying deep models in open-world environments, where inputs may lie outside the training distribution. During inference on a model trained exclusively with In-Distribution (ID) data, we observe a salient gradient phenomenon: around an ID sample, the local gradient directions for "enhancing" that sample's predicted class remain relatively consistent, whereas OOD samples--unseen in training--exhibit disorganized or conflicting gradient directions in the same neighborhood. Motivated by this observation, we propose an inference-stage technique to short-circuit those feature coordinates that spurious gradients exploit to inflate OOD confidence, while leaving ID classification largely intact. To circumvent the expense of recomputing the logits after this gradient short-circuit, we further introduce a local first-order approximation that accurately captures the post-modification outputs without a second forward pass. Experiments on standard OOD benchmarks show our approach yields substantial improvements. Moreover, the method is lightweight and requires minimal changes to the standard inference pipeline, offering a practical path toward robust OOD detection in real-world applications.
<div id='section'>Paperid: <span id='pid'>1025, <a href='https://arxiv.org/pdf/2507.00570.pdf' target='_blank'>https://arxiv.org/pdf/2507.00570.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zizhao Li, Xueyang Kang, Joseph West, Kourosh Khoshelham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00570">Out-of-distribution detection in 3D applications: a review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to detect objects that are not prevalent in the training set is a critical capability in many 3D applications, including autonomous driving. Machine learning methods for object recognition often assume that all object categories encountered during inference belong to a closed set of classes present in the training data. This assumption limits generalization to the real world, as objects not seen during training may be misclassified or entirely ignored. As part of reliable AI, OOD detection identifies inputs that deviate significantly from the training distribution. This paper provides a comprehensive overview of OOD detection within the broader scope of trustworthy and uncertain AI. We begin with key use cases across diverse domains, introduce benchmark datasets spanning multiple modalities, and discuss evaluation metrics. Next, we present a comparative analysis of OOD detection methodologies, exploring model structures, uncertainty indicators, and distributional distance taxonomies, alongside uncertainty calibration techniques. Finally, we highlight promising research directions, including adversarially robust OOD detection and failure identification, particularly relevant to 3D applications. The paper offers both theoretical and practical insights into OOD detection, showcasing emerging research opportunities such as 3D vision integration. These insights help new researchers navigate the field more effectively, contributing to the development of reliable, safe, and robust AI systems.
<div id='section'>Paperid: <span id='pid'>1026, <a href='https://arxiv.org/pdf/2506.24034.pdf' target='_blank'>https://arxiv.org/pdf/2506.24034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>George Webber, Alexander Hammers, Andrew P King, Andrew J Reader
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.24034">Supervised Diffusion-Model-Based PET Image Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models (DMs) have recently been introduced as a regularizing prior for PET image reconstruction, integrating DMs trained on high-quality PET images with unsupervised schemes that condition on measured data. While these approaches have potential generalization advantages due to their independence from the scanner geometry and the injected activity level, they forgo the opportunity to explicitly model the interaction between the DM prior and noisy measurement data, potentially limiting reconstruction accuracy. To address this, we propose a supervised DM-based algorithm for PET reconstruction. Our method enforces the non-negativity of PET's Poisson likelihood model and accommodates the wide intensity range of PET images. Through experiments on realistic brain PET phantoms, we demonstrate that our approach outperforms or matches state-of-the-art deep learning-based methods quantitatively across a range of dose levels. We further conduct ablation studies to demonstrate the benefits of the proposed components in our model, as well as its dependence on training data, parameter count, and number of diffusion steps. Additionally, we show that our approach enables more accurate posterior sampling than unsupervised DM-based methods, suggesting improved uncertainty estimation. Finally, we extend our methodology to a practical approach for fully 3D PET and present example results from real [$^{18}$F]FDG brain PET data.
<div id='section'>Paperid: <span id='pid'>1027, <a href='https://arxiv.org/pdf/2505.15240.pdf' target='_blank'>https://arxiv.org/pdf/2505.15240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yassir Fathullah, Mark J. F. Gales
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15240">Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores generalised probabilistic modelling and uncertainty estimation in comparative LLM-as-a-judge frameworks. We show that existing Product-of-Experts methods are specific cases of a broader framework, enabling diverse modelling options. Furthermore, we propose improved uncertainty estimates for individual comparisons, enabling more efficient selection and achieving strong performance with fewer evaluations. We also introduce a method for estimating overall ranking uncertainty. Finally, we demonstrate that combining absolute and comparative scoring improves performance. Experiments show that the specific expert model has a limited impact on final rankings but our proposed uncertainty estimates, especially the probability of reordering, significantly improve the efficiency of systems reducing the number of needed comparisons by ~50%. Furthermore, ranking-level uncertainty metrics can be used to identify low-performing predictions, where the nature of the probabilistic model has a notable impact on the quality of the overall uncertainty.
<div id='section'>Paperid: <span id='pid'>1028, <a href='https://arxiv.org/pdf/2505.15177.pdf' target='_blank'>https://arxiv.org/pdf/2505.15177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Gu, Ziyue Qiao, Zechao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15177">SpectralGap: Graph-Level Out-of-Distribution Detection via Laplacian Eigenvalue Gaps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The task of graph-level out-of-distribution (OOD) detection is crucial for deploying graph neural networks in real-world settings. In this paper, we observe a significant difference in the relationship between the largest and second-largest eigenvalues of the Laplacian matrix for in-distribution (ID) and OOD graph samples: \textit{OOD samples often exhibit anomalous spectral gaps (the difference between the largest and second-largest eigenvalues)}. This observation motivates us to propose SpecGap, an effective post-hoc approach for OOD detection on graphs. SpecGap adjusts features by subtracting the component associated with the second-largest eigenvalue, scaled by the spectral gap, from the high-level features (i.e., $\mathbf{X}-\left(Î»_n-Î»_{n-1}\right) \mathbf{u}_{n-1} \mathbf{v}_{n-1}^T$). SpecGap achieves state-of-the-art performance across multiple benchmark datasets. We present extensive ablation studies and comprehensive theoretical analyses to support our empirical results. As a parameter-free post-hoc method, SpecGap can be easily integrated into existing graph neural network models without requiring any additional training or model modification.
<div id='section'>Paperid: <span id='pid'>1029, <a href='https://arxiv.org/pdf/2505.07863.pdf' target='_blank'>https://arxiv.org/pdf/2505.07863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziliang Wang, Xiaohong Zhang, Ze Shi Li, Meng Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07863">QoSBERT: An Uncertainty-Aware Approach based on Pre-trained Language Models for Service Quality Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of Quality of Service (QoS) metrics is fundamental for selecting and managing cloud based services. Traditional QoS models rely on manual feature engineering and yield only point estimates, offering no insight into the confidence of their predictions. In this paper, we propose QoSBERT, the first framework that reformulates QoS prediction as a semantic regression task based on pre trained language models. Unlike previous approaches relying on sparse numerical features, QoSBERT automatically encodes user service metadata into natural language descriptions, enabling deep semantic understanding. Furthermore, we integrate a Monte Carlo Dropout based uncertainty estimation module, allowing for trustworthy and risk-aware service quality prediction, which is crucial yet underexplored in existing QoS models. QoSBERT applies attentive pooling over contextualized embeddings and a lightweight multilayer perceptron regressor, fine tuned jointly to minimize absolute error. We further exploit the resulting uncertainty estimates to select high quality training samples, improving robustness in low resource settings. On standard QoS benchmark datasets, QoSBERT achieves an average reduction of 11.7% in MAE and 6.7% in RMSE for response time prediction, and 6.9% in MAE for throughput prediction compared to the strongest baselines, while providing well calibrated confidence intervals for robust and trustworthy service quality estimation. Our approach not only advances the accuracy of service quality prediction but also delivers reliable uncertainty quantification, paving the way for more trustworthy, data driven service selection and optimization.
<div id='section'>Paperid: <span id='pid'>1030, <a href='https://arxiv.org/pdf/2504.18746.pdf' target='_blank'>https://arxiv.org/pdf/2504.18746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brian K. S. Isaac-Medina, Toby P. Breckon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18746">Dream-Box: Object-wise Outlier Generation for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have demonstrated great generalization capabilities for tasks whose training and test sets are drawn from the same distribution. Nevertheless, out-of-distribution (OOD) detection remains a challenging task that has received significant attention in recent years. Specifically, OOD detection refers to the detection of instances that do not belong to the training distribution, while still having good performance on the in-distribution task (e.g., classification or object detection). Recent work has focused on generating synthetic outliers and using them to train an outlier detector, generally achieving improved OOD detection than traditional OOD methods. In this regard, outliers can be generated either in feature or pixel space. Feature space driven methods have shown strong performance on both the classification and object detection tasks, at the expense that the visualization of training outliers remains unknown, making further analysis on OOD failure modes challenging. On the other hand, pixel space outlier generation techniques enabled by diffusion models have been used for image classification using, providing improved OOD detection performance and outlier visualization, although their adaption to the object detection task is as yet unexplored. We therefore introduce Dream-Box, a method that provides a link to object-wise outlier generation in the pixel space for OOD detection. Specifically, we use diffusion models to generate object-wise outliers that are used to train an object detector for an in-distribution task and OOD detection. Our method achieves comparable performance to previous traditional methods while being the first technique to provide concrete visualization of generated OOD objects.
<div id='section'>Paperid: <span id='pid'>1031, <a href='https://arxiv.org/pdf/2504.02214.pdf' target='_blank'>https://arxiv.org/pdf/2504.02214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunho Lee, Wenwen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02214">Geospatial Artificial Intelligence for Satellite-Based Flood Extent Mapping: Concepts, Advances, and Future Perspectives</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geospatial Artificial Intelligence (GeoAI) for satellite-based flood extent mapping systematically integrates artificial intelligence techniques with satellite data to identify flood events and assess their impacts, for disaster management and spatial decision-making. The primary output often includes flood extent maps, which delineate the affected areas, along with additional analytical outputs such as uncertainty estimation and change detection.
<div id='section'>Paperid: <span id='pid'>1032, <a href='https://arxiv.org/pdf/2504.01957.pdf' target='_blank'>https://arxiv.org/pdf/2504.01957.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shu-Wei Lu, Yi-Hsuan Tsai, Yi-Ting Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01957">Toward Real-world BEV Perception: Depth Uncertainty Estimation via Gaussian Splatting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bird's-eye view (BEV) perception has gained significant attention because it provides a unified representation to fuse multiple view images and enables a wide range of down-stream autonomous driving tasks, such as forecasting and planning. Recent state-of-the-art models utilize projection-based methods which formulate BEV perception as query learning to bypass explicit depth estimation. While we observe promising advancements in this paradigm, they still fall short of real-world applications because of the lack of uncertainty modeling and expensive computational requirement. In this work, we introduce GaussianLSS, a novel uncertainty-aware BEV perception framework that revisits unprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm, and enhances them with depth un-certainty modeling. GaussianLSS represents spatial dispersion by learning a soft depth mean and computing the variance of the depth distribution, which implicitly captures object extents. We then transform the depth distribution into 3D Gaussians and rasterize them to construct uncertainty-aware BEV features. We evaluate GaussianLSS on the nuScenes dataset, achieving state-of-the-art performance compared to unprojection-based methods. In particular, it provides significant advantages in speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory compared to projection-based methods, while achieving competitive performance with only a 0.4% IoU difference.
<div id='section'>Paperid: <span id='pid'>1033, <a href='https://arxiv.org/pdf/2504.00429.pdf' target='_blank'>https://arxiv.org/pdf/2504.00429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinghe Zhang, Chi Liu, Shuai Zhou, Sheng Shen, Peng Gui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.00429">Unleashing the Power of Pre-trained Encoders for Universal Adversarial Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adversarial attacks pose a critical security threat to real-world AI systems by injecting human-imperceptible perturbations into benign samples to induce misclassification in deep learning models. While existing detection methods, such as Bayesian uncertainty estimation and activation pattern analysis, have achieved progress through feature engineering, their reliance on handcrafted feature design and prior knowledge of attack patterns limits generalization capabilities and incurs high engineering costs. To address these limitations, this paper proposes a lightweight adversarial detection framework based on the large-scale pre-trained vision-language model CLIP. Departing from conventional adversarial feature characterization paradigms, we innovatively adopt an anomaly detection perspective. By jointly fine-tuning CLIP's dual visual-text encoders with trainable adapter networks and learnable prompts, we construct a compact representation space tailored for natural images. Notably, our detection architecture achieves substantial improvements in generalization capability across both known and unknown attack patterns compared to traditional methods, while significantly reducing training overhead. This study provides a novel technical pathway for establishing a parameter-efficient and attack-agnostic defense paradigm, markedly enhancing the robustness of vision systems against evolving adversarial threats.
<div id='section'>Paperid: <span id='pid'>1034, <a href='https://arxiv.org/pdf/2503.14106.pdf' target='_blank'>https://arxiv.org/pdf/2503.14106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jef Jonkers, Frank Coopman, Luc Duchateau, Glenn Van Wallendael, Sofie Van Hoecke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14106">Reliable uncertainty quantification for 2D/3D anatomical landmark localization using multi-output conformal prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic anatomical landmark localization in medical imaging requires not just accurate predictions but reliable uncertainty quantification for effective clinical decision support. Current uncertainty quantification approaches often fall short, particularly when combined with normality assumptions, systematically underestimating total predictive uncertainty. This paper introduces conformal prediction as a framework for reliable uncertainty quantification in anatomical landmark localization, addressing a critical gap in automatic landmark localization. We present two novel approaches guaranteeing finite-sample validity for multi-output prediction: Multi-output Regression-as-Classification Conformal Prediction (M-R2CCP) and its variant Multi-output Regression to Classification Conformal Prediction set to Region (M-R2C2R). Unlike conventional methods that produce axis-aligned hyperrectangular or ellipsoidal regions, our approaches generate flexible, non-convex prediction regions that better capture the underlying uncertainty structure of landmark predictions. Through extensive empirical evaluation across multiple 2D and 3D datasets, we demonstrate that our methods consistently outperform existing multi-output conformal prediction approaches in both validity and efficiency. This work represents a significant advancement in reliable uncertainty estimation for anatomical landmark localization, providing clinicians with trustworthy confidence measures for their diagnoses. While developed for medical imaging, these methods show promise for broader applications in multi-output regression problems.
<div id='section'>Paperid: <span id='pid'>1035, <a href='https://arxiv.org/pdf/2503.14002.pdf' target='_blank'>https://arxiv.org/pdf/2503.14002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Damian Boborzi, Phillip Mueller, Jonas Emrich, Dominik Schmid, Sebastian Mueller, Lars Mikelsons
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14002">MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models have recently made remarkable progress in the field of 3D objects. However, their practical application in fields like engineering remains limited since they fail to deliver the accuracy, quality, and controllability needed for domain-specific tasks. Fine-tuning large generative models is a promising perspective for making these models available in these fields. Creating high-quality, domain-specific 3D datasets is crucial for fine-tuning large generative models, yet the data filtering and annotation process remains a significant bottleneck. We present MeshFleet, a filtered and annotated 3D vehicle dataset extracted from Objaverse-XL, the most extensive publicly available collection of 3D objects. Our approach proposes a pipeline for automated data filtering based on a quality classifier. This classifier is trained on a manually labeled subset of Objaverse, incorporating DINOv2 and SigLIP embeddings, refined through caption-based analysis and uncertainty estimation. We demonstrate the efficacy of our filtering method through a comparative analysis against caption and image aesthetic score-based techniques and fine-tuning experiments with SV3D, highlighting the importance of targeted data selection for domain-specific 3D generative modeling.
<div id='section'>Paperid: <span id='pid'>1036, <a href='https://arxiv.org/pdf/2503.07435.pdf' target='_blank'>https://arxiv.org/pdf/2503.07435.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Riccardo Mazzieri, Jacopo Pegoraro, Michele Rossi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07435">Open-Set Gait Recognition from Sparse mmWave Radar Point Clouds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The adoption of Millimeter-Wave (mmWave) radar devices for human sensing, particularly gait recognition, has recently gathered significant attention due to their efficiency, resilience to environmental conditions, and privacy-preserving nature. In this work, we tackle the challenging problem of Open-set Gait Recognition (OSGR) from sparse mmWave radar point clouds. Unlike most existing research, which assumes a closed-set scenario, our work considers the more realistic open-set case, where unknown subjects might be present at inference time, and should be correctly recognized by the system. Point clouds are well-suited for edge computing applications with resource constraints, but are more significantly affected by noise and random fluctuations than other representations, like the more common micro-Doppler signature. This is the first work addressing open-set gait recognition with sparse point cloud data. To do so, we propose a novel neural network architecture that combines supervised classification with unsupervised reconstruction of the point clouds, creating a robust, rich, and highly regularized latent space of gait features. To detect unknown subjects at inference time, we introduce a probabilistic novelty detection algorithm that leverages the structured latent space and offers a tunable trade-off between inference speed and prediction accuracy. Along with this paper, we release mmGait10, an original human gait dataset featuring over five hours of measurements from ten subjects, under varied walking modalities. Extensive experimental results show that our solution attains F1-Score improvements by 24% over state-of-the-art methods adapted for point clouds, on average, and across multiple openness levels.
<div id='section'>Paperid: <span id='pid'>1037, <a href='https://arxiv.org/pdf/2503.00476.pdf' target='_blank'>https://arxiv.org/pdf/2503.00476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yicong Dong, Rundong He, Guangyao Chen, Wentao Zhang, Zhongyi Han, Jieming Shi, Yilong Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00476">G-OSR: A Comprehensive Benchmark for Graph Open-Set Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) have achieved significant success in machine learning, with wide applications in social networks, bioinformatics, knowledge graphs, and other fields. Most research assumes ideal closed-set environments. However, in real-world open-set environments, graph learning models face challenges in robustness and reliability due to unseen classes. This highlights the need for Graph Open-Set Recognition (GOSR) methods to address these issues and ensure effective GNN application in practical scenarios. Research in GOSR is in its early stages, with a lack of a comprehensive benchmark spanning diverse tasks and datasets to evaluate methods. Moreover, traditional methods, Graph Out-of-Distribution Detection (GOODD), GOSR, and Graph Anomaly Detection (GAD) have mostly evolved in isolation, with little exploration of their interconnections or potential applications to GOSR. To fill these gaps, we introduce \textbf{G-OSR}, a comprehensive benchmark for evaluating GOSR methods at both the node and graph levels, using datasets from multiple domains to ensure fair and standardized comparisons of effectiveness and efficiency across traditional, GOODD, GOSR, and GAD methods. The results offer critical insights into the generalizability and limitations of current GOSR methods and provide valuable resources for advancing research in this field through systematic analysis of diverse approaches.
<div id='section'>Paperid: <span id='pid'>1038, <a href='https://arxiv.org/pdf/2502.19977.pdf' target='_blank'>https://arxiv.org/pdf/2502.19977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Song, Andrea Iannelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19977">Convergence Guarantees of Model-free Policy Gradient Methods for LQR with Stochastic Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Policy gradient (PG) methods are the backbone of many reinforcement learning algorithms due to their good performance in policy optimization problems. As a gradient-based approach, PG methods typically rely on knowledge of the system dynamics. If this is not available, trajectory data can be utilized to approximate first-order information. When the data are noisy, gradient estimates become inaccurate and a study that investigates uncertainty estimation and the analysis of its propagation through the algorithm is currently missing. To address this, our work focuses on the Linear Quadratic Regulator (LQR) problem for systems subject to additive stochastic noise. After briefly summarizing the state of the art for cases with a known model, we focus on scenarios where the system dynamics are unknown, and approximate gradient information is obtained using zeroth-order optimization techniques. We analyze the theoretical properties by computing the error in the estimated gradient and examining how this error affects the convergence of PG algorithms. Additionally, we provide global convergence guarantees for various versions of PG methods, including those employing adaptive step sizes and variance reduction techniques, which help increase the convergence rate and reduce sample complexity. This study contributed to characterizing robustness of the study of the robustness of model-free PG methods, aiming to identify their limitations in the presence of stochastic noise and proposing improvements to enhance their applicability.
<div id='section'>Paperid: <span id='pid'>1039, <a href='https://arxiv.org/pdf/2501.17906.pdf' target='_blank'>https://arxiv.org/pdf/2501.17906.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingkun Chen, Guang Yang, Xiao Zhang, Jingchao Peng, Tianlu Zhang, Jianguo Zhang, Jungong Han, Vicente Grau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17906">Unsupervised Patch-GAN with Targeted Patch Ranking for Fine-Grained Novelty Detection in Medical Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting novel anomalies in medical imaging is challenging due to the limited availability of labeled data for rare abnormalities, which often display high variability and subtlety. This challenge is further compounded when small abnormal regions are embedded within larger normal areas, as whole-image predictions frequently overlook these subtle deviations. To address these issues, we propose an unsupervised Patch-GAN framework designed to detect and localize anomalies by capturing both local detail and global structure. Our framework first reconstructs masked images to learn fine-grained, normal-specific features, allowing for enhanced sensitivity to minor deviations from normality. By dividing these reconstructed images into patches and assessing the authenticity of each patch, our approach identifies anomalies at a more granular level, overcoming the limitations of whole-image evaluation. Additionally, a patch-ranking mechanism prioritizes regions with higher abnormal scores, reinforcing the alignment between local patch discrepancies and the global image context. Experimental results on the ISIC 2016 skin lesion and BraTS 2019 brain tumor datasets validate our framework's effectiveness, achieving AUCs of 95.79% and 96.05%, respectively, and outperforming three state-of-the-art baselines.
<div id='section'>Paperid: <span id='pid'>1040, <a href='https://arxiv.org/pdf/2501.10209.pdf' target='_blank'>https://arxiv.org/pdf/2501.10209.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Annita Vapsi, AndrÃ©s MuÃ±oz, Nancy Thomas, Keshav Ramani, Daniel Borrajo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.10209">Hypercone Assisted Contour Generation for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in the field of out-of-distribution (OOD) detection have placed great emphasis on learning better representations suited to this task. While there are distance-based approaches, distributional awareness has seldom been exploited for better performance. We present HAC$_k$-OOD, a novel OOD detection method that makes no distributional assumption about the data, but automatically adapts to its distribution. Specifically, HAC$_k$-OOD constructs a set of hypercones by maximizing the angular distance to neighbors in a given data-point's vicinity to approximate the contour within which in-distribution (ID) data-points lie. Experimental results show state-of-the-art FPR@95 and AUROC performance on Near-OOD detection and on Far-OOD detection on the challenging CIFAR-100 benchmark without explicitly training for OOD performance.
<div id='section'>Paperid: <span id='pid'>1041, <a href='https://arxiv.org/pdf/2501.06308.pdf' target='_blank'>https://arxiv.org/pdf/2501.06308.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexis Bose, Jonathan Ethier, Ryan G. Dempsey, Yifeng Qiu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06308">Uncertainty Estimation for Path Loss and Radio Metric Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research leverages Conformal Prediction (CP) in the form of Conformal Predictive Systems (CPS) to accurately estimate uncertainty in a suite of machine learning (ML)-based radio metric models [1] as well as in a 2-D map-based ML path loss model [2]. Utilizing diverse difficulty estimators, we construct 95% confidence prediction intervals (PIs) that are statistically robust. Our experiments demonstrate that CPS models, trained on Toronto datasets, generalize effectively to other cities such as Vancouver and Montreal, maintaining high coverage and reliability. Furthermore, the employed difficulty estimators identify challenging samples, leading to measurable reductions in RMSE as dataset difficulty decreases. These findings highlight the effectiveness of scalable and reliable uncertainty estimation through CPS in wireless network modeling, offering important potential insights for network planning, operations, and spectrum management.
<div id='section'>Paperid: <span id='pid'>1042, <a href='https://arxiv.org/pdf/2501.04899.pdf' target='_blank'>https://arxiv.org/pdf/2501.04899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanna Zubkova, Ji-Hoon Park, Seong-Whan Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04899">SUGAR: Leveraging Contextual Confidence for Smarter Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bearing in mind the limited parametric knowledge of Large Language Models (LLMs), retrieval-augmented generation (RAG) which supplies them with the relevant external knowledge has served as an approach to mitigate the issue of hallucinations to a certain extent. However, uniformly retrieving supporting context makes response generation source-inefficient, as triggering the retriever is not always necessary, or even inaccurate, when a model gets distracted by noisy retrieved content and produces an unhelpful answer. Motivated by these issues, we introduce Semantic Uncertainty Guided Adaptive Retrieval (SUGAR), where we leverage context-based entropy to actively decide whether to retrieve and to further determine between single-step and multi-step retrieval. Our empirical results show that selective retrieval guided by semantic uncertainty estimation improves the performance across diverse question answering tasks, as well as achieves a more efficient inference.
<div id='section'>Paperid: <span id='pid'>1043, <a href='https://arxiv.org/pdf/2412.19017.pdf' target='_blank'>https://arxiv.org/pdf/2412.19017.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saadat Behzadi, Danial Sharifrazi, Roohallah Alizadehsani, Mojtaba Lotfaliany, Mohammadreza Mohebbi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19017">Brain Ageing Prediction using Isolation Forest Technique and Residual Neural Network (ResNet)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Brain aging is a complex and dynamic process, leading to functional and structural changes in the brain. These changes could lead to the increased risk of neurodegenerative diseases and cognitive decline. Accurate brain-age estimation utilizing neuroimaging data has become necessary for detecting initial signs of neurodegeneration. Here, we propose a novel deep learning approach using the Residual Neural Network 101 Version 2 (ResNet101V2) model to predict brain age from MRI scans. To train, validate and test our proposed model, we used a large dataset of 2102 images which were selected randomly from the International Consortium for Brain Mapping (ICBM). Next, we applied data preprocessing techniques, including normalizing the images and using outlier detection via Isolation Forest method. Then, we evaluated various pre-trained approaches (namely: MobileNetV2, ResNet50V2, ResNet101V2, Xception). The results demonstrated that the ResNet101V2 model has higher performance compared with the other models, attaining MAEs of 0.9136 and 0.8242 years for before and after using Isolation Forest process. Our method achieved a high accuracy in brain age estimation in ICBM dataset and it provides a reliable brain age prediction.
<div id='section'>Paperid: <span id='pid'>1044, <a href='https://arxiv.org/pdf/2412.15758.pdf' target='_blank'>https://arxiv.org/pdf/2412.15758.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sophie Steger, Christian Knoll, Bernhard Klein, Holger FrÃ¶ning, Franz Pernkopf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15758">Function Space Diversity for Uncertainty Prediction via Repulsive Last-Layer Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian inference in function space has gained attention due to its robustness against overparameterization in neural networks. However, approximating the infinite-dimensional function space introduces several challenges. In this work, we discuss function space inference via particle optimization and present practical modifications that improve uncertainty estimation and, most importantly, make it applicable for large and pretrained networks. First, we demonstrate that the input samples, where particle predictions are enforced to be diverse, are detrimental to the model performance. While diversity on training data itself can lead to underfitting, the use of label-destroying data augmentation, or unlabeled out-of-distribution data can improve prediction diversity and uncertainty estimates. Furthermore, we take advantage of the function space formulation, which imposes no restrictions on network parameterization other than sufficient flexibility. Instead of using full deep ensembles to represent particles, we propose a single multi-headed network that introduces a minimal increase in parameters and computation. This allows seamless integration to pretrained networks, where this repulsive last-layer ensemble can be used for uncertainty aware fine-tuning at minimal additional cost. We achieve competitive results in disentangling aleatoric and epistemic uncertainty for active learning, detecting out-of-domain data, and providing calibrated uncertainty estimates under distribution shifts with minimal compute and memory.
<div id='section'>Paperid: <span id='pid'>1045, <a href='https://arxiv.org/pdf/2412.03058.pdf' target='_blank'>https://arxiv.org/pdf/2412.03058.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Wu, Xichen Ye, Songmin Dai, Dengye Pan, Xiaoqiang Li, Weizhong Zhang, Yifan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03058">Revisiting Energy-Based Model for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is an essential approach to robustifying deep learning models, enabling them to identify inputs that fall outside of their trained distribution. Existing OOD detection methods usually depend on crafted data, such as specific outlier datasets or elaborate data augmentations. While this is reasonable, the frequent mismatch between crafted data and OOD data limits model robustness and generalizability. In response to this issue, we introduce Outlier Exposure by Simple Transformations (OEST), a framework that enhances OOD detection by leveraging "peripheral-distribution" (PD) data. Specifically, PD data are samples generated through simple data transformations, thus providing an efficient alternative to manually curated outliers.
  We adopt energy-based models (EBMs) to study PD data. We recognize the "energy barrier" in OOD detection, which characterizes the energy difference between in-distribution (ID) and OOD samples and eases detection. PD data are introduced to establish the energy barrier during training. Furthermore, this energy barrier concept motivates a theoretically grounded energy-barrier loss to replace the classical energy-bounded loss, leading to an improved paradigm, OEST*, which achieves a more effective and theoretically sound separation between ID and OOD samples. We perform empirical validation of our proposal, and extensive experiments across various benchmarks demonstrate that OEST* achieves better or similar accuracy compared with state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1046, <a href='https://arxiv.org/pdf/2412.01596.pdf' target='_blank'>https://arxiv.org/pdf/2412.01596.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brian K. S. Isaac-Medina, Mauricio Che, Yona F. A. Gaus, Samet Akcay, Toby P. Breckon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01596">FEVER-OOD: Free Energy Vulnerability Elimination for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern machine learning models, that excel on computer vision tasks such as classification and object detection, are often overconfident in their predictions for Out-of-Distribution (OOD) examples, resulting in unpredictable behaviour for open-set environments. Recent works have demonstrated that the free energy score is an effective measure of uncertainty for OOD detection given its close relationship to the data distribution. However, despite free energy-based methods representing a significant empirical advance in OOD detection, our theoretical analysis reveals previously unexplored and inherent vulnerabilities within the free energy score formulation such that in-distribution and OOD instances can have distinct feature representations yet identical free energy scores. This phenomenon occurs when the vector direction representing the feature space difference between the in-distribution and OOD sample lies within the null space of the last layer of a neural-based classifier. To mitigate these issues, we explore lower-dimensional feature spaces to reduce the null space footprint and introduce novel regularisation to maximize the least singular value of the final linear layer, hence enhancing inter-sample free energy separation. We refer to these techniques as Free Energy Vulnerability Elimination for Robust Out-of-Distribution Detection (FEVER-OOD). Our experiments show that FEVER-OOD techniques achieve state of the art OOD detection in Imagenet-100, with average OOD false positive rate (at 95% true positive rate) of 35.83% when used with the baseline Dream-OOD model.
<div id='section'>Paperid: <span id='pid'>1047, <a href='https://arxiv.org/pdf/2411.14346.pdf' target='_blank'>https://arxiv.org/pdf/2411.14346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edgar Mauricio Salazar Duque, Bart van der Holst, Pedro P. Vergara, Juan S. Giraldo, Phuong H. Nguyen, Anne Van der Molen, Han, Slootweg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14346">Lower Dimensional Spherical Representation of Medium Voltage Load Profiles for Visualization, Outlier Detection, and Generative Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents the spherical lower dimensional representation for daily medium voltage load profiles, based on principal component analysis. The objective is to unify and simplify the tasks for (i) clustering visualisation, (ii) outlier detection and (iii) generative profile modelling under one concept. The lower dimensional projection of standardised load profiles unveils a latent distribution in a three-dimensional sphere. This spherical structure allows us to detect outliers by fitting probability distribution models in the spherical coordinate system, identifying measurements that deviate from the spherical shape. The same latent distribution exhibits an arc shape, suggesting an underlying order among load profiles. We develop a principal curve technique to uncover this order based on similarity, offering new advantages over conventional clustering techniques. This finding reveals that energy consumption in a wide region can be seen as a continuously changing process. Furthermore, we combined the principal curve with a von Mises-Fisher distribution to create a model capable of generating profiles with continuous mixtures between clusters. The presence of the spherical distribution is validated with data from four municipalities in the Netherlands. The uncovered spherical structure implies the possibility of employing new mathematical tools from directional statistics and differential geometry for load profile modelling.
<div id='section'>Paperid: <span id='pid'>1048, <a href='https://arxiv.org/pdf/2411.06308.pdf' target='_blank'>https://arxiv.org/pdf/2411.06308.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ezgi Demircan-Tureyen, Felix Lucka, Tristan van Leeuwen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06308">Exploring Out-of-distribution Detection for Sparse-view Computed Tomography with Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent works demonstrate the effectiveness of diffusion models as unsupervised solvers for inverse imaging problems. Sparse-view computed tomography (CT) has greatly benefited from these advancements, achieving improved generalization without reliance on measurement parameters. However, this comes at the cost of potential hallucinations, especially when handling out-of-distribution (OOD) data. To ensure reliability, it is essential to study OOD detection for CT reconstruction across both clinical and industrial applications. This need further extends to enabling the OOD detector to function effectively as an anomaly inspection tool. In this paper, we explore the use of a diffusion model, trained to capture the target distribution for CT reconstruction, as an in-distribution prior. Building on recent research, we employ the model to reconstruct partially diffused input images and assess OOD-ness through multiple reconstruction errors. Adapting this approach for sparse-view CT requires redefining the notions of ``input'' and ``reconstruction error''. Here, we use filtered backprojection (FBP) reconstructions as input and investigate various definitions of reconstruction error. Our proof-of-concept experiments on the MNIST dataset highlight both successes and failures, demonstrating the potential and limitations of integrating such an OOD detector into a CT reconstruction system. Our findings suggest that effective OOD detection can be achieved by comparing measurements with forward-projected reconstructions, provided that reconstructions from noisy FBP inputs are conditioned on the measurements. However, conditioning can sometimes lead the OOD detector to inadvertently reconstruct OOD images well. To counter this, we introduce a weighting approach that improves robustness against highly informative OOD measurements, albeit with a trade-off in performance in certain cases.
<div id='section'>Paperid: <span id='pid'>1049, <a href='https://arxiv.org/pdf/2410.23272.pdf' target='_blank'>https://arxiv.org/pdf/2410.23272.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qidong Yang, Weicheng Zhu, Joseph Keslin, Laure Zanna, Tim G. J. Rudner, Carlos Fernandez-Granda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.23272">A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Probabilistic prediction of sequences from images and other high-dimensional data is a key challenge, particularly in risk-sensitive applications. In these settings, it is often desirable to quantify the uncertainty associated with the prediction (instead of just determining the most likely sequence, as in language modeling). In this paper, we propose a Monte Carlo framework to estimate probabilities and confidence intervals associated with the distribution of a discrete sequence. Our framework uses a Monte Carlo simulator, implemented as an autoregressively trained neural network, to sample sequences conditioned on an image input. We then use these samples to estimate the probabilities and confidence intervals. Experiments on synthetic and real data show that the framework produces accurate discriminative predictions, but can suffer from miscalibration. In order to address this shortcoming, we propose a time-dependent regularization method, which is shown to produce calibrated predictions.
<div id='section'>Paperid: <span id='pid'>1050, <a href='https://arxiv.org/pdf/2410.18864.pdf' target='_blank'>https://arxiv.org/pdf/2410.18864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>SebastiÃ¡n Espinel-RÃ­os, JosÃ© MontaÃ±o LÃ³pez, JosÃ© L. Avalos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18864">Omics-driven hybrid dynamic modeling of bioprocesses with uncertainty estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents an omics-driven modeling pipeline that integrates machine-learning tools to facilitate the dynamic modeling of multiscale biological systems. Random forests and permutation feature importance are proposed to mine omics datasets, guiding feature selection and dimensionality reduction for dynamic modeling. Continuous and differentiable machine-learning functions can be trained to link the reduced omics feature set to key components of the dynamic model, resulting in a hybrid model. As proof of concept, we apply this framework to a high-dimensional proteomics dataset of $\textit{Saccharomyces cerevisiae}$. After identifying key intracellular proteins that correlate with cell growth, targeted dynamic experiments are designed, and key model parameters are captured as functions of the selected proteins using Gaussian processes. This approach captures the dynamic behavior of yeast strains under varying proteome profiles while estimating the uncertainty in the hybrid model's predictions. The outlined modeling framework is adaptable to other scenarios, such as integrating additional layers of omics data for more advanced multiscale biological systems, or employing alternative machine-learning methods to handle larger datasets. Overall, this study outlines a strategy for leveraging omics data to inform multiscale dynamic modeling in systems biology and bioprocess engineering.
<div id='section'>Paperid: <span id='pid'>1051, <a href='https://arxiv.org/pdf/2410.06134.pdf' target='_blank'>https://arxiv.org/pdf/2410.06134.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingle Xu, Jaehwan Lee, Sook Yoon, Dong Sun Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06134">Adaptive Label Smoothing for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection, which aims to distinguish unknown classes from known classes, has received increasing attention recently. A main challenge within is the unavailable of samples from the unknown classes in the training process, and an effective strategy is to improve the performance for known classes. Using beneficial strategies such as data augmentation and longer training is thus a way to improve OOD detection. However, label smoothing, an effective method for classifying known classes, degrades the performance of OOD detection, and this phenomenon is under exploration. In this paper, we first analyze that the limited and predefined learning target in label smoothing results in the smaller maximal probability and logit, which further leads to worse OOD detection performance. To mitigate this issue, we then propose a novel regularization method, called adaptive label smoothing (ALS), and the core is to push the non-true classes to have same probabilities whereas the maximal probability is neither fixed nor limited. Extensive experimental results in six datasets with two backbones suggest that ALS contributes to classifying known samples and discerning unknown samples with clear margins. Our code will be available to the public.
<div id='section'>Paperid: <span id='pid'>1052, <a href='https://arxiv.org/pdf/2409.12426.pdf' target='_blank'>https://arxiv.org/pdf/2409.12426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Liu, Jiaqi Zhu, Guirong Zhuo, Wufei Fu, Zonglin Meng, Yishi Lu, Min Hua, Feng Qiao, You Li, Yi He, Lu Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.12426">UniMSF: A Unified Multi-Sensor Fusion Framework for Intelligent Transportation System Global Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intelligent transportation systems (ITS) localization is of significant importance as it provides fundamental position and orientation for autonomous operations like intelligent vehicles. Integrating diverse and complementary sensors such as global navigation satellite system (GNSS) and 4D-radar can provide scalable and reliable global localization. Nevertheless, multi-sensor fusion encounters challenges including heterogeneity and time-varying uncertainty in measurements. Consequently, developing a reliable and unified multi-sensor framework remains challenging. In this paper, we introduce UniMSF, a comprehensive multi-sensor fusion localization framework for ITS, utilizing factor graphs. By integrating a multi-sensor fusion front-end, alongside outlier detection\&noise model estimation, and a factor graph optimization back-end, this framework accomplishes efficient fusion and ensures accurate localization for ITS. Specifically, in the multi-sensor fusion front-end module, we tackle the measurement heterogeneity among different modality sensors and establish effective measurement models. Reliable outlier detection and data-driven online noise estimation methods ensure that back-end optimization is immune to interference from outlier measurements. In addition, integrating multi-sensor observations via factor graph optimization offers the advantage of \enquote{plug and play}. Notably, our framework features high modularity and is seamlessly adapted to various sensor configurations. We demonstrate the effectiveness of the proposed framework through real vehicle tests by tightly integrating GNSS pseudorange and carrier phase information with IMU, and 4D-radar.
<div id='section'>Paperid: <span id='pid'>1053, <a href='https://arxiv.org/pdf/2409.10972.pdf' target='_blank'>https://arxiv.org/pdf/2409.10972.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sawan Kumar, Rajdip Nayek, Souvik Chakraborty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10972">Towards Gaussian Process for operator learning: an uncertainty aware resolution independent operator learning algorithm for computational mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing demand for accurate, efficient, and scalable solutions in computational mechanics highlights the need for advanced operator learning algorithms that can efficiently handle large datasets while providing reliable uncertainty quantification. This paper introduces a novel Gaussian Process (GP) based neural operator for solving parametric differential equations. The approach proposed leverages the expressive capability of deterministic neural operators and the uncertainty awareness of conventional GP. In particular, we propose a ``neural operator-embedded kernel'' wherein the GP kernel is formulated in the latent space learned using a neural operator. Further, we exploit a stochastic dual descent (SDD) algorithm for simultaneously training the neural operator parameters and the GP hyperparameters. Our approach addresses the (a) resolution dependence and (b) cubic complexity of traditional GP models, allowing for input-resolution independence and scalability in high-dimensional and non-linear parametric systems, such as those encountered in computational mechanics. We apply our method to a range of non-linear parametric partial differential equations (PDEs) and demonstrate its superiority in both computational efficiency and accuracy compared to standard GP models and wavelet neural operators. Our experimental results highlight the efficacy of this framework in solving complex PDEs while maintaining robustness in uncertainty estimation, positioning it as a scalable and reliable operator-learning algorithm for computational mechanics.
<div id='section'>Paperid: <span id='pid'>1054, <a href='https://arxiv.org/pdf/2408.13667.pdf' target='_blank'>https://arxiv.org/pdf/2408.13667.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xueying Ding, Rui Xi, Leman Akoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.13667">Outlier Detection Bias Busted: Understanding Sources of Algorithmic Bias through Data-centric Factors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The astonishing successes of ML have raised growing concern for the fairness of modern methods when deployed in real world settings. However, studies on fairness have mostly focused on supervised ML, while unsupervised outlier detection (OD), with numerous applications in finance, security, etc., have attracted little attention. While a few studies proposed fairness-enhanced OD algorithms, they remain agnostic to the underlying driving mechanisms or sources of unfairness. Even within the supervised ML literature, there exists debate on whether unfairness stems solely from algorithmic biases (i.e. design choices) or from the biases encoded in the data on which they are trained. To close this gap, this work aims to shed light on the possible sources of unfairness in OD by auditing detection models under different data-centric factors. By injecting various known biases into the input data -- as pertain to sample size disparity, under-representation, feature measurement noise, and group membership obfuscation -- we find that the OD algorithms under the study all exhibit fairness pitfalls, although differing in which types of data bias they are more susceptible to. Most notable of our study is to demonstrate that OD algorithm bias is not merely a data bias problem. A key realization is that the data properties that emerge from bias injection could as well be organic -- as pertain to natural group differences w.r.t. sparsity, base rate, variance, and multi-modality. Either natural or biased, such data properties can give rise to unfairness as they interact with certain algorithmic design choices.
<div id='section'>Paperid: <span id='pid'>1055, <a href='https://arxiv.org/pdf/2408.04718.pdf' target='_blank'>https://arxiv.org/pdf/2408.04718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dule Shu, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.04718">Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The success of diffusion probabilistic models in generative tasks, such as text-to-image generation, has motivated the exploration of their application to regression problems commonly encountered in scientific computing and various other domains. In this context, the use of diffusion regression models for ensemble prediction is becoming a practice with increasing popularity. Under such background, we conducted a study to quantitatively evaluate the effectiveness of ensemble methods on solving different regression problems using diffusion models. We consider the ensemble prediction of a diffusion model as a means for zero-shot uncertainty quantification, since the diffusion models in our study are not trained with a loss function containing any uncertainty estimation. Through extensive experiments on 1D and 2D data, we demonstrate that ensemble methods consistently improve model prediction accuracy across various regression tasks. Notably, we observed a larger accuracy gain in auto-regressive prediction compared with point-wise prediction, and that enhancements take place in both the mean-square error and the physics-informed loss. Additionally, we reveal a statistical correlation between ensemble prediction error and ensemble variance, offering insights into balancing computational complexity with prediction accuracy and monitoring prediction confidence in practical applications where the ground truth is unknown. Our study provides a comprehensive view of the utility of diffusion ensembles, serving as a useful reference for practitioners employing diffusion models in regression problem-solving.
<div id='section'>Paperid: <span id='pid'>1056, <a href='https://arxiv.org/pdf/2408.01977.pdf' target='_blank'>https://arxiv.org/pdf/2408.01977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fatemeh Amerehi, Patrick Healy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01977">Label Augmentation for Neural Networks Robustness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution generalization can be categorized into two types: common perturbations arising from natural variations in the real world and adversarial perturbations that are intentionally crafted to deceive neural networks. While deep neural networks excel in accuracy under the assumption of identical distributions between training and test data, they often encounter out-of-distribution scenarios resulting in a significant decline in accuracy. Data augmentation methods can effectively enhance robustness against common corruptions, but they typically fall short in improving robustness against adversarial perturbations. In this study, we develop Label Augmentation (LA), which enhances robustness against both common and intentional perturbations and improves uncertainty estimation. Our findings indicate a Clean error rate improvement of up to 23.29% when employing LA in comparisons to the baseline. Additionally, it enhances robustness under common corruptions benchmark by up to 24.23%. When tested against FGSM and PGD attacks, improvements in adversarial robustness are noticeable, with enhancements of up to 53.18% for FGSM and 24.46% for PGD attacks.
<div id='section'>Paperid: <span id='pid'>1057, <a href='https://arxiv.org/pdf/2407.15739.pdf' target='_blank'>https://arxiv.org/pdf/2407.15739.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Silvio Galesso, Philipp SchrÃ¶ppel, Hssan Driss, Thomas Brox
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15739">Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, research on out-of-distribution (OoD) detection for semantic segmentation has mainly focused on road scenes -- a domain with a constrained amount of semantic diversity. In this work, we challenge this constraint and extend the domain of this task to general natural images. To this end, we introduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and includes images from diverse domains with a high semantic diversity, and 2. a novel approach that uses Diffusion score matching for OoD detection (DOoD) and is robust to the increased semantic diversity. ADE-OoD features indoor and outdoor images, defines 150 semantic categories as in-distribution, and contains a variety of OoD objects. For DOoD, we train a diffusion model with an MLP architecture on semantic in-distribution embeddings and build on the score matching interpretation to compute pixel-wise OoD scores at inference time. On common road scene OoD benchmarks, DOoD performs on par or better than the state of the art, without using outliers for training or making assumptions about the data domain. On ADE-OoD, DOoD outperforms previous approaches, but leaves much room for future improvements.
<div id='section'>Paperid: <span id='pid'>1058, <a href='https://arxiv.org/pdf/2406.11105.pdf' target='_blank'>https://arxiv.org/pdf/2406.11105.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Armando Zhu, Jiabei Liu, Keqin Li, Shuying Dai, Bo Hong, Peng Zhao, Changsong Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11105">Exploiting Diffusion Prior for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for deploying robust machine learning models, especially in areas where security is critical. However, traditional OOD detection methods often fail to capture complex data distributions from large scale date. In this paper, we present a novel approach for OOD detection that leverages the generative ability of diffusion models and the powerful feature extraction capabilities of CLIP. By using these features as conditional inputs to a diffusion model, we can reconstruct the images after encoding them with CLIP. The difference between the original and reconstructed images is used as a signal for OOD identification. The practicality and scalability of our method is increased by the fact that it does not require class-specific labeled ID data, as is the case with many other methods. Extensive experiments on several benchmark datasets demonstrates the robustness and effectiveness of our method, which have significantly improved the detection accuracy.
<div id='section'>Paperid: <span id='pid'>1059, <a href='https://arxiv.org/pdf/2406.05143.pdf' target='_blank'>https://arxiv.org/pdf/2406.05143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lane E. Schultz, Yiqi Wang, Ryan Jacobs, Dane Morgan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05143">A General Approach for Determining Applicability Domain of Machine Learning Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge of the domain of applicability of a machine learning model is essential to ensuring accurate and reliable model predictions. In this work, we develop a new and general approach of assessing model domain and demonstrate that our approach provides accurate and meaningful domain designation across multiple model types and material property data sets. Our approach assesses the distance between data in feature space using kernel density estimation, where this distance provides an effective tool for domain determination. We show that chemical groups considered unrelated based on chemical knowledge exhibit significant dissimilarities by our measure. We also show that high measures of dissimilarity are associated with poor model performance (i.e., high residual magnitudes) and poor estimates of model uncertainty (i.e., unreliable uncertainty estimation). Automated tools are provided to enable researchers to establish acceptable dissimilarity thresholds to identify whether new predictions of their own machine learning models are in-domain versus out-of-domain.
<div id='section'>Paperid: <span id='pid'>1060, <a href='https://arxiv.org/pdf/2406.02566.pdf' target='_blank'>https://arxiv.org/pdf/2406.02566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ognjen Kundacina, Vladimir Vincan, Dragisa Miskovic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02566">Combining X-Vectors and Bayesian Batch Active Learning: Two-Stage Active Learning Pipeline for Speech Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel two-stage active learning (AL) pipeline for automatic speech recognition (ASR), combining unsupervised and supervised AL methods. The first stage utilizes unsupervised AL by using x-vectors clustering for diverse sample selection from unlabeled speech data, thus establishing a robust initial dataset for the subsequent supervised AL. The second stage incorporates a supervised AL strategy, with a batch AL method specifically developed for ASR, aimed at selecting diverse and informative batches of samples. Here, sample diversity is also achieved using x-vectors clustering, while the most informative samples are identified using a Bayesian AL method tailored for ASR with an adaptation of Monte Carlo dropout to approximate Bayesian inference. This approach enables precise uncertainty estimation, thereby enhancing ASR model training with significantly reduced data requirements. Our method has shown superior performance compared to competing methods on homogeneous, heterogeneous, and OOD test sets, demonstrating that strategic sample selection and innovative Bayesian modeling can substantially optimize both labeling effort and data utilization in deep learning-based ASR applications.
<div id='section'>Paperid: <span id='pid'>1061, <a href='https://arxiv.org/pdf/2405.15130.pdf' target='_blank'>https://arxiv.org/pdf/2405.15130.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yueyue Liu, Hongyu Zhang, Yuantian Miao, Van-Hoang Le, Zhiqiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15130">OptLLM: Optimal Assignment of Queries to Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have garnered considerable attention owing to their remarkable capabilities, leading to an increasing number of companies offering LLMs as services. Different LLMs achieve different performance at different costs. A challenge for users lies in choosing the LLMs that best fit their needs, balancing cost and performance. In this paper, we propose a framework for addressing the cost-effective query allocation problem for LLMs. Given a set of input queries and candidate LLMs, our framework, named OptLLM, provides users with a range of optimal solutions to choose from, aligning with their budget constraints and performance preferences, including options for maximizing accuracy and minimizing cost. OptLLM predicts the performance of candidate LLMs on each query using a multi-label classification model with uncertainty estimation and then iteratively generates a set of non-dominated solutions by destructing and reconstructing the current solution. To evaluate the effectiveness of OptLLM, we conduct extensive experiments on various types of tasks, including text classification, question answering, sentiment analysis, reasoning, and log parsing. Our experimental results demonstrate that OptLLM substantially reduces costs by 2.40% to 49.18% while achieving the same accuracy as the best LLM. Compared to other multi-objective optimization algorithms, OptLLM improves accuracy by 2.94% to 69.05% at the same cost or saves costs by 8.79% and 95.87% while maintaining the highest attainable accuracy.
<div id='section'>Paperid: <span id='pid'>1062, <a href='https://arxiv.org/pdf/2405.15047.pdf' target='_blank'>https://arxiv.org/pdf/2405.15047.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaizheng Wang, Fabio Cuzzolin, Keivan Shariatmadar, David Moens, Hans Hallez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15047">Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents an innovative approach, called credal wrapper, to formulating a credal set representation of model averaging for Bayesian neural networks (BNNs) and deep ensembles (DEs), capable of improving uncertainty estimation in classification tasks. Given a finite collection of single predictive distributions derived from BNNs or DEs, the proposed credal wrapper approach extracts an upper and a lower probability bound per class, acknowledging the epistemic uncertainty due to the availability of a limited amount of distributions. Such probability intervals over classes can be mapped on a convex set of probabilities (a credal set) from which, in turn, a unique prediction can be obtained using a transformation called intersection probability transformation. In this article, we conduct extensive experiments on several out-of-distribution (OOD) detection benchmarks, encompassing various dataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C, CIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network architectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base). Compared to the BNN and DE baselines, the proposed credal wrapper method exhibits superior performance in uncertainty estimation and achieves a lower expected calibration error on corrupted data.
<div id='section'>Paperid: <span id='pid'>1063, <a href='https://arxiv.org/pdf/2405.08766.pdf' target='_blank'>https://arxiv.org/pdf/2405.08766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Claus Hofmann, Simon Schmid, Bernhard Lehner, Daniel Klotz, Sepp Hochreiter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08766">Energy-based Hopfield Boosting for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical when deploying machine learning models in the real world. Outlier exposure methods, which incorporate auxiliary outlier data in the training process, can drastically improve OOD detection performance compared to approaches without advanced training strategies. We introduce Hopfield Boosting, a boosting approach, which leverages modern Hopfield energy (MHE) to sharpen the decision boundary between the in-distribution and OOD data. Hopfield Boosting encourages the model to concentrate on hard-to-distinguish auxiliary outlier examples that lie close to the decision boundary between in-distribution and auxiliary outlier data. Our method achieves a new state-of-the-art in OOD detection with outlier exposure, improving the FPR95 metric from 2.28 to 0.92 on CIFAR-10 and from 11.76 to 7.94 on CIFAR-100.
<div id='section'>Paperid: <span id='pid'>1064, <a href='https://arxiv.org/pdf/2404.10474.pdf' target='_blank'>https://arxiv.org/pdf/2404.10474.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pietro Recalcati, Fabio Garcea, Luca Piano, Fabrizio Lamberti, Lia Morra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10474">Toward a Realistic Benchmark for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks are increasingly used in a wide range of technologies and services, but remain highly susceptible to out-of-distribution (OOD) samples, that is, drawn from a different distribution than the original training set. A common approach to address this issue is to endow deep neural networks with the ability to detect OOD samples. Several benchmarks have been proposed to design and validate OOD detection techniques. However, many of them are based on far-OOD samples drawn from very different distributions, and thus lack the complexity needed to capture the nuances of real-world scenarios. In this work, we introduce a comprehensive benchmark for OOD detection, based on ImageNet and Places365, that assigns individual classes as in-distribution or out-of-distribution depending on the semantic similarity with the training set. Several techniques can be used to determine which classes should be considered in-distribution, yielding benchmarks with varying properties. Experimental results on different OOD detection techniques show how their measured efficacy depends on the selected benchmark and how confidence-based techniques may outperform classifier-based ones on near-OOD samples.
<div id='section'>Paperid: <span id='pid'>1065, <a href='https://arxiv.org/pdf/2404.00546.pdf' target='_blank'>https://arxiv.org/pdf/2404.00546.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mubariz Zaffar, Liangliang Nan, Julian F. P. Kooij
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00546">On the Estimation of Image-matching Uncertainty in Visual Place Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In Visual Place Recognition (VPR) the pose of a query image is estimated by comparing the image to a map of reference images with known reference poses. As is typical for image retrieval problems, a feature extractor maps the query and reference images to a feature space, where a nearest neighbor search is then performed. However, till recently little attention has been given to quantifying the confidence that a retrieved reference image is a correct match. Highly certain but incorrect retrieval can lead to catastrophic failure of VPR-based localization pipelines. This work compares for the first time the main approaches for estimating the image-matching uncertainty, including the traditional retrieval-based uncertainty estimation, more recent data-driven aleatoric uncertainty estimation, and the compute-intensive geometric verification. We further formulate a simple baseline method, ``SUE'', which unlike the other methods considers the freely-available poses of the reference images in the map. Our experiments reveal that a simple L2-distance between the query and reference descriptors is already a better estimate of image-matching uncertainty than current data-driven approaches. SUE outperforms the other efficient uncertainty estimation methods, and its uncertainty estimates complement the computationally expensive geometric verification approach. Future works for uncertainty estimation in VPR should consider the baselines discussed in this work.
<div id='section'>Paperid: <span id='pid'>1066, <a href='https://arxiv.org/pdf/2403.05600.pdf' target='_blank'>https://arxiv.org/pdf/2403.05600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ha Manh Bui, Anqi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.05600">Density-Regression: Efficient and Distance-Aware Deep Regressor for Uncertainty Estimation under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Morden deep ensembles technique achieves strong uncertainty estimation performance by going through multiple forward passes with different models. This is at the price of a high storage space and a slow speed in the inference (test) time. To address this issue, we propose Density-Regression, a method that leverages the density function in uncertainty estimation and achieves fast inference by a single forward pass. We prove it is distance aware on the feature space, which is a necessary condition for a neural network to produce high-quality uncertainty estimation under distribution shifts. Empirically, we conduct experiments on regression tasks with the cubic toy dataset, benchmark UCI, weather forecast with time series, and depth estimation under real-world shifted applications. We show that Density-Regression has competitive uncertainty estimation performance under distribution shifts with modern deep regressors while using a lower model size and a faster inference speed.
<div id='section'>Paperid: <span id='pid'>1067, <a href='https://arxiv.org/pdf/2402.16875.pdf' target='_blank'>https://arxiv.org/pdf/2402.16875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adrian-Gabriel Chifu, SÃ©bastien DÃ©jean, Moncef Garouani, Josiane Mothe, DiÃ©go Ortiz, Md Zia Ullah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16875">Can we predict QPP? An approach based on multivariate outliers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Query performance prediction (QPP) aims to forecast the effectiveness of a search engine across a range of queries and documents. While state-of-the-art predictors offer a certain level of precision, their accuracy is not flawless. Prior research has recognized the challenges inherent in QPP but often lacks a thorough qualitative analysis. In this paper, we delve into QPP by examining the factors that influence the predictability of query performance accuracy. We propose the working hypothesis that while some queries are readily predictable, others present significant challenges. By focusing on outliers, we aim to identify the queries that are particularly challenging to predict. To this end, we employ multivariate outlier detection method. Our results demonstrate the effectiveness of this approach in identifying queries on which QPP do not perform well, yielding less reliable predictions. Moreover, we provide evidence that excluding these hard-to-predict queries from the analysis significantly enhances the overall accuracy of QPP.
<div id='section'>Paperid: <span id='pid'>1068, <a href='https://arxiv.org/pdf/2402.13531.pdf' target='_blank'>https://arxiv.org/pdf/2402.13531.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gavin Brown, Krishnamurthy Dvijotham, Georgina Evans, Daogao Liu, Adam Smith, Abhradeep Thakurta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.13531">Private Gradient Descent for Linear Regression: Tighter Error Bounds and Instance-Specific Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We provide an improved analysis of standard differentially private gradient descent for linear regression under the squared error loss. Under modest assumptions on the input, we characterize the distribution of the iterate at each time step.
  Our analysis leads to new results on the algorithm's accuracy: for a proper fixed choice of hyperparameters, the sample complexity depends only linearly on the dimension of the data. This matches the dimension-dependence of the (non-private) ordinary least squares estimator as well as that of recent private algorithms that rely on sophisticated adaptive gradient-clipping schemes (Varshney et al., 2022; Liu et al., 2023).
  Our analysis of the iterates' distribution also allows us to construct confidence intervals for the empirical optimizer which adapt automatically to the variance of the algorithm on a particular data set. We validate our theorems through experiments on synthetic data.
<div id='section'>Paperid: <span id='pid'>1069, <a href='https://arxiv.org/pdf/2402.09264.pdf' target='_blank'>https://arxiv.org/pdf/2402.09264.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Jia, Young D. Kwon, Dong Ma, Nhat Pham, Lorena Qendro, Tam Vu, Cecilia Mascolo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.09264">UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional machine learning techniques are prone to generating inaccurate predictions when confronted with shifts in the distribution of data between the training and testing phases. This vulnerability can lead to severe consequences, especially in applications such as mobile healthcare. Uncertainty estimation has the potential to mitigate this issue by assessing the reliability of a model's output. However, existing uncertainty estimation techniques often require substantial computational resources and memory, making them impractical for implementation on microcontrollers (MCUs). This limitation hinders the feasibility of many important on-device wearable event detection (WED) applications, such as heart attack detection.
  In this paper, we present UR2M, a novel Uncertainty and Resource-aware event detection framework for MCUs. Specifically, we (i) develop an uncertainty-aware WED based on evidential theory for accurate event detection and reliable uncertainty estimation; (ii) introduce a cascade ML framework to achieve efficient model inference via early exits, by sharing shallower model layers among different event models; (iii) optimize the deployment of the model and MCU library for system efficiency. We conducted extensive experiments and compared UR2M to traditional uncertainty baselines using three wearable datasets. Our results demonstrate that UR2M achieves up to 864% faster inference speed, 857% energy-saving for uncertainty estimation, 55% memory saving on two popular MCUs, and a 22% improvement in uncertainty quantification performance.
  UR2M can be deployed on a wide range of MCUs, significantly expanding real-time and reliable WED applications.
<div id='section'>Paperid: <span id='pid'>1070, <a href='https://arxiv.org/pdf/2402.00251.pdf' target='_blank'>https://arxiv.org/pdf/2402.00251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yao-Hung Hubert Tsai, Walter Talbott, Jian Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00251">Efficient Non-Parametric Uncertainty Quantification for Black-Box Large Language Models and Decision Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Step-by-step decision planning with large language models (LLMs) is gaining attention in AI agent development. This paper focuses on decision planning with uncertainty estimation to address the hallucination problem in language models. Existing approaches are either white-box or computationally demanding, limiting use of black-box proprietary LLMs within budgets. The paper's first contribution is a non-parametric uncertainty quantification method for LLMs, efficiently estimating point-wise dependencies between input-decision on the fly with a single inference, without access to token logits. This estimator informs the statistical interpretation of decision trustworthiness. The second contribution outlines a systematic design for a decision-making agent, generating actions like ``turn on the bathroom light'' based on user prompts such as ``take a bath''. Users will be asked to provide preferences when more than one action has high estimated point-wise dependencies. In conclusion, our uncertainty estimation and decision-making agent design offer a cost-efficient approach for AI agent development.
<div id='section'>Paperid: <span id='pid'>1071, <a href='https://arxiv.org/pdf/2401.07271.pdf' target='_blank'>https://arxiv.org/pdf/2401.07271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sheng Zhang, Minheng Chen, Junxian Wu, Ziyue Zhang, Tonglong Li, Cheng Xue, Youyong Kong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.07271">SpineCLUE: Automatic Vertebrae Identification Using Contrastive Learning and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vertebrae identification in arbitrary fields-of-view plays a crucial role in diagnosing spine disease. Most spine CT contain only local regions, such as the neck, chest, and abdomen. Therefore, identification should not depend on specific vertebrae or a particular number of vertebrae being visible. Existing methods at the spine-level are unable to meet this challenge. In this paper, we propose a three-stage method to address the challenges in 3D CT vertebrae identification at vertebrae-level. By sequentially performing the tasks of vertebrae localization, segmentation, and identification, the anatomical prior information of the vertebrae is effectively utilized throughout the process. Specifically, we introduce a dual-factor density clustering algorithm to acquire localization information for individual vertebra, thereby facilitating subsequent segmentation and identification processes. In addition, to tackle the issue of interclass similarity and intra-class variability, we pre-train our identification network by using a supervised contrastive learning method. To further optimize the identification results, we estimated the uncertainty of the classification network and utilized the message fusion module to combine the uncertainty scores, while aggregating global information about the spine. Our method achieves state-of-the-art results on the VerSe19 and VerSe20 challenge benchmarks. Additionally, our approach demonstrates outstanding generalization performance on an collected dataset containing a wide range of abnormal cases.
<div id='section'>Paperid: <span id='pid'>1072, <a href='https://arxiv.org/pdf/2401.02914.pdf' target='_blank'>https://arxiv.org/pdf/2401.02914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Parvin Malekzadeh, Ming Hou, Konstantinos N. Plataniotis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02914">A unified uncertainty-aware exploration: Combining epistemic and aleatory uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Exploration is a significant challenge in practical reinforcement learning (RL), and uncertainty-aware exploration that incorporates the quantification of epistemic and aleatory uncertainty has been recognized as an effective exploration strategy. However, capturing the combined effect of aleatory and epistemic uncertainty for decision-making is difficult. Existing works estimate aleatory and epistemic uncertainty separately and consider the composite uncertainty as an additive combination of the two. Nevertheless, the additive formulation leads to excessive risk-taking behavior, causing instability. In this paper, we propose an algorithm that clarifies the theoretical connection between aleatory and epistemic uncertainty, unifies aleatory and epistemic uncertainty estimation, and quantifies the combined effect of both uncertainties for a risk-sensitive exploration. Our method builds on a novel extension of distributional RL that estimates a parameterized return distribution whose parameters are random variables encoding epistemic uncertainty. Experimental results on tasks with exploration and risk challenges show that our method outperforms alternative approaches.
<div id='section'>Paperid: <span id='pid'>1073, <a href='https://arxiv.org/pdf/2401.01021.pdf' target='_blank'>https://arxiv.org/pdf/2401.01021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Butian Xiong, Liguang Zhou, Tin Lun Lam, Yangsheng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01021">Class Relevance Learning For Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image classification plays a pivotal role across diverse applications, yet challenges persist when models are deployed in real-world scenarios. Notably, these models falter in detecting unfamiliar classes that were not incorporated during classifier training, a formidable hurdle for safe and effective real-world model deployment, commonly known as out-of-distribution (OOD) detection. While existing techniques, like max logits, aim to leverage logits for OOD identification, they often disregard the intricate interclass relationships that underlie effective detection. This paper presents an innovative class relevance learning method tailored for OOD detection. Our method establishes a comprehensive class relevance learning framework, strategically harnessing interclass relationships within the OOD pipeline. This framework significantly augments OOD detection capabilities. Extensive experimentation on diverse datasets, encompassing generic image classification datasets (Near OOD and Far OOD datasets), demonstrates the superiority of our method over state-of-the-art alternatives for OOD detection.
<div id='section'>Paperid: <span id='pid'>1074, <a href='https://arxiv.org/pdf/2312.15297.pdf' target='_blank'>https://arxiv.org/pdf/2312.15297.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gianni Franchi, Olivier Laurent, Maxence LeguÃ©ry, Andrei Bursuc, Andrea Pilzer, Angela Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.15297">Make Me a BNN: A Simple Strategy for Estimating Bayesian Uncertainty from Pre-trained Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Neural Networks (DNNs) are powerful tools for various computer vision tasks, yet they often struggle with reliable uncertainty quantification - a critical requirement for real-world applications. Bayesian Neural Networks (BNN) are equipped for uncertainty estimation but cannot scale to large DNNs that are highly unstable to train. To address this challenge, we introduce the Adaptable Bayesian Neural Network (ABNN), a simple and scalable strategy to seamlessly transform DNNs into BNNs in a post-hoc manner with minimal computational and training overheads. ABNN preserves the main predictive properties of DNNs while enhancing their uncertainty quantification abilities through simple BNN adaptation layers (attached to normalization layers) and a few fine-tuning steps on pre-trained models. We conduct extensive experiments across multiple datasets for image classification and semantic segmentation tasks, and our results demonstrate that ABNN achieves state-of-the-art performance without the computational budget typically associated with ensemble methods.
<div id='section'>Paperid: <span id='pid'>1075, <a href='https://arxiv.org/pdf/2311.00377.pdf' target='_blank'>https://arxiv.org/pdf/2311.00377.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Dirmeier, Ye Hong, Yanan Xin, Fernando Perez-Cruz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00377">Uncertainty quantification and out-of-distribution detection using surjective normalizing flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable quantification of epistemic and aleatoric uncertainty is of crucial importance in applications where models are trained in one environment but applied to multiple different environments, often seen in real-world applications for example, in climate science or mobility analysis. We propose a simple approach using surjective normalizing flows to identify out-of-distribution data sets in deep neural network models that can be computed in a single forward pass. The method builds on recent developments in deep uncertainty quantification and generative modeling with normalizing flows. We apply our method to a synthetic data set that has been simulated using a mechanistic model from the mobility literature and several data sets simulated from interventional distributions induced by soft and atomic interventions on that model, and demonstrate that our method can reliably discern out-of-distribution data from in-distribution data. We compare the surjective flow model to a Dirichlet process mixture model and a bijective flow and find that the surjections are a crucial component to reliably distinguish in-distribution from out-of-distribution data.
<div id='section'>Paperid: <span id='pid'>1076, <a href='https://arxiv.org/pdf/2309.12038.pdf' target='_blank'>https://arxiv.org/pdf/2309.12038.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yitian Shi, Philipp Schillinger, Miroslav Gabriel, Alexander Qualmann, Zohar Feldman, Hanna Ziesche, Ngo Anh Vien
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.12038">Uncertainty-driven Exploration Strategies for Online Grasp Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing grasp prediction approaches are mostly based on offline learning, while, ignoring the exploratory grasp learning during online adaptation to new picking scenarios, i.e., objects that are unseen or out-of-domain (OOD), camera and bin settings, etc. In this paper, we present an uncertainty-based approach for online learning of grasp predictions for robotic bin picking. Specifically, the online learning algorithm with an effective exploration strategy can significantly improve its adaptation performance to unseen environment settings. To this end, we first propose to formulate online grasp learning as an RL problem that will allow us to adapt both grasp reward prediction and grasp poses. We propose various uncertainty estimation schemes based on Bayesian uncertainty quantification and distributional ensembles. We carry out evaluations on real-world bin picking scenes of varying difficulty. The objects in the bin have various challenging physical and perceptual characteristics that can be characterized by semi- or total transparency, and irregular or curved surfaces. The results of our experiments demonstrate a notable improvement of grasp performance in comparison to conventional online learning methods which incorporate only naive exploration strategies. Video: https://youtu.be/fPKOrjC2QrU
<div id='section'>Paperid: <span id='pid'>1077, <a href='https://arxiv.org/pdf/2309.09593.pdf' target='_blank'>https://arxiv.org/pdf/2309.09593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex C. Stutts, Danilo Erricolo, Sathya Ravi, Theja Tulabandhula, Amit Ranjan Trivedi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.09593">Mutual Information-calibrated Conformal Feature Fusion for Uncertainty-Aware Multimodal 3D Object Detection at the Edge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the expanding landscape of AI-enabled robotics, robust quantification of predictive uncertainties is of great importance. Three-dimensional (3D) object detection, a critical robotics operation, has seen significant advancements; however, the majority of current works focus only on accuracy and ignore uncertainty quantification. Addressing this gap, our novel study integrates the principles of conformal inference (CI) with information theoretic measures to perform lightweight, Monte Carlo-free uncertainty estimation within a multimodal framework. Through a multivariate Gaussian product of the latent variables in a Variational Autoencoder (VAE), features from RGB camera and LiDAR sensor data are fused to improve the prediction accuracy. Normalized mutual information (NMI) is leveraged as a modulator for calibrating uncertainty bounds derived from CI based on a weighted loss function. Our simulation results show an inverse correlation between inherent predictive uncertainty and NMI throughout the model's training. The framework demonstrates comparable or better performance in KITTI 3D object detection benchmarks to similar methods that are not uncertainty-aware, making it suitable for real-time edge robotics.
<div id='section'>Paperid: <span id='pid'>1078, <a href='https://arxiv.org/pdf/2309.09505.pdf' target='_blank'>https://arxiv.org/pdf/2309.09505.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shunit Truzman, Guy Revach, Nir Shlezinger, Itzik Klein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.09505">Outlier-Insensitive Kalman Filtering: Theory and Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State estimation of dynamical systems from noisy observations is a fundamental task in many applications. It is commonly addressed using the linear Kalman filter (KF), whose performance can significantly degrade in the presence of outliers in the observations, due to the sensitivity of its convex quadratic objective function. To mitigate such behavior, outlier detection algorithms can be applied. In this work, we propose a parameter-free algorithm which mitigates the harmful effect of outliers while requiring only a short iterative process of the standard update step of the KF. To that end, we model each potential outlier as a normal process with unknown variance and apply online estimation through either expectation maximization or alternating maximization algorithms. Simulations and field experiment evaluations demonstrate competitive performance of our method, showcasing its robustness to outliers in filtering scenarios compared to alternative algorithms.
<div id='section'>Paperid: <span id='pid'>1079, <a href='https://arxiv.org/pdf/2309.08642.pdf' target='_blank'>https://arxiv.org/pdf/2309.08642.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Jiang, Zhongkai Yi, Li Wang, Hanwei Zhang, Jihai Zhang, Fangquan Lin, Cheng Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.08642">A Stochastic Online Forecast-and-Optimize Framework for Real-Time Energy Dispatch in Virtual Power Plants under Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Aggregating distributed energy resources in power systems significantly increases uncertainties, in particular caused by the fluctuation of renewable energy generation. This issue has driven the necessity of widely exploiting advanced predictive control techniques under uncertainty to ensure long-term economics and decarbonization. In this paper, we propose a real-time uncertainty-aware energy dispatch framework, which is composed of two key elements: (i) A hybrid forecast-and-optimize sequential task, integrating deep learning-based forecasting and stochastic optimization, where these two stages are connected by the uncertainty estimation at multiple temporal resolutions; (ii) An efficient online data augmentation scheme, jointly involving model pre-training and online fine-tuning stages. In this way, the proposed framework is capable to rapidly adapt to the real-time data distribution, as well as to target on uncertainties caused by data drift, model discrepancy and environment perturbations in the control process, and finally to realize an optimal and robust dispatch solution. The proposed framework won the championship in CityLearn Challenge 2022, which provided an influential opportunity to investigate the potential of AI application in the energy domain. In addition, comprehensive experiments are conducted to interpret its effectiveness in the real-life scenario of smart building energy management.
<div id='section'>Paperid: <span id='pid'>1080, <a href='https://arxiv.org/pdf/2309.05153.pdf' target='_blank'>https://arxiv.org/pdf/2309.05153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaxuan Zhu, Jianwen Xie, Yingnian Wu, Ruiqi Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05153">Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training energy-based models (EBMs) on high-dimensional data can be both challenging and time-consuming, and there exists a noticeable gap in sample quality between EBMs and other generative frameworks like GANs and diffusion models. To close this gap, inspired by the recent efforts of learning EBMs by maximizing diffusion recovery likelihood (DRL), we propose cooperative diffusion recovery likelihood (CDRL), an effective approach to tractably learn and sample from a series of EBMs defined on increasingly noisy versions of a dataset, paired with an initializer model for each EBM. At each noise level, the two models are jointly estimated within a cooperative training framework: samples from the initializer serve as starting points that are refined by a few MCMC sampling steps from the EBM. The EBM is then optimized by maximizing recovery likelihood, while the initializer model is optimized by learning from the difference between the refined samples and the initial samples. In addition, we made several practical designs for EBM training to further improve the sample quality. Combining these advances, our approach significantly boost the generation performance compared to existing EBM methods on CIFAR-10 and ImageNet datasets. We also demonstrate the effectiveness of our models for several downstream tasks, including classifier-free guided generation, compositional generation, image inpainting and out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>1081, <a href='https://arxiv.org/pdf/2308.06072.pdf' target='_blank'>https://arxiv.org/pdf/2308.06072.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julia Hornauer, Adrian Holzbock, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06072">Out-of-Distribution Detection for Monocular Depth Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In monocular depth estimation, uncertainty estimation approaches mainly target the data uncertainty introduced by image noise. In contrast to prior work, we address the uncertainty due to lack of knowledge, which is relevant for the detection of data not represented by the training distribution, the so-called out-of-distribution (OOD) data. Motivated by anomaly detection, we propose to detect OOD images from an encoder-decoder depth estimation model based on the reconstruction error. Given the features extracted with the fixed depth encoder, we train an image decoder for image reconstruction using only in-distribution data. Consequently, OOD images result in a high reconstruction error, which we use to distinguish between in- and out-of-distribution samples. We built our experiments on the standard NYU Depth V2 and KITTI benchmarks as in-distribution data. Our post hoc method performs astonishingly well on different models and outperforms existing uncertainty estimation approaches without modifying the trained encoder-decoder depth estimation model.
<div id='section'>Paperid: <span id='pid'>1082, <a href='https://arxiv.org/pdf/2308.01707.pdf' target='_blank'>https://arxiv.org/pdf/2308.01707.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian Wiederer, Julian Schmidt, Ulrich Kressel, Klaus Dietmayer, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.01707">Joint Out-of-Distribution Detection and Uncertainty Estimation for Trajectory Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the significant research efforts on trajectory prediction for automated driving, limited work exists on assessing the prediction reliability. To address this limitation we propose an approach that covers two sources of error, namely novel situations with out-of-distribution (OOD) detection and the complexity in in-distribution (ID) situations with uncertainty estimation. We introduce two modules next to an encoder-decoder network for trajectory prediction. Firstly, a Gaussian mixture model learns the probability density function of the ID encoder features during training, and then it is used to detect the OOD samples in regions of the feature space with low likelihood. Secondly, an error regression network is applied to the encoder, which learns to estimate the trajectory prediction error in supervised training. During inference, the estimated prediction error is used as the uncertainty. In our experiments, the combination of both modules outperforms the prior work in OOD detection and uncertainty estimation, on the Shifts robust trajectory prediction dataset by $2.8 \%$ and $10.1 \%$, respectively. The code is publicly available.
<div id='section'>Paperid: <span id='pid'>1083, <a href='https://arxiv.org/pdf/2307.14071.pdf' target='_blank'>https://arxiv.org/pdf/2307.14071.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junpeng Jing, Jiankun Li, Pengfei Xiong, Jiangyu Liu, Shuaicheng Liu, Yichen Guo, Xin Deng, Mai Xu, Lai Jiang, Leonid Sigal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.14071">Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Correlation based stereo matching has achieved outstanding performance, which pursues cost volume between two feature maps. Unfortunately, current methods with a fixed model do not work uniformly well across various datasets, greatly limiting their real-world applicability. To tackle this issue, this paper proposes a new perspective to dynamically calculate correlation for robust stereo matching. A novel Uncertainty Guided Adaptive Correlation (UGAC) module is introduced to robustly adapt the same model for different scenarios. Specifically, a variance-based uncertainty estimation is employed to adaptively adjust the sampling area during warping operation. Additionally, we improve the traditional non-parametric warping with learnable parameters, such that the position-specific weights can be learned. We show that by empowering the recurrent network with the UGAC module, stereo matching can be exploited more robustly and effectively. Extensive experiments demonstrate that our method achieves state-of-the-art performance over the ETH3D, KITTI, and Middlebury datasets when employing the same fixed model over these datasets without any retraining procedure. To target real-time applications, we further design a lightweight model based on UGAC, which also outperforms other methods over KITTI benchmarks with only 0.6 M parameters.
<div id='section'>Paperid: <span id='pid'>1084, <a href='https://arxiv.org/pdf/2307.10529.pdf' target='_blank'>https://arxiv.org/pdf/2307.10529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xueying Ding, Yue Zhao, Leman Akoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.10529">Fast Unsupervised Deep Outlier Model Selection with Hypernetworks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) finds many applications with a rich literature of numerous techniques. Deep neural network based OD (DOD) has seen a recent surge of attention thanks to the many advances in deep learning. In this paper, we consider a critical-yet-understudied challenge with unsupervised DOD, that is, effective hyperparameter (HP) tuning/model selection. While several prior work report the sensitivity of OD models to HPs, it becomes ever so critical for the modern DOD models that exhibit a long list of HPs. We introduce HYPER for tuning DOD models, tackling two fundamental challenges: (1) validation without supervision (due to lack of labeled anomalies), and (2) efficient search of the HP/model space (due to exponential growth in the number of HPs). A key idea is to design and train a novel hypernetwork (HN) that maps HPs onto optimal weights of the main DOD model. In turn, HYPER capitalizes on a single HN that can dynamically generate weights for many DOD models (corresponding to varying HPs), which offers significant speed-up. In addition, it employs meta-learning on historical OD tasks with labels to train a proxy validation function, likewise trained with our proposed HN efficiently. Extensive experiments on 35 OD tasks show that HYPER achieves high performance against 8 baselines with significant efficiency gains.
<div id='section'>Paperid: <span id='pid'>1085, <a href='https://arxiv.org/pdf/2307.08807.pdf' target='_blank'>https://arxiv.org/pdf/2307.08807.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Denis C. Ilie-Ablachim, Bogdan Dumitrescu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.08807">Anomaly Detection with Selective Dictionary Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper we present new methods of anomaly detection based on Dictionary Learning (DL) and Kernel Dictionary Learning (KDL). The main contribution consists in the adaption of known DL and KDL algorithms in the form of unsupervised methods, used for outlier detection. We propose a reduced kernel version (RKDL), which is useful for problems with large data sets, due to the large kernel matrix. We also improve the DL and RKDL methods by the use of a random selection of signals, which aims to eliminate the outliers from the training procedure. All our algorithms are introduced in an anomaly detection toolbox and are compared to standard benchmark results.
<div id='section'>Paperid: <span id='pid'>1086, <a href='https://arxiv.org/pdf/2307.01798.pdf' target='_blank'>https://arxiv.org/pdf/2307.01798.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaojiao Xiao, Qinmin Hu, Guanghui Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.01798">Edge-aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simultaneous multi-index quantification, segmentation, and uncertainty estimation of liver tumors on multi-modality non-contrast magnetic resonance imaging (NCMRI) are crucial for accurate diagnosis. However, existing methods lack an effective mechanism for multi-modality NCMRI fusion and accurate boundary information capture, making these tasks challenging. To address these issues, this paper proposes a unified framework, namely edge-aware multi-task network (EaMtNet), to associate multi-index quantification, segmentation, and uncertainty of liver tumors on the multi-modality NCMRI. The EaMtNet employs two parallel CNN encoders and the Sobel filters to extract local features and edge maps, respectively. The newly designed edge-aware feature aggregation module (EaFA) is used for feature fusion and selection, making the network edge-aware by capturing long-range dependency between feature and edge maps. Multi-tasking leverages prediction discrepancy to estimate uncertainty and improve segmentation and quantification performance. Extensive experiments are performed on multi-modality NCMRI with 250 clinical subjects. The proposed model outperforms the state-of-the-art by a large margin, achieving a dice similarity coefficient of 90.01$\pm$1.23 and a mean absolute error of 2.72$\pm$0.58 mm for MD. The results demonstrate the potential of EaMtNet as a reliable clinical-aided tool for medical image analysis.
<div id='section'>Paperid: <span id='pid'>1087, <a href='https://arxiv.org/pdf/2306.09686.pdf' target='_blank'>https://arxiv.org/pdf/2306.09686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Zeng, Guy Van den Broeck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09686">Collapsed Inference for Bayesian Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian neural networks (BNNs) provide a formalism to quantify and calibrate uncertainty in deep learning. Current inference approaches for BNNs often resort to few-sample estimation for scalability, which can harm predictive performance, while its alternatives tend to be computationally prohibitively expensive. We tackle this challenge by revealing a previously unseen connection between inference on BNNs and volume computation problems. With this observation, we introduce a novel collapsed inference scheme that performs Bayesian model averaging using collapsed samples. It improves over a Monte-Carlo sample by limiting sampling to a subset of the network weights while pairing it with some closed-form conditional distribution over the rest. A collapsed sample represents uncountably many models drawn from the approximate posterior and thus yields higher sample efficiency. Further, we show that the marginalization of a collapsed sample can be solved analytically and efficiently despite the non-linearity of neural networks by leveraging existing volume computation solvers. Our proposed use of collapsed samples achieves a balance between scalability and accuracy. On various regression and classification tasks, our collapsed Bayesian deep learning approach demonstrates significant improvements over existing methods and sets a new state of the art in terms of uncertainty estimation as well as predictive performance.
<div id='section'>Paperid: <span id='pid'>1088, <a href='https://arxiv.org/pdf/2306.06323.pdf' target='_blank'>https://arxiv.org/pdf/2306.06323.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiali Cui, Ying Nian Wu, Tian Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06323">Learning Joint Latent Space EBM Prior Model for Multi-layer Generator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper studies the fundamental problem of learning multi-layer generator models. The multi-layer generator model builds multiple layers of latent variables as a prior model on top of the generator, which benefits learning complex data distribution and hierarchical representations. However, such a prior model usually focuses on modeling inter-layer relations between latent variables by assuming non-informative (conditional) Gaussian distributions, which can be limited in model expressivity. To tackle this issue and learn more expressive prior models, we propose an energy-based model (EBM) on the joint latent space over all layers of latent variables with the multi-layer generator as its backbone. Such joint latent space EBM prior model captures the intra-layer contextual relations at each layer through layer-wise energy terms, and latent variables across different layers are jointly corrected. We develop a joint training scheme via maximum likelihood estimation (MLE), which involves Markov Chain Monte Carlo (MCMC) sampling for both prior and posterior distributions of the latent variables from different layers. To ensure efficient inference and learning, we further propose a variational training scheme where an inference model is used to amortize the costly posterior MCMC sampling. Our experiments demonstrate that the learned model can be expressive in generating high-quality images and capturing hierarchical features for better outlier detection.
<div id='section'>Paperid: <span id='pid'>1089, <a href='https://arxiv.org/pdf/2306.02800.pdf' target='_blank'>https://arxiv.org/pdf/2306.02800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Achim Hekler, Roman C. Maron, Sarah HaggenmÃ¼ller, Max Schmitt, Christoph Wies, Jochen S. Utikal, Friedegund Meier, Sarah Hobelsberger, Frank F. Gellrich, Mildred Sergon, Axel Hauschild, Lars E. French, Lucie Heinzerling, Justin G. Schlager, Kamran Ghoreschi, Max Schlaak, Franz J. Hilke, Gabriela Poch, SÃ¶ren Korsing, Carola Berking, Markus V. Heppt, Michael Erdmann, Sebastian Haferkamp, Konstantin Drexler, Dirk Schadendorf, Wiebke Sondermann, Matthias Goebeler, Bastian Schilling, Jakob N. Kather, Eva Krieghoff-Henning, Titus J. Brinker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02800">Using Multiple Dermoscopic Photographs of One Lesion Improves Melanoma Classification via Deep Learning: A Prognostic Diagnostic Accuracy Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Convolutional neural network (CNN)-based melanoma classifiers face several challenges that limit their usefulness in clinical practice. Objective: To investigate the impact of multiple real-world dermoscopic views of a single lesion of interest on a CNN-based melanoma classifier.
  Methods: This study evaluated 656 suspected melanoma lesions. Classifier performance was measured using area under the receiver operating characteristic curve (AUROC), expected calibration error (ECE) and maximum confidence change (MCC) for (I) a single-view scenario, (II) a multiview scenario using multiple artificially modified images per lesion and (III) a multiview scenario with multiple real-world images per lesion.
  Results: The multiview approach with real-world images significantly increased the AUROC from 0.905 (95% CI, 0.879-0.929) in the single-view approach to 0.930 (95% CI, 0.909-0.951). ECE and MCC also improved significantly from 0.131 (95% CI, 0.105-0.159) to 0.072 (95% CI: 0.052-0.093) and from 0.149 (95% CI, 0.125-0.171) to 0.115 (95% CI: 0.099-0.131), respectively. Comparing multiview real-world to artificially modified images showed comparable diagnostic accuracy and uncertainty estimation, but significantly worse robustness for the latter.
  Conclusion: Using multiple real-world images is an inexpensive method to positively impact the performance of a CNN-based melanoma classifier.
<div id='section'>Paperid: <span id='pid'>1090, <a href='https://arxiv.org/pdf/2304.01518.pdf' target='_blank'>https://arxiv.org/pdf/2304.01518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Myong Chol Jung, He Zhao, Joanna Dipnall, Lan Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.01518">Beyond Unimodal: Generalising Neural Processes for Multimodal Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is an important research area to make deep neural networks (DNNs) more trustworthy. While extensive research on uncertainty estimation has been conducted with unimodal data, uncertainty estimation for multimodal data remains a challenge. Neural processes (NPs) have been demonstrated to be an effective uncertainty estimation method for unimodal data by providing the reliability of Gaussian processes with efficient and powerful DNNs. While NPs hold significant potential for multimodal uncertainty estimation, the adaptation of NPs for multimodal data has not been carefully studied. To bridge this gap, we propose Multimodal Neural Processes (MNPs) by generalising NPs for multimodal uncertainty estimation. Based on the framework of NPs, MNPs consist of several novel and principled mechanisms tailored to the characteristics of multimodal data. In extensive empirical evaluation, our method achieves state-of-the-art multimodal uncertainty estimation performance, showing its appealing robustness against noisy samples and reliability in out-of-distribution detection with faster computation time compared to the current state-of-the-art multimodal uncertainty estimation method.
<div id='section'>Paperid: <span id='pid'>1091, <a href='https://arxiv.org/pdf/2304.01297.pdf' target='_blank'>https://arxiv.org/pdf/2304.01297.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacob Piland, Christopher Sweet, Priscila Saboia, Charles Vardeman, Adam Czajka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.01297">Non-Generative Energy Based Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Energy-based models (EBM) have become increasingly popular within computer vision. EBMs bring a probabilistic approach to training deep neural networks (DNN) and have been shown to enhance performance in areas such as calibration, out-of-distribution detection, and adversarial resistance. However, these advantages come at the cost of estimating input data probabilities, usually using a Langevin based method such as Stochastic Gradient Langevin Dynamics (SGLD), which bring additional computational costs, require parameterization, caching methods for efficiency, and can run into stability and scaling issues. EBMs use dynamical methods to draw samples from the probability density function (PDF) defined by the current state of the network and compare them to the training data using a maximum log likelihood approach to learn the correct PDF.
  We propose a non-generative training approach, Non-Generative EBM (NG-EBM), that utilizes the {\it{Approximate Mass}}, identified by Grathwohl et al., as a loss term to direct the training. We show that our NG-EBM training strategy retains many of the benefits of EBM in calibration, out-of-distribution detection, and adversarial resistance, but without the computational complexity and overhead of the traditional approaches. In particular, the NG-EBM approach improves the Expected Calibration Error by a factor of 2.5 for CIFAR10 and 7.5 times for CIFAR100, when compared to traditionally trained models.
<div id='section'>Paperid: <span id='pid'>1092, <a href='https://arxiv.org/pdf/2303.03242.pdf' target='_blank'>https://arxiv.org/pdf/2303.03242.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Raghav Mehta, Changjian Shui, Tal Arbel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03242">Evaluating the Fairness of Deep Learning Uncertainty Estimates in Medical Image Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although deep learning (DL) models have shown great success in many medical image analysis tasks, deployment of the resulting models into real clinical contexts requires: (1) that they exhibit robustness and fairness across different sub-populations, and (2) that the confidence in DL model predictions be accurately expressed in the form of uncertainties. Unfortunately, recent studies have indeed shown significant biases in DL models across demographic subgroups (e.g., race, sex, age) in the context of medical image analysis, indicating a lack of fairness in the models. Although several methods have been proposed in the ML literature to mitigate a lack of fairness in DL models, they focus entirely on the absolute performance between groups without considering their effect on uncertainty estimation. In this work, we present the first exploration of the effect of popular fairness models on overcoming biases across subgroups in medical image analysis in terms of bottom-line performance, and their effects on uncertainty quantification. We perform extensive experiments on three different clinically relevant tasks: (i) skin lesion classification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease clinical score regression. Our results indicate that popular ML methods, such as data-balancing and distributionally robust optimization, succeed in mitigating fairness issues in terms of the model performances for some of the tasks. However, this can come at the cost of poor uncertainty estimates associated with the model predictions. This tradeoff must be mitigated if fairness models are to be adopted in medical image analysis.
<div id='section'>Paperid: <span id='pid'>1093, <a href='https://arxiv.org/pdf/2303.02207.pdf' target='_blank'>https://arxiv.org/pdf/2303.02207.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex C. Stutts, Danilo Erricolo, Theja Tulabandhula, Amit Ranjan Trivedi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02207">Lightweight, Uncertainty-Aware Conformalized Visual Odometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven visual odometry (VO) is a critical subroutine for autonomous edge robotics, and recent progress in the field has produced highly accurate point predictions in complex environments. However, emerging autonomous edge robotics devices like insect-scale drones and surgical robots lack a computationally efficient framework to estimate VO's predictive uncertainties. Meanwhile, as edge robotics continue to proliferate into mission-critical application spaces, awareness of model's the predictive uncertainties has become crucial for risk-aware decision-making. This paper addresses this challenge by presenting a novel, lightweight, and statistically robust framework that leverages conformal inference (CI) to extract VO's uncertainty bands. Our approach represents the uncertainties using flexible, adaptable, and adjustable prediction intervals that, on average, guarantee the inclusion of the ground truth across all degrees of freedom (DOF) of pose estimation. We discuss the architectures of generative deep neural networks for estimating multivariate uncertainty bands along with point (mean) prediction. We also present techniques to improve the uncertainty estimation accuracy, such as leveraging Monte Carlo dropout (MC-dropout) for data augmentation. Finally, we propose a novel training loss function that combines interval scoring and calibration loss with traditional training metrics--mean-squared error and KL-divergence--to improve uncertainty-aware learning. Our simulation results demonstrate that the presented framework consistently captures true uncertainty in pose estimations across different datasets, estimation models, and applied noise types, indicating its wide applicability.
<div id='section'>Paperid: <span id='pid'>1094, <a href='https://arxiv.org/pdf/2303.00111.pdf' target='_blank'>https://arxiv.org/pdf/2303.00111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mevan Ekanayake, Kamlesh Pawar, Gary Egan, Zhaolin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00111">PixCUE: Joint Uncertainty Estimation and Image Reconstruction in MRI using Deep Pixel Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL) models are capable of successfully exploiting latent representations in MR data and have become state-of-the-art for accelerated MRI reconstruction. However, undersampling the measurements in k-space as well as the over- or under-parameterized and non-transparent nature of DL make these models exposed to uncertainty. Consequently, uncertainty estimation has become a major issue in DL MRI reconstruction. To estimate uncertainty, Monte Carlo (MC) inference techniques have become a common practice where multiple reconstructions are utilized to compute the variance in reconstruction as a measurement of uncertainty. However, these methods demand high computational costs as they require multiple inferences through the DL model. To this end, we introduce a method to estimate uncertainty during MRI reconstruction using a pixel classification framework. The proposed method, PixCUE (stands for Pixel Classification Uncertainty Estimation) produces the reconstructed image along with an uncertainty map during a single forward pass through the DL model. We demonstrate that this approach generates uncertainty maps that highly correlate with the reconstruction errors with respect to various MR imaging sequences and under numerous adversarial conditions. We also show that the estimated uncertainties are correlated to that of the conventional MC method. We further provide an empirical relationship between the uncertainty estimations using PixCUE and well-established reconstruction metrics such as NMSE, PSNR, and SSIM. We conclude that PixCUE is capable of reliably estimating the uncertainty in MRI reconstruction with a minimum additional computational cost.
<div id='section'>Paperid: <span id='pid'>1095, <a href='https://arxiv.org/pdf/2302.09913.pdf' target='_blank'>https://arxiv.org/pdf/2302.09913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tayyebeh Jahani-Nezhad, Mohammad Ali Maddah-Ali, Giuseppe Caire
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.09913">ByzSecAgg: A Byzantine-Resistant Secure Aggregation Scheme for Federated Learning Based on Coded Computing and Vector Commitment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose ByzSecAgg, an efficient secure aggregation scheme for federated learning that is resistant to Byzantine attacks and privacy leakages. Processing individual updates to manage adversarial behavior, while preserving the privacy of the data against colluding nodes, requires some sort of secure secret sharing. However, the communication load for secret sharing of long vectors of updates can be very high. In federated settings, where users are often edge devices with potential bandwidth constraints, excessive communication overhead is undesirable. ByzSecAgg solves this problem by partitioning local updates into smaller sub-vectors and sharing them using ramp secret sharing. However, this sharing method does not admit bilinear computations, such as pairwise distances calculations, which are needed for distance-based outlier-detection algorithms, and effective methods for mitigating Byzantine attacks. To overcome this issue, each user runs another round of ramp sharing, with a different embedding of the data in the sharing polynomial. This technique, motivated by ideas from coded computing, enables secure computation of pairwise distance. In addition, to maintain the integrity and privacy of the local update, ByzSecAgg also uses a vector commitment method, in which the commitment size remains constant (i.e., does not increase with the length of the local update), while simultaneously allowing verification of the secret sharing process. In terms of communication load, ByzSecAgg significantly outperforms the related baseline scheme, known as BREA.
<div id='section'>Paperid: <span id='pid'>1096, <a href='https://arxiv.org/pdf/2302.08875.pdf' target='_blank'>https://arxiv.org/pdf/2302.08875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Laurens Sluijterman, Eric Cator, Tom Heskes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08875">Optimal Training of Mean Variance Estimation Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper focusses on the optimal implementation of a Mean Variance Estimation network (MVE network) (Nix and Weigend, 1994). This type of network is often used as a building block for uncertainty estimation methods in a regression setting, for instance Concrete dropout (Gal et al., 2017) and Deep Ensembles (Lakshminarayanan et al., 2017). Specifically, an MVE network assumes that the data is produced from a normal distribution with a mean function and variance function. The MVE network outputs a mean and variance estimate and optimizes the network parameters by minimizing the negative loglikelihood. In our paper, we present two significant insights. Firstly, the convergence difficulties reported in recent work can be relatively easily prevented by following the simple yet often overlooked recommendation from the original authors that a warm-up period should be used. During this period, only the mean is optimized with a fixed variance. We demonstrate the effectiveness of this step through experimentation, highlighting that it should be standard practice. As a sidenote, we examine whether, after the warm-up, it is beneficial to fix the mean while optimizing the variance or to optimize both simultaneously. Here, we do not observe a substantial difference. Secondly, we introduce a novel improvement of the MVE network: separate regularization of the mean and the variance estimate. We demonstrate, both on toy examples and on a number of benchmark UCI regression data sets, that following the original recommendations and the novel separate regularization can lead to significant improvements.
<div id='section'>Paperid: <span id='pid'>1097, <a href='https://arxiv.org/pdf/2302.06495.pdf' target='_blank'>https://arxiv.org/pdf/2302.06495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ha Manh Bui, Anqi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.06495">Density-Softmax: Efficient Test-time Model for Uncertainty Estimation and Robustness under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sampling-based methods, e.g., Deep Ensembles and Bayesian Neural Nets have become promising approaches to improve the quality of uncertainty estimation and robust generalization. However, they suffer from a large model size and high latency at test-time, which limits the scalability needed for low-resource devices and real-time applications. To resolve these computational issues, we propose Density-Softmax, a sampling-free deterministic framework via combining a density function built on a Lipschitz-constrained feature extractor with the softmax layer. Theoretically, we show that our model is the solution of minimax uncertainty risk and is distance-aware on feature space, thus reducing the over-confidence of the standard softmax under distribution shifts. Empirically, our method enjoys competitive results with state-of-the-art techniques in terms of uncertainty and robustness, while having a lower number of model parameters and a lower latency at test-time.
<div id='section'>Paperid: <span id='pid'>1098, <a href='https://arxiv.org/pdf/2302.05807.pdf' target='_blank'>https://arxiv.org/pdf/2302.05807.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeremiah Zhe Liu, Krishnamurthy Dj Dvijotham, Jihyeon Lee, Quan Yuan, Martin Strobel, Balaji Lakshminarayanan, Deepak Ramachandran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05807">Pushing the Accuracy-Group Robustness Frontier with Introspective Self-play</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard empirical risk minimization (ERM) training can produce deep neural network (DNN) models that are accurate on average but under-perform in under-represented population subgroups, especially when there are imbalanced group distributions in the long-tailed training data. Therefore, approaches that improve the accuracy-group robustness trade-off frontier of a DNN model (i.e. improving worst-group accuracy without sacrificing average accuracy, or vice versa) is of crucial importance. Uncertainty-based active learning (AL) can potentially improve the frontier by preferentially sampling underrepresented subgroups to create a more balanced training dataset. However, the quality of uncertainty estimates from modern DNNs tend to degrade in the presence of spurious correlations and dataset bias, compromising the effectiveness of AL for sampling tail groups. In this work, we propose Introspective Self-play (ISP), a simple approach to improve the uncertainty estimation of a deep neural network under dataset bias, by adding an auxiliary introspection task requiring a model to predict the bias for each data point in addition to the label. We show that ISP provably improves the bias-awareness of the model representation and the resulting uncertainty estimates. On two real-world tabular and language tasks, ISP serves as a simple "plug-in" for AL model training, consistently improving both the tail-group sampling rate and the final accuracy-fairness trade-off frontier of popular AL methods.
<div id='section'>Paperid: <span id='pid'>1099, <a href='https://arxiv.org/pdf/2302.05608.pdf' target='_blank'>https://arxiv.org/pdf/2302.05608.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhu Wang, Sourav Medya, Sathya N. Ravi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05608">Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Often, deep network models are purely inductive during training and while performing inference on unseen data. Thus, when such models are used for predictions, it is well known that they often fail to capture the semantic information and implicit dependencies that exist among objects (or concepts) on a population level. Moreover, it is still unclear how domain or prior modal knowledge can be specified in a backpropagation friendly manner, especially in large-scale and noisy settings. In this work, we propose an end-to-end vision and language model incorporating explicit knowledge graphs. We also introduce an interactive out-of-distribution (OOD) layer using implicit network operator. The layer is used to filter noise that is brought by external knowledge base. In practice, we apply our model on several vision and language downstream tasks including visual question answering, visual reasoning, and image-text retrieval on different datasets. Our experiments show that it is possible to design models that perform similarly to state-of-art results but with significantly fewer samples and training time.
<div id='section'>Paperid: <span id='pid'>1100, <a href='https://arxiv.org/pdf/2302.04132.pdf' target='_blank'>https://arxiv.org/pdf/2302.04132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lily H. Zhang, Rajesh Ranganath
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.04132">Robustness to Spurious Correlations Improves Semantic Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Methods which utilize the outputs or feature representations of predictive models have emerged as promising approaches for out-of-distribution (OOD) detection of image inputs. However, these methods struggle to detect OOD inputs that share nuisance values (e.g. background) with in-distribution inputs. The detection of shared-nuisance out-of-distribution (SN-OOD) inputs is particularly relevant in real-world applications, as anomalies and in-distribution inputs tend to be captured in the same settings during deployment. In this work, we provide a possible explanation for SN-OOD detection failures and propose nuisance-aware OOD detection to address them. Nuisance-aware OOD detection substitutes a classifier trained via empirical risk minimization and cross-entropy loss with one that 1. is trained under a distribution where the nuisance-label relationship is broken and 2. yields representations that are independent of the nuisance under this distribution, both marginally and conditioned on the label. We can train a classifier to achieve these objectives using Nuisance-Randomized Distillation (NuRD), an algorithm developed for OOD generalization under spurious correlations. Output- and feature-based nuisance-aware OOD detection perform substantially better than their original counterparts, succeeding even when detection based on domain generalization algorithms fails to improve performance.
<div id='section'>Paperid: <span id='pid'>1101, <a href='https://arxiv.org/pdf/2209.12693.pdf' target='_blank'>https://arxiv.org/pdf/2209.12693.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christoph Balada, Max Bondorf, Sheraz Ahmed, Andreas Dengela, Markus Zdrallek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.12693">Leveraging the Potential of Novel Data in Power Line Communication of Electricity Grids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electricity grids have become an essential part of daily life, even if they are often not noticed in everyday life. We usually only become particularly aware of this dependence by the time the electricity grid is no longer available. However, significant changes, such as the transition to renewable energy (photovoltaic, wind turbines, etc.) and an increasing number of energy consumers with complex load profiles (electric vehicles, home battery systems, etc.), pose new challenges for the electricity grid. To address these challenges, we propose two first-of-its-kind datasets based on measurements in a broadband powerline communications (PLC) infrastructure. Both datasets FiN-1 and FiN-2, were collected during real practical use in a part of the German low-voltage grid that supplies around 4.4 million people and show more than 13 billion datapoints collected by more than 5100 sensors. In addition, we present different use cases in asset management, grid state visualization, forecasting, predictive maintenance, and novelty detection to highlight the benefits of these types of data. For these applications, we particularly highlight the use of novel machine learning architectures to extract rich information from real-world data that cannot be captured using traditional approaches. By publishing the first large-scale real-world dataset, we aim to shed light on the previously largely unrecognized potential of PLC data and emphasize machine-learning-based research in low-voltage distribution networks by presenting a variety of different use cases.
<div id='section'>Paperid: <span id='pid'>1102, <a href='https://arxiv.org/pdf/2207.13730.pdf' target='_blank'>https://arxiv.org/pdf/2207.13730.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Takuya Kanazawa, Haiyan Wang, Chetan Gupta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.13730">Distributional Actor-Critic Ensemble for Uncertainty-Aware Continuous Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification is one of the central challenges for machine learning in real-world applications. In reinforcement learning, an agent confronts two kinds of uncertainty, called epistemic uncertainty and aleatoric uncertainty. Disentangling and evaluating these uncertainties simultaneously stands a chance of improving the agent's final performance, accelerating training, and facilitating quality assurance after deployment. In this work, we propose an uncertainty-aware reinforcement learning algorithm for continuous control tasks that extends the Deep Deterministic Policy Gradient algorithm (DDPG). It exploits epistemic uncertainty to accelerate exploration and aleatoric uncertainty to learn a risk-sensitive policy. We conduct numerical experiments showing that our variant of DDPG outperforms vanilla DDPG without uncertainty estimation in benchmark tasks on robotic control and power-grid optimization.
<div id='section'>Paperid: <span id='pid'>1103, <a href='https://arxiv.org/pdf/2202.10903.pdf' target='_blank'>https://arxiv.org/pdf/2202.10903.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Laurens Sluijterman, Eric Cator, Tom Heskes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.10903">Confident Neural Network Regression with Bootstrapped Deep Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rise of the popularity and usage of neural networks, trustworthy uncertainty estimation is becoming increasingly essential. One of the most prominent uncertainty estimation methods is Deep Ensembles (Lakshminarayanan et al., 2017) . A classical parametric model has uncertainty in the parameters due to the fact that the data on which the model is build is a random sample. A modern neural network has an additional uncertainty component since the optimization of the network is random. Lakshminarayanan et al. (2017) noted that Deep Ensembles do not incorporate the classical uncertainty induced by the effect of finite data. In this paper, we present a computationally cheap extension of Deep Ensembles for the regression setting, called Bootstrapped Deep Ensembles, that explicitly takes this classical effect of finite data into account using a modified version of the parametric bootstrap. We demonstrate through an experimental study that our method significantly improves upon standard Deep Ensembles
<div id='section'>Paperid: <span id='pid'>1104, <a href='https://arxiv.org/pdf/2202.10872.pdf' target='_blank'>https://arxiv.org/pdf/2202.10872.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adnan Theerens, Oliver Urs Lenz, Chris Cornelis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.10872">Choquet-Based Fuzzy Rough Sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fuzzy rough set theory can be used as a tool for dealing with inconsistent data when there is a gradual notion of indiscernibility between objects. It does this by providing lower and upper approximations of concepts. In classical fuzzy rough sets, the lower and upper approximations are determined using the minimum and maximum operators, respectively. This is undesirable for machine learning applications, since it makes these approximations sensitive to outlying samples. To mitigate this problem, ordered weighted average (OWA) based fuzzy rough sets were introduced. In this paper, we show how the OWA-based approach can be interpreted intuitively in terms of vague quantification, and then generalize it to Choquet-based fuzzy rough sets (CFRS). This generalization maintains desirable theoretical properties, such as duality and monotonicity. Furthermore, it provides more flexibility for machine learning applications. In particular, we show that it enables the seamless integration of outlier detection algorithms, to enhance the robustness of machine learning algorithms based on fuzzy rough sets.
<div id='section'>Paperid: <span id='pid'>1105, <a href='https://arxiv.org/pdf/2101.09193.pdf' target='_blank'>https://arxiv.org/pdf/2101.09193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Petra BevandiÄ, Ivan KreÅ¡o, Marin OrÅ¡iÄ, SiniÅ¡a Å egviÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2101.09193">Dense outlier detection and open-set recognition based on training with noisy negative images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep convolutional models often produce inadequate predictions for inputs foreign to the training distribution. Consequently, the problem of detecting outlier images has recently been receiving a lot of attention. Unlike most previous work, we address this problem in the dense prediction context in order to be able to locate outlier objects in front of in-distribution background. Our approach is based on two reasonable assumptions. First, we assume that the inlier dataset is related to some narrow application field (e.g.~road driving). Second, we assume that there exists a general-purpose dataset which is much more diverse than the inlier dataset (e.g.~ImageNet-1k). We consider pixels from the general-purpose dataset as noisy negative training samples since most (but not all) of them are outliers. We encourage the model to recognize borders between known and unknown by pasting jittered negative patches over inlier training images. Our experiments target two dense open-set recognition benchmarks (WildDash 1 and Fishyscapes) and one dense open-set recognition dataset (StreetHazard). Extensive performance evaluation indicates competitive potential of the proposed approach.
<div id='section'>Paperid: <span id='pid'>1106, <a href='https://arxiv.org/pdf/1910.06588.pdf' target='_blank'>https://arxiv.org/pdf/1910.06588.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanyuan Wei, Julian Jang-Jaccard, Fariza Sabrina, Timothy McIntosh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1910.06588">MSD-Kmeans: A Novel Algorithm for Efficient Detection of Global and Local Outliers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection is a technique in data mining that aims to detect unusual or unexpected records in the dataset. Existing outlier detection algorithms have different pros and cons and exhibit different sensitivity to noisy data such as extreme values. In this paper, we propose a novel cluster-based outlier detection algorithm named MSD-Kmeans that combines the statistical method of Mean and Standard Deviation (MSD) and the machine learning clustering algorithm K-means to detect outliers more accurately with the better control of extreme values. There are two phases in this combination method of MSD-Kmeans: (1) applying MSD algorithm to eliminate as many noisy data to minimize the interference on clusters, and (2) applying K-means algorithm to obtain local optimal clusters. We evaluate our algorithm and demonstrate its effectiveness in the context of detecting possible overcharging of taxi fares, as greedy dishonest drivers may attempt to charge high fares by detouring. We compare the performance indicators of MSD-Kmeans with those of other outlier detection algorithms, such as MSD, K-means, Z-score, MIQR and LOF, and prove that the proposed MSD-Kmeans algorithm achieves the highest measure of precision, accuracy, and F-measure. We conclude that MSD-Kmeans can be used for effective and efficient outlier detection on data of varying quality on IoT devices.
<div id='section'>Paperid: <span id='pid'>1107, <a href='https://arxiv.org/pdf/2510.06505.pdf' target='_blank'>https://arxiv.org/pdf/2510.06505.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Momin Abbas, Ali Falahati, Hossein Goli, Mohammad Mohammadi Amiri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06505">A Median Perspective on Unlabeled Data for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection plays a crucial role in ensuring the robustness and reliability of machine learning systems deployed in real-world applications. Recent approaches have explored the use of unlabeled data, showing potential for enhancing OOD detection capabilities. However, effectively utilizing unlabeled in-the-wild data remains challenging due to the mixed nature of both in-distribution (InD) and OOD samples. The lack of a distinct set of OOD samples complicates the task of training an optimal OOD classifier. In this work, we introduce Medix, a novel framework designed to identify potential outliers from unlabeled data using the median operation. We use the median because it provides a stable estimate of the central tendency, as an OOD detection mechanism, due to its robustness against noise and outliers. Using these identified outliers, along with labeled InD data, we train a robust OOD classifier. From a theoretical perspective, we derive error bounds that demonstrate Medix achieves a low error rate. Empirical results further substantiate our claims, as Medix outperforms existing methods across the board in open-world settings, confirming the validity of our theoretical insights.
<div id='section'>Paperid: <span id='pid'>1108, <a href='https://arxiv.org/pdf/2510.01456.pdf' target='_blank'>https://arxiv.org/pdf/2510.01456.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brett Barkley, Preston Culbertson, David Fridovich-Keil
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01456">SCOPED: Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for reliable deployment of machine learning systems in vision, robotics, reinforcement learning, and beyond. We introduce Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion (SCOPED), a fast and general-purpose OOD detection method for diffusion models that reduces the number of forward passes on the trained model by an order of magnitude compared to prior methods, outperforming most diffusion-based baselines and closely approaching the accuracy of the strongest ones. SCOPED is computed from a single diffusion model trained once on a diverse dataset, and combines the Jacobian trace and squared norm of the model's score function into a single test statistic. Rather than thresholding on a fixed value, we estimate the in-distribution density of SCOPED scores using kernel density estimation, enabling a flexible, unsupervised test that, in the simplest case, only requires a single forward pass and one Jacobian-vector product (JVP), made efficient by Hutchinson's trace estimator. On four vision benchmarks, SCOPED achieves competitive or state-of-the-art precision-recall scores despite its low computational cost. The same method generalizes to robotic control tasks with shared state and action spaces, identifying distribution shifts across reward functions and training regimes. These results position SCOPED as a practical foundation for fast and reliable OOD detection in real-world domains, including perceptual artifacts in vision, outlier detection in autoregressive models, exploration in reinforcement learning, and dataset curation for unsupervised training.
<div id='section'>Paperid: <span id='pid'>1109, <a href='https://arxiv.org/pdf/2509.24492.pdf' target='_blank'>https://arxiv.org/pdf/2509.24492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charmaine Barker, Daniel Bethell, Simos Gerasimou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24492">Guided Uncertainty Learning Using a Post-Hoc Evidential Meta-Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty quantification remains a major obstacle to the deployment of deep learning models under distributional shift. Existing post-hoc approaches that retrofit pretrained models either inherit misplaced confidence or merely reshape predictions, without teaching the model when to be uncertain. We introduce GUIDE, a lightweight evidential learning meta-model approach that attaches to a frozen deep learning model and explicitly learns how and when to be uncertain. GUIDE identifies salient internal features via a calibration stage, and then employs these features to construct a noise-driven curriculum that teaches the model how and when to express uncertainty. GUIDE requires no retraining, no architectural modifications, and no manual intermediate-layer selection to the base deep learning model, thus ensuring broad applicability and minimal user intervention. The resulting model avoids distilling overconfidence from the base model, improves out-of-distribution detection by ~77% and adversarial attack detection by ~80%, while preserving in-distribution performance. Across diverse benchmarks, GUIDE consistently outperforms state-of-the-art approaches, evidencing the need for actively guiding uncertainty to close the gap between predictive confidence and reliability.
<div id='section'>Paperid: <span id='pid'>1110, <a href='https://arxiv.org/pdf/2509.21593.pdf' target='_blank'>https://arxiv.org/pdf/2509.21593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peng Luo, Xiayin Lou, Yu Zheng, Zhuo Zheng, Stefano Ermon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21593">GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geospatial modeling provides critical solutions for pressing global challenges such as sustainability and climate change. Existing large language model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at evolving generic code but lack the domain knowledge and multi-step reasoning required for complex geospatial problems. We introduce GeoEvolve, a multi-agent LLM framework that couples evolutionary search with geospatial domain knowledge to automatically design and refine geospatial algorithms. GeoEvolve operates in two nested loops: an inner loop leverages a code evolver to generate and mutate candidate solutions, while an outer agentic controller evaluates global elites and queries a GeoKnowRAG module -- a structured geospatial knowledge base that injects theoretical priors from geography. This knowledge-guided evolution steers the search toward theoretically meaningful and computationally efficient algorithms. We evaluate GeoEvolve on two fundamental and classical tasks: spatial interpolation (kriging) and spatial uncertainty quantification (geospatial conformal prediction). Across these benchmarks, GeoEvolve automatically improves and discovers new algorithms, incorporating geospatial theory on top of classical models. It reduces spatial interpolation error (RMSE) by 13-21% and enhances uncertainty estimation performance by 17\%. Ablation studies confirm that domain-guided retrieval is essential for stable, high-quality evolution. These results demonstrate that GeoEvolve provides a scalable path toward automated, knowledge-driven geospatial modeling, opening new opportunities for trustworthy and efficient AI-for-Science discovery.
<div id='section'>Paperid: <span id='pid'>1111, <a href='https://arxiv.org/pdf/2509.15403.pdf' target='_blank'>https://arxiv.org/pdf/2509.15403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangyi Li, Mengdi Huai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15403">Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have shown strong capabilities, enabling concise, context-aware answers in question answering (QA) tasks. The lack of transparency in complex LLMs has inspired extensive research aimed at developing methods to explain large language behaviors. Among existing explanation methods, natural language explanations stand out due to their ability to explain LLMs in a self-explanatory manner and enable the understanding of model behaviors even when the models are closed-source. However, despite these promising advancements, there is no existing work studying how to provide valid uncertainty guarantees for these generated natural language explanations. Such uncertainty quantification is critical in understanding the confidence behind these explanations. Notably, generating valid uncertainty estimates for natural language explanations is particularly challenging due to the auto-regressive generation process of LLMs and the presence of noise in medical inquiries. To bridge this gap, in this work, we first propose a novel uncertainty estimation framework for these generated natural language explanations, which provides valid uncertainty guarantees in a post-hoc and model-agnostic manner. Additionally, we also design a novel robust uncertainty estimation method that maintains valid uncertainty guarantees even under noise. Extensive experiments on QA tasks demonstrate the desired performance of our methods.
<div id='section'>Paperid: <span id='pid'>1112, <a href='https://arxiv.org/pdf/2509.12772.pdf' target='_blank'>https://arxiv.org/pdf/2509.12772.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Damola Agbelese, Krishna Chaitanya, Pushpak Pati, Chaitanya Parmar, Pooya Mobadersany, Shreyas Fadnavis, Lindsey Surace, Shadi Yarandi, Louis R. Ghanem, Molly Lucas, Tommaso Mansi, Oana Gabriela Cula, Pablo F. Damasceno, Kristopher Standish
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12772">MEGAN: Mixture of Experts for Robust Uncertainty Estimation in Endoscopy Videos</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty quantification (UQ) is essential in medical AI. Evidential Deep Learning (EDL) offers a computationally efficient way to quantify model uncertainty alongside predictions, unlike traditional methods such as Monte Carlo (MC) Dropout and Deep Ensembles (DE). However, all these methods often rely on a single expert's annotations as ground truth for model training, overlooking the inter-rater variability in healthcare. To address this issue, we propose MEGAN, a Multi-Expert Gating Network that aggregates uncertainty estimates and predictions from multiple AI experts via EDL models trained with diverse ground truths and modeling strategies. MEGAN's gating network optimally combines predictions and uncertainties from each EDL model, enhancing overall prediction confidence and calibration. We extensively benchmark MEGAN on endoscopy videos for Ulcerative colitis (UC) disease severity estimation, assessed by visual labeling of Mayo Endoscopic Subscore (MES), where inter-rater variability is prevalent. In large-scale prospective UC clinical trial, MEGAN achieved a 3.5% improvement in F1-score and a 30.5% reduction in Expected Calibration Error (ECE) compared to existing methods. Furthermore, MEGAN facilitated uncertainty-guided sample stratification, reducing the annotation burden and potentially increasing efficiency and consistency in UC trials.
<div id='section'>Paperid: <span id='pid'>1113, <a href='https://arxiv.org/pdf/2509.10914.pdf' target='_blank'>https://arxiv.org/pdf/2509.10914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Somayeh Kianpisheh, Tarik Taleb, Jari Iinatti, JaeSeung Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10914">Deep Learning based Moving Target Defence for Federated Learning against Poisoning Attack in MEC Systems with a 6G Wireless Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Collaboration opportunities for devices are facilitated with Federated Learning (FL). Edge computing facilitates aggregation at edge and reduces latency. To deal with model poisoning attacks, model-based outlier detection mechanisms may not operate efficiently with hetereogenous models or in recognition of complex attacks. This paper fosters the defense line against model poisoning attack by exploiting device-level traffic analysis to anticipate the reliability of participants. FL is empowered with a topology mutation strategy, as a Moving Target Defence (MTD) strategy to dynamically change the participants in learning. Based on the adoption of recurrent neural networks for time-series analysis of traffic and a 6G wireless model, optimization framework for MTD strategy is given. A deep reinforcement mechanism is provided to optimize topology mutation in adaption with the anticipated Byzantine status of devices and the communication channel capabilities at devices. For a DDoS attack detection application and under Botnet attack at devices level, results illustrate acceptable malicious models exclusion and improvement in recognition time and accuracy.
<div id='section'>Paperid: <span id='pid'>1114, <a href='https://arxiv.org/pdf/2509.08846.pdf' target='_blank'>https://arxiv.org/pdf/2509.08846.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>H. Martin Gillis, Isaac Xu, Thomas Trappenberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08846">Uncertainty Estimation using Variance-Gated Distributions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evaluation of per-sample uncertainty quantification from neural networks is essential for decision-making involving high-risk applications. A common approach is to use the predictive distribution from Bayesian or approximation models and decompose the corresponding predictive uncertainty into epistemic (model-related) and aleatoric (data-related) components. However, additive decomposition has recently been questioned. In this work, we propose an intuitive framework for uncertainty estimation and decomposition based on the signal-to-noise ratio of class probability distributions across different model predictions. We introduce a variance-gated measure that scales predictions by a confidence factor derived from ensembles. We use this measure to discuss the existence of a collapse in the diversity of committee machines.
<div id='section'>Paperid: <span id='pid'>1115, <a href='https://arxiv.org/pdf/2508.18473.pdf' target='_blank'>https://arxiv.org/pdf/2508.18473.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Li, Akshayaa Magesh, Venugopal V. Veeravalli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18473">Principled Detection of Hallucinations in Large Language Models via Multiple Testing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While Large Language Models (LLMs) have emerged as powerful foundational models to solve a variety of tasks, they have also been shown to be prone to hallucinations, i.e., generating responses that sound confident but are actually incorrect or even nonsensical. In this work, we formulate the problem of detecting hallucinations as a hypothesis testing problem and draw parallels to the problem of out-of-distribution detection in machine learning models. We propose a multiple-testing-inspired method to solve the hallucination detection problem, and provide extensive experimental results to validate the robustness of our approach against state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1116, <a href='https://arxiv.org/pdf/2508.04457.pdf' target='_blank'>https://arxiv.org/pdf/2508.04457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Baur, Wojciech Samek, Jackie Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04457">Benchmarking Uncertainty and its Disentanglement in multi-label Chest X-Ray Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty quantification is crucial for trustworthy decision-making and the deployment of AI models in medical imaging. While prior work has explored the ability of neural networks to quantify predictive, epistemic, and aleatoric uncertainties using an information-theoretical approach in synthetic or well defined data settings like natural image classification, its applicability to real life medical diagnosis tasks remains underexplored. In this study, we provide an extensive uncertainty quantification benchmark for multi-label chest X-ray classification using the MIMIC-CXR-JPG dataset. We evaluate 13 uncertainty quantification methods for convolutional (ResNet) and transformer-based (Vision Transformer) architectures across a wide range of tasks. Additionally, we extend Evidential Deep Learning, HetClass NNs, and Deep Deterministic Uncertainty to the multi-label setting. Our analysis provides insights into uncertainty estimation effectiveness and the ability to disentangle epistemic and aleatoric uncertainties, revealing method- and architecture-specific strengths and limitations.
<div id='section'>Paperid: <span id='pid'>1117, <a href='https://arxiv.org/pdf/2507.13486.pdf' target='_blank'>https://arxiv.org/pdf/2507.13486.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Debao Huang, Rongjun Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13486">Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification of the photogrammetry process is essential for providing per-point accuracy credentials of the point clouds. Unlike airborne LiDAR, which typically delivers consistent accuracy across various scenes, the accuracy of photogrammetric point clouds is highly scene-dependent, since it relies on algorithm-generated measurements (i.e., stereo or multi-view stereo). Generally, errors of the photogrammetric point clouds propagate through a two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA), followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM stage has been well studied using the first-order statistics of the reprojection error function, that in the MVS stage remains largely unsolved and non-standardized, primarily due to its non-differentiable and multi-modal nature (i.e., from pixel values to geometry). In this paper, we present an uncertainty quantification framework closing this gap by associating an error covariance matrix per point accounting for this two-step photogrammetry process. Specifically, to estimate the uncertainty in the MVS stage, we propose a novel, self-calibrating method by taking reliable n-view points (n>=6) per-view to regress the disparity uncertainty using highly relevant cues (such as matching cost values) from the MVS stage. Compared to existing approaches, our method uses self-contained, reliable 3D points extracted directly from the MVS process, with the benefit of being self-supervised and naturally adhering to error propagation path of the photogrammetry process, thereby providing a robust and certifiable uncertainty quantification across diverse scenes. We evaluate the framework using a variety of publicly available airborne and UAV imagery datasets. Results demonstrate that our method outperforms existing approaches by achieving high bounding rates without overestimating uncertainty.
<div id='section'>Paperid: <span id='pid'>1118, <a href='https://arxiv.org/pdf/2506.22994.pdf' target='_blank'>https://arxiv.org/pdf/2506.22994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Hakan DaÄÄ±dÄ±r, Mia Hubert, Peter J. Rousseeuw
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22994">Kernel Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A new anomaly detection method called kernel outlier detection (KOD) is proposed. It is designed to address challenges of outlier detection in high-dimensional settings. The aim is to overcome limitations of existing methods, such as dependence on distributional assumptions or on hyperparameters that are hard to tune. KOD starts with a kernel transformation, followed by a projection pursuit approach. Its novelties include a new ensemble of directions to search over, and a new way to combine results of different direction types. This provides a flexible and lightweight approach for outlier detection. Our empirical evaluations illustrate the effectiveness of KOD on three small datasets with challenging structures, and on four large benchmark datasets.
<div id='section'>Paperid: <span id='pid'>1119, <a href='https://arxiv.org/pdf/2506.21142.pdf' target='_blank'>https://arxiv.org/pdf/2506.21142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Deepak Kumar Panda, Weisi Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21142">Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing integration of UAVs into civilian airspace underscores the need for resilient and intelligent intrusion detection systems (IDS), as traditional anomaly detection methods often fail to identify novel threats. A common approach treats unfamiliar attacks as out-of-distribution (OOD) samples; however, this leaves systems vulnerable when mitigation is inadequate. Moreover, conventional OOD detectors struggle to distinguish stealthy adversarial attacks from genuine OOD events. This paper introduces a conditional generative adversarial network (cGAN)-based framework for crafting stealthy adversarial attacks that evade IDS mechanisms. We first design a robust multi-class IDS classifier trained on benign UAV telemetry and known cyber-attacks, including Denial of Service (DoS), false data injection (FDI), man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN perturbs known attacks to generate adversarial samples that misclassify as benign while retaining statistical resemblance to OOD distributions. These adversarial samples are iteratively refined to achieve high stealth and success rates. To detect such perturbations, we implement a conditional variational autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based regret scores significantly outperform traditional Mahalanobis distance-based detectors in identifying stealthy adversarial threats. Our findings emphasize the importance of advanced probabilistic modeling to strengthen IDS capabilities against adaptive, generative-model-based cyber intrusions.
<div id='section'>Paperid: <span id='pid'>1120, <a href='https://arxiv.org/pdf/2506.16724.pdf' target='_blank'>https://arxiv.org/pdf/2506.16724.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyi Liu, Weiguang Wang, Hangfeng He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16724">The Role of Model Confidence on Bias Effects in Measured Uncertainties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases induce greater changes in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence leads to greater underestimation of epistemic uncertainty (i.e. overconfidence) due to bias, whereas it has no significant effect on the direction of changes in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.
<div id='section'>Paperid: <span id='pid'>1121, <a href='https://arxiv.org/pdf/2506.16724.pdf' target='_blank'>https://arxiv.org/pdf/2506.16724.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyi Liu, Weiguang Wang, Hangfeng He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16724">The Role of Model Confidence on Bias Effects in Measured Uncertainties for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases have greater effects in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence is associated with greater bias-induced underestimation of epistemic uncertainty, resulting in overconfident estimates, whereas it has no significant effect on the direction of bias effect in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.
<div id='section'>Paperid: <span id='pid'>1122, <a href='https://arxiv.org/pdf/2506.16416.pdf' target='_blank'>https://arxiv.org/pdf/2506.16416.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Timans, Rajeev Verma, Eric Nalisnick, Christian A. Naesseth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16416">On Continuous Monitoring of Risk Violations under Unknown Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning systems deployed in the real world must operate under dynamic and often unpredictable distribution shifts. This challenges the validity of statistical safety assurances on the system's risk established beforehand. Common risk control frameworks rely on fixed assumptions and lack mechanisms to continuously monitor deployment reliability. In this work, we propose a general framework for the real-time monitoring of risk violations in evolving data streams. Leveraging the 'testing by betting' paradigm, we propose a sequential hypothesis testing procedure to detect violations of bounded risks associated with the model's decision-making mechanism, while ensuring control on the false alarm rate. Our method operates under minimal assumptions on the nature of encountered shifts, rendering it broadly applicable. We illustrate the effectiveness of our approach by monitoring risks in outlier detection and set prediction under a variety of shifts.
<div id='section'>Paperid: <span id='pid'>1123, <a href='https://arxiv.org/pdf/2506.15850.pdf' target='_blank'>https://arxiv.org/pdf/2506.15850.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Mendes, Paolo Romano, David Garlan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15850">Uncertainty Estimation by Human Perception versus Neural Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern neural networks (NNs) often achieve high predictive accuracy but are poorly calibrated, producing overconfident predictions even when wrong. This miscalibration poses serious challenges in applications where reliable uncertainty estimates are critical. In this work, we investigate how human perceptual uncertainty compares to uncertainty estimated by NNs. Using three vision benchmarks annotated with both human disagreement and crowdsourced confidence, we assess the correlation between model-predicted uncertainty and human-perceived uncertainty. Our results show that current methods only weakly align with human intuition, with correlations varying significantly across tasks and uncertainty metrics. Notably, we find that incorporating human-derived soft labels into the training process can improve calibration without compromising accuracy. These findings reveal a persistent gap between model and human uncertainty and highlight the potential of leveraging human insights to guide the development of more trustworthy AI systems.
<div id='section'>Paperid: <span id='pid'>1124, <a href='https://arxiv.org/pdf/2506.15518.pdf' target='_blank'>https://arxiv.org/pdf/2506.15518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giulio Delama, Igor Borowski, Roland Jung, Stephan Weiss
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15518">Real-Time Initialization of Unknown Anchors for UWB-aided Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a framework for the real-time initialization of unknown Ultra-Wideband (UWB) anchors in UWB-aided navigation systems. The method is designed for localization solutions where UWB modules act as supplementary sensors. Our approach enables the automatic detection and calibration of previously unknown anchors during operation, removing the need for manual setup. By combining an online Positional Dilution of Precision (PDOP) estimation, a lightweight outlier detection method, and an adaptive robust kernel for non-linear optimization, our approach significantly improves robustness and suitability for real-world applications compared to state-of-the-art. In particular, we show that our metric which triggers an initialization decision is more conservative than current ones commonly based on initial linear or non-linear initialization guesses. This allows for better initialization geometry and subsequently lower initialization errors. We demonstrate the proposed approach on two different mobile robots: an autonomous forklift and a quadcopter equipped with a UWB-aided Visual-Inertial Odometry (VIO) framework. The results highlight the effectiveness of the proposed method with robust initialization and low positioning error. We open-source our code in a C++ library including a ROS wrapper.
<div id='section'>Paperid: <span id='pid'>1125, <a href='https://arxiv.org/pdf/2506.13508.pdf' target='_blank'>https://arxiv.org/pdf/2506.13508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jungeon Kim, Geonsoo Park, Seungyong Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13508">Multiview Geometric Regularization of Gaussian Splatting for Accurate Radiance Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent methods, such as 2D Gaussian Splatting and Gaussian Opacity Fields, have aimed to address the geometric inaccuracies of 3D Gaussian Splatting while retaining its superior rendering quality. However, these approaches still struggle to reconstruct smooth and reliable geometry, particularly in scenes with significant color variation across viewpoints, due to their per-point appearance modeling and single-view optimization constraints. In this paper, we propose an effective multiview geometric regularization strategy that integrates multiview stereo (MVS) depth, RGB, and normal constraints into Gaussian Splatting initialization and optimization. Our key insight is the complementary relationship between MVS-derived depth points and Gaussian Splatting-optimized positions: MVS robustly estimates geometry in regions of high color variation through local patch-based matching and epipolar constraints, whereas Gaussian Splatting provides more reliable and less noisy depth estimates near object boundaries and regions with lower color variation. To leverage this insight, we introduce a median depth-based multiview relative depth loss with uncertainty estimation, effectively integrating MVS depth information into Gaussian Splatting optimization. We also propose an MVS-guided Gaussian Splatting initialization to avoid Gaussians falling into suboptimal positions. Extensive experiments validate that our approach successfully combines these strengths, enhancing both geometric accuracy and rendering quality across diverse indoor and outdoor scenes.
<div id='section'>Paperid: <span id='pid'>1126, <a href='https://arxiv.org/pdf/2506.06048.pdf' target='_blank'>https://arxiv.org/pdf/2506.06048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haripriya Harikumar, Santu Rana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06048">TRUST: Test-time Resource Utilization for Superior Trustworthiness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard uncertainty estimation techniques, such as dropout, often struggle to clearly distinguish reliable predictions from unreliable ones. We attribute this limitation to noisy classifier weights, which, while not impairing overall class-level predictions, render finer-level statistics less informative. To address this, we propose a novel test-time optimization method that accounts for the impact of such noise to produce more reliable confidence estimates. This score defines a monotonic subset-selection function, where population accuracy consistently increases as samples with lower scores are removed, and it demonstrates superior performance in standard risk-based metrics such as AUSE and AURC. Additionally, our method effectively identifies discrepancies between training and test distributions, reliably differentiates in-distribution from out-of-distribution samples, and elucidates key differences between CNN and ViT classifiers across various vision datasets.
<div id='section'>Paperid: <span id='pid'>1127, <a href='https://arxiv.org/pdf/2505.22803.pdf' target='_blank'>https://arxiv.org/pdf/2505.22803.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Mendes, Paolo Romano, David Garlan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22803">CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation is critical for deploying neural networks (NNs) in real-world applications. While existing calibration techniques often rely on post-hoc adjustments or coarse-grained binning methods, they remain limited in scalability, differentiability, and generalization across domains. In this work, we introduce CLUE (Calibration via Learning Uncertainty-Error Alignment), a novel approach that explicitly aligns predicted uncertainty with observed error during training, grounded in the principle that well-calibrated models should produce uncertainty estimates that match their empirical loss. CLUE adopts a novel loss function that jointly optimizes predictive performance and calibration, using summary statistics of uncertainty and loss as proxies. The proposed method is fully differentiable, domain-agnostic, and compatible with standard training pipelines. Through extensive experiments on vision, regression, and language modeling tasks, including out-of-distribution and domain-shift scenarios, we demonstrate that CLUE achieves superior calibration quality and competitive predictive performance with respect to state-of-the-art approaches without imposing significant computational overhead.
<div id='section'>Paperid: <span id='pid'>1128, <a href='https://arxiv.org/pdf/2505.13585.pdf' target='_blank'>https://arxiv.org/pdf/2505.13585.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinzhu Liang, Joseph M. Lukens, Sanjaya Lohani, Brian T. Kirby, Thomas A. Searles, Xin Qiu, Kody J. H. Law
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13585">Scalable Bayesian Monte Carlo: fast uncertainty estimation beyond deep ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces a new method designed for Bayesian deep learning called scalable Bayesian Monte Carlo (SBMC). The method is comprised of a model and an algorithm. The model interpolates between a point estimator and the posterior. The algorithm is a parallel implementation of sequential Monte Carlo sampler (SMC$_\parallel$) or Markov chain Monte Carlo (MCMC$_\parallel$). We collectively refer to these consistent (asymptotically unbiased) algorithms as Bayesian Monte Carlo (BMC), and any such algorithm can be used in our SBMC method. The utility of the method is demonstrated on practical examples: MNIST, CIFAR, IMDb. A systematic numerical study reveals that for the same wall-clock time as state-of-the-art (SOTA) methods like deep ensembles (DE), SBMC achieves comparable or better accuracy and substantially improved uncertainty quantification (UQ)--in particular, epistemic UQ. This is demonstrated on the downstream task of estimating the confidence in predictions, which can be used for reliability assessment or abstention decisions.
<div id='section'>Paperid: <span id='pid'>1129, <a href='https://arxiv.org/pdf/2505.07459.pdf' target='_blank'>https://arxiv.org/pdf/2505.07459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07459">Why Uncertainty Estimation Methods Fall Short in RAG: An Axiomatic Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are valued for their strong performance across various tasks, but they also produce inaccurate or misleading outputs. Uncertainty Estimation (UE) quantifies the model's confidence and helps users assess response reliability. However, existing UE methods have not been thoroughly examined in scenarios like Retrieval-Augmented Generation (RAG), where the input prompt includes non-parametric knowledge. This paper shows that current UE methods cannot reliably assess correctness in the RAG setting. We further propose an axiomatic framework to identify deficiencies in existing methods and guide the development of improved approaches. Our framework introduces five constraints that an effective UE method should meet after incorporating retrieved documents into the LLM's prompt. Experimental results reveal that no existing UE method fully satisfies all the axioms, explaining their suboptimal performance in RAG. We further introduce a simple yet effective calibration function based on our framework, which not only satisfies more axioms than baseline methods but also improves the correlation between uncertainty estimates and correctness.
<div id='section'>Paperid: <span id='pid'>1130, <a href='https://arxiv.org/pdf/2505.04986.pdf' target='_blank'>https://arxiv.org/pdf/2505.04986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qian Peng, Yajie Bao, Haojie Ren, Zhaojun Wang, Changliang Zou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04986">Conformal Prediction with Cellwise Outliers: A Detect-then-Impute Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformal prediction is a powerful tool for constructing prediction intervals for black-box models, providing a finite sample coverage guarantee for exchangeable data. However, this exchangeability is compromised when some entries of the test feature are contaminated, such as in the case of cellwise outliers. To address this issue, this paper introduces a novel framework called detect-then-impute conformal prediction. This framework first employs an outlier detection procedure on the test feature and then utilizes an imputation method to fill in those cells identified as outliers. To quantify the uncertainty in the processed test feature, we adaptively apply the detection and imputation procedures to the calibration set, thereby constructing exchangeable features for the conformal prediction interval of the test label. We develop two practical algorithms, PDI-CP and JDI-CP, and provide a distribution-free coverage analysis under some commonly used detection and imputation procedures. Notably, JDI-CP achieves a finite sample $1-2Î±$ coverage guarantee. Numerical experiments on both synthetic and real datasets demonstrate that our proposed algorithms exhibit robust coverage properties and comparable efficiency to the oracle baseline.
<div id='section'>Paperid: <span id='pid'>1131, <a href='https://arxiv.org/pdf/2505.02299.pdf' target='_blank'>https://arxiv.org/pdf/2505.02299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daisuke Yamada, Harit Vishwakarma, Ramya Korlakai Vinayak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02299">Adaptive Scoring and Thresholding with Human Feedback for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine Learning (ML) models are trained on in-distribution (ID) data but often encounter out-of-distribution (OOD) inputs during deployment -- posing serious risks in safety-critical domains. Recent works have focused on designing scoring functions to quantify OOD uncertainty, with score thresholds typically set based solely on ID data to achieve a target true positive rate (TPR), since OOD data is limited before deployment. However, these TPR-based thresholds leave false positive rates (FPR) uncontrolled, often resulting in high FPRs where OOD points are misclassified as ID. Moreover, fixed scoring functions and thresholds lack the adaptivity needed to handle newly observed, evolving OOD inputs, leading to sub-optimal performance. To address these challenges, we propose a human-in-the-loop framework that \emph{safely updates both scoring functions and thresholds on the fly} based on real-world OOD inputs. Our method maximizes TPR while strictly controlling FPR at all times, even as the system adapts over time. We provide theoretical guarantees for FPR control under stationary conditions and present extensive empirical evaluations on OpenOOD benchmarks to demonstrate that our approach outperforms existing methods by achieving higher TPRs while maintaining FPR control.
<div id='section'>Paperid: <span id='pid'>1132, <a href='https://arxiv.org/pdf/2504.20863.pdf' target='_blank'>https://arxiv.org/pdf/2504.20863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sven Goblirsch, Benedikt Ruhland, Johannes Betz, Markus Lienkamp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20863">Bayesian Optimization-based Tire Parameter and Uncertainty Estimation for Real-World Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents a methodology to estimate tire parameters and their uncertainty using a Bayesian optimization approach. The literature mainly considers the estimation of tire parameters but lacks an evaluation of the parameter identification quality and the required slip ratios for an adequate model fit. Therefore, we examine the use of Stochastical Variational Inference as a methodology to estimate both - the parameters and their uncertainties. We evaluate the method compared to a state-of-the-art Nelder-Mead algorithm for theoretical and real-world application. The theoretical study considers parameter fitting at different slip ratios to evaluate the required excitation for an adequate fitting of each parameter. The results are compared to a sensitivity analysis for a Pacejka Magic Formula tire model. We show the application of the algorithm on real-world data acquired during the Abu Dhabi Autonomous Racing League and highlight the uncertainties in identifying the curvature and shape parameters due to insufficient excitation. The gathered insights can help assess the acquired data's limitations and instead utilize standardized parameters until higher slip ratios are captured. We show that our proposed method can be used to assess the mean values and the uncertainties of tire model parameters in real-world conditions and derive actions for the tire modeling based on our simulative study.
<div id='section'>Paperid: <span id='pid'>1133, <a href='https://arxiv.org/pdf/2504.20862.pdf' target='_blank'>https://arxiv.org/pdf/2504.20862.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dayananda Herurkar, JÃ¶rn Hees, Vesselin Tzvetkov, Andreas Dengel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20862">Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The remarkable success of Deep Learning approaches is often based and demonstrated on large public datasets. However, when applying such approaches to internal, private datasets, one frequently faces challenges arising from structural differences in the datasets, domain shift, and the lack of labels. In this work, we introduce Tabular Data Adapters (TDA), a novel method for generating soft labels for unlabeled tabular data in outlier detection tasks. By identifying statistically similar public datasets and transforming private data (based on a shared autoencoder) into a format compatible with state-of-the-art public models, our approach enables the generation of weak labels. It thereby can help to mitigate the cold start problem of labeling by basing on existing outlier detection models for public datasets. In experiments on 50 tabular datasets across different domains, we demonstrate that our method is able to provide more accurate annotations than baseline approaches while reducing computational time. Our approach offers a scalable, efficient, and cost-effective solution, to bridge the gap between public research models and real-world industrial applications.
<div id='section'>Paperid: <span id='pid'>1134, <a href='https://arxiv.org/pdf/2504.15846.pdf' target='_blank'>https://arxiv.org/pdf/2504.15846.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonah Ekelund, Savvas Raptis, Vicki Toy-Edens, Wenli Mo, Drew L. Turner, Ian J. Cohen, Stefano Markidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15846">Adaptive PCA-Based Outlier Detection for Multi-Feature Time Series in Space Missions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Analyzing multi-featured time series data is critical for space missions making efficient event detection, potentially onboard, essential for automatic analysis. However, limited onboard computational resources and data downlink constraints necessitate robust methods for identifying regions of interest in real time. This work presents an adaptive outlier detection algorithm based on the reconstruction error of Principal Component Analysis (PCA) for feature reduction, designed explicitly for space mission applications. The algorithm adapts dynamically to evolving data distributions by using Incremental PCA, enabling deployment without a predefined model for all possible conditions. A pre-scaling process normalizes each feature's magnitude while preserving relative variance within feature types. We demonstrate the algorithm's effectiveness in detecting space plasma events, such as distinct space environments, dayside and nightside transients phenomena, and transition layers through NASA's MMS mission observations. Additionally, we apply the method to NASA's THEMIS data, successfully identifying a dayside transient using onboard-available measurements.
<div id='section'>Paperid: <span id='pid'>1135, <a href='https://arxiv.org/pdf/2504.15722.pdf' target='_blank'>https://arxiv.org/pdf/2504.15722.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Huang, Simone Rossi, Rui Yuan, Thomas Hannagan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15722">From predictions to confidence intervals: an empirical study of conformal prediction methods for in-context learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformers have become a standard architecture in machine learning, demonstrating strong in-context learning (ICL) abilities that allow them to learn from the prompt at inference time. However, uncertainty quantification for ICL remains an open challenge, particularly in noisy regression tasks. This paper investigates whether ICL can be leveraged for distribution-free uncertainty estimation, proposing a method based on conformal prediction to construct prediction intervals with guaranteed coverage. While traditional conformal methods are computationally expensive due to repeated model fitting, we exploit ICL to efficiently generate confidence intervals in a single forward pass. Our empirical analysis compares this approach against ridge regression-based conformal methods, showing that conformal prediction with in-context learning (CP with ICL) achieves robust and scalable uncertainty estimates. Additionally, we evaluate its performance under distribution shifts and establish scaling laws to guide model training. These findings bridge ICL and conformal prediction, providing a theoretically grounded and new framework for uncertainty quantification in transformer-based models.
<div id='section'>Paperid: <span id='pid'>1136, <a href='https://arxiv.org/pdf/2504.08768.pdf' target='_blank'>https://arxiv.org/pdf/2504.08768.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaofan Zhou, Liangjie Huang, Pinyang Cheng, Wenpen Yin, Rui Zhang, Wenrui Hao, Lu Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08768">Accelerating Causal Network Discovery of Alzheimer Disease Biomarkers via Scientific Literature-based Retrieval Augmented Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The causal relationships between biomarkers are essential for disease diagnosis and medical treatment planning. One notable application is Alzheimer's disease (AD) diagnosis, where certain biomarkers may influence the presence of others, enabling early detection, precise disease staging, targeted treatments, and improved monitoring of disease progression. However, understanding these causal relationships is complex and requires extensive research. Constructing a comprehensive causal network of biomarkers demands significant effort from human experts, who must analyze a vast number of research papers, and have bias in understanding diseases' biomarkers and their relation. This raises an important question: Can advanced large language models (LLMs), such as those utilizing retrieval-augmented generation (RAG), assist in building causal networks of biomarkers for further medical analysis? To explore this, we collected 200 AD-related research papers published over the past 25 years and then integrated scientific literature with RAG to extract AD biomarkers and generate causal relations among them. Given the high-risk nature of the medical diagnosis, we applied uncertainty estimation to assess the reliability of the generated causal edges and examined the faithfulness and scientificness of LLM reasoning using both automatic and human evaluation. We find that RAG enhances the ability of LLMs to generate more accurate causal networks from scientific papers. However, the overall performance of LLMs in identifying causal relations of AD biomarkers is still limited. We hope this study will inspire further foundational research on AI-driven analysis of AD biomarkers causal network discovery.
<div id='section'>Paperid: <span id='pid'>1137, <a href='https://arxiv.org/pdf/2504.08452.pdf' target='_blank'>https://arxiv.org/pdf/2504.08452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jyri MaanpÃ¤Ã¤, Julius Pesonen, Iaroslav Melekhov, Heikki Hyyti, Juha HyyppÃ¤
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08452">Road Grip Uncertainty Estimation Through Surface State Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Slippery road conditions pose significant challenges for autonomous driving. Beyond predicting road grip, it is crucial to estimate its uncertainty reliably to ensure safe vehicle control. In this work, we benchmark several uncertainty prediction methods to assess their effectiveness for grip uncertainty estimation. Additionally, we propose a novel approach that leverages road surface state segmentation to predict grip uncertainty. Our method estimates a pixel-wise grip probability distribution based on inferred road surface conditions. Experimental results indicate that the proposed approach enhances the robustness of grip uncertainty prediction.
<div id='section'>Paperid: <span id='pid'>1138, <a href='https://arxiv.org/pdf/2504.01508.pdf' target='_blank'>https://arxiv.org/pdf/2504.01508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pu Wang, Yu Zhang, Zhuoran Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01508">UAKNN: Label Distribution Learning via Uncertainty-Aware KNN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Label Distribution Learning (LDL) aims to characterize the polysemy of an instance by building a set of descriptive degrees corresponding to the instance. In recent years, researchers seek to model to obtain an accurate label distribution by using low-rank, label relations, expert experiences, and label uncertainty estimation. In general, these methods are based on algorithms with parameter learning in a linear (including kernel functions) or deep learning framework. However, these methods are difficult to deploy and update online due to high training costs, limited scalability, and outlier sensitivity. To address this problem, we design a novel LDL method called UAKNN, which has the advantages of the KNN algorithm with the benefits of uncertainty modeling. In addition, we provide solutions to the dilemma of existing work on extremely label distribution spaces. Extensive experiments demonstrate that our method is significantly competitive on 12 benchmarks and that the inference speed of the model is well-suited for industrial-level applications.
<div id='section'>Paperid: <span id='pid'>1139, <a href='https://arxiv.org/pdf/2503.22197.pdf' target='_blank'>https://arxiv.org/pdf/2503.22197.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Liu, Xun Zhang, Jiale Du, Xinbo Gao, Jungong Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22197">Extremely Simple Out-of-distribution Detection for Audio-visual Generalized Zero-shot Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Zero-shot Learning(ZSL) attains knowledge transfer from seen classes to unseen classes by exploring auxiliary category information, which is a promising yet difficult research topic. In this field, Audio-Visual Generalized Zero-Shot Learning~(AV-GZSL) has aroused researchers' great interest in which intricate relations within triple modalities~(audio, video, and natural language) render this task quite challenging but highly research-worthy. However, both existing embedding-based and generative-based AV-GZSL methods tend to suffer from domain shift problem a lot and we propose an extremely simple Out-of-distribution~(OOD) detection based AV-GZSL method~(EZ-AVOOD) to further mitigate bias problem by differentiating seen and unseen samples at the initial beginning. EZ-AVOOD accomplishes effective seen-unseen separation by exploiting the intrinsic discriminative information held in class-specific logits and class-agnostic feature subspace without training an extra OOD detector network. Followed by seen-unseen binary classification, we employ two expert models to classify seen samples and unseen samples separately. Compared to existing state-of-the-art methods, our model achieves superior ZSL and GZSL performances on three audio-visual datasets and becomes the new SOTA, which comprehensively demonstrates the effectiveness of the proposed EZ-AVOOD.
<div id='section'>Paperid: <span id='pid'>1140, <a href='https://arxiv.org/pdf/2503.18599.pdf' target='_blank'>https://arxiv.org/pdf/2503.18599.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minsu Kim, Seongmin Hong, RyeoWook Ko, Soongyu Choi, Hunjong Lee, Junsoo Kim, Joo-Young Kim, Jongse Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18599">Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern Large Language Model serving system batches multiple requests to achieve high throughput, while batching attention operations is challenging, rendering memory bandwidth a critical bottleneck. The community relies on high-end GPUs with multiple high-bandwidth memory channels. Unfortunately, HBM's high bandwidth often comes at the expense of limited memory capacity, which reduces core utilization and increases costs. Recent advancements enabling longer contexts for LLMs have substantially increased the key-value cache size, further intensifying the pressures on memory capacity. The literature has explored KV cache quantization techniques, which commonly use low bitwidth for most values, selectively using higher bitwidth for outlier values. While this approach helps achieve high accuracy and low bitwidth simultaneously, it comes with the limitation that cost for online outlier detection is excessively high, negating the advantages. We propose Oaken, an acceleration solution that achieves high accuracy and high performance simultaneously through co-designing algorithm and hardware. To effectively find a sweet spot in the accuracy-performance trade-off space of KV cache quantization, Oaken employs an online-offline hybrid approach, setting outlier thresholds offline, which are then used to determine the quantization scale online. To translate the proposed algorithmic technique into tangible performance gains, Oaken also comes with custom quantization engines and memory management units that can be integrated with any LLM accelerators. We built an Oaken accelerator on top of an LLM accelerator, LPU, and conducted a comprehensive evaluation. Our experiments show that for a batch size of 256, Oaken achieves up to 1.58x throughput improvement over NVIDIA A100 GPU, incurring a minimal accuracy loss of only 0.54\% on average, compared to state-of-the-art KV cache quantization techniques.
<div id='section'>Paperid: <span id='pid'>1141, <a href='https://arxiv.org/pdf/2503.18589.pdf' target='_blank'>https://arxiv.org/pdf/2503.18589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guillem Capellera, Antonio Rubio, Luis Ferraz, Antonio Agudo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18589">Unified Uncertainty-Aware Diffusion for Multi-Agent Trajectory Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-agent trajectory modeling has primarily focused on forecasting future states, often overlooking broader tasks like trajectory completion, which are crucial for real-world applications such as correcting tracking data. Existing methods also generally predict agents' states without offering any state-wise measure of uncertainty. Moreover, popular multi-modal sampling methods lack any error probability estimates for each generated scene under the same prior observations, making it difficult to rank the predictions during inference time. We introduce U2Diff, a \textbf{unified} diffusion model designed to handle trajectory completion while providing state-wise \textbf{uncertainty} estimates jointly. This uncertainty estimation is achieved by augmenting the simple denoising loss with the negative log-likelihood of the predicted noise and propagating latent space uncertainty to the real state space. Additionally, we incorporate a Rank Neural Network in post-processing to enable \textbf{error probability} estimation for each generated mode, demonstrating a strong correlation with the error relative to ground truth. Our method outperforms the state-of-the-art solutions in trajectory completion and forecasting across four challenging sports datasets (NBA, Basketball-U, Football-U, Soccer-U), highlighting the effectiveness of uncertainty and error probability estimation. Video at https://youtu.be/ngw4D4eJToE
<div id='section'>Paperid: <span id='pid'>1142, <a href='https://arxiv.org/pdf/2503.14983.pdf' target='_blank'>https://arxiv.org/pdf/2503.14983.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zanting Ye, Xiaolong Niu, Xuanbin Wu, Wenxiang Yi, Yuan Chang, Lijun Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14983">Semi-KAN: KAN Provides an Effective Representation for Semi-Supervised Learning in Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based medical image segmentation has shown remarkable success; however, it typically requires extensive pixel-level annotations, which are both expensive and time-intensive. Semi-supervised medical image segmentation (SSMIS) offers a viable alternative, driven by advancements in CNNs and ViTs. However, these networks often rely on single fixed activation functions and linear modeling patterns, limiting their ability to effectively learn robust representations. Given the limited availability of labeled date, achieving robust representation learning becomes crucial. Inspired by Kolmogorov-Arnold Networks (KANs), we propose Semi-KAN, which leverages the untapped potential of KANs to enhance backbone architectures for representation learning in SSMIS. Our findings indicate that: (1) compared to networks with fixed activation functions, KANs exhibit superior representation learning capabilities with fewer parameters, and (2) KANs excel in high-semantic feature spaces. Building on these insights, we integrate KANs into tokenized intermediate representations, applying them selectively at the encoder's bottleneck and the decoder's top layers within a U-Net pipeline to extract high-level semantic features. Although learnable activation functions improve feature expansion, they introduce significant computational overhead with only marginal performance gains. To mitigate this, we reduce the feature dimensions and employ horizontal scaling to capture multiple pattern representations. Furthermore, we design a multi-branch U-Net architecture with uncertainty estimation to effectively learn diverse pattern representations. Extensive experiments on four public datasets demonstrate that Semi-KAN surpasses baseline networks, utilizing fewer KAN layers and lower computational cost, thereby underscoring the potential of KANs as a promising approach for SSMIS.
<div id='section'>Paperid: <span id='pid'>1143, <a href='https://arxiv.org/pdf/2503.05238.pdf' target='_blank'>https://arxiv.org/pdf/2503.05238.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohit Prashant, Arvind Easwaran, Suman Das, Michael Yuhas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05238">Guaranteeing Out-Of-Distribution Detection in Deep RL via Transition Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An issue concerning the use of deep reinforcement learning (RL) agents is whether they can be trusted to perform reliably when deployed, as training environments may not reflect real-life environments. Anticipating instances outside their training scope, learning-enabled systems are often equipped with out-of-distribution (OOD) detectors that alert when a trained system encounters a state it does not recognize or in which it exhibits uncertainty. There exists limited work conducted on the problem of OOD detection within RL, with prior studies being unable to achieve a consensus on the definition of OOD execution within the context of RL. By framing our problem using a Markov Decision Process, we assume there is a transition distribution mapping each state-action pair to another state with some probability. Based on this, we consider the following definition of OOD execution within RL: A transition is OOD if its probability during real-life deployment differs from the transition distribution encountered during training. As such, we utilize conditional variational autoencoders (CVAE) to approximate the transition dynamics of the training environment and implement a conformity-based detector using reconstruction loss that is able to guarantee OOD detection with a pre-determined confidence level. We evaluate our detector by adapting existing benchmarks and compare it with existing OOD detection models for RL.
<div id='section'>Paperid: <span id='pid'>1144, <a href='https://arxiv.org/pdf/2503.04191.pdf' target='_blank'>https://arxiv.org/pdf/2503.04191.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sara Sangalli, Gary Sarwin, Ertunc Erdil, Alessandro Carretta, Victor Staartjes, Carlo Serra, Ender Konukoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04191">Conformal forecasting for surgical instrument trajectory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Forecasting surgical instrument trajectories and predicting the next surgical action recently started to attract attention from the research community. Both these tasks are crucial for automation and assistance in endoscopy surgery. Given the safety-critical nature of these tasks, reliable uncertainty quantification is essential. Conformal prediction is a fast-growing and widely recognized framework for uncertainty estimation in machine learning and computer vision, offering distribution-free, theoretically valid prediction intervals. In this work, we explore the application of standard conformal prediction and conformalized quantile regression to estimate uncertainty in forecasting surgical instrument motion, i.e., predicting direction and magnitude of surgical instruments' future motion. We analyze and compare their coverage and interval sizes, assessing the impact of multiple hypothesis testing and correction methods. Additionally, we show how these techniques can be employed to produce useful uncertainty heatmaps. To the best of our knowledge, this is the first study applying conformal prediction to surgical guidance, marking an initial step toward constructing principled prediction intervals with formal coverage guarantees in this domain.
<div id='section'>Paperid: <span id='pid'>1145, <a href='https://arxiv.org/pdf/2503.00172.pdf' target='_blank'>https://arxiv.org/pdf/2503.00172.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiqiu Xia, Jinxuan Xu, Yuqian Zhang, Hang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00172">A Survey of Uncertainty Estimation Methods on Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have demonstrated remarkable capabilities across various tasks. However, these models could offer biased, hallucinated, or non-factual responses camouflaged by their fluency and realistic appearance. Uncertainty estimation is the key method to address this challenge. While research efforts in uncertainty estimation are ramping up, there is a lack of comprehensive and dedicated surveys on LLM uncertainty estimation. This survey presents four major avenues of LLM uncertainty estimation. Furthermore, we perform extensive experimental evaluations across multiple methods and datasets. At last, we provide critical and promising future directions for LLM uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1146, <a href='https://arxiv.org/pdf/2502.18883.pdf' target='_blank'>https://arxiv.org/pdf/2502.18883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanfu Yan, Viet Duong, Huajie Shao, Denys Poshyvanyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18883">Towards More Trustworthy Deep Code Models by Enabling Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerous machine learning (ML) models have been developed, including those for software engineering (SE) tasks, under the assumption that training and testing data come from the same distribution. However, training and testing distributions often differ, as training datasets rarely encompass the entire distribution, while testing distribution tends to shift over time. Hence, when confronted with out-of-distribution (OOD) instances that differ from the training data, a reliable and trustworthy SE ML model must be capable of detecting them to either abstain from making predictions, or potentially forward these OODs to appropriate models handling other categories or tasks.
  In this paper, we develop two types of SE-specific OOD detection models, unsupervised and weakly-supervised OOD detection for code. The unsupervised OOD detection approach is trained solely on in-distribution samples while the weakly-supervised approach utilizes a tiny number of OOD samples to further enhance the detection performance in various OOD scenarios. Extensive experimental results demonstrate that our proposed methods significantly outperform the baselines in detecting OOD samples from four different scenarios simultaneously and also positively impact a main code understanding task.
<div id='section'>Paperid: <span id='pid'>1147, <a href='https://arxiv.org/pdf/2502.18224.pdf' target='_blank'>https://arxiv.org/pdf/2502.18224.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eduardo Aguilar, Bogdan Raducanu, Petia Radeva
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18224">Multi-label out-of-distribution detection via evidential learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A crucial requirement for machine learning algorithms is not only to perform well, but also to show robustness and adaptability when encountering novel scenarios. One way to achieve these characteristics is to endow the deep learning models with the ability to detect out-of-distribution (OOD) data, i.e. data that belong to distributions different from the one used during their training. It is even a more complicated situation, when these data usually are multi-label. In this paper, we propose an approach based on evidential deep learning in order to meet these challenges applied to visual recognition problems. More concretely, we designed a CNN architecture that uses a Beta Evidential Neural Network to compute both the likelihood and the predictive uncertainty of the samples. Based on these results, we propose afterwards two new uncertainty-based scores for OOD data detection: (i) OOD - score Max, based on the maximum evidence; and (ii) OOD score - Sum, which considers the evidence from all outputs. Extensive experiments have been carried out to validate the proposed approach using three widely-used datasets: PASCAL-VOC, MS-COCO and NUS-WIDE, demonstrating its outperformance over several State-of-the-Art methods.
<div id='section'>Paperid: <span id='pid'>1148, <a href='https://arxiv.org/pdf/2502.04807.pdf' target='_blank'>https://arxiv.org/pdf/2502.04807.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meshi Bashari, Matteo Sesia, Yaniv Romano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04807">Robust Conformal Outlier Detection under Contaminated Reference Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformal prediction is a flexible framework for calibrating machine learning predictions, providing distribution-free statistical guarantees. In outlier detection, this calibration relies on a reference set of labeled inlier data to control the type-I error rate. However, obtaining a perfectly labeled inlier reference set is often unrealistic, and a more practical scenario involves access to a contaminated reference set containing a small fraction of outliers. This paper analyzes the impact of such contamination on the validity of conformal methods. We prove that under realistic, non-adversarial settings, calibration on contaminated data yields conservative type-I error control, shedding light on the inherent robustness of conformal methods. This conservativeness, however, typically results in a loss of power. To alleviate this limitation, we propose a novel, active data-cleaning framework that leverages a limited labeling budget and an outlier detection model to selectively annotate data points in the contaminated reference set that are suspected as outliers. By removing only the annotated outliers in this ``suspicious'' subset, we can effectively enhance power while mitigating the risk of inflating the type-I error rate, as supported by our theoretical analysis. Experiments on real datasets validate the conservative behavior of conformal methods under contamination and show that the proposed data-cleaning strategy improves power without sacrificing validity.
<div id='section'>Paperid: <span id='pid'>1149, <a href='https://arxiv.org/pdf/2502.03982.pdf' target='_blank'>https://arxiv.org/pdf/2502.03982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hannah Rosa Friesacher, Emma Svensson, Susanne Winiwarter, Lewis Mervin, Adam Arany, Ola Engkvist
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03982">Temporal Distribution Shift in Real-World Pharmaceutical Data: Implications for Uncertainty Quantification in QSAR Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The estimation of uncertainties associated with predictions from quantitative structure-activity relationship (QSAR) models can accelerate the drug discovery process by identifying promising experiments and allowing an efficient allocation of resources. Several computational tools exist that estimate the predictive uncertainty in machine learning models. However, deviations from the i.i.d. setting have been shown to impair the performance of these uncertainty quantification methods. We use a real-world pharmaceutical dataset to address the pressing need for a comprehensive, large-scale evaluation of uncertainty estimation methods in the context of realistic distribution shifts over time. We investigate the performance of several uncertainty estimation methods, including ensemble-based and Bayesian approaches. Furthermore, we use this real-world setting to systematically assess the distribution shifts in label and descriptor space and their impact on the capability of the uncertainty estimation methods. Our study reveals significant shifts over time in both label and descriptor space and a clear connection between the magnitude of the shift and the nature of the assay. Moreover, we show that pronounced distribution shifts impair the performance of popular uncertainty estimation methods used in QSAR models. This work highlights the challenges of identifying uncertainty quantification methods that remain reliable under distribution shifts introduced by real-world data.
<div id='section'>Paperid: <span id='pid'>1150, <a href='https://arxiv.org/pdf/2501.17827.pdf' target='_blank'>https://arxiv.org/pdf/2501.17827.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haque Ishfaq, Guangyuan Wang, Sami Nur Islam, Doina Precup
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17827">Langevin Soft Actor-Critic: Efficient Exploration through Uncertainty-Driven Critic Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing actor-critic algorithms, which are popular for continuous control reinforcement learning (RL) tasks, suffer from poor sample efficiency due to lack of principled exploration mechanism within them. Motivated by the success of Thompson sampling for efficient exploration in RL, we propose a novel model-free RL algorithm, Langevin Soft Actor Critic (LSAC), which prioritizes enhancing critic learning through uncertainty estimation over policy optimization. LSAC employs three key innovations: approximate Thompson sampling through distributional Langevin Monte Carlo (LMC) based $Q$ updates, parallel tempering for exploring multiple modes of the posterior of the $Q$ function, and diffusion synthesized state-action samples regularized with $Q$ action gradients. Our extensive experiments demonstrate that LSAC outperforms or matches the performance of mainstream model-free RL algorithms for continuous control tasks. Notably, LSAC marks the first successful application of an LMC based Thompson sampling in continuous control tasks with continuous action spaces.
<div id='section'>Paperid: <span id='pid'>1151, <a href='https://arxiv.org/pdf/2501.14741.pdf' target='_blank'>https://arxiv.org/pdf/2501.14741.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Denis Kleyko, Dmitri A. Rachkovskij
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14741">On Design Choices in Similarity-Preserving Sparse Randomized Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Expand & Sparsify is a principle that is observed in anatomically similar neural circuits found in the mushroom body (insects) and the cerebellum (mammals). Sensory data are projected randomly to much higher-dimensionality (expand part) where only few the most strongly excited neurons are activated (sparsify part). This principle has been leveraged to design a FlyHash algorithm that forms similarity-preserving sparse embeddings, which have been found useful for such tasks as novelty detection, pattern recognition, and similarity search. Despite its simplicity, FlyHash has a number of design choices to be set such as preprocessing of the input data, choice of sparsifying activation function, and formation of the random projection matrix. In this paper, we explore the effect of these choices on the performance of similarity search with FlyHash embeddings. We find that the right combination of design choices can lead to drastic difference in the search performance.
<div id='section'>Paperid: <span id='pid'>1152, <a href='https://arxiv.org/pdf/2412.16409.pdf' target='_blank'>https://arxiv.org/pdf/2412.16409.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda S. Rios, Ibrahima J. Ndiour, Parual Datta, Jaroslaw Sydir, Omesh Tickoo, Nilesh Ahuja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16409">Uncertainty Quantification in Continual Open-World Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI deployed in the real-world should be capable of autonomously adapting to novelties encountered after deployment. Yet, in the field of continual learning, the reliance on novelty and labeling oracles is commonplace albeit unrealistic. This paper addresses a challenging and under-explored problem: a deployed AI agent that continuously encounters unlabeled data - which may include both unseen samples of known classes and samples from novel (unknown) classes - and must adapt to it continuously. To tackle this challenge, we propose our method COUQ "Continual Open-world Uncertainty Quantification", an iterative uncertainty estimation algorithm tailored for learning in generalized continual open-world multi-class settings. We rigorously apply and evaluate COUQ on key sub-tasks in the Continual Open-World: continual novelty detection, uncertainty guided active learning, and uncertainty guided pseudo-labeling for semi-supervised CL. We demonstrate the effectiveness of our method across multiple datasets, ablations, backbones and performance superior to state-of-the-art.
<div id='section'>Paperid: <span id='pid'>1153, <a href='https://arxiv.org/pdf/2412.12566.pdf' target='_blank'>https://arxiv.org/pdf/2412.12566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haonan Xu, Yang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12566">ITP: Instance-Aware Test Pruning for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring the reliable deployment of deep models in real-world scenarios. Recently, from the perspective of over-parameterization, a series of methods leveraging weight sparsification techniques have shown promising performance. These methods typically focus on selecting important parameters for in-distribution (ID) data to reduce the negative impact of redundant parameters on OOD detection. However, we empirically find that these selected parameters may behave overconfidently toward OOD data and hurt OOD detection. To address this issue, we propose a simple yet effective post-hoc method called Instance-aware Test Pruning (ITP), which performs OOD detection by considering both coarse-grained and fine-grained levels of parameter pruning. Specifically, ITP first estimates the class-specific parameter contribution distribution by exploring the ID data. By using the contribution distribution, ITP conducts coarse-grained pruning to eliminate redundant parameters. More importantly, ITP further adopts a fine-grained test pruning process based on the right-tailed Z-score test, which can adaptively remove instance-level overconfident parameters. Finally, ITP derives OOD scores from the pruned model to achieve more reliable predictions. Extensive experiments on widely adopted benchmarks verify the effectiveness of ITP, demonstrating its competitive performance.
<div id='section'>Paperid: <span id='pid'>1154, <a href='https://arxiv.org/pdf/2412.10473.pdf' target='_blank'>https://arxiv.org/pdf/2412.10473.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda Rios, Ibrahima Ndiour, Parual Datta, Omesh Tickoo, Nilesh Ahuja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.10473">CONCLAD: COntinuous Novel CLAss Detector</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of continual learning, relying on so-called oracles for novelty detection is commonplace albeit unrealistic. This paper introduces CONCLAD ("COntinuous Novel CLAss Detector"), a comprehensive solution to the under-explored problem of continual novel class detection in post-deployment data. At each new task, our approach employs an iterative uncertainty estimation algorithm to differentiate between known and novel class(es) samples, and to further discriminate between the different novel classes themselves. Samples predicted to be from a novel class with high-confidence are automatically pseudo-labeled and used to update our model. Simultaneously, a tiny supervision budget is used to iteratively query ambiguous novel class predictions, which are also used during update. Evaluation across multiple datasets, ablations and experimental settings demonstrate our method's effectiveness at separating novel and old class samples continuously. We will release our code upon acceptance.
<div id='section'>Paperid: <span id='pid'>1155, <a href='https://arxiv.org/pdf/2412.09701.pdf' target='_blank'>https://arxiv.org/pdf/2412.09701.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda Rios, Ibrahima Ndiour, Parual Datta, Jerry Sydir, Omesh Tickoo, Nilesh Ahuja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09701">CUAL: Continual Uncertainty-aware Active Learner</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI deployed in many real-world use cases should be capable of adapting to novelties encountered after deployment. Here, we consider a challenging, under-explored and realistic continual adaptation problem: a deployed AI agent is continuously provided with unlabeled data that may contain not only unseen samples of known classes but also samples from novel (unknown) classes. In such a challenging setting, it has only a tiny labeling budget to query the most informative samples to help it continuously learn. We present a comprehensive solution to this complex problem with our model "CUAL" (Continual Uncertainty-aware Active Learner). CUAL leverages an uncertainty estimation algorithm to prioritize active labeling of ambiguous (uncertain) predicted novel class samples while also simultaneously pseudo-labeling the most certain predictions of each class. Evaluations across multiple datasets, ablations, settings and backbones (e.g. ViT foundation model) demonstrate our method's effectiveness. We will release our code upon acceptance.
<div id='section'>Paperid: <span id='pid'>1156, <a href='https://arxiv.org/pdf/2412.03178.pdf' target='_blank'>https://arxiv.org/pdf/2412.03178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gianni Franchi, Dat Nguyen Trong, Nacim Belkhir, Guoxuan Xia, Andrea Pilzer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03178">Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification in text-to-image (T2I) generative models is crucial for understanding model behavior and improving output reliability. In this paper, we are the first to quantify and evaluate the uncertainty of T2I models with respect to the prompt. Alongside adapting existing approaches designed to measure uncertainty in the image space, we also introduce Prompt-based UNCertainty Estimation for T2I models (PUNC), a novel method leveraging Large Vision-Language Models (LVLMs) to better address uncertainties arising from the semantics of the prompt and generated images. PUNC utilizes a LVLM to caption a generated image, and then compares the caption with the original prompt in the more semantically meaningful text space. PUNC also enables the disentanglement of both aleatoric and epistemic uncertainties via precision and recall, which image-space approaches are unable to do. Extensive experiments demonstrate that PUNC outperforms state-of-the-art uncertainty estimation techniques across various settings. Uncertainty quantification in text-to-image generation models can be used on various applications including bias detection, copyright protection, and OOD detection. We also introduce a comprehensive dataset of text prompts and generation pairs to foster further research in uncertainty quantification for generative models. Our findings illustrate that PUNC not only achieves competitive performance but also enables novel applications in evaluating and improving the trustworthiness of text-to-image models.
<div id='section'>Paperid: <span id='pid'>1157, <a href='https://arxiv.org/pdf/2411.17917.pdf' target='_blank'>https://arxiv.org/pdf/2411.17917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Boqi Li, Haojie Zhu, Henry X. Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17917">DECODE: Domain-aware Continual Domain Expansion for Motion Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motion prediction is critical for autonomous vehicles to effectively navigate complex environments and accurately anticipate the behaviors of other traffic participants. As autonomous driving continues to evolve, the need to assimilate new and varied driving scenarios necessitates frequent model updates through retraining. To address these demands, we introduce DECODE, a novel continual learning framework that begins with a pre-trained generalized model and incrementally develops specialized models for distinct domains. Unlike existing continual learning approaches that attempt to develop a unified model capable of generalizing across diverse scenarios, DECODE uniquely balances specialization with generalization, dynamically adjusting to real-time demands. The proposed framework leverages a hypernetwork to generate model parameters, significantly reducing storage requirements, and incorporates a normalizing flow mechanism for real-time model selection based on likelihood estimation. Furthermore, DECODE merges outputs from the most relevant specialized and generalized models using deep Bayesian uncertainty estimation techniques. This integration ensures optimal performance in familiar conditions while maintaining robustness in unfamiliar scenarios. Extensive evaluations confirm the effectiveness of the framework, achieving a notably low forgetting rate of 0.044 and an average minADE of 0.584 m, significantly surpassing traditional learning strategies and demonstrating adaptability across a wide range of driving conditions.
<div id='section'>Paperid: <span id='pid'>1158, <a href='https://arxiv.org/pdf/2411.10254.pdf' target='_blank'>https://arxiv.org/pdf/2411.10254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdullah Abdullah, Fannya Ratana Sandjaja, Ayesha Abdul Majeed, Gyan Wickremasinghe, Karen Rafferty, Vishal Sharma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10254">Uncertainty in Supply Chain Digital Twins: A Quantum-Classical Hybrid Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates uncertainty quantification (UQ) using quantum-classical hybrid machine learning (ML) models for applications in complex and dynamic fields, such as attaining resiliency in supply chain digital twins and financial risk assessment. Although quantum feature transformations have been integrated into ML models for complex data tasks, a gap exists in determining their impact on UQ within their hybrid architectures (quantum-classical approach). This work applies existing UQ techniques for different models within a hybrid framework, examining how quantum feature transformation affects uncertainty propagation. Increasing qubits from 4 to 16 shows varied model responsiveness to outlier detection (OD) samples, which is a critical factor for resilient decision-making in dynamic environments. This work shows how quantum computing techniques can transform data features for UQ, particularly when combined with classical methods.
<div id='section'>Paperid: <span id='pid'>1159, <a href='https://arxiv.org/pdf/2411.02184.pdf' target='_blank'>https://arxiv.org/pdf/2411.02184.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MouÃ¯n Ben Ammar, David Brellmann, Arturo Mendoza, Antoine Manzanera, Gianni Franchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02184">Double Descent Meets Out-of-Distribution Detection: Theoretical Insights and Empirical Analysis on the role of model complexity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for ensuring the reliability and safety of machine learning systems. In recent years, it has received increasing attention, particularly through post-hoc detection and training-based methods. In this paper, we focus on post-hoc OOD detection, which enables identifying OOD samples without altering the model's training procedure or objective. Our primary goal is to investigate the relationship between model capacity and its OOD detection performance. Specifically, we aim to answer the following question: Does the Double Descent phenomenon manifest in post-hoc OOD detection? This question is crucial, as it can reveal whether overparameterization, which is already known to benefit generalization, can also enhance OOD detection. Despite the growing interest in these topics by the classic supervised machine learning community, this intersection remains unexplored for OOD detection. We empirically demonstrate that the Double Descent effect does indeed appear in post-hoc OOD detection. Furthermore, we provide theoretical insights to explain why this phenomenon emerges in such setting. Finally, we show that the overparameterized regime does not yield superior results consistently, and we propose a method to identify the optimal regime for OOD detection based on our observations.
<div id='section'>Paperid: <span id='pid'>1160, <a href='https://arxiv.org/pdf/2411.01487.pdf' target='_blank'>https://arxiv.org/pdf/2411.01487.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyao Geng, Yuan Zhang, Jiaqi Huang, Feng Xue, Falong Tan, Chuanlong Xie, Shumei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01487">DSDE: Using Proportion Estimation to Improve Model Selection for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model library is an effective tool for improving the performance of single-model Out-of-Distribution (OoD) detector, mainly through model selection and detector fusion. However, existing methods in the literature do not provide uncertainty quantification for model selection results. Additionally, the model ensemble process primarily focuses on controlling the True Positive Rate (TPR) while neglecting the False Positive Rate (FPR). In this paper, we emphasize the significance of the proportion of models in the library that identify the test sample as an OoD sample. This proportion holds crucial information and directly influences the error rate of OoD detection.To address this, we propose inverting the commonly-used sequential p-value strategies. We define the rejection region initially and then estimate the error rate. Furthermore, we introduce a novel perspective from change-point detection and propose an approach for proportion estimation with automatic hyperparameter selection. We name the proposed approach as DOS-Storey-based Detector Ensemble (DSDE). Experimental results on CIFAR10 and CIFAR100 demonstrate the effectiveness of our approach in tackling OoD detection challenges. Specifically, the CIFAR10 experiments show that DSDE reduces the FPR from 11.07% to 3.31% compared to the top-performing single-model detector.
<div id='section'>Paperid: <span id='pid'>1161, <a href='https://arxiv.org/pdf/2411.00430.pdf' target='_blank'>https://arxiv.org/pdf/2411.00430.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuchen Xie, Yiqiao Qiu, Run Lin, Weishi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00430">Class Incremental Learning with Task-Specific Batch Normalization and Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study focuses on incremental learning for image classification, exploring how to reduce catastrophic forgetting of all learned knowledge when access to old data is restricted due to memory or privacy constraints. The challenge of incremental learning lies in achieving an optimal balance between plasticity, the ability to learn new knowledge, and stability, the ability to retain old knowledge. Based on whether the task identifier (task-ID) of an image can be obtained during the test stage, incremental learning for image classifcation is divided into two main paradigms, which are task incremental learning (TIL) and class incremental learning (CIL). The TIL paradigm has access to the task-ID, allowing it to use multiple task-specific classification heads selected based on the task-ID. Consequently, in CIL, where the task-ID is unavailable, TIL methods must predict the task-ID to extend their application to the CIL paradigm. Our previous method for TIL adds task-specific batch normalization and classification heads incrementally. This work extends the method by predicting task-ID through an "unknown" class added to each classification head. The head with the lowest "unknown" probability is selected, enabling task-ID prediction and making the method applicable to CIL. The task-specific batch normalization (BN) modules effectively adjust the distribution of output feature maps across different tasks, enhancing the model's plasticity.Moreover, since BN has much fewer parameters compared to convolutional kernels, by only modifying the BN layers as new tasks arrive, the model can effectively manage parameter growth while ensuring stability across tasks. The innovation of this study lies in the first-time introduction of task-specific BN into CIL and verifying the feasibility of extending TIL methods to CIL through task-ID prediction with state-of-the-art performance on multiple datasets.
<div id='section'>Paperid: <span id='pid'>1162, <a href='https://arxiv.org/pdf/2410.21712.pdf' target='_blank'>https://arxiv.org/pdf/2410.21712.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julien Pallage, Bertrand Scherrer, Salma Naccache, Christophe BÃ©langer, Antoine Lesage-Landry
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21712">Sliced-Wasserstein-based Anomaly Detection and Open Dataset for Localized Critical Peak Rebates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present a new unsupervised anomaly (outlier) detection (AD) method using the sliced-Wasserstein metric. This filtering technique is conceptually interesting for MLOps pipelines deploying machine learning models in critical sectors, e.g., energy, as it offers a conservative data selection. Additionally, we open the first dataset showcasing localized critical peak rebate demand response in a northern climate. We demonstrate the capabilities of our method on synthetic datasets as well as standard AD datasets and use it in the making of a first benchmark for our open-source localized critical peak rebate dataset.
<div id='section'>Paperid: <span id='pid'>1163, <a href='https://arxiv.org/pdf/2410.20432.pdf' target='_blank'>https://arxiv.org/pdf/2410.20432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sina DÃ¤ubener, Kira Maag, David Krueger, Asja Fischer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20432">Integrating uncertainty quantification into randomized smoothing based robustness guarantees</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have proven to be extremely powerful, however, they are also vulnerable to adversarial attacks which can cause hazardous incorrect predictions in safety-critical applications. Certified robustness via randomized smoothing gives a probabilistic guarantee that the smoothed classifier's predictions will not change within an $\ell_2$-ball around a given input. On the other hand (uncertainty) score-based rejection is a technique often applied in practice to defend models against adversarial attacks. In this work, we fuse these two approaches by integrating a classifier that abstains from predicting when uncertainty is high into the certified robustness framework. This allows us to derive two novel robustness guarantees for uncertainty aware classifiers, namely (i) the radius of an $\ell_2$-ball around the input in which the same label is predicted and uncertainty remains low and (ii) the $\ell_2$-radius of a ball in which the predictions will either not change or be uncertain. While the former provides robustness guarantees with respect to attacks aiming at increased uncertainty, the latter informs about the amount of input perturbation necessary to lead the uncertainty aware model into a wrong prediction. Notably, this is on CIFAR10 up to 20.93% larger than for models not allowing for uncertainty based rejection. We demonstrate, that the novel framework allows for a systematic robustness evaluation of different network architectures and uncertainty measures and to identify desired properties of uncertainty quantification techniques. Moreover, we show that leveraging uncertainty in a smoothed classifier helps out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>1164, <a href='https://arxiv.org/pdf/2410.20312.pdf' target='_blank'>https://arxiv.org/pdf/2410.20312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Zhang, Linjiajie Fang, Kexin Shi, Wenjia Wang, Bing-Yi Jing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20312">Q-Distribution guided Q-learning for offline reinforcement learning: Uncertainty penalized Q-value via consistency model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>``Distribution shift'' is the main obstacle to the success of offline reinforcement learning. A learning policy may take actions beyond the behavior policy's knowledge, referred to as Out-of-Distribution (OOD) actions. The Q-values for these OOD actions can be easily overestimated. As a result, the learning policy is biased by using incorrect Q-value estimates. One common approach to avoid Q-value overestimation is to make a pessimistic adjustment. Our key idea is to penalize the Q-values of OOD actions associated with high uncertainty. In this work, we propose Q-Distribution Guided Q-Learning (QDQ), which applies a pessimistic adjustment to Q-values in OOD regions based on uncertainty estimation. This uncertainty measure relies on the conditional Q-value distribution, learned through a high-fidelity and efficient consistency model. Additionally, to prevent overly conservative estimates, we introduce an uncertainty-aware optimization objective for updating the Q-value function. The proposed QDQ demonstrates solid theoretical guarantees for the accuracy of Q-value distribution learning and uncertainty measurement, as well as the performance of the learning policy. QDQ consistently shows strong performance on the D4RL benchmark and achieves significant improvements across many tasks.
<div id='section'>Paperid: <span id='pid'>1165, <a href='https://arxiv.org/pdf/2410.07725.pdf' target='_blank'>https://arxiv.org/pdf/2410.07725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yonghang Zhou, Hongyi Zhu, Yidong Chai, Yuanchun Jiang, Yezheng Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07725">Towards Trustworthy Web Attack Detection: An Uncertainty-Aware Ensemble Deep Kernel Learning Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Web attacks are one of the major and most persistent forms of cyber threats, which bring huge costs and losses to web application-based businesses. Various detection methods, such as signature-based, machine learning-based, and deep learning-based, have been proposed to identify web attacks. However, these methods either (1) heavily rely on accurate and complete rule design and feature engineering, which may not adapt to fast-evolving attacks, or (2) fail to estimate model uncertainty, which is essential to the trustworthiness of the prediction made by the model. In this study, we proposed an Uncertainty-aware Ensemble Deep Kernel Learning (UEDKL) model to detect web attacks from HTTP request payload data with the model uncertainty captured from the perspective of both data distribution and model parameters. The proposed UEDKL utilizes a deep kernel learning model to distinguish normal HTTP requests from different types of web attacks with model uncertainty estimated from data distribution perspective. Multiple deep kernel learning models were trained as base learners to capture the model uncertainty from model parameters perspective. An attention-based ensemble learning approach was designed to effectively integrate base learners' predictions and model uncertainty. We also proposed a new metric named High Uncertainty Ratio-F Score Curve to evaluate model uncertainty estimation. Experiments on BDCI and SRBH datasets demonstrated that the proposed UEDKL framework yields significant improvement in both web attack detection performance and uncertainty estimation quality compared to benchmark models.
<div id='section'>Paperid: <span id='pid'>1166, <a href='https://arxiv.org/pdf/2409.16305.pdf' target='_blank'>https://arxiv.org/pdf/2409.16305.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis Gustavo Gioacon Villani, Samuel da Silva, Americo Cunha, Michael D. Todd
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.16305">Damage detection in an uncertain nonlinear beam based on stochastic Volterra series: an experimental application</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The damage detection problem becomes a more difficult task when the intrinsically nonlinear behavior of the structures and the natural data variation are considered in the analysis because both phenomena can be confused with damage if linear and deterministic approaches are implemented. Therefore, this work aims the experimental application of a stochastic version of the Volterra series combined with a novelty detection approach to detect damage in an initially nonlinear system taking into account the measured data variation, caused by the presence of uncertainties. The experimental setup is composed by a cantilever beam operating in a nonlinear regime of motion, even in the healthy condition, induced by the presence of a magnet near to the free extremity. The damage associated with mass changes in a bolted connection (nuts loosed) is detected based on the comparison between linear and nonlinear contributions of the stochastic Volterra kernels in the total response, estimated in the reference and damaged conditions. The experimental measurements were performed on different days to add natural variation to the data measured. The results obtained through the stochastic proposed approach are compared with those obtained by the deterministic version of the Volterra series, showing the advantage of the stochastic model use when we consider the experimental data variation with the capability to detect the presence of the damage with statistical confidence. Besides, the nonlinear metric used presented a higher sensitivity to the occurrence of the damage compared with the linear one, justifying the application of a nonlinear metric when the system exhibits intrinsically nonlinear behavior.
<div id='section'>Paperid: <span id='pid'>1167, <a href='https://arxiv.org/pdf/2409.10655.pdf' target='_blank'>https://arxiv.org/pdf/2409.10655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel FlÃ¶gel, Marcos GÃ³mez VillafaÃ±e, Joshua Ransiek, SÃ¶ren Hohmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10655">Disentangling Uncertainty for Safe Social Navigation using Deep Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous mobile robots are increasingly used in pedestrian-rich environments where safe navigation and appropriate human interaction are crucial. While Deep Reinforcement Learning (DRL) enables socially integrated robot behavior, challenges persist in novel or perturbed scenarios to indicate when and why the policy is uncertain. Unknown uncertainty in decision-making can lead to collisions or human discomfort and is one reason why safe and risk-aware navigation is still an open problem. This work introduces a novel approach that integrates aleatoric, epistemic, and predictive uncertainty estimation into a DRL navigation framework for policy distribution uncertainty estimates. We, therefore, incorporate Observation-Dependent Variance (ODV) and dropout into the Proximal Policy Optimization (PPO) algorithm. For different types of perturbations, we compare the ability of deep ensembles and Monte-Carlo dropout (MC-dropout) to estimate the uncertainties of the policy. In uncertain decision-making situations, we propose to change the robot's social behavior to conservative collision avoidance. The results show improved training performance with ODV and dropout in PPO and reveal that the training scenario has an impact on the generalization. In addition, MC-dropout is more sensitive to perturbations and correlates the uncertainty type to the perturbation better. With the safe action selection, the robot can navigate in perturbed environments with fewer collisions.
<div id='section'>Paperid: <span id='pid'>1168, <a href='https://arxiv.org/pdf/2409.08756.pdf' target='_blank'>https://arxiv.org/pdf/2409.08756.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin Bubel, Jochen Schmid, Maximilian Carmesin, Volodymyr Kozachynskyi, Erik Esche, Michael Bortz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08756">Cubature-based uncertainty estimation for nonlinear regression models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Calibrating model parameters to measured data by minimizing loss functions is an important step in obtaining realistic predictions from model-based approaches, e.g., for process optimization. This is applicable to both knowledge-driven and data-driven model setups. Due to measurement errors, the calibrated model parameters also carry uncertainty. In this contribution, we use cubature formulas based on sparse grids to calculate the variance of the regression results. The number of cubature points is close to the theoretical minimum required for a given level of exactness. We present exact benchmark results, which we also compare to other cubatures. This scheme is then applied to estimate the prediction uncertainty of the NRTL model, calibrated to observations from different experimental designs.
<div id='section'>Paperid: <span id='pid'>1169, <a href='https://arxiv.org/pdf/2409.08636.pdf' target='_blank'>https://arxiv.org/pdf/2409.08636.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lars BÃ¶cking, Leopold MÃ¼ller, Niklas KÃ¼hl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08636">Utilizing Data Fingerprints for Privacy-Preserving Algorithm Selection in Time Series Classification: Performance and Uncertainty Estimation on Unseen Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The selection of algorithms is a crucial step in designing AI services for real-world time series classification use cases. Traditional methods such as neural architecture search, automated machine learning, combined algorithm selection, and hyperparameter optimizations are effective but require considerable computational resources and necessitate access to all data points to run their optimizations. In this work, we introduce a novel data fingerprint that describes any time series classification dataset in a privacy-preserving manner and provides insight into the algorithm selection problem without requiring training on the (unseen) dataset. By decomposing the multi-target regression problem, only our data fingerprints are used to estimate algorithm performance and uncertainty in a scalable and adaptable manner. Our approach is evaluated on the 112 University of California riverside benchmark datasets, demonstrating its effectiveness in predicting the performance of 35 state-of-the-art algorithms and providing valuable insights for effective algorithm selection in time series classification service systems, improving a naive baseline by 7.32% on average in estimating the mean performance and 15.81% in estimating the uncertainty.
<div id='section'>Paperid: <span id='pid'>1170, <a href='https://arxiv.org/pdf/2409.04159.pdf' target='_blank'>https://arxiv.org/pdf/2409.04159.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Clemens Damke, Eyke HÃ¼llermeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04159">CUQ-GNN: Committee-based Graph Uncertainty Quantification using Posterior Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we study the influence of domain-specific characteristics when defining a meaningful notion of predictive uncertainty on graph data. Previously, the so-called Graph Posterior Network (GPN) model has been proposed to quantify uncertainty in node classification tasks. Given a graph, it uses Normalizing Flows (NFs) to estimate class densities for each node independently and converts those densities into Dirichlet pseudo-counts, which are then dispersed through the graph using the personalized Page-Rank algorithm. The architecture of GPNs is motivated by a set of three axioms on the properties of its uncertainty estimates. We show that those axioms are not always satisfied in practice and therefore propose the family of Committe-based Uncertainty Quantification Graph Neural Networks (CUQ-GNNs), which combine standard Graph Neural Networks with the NF-based uncertainty estimation of Posterior Networks (PostNets). This approach adapts more flexibly to domain-specific demands on the properties of uncertainty estimates. We compare CUQ-GNN against GPN and other uncertainty quantification approaches on common node classification benchmarks and show that it is effective at producing useful uncertainty estimates.
<div id='section'>Paperid: <span id='pid'>1171, <a href='https://arxiv.org/pdf/2408.14841.pdf' target='_blank'>https://arxiv.org/pdf/2408.14841.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Suhee Yoon, Sanghyu Yoon, Ye Seul Sim, Sungik Choi, Kyungeun Lee, Hye-Seung Cho, Hankook Lee, Woohyung Lim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14841">Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection, which determines whether a given sample is part of the in-distribution (ID), has recently shown promising results through training with synthetic OOD datasets. Nonetheless, existing methods often produce outliers that are considerably distant from the ID, showing limited efficacy for capturing subtle distinctions between ID and OOD. To address these issues, we propose a novel framework, Semantic Outlier generation via Nuisance Awareness (SONA), which notably produces challenging outliers by directly leveraging pixel-space ID samples through diffusion models. Our approach incorporates SONA guidance, providing separate control over semantic and nuisance regions of ID samples. Thereby, the generated outliers achieve two crucial properties: (i) they present explicit semantic-discrepant information, while (ii) maintaining various levels of nuisance resemblance with ID. Furthermore, the improved OOD detector training with SONA outliers facilitates learning with a focus on semantic distinctions. Extensive experiments demonstrate the effectiveness of our framework, achieving an impressive AUROC of 88% on near-OOD datasets, which surpasses the performance of baseline methods by a significant margin of approximately 6%.
<div id='section'>Paperid: <span id='pid'>1172, <a href='https://arxiv.org/pdf/2408.12355.pdf' target='_blank'>https://arxiv.org/pdf/2408.12355.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanyun Lu, Renshu Gu, Huimin Cheng, Siyu Pang, Mingyu Xu, Peifang Xu, Yaqi Wang, Yuichiro Kinoshita, Juan Ye, Gangyong Jia, Qing Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12355">Class-balanced Open-set Semi-supervised Object Detection for Medical Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical image datasets in the real world are often unlabeled and imbalanced, and Semi-Supervised Object Detection (SSOD) can utilize unlabeled data to improve an object detector. However, existing approaches predominantly assumed that the unlabeled data and test data do not contain out-of-distribution (OOD) classes. The few open-set semi-supervised object detection methods have two weaknesses: first, the class imbalance is not considered; second, the OOD instances are distinguished and simply discarded during pseudo-labeling. In this paper, we consider the open-set semi-supervised object detection problem which leverages unlabeled data that contain OOD classes to improve object detection for medical images. Our study incorporates two key innovations: Category Control Embed (CCE) and out-of-distribution Detection Fusion Classifier (OODFC). CCE is designed to tackle dataset imbalance by constructing a Foreground information Library, while OODFC tackles open-set challenges by integrating the ``unknown'' information into basic pseudo-labels. Our method outperforms the state-of-the-art SSOD performance, achieving a 4.25 mAP improvement on the public Parasite dataset.
<div id='section'>Paperid: <span id='pid'>1173, <a href='https://arxiv.org/pdf/2408.11237.pdf' target='_blank'>https://arxiv.org/pdf/2408.11237.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Constantinou, Georgios Ioannides, Aman Chadha, Aaron Elkins, Edwin Simpson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11237">Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) data is crucial in machine learning applications to mitigate the risk of model overconfidence, thereby enhancing the reliability and safety of deployed systems. The majority of existing OOD detection methods predominantly address uni-modal inputs, such as images or texts. In the context of multi-modal documents, there is a notable lack of extensive research on the performance of these methods, which have primarily been developed with a focus on computer vision tasks. We propose a novel methodology termed as attention head masking (AHM) for multi-modal OOD tasks in document classification systems. Our empirical results demonstrate that the proposed AHM method outperforms all state-of-the-art approaches and significantly decreases the false positive rate (FPR) compared to existing solutions up to 7.5\%. This methodology generalizes well to multi-modal data, such as documents, where visual and textual information are modeled under the same Transformer architecture. To address the scarcity of high-quality publicly available document datasets and encourage further research on OOD detection for documents, we introduce FinanceDocs, a new document AI dataset. Our code and dataset are publicly available.
<div id='section'>Paperid: <span id='pid'>1174, <a href='https://arxiv.org/pdf/2408.10021.pdf' target='_blank'>https://arxiv.org/pdf/2408.10021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kira Maag, Roman Resner, Asja Fischer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10021">Detecting Adversarial Attacks in Semantic Segmentation via Uncertainty Estimation: A Deep Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have demonstrated remarkable effectiveness across a wide range of tasks such as semantic segmentation. Nevertheless, these networks are vulnerable to adversarial attacks that add imperceptible perturbations to the input image, leading to false predictions. This vulnerability is particularly dangerous in safety-critical applications like automated driving. While adversarial examples and defense strategies are well-researched in the context of image classification, there is comparatively less research focused on semantic segmentation. Recently, we have proposed an uncertainty-based method for detecting adversarial attacks on neural networks for semantic segmentation. We observed that uncertainty, as measured by the entropy of the output distribution, behaves differently on clean versus adversely perturbed images, and we utilize this property to differentiate between the two. In this extended version of our work, we conduct a detailed analysis of uncertainty-based detection of adversarial attacks including a diverse set of adversarial attacks and various state-of-the-art neural networks. Our numerical experiments show the effectiveness of the proposed uncertainty-based detection method, which is lightweight and operates as a post-processing step, i.e., no model modifications or knowledge of the adversarial example generation process are required.
<div id='section'>Paperid: <span id='pid'>1175, <a href='https://arxiv.org/pdf/2408.06018.pdf' target='_blank'>https://arxiv.org/pdf/2408.06018.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shanu Saklani, Chitwan Goel, Shrey Bansal, Zhe Wang, Soumya Dutta, Tushar M. Athawale, David Pugmire, Christopher R. Johnson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06018">Uncertainty-Informed Volume Visualization using Implicit Neural Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The increasing adoption of Deep Neural Networks (DNNs) has led to their application in many challenging scientific visualization tasks. While advanced DNNs offer impressive generalization capabilities, understanding factors such as model prediction quality, robustness, and uncertainty is crucial. These insights can enable domain scientists to make informed decisions about their data. However, DNNs inherently lack ability to estimate prediction uncertainty, necessitating new research to construct robust uncertainty-aware visualization techniques tailored for various visualization tasks. In this work, we propose uncertainty-aware implicit neural representations to model scalar field data sets effectively and comprehensively study the efficacy and benefits of estimated uncertainty information for volume visualization tasks. We evaluate the effectiveness of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout (MCDropout). These techniques enable uncertainty-informed volume visualization in scalar field data sets. Our extensive exploration across multiple data sets demonstrates that uncertainty-aware models produce informative volume visualization results. Moreover, integrating prediction uncertainty enhances the trustworthiness of our DNN model, making it suitable for robustly analyzing and visualizing real-world scientific volumetric data sets.
<div id='section'>Paperid: <span id='pid'>1176, <a href='https://arxiv.org/pdf/2407.16871.pdf' target='_blank'>https://arxiv.org/pdf/2407.16871.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ratanond Koonchanok, Michael E. Papka, Khairi Reda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16871">Trust Your Gut: Comparing Human and Machine Inference from Noisy Visualizations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>People commonly utilize visualizations not only to examine a given dataset, but also to draw generalizable conclusions about the underlying models or phenomena. Prior research has compared human visual inference to that of an optimal Bayesian agent, with deviations from rational analysis viewed as problematic. However, human reliance on non-normative heuristics may prove advantageous in certain circumstances. We investigate scenarios where human intuition might surpass idealized statistical rationality. In two experiments, we examine individuals' accuracy in characterizing the parameters of known data-generating models from bivariate visualizations. Our findings indicate that, although participants generally exhibited lower accuracy compared to statistical models, they frequently outperformed Bayesian agents, particularly when faced with extreme samples. Participants appeared to rely on their internal models to filter out noisy visualizations, thus improving their resilience against spurious data. However, participants displayed overconfidence and struggled with uncertainty estimation. They also exhibited higher variance than statistical machines. Our findings suggest that analyst gut reactions to visualizations may provide an advantage, even when departing from rationality. These results carry implications for designing visual analytics tools, offering new perspectives on how to integrate statistical models and analyst intuition for improved inference and decision-making. The data and materials for this paper are available at https://osf.io/qmfv6
<div id='section'>Paperid: <span id='pid'>1177, <a href='https://arxiv.org/pdf/2407.15110.pdf' target='_blank'>https://arxiv.org/pdf/2407.15110.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxiang Yi, Ji Cheng, Miguel A. Bessa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15110">Practical multi-fidelity machine learning: fusion of deterministic and Bayesian models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-fidelity machine learning methods address the accuracy-efficiency trade-off by integrating scarce, resource-intensive high-fidelity data with abundant but less accurate low-fidelity data. We propose a practical multi-fidelity strategy for problems spanning low- and high-dimensional domains, integrating a non-probabilistic regression model for the low-fidelity with a Bayesian model for the high-fidelity. The models are trained in a staggered scheme, where the low-fidelity model is transfer-learned to the high-fidelity data and a Bayesian model is trained to learn the residual between the data and the transfer-learned model. This three-model strategy -- deterministic low-fidelity, transfer-learning, and Bayesian residual -- leads to a prediction that includes uncertainty quantification for noisy and noiseless multi-fidelity data. The strategy is general and unifies the topic, highlighting the expressivity trade-off between the transfer-learning and Bayesian models (a complex transfer-learning model leads to a simpler Bayesian model, and vice versa). We propose modeling choices for two scenarios, and argue in favor of using a linear transfer-learning model that fuses 1) kernel ridge regression for low-fidelity with Gaussian processes for high-fidelity; or 2) deep neural network for low-fidelity with a Bayesian neural network for high-fidelity. We demonstrate the effectiveness and efficiency of the proposed strategies and contrast them with the state-of-the-art based on various numerical examples and two engineering problems. The results indicate that the proposed approach achieves comparable performance in both mean and uncertainty estimation while significantly reducing training time for machine learning modeling in data-scarce scenarios. Moreover, in data-rich settings, it outperforms other multi-fidelity architectures by effectively mitigating overfitting.
<div id='section'>Paperid: <span id='pid'>1178, <a href='https://arxiv.org/pdf/2407.14185.pdf' target='_blank'>https://arxiv.org/pdf/2407.14185.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hannah Rosa Friesacher, Ola Engkvist, Lewis Mervin, Yves Moreau, Adam Arany
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14185">Achieving Well-Informed Decision-Making in Drug Discovery: A Comprehensive Calibration Study using Neural Network-Based Structure-Activity Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the drug discovery process, where experiments can be costly and time-consuming, computational models that predict drug-target interactions are valuable tools to accelerate the development of new therapeutic agents. Estimating the uncertainty inherent in these neural network predictions provides valuable information that facilitates optimal decision-making when risk assessment is crucial. However, such models can be poorly calibrated, which results in unreliable uncertainty estimates that do not reflect the true predictive uncertainty. In this study, we compare different metrics, including accuracy and calibration scores, used for model hyperparameter tuning to investigate which model selection strategy achieves well-calibrated models. Furthermore, we propose to use a computationally efficient Bayesian uncertainty estimation method named Bayesian Linear Probing (BLP), which generates Hamiltonian Monte Carlo (HMC) trajectories to obtain samples for the parameters of a Bayesian Logistic Regression fitted to the hidden layer of the baseline neural network. We report that BLP improves model calibration and achieves the performance of common uncertainty quantification methods by combining the benefits of uncertainty estimation and probability calibration methods. Finally, we show that combining post hoc calibration method with well-performing uncertainty quantification approaches can boost model accuracy and calibration.
<div id='section'>Paperid: <span id='pid'>1179, <a href='https://arxiv.org/pdf/2407.13553.pdf' target='_blank'>https://arxiv.org/pdf/2407.13553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyue Zhao, Peiqi Li, Xiangde Luo, Meng Yang, Shi Chang, Zhongyu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13553">SAM-Driven Weakly Supervised Nodule Segmentation with Uncertainty-Aware Cross Teaching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated nodule segmentation is essential for computer-assisted diagnosis in ultrasound images. Nevertheless, most existing methods depend on precise pixel-level annotations by medical professionals, a process that is both costly and labor-intensive. Recently, segmentation foundation models like SAM have shown impressive generalizability on natural images, suggesting their potential as pseudo-labelers. However, accurate prompts remain crucial for their success in medical images. In this work, we devise a novel weakly supervised framework that effectively utilizes the segmentation foundation model to generate pseudo-labels from aspect ration annotations for automatic nodule segmentation. Specifically, we develop three types of bounding box prompts based on scalable shape priors, followed by an adaptive pseudo-label selection module to fully exploit the prediction capabilities of the foundation model for nodules. We also present a SAM-driven uncertainty-aware cross-teaching strategy. This approach integrates SAM-based uncertainty estimation and label-space perturbations into cross-teaching to mitigate the impact of pseudo-label inaccuracies on model training. Extensive experiments on two clinically collected ultrasound datasets demonstrate the superior performance of our proposed method.
<div id='section'>Paperid: <span id='pid'>1180, <a href='https://arxiv.org/pdf/2407.13392.pdf' target='_blank'>https://arxiv.org/pdf/2407.13392.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Judith Dijk, Gertjan Burghouts, Kapil D. Katyal, Bryanna Y. Yeh, Craig T. Knuth, Ella Fokkinga, Tejaswi Kasarla, Pascal Mettes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13392">Lightweight Uncertainty Quantification with Simplex Semantic Segmentation for Terrain Traversability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For navigation of robots, image segmentation is an important component to determining a terrain's traversability. For safe and efficient navigation, it is key to assess the uncertainty of the predicted segments. Current uncertainty estimation methods are limited to a specific choice of model architecture, are costly in terms of training time, require large memory for inference (ensembles), or involve complex model architectures (energy-based, hyperbolic, masking). In this paper, we propose a simple, light-weight module that can be connected to any pretrained image segmentation model, regardless of its architecture, with marginal additional computation cost because it reuses the model's backbone. Our module is based on maximum separation of the segmentation classes by respective prototype vectors. This optimizes the probability that out-of-distribution segments are projected in between the prototype vectors. The uncertainty value in the classification label is obtained from the distance to the nearest prototype. We demonstrate the effectiveness of our module for terrain segmentation.
<div id='section'>Paperid: <span id='pid'>1181, <a href='https://arxiv.org/pdf/2406.01170.pdf' target='_blank'>https://arxiv.org/pdf/2406.01170.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Choubo Ding, Guansong Pang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01170">Zero-Shot Out-of-Distribution Detection with Outlier Label Exposure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As vision-language models like CLIP are widely applied to zero-shot tasks and gain remarkable performance on in-distribution (ID) data, detecting and rejecting out-of-distribution (OOD) inputs in the zero-shot setting have become crucial for ensuring the safety of using such models on the fly. Most existing zero-shot OOD detectors rely on ID class label-based prompts to guide CLIP in classifying ID images and rejecting OOD images. In this work we instead propose to leverage a large set of diverse auxiliary outlier class labels as pseudo OOD class text prompts to CLIP for enhancing zero-shot OOD detection, an approach we called Outlier Label Exposure (OLE). The key intuition is that ID images are expected to have lower similarity to these outlier class prompts than OOD images. One issue is that raw class labels often include noise labels, e.g., synonyms of ID labels, rendering raw OLE-based detection ineffective. To address this issue, we introduce an outlier prototype learning module that utilizes the prompt embeddings of the outlier labels to learn a small set of pivotal outlier prototypes for an embedding similarity-based OOD scoring. Additionally, the outlier classes and their prototypes can be loosely coupled with the ID classes, leading to an inseparable decision region between them. Thus, we also introduce an outlier label generation module that synthesizes our outlier prototypes and ID class embeddings to generate in-between outlier prototypes to further calibrate the detection in OLE. Despite its simplicity, extensive experiments show that OLE substantially improves detection performance and achieves new state-of-the-art performance in large-scale OOD and hard OOD detection benchmarks.
<div id='section'>Paperid: <span id='pid'>1182, <a href='https://arxiv.org/pdf/2405.19247.pdf' target='_blank'>https://arxiv.org/pdf/2405.19247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuang Qi, Junlin Zhang, Xiaming Chen, Xin Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19247">Comparative Study of Neighbor-based Methods for Local Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The neighbor-based method has become a powerful tool to handle the outlier detection problem, which aims to infer the abnormal degree of the sample based on the compactness of the sample and its neighbors. However, the existing methods commonly focus on designing different processes to locate outliers in the dataset, while the contributions of different types neighbors to outlier detection has not been well discussed. To this end, this paper studies the neighbor in the existing outlier detection algorithms and a taxonomy is introduced, which uses the three-level components of information, neighbor and methodology to define hybrid methods. This taxonomy can serve as a paradigm where a novel neighbor-based outlier detection method can be proposed by combining different components in this taxonomy. A large number of comparative experiments were conducted on synthetic and real-world datasets in terms of performance comparison and case study, and the results show that reverse K-nearest neighbor based methods achieve promising performance and dynamic selection method is suitable for working in high-dimensional space. Notably, it is verified that rationally selecting components from this taxonomy may create an algorithms superior to existing methods.
<div id='section'>Paperid: <span id='pid'>1183, <a href='https://arxiv.org/pdf/2405.15991.pdf' target='_blank'>https://arxiv.org/pdf/2405.15991.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuesong Wang, He Zhao, Edwin V. Bonilla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15991">RÃ©nyi Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Processes (NPs) are deep probabilistic models that represent stochastic processes by conditioning their prior distributions on a set of context points. Despite their advantages in uncertainty estimation for complex distributions, NPs enforce parameterization coupling between the conditional prior model and the posterior model. We show that this coupling amounts to prior misspecification and revisit the NP objective to address this issue. More specifically, we propose RÃ©nyi Neural Processes (RNP), a method that replaces the standard KL divergence with the RÃ©nyi divergence, dampening the effects of the misspecified prior during posterior updates. We validate our approach across multiple benchmarks including regression and image inpainting tasks, and show significant performance improvements of RNPs in real-world problems. Our extensive experiments show consistently better log-likelihoods over state-of-the-art NP models.
<div id='section'>Paperid: <span id='pid'>1184, <a href='https://arxiv.org/pdf/2405.13864.pdf' target='_blank'>https://arxiv.org/pdf/2405.13864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Konstantinos Pitas, Julyan Arbel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13864">Just rotate it! Uncertainty estimation in closed-source models via multiple queries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a simple and effective method to estimate the uncertainty of closed-source deep neural network image classification models. Given a base image, our method creates multiple transformed versions and uses them to query the top-1 prediction of the closed-source model. We demonstrate significant improvements in the calibration of uncertainty estimates compared to the naive baseline of assigning 100\% confidence to all predictions. While we initially explore Gaussian perturbations, our empirical findings indicate that natural transformations, such as rotations and elastic deformations, yield even better-calibrated predictions. Furthermore, through empirical results and a straightforward theoretical analysis, we elucidate the reasons behind the superior performance of natural transformations over Gaussian noise. Leveraging these insights, we propose a transfer learning approach that further improves our calibration results.
<div id='section'>Paperid: <span id='pid'>1185, <a href='https://arxiv.org/pdf/2405.07104.pdf' target='_blank'>https://arxiv.org/pdf/2405.07104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Schwarz, Arian Mehrfard, Golchehr Amirkhani, Henry Phalen, Justin H. Ma, Robert B. Grupp, Alejandro Martin-Gomez, Mehran Armand
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.07104">Uncertainty-Aware Shape Estimation of a Surgical Continuum Manipulator in Constrained Environments using Fiber Bragg Grating Sensors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continuum Dexterous Manipulators (CDMs) are well-suited tools for minimally invasive surgery due to their inherent dexterity and reachability. Nonetheless, their flexible structure and non-linear curvature pose significant challenges for shape-based feedback control. The use of Fiber Bragg Grating (FBG) sensors for shape sensing has shown great potential in estimating the CDM's tip position and subsequently reconstructing the shape using optimization algorithms. This optimization, however, is under-constrained and may be ill-posed for complex shapes, falling into local minima. In this work, we introduce a novel method capable of directly estimating a CDM's shape from FBG sensor wavelengths using a deep neural network. In addition, we propose the integration of uncertainty estimation to address the critical issue of uncertainty in neural network predictions. Neural network predictions are unreliable when the input sample is outside the training distribution or corrupted by noise. Recognizing such deviations is crucial when integrating neural networks within surgical robotics, as inaccurate estimations can pose serious risks to the patient. We present a robust method that not only improves the precision upon existing techniques for FBG-based shape estimation but also incorporates a mechanism to quantify the models' confidence through uncertainty estimation. We validate the uncertainty estimation through extensive experiments, demonstrating its effectiveness and reliability on out-of-distribution (OOD) data, adding an additional layer of safety and precision to minimally invasive surgical robotics.
<div id='section'>Paperid: <span id='pid'>1186, <a href='https://arxiv.org/pdf/2405.01205.pdf' target='_blank'>https://arxiv.org/pdf/2405.01205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Mendes, Paolo Romano, David Garlan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01205">Error-Driven Uncertainty Aware Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks are often overconfident about their predictions, which undermines their reliability and trustworthiness. In this work, we present a novel technique, named Error-Driven Uncertainty Aware Training (EUAT), which aims to enhance the ability of neural classifiers to estimate their uncertainty correctly, namely to be highly uncertain when they output inaccurate predictions and low uncertain when their output is accurate. The EUAT approach operates during the model's training phase by selectively employing two loss functions depending on whether the training examples are correctly or incorrectly predicted by the model. This allows for pursuing the twofold goal of i) minimizing model uncertainty for correctly predicted inputs and ii) maximizing uncertainty for mispredicted inputs, while preserving the model's misprediction rate. We evaluate EUAT using diverse neural models and datasets in the image recognition domains considering both non-adversarial and adversarial settings. The results show that EUAT outperforms existing approaches for uncertainty estimation (including other uncertainty-aware training techniques, calibration, ensembles, and DEUP) by providing uncertainty estimates that not only have higher quality when evaluated via statistical metrics (e.g., correlation with residuals) but also when employed to build binary classifiers that decide whether the model's output can be trusted or not and under distributional data shifts.
<div id='section'>Paperid: <span id='pid'>1187, <a href='https://arxiv.org/pdf/2404.16954.pdf' target='_blank'>https://arxiv.org/pdf/2404.16954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harit Vishwakarma, Heguang Lin, Ramya Korlakai Vinayak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16954">Taming False Positives in Out-of-Distribution Detection with Human Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robustness to out-of-distribution (OOD) samples is crucial for safely deploying machine learning models in the open world. Recent works have focused on designing scoring functions to quantify OOD uncertainty. Setting appropriate thresholds for these scoring functions for OOD detection is challenging as OOD samples are often unavailable up front. Typically, thresholds are set to achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can lead to very high false positive rates (FPR), ranging from 60 to 96\%, as observed in the Open-OOD benchmark. In safety-critical real-life applications, e.g., medical diagnosis, controlling the FPR is essential when dealing with various OOD samples dynamically. To address these challenges, we propose a mathematically grounded OOD detection framework that leverages expert feedback to \emph{safely} update the threshold on the fly. We provide theoretical results showing that it is guaranteed to meet the FPR constraint at all times while minimizing the use of human feedback. Another key feature of our framework is that it can work with any scoring function for OOD uncertainty quantification. Empirical evaluation of our system on synthetic and benchmark OOD datasets shows that our method can maintain FPR at most $5\%$ while maximizing TPR.
<div id='section'>Paperid: <span id='pid'>1188, <a href='https://arxiv.org/pdf/2404.13288.pdf' target='_blank'>https://arxiv.org/pdf/2404.13288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zirui Zang, Ahmad Amine, Rahul Mangharam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.13288">PoseINN: Realtime Visual-based Pose Regression and Localization with Invertible Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating ego-pose from cameras is an important problem in robotics with applications ranging from mobile robotics to augmented reality. While SOTA models are becoming increasingly accurate, they can still be unwieldy due to high computational costs. In this paper, we propose to solve the problem by using invertible neural networks (INN) to find the mapping between the latent space of images and poses for a given scene. Our model achieves similar performance to the SOTA while being faster to train and only requiring offline rendering of low-resolution synthetic data. By using normalizing flows, the proposed method also provides uncertainty estimation for the output. We also demonstrated the efficiency of this method by deploying the model on a mobile robot.
<div id='section'>Paperid: <span id='pid'>1189, <a href='https://arxiv.org/pdf/2404.07518.pdf' target='_blank'>https://arxiv.org/pdf/2404.07518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuwei Sun, Ippei Fujisawa, Arthur Juliani, Jun Sakuma, Ryota Kanai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07518">Remembering Transformer for Continual Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks encounter the challenge of Catastrophic Forgetting (CF) in continual learning, where new task learning interferes with previously learned knowledge. Existing data fine-tuning and regularization methods necessitate task identity information during inference and cannot eliminate interference among different tasks, while soft parameter sharing approaches encounter the problem of an increasing model parameter size. To tackle these challenges, we propose the Remembering Transformer, inspired by the brain's Complementary Learning Systems (CLS). Remembering Transformer employs a mixture-of-adapters architecture and a generative model-based novelty detection mechanism in a pretrained Transformer to alleviate CF. Remembering Transformer dynamically routes task data to the most relevant adapter with enhanced parameter efficiency based on knowledge distillation. We conducted extensive experiments, including ablation studies on the novelty detection mechanism and model capacity of the mixture-of-adapters, in a broad range of class-incremental split tasks and permutation tasks. Our approach demonstrated SOTA performance surpassing the second-best method by 15.90% in the split tasks, reducing the memory footprint from 11.18M to 0.22M in the five splits CIFAR10 task.
<div id='section'>Paperid: <span id='pid'>1190, <a href='https://arxiv.org/pdf/2404.06230.pdf' target='_blank'>https://arxiv.org/pdf/2404.06230.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emre Ozfatura, Kerem Ozfatura, Alptekin Kupcu, Deniz Gunduz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06230">Aggressive or Imperceptible, or Both: Network Pruning Assisted Hybrid Byzantines in Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning (FL) has been introduced to enable a large number of clients, possibly mobile devices, to collaborate on generating a generalized machine learning model thanks to utilizing a larger number of local samples without sharing to offer certain privacy to collaborating clients. However, due to the participation of a large number of clients, it is often difficult to profile and verify each client, which leads to a security threat that malicious participants may hamper the accuracy of the trained model by conveying poisoned models during the training. Hence, the aggregation framework at the parameter server also needs to minimize the detrimental effects of these malicious clients. A plethora of attack and defence strategies have been analyzed in the literature. However, often the Byzantine problem is analyzed solely from the outlier detection perspective, being oblivious to the topology of neural networks (NNs).
  In the scope of this work, we argue that by extracting certain side information specific to the NN topology, one can design stronger attacks. Hence, inspired by the sparse neural networks, we introduce a hybrid sparse Byzantine attack that is composed of two parts: one exhibiting a sparse nature and attacking only certain NN locations with higher sensitivity, and the other being more silent but accumulating over time, where each ideally targets a different type of defence mechanism, and together they form a strong but imperceptible attack. Finally, we show through extensive simulations that the proposed hybrid Byzantine attack is effective against 8 different defence methods.
<div id='section'>Paperid: <span id='pid'>1191, <a href='https://arxiv.org/pdf/2404.02649.pdf' target='_blank'>https://arxiv.org/pdf/2404.02649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>NicolÃ² Felicioni, Lucas Maystre, Sina Ghiassian, Kamil Ciosek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.02649">On the Importance of Uncertainty in Decision-Making with Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate the role of uncertainty in decision-making problems with natural language as input. For such tasks, using Large Language Models as agents has become the norm. However, none of the recent approaches employ any additional phase for estimating the uncertainty the agent has about the world during the decision-making task. We focus on a fundamental decision-making framework with natural language as input, which is the one of contextual bandits, where the context information consists of text. As a representative of the approaches with no uncertainty estimation, we consider an LLM bandit with a greedy policy, which picks the action corresponding to the largest predicted reward. We compare this baseline to LLM bandits that make active use of uncertainty estimation by integrating the uncertainty in a Thompson Sampling policy. We employ different techniques for uncertainty estimation, such as Laplace Approximation, Dropout, and Epinets. We empirically show on real-world data that the greedy policy performs worse than the Thompson Sampling policies. These findings suggest that, while overlooked in the LLM literature, uncertainty plays a fundamental role in bandit tasks with LLMs.
<div id='section'>Paperid: <span id='pid'>1192, <a href='https://arxiv.org/pdf/2403.18514.pdf' target='_blank'>https://arxiv.org/pdf/2403.18514.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aissam Djahnine, Alexandre Popoff, Emilien Jupin-Delevaux, Vincent Cottin, Olivier Nempont, Loic Boussel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18514">CT-3DFlow : Leveraging 3D Normalizing Flows for Unsupervised Detection of Pathological Pulmonary CT scans</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised pathology detection can be implemented by training a model on healthy data only and measuring the deviation from the training set upon inference, for example with CNN-based feature extraction and one-class classifiers, or reconstruction-score-based methods such as AEs, GANs and Diffusion models. Normalizing Flows (NF) have the ability to directly learn the probability distribution of training examples through an invertible architecture. We leverage this property in a novel 3D NF-based model named CT-3DFlow, specifically tailored for patient-level pulmonary pathology detection in chest CT data. Our model is trained unsupervised on healthy 3D pulmonary CT patches, and detects deviations from its log-likelihood distribution as anomalies. We aggregate patches-level likelihood values from a patient's CT scan to provide a patient-level 'normal'/'abnormal' prediction. Out-of-distribution detection performance is evaluated using expert annotations on a separate chest CT test dataset, outperforming other state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1193, <a href='https://arxiv.org/pdf/2403.14067.pdf' target='_blank'>https://arxiv.org/pdf/2403.14067.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Blanchet, Jiajin Li, Markus Pelger, Greg Zanotti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14067">Automatic Outlier Rectification via Optimal Transport</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel conceptual framework to detect outliers using optimal transport with a concave cost function. Conventional outlier detection approaches typically use a two-stage procedure: first, outliers are detected and removed, and then estimation is performed on the cleaned data. However, this approach does not inform outlier removal with the estimation task, leaving room for improvement. To address this limitation, we propose an automatic outlier rectification mechanism that integrates rectification and estimation within a joint optimization framework. We take the first step to utilize the optimal transport distance with a concave cost function to construct a rectification set in the space of probability distributions. Then, we select the best distribution within the rectification set to perform the estimation task. Notably, the concave cost function we introduced in this paper is the key to making our estimator effectively identify the outlier during the optimization process. We demonstrate the effectiveness of our approach over conventional approaches in simulations and empirical analyses for mean estimation, least absolute regression, and the fitting of option implied volatility surfaces.
<div id='section'>Paperid: <span id='pid'>1194, <a href='https://arxiv.org/pdf/2403.10803.pdf' target='_blank'>https://arxiv.org/pdf/2403.10803.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Li, Sitong Li, Shanshan Wang, Yicheng Zeng, Falong Tan, Chuanlong Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10803">Enhancing Out-of-Distribution Detection with Multitesting-based Layer-wise Feature Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying machine learning in open environments presents the challenge of encountering diverse test inputs that differ significantly from the training data. These out-of-distribution samples may exhibit shifts in local or global features compared to the training distribution. The machine learning (ML) community has responded with a number of methods aimed at distinguishing anomalous inputs from original training data. However, the majority of previous studies have primarily focused on the output layer or penultimate layer of pre-trained deep neural networks. In this paper, we propose a novel framework, Multitesting-based Layer-wise Out-of-Distribution (OOD) Detection (MLOD), to identify distributional shifts in test samples at different levels of features through rigorous multiple testing procedure. Our approach distinguishes itself from existing methods as it does not require modifying the structure or fine-tuning of the pre-trained classifier. Through extensive experiments, we demonstrate that our proposed framework can seamlessly integrate with any existing distance-based inspection method while efficiently utilizing feature extractors of varying depths. Our scheme effectively enhances the performance of out-of-distribution detection when compared to baseline methods. In particular, MLOD-Fisher achieves superior performance in general. When trained using KNN on CIFAR10, MLOD-Fisher significantly lowers the false positive rate (FPR) from 24.09% to 7.47% on average compared to merely utilizing the features of the last layer.
<div id='section'>Paperid: <span id='pid'>1195, <a href='https://arxiv.org/pdf/2403.10168.pdf' target='_blank'>https://arxiv.org/pdf/2403.10168.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arthur Thuy, Dries F. Benoit
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10168">Explainability through uncertainty: Trustworthy decision-making with neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty is a key feature of any machine learning model and is particularly important in neural networks, which tend to be overconfident. This overconfidence is worrying under distribution shifts, where the model performance silently degrades as the data distribution diverges from the training data distribution. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Although methods for uncertainty estimation have been developed, they have not been explicitly linked to the field of explainable artificial intelligence (XAI). Furthermore, literature in operations research ignores the actionability component of uncertainty estimation and does not consider distribution shifts. This work proposes a general uncertainty framework, with contributions being threefold: (i) uncertainty estimation in ML models is positioned as an XAI technique, giving local and model-specific explanations; (ii) classification with rejection is used to reduce misclassifications by bringing a human expert in the loop for uncertain observations; (iii) the framework is applied to a case study on neural networks in educational data mining subject to distribution shifts. Uncertainty as XAI improves the model's trustworthiness in downstream decision-making tasks, giving rise to more actionable and robust machine learning systems in operations research.
<div id='section'>Paperid: <span id='pid'>1196, <a href='https://arxiv.org/pdf/2403.03412.pdf' target='_blank'>https://arxiv.org/pdf/2403.03412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingrui Ji, Yao Zhu, Zhigang Li, Jiansheng Chen, Yunlong Kong, Jingbo Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.03412">Advancing Out-of-Distribution Detection through Data Purification and Dynamic Activation Function Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the dynamic realms of machine learning and deep learning, the robustness and reliability of models are paramount, especially in critical real-world applications. A fundamental challenge in this sphere is managing Out-of-Distribution (OOD) samples, significantly increasing the risks of model misclassification and uncertainty. Our work addresses this challenge by enhancing the detection and management of OOD samples in neural networks. We introduce OOD-R (Out-of-Distribution-Rectified), a meticulously curated collection of open-source datasets with enhanced noise reduction properties. In-Distribution (ID) noise in existing OOD datasets can lead to inaccurate evaluation of detection algorithms. Recognizing this, OOD-R incorporates noise filtering technologies to refine the datasets, ensuring a more accurate and reliable evaluation of OOD detection algorithms. This approach not only improves the overall quality of data but also aids in better distinguishing between OOD and ID samples, resulting in up to a 2.5\% improvement in model accuracy and a minimum 3.2\% reduction in false positives. Furthermore, we present ActFun, an innovative method that fine-tunes the model's response to diverse inputs, thereby improving the stability of feature extraction and minimizing specificity issues. ActFun addresses the common problem of model overconfidence in OOD detection by strategically reducing the influence of hidden units, which enhances the model's capability to estimate OOD uncertainty more accurately. Implementing ActFun in the OOD-R dataset has led to significant performance enhancements, including an 18.42\% increase in AUROC of the GradNorm method and a 16.93\% decrease in FPR95 of the Energy method. Overall, our research not only advances the methodologies in OOD detection but also emphasizes the importance of dataset integrity for accurate algorithm evaluation.
<div id='section'>Paperid: <span id='pid'>1197, <a href='https://arxiv.org/pdf/2403.01485.pdf' target='_blank'>https://arxiv.org/pdf/2403.01485.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sam Dauncey, Chris Holmes, Christopher Williams, Fabian Falck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01485">Approximations to the Fisher Information Metric of Deep Generative Models for Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Likelihood-based deep generative models such as score-based diffusion models and variational autoencoders are state-of-the-art machine learning models approximating high-dimensional distributions of data such as images, text, or audio. One of many downstream tasks they can be naturally applied to is out-of-distribution (OOD) detection. However, seminal work by Nalisnick et al. which we reproduce showed that deep generative models consistently infer higher log-likelihoods for OOD data than data they were trained on, marking an open problem. In this work, we analyse using the gradient of a data point with respect to the parameters of the deep generative model for OOD detection, based on the simple intuition that OOD data should have larger gradient norms than training data. We formalise measuring the size of the gradient as approximating the Fisher information metric. We show that the Fisher information matrix (FIM) has large absolute diagonal values, motivating the use of chi-square distributed, layer-wise gradient norms as features. We combine these features to make a simple, model-agnostic and hyperparameter-free method for OOD detection which estimates the joint density of the layer-wise gradient norms for a given data point. We find that these layer-wise gradient norms are weakly correlated, rendering their combined usage informative, and prove that the layer-wise gradient norms satisfy the principle of (data representation) invariance. Our empirical results indicate that this method outperforms the Typicality test for most deep generative models and image dataset pairings.
<div id='section'>Paperid: <span id='pid'>1198, <a href='https://arxiv.org/pdf/2403.00543.pdf' target='_blank'>https://arxiv.org/pdf/2403.00543.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuting Li, Yingyi Chen, Xuanlong Yu, Dexiong Chen, Xi Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.00543">SURE: SUrvey REcipes for building reliable and robust deep networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we revisit techniques for uncertainty estimation within deep neural networks and consolidate a suite of techniques to enhance their reliability. Our investigation reveals that an integrated application of diverse techniques--spanning model regularization, classifier and optimization--substantially improves the accuracy of uncertainty predictions in image classification tasks. The synergistic effect of these techniques culminates in our novel SURE approach. We rigorously evaluate SURE against the benchmark of failure prediction, a critical testbed for uncertainty estimation efficacy. Our results showcase a consistently better performance than models that individually deploy each technique, across various datasets and model architectures. When applied to real-world challenges, such as data corruption, label noise, and long-tailed class distribution, SURE exhibits remarkable robustness, delivering results that are superior or on par with current state-of-the-art specialized methods. Particularly on Animal-10N and Food-101N for learning with noisy labels, SURE achieves state-of-the-art performance without any task-specific adjustments. This work not only sets a new benchmark for robust uncertainty estimation but also paves the way for its application in diverse, real-world scenarios where reliability is paramount. Our code is available at \url{https://yutingli0606.github.io/SURE/}.
<div id='section'>Paperid: <span id='pid'>1199, <a href='https://arxiv.org/pdf/2402.03985.pdf' target='_blank'>https://arxiv.org/pdf/2402.03985.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ossi RÃ¤isÃ¤, Antti Honkela
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03985">A Bias-Variance Decomposition for Ensembles over Multiple Synthetic Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent studies have highlighted the benefits of generating multiple synthetic datasets for supervised learning, from increased accuracy to more effective model selection and uncertainty estimation. These benefits have clear empirical support, but the theoretical understanding of them is currently very light. We seek to increase the theoretical understanding by deriving bias-variance decompositions for several settings of using multiple synthetic datasets, including differentially private synthetic data. Our theory yields a simple rule of thumb to select the appropriate number of synthetic datasets in the case of mean-squared error and Brier score. We investigate how our theory works in practice with several real datasets, downstream predictors and error metrics. As our theory predicts, multiple synthetic datasets often improve accuracy, while a single large synthetic dataset gives at best minimal improvement, showing that our insights are practically relevant.
<div id='section'>Paperid: <span id='pid'>1200, <a href='https://arxiv.org/pdf/2402.00396.pdf' target='_blank'>https://arxiv.org/pdf/2402.00396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vikranth Dwaracherla, Seyed Mohammad Asghari, Botao Hao, Benjamin Van Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00396">Efficient Exploration for LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present evidence of substantial benefit from efficient exploration in gathering human feedback to improve large language models. In our experiments, an agent sequentially generates queries while fitting a reward model to the feedback received. Our best-performing agent generates queries using double Thompson sampling, with uncertainty represented by an epistemic neural network. Our results demonstrate that efficient exploration enables high levels of performance with far fewer queries. Further, both uncertainty estimation and the choice of exploration scheme play critical roles.
<div id='section'>Paperid: <span id='pid'>1201, <a href='https://arxiv.org/pdf/2401.08140.pdf' target='_blank'>https://arxiv.org/pdf/2401.08140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kiyohiro Nakayama, Mikaela Angelina Uy, Yang You, Ke Li, Leonidas J. Guibas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08140">ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Field</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural radiance fields (NeRFs) have gained popularity with multiple works showing promising results across various applications. However, to the best of our knowledge, existing works do not explicitly model the distribution of training camera poses, or consequently the triangulation quality, a key factor affecting reconstruction quality dating back to classical vision literature. We close this gap with ProvNeRF, an approach that models the \textbf{provenance} for each point -- i.e., the locations where it is likely visible -- of NeRFs as a stochastic field. We achieve this by extending implicit maximum likelihood estimation (IMLE) to functional space with an optimizable objective. We show that modeling per-point provenance during the NeRF optimization enriches the model with information on triangulation leading to improvements in novel view synthesis and uncertainty estimation under the challenging sparse, unconstrained view setting against competitive baselines.
<div id='section'>Paperid: <span id='pid'>1202, <a href='https://arxiv.org/pdf/2401.01459.pdf' target='_blank'>https://arxiv.org/pdf/2401.01459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ananya Joshi, Tina Townes, Nolan Gormley, Luke Neureiter, Roni Rosenfeld, Bryan Wilder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01459">Outlier Ranking in Large-Scale Public Health Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Disease control experts inspect public health data streams daily for outliers worth investigating, like those corresponding to data quality issues or disease outbreaks. However, they can only examine a few of the thousands of maximally-tied outliers returned by univariate outlier detection methods applied to large-scale public health data streams. To help experts distinguish the most important outliers from these thousands of tied outliers, we propose a new task for algorithms to rank the outputs of any univariate method applied to each of many streams. Our novel algorithm for this task, which leverages hierarchical networks and extreme value analysis, performed the best across traditional outlier detection metrics in a human-expert evaluation using public health data streams. Most importantly, experts have used our open-source Python implementation since April 2023 and report identifying outliers worth investigating 9.1x faster than their prior baseline. Other organizations can readily adapt this implementation to create rankings from the outputs of their tailored univariate methods across large-scale streams.
<div id='section'>Paperid: <span id='pid'>1203, <a href='https://arxiv.org/pdf/2312.14996.pdf' target='_blank'>https://arxiv.org/pdf/2312.14996.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal Bechny, Giuliana Monachino, Luigi Fiorillo, Julia van der Meer, Markus H. Schmidt, Claudio L. A. Bassetti, Athina Tzovara, Francesca D. Faraci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.14996">Bridging AI and Clinical Practice: Integrating Automated Sleep Scoring Algorithm with Uncertainty-Guided Physician Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose: This study aims to enhance the clinical use of automated sleep-scoring algorithms by incorporating an uncertainty estimation approach to efficiently assist clinicians in the manual review of predicted hypnograms, a necessity due to the notable inter-scorer variability inherent in polysomnography (PSG) databases. Our efforts target the extent of review required to achieve predefined agreement levels, examining both in-domain and out-of-domain data, and considering subjects diagnoses. Patients and methods: Total of 19578 PSGs from 13 open-access databases were used to train U-Sleep, a state-of-the-art sleep-scoring algorithm. We leveraged a comprehensive clinical database of additional 8832 PSGs, covering a full spectrum of ages and sleep-disorders, to refine the U-Sleep, and to evaluate different uncertainty-quantification approaches, including our novel confidence network. The ID data consisted of PSGs scored by over 50 physicians, and the two OOD sets comprised recordings each scored by a unique senior physician. Results: U-Sleep demonstrated robust performance, with Cohen's kappa (K) at 76.2% on ID and 73.8-78.8% on OOD data. The confidence network excelled at identifying uncertain predictions, achieving AUROC scores of 85.7% on ID and 82.5-85.6% on OOD data. Independently of sleep-disorder status, statistical evaluations revealed significant differences in confidence scores between aligning vs discording predictions, and significant correlations of confidence scores with classification performance metrics. To achieve K of at least 90% with physician intervention, examining less than 29.0% of uncertain epochs was required, substantially reducing physicians workload, and facilitating near-perfect agreement.
<div id='section'>Paperid: <span id='pid'>1204, <a href='https://arxiv.org/pdf/2312.14427.pdf' target='_blank'>https://arxiv.org/pdf/2312.14427.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mostafa ElAraby, Sabyasachi Sahoo, Yann Pequignot, Paul Novello, Liam Paull
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.14427">GROOD: GRadient-Aware Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for ensuring the reliability of deep learning models in real-world applications. Existing methods typically focus on feature representations or output-space analysis, often assuming a distribution over these spaces or leveraging gradient norms with respect to model parameters. However, these approaches struggle to distinguish near-OOD samples and often require extensive hyper-parameter tuning, limiting their practicality.In this work, we propose GRadient-aware Out-Of-Distribution detection (GROOD), a method that derives an OOD prototype from synthetic samples and computes class prototypes directly from In-distribution (ID) training data. By analyzing the gradients of a nearest-class-prototype loss function concerning an artificial OOD prototype, our approach achieves a clear separation between in-distribution and OOD samples. Experimental evaluations demonstrate that gradients computed from the OOD prototype enhance the distinction between ID and OOD data, surpassing established baselines in robustness, particularly on ImageNet-1k. These findings highlight the potential of gradient-based methods and prototype-driven approaches in advancing OOD detection within deep neural networks.
<div id='section'>Paperid: <span id='pid'>1205, <a href='https://arxiv.org/pdf/2312.02158.pdf' target='_blank'>https://arxiv.org/pdf/2312.02158.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anh-Quan Cao, Angela Dai, Raoul de Charette
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.02158">PaSCo: Urban 3D Panoptic Scene Completion with Uncertainty Awareness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the task of Panoptic Scene Completion (PSC) which extends the recently popular Semantic Scene Completion (SSC) task with instance-level information to produce a richer understanding of the 3D scene. Our PSC proposal utilizes a hybrid mask-based technique on the non-empty voxels from sparse multi-scale completions. Whereas the SSC literature overlooks uncertainty which is critical for robotics applications, we instead propose an efficient ensembling to estimate both voxel-wise and instance-wise uncertainties along PSC. This is achieved by building on a multi-input multi-output (MIMO) strategy, while improving performance and yielding better uncertainty for little additional compute. Additionally, we introduce a technique to aggregate permutation-invariant mask predictions. Our experiments demonstrate that our method surpasses all baselines in both Panoptic Scene Completion and uncertainty estimation on three large-scale autonomous driving datasets. Our code and data are available at https://astra-vision.github.io/PaSCo .
<div id='section'>Paperid: <span id='pid'>1206, <a href='https://arxiv.org/pdf/2311.08150.pdf' target='_blank'>https://arxiv.org/pdf/2311.08150.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pieter Dewulf, Bernard De Baets, Michiel Stock
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.08150">The Hyperdimensional Transform for Distributional Modelling, Regression and Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hyperdimensional computing (HDC) is an increasingly popular computing paradigm with immense potential for future intelligent applications. Although the main ideas already took form in the 1990s, HDC recently gained significant attention, especially in the field of machine learning and data science. Next to efficiency, interoperability and explainability, HDC offers attractive properties for generalization as it can be seen as an attempt to combine connectionist ideas from neural networks with symbolic aspects. In recent work, we introduced the hyperdimensional transform, revealing deep theoretical foundations for representing functions and distributions as high-dimensional holographic vectors. Here, we present the power of the hyperdimensional transform to a broad data science audience. We use the hyperdimensional transform as a theoretical basis and provide insight into state-of-the-art HDC approaches for machine learning. We show how existing algorithms can be modified and how this transform can lead to a novel, well-founded toolbox. Next to the standard regression and classification tasks of machine learning, our discussion includes various aspects of statistical modelling, such as representation, learning and deconvolving distributions, sampling, Bayesian inference, and uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1207, <a href='https://arxiv.org/pdf/2310.18104.pdf' target='_blank'>https://arxiv.org/pdf/2310.18104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuohao Sun, Yiqiao Qiu, Zhijun Tan, Weishi Zheng, Ruixuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18104">Classifier-head Informed Feature Masking and Prototype-based Logit Smoothing for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential when deploying neural networks in the real world. One main challenge is that neural networks often make overconfident predictions on OOD data. In this study, we propose an effective post-hoc OOD detection method based on a new feature masking strategy and a novel logit smoothing strategy. Feature masking determines the important features at the penultimate layer for each in-distribution (ID) class based on the weights of the ID class in the classifier head and masks the rest features. Logit smoothing computes the cosine similarity between the feature vector of the test sample and the prototype of the predicted ID class at the penultimate layer and uses the similarity as an adaptive temperature factor on the logit to alleviate the network's overconfidence prediction for OOD data. With these strategies, we can reduce feature activation of OOD data and enlarge the gap in OOD score between ID and OOD data. Extensive experiments on multiple standard OOD detection benchmarks demonstrate the effectiveness of our method and its compatibility with existing methods, with new state-of-the-art performance achieved from our method. The source code will be released publicly.
<div id='section'>Paperid: <span id='pid'>1208, <a href='https://arxiv.org/pdf/2310.12620.pdf' target='_blank'>https://arxiv.org/pdf/2310.12620.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Guo, Chenxi Hu, Yi Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.12620">Predict the Future from the Past? On the Temporal Data Distribution Shift in Financial Sentiment Classifications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Temporal data distribution shift is prevalent in the financial text. How can a financial sentiment analysis system be trained in a volatile market environment that can accurately infer sentiment and be robust to temporal data distribution shifts? In this paper, we conduct an empirical study on the financial sentiment analysis system under temporal data distribution shifts using a real-world financial social media dataset that spans three years. We find that the fine-tuned models suffer from general performance degradation in the presence of temporal distribution shifts. Furthermore, motivated by the unique temporal nature of the financial text, we propose a novel method that combines out-of-distribution detection with time series modeling for temporal financial sentiment analysis. Experimental results show that the proposed method enhances the model's capability to adapt to evolving temporal shifts in a volatile financial market.
<div id='section'>Paperid: <span id='pid'>1209, <a href='https://arxiv.org/pdf/2310.09999.pdf' target='_blank'>https://arxiv.org/pdf/2310.09999.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jirong Yi, Jingchao Gao, Tianming Wang, Xiaodong Wu, Weiyu Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.09999">Outlier Detection Using Generative Models with Theoretical Performance Guarantees</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper considers the problem of recovering signals modeled by generative models from linear measurements contaminated with sparse outliers. We propose an outlier detection approach for reconstructing the ground-truth signals modeled by generative models under sparse outliers. We establish theoretical recovery guarantees for reconstruction of signals using generative models in the presence of outliers, giving lower bounds on the number of correctable outliers. Our results are applicable to both linear generator neural networks and the nonlinear generator neural networks with an arbitrary number of layers. We propose an iterative alternating direction method of multipliers (ADMM) algorithm for solving the outlier detection problem via $\ell_1$ norm minimization, and a gradient descent algorithm for solving the outlier detection problem via squared $\ell_1$ norm minimization. We conduct extensive experiments using variational auto-encoder and deep convolutional generative adversarial networks, and the experimental results show that the signals can be successfully reconstructed under outliers using our approach. Our approach outperforms the traditional Lasso and $\ell_2$ minimization approach.
<div id='section'>Paperid: <span id='pid'>1210, <a href='https://arxiv.org/pdf/2310.08731.pdf' target='_blank'>https://arxiv.org/pdf/2310.08731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geigh Zollicoffer, Kenneth Eaton, Jonathan Balloch, Julia Kim, Wei Zhou, Robert Wright, Mark O. Riedl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08731">Novelty Detection in Reinforcement Learning with World Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning (RL) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as novelties. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional machine learning novelty detection methods as well as currently accepted RL focused novelty detection algorithms.
<div id='section'>Paperid: <span id='pid'>1211, <a href='https://arxiv.org/pdf/2310.08040.pdf' target='_blank'>https://arxiv.org/pdf/2310.08040.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoyang Song, Wenbo Sun, Maher Nouiehed, Raed Al Kontar, Judy Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08040">SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current techniques for Out-of-Distribution (OoD) detection predominantly rely on quantifying predictive uncertainty and incorporating model regularization during the training phase, using either real or synthetic OoD samples. However, methods that utilize real OoD samples lack exploration and are prone to overfit the OoD samples at hand. Whereas synthetic samples are often generated based on features extracted from training data, rendering them less effective when the training and OoD data are highly overlapped in the feature space. In this work, we propose a Wasserstein-score-based generative adversarial training scheme to enhance OoD detection accuracy, which, for the first time, performs data augmentation and exploration simultaneously under the supervision of limited OoD samples. Specifically, the generator explores OoD spaces and generates synthetic OoD samples using feedback from the discriminator, while the discriminator exploits both the observed and synthesized samples for OoD detection using a predefined Wasserstein score. We provide theoretical guarantees that the optimal solutions of our generative scheme are statistically achievable through adversarial training in empirical settings. We then demonstrate that the proposed method outperforms state-of-the-art techniques on various computer vision datasets and exhibits superior generalizability to unseen OoD data.
<div id='section'>Paperid: <span id='pid'>1212, <a href='https://arxiv.org/pdf/2310.06823.pdf' target='_blank'>https://arxiv.org/pdf/2310.06823.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MouÃ¯n Ben Ammar, Nacim Belkhir, Sebastian Popescu, Antoine Manzanera, Gianni Franchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06823">NECO: NEural Collapse Based Out-of-distribution detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) data is a critical challenge in machine learning due to model overconfidence, often without awareness of their epistemological limits. We hypothesize that ``neural collapse'', a phenomenon affecting in-distribution data for models trained beyond loss convergence, also influences OOD data. To benefit from this interplay, we introduce NECO, a novel post-hoc method for OOD detection, which leverages the geometric properties of ``neural collapse'' and of principal component spaces to identify OOD data. Our extensive experiments demonstrate that NECO achieves state-of-the-art results on both small and large-scale OOD detection tasks while exhibiting strong generalization capabilities across different network architectures. Furthermore, we provide a theoretical explanation for the effectiveness of our method in OOD detection. Code is available at https://gitlab.com/drti/neco
<div id='section'>Paperid: <span id='pid'>1213, <a href='https://arxiv.org/pdf/2310.00923.pdf' target='_blank'>https://arxiv.org/pdf/2310.00923.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Risto Ojala, Alvari SeppÃ¤nen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00923">Lightweight Regression Model with Prediction Interval Estimation for Computer Vision-based Winter Road Surface Condition Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Winter conditions pose several challenges for automated driving applications. A key challenge during winter is accurate assessment of road surface condition, as its impact on friction is a critical parameter for safely and reliably controlling a vehicle. This paper proposes a deep learning regression model, SIWNet, capable of estimating road surface friction properties from camera images. SIWNet extends state of the art by including an uncertainty estimation mechanism in the architecture. This is achieved by including an additional head in the network, which estimates a prediction interval. The prediction interval head is trained with a maximum likelihood loss function. The model was trained and tested with the SeeingThroughFog dataset, which features corresponding road friction sensor readings and images from an instrumented vehicle. Acquired results highlight the functionality of the prediction interval estimation of SIWNet, while the network also achieved similar point estimate accuracy as the previous state of the art. Furthermore, the SIWNet architecture is several times more lightweight than the previously applied state-of-the-art model, resulting in more practical and efficient deployment.
<div id='section'>Paperid: <span id='pid'>1214, <a href='https://arxiv.org/pdf/2309.16397.pdf' target='_blank'>https://arxiv.org/pdf/2309.16397.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zenan Li, Fan Nie, Qiao Sun, Fang Da, Hang Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16397">Uncertainty-Aware Decision Transformer for Stochastic Driving Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline Reinforcement Learning (RL) enables policy learning without active interactions, making it especially appealing for self-driving tasks. Recent successes of Transformers inspire casting offline RL as sequence modeling, which, however, fails in stochastic environments with incorrect assumptions that identical actions can consistently achieve the same goal. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer (UNREST) for planning in stochastic driving environments without introducing additional transition or complex generative models. Specifically, UNREST estimates uncertainties by conditional mutual information between transitions and returns. Discovering 'uncertainty accumulation' and 'temporal locality' properties of driving environments, we replace the global returns in decision transformers with truncated returns less affected by environments to learn from actual outcomes of actions rather than environment transitions. We also dynamically evaluate uncertainty at inference for cautious planning. Extensive experiments demonstrate UNREST's superior performance in various driving scenarios and the power of our uncertainty estimation strategy.
<div id='section'>Paperid: <span id='pid'>1215, <a href='https://arxiv.org/pdf/2309.16314.pdf' target='_blank'>https://arxiv.org/pdf/2309.16314.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julyan Arbel, Konstantinos Pitas, Mariia Vladimirova, Vincent Fortuin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16314">A Primer on Bayesian Neural Networks: Review and Debates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks have achieved remarkable performance across various problem domains, but their widespread applicability is hindered by inherent limitations such as overconfidence in predictions, lack of interpretability, and vulnerability to adversarial attacks. To address these challenges, Bayesian neural networks (BNNs) have emerged as a compelling extension of conventional neural networks, integrating uncertainty estimation into their predictive capabilities.
  This comprehensive primer presents a systematic introduction to the fundamental concepts of neural networks and Bayesian inference, elucidating their synergistic integration for the development of BNNs. The target audience comprises statisticians with a potential background in Bayesian methods but lacking deep learning expertise, as well as machine learners proficient in deep neural networks but with limited exposure to Bayesian statistics. We provide an overview of commonly employed priors, examining their impact on model behavior and performance. Additionally, we delve into the practical considerations associated with training and inference in BNNs.
  Furthermore, we explore advanced topics within the realm of BNN research, acknowledging the existence of ongoing debates and controversies. By offering insights into cutting-edge developments, this primer not only equips researchers and practitioners with a solid foundation in BNNs, but also illuminates the potential applications of this dynamic field. As a valuable resource, it fosters an understanding of BNNs and their promising prospects, facilitating further advancements in the pursuit of knowledge and innovation.
<div id='section'>Paperid: <span id='pid'>1216, <a href='https://arxiv.org/pdf/2309.15704.pdf' target='_blank'>https://arxiv.org/pdf/2309.15704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antoine de Mathelin, FranÃ§ois Deheeger, Mathilde Mougeot, Nicolas Vayatis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.15704">Deep Out-of-Distribution Uncertainty Quantification via Weight Entropy Maximization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper deals with uncertainty quantification and out-of-distribution detection in deep learning using Bayesian and ensemble methods. It proposes a practical solution to the lack of prediction diversity observed recently for standard approaches when used out-of-distribution (Ovadia et al., 2019; Liu et al., 2021). Considering that this issue is mainly related to a lack of weight diversity, we claim that standard methods sample in "over-restricted" regions of the weight space due to the use of "over-regularization" processes, such as weight decay and zero-mean centered Gaussian priors. We propose to solve the problem by adopting the maximum entropy principle for the weight distribution, with the underlying idea to maximize the weight diversity. Under this paradigm, the epistemic uncertainty is described by the weight distribution of maximal entropy that produces neural networks "consistent" with the training observations. Considering stochastic neural networks, a practical optimization is derived to build such a distribution, defined as a trade-off between the average empirical risk and the weight distribution entropy. We develop a novel weight parameterization for the stochastic model, based on the singular value decomposition of the neural network's hidden representations, which enables a large increase of the weight entropy for a small empirical risk penalization. We provide both theoretical and numerical results to assess the efficiency of the approach. In particular, the proposed algorithm appears in the top three best methods in all configurations of an extensive out-of-distribution detection benchmark including more than thirty competitors.
<div id='section'>Paperid: <span id='pid'>1217, <a href='https://arxiv.org/pdf/2309.12301.pdf' target='_blank'>https://arxiv.org/pdf/2309.12301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefan Smeu, Elena Burceanu, Emanuela Haller, Andrei Liviu Nicolicioiu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.12301">Environment-biased Feature Ranking for Novelty Detection Robustness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We tackle the problem of robust novelty detection, where we aim to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors. Specifically, we operate in a setup with multiple environments, where we determine the set of features that are associated more with the environments, rather than to the content relevant for the task. Thus, we propose a method that starts with a pretrained embedding and a multi-env setup and manages to rank the features based on their environment-focus. First, we compute a per-feature score based on the feature distribution variance between envs. Next, we show that by dropping the highly scored ones, we manage to remove spurious correlations and improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark, that we introduce for this task.
<div id='section'>Paperid: <span id='pid'>1218, <a href='https://arxiv.org/pdf/2309.02995.pdf' target='_blank'>https://arxiv.org/pdf/2309.02995.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eduardo Aguilar, Bogdan Raducanu, Petia Radeva, Joost Van de Weijer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02995">Continual Evidential Deep Learning for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty-based deep learning models have attracted a great deal of interest for their ability to provide accurate and reliable predictions. Evidential deep learning stands out achieving remarkable performance in detecting out-of-distribution (OOD) data with a single deterministic neural network. Motivated by this fact, in this paper we propose the integration of an evidential deep learning method into a continual learning framework in order to perform simultaneously incremental object classification and OOD detection. Moreover, we analyze the ability of vacuity and dissonance to differentiate between in-distribution data belonging to old classes and OOD data. The proposed method, called CEDL, is evaluated on CIFAR-100 considering two settings consisting of 5 and 10 tasks, respectively. From the obtained results, we could appreciate that the proposed method, in addition to provide comparable results in object classification with respect to the baseline, largely outperforms OOD detection compared to several posthoc methods on three evaluation metrics: AUROC, AUPR and FPR95.
<div id='section'>Paperid: <span id='pid'>1219, <a href='https://arxiv.org/pdf/2309.02732.pdf' target='_blank'>https://arxiv.org/pdf/2309.02732.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steven X. Ding, Linlin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02732">A study on fault diagnosis in nonlinear dynamic systems with uncertainties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this draft, fault diagnosis in nonlinear dynamic systems is addressed. The objective of this work is to establish a framework, in which not only model-based but also data-driven and machine learning based fault diagnosis strategies can be uniformly handled. Instead of the well-established input-output and the associated state space models, stable image and kernel representations are adopted in our work as the basic process model forms. Based on it, the nominal system dynamics can then be modelled as a lower-dimensional manifold embedded in the process data space. To achieve a reliable fault detection as a classification problem, projection technique is a capable tool. For nonlinear dynamic systems, we propose to construct projection systems in the well-established framework of Hamiltonian systems and by means of the normalised image and kernel representations. For nonlinear dynamic systems, process data form a non-Euclidean space. Consequently, the norm-based distance defined in Hilbert space is not suitable to measure the distance from a data vector to the manifold of the nominal dynamics. To deal with this issue, we propose to use a Bregman divergence, a measure of difference between two points in a space, as a solution. Moreover, for our purpose of achieving a performance-oriented fault detection, the Bregman divergences adopted in our work are defined by Hamiltonian functions. This scheme not only enables to realise the performance-oriented fault detection, but also uncovers the information geometric aspect of our work. The last part of our work is devoted to the kernel representation based fault detection and uncertainty estimation that can be equivalently used for fault estimation. It is demonstrated that the projection onto the manifold of uncertainty data, together with the correspondingly defined Bregman divergence, is also capable for fault detection.
<div id='section'>Paperid: <span id='pid'>1220, <a href='https://arxiv.org/pdf/2308.12316.pdf' target='_blank'>https://arxiv.org/pdf/2308.12316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Richard Bergna, Felix Opolka, Pietro LiÃ², Jose Miguel Hernandez-Lobato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12316">Graph Neural Stochastic Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel model Graph Neural Stochastic Differential Equations (Graph Neural SDEs). This technique enhances the Graph Neural Ordinary Differential Equations (Graph Neural ODEs) by embedding randomness into data representation using Brownian motion. This inclusion allows for the assessment of prediction uncertainty, a crucial aspect frequently missed in current models. In our framework, we spotlight the \textit{Latent Graph Neural SDE} variant, demonstrating its effectiveness. Through empirical studies, we find that Latent Graph Neural SDEs surpass conventional models like Graph Convolutional Networks and Graph Neural ODEs, especially in confidence prediction, making them superior in handling out-of-distribution detection across both static and spatio-temporal contexts.
<div id='section'>Paperid: <span id='pid'>1221, <a href='https://arxiv.org/pdf/2308.10650.pdf' target='_blank'>https://arxiv.org/pdf/2308.10650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Frederik Boe HÃ¼ttel, Filipe Rodrigues, Francisco CÃ¢mara Pereira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10650">Deep Evidential Learning for Bayesian Quantile Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It is desirable to have accurate uncertainty estimation from a single deterministic forward-pass model, as traditional methods for uncertainty quantification are computationally expensive. However, this is difficult because single forward-pass models do not sample weights during inference and often make assumptions about the target distribution, such as assuming it is Gaussian. This can be restrictive in regression tasks, where the mean and standard deviation are inadequate to model the target distribution accurately. This paper proposes a deep Bayesian quantile regression model that can estimate the quantiles of a continuous target distribution without the Gaussian assumption. The proposed method is based on evidential learning, which allows the model to capture aleatoric and epistemic uncertainty with a single deterministic forward-pass model. This makes the method efficient and scalable to large models and datasets. We demonstrate that the proposed method achieves calibrated uncertainties on non-Gaussian distributions, disentanglement of aleatoric and epistemic uncertainty, and robustness to out-of-distribution samples.
<div id='section'>Paperid: <span id='pid'>1222, <a href='https://arxiv.org/pdf/2308.03723.pdf' target='_blank'>https://arxiv.org/pdf/2308.03723.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>McKell Woodland, Nihil Patel, Mais Al Taie, Joshua P. Yung, Tucker J. Netherton, Ankit B. Patel, Kristy K. Brock
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.03723">Dimensionality Reduction for Improving Out-of-Distribution Detection in Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clinically deployed segmentation models are known to fail on data outside of their training distribution. As these models perform well on most cases, it is imperative to detect out-of-distribution (OOD) images at inference to protect against automation bias. This work applies the Mahalanobis distance post hoc to the bottleneck features of a Swin UNETR model that segments the liver on T1-weighted magnetic resonance imaging. By reducing the dimensions of the bottleneck features with principal component analysis, OOD images were detected with high performance and minimal computational load.
<div id='section'>Paperid: <span id='pid'>1223, <a href='https://arxiv.org/pdf/2308.02675.pdf' target='_blank'>https://arxiv.org/pdf/2308.02675.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Elkobi, Bernd Gruner, Tim Sonnekalb, Clemens-Alexander Brust
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02675">TIPICAL -- Type Inference for Python In Critical Accuracy Level</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Type inference methods based on deep learning are becoming increasingly popular as they aim to compensate for the drawbacks of static and dynamic analysis approaches, such as high uncertainty. However, their practical application is still debatable due to several intrinsic issues such as code from different software domains will involve data types that are unknown to the type inference system. In order to overcome these problems and gain high-confidence predictions, we thus present TIPICAL, a method that combines deep similarity learning with novelty detection. We show that our method can better predict data types in high confidence by successfully filtering out unknown and inaccurate predicted data types and achieving higher F1 scores to the state-of-the-art type inference method Type4Py. Additionally, we investigate how different software domains and data type frequencies may affect the results of our method.
<div id='section'>Paperid: <span id='pid'>1224, <a href='https://arxiv.org/pdf/2308.02631.pdf' target='_blank'>https://arxiv.org/pdf/2308.02631.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Fischer, Thomas KÃ¼stner, Christian F. Baumgartner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02631">Uncertainty Estimation and Propagation in Accelerated MRI Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>MRI reconstruction techniques based on deep learning have led to unprecedented reconstruction quality especially in highly accelerated settings. However, deep learning techniques are also known to fail unexpectedly and hallucinate structures. This is particularly problematic if reconstructions are directly used for downstream tasks such as real-time treatment guidance or automated extraction of clinical paramters (e.g. via segmentation). Well-calibrated uncertainty quantification will be a key ingredient for safe use of this technology in clinical practice. In this paper we propose a novel probabilistic reconstruction technique (PHiRec) building on the idea of conditional hierarchical variational autoencoders. We demonstrate that our proposed method produces high-quality reconstructions as well as uncertainty quantification that is substantially better calibrated than several strong baselines. We furthermore demonstrate how uncertainties arising in the MR econstruction can be propagated to a downstream segmentation task, and show that PHiRec also allows well-calibrated estimation of segmentation uncertainties that originated in the MR reconstruction process.
<div id='section'>Paperid: <span id='pid'>1225, <a href='https://arxiv.org/pdf/2308.01412.pdf' target='_blank'>https://arxiv.org/pdf/2308.01412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergio Naval Marimont, Giacomo Tarroni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.01412">Achieving state-of-the-art performance in the Medical Out-of-Distribution (MOOD) challenge using plausible synthetic anomalies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection and localization of anomalies is one important medical image analysis task. Most commonly, Computer Vision anomaly detection approaches rely on manual annotations that are both time consuming and expensive to obtain. Unsupervised anomaly detection, or Out-of-Distribution detection, aims at identifying anomalous samples relying only on unannotated samples considered normal. In this study we present a new unsupervised anomaly detection method. Our method builds upon the self-supervised strategy consisting on training a segmentation network to identify local synthetic anomalies. Our contributions improve the synthetic anomaly generation process, making synthetic anomalies more heterogeneous and challenging by 1) using complex random shapes and 2) smoothing the edges of synthetic anomalies so networks cannot rely on the high gradient between image and synthetic anomalies. In our implementation we adopted standard practices in 3D medical image segmentation, including 3D U-Net architecture, patch-wise training and model ensembling. Our method was evaluated using a validation set with different types of synthetic anomalies. Our experiments show that our method improved substantially the baseline method performance. Additionally, we evaluated our method by participating in the Medical Out-of-Distribution (MOOD) Challenge held at MICCAI in 2022 and achieved first position in both sample-wise and pixel-wise tasks. Our experiments and results in the latest MOOD challenge show that our simple yet effective approach can substantially improve the performance of Out-of-Distribution detection techniques which rely on synthetic anomalies.
<div id='section'>Paperid: <span id='pid'>1226, <a href='https://arxiv.org/pdf/2307.16528.pdf' target='_blank'>https://arxiv.org/pdf/2307.16528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mona Ashtari-Majlan, Mohammad Mahdi Dehshibi, David Masip
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.16528">Deep Learning and Computer Vision for Glaucoma Detection: A Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Glaucoma is the leading cause of irreversible blindness worldwide and poses significant diagnostic challenges due to its reliance on subjective evaluation. However, recent advances in computer vision and deep learning have demonstrated the potential for automated assessment. In this paper, we survey recent studies on AI-based glaucoma diagnosis using fundus, optical coherence tomography, and visual field images, with a particular emphasis on deep learning-based methods. We provide an updated taxonomy that organizes methods into architectural paradigms and includes links to available source code to enhance the reproducibility of the methods. Through rigorous benchmarking on widely-used public datasets, we reveal performance gaps in generalizability, uncertainty estimation, and multimodal integration. Additionally, our survey curates key datasets while highlighting limitations such as scale, labeling inconsistencies, and bias. We outline open research challenges and detail promising directions for future studies. This survey is expected to be useful for both AI researchers seeking to translate advances into practice and ophthalmologists aiming to improve clinical workflows and diagnosis using the latest AI outcomes.
<div id='section'>Paperid: <span id='pid'>1227, <a href='https://arxiv.org/pdf/2307.16164.pdf' target='_blank'>https://arxiv.org/pdf/2307.16164.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Werner Zellinger, Stefan Kindermann, Sergei V. Pereverzyev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.16164">Adaptive learning of density ratios in RKHS</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating the ratio of two probability densities from finitely many observations of the densities is a central problem in machine learning and statistics with applications in two-sample testing, divergence estimation, generative modeling, covariate shift adaptation, conditional density estimation, and novelty detection. In this work, we analyze a large class of density ratio estimation methods that minimize a regularized Bregman divergence between the true density ratio and a model in a reproducing kernel Hilbert space (RKHS). We derive new finite-sample error bounds, and we propose a Lepskii type parameter choice principle that minimizes the bounds without knowledge of the regularity of the density ratio. In the special case of quadratic loss, our method adaptively achieves a minimax optimal error rate. A numerical illustration is provided.
<div id='section'>Paperid: <span id='pid'>1228, <a href='https://arxiv.org/pdf/2307.10193.pdf' target='_blank'>https://arxiv.org/pdf/2307.10193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>McKell Woodland, John Wood, Caleb O'Connor, Ankit B. Patel, Kristy K. Brock
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.10193">StyleGAN2-based Out-of-Distribution Detection for Medical Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One barrier to the clinical deployment of deep learning-based models is the presence of images at runtime that lie far outside the training distribution of a given model. We aim to detect these out-of-distribution (OOD) images with a generative adversarial network (GAN). Our training dataset was comprised of 3,234 liver-containing computed tomography (CT) scans from 456 patients. Our OOD test data consisted of CT images of the brain, head and neck, lung, cervix, and abnormal livers. A StyleGAN2-ADA architecture was employed to model the training distribution. Images were reconstructed using backpropagation. Reconstructions were evaluated using the Wasserstein distance, mean squared error, and the structural similarity index measure. OOD detection was evaluated with the area under the receiver operating characteristic curve (AUROC). Our paradigm distinguished between liver and non-liver CT with greater than 90% AUROC. It was also completely unable to reconstruct liver artifacts, such as needles and ascites.
<div id='section'>Paperid: <span id='pid'>1229, <a href='https://arxiv.org/pdf/2307.09455.pdf' target='_blank'>https://arxiv.org/pdf/2307.09455.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaeyoung Kim, Kyuheon Jung, Dongbin Na, Sion Jang, Eunbin Park, Sungchul Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.09455">Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold. A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any external OOD data and can be easily implemented within off-the-shelf Transformers. A comprehensive comparison with state-of-the-art algorithms demonstrates POE's competitiveness on several text classification benchmarks.
<div id='section'>Paperid: <span id='pid'>1230, <a href='https://arxiv.org/pdf/2306.03412.pdf' target='_blank'>https://arxiv.org/pdf/2306.03412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sajal Saha, Sudipto Baral, Anwar Haque
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03412">DEK-Forecaster: A Novel Deep Learning Model Integrated with EMD-KNN for Traffic Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Internet traffic volume estimation has a significant impact on the business policies of the ISP (Internet Service Provider) industry and business successions. Forecasting the internet traffic demand helps to shed light on the future traffic trend, which is often helpful for ISPs decision-making in network planning activities and investments. Besides, the capability to understand future trend contributes to managing regular and long-term operations. This study aims to predict the network traffic volume demand using deep sequence methods that incorporate Empirical Mode Decomposition (EMD) based noise reduction, Empirical rule based outlier detection, and $K$-Nearest Neighbour (KNN) based outlier mitigation. In contrast to the former studies, the proposed model does not rely on a particular EMD decomposed component called Intrinsic Mode Function (IMF) for signal denoising. In our proposed traffic prediction model, we used an average of all IMFs components for signal denoising. Moreover, the abnormal data points are replaced by $K$ nearest data points average, and the value for $K$ has been optimized based on the KNN regressor prediction error measured in Root Mean Squared Error (RMSE). Finally, we selected the best time-lagged feature subset for our prediction model based on AutoRegressive Integrated Moving Average (ARIMA) and Akaike Information Criterion (AIC) value. Our experiments are conducted on real-world internet traffic datasets from industry, and the proposed method is compared with various traditional deep sequence baseline models. Our results show that the proposed EMD-KNN integrated prediction models outperform comparative models.
<div id='section'>Paperid: <span id='pid'>1231, <a href='https://arxiv.org/pdf/2305.10384.pdf' target='_blank'>https://arxiv.org/pdf/2305.10384.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yassir Fathullah, Guoxuan Xia, Mark Gales
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.10384">Logit-Based Ensemble Distribution Distillation for Robust Autoregressive Sequence Uncertainties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficiently and reliably estimating uncertainty is an important objective in deep learning. It is especially pertinent to autoregressive sequence tasks, where training and inference costs are typically very high. However, existing research has predominantly focused on tasks with static data such as image classification. In this work, we investigate Ensemble Distribution Distillation (EDD) applied to large-scale natural language sequence-to-sequence data. EDD aims to compress the superior uncertainty performance of an expensive (teacher) ensemble into a cheaper (student) single model. Importantly, the ability to separate knowledge (epistemic) and data (aleatoric) uncertainty is retained. Existing probability-space approaches to EDD, however, are difficult to scale to large vocabularies. We show, for modern transformer architectures on large-scale translation tasks, that modelling the ensemble logits, instead of softmax probabilities, leads to significantly better students. Moreover, the students surprisingly even outperform Deep Ensembles by up to ~10% AUROC on out-of-distribution detection, whilst matching them at in-distribution translation.
<div id='section'>Paperid: <span id='pid'>1232, <a href='https://arxiv.org/pdf/2305.06139.pdf' target='_blank'>https://arxiv.org/pdf/2305.06139.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Bolt, Conrad Sanderson, Joel Janek Dabrowski, Carolyn Huston, Petra Kuhnert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.06139">A Neural Emulator for Uncertainty Estimation of Fire Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wildfire propagation is a highly stochastic process where small changes in environmental conditions (such as wind speed and direction) can lead to large changes in observed behaviour. A traditional approach to quantify uncertainty in fire-front progression is to generate probability maps via ensembles of simulations. However, use of ensembles is typically computationally expensive, which can limit the scope of uncertainty analysis. To address this, we explore the use of a spatio-temporal neural-based modelling approach to directly estimate the likelihood of fire propagation given uncertainty in input parameters. The uncertainty is represented by deliberately perturbing the input weather forecast during model training. The computational load is concentrated in the model training process, which allows larger probability spaces to be explored during deployment. Empirical evaluations indicate that the proposed model achieves comparable fire boundaries to those produced by the traditional SPARK simulation platform, with an overall Jaccard index (similarity score) of 67.4% on a set of 35 simulated fires. When compared to a related neural model (emulator) which was employed to generate probability maps via ensembles of emulated fires, the proposed approach produces competitive Jaccard similarity scores while being approximately an order of magnitude faster.
<div id='section'>Paperid: <span id='pid'>1233, <a href='https://arxiv.org/pdf/2305.02859.pdf' target='_blank'>https://arxiv.org/pdf/2305.02859.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Timur Akhtyamov, Aleksandr Kashirin, Aleksey Postnikov, Gonzalo Ferrer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.02859">Social Robot Navigation through Constrained Optimization: a Comparative Study of Uncertainty-based Objectives and Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work is dedicated to the study of how uncertainty estimation of the human motion prediction can be embedded into constrained optimization techniques, such as Model Predictive Control (MPC) for the social robot navigation. We propose several cost objectives and constraint functions obtained from the uncertainty of predicting pedestrian positions and related to the probability of the collision that can be applied to the MPC, and all the different variants are compared in challenging scenes with multiple agents. The main question this paper tries to answer is: what are the most important uncertainty-based criteria for social MPC? For that, we evaluate the proposed approaches with several social navigation metrics in an extensive set of scenarios of different complexity in reproducible synthetic environments. The main outcome of our study is a foundation for a practical guide on when and how to use uncertainty-aware approaches for social robot navigation in practice and what are the most effective criteria.
<div id='section'>Paperid: <span id='pid'>1234, <a href='https://arxiv.org/pdf/2304.08538.pdf' target='_blank'>https://arxiv.org/pdf/2304.08538.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ersin DaÅ, Skylar X. Wei, Joel W. Burdick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.08538">Robust Control Barrier Functions with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a safety controller for control-affine nonlinear systems with unmodelled dynamics and disturbances to improve closed-loop robustness. Uncertainty estimation-based control barrier functions (CBFs) are utilized to ensure robust safety in the presence of model uncertainties, which may depend on control input and states. We present a new uncertainty/disturbance estimator with theoretical upper bounds on estimation error and estimated outputs, which are used to ensure robust safety by formulating a convex optimization problem using a high-order CBF. The possibly unsafe nominal feedback controller is augmented with the proposed estimator in two frameworks (1) an uncertainty compensator and (2) a robustifying reformulation of CBF constraint with respect to the estimator outputs. The former scheme ensures safety with performance improvement by adaptively rejecting the matched uncertainty. The second method uses uncertainty estimation to robustify higher-order CBFs for safety-critical control. The proposed methods are demonstrated in simulations of an uncertain adaptive cruise control problem and a multirotor obstacle avoidance situation.
<div id='section'>Paperid: <span id='pid'>1235, <a href='https://arxiv.org/pdf/2304.00709.pdf' target='_blank'>https://arxiv.org/pdf/2304.00709.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xu Tan, Jiawei Yang, Junqi Chen, Sylwan Rahardja, Susanto Rahardja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.00709">MSS-PAE: Saving Autoencoder-based Outlier Detection from Unexpected Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AutoEncoders (AEs) are commonly used for machine learning tasks due to their intrinsic learning ability. This unique characteristic can be capitalized for Outlier Detection (OD). However conventional AE-based methods face the issue of overconfident decisions and unexpected reconstruction results of outliers, limiting their performance in OD. To mitigate these issues, the Mean Squared Error (MSE) and Negative Logarithmic Likelihood (NLL) were firstly analyzed, and the importance of incorporating aleatoric uncertainty to AE-based OD was elucidated. Then the Weighted Negative Logarithmic Likelihood (WNLL) was proposed to adjust for the effect of uncertainty for different OD scenarios. Moreover, the Mean-Shift Scoring (MSS) method was proposed to utilize the local relationship of data to reduce the issue of false inliers caused by AE. Experiments on 32 real-world OD datasets proved the effectiveness of the proposed methods. The combination of WNLL and MSS achieved 41% relative performance improvement compared to the best baseline. In addition, MSS improved the detection performance of multiple AE-based outlier detectors by an average of 20%. The proposed methods have the potential to advance AE's development in OD.
<div id='section'>Paperid: <span id='pid'>1236, <a href='https://arxiv.org/pdf/2304.00152.pdf' target='_blank'>https://arxiv.org/pdf/2304.00152.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liyan Chen, Weihan Wang, Philippos Mordohai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.00152">Learning the Distribution of Errors in Stereo Matching for Joint Disparity and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new loss function for joint disparity and uncertainty estimation in deep stereo matching. Our work is motivated by the need for precise uncertainty estimates and the observation that multi-task learning often leads to improved performance in all tasks. We show that this can be achieved by requiring the distribution of uncertainty to match the distribution of disparity errors via a KL divergence term in the network's loss function. A differentiable soft-histogramming technique is used to approximate the distributions so that they can be used in the loss. We experimentally assess the effectiveness of our approach and observe significant improvements in both disparity and uncertainty prediction on large datasets.
<div id='section'>Paperid: <span id='pid'>1237, <a href='https://arxiv.org/pdf/2303.13995.pdf' target='_blank'>https://arxiv.org/pdf/2303.13995.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yong Hyun Ahn, Gyeong-Moon Park, Seong Tae Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.13995">LINe: Out-of-Distribution Detection by Leveraging Important Neurons</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It is important to quantify the uncertainty of input samples, especially in mission-critical domains such as autonomous driving and healthcare, where failure predictions on out-of-distribution (OOD) data are likely to cause big problems. OOD detection problem fundamentally begins in that the model cannot express what it is not aware of. Post-hoc OOD detection approaches are widely explored because they do not require an additional re-training process which might degrade the model's performance and increase the training cost. In this study, from the perspective of neurons in the deep layer of the model representing high-level features, we introduce a new aspect for analyzing the difference in model outputs between in-distribution data and OOD data. We propose a novel method, Leveraging Important Neurons (LINe), for post-hoc Out of distribution detection.
  Shapley value-based pruning reduces the effects of noisy outputs by selecting only high-contribution neurons for predicting specific classes of input data and masking the rest. Activation clipping fixes all values above a certain threshold into the same value, allowing LINe to treat all the class-specific features equally and just consider the difference between the number of activated feature differences between in-distribution and OOD data. Comprehensive experiments verify the effectiveness of the proposed method by outperforming state-of-the-art post-hoc OOD detection methods on CIFAR-10, CIFAR-100, and ImageNet datasets.
<div id='section'>Paperid: <span id='pid'>1238, <a href='https://arxiv.org/pdf/2303.10062.pdf' target='_blank'>https://arxiv.org/pdf/2303.10062.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiaojie Zheng, Xiaoli Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10062">Confidence-aware 3D Gaze Estimation and Evaluation Metric</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning appearance-based 3D gaze estimation is gaining popularity due to its minimal hardware requirements and being free of constraint. Unreliable and overconfident inferences, however, still limit the adoption of this gaze estimation method. To address the unreliable and overconfident issues, we introduce a confidence-aware model that predicts uncertainties together with gaze angle estimations. We also introduce a novel effectiveness evaluation method based on the causality between eye feature degradation and the rise in inference uncertainty to assess the uncertainty estimation. Our confidence-aware model demonstrates reliable uncertainty estimations while providing angular estimation accuracies on par with the state-of-the-art. Compared with the existing statistical uncertainty-angular-error evaluation metric, the proposed effectiveness evaluation approach can more effectively judge inferred uncertainties' performance at each prediction.
<div id='section'>Paperid: <span id='pid'>1239, <a href='https://arxiv.org/pdf/2303.08727.pdf' target='_blank'>https://arxiv.org/pdf/2303.08727.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Choubo Ding, Guansong Pang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08727">Improving Out-of-Distribution Detection with Disentangled Foreground and Background Features</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) inputs is a principal task for ensuring the safety of deploying deep-neural-network classifiers in open-set scenarios. OOD samples can be drawn from arbitrary distributions and exhibit deviations from in-distribution (ID) data in various dimensions, such as foreground features (e.g., objects in CIFAR100 images vs. those in CIFAR10 images) and background features (e.g., textural images vs. objects in CIFAR10). Existing methods can confound foreground and background features in training, failing to utilize the background features for OOD detection. This paper considers the importance of feature disentanglement in out-of-distribution detection and proposes the simultaneous exploitation of both foreground and background features to support the detection of OOD inputs in in out-of-distribution detection. To this end, we propose a novel framework that first disentangles foreground and background features from ID training samples via a dense prediction approach, and then learns a new classifier that can evaluate the OOD scores of test images from both foreground and background features. It is a generic framework that allows for a seamless combination with various existing OOD detection methods. Extensive experiments show that our approach 1) can substantially enhance the performance of four different state-of-the-art (SotA) OOD detection methods on multiple widely-used OOD datasets with diverse background features, and 2) achieves new SotA performance on these benchmarks.
<div id='section'>Paperid: <span id='pid'>1240, <a href='https://arxiv.org/pdf/2302.12443.pdf' target='_blank'>https://arxiv.org/pdf/2302.12443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhishek Verma, Virender Ranga
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12443">CoSec-RPL: detection of copycat attacks in RPL based 6LoWPANs using outlier analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The IPv6 routing protocol for low-power and lossy networks (RPL) is the standard routing protocol for IPv6 based low-power wireless personal area networks (6LoWPANs). In RPL protocol, DODAG information object (DIO) messages are used to disseminate routing information to other nodes in the network. A malicious node may eavesdrop DIO messages of its neighbor nodes and later replay the captured DIO many times with fixed intervals. In this paper, we present and investigate one of the severe attacks named as a non-spoofed copycat attack, a type of replay based DoS attack against RPL protocol. It is shown that the non-spoofed copycat attack increases the average end-to-end delay (AE2ED) and packet delivery ratio of the network. Thus, to address this problem, an intrusion detection system (IDS) named CoSec-RPL is proposed in this paper. The attack detection logic of CoSec-RPL is primarily based on the idea of outlier detection (OD). CoSec-RPL significantly mitigates the effects of the non-spoofed copycat attack on the network's performance. The effectiveness of the proposed IDS is compared with the standard RPL protocol. The experimental results indicate that CoSec-RPL detects and mitigates non-spoofed copycat attack efficiently in both static and mobile network scenarios without adding any significant overhead to the nodes. To the best of our knowledge, CoSec-RPL is the first RPL specific IDS that utilizes OD for intrusion detection in 6LoWPANs.
<div id='section'>Paperid: <span id='pid'>1241, <a href='https://arxiv.org/pdf/2302.07294.pdf' target='_blank'>https://arxiv.org/pdf/2302.07294.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meshi Bashari, Amir Epstein, Yaniv Romano, Matteo Sesia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.07294">Derandomized Novelty Detection with FDR Control via Conformal E-values</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformal inference provides a general distribution-free method to rigorously calibrate the output of any machine learning algorithm for novelty detection. While this approach has many strengths, it has the limitation of being randomized, in the sense that it may lead to different results when analyzing twice the same data, and this can hinder the interpretation of any findings. We propose to make conformal inferences more stable by leveraging suitable conformal e-values instead of p-values to quantify statistical significance. This solution allows the evidence gathered from multiple analyses of the same data to be aggregated effectively while provably controlling the false discovery rate. Further, we show that the proposed method can reduce randomness without much loss of power compared to standard conformal inference, partly thanks to an innovative way of weighting conformal e-values based on additional side information carefully extracted from the same data. Simulations with synthetic and real data confirm this solution can be effective at eliminating random noise in the inferences obtained with state-of-the-art alternative techniques, sometimes also leading to higher power.
<div id='section'>Paperid: <span id='pid'>1242, <a href='https://arxiv.org/pdf/2302.06048.pdf' target='_blank'>https://arxiv.org/pdf/2302.06048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minkyung Kim, Junsik Kim, Jongmin Yu, Jun Kyun Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.06048">Unsupervised Deep One-Class Classification with Adaptive Threshold based on Training Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One-class classification has been a prevailing method in building deep anomaly detection models under the assumption that a dataset consisting of normal samples is available. In practice, however, abnormal samples are often mixed in a training dataset, and they detrimentally affect the training of deep models, which limits their applicability. For robust normality learning of deep practical models, we propose an unsupervised deep one-class classification that learns normality from pseudo-labeled normal samples, i.e., outlier detection in single cluster scenarios. To this end, we propose a pseudo-labeling method by an adaptive threshold selected by ranking-based training dynamics. The experiments on 10 anomaly detection benchmarks show that our method effectively improves performance on anomaly detection by sizable margins.
<div id='section'>Paperid: <span id='pid'>1243, <a href='https://arxiv.org/pdf/2301.06418.pdf' target='_blank'>https://arxiv.org/pdf/2301.06418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Frederik Boe HÃ¼ttel, Filipe Rodrigues, Francisco CÃ¢mara Pereira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.06418">Mind the Gap: Modelling Difference Between Censored and Uncensored Electric Vehicle Charging Demand</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electric vehicle charging demand models, with charging records as input, will inherently be biased toward the supply of available chargers. These models often fail to account for demand lost from occupied charging stations and competitors. The lost demand suggests that the actual demand is likely higher than the charging records reflect, i.e., the true demand is latent (unobserved), and the observations are censored. As a result, machine learning models that rely on these observed records for forecasting charging demand may be limited in their application in future infrastructure expansion and supply management, as they do not estimate the true demand for charging. We propose using censorship-aware models to model charging demand to address this limitation. These models incorporate censorship in their loss functions and learn the true latent demand distribution from observed charging records. We study how occupied charging stations and competing services censor demand using GPS trajectories from cars in Copenhagen, Denmark. We find that censorship occurs up to $61\%$ of the time in some areas of the city. We use the observed charging demand from our study to estimate the true demand and find that censorship-aware models provide better prediction and uncertainty estimation of actual demand than censorship-unaware models. We suggest that future charging models based on charging records should account for censoring to expand the application areas of machine learning models in supply management and infrastructure expansion.
<div id='section'>Paperid: <span id='pid'>1244, <a href='https://arxiv.org/pdf/2212.12720.pdf' target='_blank'>https://arxiv.org/pdf/2212.12720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feng Xue, Zi He, Chuanlong Xie, Falong Tan, Zhenguo Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.12720">Boosting Out-of-Distribution Detection with Multiple Pre-trained Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection, i.e., identifying whether an input is sampled from a novel distribution other than the training distribution, is a critical task for safely deploying machine learning systems in the open world. Recently, post hoc detection utilizing pre-trained models has shown promising performance and can be scaled to large-scale problems. This advance raises a natural question: Can we leverage the diversity of multiple pre-trained models to improve the performance of post hoc detection methods? In this work, we propose a detection enhancement method by ensembling multiple detection decisions derived from a zoo of pre-trained models. Our approach uses the p-value instead of the commonly used hard threshold and leverages a fundamental framework of multiple hypothesis testing to control the true positive rate of In-Distribution (ID) data. We focus on the usage of model zoos and provide systematic empirical comparisons with current state-of-the-art methods on various OOD detection benchmarks. The proposed ensemble scheme shows consistent improvement compared to single-model detectors and significantly outperforms the current competitive methods. Our method substantially improves the relative performance by 65.40% and 26.96% on the CIFAR10 and ImageNet benchmarks.
<div id='section'>Paperid: <span id='pid'>1245, <a href='https://arxiv.org/pdf/2212.04831.pdf' target='_blank'>https://arxiv.org/pdf/2212.04831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huajian Fang, Timo Gerkmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.04831">Uncertainty Estimation in Deep Speech Enhancement Using Complex Gaussian Mixture Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Single-channel deep speech enhancement approaches often estimate a single multiplicative mask to extract clean speech without a measure of its accuracy. Instead, in this work, we propose to quantify the uncertainty associated with clean speech estimates in neural network-based speech enhancement. Predictive uncertainty is typically categorized into aleatoric uncertainty and epistemic uncertainty. The former accounts for the inherent uncertainty in data and the latter corresponds to the model uncertainty. Aiming for robust clean speech estimation and efficient predictive uncertainty quantification, we propose to integrate statistical complex Gaussian mixture models (CGMMs) into a deep speech enhancement framework. More specifically, we model the dependency between input and output stochastically by means of a conditional probability density and train a neural network to map the noisy input to the full posterior distribution of clean speech, modeled as a mixture of multiple complex Gaussian components. Experimental results on different datasets show that the proposed algorithm effectively captures predictive uncertainty and that combining powerful statistical models and deep learning also delivers a superior speech enhancement performance.
<div id='section'>Paperid: <span id='pid'>1246, <a href='https://arxiv.org/pdf/2209.14602.pdf' target='_blank'>https://arxiv.org/pdf/2209.14602.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiwen Cai, Chris Xiaoxuan Lu, Xiaowei Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.14602">Uncertainty Estimation for 3D Dense Prediction via Cross-Point Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dense prediction tasks are common for 3D point clouds, but the uncertainties inherent in massive points and their embeddings have long been ignored. In this work, we present CUE, a novel uncertainty estimation method for dense prediction tasks in 3D point clouds. Inspired by metric learning, the key idea of CUE is to explore cross-point embeddings upon a conventional 3D dense prediction pipeline. Specifically, CUE involves building a probabilistic embedding model and then enforcing metric alignments of massive points in the embedding space. We also propose CUE+, which enhances CUE by explicitly modeling crosspoint dependencies in the covariance matrix. We demonstrate that both CUE and CUE+ are generic and effective for uncertainty estimation in 3D point clouds with two different tasks: (1) in 3D geometric feature learning we for the first time obtain wellcalibrated uncertainty, and (2) in semantic segmentation we reduce uncertainty's Expected Calibration Error of the state-of-the-arts by 16.5%. All uncertainties are estimated without compromising predictive performance.
<div id='section'>Paperid: <span id='pid'>1247, <a href='https://arxiv.org/pdf/2206.08289.pdf' target='_blank'>https://arxiv.org/pdf/2206.08289.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengsen Wu, Yan Bai, Yihang Lou, Xiongkun Linghu, Jianzhong He, Ling-Yu Duan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.08289">Switchable Representation Learning Framework with Self-compatibility</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world visual search systems involve deployments on multiple platforms with different computing and storage resources. Deploying a unified model that suits the minimal-constrain platforms leads to limited accuracy. It is expected to deploy models with different capacities adapting to the resource constraints, which requires features extracted by these models to be aligned in the metric space. The method to achieve feature alignments is called ``compatible learning''. Existing research mainly focuses on the one-to-one compatible paradigm, which is limited in learning compatibility among multiple models. We propose a Switchable representation learning Framework with Self-Compatibility (SFSC). SFSC generates a series of compatible sub-models with different capacities through one training process. The optimization of sub-models faces gradients conflict, and we mitigate this problem from the perspective of the magnitude and direction. We adjust the priorities of sub-models dynamically through uncertainty estimation to co-optimize sub-models properly. Besides, the gradients with conflicting directions are projected to avoid mutual interference. SFSC achieves state-of-the-art performance on the evaluated datasets.
<div id='section'>Paperid: <span id='pid'>1248, <a href='https://arxiv.org/pdf/2205.01887.pdf' target='_blank'>https://arxiv.org/pdf/2205.01887.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anshul Nayak, Azim Eskandarian, Zachary Doerzaph
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.01887">Uncertainty estimation of pedestrian future trajectory using Bayesian approximation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Past research on pedestrian trajectory forecasting mainly focused on deterministic predictions which provide only point estimates of future states. These future estimates can help an autonomous vehicle plan its trajectory and avoid collision. However, under dynamic traffic scenarios, planning based on deterministic predictions is not trustworthy. Rather, estimating the uncertainty associated with the predicted states with a certain level of confidence can lead to robust path planning. Hence, the authors propose to quantify this uncertainty during forecasting using stochastic approximation which deterministic approaches fail to capture. The current method is simple and applies Bayesian approximation during inference to standard neural network architectures for estimating uncertainty. The authors compared the predictions between the probabilistic neural network (NN) models with the standard deterministic models. The results indicate that the mean predicted path of probabilistic models was closer to the ground truth when compared with the deterministic prediction. Further, the effect of stochastic dropout of weights and long-term prediction on future state uncertainty has been studied. It was found that the probabilistic models produced better performance metrics like average displacement error (ADE) and final displacement error (FDE). Finally, the study has been extended to multiple datasets providing a comprehensive comparison for each model.
<div id='section'>Paperid: <span id='pid'>1249, <a href='https://arxiv.org/pdf/2204.10888.pdf' target='_blank'>https://arxiv.org/pdf/2204.10888.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chandra Sekhar Mukherjee, Nikhil Doerkar, Jiapeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.10888">Capturing the Denoising Effect of PCA via Compression Ratio</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Principal component analysis (PCA) is one of the most fundamental tools in machine learning with broad use as a dimensionality reduction and denoising tool. In the later setting, while PCA is known to be effective at subspace recovery and is proven to aid clustering algorithms in some specific settings, its improvement of noisy data is still not well quantified in general.
  In this paper, we propose a novel metric called \emph{compression ratio} to capture the effect of PCA on high-dimensional noisy data. We show that, for data with \emph{underlying community structure}, PCA significantly reduces the distance of data points belonging to the same community while reducing inter-community distance relatively mildly. We explain this phenomenon through both theoretical proofs and experiments on real-world data.
  Building on this new metric, we design a straightforward algorithm that could be used to detect outliers. Roughly speaking, we argue that points that have a \emph{lower variance of compression ratio} do not share a \emph{common signal} with others (hence could be considered outliers).
  We provide theoretical justification for this simple outlier detection algorithm and use simulations to demonstrate that our method is competitive with popular outlier detection tools. Finally, we run experiments on real-world high-dimension noisy data (single-cell RNA-seq) to show that removing points from these datasets via our outlier detection method improves the accuracy of clustering algorithms. Our method is very competitive with popular outlier detection tools in this task.
<div id='section'>Paperid: <span id='pid'>1250, <a href='https://arxiv.org/pdf/2203.00872.pdf' target='_blank'>https://arxiv.org/pdf/2203.00872.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seyed A. Esmaeili, Darshan Chakrabarti, Hayley Grape, Brian Brubach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.00872">Implications of Distance over Redistricting Maps: Central and Outlier Maps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In representative democracy, a redistricting map is chosen to partition an electorate into districts which each elects a representative. A valid redistricting map must satisfy a collection of constraints such as being compact, contiguous, and of almost-equal population. However, these constraints are loose enough to enable an enormous ensemble of valid redistricting maps. This enables a partisan legislature to gerrymander by choosing a map which unfairly favors it. In this paper, we introduce an interpretable and tractable distance measure over redistricting maps which does not use election results and study its implications over the ensemble of redistricting maps. Specifically, we define a central map which may be considered "most typical" and give a rigorous justification for it by showing that it mirrors the Kemeny ranking in a scenario where we have a committee voting over a collection of redistricting maps to be drawn. We include running time and sample complexity analysis for our algorithms, including some negative results which hold using any algorithm. We further study outlier detection based on this distance measure and show that our framework can detect some gerrymandered maps. More precisely, we show some maps that are widely considered to be gerrymandered that lie very far away from our central maps in comparison to a large ensemble of valid redistricting maps. Since our distance measure does not rely on election results, this gives a significant advantage in gerrymandering detection which is lacking in all previous methods.
<div id='section'>Paperid: <span id='pid'>1251, <a href='https://arxiv.org/pdf/2202.01479.pdf' target='_blank'>https://arxiv.org/pdf/2202.01479.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guanxiong Luo, Moritz Blumenthal, Martin Heide, Martin Uecker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.01479">Bayesian MRI Reconstruction with Joint Uncertainty Estimation using Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a framework that enables efficient sampling from learned probability distributions for MRI reconstruction. Different from conventional deep learning-based MRI reconstruction techniques, samples are drawn from the posterior distribution given the measured k-space using the Markov chain Monte Carlo (MCMC) method. In addition to the maximum a posteriori (MAP) estimate for the image, which can be obtained with conventional methods, the minimum mean square error (MMSE) estimate and uncertainty maps can also be computed. The data-driven Markov chains are constructed from the generative model learned from a given image database and are independent of the forward operator that is used to model the k-space measurement. This provides flexibility because the method can be applied to k-space acquired with different sampling schemes or receive coils using the same pre-trained models. Furthermore, we use a framework based on a reverse diffusion process to be able to utilize advanced generative models. The performance of the method is evaluated on an open dataset using 10-fold undersampling in k-space.
<div id='section'>Paperid: <span id='pid'>1252, <a href='https://arxiv.org/pdf/2109.02748.pdf' target='_blank'>https://arxiv.org/pdf/2109.02748.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sepideh Esmaeilpour, Bing Liu, Eric Robertson, Lei Shu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2109.02748">Zero-Shot Out-of-Distribution Detection Based on the Pre-trained Model CLIP</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In an out-of-distribution (OOD) detection problem, samples of known classes(also called in-distribution classes) are used to train a special classifier. In testing, the classifier can (1) classify the test samples of known classes to their respective classes and also (2) detect samples that do not belong to any of the known classes (i.e., they belong to some unknown or OOD classes). This paper studies the problem of zero-shot out-of-distribution(OOD) detection, which still performs the same two tasks in testing but has no training except using the given known class names. This paper proposes a novel yet simple method (called ZOC) to solve the problem. ZOC builds on top of the recent advances in zero-shot classification through multi-modal representation learning. It first extends the pre-trained language-vision model CLIP by training a text-based image description generator on top of CLIP. In testing, it uses the extended model to generate candidate unknown class names for each test sample and computes a confidence score based on both the known class names and candidate unknown class names for zero-shot OOD detection. Experimental results on 5 benchmark datasets for OOD detection demonstrate that ZOC outperforms the baselines by a large margin.
<div id='section'>Paperid: <span id='pid'>1253, <a href='https://arxiv.org/pdf/2011.03353.pdf' target='_blank'>https://arxiv.org/pdf/2011.03353.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaroslav Zharov, Alexey Ershov, Tilo Baumbach, Vincent Heuveline
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2011.03353">Self-Supervised Learning for Biological Sample Localization in 3D Tomographic Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In synchrotron-based Computed Tomography (CT) there is a trade-off between spatial resolution, field of view and speed of positioning and alignment of samples. The problem is even more prominent for high-throughput tomography--an automated setup, capable of scanning large batches of samples without human interaction. As a result, in many applications, only 20-30% of the reconstructed volume contains the actual sample. Such data redundancy clutters the storage and increases processing time. Hence, an automated sample localization becomes an important practical problem. In this work, we describe two self-supervised losses designed for biological CT. We further demonstrate how to employ the uncertainty estimation for sample localization. This approach shows the ability to localize a sample with less than 1.5\% relative error and reduce the used storage by a factor of four. We also show that one of the proposed losses works reasonably well as a pre-training task for the semantic segmentation.
<div id='section'>Paperid: <span id='pid'>1254, <a href='https://arxiv.org/pdf/2008.02046.pdf' target='_blank'>https://arxiv.org/pdf/2008.02046.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joachim Schreurs, Iwein Vranckx, Mia Hubert, Johan A. K. Suykens, Peter J. Rousseeuw
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2008.02046">Outlier detection in non-elliptical data by kernel MRCD</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The minimum regularized covariance determinant method (MRCD) is a robust estimator for multivariate location and scatter, which detects outliers by fitting a robust covariance matrix to the data. Its regularization ensures that the covariance matrix is well-conditioned in any dimension. The MRCD assumes that the non-outlying observations are roughly elliptically distributed, but many datasets are not of that form. Moreover, the computation time of MRCD increases substantially when the number of variables goes up, and nowadays datasets with many variables are common. The proposed Kernel Minimum Regularized Covariance Determinant (KMRCD) estimator addresses both issues. It is not restricted to elliptical data because it implicitly computes the MRCD estimates in a kernel induced feature space. A fast algorithm is constructed that starts from kernel-based initial estimates and exploits the kernel trick to speed up the subsequent computations. Based on the KMRCD estimates, a rule is proposed to flag outliers. The KMRCD algorithm performs well in simulations, and is illustrated on real-life data.
<div id='section'>Paperid: <span id='pid'>1255, <a href='https://arxiv.org/pdf/2510.06742.pdf' target='_blank'>https://arxiv.org/pdf/2510.06742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Sarabadani, Kheirolah Rahsepar Fard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06742">MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advent of large language models (LLMs) has revolutionized the integration of knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming limitations in traditional machine learning methods for capturing intricate semantic links among genes, diseases, and cognitive processes. We introduce MultiCNKG, an innovative framework that merges three key knowledge sources: the Cognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges across 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes and 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO) comprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types. Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity computation, and graph augmentation to create a cohesive KG that interconnects genetic mechanisms, neurological disorders, and cognitive functions. The resulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes, Diseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes, Associated with, Regulates), facilitating a multi-layered view from molecular to behavioral domains. Assessments using metrics such as precision (85.20%), recall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty detection (40.28%), and expert validation (89.50%) affirm its robustness and coherence. Link prediction evaluations with models like TransE (MR: 391, MRR: 0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against benchmarks like FB15k-237 and WN18RR. This KG advances applications in personalized medicine, cognitive disorder diagnostics, and hypothesis formulation in cognitive neuroscience.
<div id='section'>Paperid: <span id='pid'>1256, <a href='https://arxiv.org/pdf/2510.01251.pdf' target='_blank'>https://arxiv.org/pdf/2510.01251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlo Bono, Federico Belotti, Matteo Palmonari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01251">Efficient Uncertainty Estimation for LLM-based Entity Linking in Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Linking textual values in tabular data to their corresponding entities in a Knowledge Base is a core task across a variety of data integration and enrichment applications. Although Large Language Models (LLMs) have shown State-of-The-Art performance in Entity Linking (EL) tasks, their deployment in real-world scenarios requires not only accurate predictions but also reliable uncertainty estimates, which require resource-demanding multi-shot inference, posing serious limits to their actual applicability. As a more efficient alternative, we investigate a self-supervised approach for estimating uncertainty from single-shot LLM outputs using token-level features, reducing the need for multiple generations. Evaluation is performed on an EL task on tabular data across multiple LLMs, showing that the resulting uncertainty estimates are highly effective in detecting low-accuracy outputs. This is achieved at a fraction of the computational cost, ultimately supporting a cost-effective integration of uncertainty measures into LLM-based EL workflows. The method offers a practical way to incorporate uncertainty estimation into EL workflows with limited computational overhead.
<div id='section'>Paperid: <span id='pid'>1257, <a href='https://arxiv.org/pdf/2509.21750.pdf' target='_blank'>https://arxiv.org/pdf/2509.21750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Li, Da Chang, Xi Xiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21750">KG-SAM: Injecting Anatomical Knowledge into Segment Anything Models via Conditional Random Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While the Segment Anything Model (SAM) has achieved remarkable success in image segmentation, its direct application to medical imaging remains hindered by fundamental challenges, including ambiguous boundaries, insufficient modeling of anatomical relationships, and the absence of uncertainty quantification. To address these limitations, we introduce KG-SAM, a knowledge-guided framework that synergistically integrates anatomical priors with boundary refinement and uncertainty estimation. Specifically, KG-SAM incorporates (i) a medical knowledge graph to encode fine-grained anatomical relationships, (ii) an energy-based Conditional Random Field (CRF) to enforce anatomically consistent predictions, and (iii) an uncertainty-aware fusion module to enhance reliability in high-stakes clinical scenarios. Extensive experiments across multi-center medical datasets demonstrate the effectiveness of our approach: KG-SAM achieves an average Dice score of 82.69% on prostate segmentation and delivers substantial gains in abdominal segmentation, reaching 78.05% on MRI and 79.68% on CT. These results establish KG-SAM as a robust and generalizable framework for advancing medical image segmentation.
<div id='section'>Paperid: <span id='pid'>1258, <a href='https://arxiv.org/pdf/2509.12358.pdf' target='_blank'>https://arxiv.org/pdf/2509.12358.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Sun, Joshua A. Vita, Amit Samanta, Vincenzo Lordi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12358">Unsupervised Atomic Data Mining via Multi-Kernel Graph Autoencoders for Machine Learning Force Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing a chemically diverse dataset while avoiding sampling bias is critical to training efficient and generalizable force fields. However, in computational chemistry and materials science, many common dataset generation techniques are prone to oversampling regions of the potential energy surface. Furthermore, these regions can be difficult to identify and isolate from each other or may not align well with human intuition, making it challenging to systematically remove bias in the dataset. While traditional clustering and pruning (down-sampling) approaches can be useful for this, they can often lead to information loss or a failure to properly identify distinct regions of the potential energy surface due to difficulties associated with the high dimensionality of atomic descriptors. In this work, we introduce the Multi-kernel Edge Attention-based Graph Autoencoder (MEAGraph) model, an unsupervised approach for analyzing atomic datasets. MEAGraph combines multiple linear kernel transformations with attention-based message passing to capture geometric sensitivity and enable effective dataset pruning without relying on labels or extensive training. Demonstrated applications on niobium, tantalum, and iron datasets show that MEAGraph efficiently groups similar atomic environments, allowing for the use of basic pruning techniques for removing sampling bias. This approach provides an effective method for representation learning and clustering that can be used for data analysis, outlier detection, and dataset optimization.
<div id='section'>Paperid: <span id='pid'>1259, <a href='https://arxiv.org/pdf/2509.12329.pdf' target='_blank'>https://arxiv.org/pdf/2509.12329.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengjie Kris Liu, Siqin Wang, Lu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12329">Uncertainty-Aware Hourly Air Temperature Mapping at 2 km Resolution via Physics-Guided Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Near-surface air temperature is a key physical property of the Earth's surface. Although weather stations offer continuous monitoring and satellites provide broad spatial coverage, no single data source offers seamless data in a spatiotemporal fashion. Here, we propose a data-driven, physics-guided deep learning approach to generate hourly air temperature data at 2 km resolution over the contiguous United States. The approach, called Amplifier Air-Transformer, first reconstructs GOES-16 surface temperature data obscured by clouds. It does so through a neural network encoded with the annual temperature cycle, incorporating a linear term to amplify ERA5 temperature values at finer scales and convolutional layers to capture spatiotemporal variations. Then, another neural network transforms the reconstructed surface temperature into air temperature by leveraging its latent relationship with key Earth surface properties. The approach is further enhanced with predictive uncertainty estimation through deep ensemble learning to improve reliability. The proposed approach is built and tested on 77.7 billion surface temperature pixels and 155 million air temperature records from weather stations across the contiguous United States (2018-2024), achieving hourly air temperature mapping accuracy of 1.93 C in station-based validation. The proposed approach streamlines surface temperature reconstruction and air temperature prediction, and it can be extended to other satellite sources for seamless air temperature monitoring at high spatiotemporal resolution. The generated data of this study can be downloaded at https://doi.org/10.5281/zenodo.15252812, and the project webpage can be found at https://skrisliu.com/HourlyAirTemp2kmUSA/.
<div id='section'>Paperid: <span id='pid'>1260, <a href='https://arxiv.org/pdf/2509.11892.pdf' target='_blank'>https://arxiv.org/pdf/2509.11892.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akito Shinohara, Kohei Fukuda, Hiroaki Aizawa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11892">Logit Mixture Outlier Exposure for Fine-grained Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to detect out-of-distribution data is essential not only for ensuring robustness against unknown or unexpected input data but also for improving the generalization performance of the model. Among various out-of-distribution detection methods, Outlier Exposure and Mixture Outlier Exposure are promising approaches that enhance out-of-distribution detection performance by exposing the outlier data during training. However, even with these sophisticated techniques, it remains challenging for models to learn the relationships between classes effectively and to distinguish data sampling from in-distribution and out-of-distribution clearly. Therefore, we focus on the logit space, where the properties between class-wise distributions are distinctly separated from those in the input or feature spaces. Specifically, we propose a linear interpolation technique in the logit space that mixes in-distribution and out-of-distribution data to facilitate smoothing logits between classes and improve the out-of-distribution detection performance, particularly for out-of-distribution data that lie close to the in-distribution data. Additionally, we enforce consistency between the logits obtained through mixing in the logit space and those generated via mixing in the input space. Our experiments demonstrate that our logit-space mixing technique reduces the abrupt fluctuations in the model outputs near the decision boundaries, resulting in smoother and more reliable separation between in-distribution and out-of-distribution data. Furthermore, we evaluate the effectiveness of the proposed method on a fine-grained out-of-distribution detection task.
<div id='section'>Paperid: <span id='pid'>1261, <a href='https://arxiv.org/pdf/2509.07523.pdf' target='_blank'>https://arxiv.org/pdf/2509.07523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jad Yehya, Mansour Benbakoura, Cédric Allain, Benoît Malezieux, Matthieu Kowalski, Thomas Moreau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07523">RoseCDL: Robust and Scalable Convolutional Dictionary Learning for Rare-event Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying recurring patterns and rare events in large-scale signals is a fundamental challenge in fields such as astronomy, physical simulations, and biomedical science. Convolutional Dictionary Learning (CDL) offers a powerful framework for modeling local structures in signals, but its use for detecting rare or anomalous events remains largely unexplored. In particular, CDL faces two key challenges in this setting: high computational cost and sensitivity to artifacts and outliers. In this paper, we introduce RoseCDL, a scalable and robust CDL algorithm designed for unsupervised rare event detection in long signals. RoseCDL combines stochastic windowing for efficient training on large datasets with inline outlier detection to enhance robustness and isolate anomalous patterns. This reframes CDL as a practical tool for event discovery and characterization in real-world signals, extending its role beyond traditional tasks like compression or denoising.
<div id='section'>Paperid: <span id='pid'>1262, <a href='https://arxiv.org/pdf/2508.20066.pdf' target='_blank'>https://arxiv.org/pdf/2508.20066.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheng Li, Yanming Guo, WenZhe Liu, Xueyi Zhang, Zhaoyun Ding, Long Xu, Mingrui Lao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20066">PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cross-view geo-localization is a critical task for UAV navigation, event detection, and aerial surveying, as it enables matching between drone-captured and satellite imagery. Most existing approaches embed multi-modal data into a joint feature space to maximize the similarity of paired images. However, these methods typically assume perfect alignment of image pairs during training, which rarely holds true in real-world scenarios. In practice, factors such as urban canyon effects, electromagnetic interference, and adverse weather frequently induce GPS drift, resulting in systematic alignment shifts where only partial correspondences exist between pairs. Despite its prevalence, this source of noisy correspondence has received limited attention in current research. In this paper, we formally introduce and address the Noisy Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to bridge the gap between idealized benchmarks and practical applications. To this end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a novel framework that partitions and augments training data based on estimated data uncertainty through uncertainty-aware co-augmentation and evidential co-training. Specifically, PAUL selectively augments regions with high correspondence confidence and utilizes uncertainty estimation to refine feature learning, effectively suppressing noise from misaligned pairs. Distinct from traditional filtering or label correction, PAUL leverages both data uncertainty and loss discrepancy for targeted partitioning and augmentation, thus providing robust supervision for noisy samples. Comprehensive experiments validate the effectiveness of individual components in PAUL,which consistently achieves superior performance over other competitive noisy-correspondence-driven methods in various noise ratios.
<div id='section'>Paperid: <span id='pid'>1263, <a href='https://arxiv.org/pdf/2508.18188.pdf' target='_blank'>https://arxiv.org/pdf/2508.18188.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Neo Christopher Chung, Jakub Binda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18188">Explain and Monitor Deep Learning Models for Computer Vision using Obz AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has transformed computer vision (CV), achieving outstanding performance in classification, segmentation, and related tasks. Such AI-based CV systems are becoming prevalent, with applications spanning from medical imaging to surveillance. State of the art models such as convolutional neural networks (CNNs) and vision transformers (ViTs) are often regarded as ``black boxes,'' offering limited transparency into their decision-making processes. Despite a recent advancement in explainable AI (XAI), explainability remains underutilized in practical CV deployments. A primary obstacle is the absence of integrated software solutions that connect XAI techniques with robust knowledge management and monitoring frameworks. To close this gap, we have developed Obz AI, a comprehensive software ecosystem designed to facilitate state-of-the-art explainability and observability for vision AI systems. Obz AI provides a seamless integration pipeline, from a Python client library to a full-stack analytics dashboard. With Obz AI, a machine learning engineer can easily incorporate advanced XAI methodologies, extract and analyze features for outlier detection, and continuously monitor AI models in real time. By making the decision-making mechanisms of deep models interpretable, Obz AI promotes observability and responsible deployment of computer vision systems.
<div id='section'>Paperid: <span id='pid'>1264, <a href='https://arxiv.org/pdf/2508.13406.pdf' target='_blank'>https://arxiv.org/pdf/2508.13406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nooshin Bahador, Milad Lankarany
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13406">Semi-Supervised Anomaly Detection Pipeline for SOZ Localization Using Ictal-Related Chirp</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a quantitative framework for evaluating the spatial concordance between clinically defined seizure onset zones (SOZs) and statistically anomalous channels identified through time-frequency analysis of chirp events. The proposed pipeline employs a two-step methodology: (1) Unsupervised Outlier Detection, where Local Outlier Factor (LOF) analysis with adaptive neighborhood selection identifies anomalous channels based on spectro-temporal features of chirp (Onset frequency, offset frequency, and temporal duration); and (2) Spatial Correlation Analysis, which computes both exact co-occurrence metrics and weighted index similarity, incorporating hemispheric congruence and electrode proximity. Key findings demonstrate that the LOF-based approach (N neighbors=20, contamination=0.2) effectively detects outliers, with index matching (weighted by channel proximity) outperforming exact matching in SOZ localization. Performance metrics (precision, recall, F1) were highest for seizure-free patients (Index Precision mean: 0.903) and those with successful surgical outcomes (Index Precision mean: 0.865), whereas failure cases exhibited lower concordance (Index Precision mean: 0.460). The key takeaway is that chirp-based outlier detection, combined with weighted spatial metrics, provides a complementary method for SOZ localization, particularly in patients with successful surgical outcomes.
<div id='section'>Paperid: <span id='pid'>1265, <a href='https://arxiv.org/pdf/2508.07923.pdf' target='_blank'>https://arxiv.org/pdf/2508.07923.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jakub Binda, Valentina Paneta, Vasileios Eleftheriadis, Hongkyou Chung, Panagiotis Papadimitroulas, Neo Christopher Chung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07923">Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative AI holds great potentials to automate and enhance data synthesis in nuclear medicine. However, the high-stakes nature of biomedical imaging necessitates robust mechanisms to detect and manage unexpected or erroneous model behavior. We introduce development and implementation of a hybrid anomaly detection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems. Two applications are demonstrated: Pose2Xray, which generates synthetic X-rays from photographic mouse images, and DosimetrEYE, which estimates 3D radiation dose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD) enhances reliability, reduces manual oversight, and supports real-time quality control. This approach strengthens the industrial viability of GenAI in preclinical settings by increasing robustness, scalability, and regulatory compliance.
<div id='section'>Paperid: <span id='pid'>1266, <a href='https://arxiv.org/pdf/2507.23035.pdf' target='_blank'>https://arxiv.org/pdf/2507.23035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xueying Wu, Baijun Zhou, Zhihui Gao, Yuzhe Fu, Qilin Zheng, Yintao He, Hai Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.23035">KLLM: Fast LLM Inference with K-Means Quantization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language model (LLM) inference poses significant challenges due to its intensive memory and computation demands. Weight and activation quantization (WAQ) offers a promising solution by reducing both memory footprint and arithmetic complexity. Traditional WAQ designs rely on uniform integer quantization for hardware efficiency, but often suffer from significant model performance degradation at low precision. In contrast, K-Means quantization, a non-uniform technique, achieves higher accuracy by aligning with the Gaussian-like distributions of weights and activations in LLMs. However, two key challenges prevent the efficient deployment of K-Means-based WAQ designs for LLM inference: (1) The non-uniform structure of K-Means-quantized data precludes direct execution on low-precision compute units, necessitating dequantization and floating-point matrix multiplications (MatMuls) during inference. (2) Activation outliers hinder effective low-precision quantization. Offline thresholding methods for outlier detection degrade model performance substantially, while existing online detection techniques introduce significant runtime overhead. To address the aforementioned challenges and fully unleash the potential of K-Means-based WAQ for LLM inference, in this paper, we propose KLLM, an LLM inference accelerator for efficient execution with K-Means-quantized weights and activations. KLLM features an index-based computation scheme for efficient execution of MatMuls and nonlinear operations on K-Means-quantized data, which avoids most of the dequantization and full-precision computations. Moreover, KLLM incorporates a lightweight outlier detection engine, Orizuru, that efficiently identifies the top-$k$ largest and smallest elements in the activation data stream during online inference.
<div id='section'>Paperid: <span id='pid'>1267, <a href='https://arxiv.org/pdf/2507.17193.pdf' target='_blank'>https://arxiv.org/pdf/2507.17193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyi Wang, Bingqian Dai, Kin Wong, Yaochen Li, Yang Cheng, Qingyuan Shu, Haoran He, Puyang Huang, Hanshen Huang, Kang L. Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.17193">Spintronic Bayesian Hardware Driven by Stochastic Magnetic Domain Wall Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As artificial intelligence (AI) advances into diverse applications, ensuring reliability of AI models is increasingly critical. Conventional neural networks offer strong predictive capabilities but produce deterministic outputs without inherent uncertainty estimation, limiting their reliability in safety-critical domains. Probabilistic neural networks (PNNs), which introduce randomness, have emerged as a powerful approach for enabling intrinsic uncertainty quantification. However, traditional CMOS architectures are inherently designed for deterministic operation and actively suppress intrinsic randomness. This poses a fundamental challenge for implementing PNNs, as probabilistic processing introduces significant computational overhead. To address this challenge, we introduce a Magnetic Probabilistic Computing (MPC) platform-an energy-efficient, scalable hardware accelerator that leverages intrinsic magnetic stochasticity for uncertainty-aware computing. This physics-driven strategy utilizes spintronic systems based on magnetic domain walls (DWs) and their dynamics to establish a new paradigm of physical probabilistic computing for AI. The MPC platform integrates three key mechanisms: thermally induced DW stochasticity, voltage controlled magnetic anisotropy (VCMA), and tunneling magnetoresistance (TMR), enabling fully electrical and tunable probabilistic functionality at the device level. As a representative demonstration, we implement a Bayesian Neural Network (BNN) inference structure and validate its functionality on CIFAR-10 classification tasks. Compared to standard 28nm CMOS implementations, our approach achieves a seven orders of magnitude improvement in the overall figure of merit, with substantial gains in area efficiency, energy consumption, and speed. These results underscore the MPC platform's potential to enable reliable and trustworthy physical AI systems.
<div id='section'>Paperid: <span id='pid'>1268, <a href='https://arxiv.org/pdf/2507.08905.pdf' target='_blank'>https://arxiv.org/pdf/2507.08905.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Koen Vellenga, H. Joe Steinhauer, GÃ¶ran Falkman, Jonas Andersson, Anders SjÃ¶gren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08905">Last Layer Hamiltonian Monte Carlo</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore the use of Hamiltonian Monte Carlo (HMC) sampling as a probabilistic last layer approach for deep neural networks (DNNs). While HMC is widely regarded as a gold standard for uncertainty estimation, the computational demands limit its application to large-scale datasets and large DNN architectures. Although the predictions from the sampled DNN parameters can be parallelized, the computational cost still scales linearly with the number of samples (similar to an ensemble). Last layer HMC (LL--HMC) reduces the required computations by restricting the HMC sampling to the final layer of a DNN, making it applicable to more data-intensive scenarios with limited computational resources. In this paper, we compare LL-HMC against five last layer probabilistic deep learning (LL-PDL) methods across three real-world video datasets for driver action and intention. We evaluate the in-distribution classification performance, calibration, and out-of-distribution (OOD) detection. Due to the stochastic nature of the probabilistic evaluations, we performed five grid searches for different random seeds to avoid being reliant on a single initialization for the hyperparameter configurations. The results show that LL--HMC achieves competitive in-distribution classification and OOD detection performance. Additional sampled last layer parameters do not improve the classification performance, but can improve the OOD detection. Multiple chains or starting positions did not yield consistent improvements.
<div id='section'>Paperid: <span id='pid'>1269, <a href='https://arxiv.org/pdf/2507.07668.pdf' target='_blank'>https://arxiv.org/pdf/2507.07668.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Frohnert, Denny Lane B. Sombillo, Evert van Nieuwenburg, Patrick Emonts
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07668">Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Matching theoretical predictions to experimental data remains a central challenge in hadron spectroscopy. In particular, the identification of new hadronic states is difficult, as exotic signals near threshold can arise from a variety of physical mechanisms. A key diagnostic in this context is the pole structure of the scattering amplitude, but different configurations can produce similar signatures. The mapping between pole configurations and line shapes is especially ambiguous near the mass threshold, where analytic control is limited. In this work, we introduce an uncertainty-aware machine learning approach for classifying pole structures in $S$-matrix elements. Our method is based on an ensemble of classifier chains that provide both epistemic and aleatoric uncertainty estimates. We apply a rejection criterion based on predictive uncertainty, achieving a validation accuracy of nearly $95\%$ while discarding only a small fraction of high-uncertainty predictions. Trained on synthetic data with known pole structures, the model generalizes to previously unseen experimental data, including enhancements associated with the $P_{c\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole structure, representing the presence of a genuine compact pentaquark in the presence of a higher channel virtual state pole with non-vanishing width. While evaluated on this particular state, our framework is broadly applicable to other candidate hadronic states and offers a scalable tool for pole structure inference in scattering amplitudes.
<div id='section'>Paperid: <span id='pid'>1270, <a href='https://arxiv.org/pdf/2507.05698.pdf' target='_blank'>https://arxiv.org/pdf/2507.05698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohsi Jawaid, Marcus MÃ¤rtens, Tat-Jun Chin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05698">Event-RGB Fusion for Spacecraft Pose Estimation Under Harsh Lighting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spacecraft pose estimation is crucial for autonomous in-space operations, such as rendezvous, docking and on-orbit servicing. Vision-based pose estimation methods, which typically employ RGB imaging sensors, is a compelling solution for spacecraft pose estimation, but are challenged by harsh lighting conditions, which produce imaging artifacts such as glare, over-exposure, blooming and lens flare. Due to their much higher dynamic range, neuromorphic or event sensors are more resilient to extreme lighting conditions. However, event sensors generally have lower spatial resolution and suffer from reduced signal-to-noise ratio during periods of low relative motion. This work addresses these individual sensor limitations by introducing a sensor fusion approach combining RGB and event sensors. A beam-splitter prism was employed to achieve precise optical and temporal alignment. Then, a RANSAC-based technique was developed to fuse the information from the RGB and event channels to achieve pose estimation that leveraged the strengths of the two modalities. The pipeline was complemented by dropout uncertainty estimation to detect extreme conditions that affect either channel. To benchmark the performance of the proposed event-RGB fusion method, we collected a comprehensive real dataset of RGB and event data for satellite pose estimation in a laboratory setting under a variety of challenging illumination conditions. Encouraging results on the dataset demonstrate the efficacy of our event-RGB fusion approach and further supports the usage of event sensors for spacecraft pose estimation. To support community research on this topic, our dataset will be released publicly.
<div id='section'>Paperid: <span id='pid'>1271, <a href='https://arxiv.org/pdf/2506.17872.pdf' target='_blank'>https://arxiv.org/pdf/2506.17872.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sree Bhargavi Balija, Amitash Nanda, Debashis Sahoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17872">Decoding Federated Learning: The FedNAM+ Conformal Revolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning has significantly advanced distributed training of machine learning models across decentralized data sources. However, existing frameworks often lack comprehensive solutions that combine uncertainty quantification, interpretability, and robustness. To address this, we propose FedNAM+, a federated learning framework that integrates Neural Additive Models (NAMs) with a novel conformal prediction method to enable interpretable and reliable uncertainty estimation. Our method introduces a dynamic level adjustment technique that utilizes gradient-based sensitivity maps to identify key input features influencing predictions. This facilitates both interpretability and pixel-wise uncertainty estimates. Unlike traditional interpretability methods such as LIME and SHAP, which do not provide confidence intervals, FedNAM+ offers visual insights into prediction reliability. We validate our approach through experiments on CT scan, MNIST, and CIFAR datasets, demonstrating high prediction accuracy with minimal loss (e.g., only 0.1% on MNIST), along with transparent uncertainty measures. Visual analysis highlights variable uncertainty intervals, revealing low-confidence regions where model performance can be improved with additional data. Compared to Monte Carlo Dropout, FedNAM+ delivers efficient and global uncertainty estimates with reduced computational overhead, making it particularly suitable for federated learning scenarios. Overall, FedNAM+ provides a robust, interpretable, and computationally efficient framework that enhances trust and transparency in decentralized predictive modeling.
<div id='section'>Paperid: <span id='pid'>1272, <a href='https://arxiv.org/pdf/2506.15505.pdf' target='_blank'>https://arxiv.org/pdf/2506.15505.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Agnimitra Dasgupta, Javier Murgoitio-Esandi, Ali Fardisi, Assad A Oberai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15505">Time-dependent density estimation using binary classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a data-driven method to learn the time-dependent probability density of a multivariate stochastic process from sample paths, assuming that the initial probability density is known and can be evaluated. Our method uses a novel time-dependent binary classifier trained using a contrastive estimation-based objective that trains the classifier to discriminate between realizations of the stochastic process at two nearby time instants. Significantly, the proposed method explicitly models the time-dependent probability distribution, which means that it is possible to obtain the value of the probability density within the time horizon of interest. Additionally, the input before the final activation in the time-dependent classifier is a second-order approximation to the partial derivative, with respect to time, of the logarithm of the density. We apply the proposed approach to approximate the time-dependent probability density functions for systems driven by stochastic excitations. We also use the proposed approach to synthesize new samples of a random vector from a given set of its realizations. In such applications, we generate sample paths necessary for training using stochastic interpolants. Subsequently, new samples are generated using gradient-based Markov chain Monte Carlo methods because automatic differentiation can efficiently provide the necessary gradient. Further, we demonstrate the utility of an explicit approximation to the time-dependent probability density function through applications in unsupervised outlier detection. Through several numerical experiments, we show that the proposed method accurately reconstructs complex time-dependent, multi-modal, and near-degenerate densities, scales effectively to moderately high-dimensional problems, and reliably detects rare events among real-world data.
<div id='section'>Paperid: <span id='pid'>1273, <a href='https://arxiv.org/pdf/2506.10770.pdf' target='_blank'>https://arxiv.org/pdf/2506.10770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joran Leest, Claudia Raibulet, Patricia Lago, Ilias Gerostathopoulos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10770">From Tea Leaves to System Maps: A Survey and Framework on Context-aware Machine Learning Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) models in production fail when their broader systems -- from data pipelines to deployment environments -- deviate from training assumptions, not merely due to statistical anomalies in input data. Despite extensive work on data drift, data validation, and out-of-distribution detection, ML monitoring research remains largely model-centric while neglecting contextual information: auxiliary signals about the system around the model (external factors, data pipelines, downstream applications). Incorporating this context turns statistical anomalies into actionable alerts and structured root-cause analysis. Drawing on a systematic review of 94 primary studies, we identify three dimensions of contextual information for ML monitoring: the system element concerned (natural environment or technical infrastructure); the aspect of that element (runtime states, structural relationships, prescriptive properties); and the representation used (formal constructs or informal formats). This forms the Contextual System-Aspect-Representation (C-SAR) framework, a descriptive model synthesizing our findings. We identify 20 recurring triplets across these dimensions and map them to the monitoring activities they support. This study provides a holistic perspective on ML monitoring: from interpreting "tea leaves" (i.e., isolated data and performance statistics) to constructing and managing "system maps" (i.e., end-to-end views that connect data, models, and operating context).
<div id='section'>Paperid: <span id='pid'>1274, <a href='https://arxiv.org/pdf/2506.09745.pdf' target='_blank'>https://arxiv.org/pdf/2506.09745.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangrui Zhu, Junhua Bao, Yipan Wei, Yapeng Li, Bo Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09745">Class Similarity-Based Multimodal Classification under Heterogeneous Category Sets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing multimodal methods typically assume that different modalities share the same category set. However, in real-world applications, the category distributions in multimodal data exhibit inconsistencies, which can hinder the model's ability to effectively utilize cross-modal information for recognizing all categories. In this work, we propose the practical setting termed Multi-Modal Heterogeneous Category-set Learning (MMHCL), where models are trained in heterogeneous category sets of multi-modal data and aim to recognize complete classes set of all modalities during test. To effectively address this task, we propose a Class Similarity-based Cross-modal Fusion model (CSCF). Specifically, CSCF aligns modality-specific features to a shared semantic space to enable knowledge transfer between seen and unseen classes. It then selects the most discriminative modality for decision fusion through uncertainty estimation. Finally, it integrates cross-modal information based on class similarity, where the auxiliary modality refines the prediction of the dominant one. Experimental results show that our method significantly outperforms existing state-of-the-art (SOTA) approaches on multiple benchmark datasets, effectively addressing the MMHCL task.
<div id='section'>Paperid: <span id='pid'>1275, <a href='https://arxiv.org/pdf/2505.18890.pdf' target='_blank'>https://arxiv.org/pdf/2505.18890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Morteza Rakhshaninejad, Mira Jurgens, Nicolas Dewolf, Willem Waegeman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18890">Conformal Prediction for Uncertainty Estimation in Drug-Target Interaction Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate drug-target interaction (DTI) prediction with machine learning models is essential for drug discovery. Such models should also provide a credible representation of their uncertainty, but applying classical marginal conformal prediction (CP) in DTI prediction often overlooks variability across drug and protein subgroups. In this work, we analyze three cluster-conditioned CP methods for DTI prediction, and compare them with marginal and group-conditioned CP. Clusterings are obtained via nonconformity scores, feature similarity, and nearest neighbors, respectively. Experiments on the KIBA dataset using four data-splitting strategies show that nonconformity-based clustering yields the tightest intervals and most reliable subgroup coverage, especially in random and fully unseen drug-protein splits. Group-conditioned CP works well when one entity is familiar, but residual-driven clustering provides robust uncertainty estimates even in sparse or novel scenarios. These results highlight the potential of cluster-based CP for improving DTI prediction under uncertainty.
<div id='section'>Paperid: <span id='pid'>1276, <a href='https://arxiv.org/pdf/2505.16017.pdf' target='_blank'>https://arxiv.org/pdf/2505.16017.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mariia Seleznova, Hung-Hsu Chou, Claudio Mayrink Verdun, Gitta Kutyniok
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16017">GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce GradPCA, an Out-of-Distribution (OOD) detection method that exploits the low-rank structure of neural network gradients induced by Neural Tangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis (PCA) to gradient class-means, achieving more consistent performance than existing methods across standard image classification benchmarks. We provide a theoretical perspective on spectral OOD detection in neural networks to support GradPCA, highlighting feature-space properties that enable effective detection and naturally emerge from NTK alignment. Our analysis further reveals that feature quality -- particularly the use of pretrained versus non-pretrained representations -- plays a crucial role in determining which detectors will succeed. Extensive experiments validate the strong performance of GradPCA, and our theoretical framework offers guidance for designing more principled spectral OOD detectors.
<div id='section'>Paperid: <span id='pid'>1277, <a href='https://arxiv.org/pdf/2505.12803.pdf' target='_blank'>https://arxiv.org/pdf/2505.12803.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawen Xu, Odej Kao, Margret Keuper
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12803">Informed Mixing -- Improving Open Set Recognition via Attribution-based Augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Open set recognition (OSR) is devised to address the problem of detecting novel classes during model inference. Even in recent vision models, this remains an open issue which is receiving increasing attention. Thereby, a crucial challenge is to learn features that are relevant for unseen categories from given data, for which these features might not be discriminative. To facilitate this process and "optimize to learn" more diverse features, we propose GradMix, a data augmentation method that dynamically leverages gradient-based attribution maps of the model during training to mask out already learned concepts. Thus GradMix encourages the model to learn a more complete set of representative features from the same data source. Extensive experiments on open set recognition, close set classification, and out-of-distribution detection reveal that our method can often outperform the state-of-the-art. GradMix can further increase model robustness to corruptions as well as downstream classification performance for self-supervised learning, indicating its benefit for model generalization.
<div id='section'>Paperid: <span id='pid'>1278, <a href='https://arxiv.org/pdf/2505.04787.pdf' target='_blank'>https://arxiv.org/pdf/2505.04787.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sriram Mandalika, Harsha Vardhan, Athira Nambiar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04787">Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Learning entails progressively acquiring knowledge from new data while retaining previously acquired knowledge, thereby mitigating ``Catastrophic Forgetting'' in neural networks. Our work presents a novel uncertainty-driven Unsupervised Continual Learning framework using Generative Replay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture efficiently uses unlabelled and synthetic labelled data in a balanced proportion using a cluster-level uncertainty-driven feedback mechanism and a VLM-powered generative replay module. Unlike traditional memory-buffer methods that depend on pretrained models and pseudo-labels, our R2R framework operates without any prior training. It leverages visual features from unlabeled data and adapts continuously using clustering-based uncertainty estimation coupled with dynamic thresholding. Concurrently, a generative replay mechanism along with DeepSeek-R1 powered CLIP VLM produces labelled synthetic data representative of past experiences, resembling biological visual thinking that replays memory to remember and act in new, unseen tasks. Extensive experimental analyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and TinyImageNet datasets. Our proposed R2R approach improves knowledge retention, achieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%, 59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.
<div id='section'>Paperid: <span id='pid'>1279, <a href='https://arxiv.org/pdf/2505.04019.pdf' target='_blank'>https://arxiv.org/pdf/2505.04019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matteo Ceschin, Leonardo Arrighi, Luca Longo, Sylvio Barbon Junior
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04019">Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The need to explain predictive models is well-established in modern machine learning. However, beyond model interpretability, understanding pre-processing methods is equally essential. Understanding how data modifications impact model performance improvements and potential biases and promoting a reliable pipeline is mandatory for developing robust machine learning solutions. Isolation Forest (iForest) is a widely used technique for outlier detection that performs well. Its effectiveness increases with the number of tree-based learners. However, this also complicates the explanation of outlier selection and the decision boundaries for inliers. This research introduces a novel Explainable AI (XAI) method, tackling the problem of global explainability. In detail, it aims to offer a global explanation for outlier detection to address its opaque nature. Our approach is based on the Decision Predicate Graph (DPG), which clarifies the logic of ensemble methods and provides both insights and a graph-based metric to explain how samples are identified as outliers using the proposed Inlier-Outlier Propagation Score (IOP-Score). Our proposal enhances iForest's explainability and provides a comprehensive view of the decision-making process, detailing which features contribute to outlier identification and how the model utilizes them. This method advances the state-of-the-art by providing insights into decision boundaries and a comprehensive view of holistic feature usage in outlier identification. -- thus promoting a fully explainable machine learning pipeline.
<div id='section'>Paperid: <span id='pid'>1280, <a href='https://arxiv.org/pdf/2505.03567.pdf' target='_blank'>https://arxiv.org/pdf/2505.03567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zengli Luo, Canlong Zhang, Zhixin Li, Zhiwen Wang, Chunrong Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03567">Uncertainty-Aware Prototype Semantic Decoupling for Text-Based Person Search in Full Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Text-based pedestrian search (TBPS) in full images aims to locate a target pedestrian in untrimmed images using natural language descriptions. However, in complex scenes with multiple pedestrians, existing methods are limited by uncertainties in detection and matching, leading to degraded performance. To address this, we propose UPD-TBPS, a novel framework comprising three modules: Multi-granularity Uncertainty Estimation (MUE), Prototype-based Uncertainty Decoupling (PUD), and Cross-modal Re-identification (ReID). MUE conducts multi-granularity queries to identify potential targets and assigns confidence scores to reduce early-stage uncertainty. PUD leverages visual context decoupling and prototype mining to extract features of the target pedestrian described in the query. It separates and learns pedestrian prototype representations at both the coarse-grained cluster level and the fine-grained individual level, thereby reducing matching uncertainty. ReID evaluates candidates with varying confidence levels, improving detection and retrieval accuracy. Experiments on CUHK-SYSU-TBPS and PRW-TBPS datasets validate the effectiveness of our framework.
<div id='section'>Paperid: <span id='pid'>1281, <a href='https://arxiv.org/pdf/2504.11434.pdf' target='_blank'>https://arxiv.org/pdf/2504.11434.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Ding, Xixi Liu, Jonas Unger, Gabriel Eilertsen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11434">Enhancing Out-of-Distribution Detection with Extended Logit Normalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for the safe deployment of machine learning models. Recent advances have explored improved classification losses and representation learning strategies to enhance OOD detection. However, these methods are often tailored to specific post-hoc detection techniques, limiting their generalizability. In this work, we identify a critical issue in Logit Normalization (LogitNorm), which inhibits its effectiveness in improving certain post-hoc OOD detection methods. To address this, we propose Extended Logit Normalization ($\textbf{ELogitNorm}$), a novel hyperparameter-free formulation that significantly benefits a wide range of post-hoc detection methods. By incorporating feature distance-awareness to LogitNorm, $\textbf{ELogitNorm}$ shows more robust OOD separability and in-distribution (ID) confidence calibration than its predecessor. Extensive experiments across standard benchmarks demonstrate that our approach outperforms state-of-the-art training-time methods in OOD detection while maintaining strong ID classification accuracy.
<div id='section'>Paperid: <span id='pid'>1282, <a href='https://arxiv.org/pdf/2503.22271.pdf' target='_blank'>https://arxiv.org/pdf/2503.22271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Omini Rathore, Richard Paul, Abigail Morrison, Hanno Scharr, Elisabeth Pfaehler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22271">Efficient Epistemic Uncertainty Estimation in Cerebrovascular Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Brain vessel segmentation of MR scans is a critical step in the diagnosis of cerebrovascular diseases. Due to the fine vessel structure, manual vessel segmentation is time consuming. Therefore, automatic deep learning (DL) based segmentation techniques are intensively investigated. As conventional DL models yield a high complexity and lack an indication of decision reliability, they are often considered as not trustworthy. This work aims to increase trust in DL based models by incorporating epistemic uncertainty quantification into cerebrovascular segmentation models for the first time. By implementing an efficient ensemble model combining the advantages of Bayesian Approximation and Deep Ensembles, we aim to overcome the high computational costs of conventional probabilistic networks. Areas of high model uncertainty and erroneous predictions are aligned which demonstrates the effectiveness and reliability of the approach. We perform extensive experiments applying the ensemble model on out-of-distribution (OOD) data. We demonstrate that for OOD-images, the estimated uncertainty increases. Additionally, omitting highly uncertain areas improves the segmentation quality, both for in- and out-of-distribution data. The ensemble model explains its limitations in a reliable manner and can maintain trustworthiness also for OOD data and could be considered in clinical applications
<div id='section'>Paperid: <span id='pid'>1283, <a href='https://arxiv.org/pdf/2503.18836.pdf' target='_blank'>https://arxiv.org/pdf/2503.18836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxuan Zhang, Jinkui Hao, Bo Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18836">Dual-domain Multi-path Self-supervised Diffusion Model for Accelerated MRI Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic resonance imaging (MRI) is a vital diagnostic tool, but its inherently long acquisition times reduce clinical efficiency and patient comfort. Recent advancements in deep learning, particularly diffusion models, have improved accelerated MRI reconstruction. However, existing diffusion models' training often relies on fully sampled data, models incur high computational costs, and often lack uncertainty estimation, limiting their clinical applicability. To overcome these challenges, we propose a novel framework, called Dual-domain Multi-path Self-supervised Diffusion Model (DMSM), that integrates a self-supervised dual-domain diffusion model training scheme, a lightweight hybrid attention network for the reconstruction diffusion model, and a multi-path inference strategy, to enhance reconstruction accuracy, efficiency, and explainability. Unlike traditional diffusion-based models, DMSM eliminates the dependency on training from fully sampled data, making it more practical for real-world clinical settings. We evaluated DMSM on two human MRI datasets, demonstrating that it achieves favorable performance over several supervised and self-supervised baselines, particularly in preserving fine anatomical structures and suppressing artifacts under high acceleration factors. Additionally, our model generates uncertainty maps that correlate reasonably well with reconstruction errors, offering valuable clinically interpretable guidance and potentially enhancing diagnostic confidence.
<div id='section'>Paperid: <span id='pid'>1284, <a href='https://arxiv.org/pdf/2503.18784.pdf' target='_blank'>https://arxiv.org/pdf/2503.18784.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenxi Chen, Raymond A. Yeh, Shaoshuai Mou, Yan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18784">Leveraging Perturbation Robustness to Enhance Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is the task of identifying inputs that deviate from the training data distribution. This capability is essential for safely deploying deep computer vision models in open-world environments. In this work, we propose a post-hoc method, Perturbation-Rectified OOD detection (PRO), based on the insight that prediction confidence for OOD inputs is more susceptible to reduction under perturbation than in-distribution (IND) inputs. Based on the observation, we propose an adversarial score function that searches for the local minimum scores near the original inputs by applying gradient descent. This procedure enhances the separability between IND and OOD samples. Importantly, the approach improves OOD detection performance without complex modifications to the underlying model architectures. We conduct extensive experiments using the OpenOOD benchmark~\cite{yang2022openood}. Our approach further pushes the limit of softmax-based OOD detection and is the leading post-hoc method for small-scale models. On a CIFAR-10 model with adversarial training, PRO effectively detects near-OOD inputs, achieving a reduction of more than 10\% on FPR@95 compared to state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1285, <a href='https://arxiv.org/pdf/2503.18341.pdf' target='_blank'>https://arxiv.org/pdf/2503.18341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuma Kitazawa, Takahito Aoto, Satoshi Ikehata, Tsuyoshi Takatani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18341">PS-EIP: Robust Photometric Stereo Based on Event Interval Profile</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, the energy-efficient photometric stereo method using an event camera has been proposed to recover surface normals from events triggered by changes in logarithmic Lambertian reflections under a moving directional light source. However, EventPS treats each event interval independently, making it sensitive to noise, shadows, and non-Lambertian reflections. This paper proposes Photometric Stereo based on Event Interval Profile (PS-EIP), a robust method that recovers pixelwise surface normals from a time-series profile of event intervals. By exploiting the continuity of the profile and introducing an outlier detection method based on profile shape, our approach enhances robustness against outliers from shadows and specular reflections. Experiments using real event data from 3D-printed objects demonstrate that PS-EIP significantly improves robustness to outliers compared to EventPS's deep-learning variant, EventPS-FCN, without relying on deep learning.
<div id='section'>Paperid: <span id='pid'>1286, <a href='https://arxiv.org/pdf/2503.01691.pdf' target='_blank'>https://arxiv.org/pdf/2503.01691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuyan Chen, Nico Lang, B. Christian Schmidt, Aditya Jain, Yves Basset, Sara Beery, Maxim LarrivÃ©e, David Rolnick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.01691">Open-Set Recognition of Novel Species in Biodiversity Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning is increasingly being applied to facilitate long-term, large-scale biodiversity monitoring. With most species on Earth still undiscovered or poorly documented, species-recognition models are expected to encounter new species during deployment. We introduce Open-Insects, a fine-grained image recognition benchmark dataset for open-set recognition and out-of-distribution detection in biodiversity monitoring. Open-Insects makes it possible to evaluate algorithms for new species detection on several geographical open-set splits with varying difficulty. Furthermore, we present a test set recently collected in the wild with 59 species that are likely new to science. We evaluate a variety of open-set recognition algorithms, including post-hoc methods, training-time regularization, and training with auxiliary data, finding that the simple post-hoc approach of utilizing softmax scores remains a strong baseline. We also demonstrate how to leverage auxiliary data to improve the detection performance when the training dataset is limited. Our results provide timely insights to guide the development of computer vision methods for biodiversity monitoring and species discovery.
<div id='section'>Paperid: <span id='pid'>1287, <a href='https://arxiv.org/pdf/2503.00479.pdf' target='_blank'>https://arxiv.org/pdf/2503.00479.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andy Gray, Alma Rahat, Tom Crick, Stephen Lindsay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00479">Bayesian Active Learning for Multi-Criteria Comparative Judgement in Educational Assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Comparative Judgement (CJ) provides an alternative assessment approach by evaluating work holistically rather than breaking it into discrete criteria. This method leverages human ability to make nuanced comparisons, yielding more reliable and valid assessments. CJ aligns with real-world evaluations, where overall quality emerges from the interplay of various elements. However, rubrics remain widely used in education, offering structured criteria for grading and detailed feedback. This creates a gap between CJ's holistic ranking and the need for criterion-based performance breakdowns. This paper addresses this gap using a Bayesian approach. We build on Bayesian CJ (BCJ) by Gray et al., which directly models preferences instead of using likelihoods over total scores, allowing for expected ranks with uncertainty estimation. Their entropy-based active learning method selects the most informative pairwise comparisons for assessors. We extend BCJ to handle multiple independent learning outcome (LO) components, defined by a rubric, enabling both holistic and component-wise predictive rankings with uncertainty estimates. Additionally, we propose a method to aggregate entropies and identify the most informative comparison for assessors. Experiments on synthetic and real data demonstrate our method's effectiveness. Finally, we address a key limitation of BCJ, which is the inability to quantify assessor agreement. We show how to derive agreement levels, enhancing transparency in assessment.
<div id='section'>Paperid: <span id='pid'>1288, <a href='https://arxiv.org/pdf/2502.20375.pdf' target='_blank'>https://arxiv.org/pdf/2502.20375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aravind Gollakota, Parikshit Gopalan, Aayush Karan, Charlotte Peale, Udi Wieder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.20375">When does a predictor know its own loss?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given a predictor and a loss function, how well can we predict the loss that the predictor will incur on an input? This is the problem of loss prediction, a key computational task associated with uncertainty estimation for a predictor. In a classification setting, a predictor will typically predict a distribution over labels and hence have its own estimate of the loss that it will incur, given by the entropy of the predicted distribution. Should we trust this estimate? In other words, when does the predictor know what it knows and what it does not know?
  In this work we study the theoretical foundations of loss prediction. Our main contribution is to establish tight connections between nontrivial loss prediction and certain forms of multicalibration, a multigroup fairness notion that asks for calibrated predictions across computationally identifiable subgroups. Formally, we show that a loss predictor that is able to improve on the self-estimate of a predictor yields a witness to a failure of multicalibration, and vice versa. This has the implication that nontrivial loss prediction is in effect no easier or harder than auditing for multicalibration. We support our theoretical results with experiments that show a robust positive correlation between the multicalibration error of a predictor and the efficacy of training a loss predictor.
<div id='section'>Paperid: <span id='pid'>1289, <a href='https://arxiv.org/pdf/2502.14281.pdf' target='_blank'>https://arxiv.org/pdf/2502.14281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weipeng Huang, Qin Li, Yang Xiao, Cheng Qiao, Tie Cai, Junwei Liang, Neil J. Hurley, Guangyuan Piao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14281">Correcting Noisy Multilabel Predictions: Modeling Label Noise through Latent Space Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Noise in data appears to be inevitable in most real-world machine learning applications and would cause severe overfitting problems. Not only can data features contain noise, but labels are also prone to be noisy due to human input. In this paper, rather than noisy label learning in multiclass classifications, we instead focus on the less explored area of noisy label learning for multilabel classifications. Specifically, we investigate the post-correction of predictions generated from classifiers learned with noisy labels. The reasons are two-fold. Firstly, this approach can directly work with the trained models to save computational resources. Secondly, it could be applied on top of other noisy label correction techniques to achieve further improvements. To handle this problem, we appeal to deep generative approaches that are possible for uncertainty estimation. Our model posits that label noise arises from a stochastic shift in the latent variable, providing a more robust and beneficial means for noisy learning. We develop both unsupervised and semi-supervised learning methods for our model. The extensive empirical study presents solid evidence to that our approach is able to consistently improve the independent models and performs better than a number of existing methods across various noisy label settings. Moreover, a comprehensive empirical analysis of the proposed method is carried out to validate its robustness, including sensitivity analysis and an ablation study, among other elements.
<div id='section'>Paperid: <span id='pid'>1290, <a href='https://arxiv.org/pdf/2502.14003.pdf' target='_blank'>https://arxiv.org/pdf/2502.14003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryo Moriai, Nakamasa Inoue, Masayuki Tanaka, Rei Kawakami, Satoshi Ikehata, Ikuro Sato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14003">Rectified Lagrangian for Out-of-Distribution Detection in Modern Hopfield Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern Hopfield networks (MHNs) have recently gained significant attention in the field of artificial intelligence because they can store and retrieve a large set of patterns with an exponentially large memory capacity. A MHN is generally a dynamical system defined with Lagrangians of memory and feature neurons, where memories associated with in-distribution (ID) samples are represented by attractors in the feature space. One major problem in existing MHNs lies in managing out-of-distribution (OOD) samples because it was originally assumed that all samples are ID samples. To address this, we propose the rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that explicitly incorporates an attractor for OOD samples in the dynamical system of MHNs. RecLag creates a trivial point attractor for any interaction matrix, enabling OOD detection by identifying samples that fall into this attractor as OOD. The interaction matrix is optimized so that the probability densities can be estimated to identify ID/OOD. We demonstrate the effectiveness of RecLag-based MHNs compared to energy-based OOD detection methods, including those using state-of-the-art Hopfield energies, across nine image datasets.
<div id='section'>Paperid: <span id='pid'>1291, <a href='https://arxiv.org/pdf/2501.05530.pdf' target='_blank'>https://arxiv.org/pdf/2501.05530.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Shi, Nedret Billor, Elvan Ceyhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05530">Outlyingness Scores with Cluster Catch Digraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces two novel, outlyingness scores (OSs) based on Cluster Catch Digraphs (CCDs): Outbound Outlyingness Score (OOS) and Inbound Outlyingness Score (IOS). These scores enhance the interpretability of outlier detection results. Both OSs employ graph-, density-, and distribution-based techniques, tailored to high-dimensional data with varying cluster shapes and intensities. OOS evaluates the outlyingness of a point relative to its nearest neighbors, while IOS assesses the total ``influence" a point receives from others within its cluster. Both OSs effectively identify global and local outliers, invariant to data collinearity. Moreover, IOS is robust to the masking problems. With extensive Monte Carlo simulations, we compare the performance of both OSs with CCD-based, traditional, and state-of-the-art outlier detection methods. Both OSs exhibit substantial overall improvements over the CCD-based methods in both artificial and real-world data sets, particularly with IOS, which delivers the best overall performance among all the methods, especially in high-dimensional settings.
  Keywords: Outlier detection, Outlyingness score, Graph-based clustering, Cluster catch digraphs, High-dimensional data.
<div id='section'>Paperid: <span id='pid'>1292, <a href='https://arxiv.org/pdf/2501.01525.pdf' target='_blank'>https://arxiv.org/pdf/2501.01525.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammadreza M. Kalan, Eitan J. Neugut, Samory Kpotufe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01525">Transfer Neyman-Pearson Algorithm for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of transfer learning in outlier detection where target abnormal data is rare. While transfer learning has been considered extensively in traditional balanced classification, the problem of transfer in outlier detection and more generally in imbalanced classification settings has received less attention. We propose a general meta-algorithm which is shown theoretically to yield strong guarantees w.r.t. to a range of changes in abnormal distribution, and at the same time amenable to practical implementation. We then investigate different instantiations of this general meta-algorithm, e.g., based on multi-layer neural networks, and show empirically that they outperform natural extensions of transfer methods for traditional balanced classification settings (which are the only solutions available at the moment).
<div id='section'>Paperid: <span id='pid'>1293, <a href='https://arxiv.org/pdf/2501.01072.pdf' target='_blank'>https://arxiv.org/pdf/2501.01072.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiang Shang, Yuanmeng Wu, Xiaoxiang Han, Xi Chen, Qi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01072">Evidential Calibrated Uncertainty-Guided Interactive Segmentation paradigm for Ultrasound Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and robust ultrasound image segmentation is critical for computer-aided diagnostic systems. Nevertheless, the inherent challenges of ultrasound imaging, such as blurry boundaries and speckle noise, often cause traditional segmentation methods to struggle with performance. Despite recent advancements in universal image segmentation, such as the Segment Anything Model, existing interactive segmentation methods still suffer from inefficiency and lack of specialization. These methods rely heavily on extensive accurate manual or random sampling prompts for interaction, necessitating numerous prompts and iterations to reach satisfactory performance. In response to this challenge, we propose the Evidential Uncertainty-Guided Interactive Segmentation (EUGIS), an end-to-end, efficient tiered interactive segmentation paradigm based on evidential uncertainty estimation for ultrasound image segmentation. Specifically, EUGIS harnesses evidence-based uncertainty estimation, grounded in Dempster-Shafer theory and Subjective Logic, to gauge the level of uncertainty in the predictions of model for different regions. By prioritizing sampling the high-uncertainty region, our method can effectively simulate the interactive behavior of well-trained radiologists, enhancing the targeted of sampling while reducing the number of prompts and iterations required.Additionally, we propose a trainable calibration mechanism for uncertainty estimation, which can further optimize the boundary between certainty and uncertainty, thereby enhancing the confidence of uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1294, <a href='https://arxiv.org/pdf/2412.17586.pdf' target='_blank'>https://arxiv.org/pdf/2412.17586.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Evi M. C. Huijben, Sina Amirrajab, Josien P. W. Pluim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17586">Enhancing Reconstruction-Based Out-of-Distribution Detection in Brain MRI with Model and Metric Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for safely deploying automated medical image analysis systems, as abnormal patterns in images could hamper their performance. However, OOD detection in medical imaging remains an open challenge, and we address three gaps: the underexplored potential of a simple OOD detection model, the lack of optimization of deep learning strategies specifically for OOD detection, and the selection of appropriate reconstruction metrics. In this study, we investigated the effectiveness of a reconstruction-based autoencoder for unsupervised detection of synthetic artifacts in brain MRI. We evaluated the general reconstruction capability of the model, analyzed the impact of the selected training epoch and reconstruction metrics, assessed the potential of model and/or metric ensembles, and tested the model on a dataset containing a diverse range of artifacts. Among the metrics assessed, the contrast component of SSIM and LPIPS consistently outperformed others in detecting homogeneous circular anomalies. By combining two well-converged models and using LPIPS and contrast as reconstruction metrics, we achieved a pixel-level area under the Precision-Recall curve of 0.66. Furthermore, with the more realistic OOD dataset, we observed that the detection performance varied between artifact types; local artifacts were more difficult to detect, while global artifacts showed better detection results. These findings underscore the importance of carefully selecting metrics and model configurations, and highlight the need for tailored approaches, as standard deep learning approaches do not always align with the unique needs of OOD detection.
<div id='section'>Paperid: <span id='pid'>1295, <a href='https://arxiv.org/pdf/2412.04177.pdf' target='_blank'>https://arxiv.org/pdf/2412.04177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis A. Ortega, SimÃ³n RodrÃ­guez-Santana, Daniel HernÃ¡ndez-Lobato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04177">Fixed-Mean Gaussian Processes for Post-hoc Bayesian Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, there has been an increasing interest in performing post-hoc uncertainty estimation about the predictions of pre-trained deep neural networks (DNNs). Given a pre-trained DNN via back-propagation, these methods enhance the original network by adding output confidence measures, such as error bars, without compromising its initial accuracy. In this context, we introduce a novel family of sparse variational Gaussian processes (GPs), where the posterior mean is fixed to any continuous function when using a universal kernel. Specifically, we fix the mean of this GP to the output of the pre-trained DNN, allowing our approach to effectively fit the GP's predictive variances to estimate the DNN prediction uncertainty. Our approach leverages variational inference (VI) for efficient stochastic optimization, with training costs that remain independent of the number of training points, scaling efficiently to large datasets such as ImageNet. The proposed method, called fixed mean GP (FMGP), is architecture-agnostic, relying solely on the pre-trained model's outputs to adjust the predictive variances. Experimental results demonstrate that FMGP improves both uncertainty estimation and computational efficiency when compared to state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1296, <a href='https://arxiv.org/pdf/2412.02904.pdf' target='_blank'>https://arxiv.org/pdf/2412.02904.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ranganath Krishnan, Piyush Khanna, Omesh Tickoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02904">Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have revolutionized the field of natural language processing with their impressive reasoning and question-answering capabilities. However, these models are sometimes prone to generating credible-sounding but incorrect information, a phenomenon known as LLM hallucinations. Reliable uncertainty estimation in LLMs is essential for fostering trust in their generated responses and serves as a critical tool for the detection and prevention of erroneous or hallucinated outputs. To achieve reliable and well-calibrated uncertainty quantification in open-ended and free-form natural language generation, we propose an uncertainty-aware fine-tuning approach for LLMs. This approach enhances the model's ability to provide reliable uncertainty estimates without compromising accuracy, thereby guiding them to produce more trustworthy responses. We introduce a novel uncertainty-aware causal language modeling loss function, grounded in the principles of decision theory. Through rigorous evaluation on multiple free-form question-answering datasets and models, we demonstrate that our uncertainty-aware fine-tuning approach yields better calibrated uncertainty estimates in natural language generation tasks than fine-tuning with the standard causal language modeling loss. Furthermore, the experimental results show that the proposed method significantly improves the model's ability to detect hallucinations and identify out-of-domain prompts.
<div id='section'>Paperid: <span id='pid'>1297, <a href='https://arxiv.org/pdf/2411.00718.pdf' target='_blank'>https://arxiv.org/pdf/2411.00718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurav R. Pandey, Aaqib Saeed, Harlin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00718">PedSleepMAE: Generative Model for Multimodal Pediatric Sleep Signals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pediatric sleep is an important but often overlooked area in health informatics. We present PedSleepMAE, a generative model that fully leverages multimodal pediatric sleep signals including multichannel EEGs, respiratory signals, EOGs and EMG. This masked autoencoder-based model performs comparably to supervised learning models in sleep scoring and in the detection of apnea, hypopnea, EEG arousal and oxygen desaturation. Its embeddings are also shown to capture subtle differences in sleep signals coming from a rare genetic disorder. Furthermore, PedSleepMAE generates realistic signals that can be used for sleep segment retrieval, outlier detection, and missing channel imputation. This is the first general-purpose generative model trained on multiple types of pediatric sleep signals.
<div id='section'>Paperid: <span id='pid'>1298, <a href='https://arxiv.org/pdf/2410.23883.pdf' target='_blank'>https://arxiv.org/pdf/2410.23883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rena Gao, Xuetong Wu, Siwen Luo, Caren Han, Feng Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.23883">'No' Matters: Out-of-Distribution Detection in Multimodality Long Dialogue</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection in multimodal contexts is essential for identifying deviations in combined inputs from different modalities, particularly in applications like open-domain dialogue systems or real-life dialogue interactions. This paper aims to improve the user experience that involves multi-round long dialogues by efficiently detecting OOD dialogues and images. We introduce a novel scoring framework named Dialogue Image Aligning and Enhancing Framework (DIAEF) that integrates the visual language models with the novel proposed scores that detect OOD in two key scenarios (1) mismatches between the dialogue and image input pair and (2) input pairs with previously unseen labels. Our experimental results, derived from various benchmarks, demonstrate that integrating image and multi-round dialogue OOD detection is more effective with previously unseen labels than using either modality independently. In the presence of mismatched pairs, our proposed score effectively identifies these mismatches and demonstrates strong robustness in long dialogues. This approach enhances domain-aware, adaptive conversational agents and establishes baselines for future studies.
<div id='section'>Paperid: <span id='pid'>1299, <a href='https://arxiv.org/pdf/2410.13822.pdf' target='_blank'>https://arxiv.org/pdf/2410.13822.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>ClÃ©ment Playout, Renaud Duval, Marie Carole Boucher, Farida Cheriet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13822">Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The diagnosis of diabetic retinopathy, which relies on fundus images, faces challenges in achieving transparency and interpretability when using a global classification approach. However, segmentation-based databases are significantly more expensive to acquire and combining them is often problematic. This paper introduces a novel method, termed adversarial style conversion, to address the lack of standardization in annotation styles across diverse databases. By training a single architecture on combined databases, the model spontaneously modifies its segmentation style depending on the input, demonstrating the ability to convert among different labeling styles. The proposed methodology adds a linear probe to detect dataset origin based on encoder features and employs adversarial attacks to condition the model's segmentation style. Results indicate significant qualitative and quantitative through dataset combination, offering avenues for improved model generalization, uncertainty estimation and continuous interpolation between annotation styles. Our approach enables training a segmentation model with diverse databases while controlling and leveraging annotation styles for improved retinopathy diagnosis.
<div id='section'>Paperid: <span id='pid'>1300, <a href='https://arxiv.org/pdf/2410.08739.pdf' target='_blank'>https://arxiv.org/pdf/2410.08739.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qihang Yang, Yang Zhao, Hong Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08739">MMLF: Multi-modal Multi-class Late Fusion for Object Detection with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous driving necessitates advanced object detection techniques that integrate information from multiple modalities to overcome the limitations associated with single-modal approaches. The challenges of aligning diverse data in early fusion and the complexities, along with overfitting issues introduced by deep fusion, underscore the efficacy of late fusion at the decision level. Late fusion ensures seamless integration without altering the original detector's network structure. This paper introduces a pioneering Multi-modal Multi-class Late Fusion method, designed for late fusion to enable multi-class detection. Fusion experiments conducted on the KITTI validation and official test datasets illustrate substantial performance improvements, presenting our model as a versatile solution for multi-modal object detection in autonomous driving. Moreover, our approach incorporates uncertainty analysis into the classification fusion process, rendering our model more transparent and trustworthy and providing more reliable insights into category predictions.
<div id='section'>Paperid: <span id='pid'>1301, <a href='https://arxiv.org/pdf/2410.08651.pdf' target='_blank'>https://arxiv.org/pdf/2410.08651.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gleb Radchenko, Victoria Andrea Fill
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08651">Edge AI Collaborative Learning: Bayesian Approaches to Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in edge computing have significantly enhanced the AI capabilities of Internet of Things (IoT) devices. However, these advancements introduce new challenges in knowledge exchange and resource management, particularly addressing the spatiotemporal data locality in edge computing environments. This study examines algorithms and methods for deploying distributed machine learning within autonomous, network-capable, AI-enabled edge devices. We focus on determining confidence levels in learning outcomes considering the spatial variability of data encountered by independent agents. Using collaborative mapping as a case study, we explore the application of the Distributed Neural Network Optimization (DiNNO) algorithm extended with Bayesian neural networks (BNNs) for uncertainty estimation. We implement a 3D environment simulation using the Webots platform to simulate collaborative mapping tasks, decouple the DiNNO algorithm into independent processes for asynchronous network communication in distributed learning, and integrate distributed uncertainty estimation using BNNs. Our experiments demonstrate that BNNs can effectively support uncertainty estimation in a distributed learning context, with precise tuning of learning hyperparameters crucial for effective uncertainty assessment. Notably, applying Kullback-Leibler divergence for parameter regularization resulted in a 12-30% reduction in validation loss during distributed BNN training compared to other regularization strategies.
<div id='section'>Paperid: <span id='pid'>1302, <a href='https://arxiv.org/pdf/2410.07806.pdf' target='_blank'>https://arxiv.org/pdf/2410.07806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Niklas Erdmann, Lars Ã. Bentsen, Roy Stenbro, Heine N. Riise, Narada Warakagoda, Paal Engelstad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07806">Deep and Probabilistic Solar Irradiance Forecast at the Arctic Circle</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solar irradiance forecasts can be dynamic and unreliable due to changing weather conditions. Near the Arctic circle, this also translates into a distinct set of further challenges. This work is forecasting solar irradiance with Norwegian data using variations of Long-Short-Term Memory units (LSTMs). In order to gain more trustworthiness of results, the probabilistic approaches Quantile Regression (QR) and Maximum Likelihood (MLE) are optimized on top of the LSTMs, providing measures of uncertainty for the results. MLE is further extended by using a Johnson's SU distribution, a Johnson's SB distribution, and a Weibull distribution in addition to a normal Gaussian to model parameters. Contrary to a Gaussian, Weibull, Johnson's SU and Johnson's SB can return skewed distributions, enabling it to fit the non-normal solar irradiance distribution more optimally. The LSTMs are compared against each other, a simple Multi-layer Perceptron (MLP), and a smart-persistence estimator. The proposed LSTMs are found to be more accurate than smart persistence and the MLP for a multi-horizon, day-ahead (36 hours) forecast. The deterministic LSTM showed better root mean squared error (RMSE), but worse mean absolute error (MAE) than a MLE with Johnson's SB distribution. Probabilistic uncertainty estimation is shown to fit relatively well across the distribution of observed irradiance. While QR shows better uncertainty estimation calibration, MLE with Johnson's SB, Johnson's SU, or Gaussian show better performance in the other metrics employed. Optimizing and comparing the models against each other reveals a seemingly inherent trade-off between point-prediction and uncertainty estimation calibration.
<div id='section'>Paperid: <span id='pid'>1303, <a href='https://arxiv.org/pdf/2410.05468.pdf' target='_blank'>https://arxiv.org/pdf/2410.05468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanhao Sun, Thanos Triantafyllou, Anthos Makris, Maja DrmaÄ, Kai Xu, Luo Mai, Mahesh K. Marina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.05468">PH-Dropout: Practical Epistemic Uncertainty Quantification for View Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>View synthesis using Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) has demonstrated impressive fidelity in rendering real-world scenarios. However, practical methods for accurate and efficient epistemic Uncertainty Quantification (UQ) in view synthesis are lacking. Existing approaches for NeRF either introduce significant computational overhead (e.g., ``10x increase in training time" or ``10x repeated training") or are limited to specific uncertainty conditions or models. Notably, GS models lack any systematic approach for comprehensive epistemic UQ. This capability is crucial for improving the robustness and scalability of neural view synthesis, enabling active model updates, error estimation, and scalable ensemble modeling based on uncertainty. In this paper, we revisit NeRF and GS-based methods from a function approximation perspective, identifying key differences and connections in 3D representation learning. Building on these insights, we introduce PH-Dropout (Post hoc Dropout), the first real-time and accurate method for epistemic uncertainty estimation that operates directly on pre-trained NeRF and GS models. Extensive evaluations validate our theoretical findings and demonstrate the effectiveness of PH-Dropout.
<div id='section'>Paperid: <span id='pid'>1304, <a href='https://arxiv.org/pdf/2410.01281.pdf' target='_blank'>https://arxiv.org/pdf/2410.01281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haomin Wen, Shurui Cao, Zeeshan Rasheed, Khurram Hassan Shafique, Leman Akoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01281">Uncertainty-aware Human Mobility Modeling and Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the temporal GPS coordinates from a large set of human agents, how can we model their mobility behavior toward effective anomaly (e.g. bad-actor or malicious behavior) detection without any labeled data? Human mobility and trajectory modeling have been extensively studied, showcasing varying abilities to manage complex inputs and balance performance-efficiency trade-offs. In this work, we formulate anomaly detection in complex human behavior by modeling raw GPS data as a sequence of stay-point events, each characterized by spatio-temporal features, along with trips (i.e. commute) between the stay-points. Our problem formulation allows us to leverage modern sequence models for unsupervised training and anomaly detection. Notably, we equip our proposed model USTAD (for Uncertainty-aware Spatio-Temporal Anomaly Detection) with aleatoric (i.e. data) uncertainty estimation to account for inherent stochasticity in certain individuals' behavior, as well as epistemic (i.e. model) uncertainty to handle data sparsity under a large variety of human behaviors. Together, aleatoric and epistemic uncertainties unlock a robust loss function as well as uncertainty-aware decision-making in anomaly scoring. Extensive experiments shows that USTAD improves anomaly detection AUCROC by 3\%-15\% over baselines in industry-scale data.
<div id='section'>Paperid: <span id='pid'>1305, <a href='https://arxiv.org/pdf/2409.11985.pdf' target='_blank'>https://arxiv.org/pdf/2409.11985.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Viacheslav Barkov, Jonas Schmidinger, Robin Gebbers, Martin Atzmueller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11985">An Efficient Model-Agnostic Approach for Uncertainty Estimation in Data-Restricted Pedometric Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a model-agnostic approach designed to enhance uncertainty estimation in the predictive modeling of soil properties, a crucial factor for advancing pedometrics and the practice of digital soil mapping. For addressing the typical challenge of data scarcity in soil studies, we present an improved technique for uncertainty estimation. This method is based on the transformation of regression tasks into classification problems, which not only allows for the production of reliable uncertainty estimates but also enables the application of established machine learning algorithms with competitive performance that have not yet been utilized in pedometrics. Empirical results from datasets collected from two German agricultural fields showcase the practical application of the proposed methodology. Our results and findings suggest that the proposed approach has the potential to provide better uncertainty estimation than the models commonly used in pedometrics.
<div id='section'>Paperid: <span id='pid'>1306, <a href='https://arxiv.org/pdf/2409.11596.pdf' target='_blank'>https://arxiv.org/pdf/2409.11596.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Shi, Nedret Billor, Elvan Ceyhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11596">Outlier Detection with Cluster Catch Digraphs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel family of outlier detection algorithms based on Cluster Catch Digraphs (CCDs), specifically tailored to address the challenges of high dimensionality and varying cluster shapes, which deteriorate the performance of most traditional outlier detection methods. We propose the Uniformity-Based CCD with Mutual Catch Graph (U-MCCD), the Uniformity- and Neighbor-Based CCD with Mutual Catch Graph (UN-MCCD), and their shape-adaptive variants (SU-MCCD and SUN-MCCD), which are designed to detect outliers in data sets with arbitrary cluster shapes and high dimensions. We present the advantages and shortcomings of these algorithms and provide the motivation or need to define each particular algorithm. Through comprehensive Monte Carlo simulations, we assess their performance and demonstrate the robustness and effectiveness of our algorithms across various settings and contamination levels. We also illustrate the use of our algorithms on various real-life data sets. The U-MCCD algorithm efficiently identifies outliers while maintaining high true negative rates, and the SU-MCCD algorithm shows substantial improvement in handling non-uniform clusters. Additionally, the UN-MCCD and SUN-MCCD algorithms address the limitations of existing methods in high-dimensional spaces by utilizing Nearest Neighbor Distances (NND) for clustering and outlier detection. Our results indicate that these novel algorithms offer substantial advancements in the accuracy and adaptability of outlier detection, providing a valuable tool for various real-world applications.
  Keyword: Outlier detection, Graph-based clustering, Cluster catch digraphs, $k$-nearest-neighborhood, Mutual catch graphs, Nearest neighbor distance.
<div id='section'>Paperid: <span id='pid'>1307, <a href='https://arxiv.org/pdf/2409.11212.pdf' target='_blank'>https://arxiv.org/pdf/2409.11212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianing Wang, Yang Zhou, Xiaocheng Zhang, Mengjiao Bao, Peng Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11212">Self-Evolutionary Large Language Models through Uncertainty-Enhanced Preference Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iterative preference optimization has recently become one of the de-facto training paradigms for large language models (LLMs), but the performance is still underwhelming due to too much noisy preference data yielded in the loop. To combat this issue, we present an \textbf{U}ncertainty-enhanced \textbf{P}reference \textbf{O}ptimization (UPO) framework to make the LLM self-evolve with reliable feedback. The key idea is mitigating the noisy preference data derived from the current policy and reward models by performing pair-wise uncertainty estimation and judiciously reliable feedback sampling. To reach this goal, we thus introduce an estimator model, which incorporates Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the preference data derived from the LLM policy. Compared to the existing methods that directly filter generated responses based on the reward score, the estimator focuses on the model uncertainty in a pair-wise manner and effectively bypasses the confirmation bias problem of the reward model. Additionally, we also propose an uncertainty-enhanced self-evolution algorithm to improve the robustness of preference optimization and encourage the LLM to generate responses with both high reward and certainty. Extensive experiments over multiple benchmarks demonstrate that our framework substantially alleviates the noisy problem and improves the performance of iterative preference optimization.
<div id='section'>Paperid: <span id='pid'>1308, <a href='https://arxiv.org/pdf/2409.06593.pdf' target='_blank'>https://arxiv.org/pdf/2409.06593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hugo Gobato Souto, Francisco Louzada Neto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06593">Advancing Causal Inference: A Nonparametric Approach to ATE and CATE Estimation with Continuous Treatments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a generalized ps-BART model for the estimation of Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE) in continuous treatments, addressing limitations of the Bayesian Causal Forest (BCF) model. The ps-BART model's nonparametric nature allows for flexibility in capturing nonlinear relationships between treatment and outcome variables. Across three distinct sets of Data Generating Processes (DGPs), the ps-BART model consistently outperforms the BCF model, particularly in highly nonlinear settings. The ps-BART model's robustness in uncertainty estimation and accuracy in both point-wise and probabilistic estimation demonstrate its utility for real-world applications. This research fills a crucial gap in causal inference literature, providing a tool better suited for nonlinear treatment-outcome relationships and opening avenues for further exploration in the domain of continuous treatment effect estimation.
<div id='section'>Paperid: <span id='pid'>1309, <a href='https://arxiv.org/pdf/2409.06270.pdf' target='_blank'>https://arxiv.org/pdf/2409.06270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mulin Chen, Haojian Huang, Qiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06270">Towards Robust Uncertainty-Aware Incomplete Multi-View Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Handling incomplete data in multi-view classification is challenging, especially when traditional imputation methods introduce biases that compromise uncertainty estimation. Existing Evidential Deep Learning (EDL) based approaches attempt to address these issues, but they often struggle with conflicting evidence due to the limitations of the Dempster-Shafer combination rule, leading to unreliable decisions. To address these challenges, we propose the Alternating Progressive Learning Network (APLN), specifically designed to enhance EDL-based methods in incomplete MVC scenarios. Our approach mitigates bias from corrupted observed data by first applying coarse imputation, followed by mapping the data to a latent space. In this latent space, we progressively learn an evidence distribution aligned with the target domain, incorporating uncertainty considerations through EDL. Additionally, we introduce a conflict-aware Dempster-Shafer combination rule (DSCR) to better handle conflicting evidence. By sampling from the learned distribution, we optimize the latent representations of missing views, reducing bias and enhancing decision-making robustness. Extensive experiments demonstrate that APLN, combined with DSCR, significantly outperforms traditional methods, particularly in environments characterized by high uncertainty and conflicting evidence, establishing it as a promising solution for incomplete multi-view classification.
<div id='section'>Paperid: <span id='pid'>1310, <a href='https://arxiv.org/pdf/2409.02079.pdf' target='_blank'>https://arxiv.org/pdf/2409.02079.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alice Williams, Boris Kovalerchuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02079">Synthetic Data Generation and Automated Multidimensional Data Labeling for AI/ML in General and Circular Coordinates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Insufficient amounts of available training data is a critical challenge for both development and deployment of artificial intelligence and machine learning (AI/ML) models. This paper proposes a unified approach to both synthetic data generation (SDG) and automated data labeling (ADL) with a unified SDG-ADL algorithm. SDG-ADL uses multidimensional (n-D) representations of data visualized losslessly with General Line Coordinates (GLCs), relying on reversible GLC properties to visualize n-D data in multiple GLCs. This paper demonstrates use of the new Circular Coordinates in Static and Dynamic forms, used with Parallel Coordinates and Shifted Paired Coordinates, since each GLC exemplifies unique data properties, such as interattribute n-D distributions and outlier detection. The approach is interactively implemented in computer software with the Dynamic Coordinates Visualization system (DCVis). Results with real data are demonstrated in case studies, evaluating impact on classifiers.
<div id='section'>Paperid: <span id='pid'>1311, <a href='https://arxiv.org/pdf/2408.15874.pdf' target='_blank'>https://arxiv.org/pdf/2408.15874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philipp RÃ¶chner, Henrique O. Marques, Ricardo J. G. B. Campello, Arthur Zimek, Franz Rothlauf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15874">Robust Statistical Scaling of Outlier Scores: Improving the Quality of Outlier Probabilities for Outliers (Extended Version)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection algorithms typically assign an outlier score to each observation in a dataset, indicating the degree to which an observation is an outlier. However, these scores are often not comparable across algorithms and can be difficult for humans to interpret. Statistical scaling addresses this problem by transforming outlier scores into outlier probabilities without using ground-truth labels, thereby improving interpretability and comparability across algorithms. However, the quality of this transformation can be different for outliers and inliers. Missing outliers in scenarios where they are of particular interest - such as healthcare, finance, or engineering - can be costly or dangerous. Thus, ensuring good probabilities for outliers is essential. This paper argues that statistical scaling, as commonly used in the literature, does not produce equally good probabilities for outliers as for inliers. Therefore, we propose robust statistical scaling, which uses robust estimators to improve the probabilities for outliers. We evaluate several variants of our method against other outlier score transformations for real-world datasets and outlier detection algorithms, where it can improve the probabilities for outliers.
<div id='section'>Paperid: <span id='pid'>1312, <a href='https://arxiv.org/pdf/2408.10713.pdf' target='_blank'>https://arxiv.org/pdf/2408.10713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Padmanaba Srinivasan, William Knottenbelt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10713">Offline Model-Based Reinforcement Learning with Anti-Exploration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model-based reinforcement learning (MBRL) algorithms learn a dynamics model from collected data and apply it to generate synthetic trajectories to enable faster learning. This is an especially promising paradigm in offline reinforcement learning (RL) where data may be limited in quantity, in addition to being deficient in coverage and quality. Practical approaches to offline MBRL usually rely on ensembles of dynamics models to prevent exploitation of any individual model and to extract uncertainty estimates that penalize values in states far from the dataset support. Uncertainty estimates from ensembles can vary greatly in scale, making it challenging to generalize hyperparameters well across even similar tasks. In this paper, we present Morse Model-based offline RL (MoMo), which extends the anti-exploration paradigm found in offline model-free RL to the model-based space. We develop model-free and model-based variants of MoMo and show how the model-free version can be extended to detect and deal with out-of-distribution (OOD) states using explicit uncertainty estimation without the need for large ensembles. MoMo performs offline MBRL using an anti-exploration bonus to counteract value overestimation in combination with a policy constraint, as well as a truncation function to terminate synthetic rollouts that are excessively OOD. Experimentally, we find that both model-free and model-based MoMo perform well, and the latter outperforms prior model-based and model-free baselines on the majority of D4RL datasets tested.
<div id='section'>Paperid: <span id='pid'>1313, <a href='https://arxiv.org/pdf/2407.21273.pdf' target='_blank'>https://arxiv.org/pdf/2407.21273.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohini Banerjee, Cecilia G. Morales, Artur Dubrawski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21273">Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient intravascular access in trauma and critical care significantly impacts patient outcomes. However, the availability of skilled medical personnel in austere environments is often limited. Autonomous robotic ultrasound systems can aid in needle insertion for medication delivery and support non-experts in such tasks. Despite advances in autonomous needle insertion, inaccuracies in vessel segmentation predictions pose risks. Understanding the uncertainty of predictive models in ultrasound imaging is crucial for assessing their reliability. We introduce MSU-Net, a novel multistage approach for training an ensemble of U-Nets to yield accurate ultrasound image segmentation maps. We demonstrate substantial improvements, 18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model transparency, and trustworthiness. By highlighting areas of model certainty, MSU-Net can guide safe needle insertions, empowering non-experts to accomplish such tasks.
<div id='section'>Paperid: <span id='pid'>1314, <a href='https://arxiv.org/pdf/2407.13708.pdf' target='_blank'>https://arxiv.org/pdf/2407.13708.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ji-Hun Oh, Kianoush Falahkheirkhah, Rohit Bhargava
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13708">Are We Ready for Out-of-Distribution Detection in Digital Pathology?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of semantic and covariate out-of-distribution (OOD) examples is a critical yet overlooked challenge in digital pathology (DP). Recently, substantial insight and methods on OOD detection were presented by the ML community, but how do they fare in DP applications? To this end, we establish a benchmark study, our highlights being: 1) the adoption of proper evaluation protocols, 2) the comparison of diverse detectors in both a single and multi-model setting, and 3) the exploration into advanced ML settings like transfer learning (ImageNet vs. DP pre-training) and choice of architecture (CNNs vs. transformers). Through our comprehensive experiments, we contribute new insights and guidelines, paving the way for future research and discussion.
<div id='section'>Paperid: <span id='pid'>1315, <a href='https://arxiv.org/pdf/2407.13141.pdf' target='_blank'>https://arxiv.org/pdf/2407.13141.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aryan Gulati, Xingjian Dong, Carlos Hurtado, Sarath Shekkizhar, Swabha Swayamdipta, Antonio Ortega
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13141">Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As language models become more general purpose, increased attention needs to be paid to detecting out-of-distribution (OOD) instances, i.e., those not belonging to any of the distributions seen during training. Existing methods for detecting OOD data are computationally complex and storage-intensive. We propose a novel soft clustering approach for OOD detection based on non-negative kernel regression. Our approach greatly reduces computational and space complexities (up to 11x improvement in inference time and 87% reduction in storage requirements) and outperforms existing approaches by up to 4 AUROC points on four different benchmarks. We also introduce an entropy-constrained version of our algorithm, which leads to further reductions in storage requirements (up to 97% lower than comparable approaches) while retaining competitive performance. Our soft clustering approach for OOD detection highlights its potential for detecting tail-end phenomena in extreme-scale data settings.
<div id='section'>Paperid: <span id='pid'>1316, <a href='https://arxiv.org/pdf/2407.04760.pdf' target='_blank'>https://arxiv.org/pdf/2407.04760.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MZ Naser, Ahmed Z Naser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04760">SPINEX: Similarity-based Predictions with Explainable Neighbors Exploration for Anomaly and Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel anomaly and outlier detection algorithm from the SPINEX (Similarity-based Predictions with Explainable Neighbors Exploration) family. This algorithm leverages the concept of similarity and higher-order interactions across multiple subspaces to identify outliers. A comprehensive set of experiments was conducted to evaluate the performance of SPINEX. This algorithm was examined against 21 commonly used anomaly detection algorithms, namely, namely, Angle-Based Outlier Detection (ABOD), Connectivity-Based Outlier Factor (COF), Copula-Based Outlier Detection (COPOD), ECOD, Elliptic Envelope (EE), Feature Bagging with KNN, Gaussian Mixture Models (GMM), Histogram-based Outlier Score (HBOS), Isolation Forest (IF), Isolation Neural Network Ensemble (INNE), Kernel Density Estimation (KDE), K-Nearest Neighbors (KNN), Lightweight Online Detector of Anomalies (LODA), Linear Model Deviation-based Detector (LMDD), Local Outlier Factor (LOF), Minimum Covariance Determinant (MCD), One-Class SVM (OCSVM), Quadratic MCD (QMCD), Robust Covariance (RC), Stochastic Outlier Selection (SOS), and Subspace Outlier Detection (SOD), and across 39 synthetic and real datasets from various domains and of a variety of dimensions and complexities. Furthermore, a complexity analysis was carried out to examine the complexity of the proposed algorithm. Our results demonstrate that SPINEX achieves superior performance, outperforms commonly used anomaly detection algorithms, and has moderate complexity (e.g., O(n log n d)). More specifically, SPINEX was found to rank at the top of algorithms on the synthetic datasets and the 7th on the real datasets. Finally, a demonstration of the explainability capabilities of SPINEX, along with future research needs, is presented.
<div id='section'>Paperid: <span id='pid'>1317, <a href='https://arxiv.org/pdf/2407.04248.pdf' target='_blank'>https://arxiv.org/pdf/2407.04248.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhikun Zhang, Yiting Duan, Xiangjun Wang, Mingyuan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04248">Machine Learning for Complex Systems with Abnormal Pattern by Exception Maximization Outlier Detection Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a novel fast online methodology for outlier detection called the exception maximization outlier detection method(EMODM), which employs probabilistic models and statistical algorithms to detect abnormal patterns from the outputs of complex systems. The EMODM is based on a two-state Gaussian mixture model and demonstrates strong performance in probability anomaly detection working on real-time raw data rather than using special prior distribution information. We confirm this using the synthetic data from two numerical cases. For the real-world data, we have detected the short circuit pattern of the circuit system using EMODM by the current and voltage output of a three-phase inverter. The EMODM also found an abnormal period due to COVID-19 in the insured unemployment data of 53 regions in the United States from 2000 to 2024. The application of EMODM to these two real-life datasets demonstrated the effectiveness and accuracy of our algorithm.
<div id='section'>Paperid: <span id='pid'>1318, <a href='https://arxiv.org/pdf/2407.00616.pdf' target='_blank'>https://arxiv.org/pdf/2407.00616.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masoud Ataei, Vikas Dhiman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00616">DADEE: Well-calibrated uncertainty quantification in neural networks for barriers-based robot safety</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty-aware controllers that guarantee safety are critical for safety critical applications. Among such controllers, Control Barrier Functions (CBFs) based approaches are popular because they are fast, yet safe. However, most such works depend on Gaussian Processes (GPs) or MC-Dropout for learning and uncertainty estimation, and both approaches come with drawbacks: GPs are non-parametric methods that are slow, while MC-Dropout does not capture aleatoric uncertainty. On the other hand, modern Bayesian learning algorithms have shown promise in uncertainty quantification. The application of modern Bayesian learning methods to CBF-based controllers has not yet been studied. We aim to fill this gap by surveying uncertainty quantification algorithms and evaluating them on CBF-based safe controllers. We find that model variance-based algorithms (for example, Deep ensembles, MC-dropout, etc.) and direct estimation-based algorithms (such as DEUP) have complementary strengths. Algorithms in the former category can only estimate uncertainty accurately out-of-domain, while those in the latter category can only do so in-domain. We combine the two approaches to obtain more accurate uncertainty estimates both in- and out-of-domain. As measured by the failure rate of a simulated robot, this results in a safer CBF-based robot controller.
<div id='section'>Paperid: <span id='pid'>1319, <a href='https://arxiv.org/pdf/2406.12082.pdf' target='_blank'>https://arxiv.org/pdf/2406.12082.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anna Susmelj, Mael Macuglia, NataÅ¡a Tagasovska, Reto Sutter, Sebastiano Caprara, Jean-Philippe Thiran, Ender Konukoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12082">Uncertainty modeling for fine-tuned implicit functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Implicit functions such as Neural Radiance Fields (NeRFs), occupancy networks, and signed distance functions (SDFs) have become pivotal in computer vision for reconstructing detailed object shapes from sparse views. Achieving optimal performance with these models can be challenging due to the extreme sparsity of inputs and distribution shifts induced by data corruptions. To this end, large, noise-free synthetic datasets can serve as shape priors to help models fill in gaps, but the resulting reconstructions must be approached with caution. Uncertainty estimation is crucial for assessing the quality of these reconstructions, particularly in identifying areas where the model is uncertain about the parts it has inferred from the prior. In this paper, we introduce Dropsembles, a novel method for uncertainty estimation in tuned implicit functions. We demonstrate the efficacy of our approach through a series of experiments, starting with toy examples and progressing to a real-world scenario. Specifically, we train a Convolutional Occupancy Network on synthetic anatomical data and test it on low-resolution MRI segmentations of the lumbar spine. Our results show that Dropsembles achieve the accuracy and calibration levels of deep ensembles but with significantly less computational cost.
<div id='section'>Paperid: <span id='pid'>1320, <a href='https://arxiv.org/pdf/2406.10023.pdf' target='_blank'>https://arxiv.org/pdf/2406.10023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luckeciano C. Melo, Panagiotis Tigas, Alessandro Abate, Yarin Gal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10023">Deep Bayesian Active Learning for Preference Modeling in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Leveraging human preferences for steering the behavior of Large Language Models (LLMs) has demonstrated notable success in recent years. Nonetheless, data selection and labeling are still a bottleneck for these systems, particularly at large scale. Hence, selecting the most informative points for acquiring human feedback may considerably reduce the cost of preference labeling and unleash the further development of LLMs. Bayesian Active Learning provides a principled framework for addressing this challenge and has demonstrated remarkable success in diverse settings. However, previous attempts to employ it for Preference Modeling did not meet such expectations. In this work, we identify that naive epistemic uncertainty estimation leads to the acquisition of redundant samples. We address this by proposing the Bayesian Active Learner for Preference Modeling (BAL-PM), a novel stochastic acquisition policy that not only targets points of high epistemic uncertainty according to the preference model but also seeks to maximize the entropy of the acquired prompt distribution in the feature space spanned by the employed LLM. Notably, our experiments demonstrate that BAL-PM requires 33% to 68% fewer preference labels in two popular human preference datasets and exceeds previous stochastic Bayesian acquisition policies.
<div id='section'>Paperid: <span id='pid'>1321, <a href='https://arxiv.org/pdf/2406.09966.pdf' target='_blank'>https://arxiv.org/pdf/2406.09966.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Constantine Maganaris, Eftychios Protopapadakis, Nikolaos Doulamis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09966">Outlier detection in maritime environments using AIS data and deep recurrent architectures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A methodology based on deep recurrent models for maritime surveillance, over publicly available Automatic Identification System (AIS) data, is presented in this paper. The setup employs a deep Recurrent Neural Network (RNN)-based model, for encoding and reconstructing the observed ships' motion patterns. Our approach is based on a thresholding mechanism, over the calculated errors between observed and reconstructed motion patterns of maritime vessels. Specifically, a deep-learning framework, i.e. an encoder-decoder architecture, is trained using the observed motion patterns, enabling the models to learn and predict the expected trajectory, which will be compared to the effective ones. Our models, particularly the bidirectional GRU with recurrent dropouts, showcased superior performance in capturing the temporal dynamics of maritime data, illustrating the potential of deep learning to enhance maritime surveillance capabilities. Our work lays a solid foundation for future research in this domain, highlighting a path toward improved maritime safety through the innovative application of technology.
<div id='section'>Paperid: <span id='pid'>1322, <a href='https://arxiv.org/pdf/2406.03188.pdf' target='_blank'>https://arxiv.org/pdf/2406.03188.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qutub Syed, Michael Paulitsch, Korbinian Hagn, Neslihan Kose Cihangir, Kay-Ulrich Scholl, Fabian Oboril, Gereon Hinz, Alois Knoll
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03188">Situation Monitor: Diversity-Driven Zero-Shot Out-of-Distribution Detection using Budding Ensemble Architecture for Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Situation Monitor, a novel zero-shot Out-of-Distribution (OOD) detection approach for transformer-based object detection models to enhance reliability in safety-critical machine learning applications such as autonomous driving. The Situation Monitor utilizes the Diversity-based Budding Ensemble Architecture (DBEA) and increases the OOD performance by integrating a diversity loss into the training process on top of the budding ensemble architecture, detecting Far-OOD samples and minimizing false positives on Near-OOD samples. Moreover, utilizing the resulting DBEA increases the model's OOD performance and improves the calibration of confidence scores, particularly concerning the intersection over union of the detected objects. The DBEA model achieves these advancements with a 14% reduction in trainable parameters compared to the vanilla model. This signifies a substantial improvement in efficiency without compromising the model's ability to detect OOD instances and calibrate the confidence scores accurately.
<div id='section'>Paperid: <span id='pid'>1323, <a href='https://arxiv.org/pdf/2405.06424.pdf' target='_blank'>https://arxiv.org/pdf/2405.06424.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JoonHo Lee, Jae Oh Woo, Juree Seok, Parisa Hassanzadeh, Wooseok Jang, JuYoun Son, Sima Didari, Baruch Gutow, Heng Hao, Hankyu Moon, Wenjun Hu, Yeong-Dae Kwon, Taehee Lee, Seungjai Min
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06424">Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Assessing response quality to instructions in language models is vital but challenging due to the complexity of human language across different contexts. This complexity often results in ambiguous or inconsistent interpretations, making accurate assessment difficult. To address this issue, we propose a novel Uncertainty-aware Reward Model (URM) that introduces a robust uncertainty estimation for the quality of paired responses based on Bayesian approximation. Trained with preference datasets, our uncertainty-enabled proxy not only scores rewards for responses but also evaluates their inherent uncertainty. Empirical results demonstrate significant benefits of incorporating the proposed proxy into language model training. Our method boosts the instruction following capability of language models by refining data curation for training and improving policy optimization objectives, thereby surpassing existing methods by a large margin on benchmarks such as Vicuna and MT-bench. These findings highlight that our proposed approach substantially advances language model training and paves a new way of harnessing uncertainty within language models.
<div id='section'>Paperid: <span id='pid'>1324, <a href='https://arxiv.org/pdf/2404.11599.pdf' target='_blank'>https://arxiv.org/pdf/2404.11599.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>James Harrison, John Willes, Jasper Snoek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.11599">Variational Bayesian Last Layers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a deterministic variational formulation for training Bayesian last layer neural networks. This yields a sampling-free, single-pass model and loss that effectively improves uncertainty estimation. Our variational Bayesian last layer (VBLL) can be trained and evaluated with only quadratic complexity in last layer width, and is thus (nearly) computationally free to add to standard architectures. We experimentally investigate VBLLs, and show that they improve predictive accuracy, calibration, and out of distribution detection over baselines across both regression and classification. Finally, we investigate combining VBLL layers with variational Bayesian feature learning, yielding a lower variance collapsed variational inference method for Bayesian neural networks.
<div id='section'>Paperid: <span id='pid'>1325, <a href='https://arxiv.org/pdf/2404.10124.pdf' target='_blank'>https://arxiv.org/pdf/2404.10124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanjing Wang, Qiang Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10124">Epistemic Uncertainty Quantification For Pre-trained Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Epistemic uncertainty quantification (UQ) identifies where models lack knowledge. Traditional UQ methods, often based on Bayesian neural networks, are not suitable for pre-trained non-Bayesian models. Our study addresses quantifying epistemic uncertainty for any pre-trained model, which does not need the original training data or model modifications and can ensure broad applicability regardless of network architectures or training techniques. Specifically, we propose a gradient-based approach to assess epistemic uncertainty, analyzing the gradients of outputs relative to model parameters, and thereby indicating necessary model adjustments to accurately represent the inputs. We first explore theoretical guarantees of gradient-based methods for epistemic UQ, questioning the view that this uncertainty is only calculable through differences between multiple models. We further improve gradient-driven UQ by using class-specific weights for integrating gradients and emphasizing distinct contributions from neural network layers. Additionally, we enhance UQ accuracy by combining gradient and perturbation methods to refine the gradients. We evaluate our approach on out-of-distribution detection, uncertainty calibration, and active learning, demonstrating its superiority over current state-of-the-art UQ methods for pre-trained models.
<div id='section'>Paperid: <span id='pid'>1326, <a href='https://arxiv.org/pdf/2403.18539.pdf' target='_blank'>https://arxiv.org/pdf/2403.18539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taku Yamagata, Raul Santos-Rodriguez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18539">Safe and Robust Reinforcement Learning: Principles and Practice</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement Learning (RL) has shown remarkable success in solving relatively complex tasks, yet the deployment of RL systems in real-world scenarios poses significant challenges related to safety and robustness. This paper aims to identify and further understand those challenges thorough the exploration of the main dimensions of the safe and robust RL landscape, encompassing algorithmic, ethical, and practical considerations. We conduct a comprehensive review of methodologies and open problems that summarizes the efforts in recent years to address the inherent risks associated with RL applications.
  After discussing and proposing definitions for both safe and robust RL, the paper categorizes existing research works into different algorithmic approaches that enhance the safety and robustness of RL agents. We examine techniques such as uncertainty estimation, optimisation methodologies, exploration-exploitation trade-offs, and adversarial training. Environmental factors, including sim-to-real transfer and domain adaptation, are also scrutinized to understand how RL systems can adapt to diverse and dynamic surroundings. Moreover, human involvement is an integral ingredient of the analysis, acknowledging the broad set of roles that humans can take in this context.
  Importantly, to aid practitioners in navigating the complexities of safe and robust RL implementation, this paper introduces a practical checklist derived from the synthesized literature. The checklist encompasses critical aspects of algorithm design, training environment considerations, and ethical guidelines. It will serve as a resource for developers and policymakers alike to ensure the responsible deployment of RL systems in many application domains.
<div id='section'>Paperid: <span id='pid'>1327, <a href='https://arxiv.org/pdf/2403.18207.pdf' target='_blank'>https://arxiv.org/pdf/2403.18207.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chihiro Noguchi, Toshiaki Ohgushi, Masao Yamanaka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18207">Road Obstacle Detection based on Unknown Objectness Scores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of unknown traffic obstacles is vital to ensure safe autonomous driving. The standard object-detection methods cannot identify unknown objects that are not included under predefined categories. This is because object-detection methods are trained to assign a background label to pixels corresponding to the presence of unknown objects. To address this problem, the pixel-wise anomaly-detection approach has attracted increased research attention. Anomaly-detection techniques, such as uncertainty estimation and perceptual difference from reconstructed images, make it possible to identify pixels of unknown objects as out-of-distribution (OoD) samples. However, when applied to images with many unknowns and complex components, such as driving scenes, these methods often exhibit unstable performance. The purpose of this study is to achieve stable performance for detecting unknown objects by incorporating the object-detection fashions into the pixel-wise anomaly detection methods. To achieve this goal, we adopt a semantic-segmentation network with a sigmoid head that simultaneously provides pixel-wise anomaly scores and objectness scores. Our experimental results show that the objectness scores play an important role in improving the detection performance. Based on these results, we propose a novel anomaly score by integrating these two scores, which we term as unknown objectness score. Quantitative evaluations show that the proposed method outperforms state-of-the-art methods when applied to the publicly available datasets.
<div id='section'>Paperid: <span id='pid'>1328, <a href='https://arxiv.org/pdf/2403.14058.pdf' target='_blank'>https://arxiv.org/pdf/2403.14058.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yasith Jayawardana, Azeem Ahmad, Balpreet S. Ahluwalia, Rafi Ahmad, Sampath Jayarathna, Dushan N. Wadduwage
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14058">Hypothesis-Driven Deep Learning for Out of Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare. For such applications, it is crucial to assess how models handle samples beyond the domain of training data. While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use. In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD. Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses. We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothesis. We adapt our method to detect an unseen sample of bacteria to a trained deep learning model, and show that it reveals interpretable differences between InD and OoD latent responses. Our work has implications for systematic novelty detection and informed decision-making from classifiers trained on a subset of labels.
<div id='section'>Paperid: <span id='pid'>1329, <a href='https://arxiv.org/pdf/2403.09141.pdf' target='_blank'>https://arxiv.org/pdf/2403.09141.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gleb Radchenko, Victoria Andrea Fill
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.09141">Uncertainty Estimation in Multi-Agent Distributed Learning for AI-Enabled Edge Devices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Initially considered as low-power units with limited autonomous processing, Edge IoT devices have seen a paradigm shift with the introduction of FPGAs and AI accelerators. This advancement has vastly amplified their computational capabilities, emphasizing the practicality of edge AI. Such progress introduces new challenges of optimizing AI tasks for the limitations of energy and network resources typical in Edge computing environments. Our study explores methods that enable distributed data processing through AI-enabled edge devices, enhancing collaborative learning capabilities. A key focus of our research is the challenge of determining confidence levels in learning outcomes, considering the spatial and temporal variability of data sets encountered by independent agents. To address this issue, we investigate the application of Bayesian neural networks, proposing a novel approach to manage uncertainty in distributed learning environments.
<div id='section'>Paperid: <span id='pid'>1330, <a href='https://arxiv.org/pdf/2402.14080.pdf' target='_blank'>https://arxiv.org/pdf/2402.14080.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Nolte, Souparno Ghosh, Ranadip Pal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14080">Efficient Normalized Conformal Prediction and Uncertainty Quantification for Anti-Cancer Drug Sensitivity Prediction with Deep Regression Forests</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models are being adopted and applied on various critical decision-making tasks, yet they are trained to provide point predictions without providing degrees of confidence. The trustworthiness of deep learning models can be increased if paired with uncertainty estimations. Conformal Prediction has emerged as a promising method to pair machine learning models with prediction intervals, allowing for a view of the model's uncertainty. However, popular uncertainty estimation methods for conformal prediction fail to provide heteroskedastic intervals that are equally accurate for all samples. In this paper, we propose a method to estimate the uncertainty of each sample by calculating the variance obtained from a Deep Regression Forest. We show that the deep regression forest variance improves the efficiency and coverage of normalized inductive conformal prediction on a drug response prediction task.
<div id='section'>Paperid: <span id='pid'>1331, <a href='https://arxiv.org/pdf/2402.08088.pdf' target='_blank'>https://arxiv.org/pdf/2402.08088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ghada Zamzmi, Kesavan Venkatesh, Brandon Nelson, Smriti Prathapan, Paul H. Yi, Berkman Sahiner, Jana G. Delfino
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08088">Out-of-Distribution Detection and Data Drift Monitoring using Statistical Process Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Machine learning (ML) methods often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices in clinical settings, where data drift may cause unexpected performance that jeopardizes patient safety.
  Method: We propose a ML-enabled Statistical Process Control (SPC) framework for out-of-distribution (OOD) detection and drift monitoring. SPC is advantageous as it visually and statistically highlights deviations from the expected distribution. To demonstrate the utility of the proposed framework for monitoring data drift in radiological images, we investigated different design choices, including methods for extracting feature representations, drift quantification, and SPC parameter selection.
  Results: We demonstrate the effectiveness of our framework for two tasks: 1) differentiating axial vs. non-axial computed tomography (CT) images and 2) separating chest x-ray (CXR) from other modalities. For both tasks, we achieved high accuracy in detecting OOD inputs, with 0.913 in CT and 0.995 in CXR, and sensitivity of 0.980 in CT and 0.984 in CXR. Our framework was also adept at monitoring data streams and identifying the time a drift occurred. In a simulation with 100 daily CXR cases, we detected a drift in OOD input percentage from 0-1% to 3-5% within two days, maintaining a low false-positive rate. Through additional experimental results, we demonstrate the framework's data-agnostic nature and independence from the underlying model's structure.
  Conclusion: We propose a framework for OOD detection and drift monitoring that is agnostic to data, modality, and model. The framework is customizable and can be adapted for specific applications.
<div id='section'>Paperid: <span id='pid'>1332, <a href='https://arxiv.org/pdf/2402.07281.pdf' target='_blank'>https://arxiv.org/pdf/2402.07281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shanay Mehta, Shlok Mehendale, Nicole Fernandes, Jyotirmoy Sarkar, Santonu Sarkar, Snehanshu Saha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07281">Benchmarking Anomaly Detection Algorithms: Deep Learning and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detection of anomalous situations for complex mission-critical systems hold paramount importance when their service continuity needs to be ensured. A major challenge in detecting anomalies from the operational data arises due to the imbalanced class distribution problem since the anomalies are supposed to be rare events. This paper evaluates a diverse array of Machine Learning (ML)-based anomaly detection algorithms through a comprehensive benchmark study. The paper contributes significantly by conducting an unbiased comparison of various anomaly detection algorithms, spanning classical ML, including various tree-based approaches to Deep Learning (DL) and outlier detection methods. The inclusion of 104 publicly available enhances the diversity of the study, allowing a more realistic evaluation of algorithm performance and emphasizing the importance of adaptability to real-world scenarios.
  The paper evaluates the general notion of DL as a universal solution, showing that, while powerful, it is not always the best fit for every scenario. The findings reveal that recently proposed tree-based evolutionary algorithms match DL methods and sometimes outperform them in many instances of univariate data where the size of the data is small and number of anomalies are less than 10%. Specifically, tree-based approaches successfully detect singleton anomalies in datasets where DL falls short. To the best of the authors' knowledge, such a study on a large number of state-of-the-art algorithms using diverse data sets, with the objective of guiding researchers and practitioners in making informed algorithmic choices, has not been attempted earlier.
<div id='section'>Paperid: <span id='pid'>1333, <a href='https://arxiv.org/pdf/2402.03478.pdf' target='_blank'>https://arxiv.org/pdf/2402.03478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew A. Chan, Maria J. Molina, Christopher A. Metzler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03478">Estimating Epistemic and Aleatoric Uncertainty with a Single Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating and disentangling epistemic uncertainty, uncertainty that is reducible with more training data, and aleatoric uncertainty, uncertainty that is inherent to the task at hand, is critically important when applying machine learning to high-stakes applications such as medical imaging and weather forecasting. Conditional diffusion models' breakthrough ability to accurately and efficiently sample from the posterior distribution of a dataset now makes uncertainty estimation conceptually straightforward: One need only train and sample from a large ensemble of diffusion models. Unfortunately, training such an ensemble becomes computationally intractable as the complexity of the model architecture grows. In this work we introduce a new approach to ensembling, hyper-diffusion models (HyperDM), which allows one to accurately estimate both epistemic and aleatoric uncertainty with a single model. Unlike existing single-model uncertainty methods like Monte-Carlo dropout and Bayesian neural networks, HyperDM offers prediction accuracy on par with, and in some cases superior to, multi-model ensembles. Furthermore, our proposed approach scales to modern network architectures such as Attention U-Net and yields more accurate uncertainty estimates compared to existing methods. We validate our method on two distinct real-world tasks: x-ray computed tomography reconstruction and weather temperature forecasting.
<div id='section'>Paperid: <span id='pid'>1334, <a href='https://arxiv.org/pdf/2401.12129.pdf' target='_blank'>https://arxiv.org/pdf/2401.12129.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Will LeVine, Benjamin Pikus, Jacob Phillips, Berk Norman, Fernando Amat Gil, Sean Hendryx
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.12129">Out-of-Distribution Detection & Applications With Ablated Learned Temperature Energy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As deep neural networks become adopted in high-stakes domains, it is crucial to identify when inference inputs are Out-of-Distribution (OOD) so that users can be alerted of likely drops in performance and calibration despite high confidence -- ultimately to know when networks' decisions (and their uncertainty in those decisions) should be trusted. In this paper we introduce Ablated Learned Temperature Energy (or "AbeT" for short), an OOD detection method which lowers the False Positive Rate at 95\% True Positive Rate (FPR@95) by $43.43\%$ in classification compared to state of the art without training networks in multiple stages or requiring hyperparameters or test-time backward passes. We additionally provide empirical insights as to why our model learns to distinguish between In-Distribution (ID) and OOD samples while only being explicitly trained on ID samples via exposure to misclassified ID examples at training time. Lastly, we show the efficacy of our method in identifying predicted bounding boxes and pixels corresponding to OOD objects in object detection and semantic segmentation, respectively -- with an AUROC increase of $5.15\%$ in object detection and both a decrease in FPR@95 of $41.48\%$ and an increase in AUPRC of $34.20\%$ in semantic segmentation compared to previous state of the art.
<div id='section'>Paperid: <span id='pid'>1335, <a href='https://arxiv.org/pdf/2401.10288.pdf' target='_blank'>https://arxiv.org/pdf/2401.10288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunju Kim, Dongman Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.10288">Self-supervised New Activity Detection in Sensor-based Smart Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rapid advancement of ubiquitous computing technology, human activity analysis based on time series data from a diverse range of sensors enables the delivery of more intelligent services. Despite the importance of exploring new activities in real-world scenarios, existing human activity recognition studies generally rely on predefined known activities and often overlook detecting new patterns (novelties) that have not been previously observed during training. Novelty detection in human activities becomes even more challenging due to (1) diversity of patterns within the same known activity, (2) shared patterns between known and new activities, and (3) differences in sensor properties of each activity dataset. We introduce CLAN, a two-tower model that leverages Contrastive Learning with diverse data Augmentation for New activity detection in sensor-based environments. CLAN simultaneously and explicitly utilizes multiple types of strongly shifted data as negative samples in contrastive learning, effectively learning invariant representations that adapt to various pattern variations within the same activity. To enhance the ability to distinguish between known and new activities that share common features, CLAN incorporates both time and frequency domains, enabling the learning of multi-faceted discriminative representations. Additionally, we design an automatic selection mechanism of data augmentation methods tailored to each dataset's properties, generating appropriate positive and negative pairs for contrastive learning. Comprehensive experiments on real-world datasets show that CLAN achieves a 9.24% improvement in AUROC compared to the best-performing baseline model.
<div id='section'>Paperid: <span id='pid'>1336, <a href='https://arxiv.org/pdf/2312.15086.pdf' target='_blank'>https://arxiv.org/pdf/2312.15086.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikhil Mehta, Kevin J Liang, Jing Huang, Fu-Jen Chu, Li Yin, Tal Hassner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.15086">HyperMix: Out-of-Distribution Detection and Classification in Few-Shot Settings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is an important topic for real-world machine learning systems, but settings with limited in-distribution samples have been underexplored. Such few-shot OOD settings are challenging, as models have scarce opportunities to learn the data distribution before being tasked with identifying OOD samples. Indeed, we demonstrate that recent state-of-the-art OOD methods fail to outperform simple baselines in the few-shot setting. We thus propose a hypernetwork framework called HyperMix, using Mixup on the generated classifier parameters, as well as a natural out-of-episode outlier exposure technique that does not require an additional outlier dataset. We conduct experiments on CIFAR-FS and MiniImageNet, significantly outperforming other OOD methods in the few-shot regime.
<div id='section'>Paperid: <span id='pid'>1337, <a href='https://arxiv.org/pdf/2312.14027.pdf' target='_blank'>https://arxiv.org/pdf/2312.14027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Bieringer, Gregor Kasieczka, Maximilian F. Steffen, Mathias Trabs
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.14027">AdamMCMC: Combining Metropolis Adjusted Langevin with Momentum-based Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a key issue when considering the application of deep neural network methods in science and engineering. In this work, we introduce a novel algorithm that quantifies epistemic uncertainty via Monte Carlo sampling from a tempered posterior distribution. It combines the well established Metropolis Adjusted Langevin Algorithm (MALA) with momentum-based optimization using Adam and leverages a prolate proposal distribution, to efficiently draw from the posterior. We prove that the constructed chain admits the Gibbs posterior as invariant distribution and approximates this posterior in total variation distance. Furthermore, we demonstrate the efficiency of the resulting algorithm and the merit of the proposed changes on a state-of-the-art classifier from high-energy particle physics.
<div id='section'>Paperid: <span id='pid'>1338, <a href='https://arxiv.org/pdf/2312.10992.pdf' target='_blank'>https://arxiv.org/pdf/2312.10992.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zahra Ghasemi, Mehdi Neshat, Chris Aldrich, John Karageorgos, Max Zanin, Frank Neumann, Lei Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10992">A Hybrid Intelligent Framework for Maximising SAG Mill Throughput: An Integration of Expert Knowledge, Machine Learning and Evolutionary Algorithms for Parameter Optimisation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In mineral processing plants, grinding is a crucial step, accounting for approximately 50 percent of the total mineral processing costs. Semi-autogenous grinding mills are extensively employed in the grinding circuit of mineral processing plants. Maximizing SAG mill throughput is of significant importance considering its profound financial outcomes. However, the optimum process parameter setting aimed at achieving maximum mill throughput remains an uninvestigated domain in prior research. This study introduces a hybrid intelligent framework leveraging expert knowledge, machine learning techniques, and evolutionary algorithms to address this research need. In this study, we utilize an extensive industrial dataset comprising 36743 records and select relevant features based on the insights of industry experts. Following the removal of erroneous data, a comprehensive evaluation of 17 diverse machine learning models is undertaken to identify the most accurate predictive model. To improve the model performance, feature selection and outlier detection are executed. The resultant optimal model, trained with refined features, serves as the objective function within three distinct evolutionary algorithms. These algorithms are employed to identify parameter configurations that maximize SAG mill throughput while adhering to the working limits of input parameters as constraints. Notably, our analysis revealed that CatBoost, as an ensemble model, stands out as the most accurate predictor. Furthermore, differential evolution emerges as the preferred optimization algorithm, exhibiting superior performance in both achieving the highest mill throughput predictions and ensuring robustness in predictions, surpassing alternative methods.
<div id='section'>Paperid: <span id='pid'>1339, <a href='https://arxiv.org/pdf/2312.10817.pdf' target='_blank'>https://arxiv.org/pdf/2312.10817.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Na Li, Yiyang Qi, Ruyue Xin, Zhiming Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10817">Ocean Data Quality Assessment through Outlier Detection-enhanced Active Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ocean and climate research benefits from global ocean observation initiatives such as Argo, GLOSS, and EMSO. The Argo network, dedicated to ocean profiling, generates a vast volume of observatory data. However, data quality issues from sensor malfunctions and transmission errors necessitate stringent quality assessment. Existing methods, including machine learning, fall short due to limited labeled data and imbalanced datasets. To address these challenges, we propose an ODEAL framework for ocean data quality assessment, employing AL to reduce human experts' workload in the quality assessment workflow and leveraging outlier detection algorithms for effective model initialization. We also conduct extensive experiments on five large-scale realistic Argo datasets to gain insights into our proposed method, including the effectiveness of AL query strategies and the initial set construction approach. The results suggest that our framework enhances quality assessment efficiency by up to 465.5% with the uncertainty-based query strategy compared to random sampling and minimizes overall annotation costs by up to 76.9% using the initial set built with outlier detectors.
<div id='section'>Paperid: <span id='pid'>1340, <a href='https://arxiv.org/pdf/2312.10464.pdf' target='_blank'>https://arxiv.org/pdf/2312.10464.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maksim Zhdanov, Stanislav Dereka, Sergey Kolesnikov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10464">Identity Curvature Laplace Approximation for Improved Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial in safety-critical applications, where robust out-of-distribution (OOD) detection is essential. Traditional Bayesian methods, though effective, are often hindered by high computational demands. As an alternative, Laplace approximation offers a more practical and efficient approach to uncertainty estimation. In this paper, we introduce the Identity Curvature Laplace Approximation (ICLA), a novel method that challenges the conventional posterior covariance formulation by using identity curvature and optimizing prior precision. This innovative design significantly enhances OOD detection performance on well-known datasets such as CIFAR-10, CIFAR-100, and ImageNet, while maintaining calibration scores. We attribute this improvement to the alignment issues between typical feature embeddings and curvature as measured by the Fisher information matrix. Our findings are further supported by demonstrating that incorporating Fisher penalty or sharpness-aware minimization techniques can greatly enhance the uncertainty estimation capabilities of standard Laplace approximation.
<div id='section'>Paperid: <span id='pid'>1341, <a href='https://arxiv.org/pdf/2312.09780.pdf' target='_blank'>https://arxiv.org/pdf/2312.09780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benno Buschmann, Andreea Dogaru, Elmar Eisemann, Michael Weinmann, Bernhard Egger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09780">RANRAC: Robust Neural Scene Representations via Random Ray Consensus</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning-based scene representations such as neural radiance fields or light field networks, that rely on fitting a scene model to image observations, commonly encounter challenges in the presence of inconsistencies within the images caused by occlusions, inaccurately estimated camera parameters or effects like lens flare. To address this challenge, we introduce RANdom RAy Consensus (RANRAC), an efficient approach to eliminate the effect of inconsistent data, thereby taking inspiration from classical RANSAC based outlier detection for model fitting. In contrast to the down-weighting of the effect of outliers based on robust loss formulations, our approach reliably detects and excludes inconsistent perspectives, resulting in clean images without floating artifacts. For this purpose, we formulate a fuzzy adaption of the RANSAC paradigm, enabling its application to large scale models. We interpret the minimal number of samples to determine the model parameters as a tunable hyperparameter, investigate the generation of hypotheses with data-driven models, and analyze the validation of hypotheses in noisy environments. We demonstrate the compatibility and potential of our solution for both photo-realistic robust multi-view reconstruction from real-world images based on neural radiance fields and for single-shot reconstruction based on light-field networks. In particular, the results indicate significant improvements compared to state-of-the-art robust methods for novel-view synthesis on both synthetic and captured scenes with various inconsistencies including occlusions, noisy camera pose estimates, and unfocused perspectives. The results further indicate significant improvements for single-shot reconstruction from occluded images. Project Page: https://bennobuschmann.com/ranrac/
<div id='section'>Paperid: <span id='pid'>1342, <a href='https://arxiv.org/pdf/2312.03024.pdf' target='_blank'>https://arxiv.org/pdf/2312.03024.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nima Rahmanian, Michael Gupta, Renzo Soatto, Srisai Nachuri, Michael Psenka, Yi Ma, S. Shankar Sastry
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03024">Role of Uncertainty in Anticipatory Trajectory Prediction for a Ping-Pong Playing Robot</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robotic interaction in fast-paced environments presents a substantial challenge, particularly in tasks requiring the prediction of dynamic, non-stationary objects for timely and accurate responses. An example of such a task is ping-pong, where the physical limitations of a robot may prevent it from reaching its goal in the time it takes the ball to cross the table. The scene of a ping-pong match contains rich visual information of a player's movement that can allow future game state prediction, with varying degrees of uncertainty. To this aim, we present a visual modeling, prediction, and control system to inform a ping-pong playing robot utilizing visual model uncertainty to allow earlier motion of the robot throughout the game. We present demonstrations and metrics in simulation to show the benefit of incorporating model uncertainty, the limitations of current standard model uncertainty estimators, and the need for more verifiable model uncertainty estimation. Our code is publicly available.
<div id='section'>Paperid: <span id='pid'>1343, <a href='https://arxiv.org/pdf/2311.18645.pdf' target='_blank'>https://arxiv.org/pdf/2311.18645.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Franciskus Xaverius Erick, Mina Rezaei, Johanna Paula MÃ¼ller, Bernhard Kainz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18645">Stochastic Vision Transformers with Wasserstein Distance-Aware Attention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning is one of the most promising approaches to acquiring knowledge from limited labeled data. Despite the substantial advancements made in recent years, self-supervised models have posed a challenge to practitioners, as they do not readily provide insight into the model's confidence and uncertainty. Tackling this issue is no simple feat, primarily due to the complexity involved in implementing techniques that can make use of the latent representations learned during pre-training without relying on explicit labels. Motivated by this, we introduce a new stochastic vision transformer that integrates uncertainty and distance awareness into self-supervised learning (SSL) pipelines. Instead of the conventional deterministic vector embedding, our novel stochastic vision transformer encodes image patches into elliptical Gaussian distributional embeddings. Notably, the attention matrices of these stochastic representational embeddings are computed using Wasserstein distance-based attention, effectively capitalizing on the distributional nature of these embeddings. Additionally, we propose a regularization term based on Wasserstein distance for both pre-training and fine-tuning processes, thereby incorporating distance awareness into latent representations. We perform extensive experiments across different tasks such as in-distribution generalization, out-of-distribution detection, dataset corruption, semi-supervised settings, and transfer learning to other datasets and tasks. Our proposed method achieves superior accuracy and calibration, surpassing the self-supervised baseline in a wide range of experiments on a variety of datasets.
<div id='section'>Paperid: <span id='pid'>1344, <a href='https://arxiv.org/pdf/2311.17852.pdf' target='_blank'>https://arxiv.org/pdf/2311.17852.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruixuan Wang, Sabrina Hassan Moon, Xiaobo Sharon Hu, Xun Jiao, Dayane Reis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.17852">A Computing-in-Memory-based One-Class Hyperdimensional Computing Model for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present ODHD, an algorithm for outlier detection based on hyperdimensional computing (HDC), a non-classical learning paradigm. Along with the HDC-based algorithm, we propose IM-ODHD, a computing-in-memory (CiM) implementation based on hardware/software (HW/SW) codesign for improved latency and energy efficiency. The training and testing phases of ODHD may be performed with conventional CPU/GPU hardware or our IM-ODHD, SRAM-based CiM architecture using the proposed HW/SW codesign techniques. We evaluate the performance of ODHD on six datasets from different application domains using three metrics, namely accuracy, F1 score, and ROC-AUC, and compare it with multiple baseline methods such as OCSVM, isolation forest, and autoencoder. The experimental results indicate that ODHD outperforms all the baseline methods in terms of these three metrics on every dataset for both CPU/GPU and CiM implementations. Furthermore, we perform an extensive design space exploration to demonstrate the tradeoff between delay, energy efficiency, and performance of ODHD. We demonstrate that the HW/SW codesign implementation of the outlier detection on IM-ODHD is able to outperform the GPU-based implementation of ODHD by at least 331.5x/889x in terms of training/testing latency (and on average 14.0x/36.9x in terms of training/testing energy consumption.
<div id='section'>Paperid: <span id='pid'>1345, <a href='https://arxiv.org/pdf/2311.16185.pdf' target='_blank'>https://arxiv.org/pdf/2311.16185.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuetian Chen, Mei Si
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16185">Enhancing Sentiment Analysis Results through Outlier Detection Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When dealing with text data containing subjective labels like speaker emotions, inaccuracies or discrepancies among labelers are not uncommon. Such discrepancies can significantly affect the performance of machine learning algorithms. This study investigates the potential of identifying and addressing outliers in text data with subjective labels, aiming to enhance classification outcomes. We utilized the Deep SVDD algorithm, a one-class classification method, to detect outliers in nine text-based emotion and sentiment analysis datasets. By employing both a small-sized language model (DistilBERT base model with 66 million parameters) and non-deep learning machine learning algorithms (decision tree, KNN, Logistic Regression, and LDA) as the classifier, our findings suggest that the removal of outliers can lead to enhanced results in most cases. Additionally, as outliers in such datasets are not necessarily unlearnable, we experienced utilizing a large language model -- DeBERTa v3 large with 131 million parameters, which can capture very complex patterns in data. We continued to observe performance enhancements across multiple datasets.
<div id='section'>Paperid: <span id='pid'>1346, <a href='https://arxiv.org/pdf/2311.13356.pdf' target='_blank'>https://arxiv.org/pdf/2311.13356.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gleb Radchenko, Victoria Andrea Fill
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13356">Uncertainty Estimation in Multi-Agent Distributed Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditionally, IoT edge devices have been perceived primarily as low-power components with limited capabilities for autonomous operations. Yet, with emerging advancements in embedded AI hardware design, a foundational shift paves the way for future possibilities. Thus, the aim of the KDT NEUROKIT2E project is to establish a new open-source framework to further facilitate AI applications on edge devices by developing new methods in quantization, pruning-aware training, and sparsification. These innovations hold the potential to expand the functional range of such devices considerably, enabling them to manage complex Machine Learning (ML) tasks utilizing local resources and laying the groundwork for innovative learning approaches.
  In the context of 6G's transformative potential, distributed learning among independent agents emerges as a pivotal application, attributed to 6G networks' support for ultra-reliable low-latency communication, enhanced data rates, and advanced edge computing capabilities.
  Our research focuses on the mechanisms and methodologies that allow edge network-enabled agents to engage in collaborative learning in distributed environments. Particularly, one of the key issues within distributed collaborative learning is determining the degree of confidence in the learning results, considering the spatio-temporal locality of data sets perceived by independent agents.
<div id='section'>Paperid: <span id='pid'>1347, <a href='https://arxiv.org/pdf/2311.11057.pdf' target='_blank'>https://arxiv.org/pdf/2311.11057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Diana Koldasbayeva, Polina Tregubova, Mikhail Gasanov, Alexey Zaytsev, Anna Petrovskaia, Evgeny Burnaev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.11057">Challenges in data-based geospatial modeling for environmental research and practice</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rise of electronic data, particularly Earth observation data, data-based geospatial modelling using machine learning (ML) has gained popularity in environmental research. Accurate geospatial predictions are vital for domain research based on ecosystem monitoring and quality assessment and for policy-making and action planning, considering effective management of natural resources. The accuracy and computation speed of ML has generally proved efficient. However, many questions have yet to be addressed to obtain precise and reproducible results suitable for further use in both research and practice. A better understanding of the ML concepts applicable to geospatial problems enhances the development of data science tools providing transparent information crucial for making decisions on global challenges such as biosphere degradation and climate change. This survey reviews common nuances in geospatial modelling, such as imbalanced data, spatial autocorrelation, prediction errors, model generalisation, domain specificity, and uncertainty estimation. We provide an overview of techniques and popular programming tools to overcome or account for the challenges. We also discuss prospects for geospatial Artificial Intelligence in environmental applications.
<div id='section'>Paperid: <span id='pid'>1348, <a href='https://arxiv.org/pdf/2311.10919.pdf' target='_blank'>https://arxiv.org/pdf/2311.10919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huayu Li, Gregory Ditzler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.10919">PACOL: Poisoning Attacks Against Continual Learners</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual learning algorithms are typically exposed to untrusted sources that contain training data inserted by adversaries and bad actors. An adversary can insert a small number of poisoned samples, such as mislabeled samples from previously learned tasks, or intentional adversarial perturbed samples, into the training datasets, which can drastically reduce the model's performance. In this work, we demonstrate that continual learning systems can be manipulated by malicious misinformation and present a new category of data poisoning attacks specific for continual learners, which we refer to as {\em Poisoning Attacks Against Continual Learners} (PACOL). The effectiveness of labeling flipping attacks inspires PACOL; however, PACOL produces attack samples that do not change the sample's label and produce an attack that causes catastrophic forgetting. A comprehensive set of experiments shows the vulnerability of commonly used generative replay and regularization-based continual learning approaches against attack methods. We evaluate the ability of label-flipping and a new adversarial poison attack, namely PACOL proposed in this work, to force the continual learning system to forget the knowledge of a learned task(s). More specifically, we compared the performance degradation of continual learning systems trained on benchmark data streams with and without poisoning attacks. Moreover, we discuss the stealthiness of the attacks in which we test the success rate of data sanitization defense and other outlier detection-based defenses for filtering out adversarial samples.
<div id='section'>Paperid: <span id='pid'>1349, <a href='https://arxiv.org/pdf/2311.07578.pdf' target='_blank'>https://arxiv.org/pdf/2311.07578.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meghna Gummadi, Cassandra Kent, Karl Schmeckpeper, Eric Eaton
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.07578">A Metacognitive Approach to Out-of-Distribution Detection for Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite outstanding semantic scene segmentation in closed-worlds, deep neural networks segment novel instances poorly, which is required for autonomous agents acting in an open world. To improve out-of-distribution (OOD) detection for segmentation, we introduce a metacognitive approach in the form of a lightweight module that leverages entropy measures, segmentation predictions, and spatial context to characterize the segmentation model's uncertainty and detect pixel-wise OOD data in real-time. Additionally, our approach incorporates a novel method of generating synthetic OOD data in context with in-distribution data, which we use to fine-tune existing segmentation models with maximum entropy training. This further improves the metacognitive module's performance without requiring access to OOD data while enabling compatibility with established pre-trained models. Our resulting approach can reliably detect OOD instances in a scene, as shown by state-of-the-art performance on OOD detection for semantic segmentation benchmarks.
<div id='section'>Paperid: <span id='pid'>1350, <a href='https://arxiv.org/pdf/2311.04258.pdf' target='_blank'>https://arxiv.org/pdf/2311.04258.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>D. Dhinakaran, S. Gopalakrishnan, M. D. Manigandan, T. P. Anish
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04258">IoT-Based Environmental Control System for Fish Farms with Sensor Integration and Machine Learning Decision Support</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In response to the burgeoning global demand for seafood and the challenges of managing fish farms, we introduce an innovative IoT based environmental control system that integrates sensor technology and advanced machine learning decision support. Deploying a network of wireless sensors within the fish farm, we continuously collect real-time data on crucial environmental parameters, including water temperature, pH levels, humidity, and fish behavior. This data undergoes meticulous preprocessing to ensure its reliability, including imputation, outlier detection, feature engineering, and synchronization. At the heart of our system are four distinct machine learning algorithms: Random Forests predict and optimize water temperature and pH levels for the fish, fostering their health and growth; Support Vector Machines (SVMs) function as an early warning system, promptly detecting diseases and parasites in fish; Gradient Boosting Machines (GBMs) dynamically fine-tune the feeding schedule based on real-time environmental conditions, promoting resource efficiency and fish productivity; Neural Networks manage the operation of critical equipment like water pumps and heaters to maintain the desired environmental conditions within the farm. These machine learning algorithms collaboratively make real-time decisions to ensure that the fish farm's environmental conditions align with predefined specifications, leading to improved fish health and productivity while simultaneously reducing resource wastage, thereby contributing to increased profitability and sustainability. This research article showcases the power of data-driven decision support in fish farming, promising to meet the growing demand for seafood while emphasizing environmental responsibility and economic viability, thus revolutionizing the future of fish farming.
<div id='section'>Paperid: <span id='pid'>1351, <a href='https://arxiv.org/pdf/2310.08654.pdf' target='_blank'>https://arxiv.org/pdf/2310.08654.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Evi M. C. Huijben, Sina Amirrajab, Josien P. W. Pluim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08654">Histogram- and Diffusion-Based Medical Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for the safety and reliability of artificial intelligence algorithms, especially in the medical domain. In the context of the Medical OOD (MOOD) detection challenge 2023, we propose a pipeline that combines a histogram-based method and a diffusion-based method. The histogram-based method is designed to accurately detect homogeneous anomalies in the toy examples of the challenge, such as blobs with constant intensity values. The diffusion-based method is based on one of the latest methods for unsupervised anomaly detection, called DDPM-OOD. We explore this method and propose extensive post-processing steps for pixel-level and sample-level anomaly detection on brain MRI and abdominal CT data provided by the challenge. Our results show that the proposed DDPM method is sensitive to blur and bias field samples, but faces challenges with anatomical deformation, black slice, and swapped patches. These findings suggest that further research is needed to improve the performance of DDPM for OOD detection in medical images.
<div id='section'>Paperid: <span id='pid'>1352, <a href='https://arxiv.org/pdf/2310.07998.pdf' target='_blank'>https://arxiv.org/pdf/2310.07998.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tinghui Ouyang, Isao Echizen, Yoshiki Seo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07998">A Novel Statistical Measure for Out-of-Distribution Detection in Data Quality Assurance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data outside the problem domain poses significant threats to the security of AI-based intelligent systems. Aiming to investigate the data domain and out-of-distribution (OOD) data in AI quality management (AIQM) study, this paper proposes to use deep learning techniques for feature representation and develop a novel statistical measure for OOD detection. First, to extract low-dimensional representative features distinguishing normal and OOD data, the proposed research combines the deep auto-encoder (AE) architecture and neuron activation status for feature engineering. Then, using local conditional probability (LCP) in data reconstruction, a novel and superior statistical measure is developed to calculate the score of OOD detection. Experiments and evaluations are conducted on image benchmark datasets and an industrial dataset. Through comparative analysis with other common statistical measures in OOD detection, the proposed research is validated as feasible and effective in OOD and AIQM studies.
<div id='section'>Paperid: <span id='pid'>1353, <a href='https://arxiv.org/pdf/2310.04686.pdf' target='_blank'>https://arxiv.org/pdf/2310.04686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammadreza M. Kalan, Samory Kpotufe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04686">Tight Rates in Supervised Outlier Transfer Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A critical barrier to learning an accurate decision rule for outlier detection is the scarcity of outlier data. As such, practitioners often turn to the use of similar but imperfect outlier data from which they might transfer information to the target outlier detection task. Despite the recent empirical success of transfer learning approaches in outlier detection, a fundamental understanding of when and how knowledge can be transferred from a source to a target outlier detection task remains elusive. In this work, we adopt the traditional framework of Neyman-Pearson classification -- which formalizes supervised outlier detection -- with the added assumption that one has access to some related but imperfect outlier data. Our main results are as follows:
  We first determine the information-theoretic limits of the problem under a measure of discrepancy that extends some existing notions from traditional balanced classification; interestingly, unlike in balanced classification, seemingly very dissimilar sources can provide much information about a target, thus resulting in fast transfer.
  We then show that, in principle, these information-theoretic limits are achievable by adaptive procedures, i.e., procedures with no a priori information on the discrepancy between source and target outlier distributions.
<div id='section'>Paperid: <span id='pid'>1354, <a href='https://arxiv.org/pdf/2310.03833.pdf' target='_blank'>https://arxiv.org/pdf/2310.03833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Omar Zamzam, Haleh Akrami, Mahdi Soltanolkotabi, Richard Leahy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03833">Learning A Disentangling Representation For PU Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we address the problem of learning a binary (positive vs. negative) classifier given Positive and Unlabeled data commonly referred to as PU learning. Although rudimentary techniques like clustering, out-of-distribution detection, or positive density estimation can be used to solve the problem in low-dimensional settings, their efficacy progressively deteriorates with higher dimensions due to the increasing complexities in the data distribution. In this paper we propose to learn a neural network-based data representation using a loss function that can be used to project the unlabeled data into two (positive and negative) clusters that can be easily identified using simple clustering techniques, effectively emulating the phenomenon observed in low-dimensional settings. We adopt a vector quantization technique for the learned representations to amplify the separation between the learned unlabeled data clusters. We conduct experiments on simulated PU data that demonstrate the improved performance of our proposed method compared to the current state-of-the-art approaches. We also provide some theoretical justification for our two cluster-based approach and our algorithmic choices.
<div id='section'>Paperid: <span id='pid'>1355, <a href='https://arxiv.org/pdf/2309.08036.pdf' target='_blank'>https://arxiv.org/pdf/2309.08036.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Syed Sha Qutub, Neslihan Kose, Rafael Rosales, Michael Paulitsch, Korbinian Hagn, Florian Geissler, Yang Peng, Gereon Hinz, Alois Knoll
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.08036">BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces the Budding Ensemble Architecture (BEA), a novel reduced ensemble architecture for anchor-based object detection models. Object detection models are crucial in vision-based tasks, particularly in autonomous systems. They should provide precise bounding box detections while also calibrating their predicted confidence scores, leading to higher-quality uncertainty estimates. However, current models may make erroneous decisions due to false positives receiving high scores or true positives being discarded due to low scores. BEA aims to address these issues. The proposed loss functions in BEA improve the confidence score calibration and lower the uncertainty error, which results in a better distinction of true and false positives and, eventually, higher accuracy of the object detection models. Both Base-YOLOv3 and SSD models were enhanced using the BEA method and its proposed loss functions. The BEA on Base-YOLOv3 trained on the KITTI dataset results in a 6% and 3.7% increase in mAP and AP50, respectively. Utilizing a well-balanced uncertainty estimation threshold to discard samples in real-time even leads to a 9.6% higher AP50 than its base model. This is attributed to a 40% increase in the area under the AP50-based retention curve used to measure the quality of calibration of confidence scores. Furthermore, BEA-YOLOV3 trained on KITTI provides superior out-of-distribution detection on Citypersons, BDD100K, and COCO datasets compared to the ensembles and vanilla models of YOLOv3 and Gaussian-YOLOv3.
<div id='section'>Paperid: <span id='pid'>1356, <a href='https://arxiv.org/pdf/2308.16483.pdf' target='_blank'>https://arxiv.org/pdf/2308.16483.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaeik Jeon, Seongmin Ha, Yeonggul Jang, Yeonyee E. Yoon, Jiyeon Kim, Hyunseok Jeong, Dawun Jeong, Youngtaek Hong, Seung-Ah Lee Hyuk-Jae Chang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16483">Improving Out-of-Distribution Detection in Echocardiographic View Classication through Enhancing Semantic Features</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In echocardiographic view classification, accurately detecting out-of-distribution (OOD) data is essential but challenging, especially given the subtle differences between in-distribution and OOD data. While conventional OOD detection methods, such as Mahalanobis distance (MD) are effective in far-OOD scenarios with clear distinctions between distributions, they struggle to discern the less obvious variations characteristic of echocardiographic data. In this study, we introduce a novel use of label smoothing to enhance semantic feature representation in echocardiographic images, demonstrating that these enriched semantic features are key for significantly improving near-OOD instance detection. By combining label smoothing with MD-based OOD detection, we establish a new benchmark for accuracy in echocardiographic OOD detection.
<div id='section'>Paperid: <span id='pid'>1357, <a href='https://arxiv.org/pdf/2308.07506.pdf' target='_blank'>https://arxiv.org/pdf/2308.07506.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jadie Adams, Shireen Y. Elhabian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07506">Benchmarking Scalable Epistemic Uncertainty Quantification in Organ Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning based methods for automatic organ segmentation have shown promise in aiding diagnosis and treatment planning. However, quantifying and understanding the uncertainty associated with model predictions is crucial in critical clinical applications. While many techniques have been proposed for epistemic or model-based uncertainty estimation, it is unclear which method is preferred in the medical image analysis setting. This paper presents a comprehensive benchmarking study that evaluates epistemic uncertainty quantification methods in organ segmentation in terms of accuracy, uncertainty calibration, and scalability. We provide a comprehensive discussion of the strengths, weaknesses, and out-of-distribution detection capabilities of each method as well as recommendations for future improvements. These findings contribute to the development of reliable and robust models that yield accurate segmentations while effectively quantifying epistemic uncertainty.
<div id='section'>Paperid: <span id='pid'>1358, <a href='https://arxiv.org/pdf/2308.06498.pdf' target='_blank'>https://arxiv.org/pdf/2308.06498.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiqi Chen, Jing Yu Lim, Kingsley Kuan, Harold Soh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06498">Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Perspective-taking is the ability to perceive or understand a situation or concept from another individual's point of view, and is crucial in daily human interactions. Enabling robots to perform perspective-taking remains an unsolved problem; existing approaches that use deterministic or handcrafted methods are unable to accurately account for uncertainty in partially-observable settings. This work proposes to address this limitation via a deep world model that enables a robot to perform both perception and conceptual perspective taking, i.e., the robot is able to infer what a human sees and believes. The key innovation is a decomposed multi-modal latent state space model able to generate and augment fictitious observations/emissions. Optimizing the ELBO that arises from this probabilistic graphical model enables the learning of uncertainty in latent space, which facilitates uncertainty estimation from high-dimensional observations. We tasked our model to predict human observations and beliefs on three partially-observable HRI tasks. Experiments show that our method significantly outperforms existing baselines and is able to infer visual observations available to other agent and their internal beliefs.
<div id='section'>Paperid: <span id='pid'>1359, <a href='https://arxiv.org/pdf/2308.02674.pdf' target='_blank'>https://arxiv.org/pdf/2308.02674.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Brendon Forsgren, Ram Vasudevan, Michael Kaess, Timothy W. McLain, Joshua G. Mangelson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02674">Group-$k$ consistent measurement set maximization via maximum clique over k-Uniform hypergraphs for robust multi-robot map merging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper unifies the theory of consistent-set maximization for robust outlier detection in a simultaneous localization and mapping framework. We first describe the notion of pairwise consistency before discussing how a consistency graph can be formed by evaluating pairs of measurements for consistency. Finding the largest set of consistent measurements is transformed into an instance of the maximum clique problem and can be solved relatively quickly using existing maximum-clique solvers. We then generalize our algorithm to check consistency on a group-$k$ basis by using a generalized notion of consistency and using generalized graphs. We also present modified maximum clique algorithms that function on generalized graphs to find the set of measurements that is internally group-$k$ consistent. We address the exponential nature of group-$k$ consistency and present methods that can substantially decrease the number of necessary checks performed when evaluating consistency. We extend our prior work to multi-agent systems in both simulation and hardware and provide a comparison with other state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1360, <a href='https://arxiv.org/pdf/2308.02248.pdf' target='_blank'>https://arxiv.org/pdf/2308.02248.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mariella Dreissig, Florian Piewak, Joschka Boedecker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02248">On the Calibration of Uncertainty Estimation in LiDAR-based Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The confidence calibration of deep learning-based perception models plays a crucial role in their reliability. Especially in the context of autonomous driving, downstream tasks like prediction and planning depend on accurate confidence estimates. In point-wise multiclass classification tasks like sematic segmentation the model has to deal with heavy class imbalances. Due to their underrepresentation, the confidence calibration of classes with smaller instances is challenging but essential, not only for safety reasons. We propose a metric to measure the confidence calibration quality of a semantic segmentation model with respect to individual classes. It is calculated by computing sparsification curves for each class based on the uncertainty estimates. We use the classification calibration metric to evaluate uncertainty estimation methods with respect to their confidence calibration of underrepresented classes. We furthermore suggest a double use for the method to automatically find label problems to improve the quality of hand- or auto-annotated datasets.
<div id='section'>Paperid: <span id='pid'>1361, <a href='https://arxiv.org/pdf/2308.01030.pdf' target='_blank'>https://arxiv.org/pdf/2308.01030.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunjun Choi, JaeHo Chung, Hawook Jeong, Jin Young Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.01030">Three Factors to Improve Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the problem of out-of-distribution (OOD) detection, the usage of auxiliary data as outlier data for fine-tuning has demonstrated encouraging performance. However, previous methods have suffered from a trade-off between classification accuracy (ACC) and OOD detection performance (AUROC, FPR, AUPR). To improve this trade-off, we make three contributions: (i) Incorporating a self-knowledge distillation loss can enhance the accuracy of the network; (ii) Sampling semi-hard outlier data for training can improve OOD detection performance with minimal impact on accuracy; (iii) The introduction of our novel supervised contrastive learning can simultaneously improve OOD detection performance and the accuracy of the network. By incorporating all three factors, our approach enhances both accuracy and OOD detection performance by addressing the trade-off between classification and OOD detection. Our method achieves improvements over previous approaches in both performance metrics.
<div id='section'>Paperid: <span id='pid'>1362, <a href='https://arxiv.org/pdf/2307.07002.pdf' target='_blank'>https://arxiv.org/pdf/2307.07002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mateusz Baran, Joanna Baran, Mateusz WÃ³jcik, Maciej ZiÄba, Adam Gonczarek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.07002">Classical Out-of-Distribution Detection Methods Benchmark in Text Classification Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State-of-the-art models can perform well in controlled environments, but they often struggle when presented with out-of-distribution (OOD) examples, making OOD detection a critical component of NLP systems. In this paper, we focus on highlighting the limitations of existing approaches to OOD detection in NLP. Specifically, we evaluated eight OOD detection methods that are easily integrable into existing NLP systems and require no additional OOD data or model modifications. One of our contributions is providing a well-structured research environment that allows for full reproducibility of the results. Additionally, our analysis shows that existing OOD detection methods for NLP tasks are not yet sufficiently sensitive to capture all samples characterized by various types of distributional shifts. Particularly challenging testing scenarios arise in cases of background shift and randomly shuffled word order within in domain texts. This highlights the need for future work to develop more effective OOD detection approaches for the NLP problems, and our work provides a well-defined foundation for further research in this area.
<div id='section'>Paperid: <span id='pid'>1363, <a href='https://arxiv.org/pdf/2307.05199.pdf' target='_blank'>https://arxiv.org/pdf/2307.05199.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vojtech Franc, Daniel Prusa, Jakub Paplham
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.05199">Reject option models comprising out-of-distribution detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The optimal prediction strategy for out-of-distribution (OOD) setups is a fundamental question in machine learning. In this paper, we address this question and present several contributions. We propose three reject option models for OOD setups: the Cost-based model, the Bounded TPR-FPR model, and the Bounded Precision-Recall model. These models extend the standard reject option models used in non-OOD setups and define the notion of an optimal OOD selective classifier. We establish that all the proposed models, despite their different formulations, share a common class of optimal strategies. Motivated by the optimal strategy, we introduce double-score OOD methods that leverage uncertainty scores from two chosen OOD detectors: one focused on OOD/ID discrimination and the other on misclassification detection. The experimental results consistently demonstrate the superior performance of this simple strategy compared to state-of-the-art methods. Additionally, we propose novel evaluation metrics derived from the definition of the optimal strategy under the proposed OOD rejection models. These new metrics provide a comprehensive and reliable assessment of OOD methods without the deficiencies observed in existing evaluation approaches.
<div id='section'>Paperid: <span id='pid'>1364, <a href='https://arxiv.org/pdf/2306.13370.pdf' target='_blank'>https://arxiv.org/pdf/2306.13370.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcel Matha, Christian Morsbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13370">Physics-constrained Random Forests for Turbulence Model Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To achieve virtual certification for industrial design, quantifying the uncertainties in simulation-driven processes is crucial. We discuss a physics-constrained approach to account for epistemic uncertainty of turbulence models. In order to eliminate user input, we incorporate a data-driven machine learning strategy. In addition to it, our study focuses on developing an a priori estimation of prediction confidence when accurate data is scarce.
<div id='section'>Paperid: <span id='pid'>1365, <a href='https://arxiv.org/pdf/2306.03367.pdf' target='_blank'>https://arxiv.org/pdf/2306.03367.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Faris JanjoÅ¡, Max Keller, Maxim Dolgov, J. Marius ZÃ¶llner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03367">Bridging the Gap Between Multi-Step and One-Shot Trajectory Prediction via Self-Supervision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate vehicle trajectory prediction is an unsolved problem in autonomous driving with various open research questions. State-of-the-art approaches regress trajectories either in a one-shot or step-wise manner. Although one-shot approaches are usually preferred for their simplicity, they relinquish powerful self-supervision schemes that can be constructed by chaining multiple time-steps. We address this issue by proposing a middle-ground where multiple trajectory segments are chained together. Our proposed Multi-Branch Self-Supervised Predictor receives additional training on new predictions starting at intermediate future segments. In addition, the model 'imagines' the latent context and 'predicts the past' while combining multi-modal trajectories in a tree-like manner. We deliberately keep aspects such as interaction and environment modeling simplistic and nevertheless achieve competitive results on the INTERACTION dataset. Furthermore, we investigate the sparsely explored uncertainty estimation of deterministic predictors. We find positive correlations between the prediction error and two proposed metrics, which might pave way for determining prediction confidence.
<div id='section'>Paperid: <span id='pid'>1366, <a href='https://arxiv.org/pdf/2305.10219.pdf' target='_blank'>https://arxiv.org/pdf/2305.10219.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahdi Shamsi, Soosan Beheshti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.10219">Separability and Scatteredness (S&S) Ratio-Based Efficient SVM Regularization Parameter, Kernel, and Kernel Parameter Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Support Vector Machine (SVM) is a robust machine learning algorithm with broad applications in classification, regression, and outlier detection. SVM requires tuning the regularization parameter (RP) which controls the model capacity and the generalization performance. Conventionally, the optimum RP is found by comparison of a range of values through the Cross-Validation (CV) procedure. In addition, for non-linearly separable data, the SVM uses kernels where a set of kernels, each with a set of parameters, denoted as a grid of kernels, are considered. The optimal choice of RP and the grid of kernels is through the grid-search of CV. By stochastically analyzing the behavior of the regularization parameter, this work shows that the SVM performance can be modeled as a function of separability and scatteredness (S&S) of the data. Separability is a measure of the distance between classes, and scatteredness is the ratio of the spread of data points. In particular, for the hinge loss cost function, an S&S ratio-based table provides the optimum RP. The S&S ratio is a powerful value that can automatically detect linear or non-linear separability before using the SVM algorithm. The provided S&S ratio-based table can also provide the optimum kernel and its parameters before using the SVM algorithm. Consequently, the computational complexity of the CV grid-search is reduced to only one time use of the SVM. The simulation results on the real dataset confirm the superiority and efficiency of the proposed approach in the sense of computational complexity over the grid-search CV method.
<div id='section'>Paperid: <span id='pid'>1367, <a href='https://arxiv.org/pdf/2305.07618.pdf' target='_blank'>https://arxiv.org/pdf/2305.07618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danyal F. Bhutto, Bo Zhu, Jeremiah Z. Liu, Neha Koonjoo, Hongwei B. Li, Bruce R. Rosen, Matthew S. Rosen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.07618">Uncertainty Estimation and Out-of-Distribution Detection for Deep Learning-Based Image Reconstruction using the Local Lipschitz</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate image reconstruction is at the heart of diagnostics in medical imaging. Supervised deep learning-based approaches have been investigated for solving inverse problems including image reconstruction. However, these trained models encounter unseen data distributions that are widely shifted from training data during deployment. Therefore, it is essential to assess whether a given input falls within the training data distribution for diagnostic purposes. Uncertainty estimation approaches exist but focus on providing an uncertainty map to radiologists, rather than assessing the training distribution fit. In this work, we propose a method based on the local Lipschitz-based metric to distinguish out-of-distribution images from in-distribution with an area under the curve of 99.94%. Empirically, we demonstrate a very strong relationship between the local Lipschitz value and mean absolute error (MAE), supported by a high Spearman's rank correlation coefficient of 0.8475, which determines the uncertainty estimation threshold for optimal model performance. Through the identification of false positives, the local Lipschitz and MAE relationship was used to guide data augmentation and reduce model uncertainty. Our study was validated using the AUTOMAP architecture for sensor-to-image Magnetic Resonance Imaging (MRI) reconstruction. We compare our proposed approach with baseline methods: Monte-Carlo dropout and deep ensembles, and further analysis included MRI denoising and Computed Tomography (CT) sparse-to-full view reconstruction using UNET architectures. We show that our approach is applicable to various architectures and learned functions, especially in the realm of medical image reconstruction, where preserving the diagnostic accuracy of reconstructed images remains paramount.
<div id='section'>Paperid: <span id='pid'>1368, <a href='https://arxiv.org/pdf/2304.12332.pdf' target='_blank'>https://arxiv.org/pdf/2304.12332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ãngel LÃ³pez Oriona, JosÃ© Antonio Vilar FernÃ¡ndez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12332">Analyzing categorical time series with the R package ctsfeatures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time series data are ubiquitous nowadays. Whereas most of the literature on the topic deals with real-valued time series, categorical time series have received much less attention. However, the development of data mining techniques for this kind of data has substantially increased in recent years. The R package ctsfeatures offers users a set of useful tools for analyzing categorical time series. In particular, several functions allowing the extraction of well-known statistical features and the construction of illustrative graphs describing underlying temporal patterns are provided in the package. The output of some functions can be employed to perform traditional machine learning tasks including clustering, classification and outlier detection. The package also includes two datasets of biological sequences introduced in the literature for clustering purposes, as well as three interesting synthetic databases. In this work, the main characteristics of the package are described and its use is illustrated through various examples. Practitioners from a wide variety of fields could benefit from the valuable tools provided by ctsfeatures.
<div id='section'>Paperid: <span id='pid'>1369, <a href='https://arxiv.org/pdf/2304.12251.pdf' target='_blank'>https://arxiv.org/pdf/2304.12251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ãngel LÃ³pez Oriona, JosÃ© Antonio Vilar FernÃ¡ndez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12251">Ordinal time series analysis with the R package otsfeatures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The 21st century has witnessed a growing interest in the analysis of time series data. Whereas most of the literature on the topic deals with real-valued time series, ordinal time series have typically received much less attention. However, the development of specific analytical tools for the latter objects has substantially increased in recent years. The R package otsfeatures attempts to provide a set of simple functions for analyzing ordinal time series. In particular, several commands allowing the extraction of well-known statistical features and the execution of inferential tasks are available for the user. The output of several functions can be employed to perform traditional machine learning tasks including clustering, classification or outlier detection. otsfeatures also incorporates two datasets of financial time series which were used in the literature for clustering purposes, as well as three interesting synthetic databases. The main properties of the package are described and its use is illustrated through several examples. Researchers from a broad variety of disciplines could benefit from the powerful tools provided by otsfeatures.
<div id='section'>Paperid: <span id='pid'>1370, <a href='https://arxiv.org/pdf/2304.05749.pdf' target='_blank'>https://arxiv.org/pdf/2304.05749.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxing Tian, Mingjie Zhu, Jiachi Luo, Song Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.05749">Boosting long-term forecasting performance for continuous-time dynamic graph networks via data augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study focuses on long-term forecasting (LTF) on continuous-time dynamic graph networks (CTDGNs), which is important for real-world modeling. Existing CTDGNs are effective for modeling temporal graph data due to their ability to capture complex temporal dependencies but perform poorly on LTF due to the substantial requirement for historical data, which is not practical in most cases. To relieve this problem, a most intuitive way is data augmentation. In this study, we propose \textbf{\underline{U}ncertainty \underline{M}asked \underline{M}ix\underline{U}p (UmmU)}: a plug-and-play module that conducts uncertainty estimation to introduce uncertainty into the embedding of intermediate layer of CTDGNs, and perform masked mixup to further enhance the uncertainty of the embedding to make it generalize to more situations. UmmU can be easily inserted into arbitrary CTDGNs without increasing the number of parameters. We conduct comprehensive experiments on three real-world dynamic graph datasets, the results demonstrate that UmmU can effectively improve the long-term forecasting performance for CTDGNs.
<div id='section'>Paperid: <span id='pid'>1371, <a href='https://arxiv.org/pdf/2304.04441.pdf' target='_blank'>https://arxiv.org/pdf/2304.04441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanhong Qiu, Haitao Gan, Ming Shi, Zhongwei Huang, Zhi Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04441">Self-training with dual uncertainty for semi-supervised medical image segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of semi-supervised medical image segmentation, the shortage of labeled data is the fundamental problem. How to effectively learn image features from unlabeled images to improve segmentation accuracy is the main research direction in this field. Traditional self-training methods can partially solve the problem of insufficient labeled data by generating pseudo labels for iterative training. However, noise generated due to the model's uncertainty during training directly affects the segmentation results. Therefore, we added sample-level and pixel-level uncertainty to stabilize the training process based on the self-training framework. Specifically, we saved several moments of the model during pre-training, and used the difference between their predictions on unlabeled samples as the sample-level uncertainty estimate for that sample. Then, we gradually add unlabeled samples from easy to hard during training. At the same time, we added a decoder with different upsampling methods to the segmentation network and used the difference between the outputs of the two decoders as pixel-level uncertainty. In short, we selectively retrained unlabeled samples and assigned pixel-level uncertainty to pseudo labels to optimize the self-training process. We compared the segmentation results of our model with five semi-supervised approaches on the public 2017 ACDC dataset and 2018 Prostate dataset. Our proposed method achieves better segmentation performance on both datasets under the same settings, demonstrating its effectiveness, robustness, and potential transferability to other medical image segmentation tasks. Keywords: Medical image segmentation, semi-supervised learning, self-training, uncertainty estimation
<div id='section'>Paperid: <span id='pid'>1372, <a href='https://arxiv.org/pdf/2304.02947.pdf' target='_blank'>https://arxiv.org/pdf/2304.02947.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marek Wadinger, Michal Kvasnica
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02947">Adaptable and Interpretable Framework for Novelty Detection in Real-Time IoT Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents the Real-time Adaptive and Interpretable Detection (RAID) algorithm. The novel approach addresses the limitations of state-of-the-art anomaly detection methods for multivariate dynamic processes, which are restricted to detecting anomalies within the scope of the model training conditions. The RAID algorithm adapts to non-stationary effects such as data drift and change points that may not be accounted for during model development, resulting in prolonged service life. A dynamic model based on joint probability distribution handles anomalous behavior detection in a system and the root cause isolation based on adaptive process limits. RAID algorithm does not require changes to existing process automation infrastructures, making it highly deployable across different domains. Two case studies involving real dynamic system data demonstrate the benefits of the RAID algorithm, including change point adaptation, root cause isolation, and improved detection accuracy.
<div id='section'>Paperid: <span id='pid'>1373, <a href='https://arxiv.org/pdf/2304.02208.pdf' target='_blank'>https://arxiv.org/pdf/2304.02208.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Ravishankar Rao, Subrata Garai, Soumyabrata Dey, Hang Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02208">PIKS: A Technique to Identify Actionable Trends for Policy-Makers Through Open Healthcare Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With calls for increasing transparency, governments are releasing greater amounts of data in multiple domains including finance, education and healthcare. The efficient exploratory analysis of healthcare data constitutes a significant challenge. Key concerns in public health include the quick identification and analysis of trends, and the detection of outliers. This allows policies to be rapidly adapted to changing circumstances. We present an efficient outlier detection technique, termed PIKS (Pruned iterative-k means searchlight), which combines an iterative k-means algorithm with a pruned searchlight based scan. We apply this technique to identify outliers in two publicly available healthcare datasets from the New York Statewide Planning and Research Cooperative System, and California's Office of Statewide Health Planning and Development. We provide a comparison of our technique with three other existing outlier detection techniques, consisting of auto-encoders, isolation forests and feature bagging. We identified outliers in conditions including suicide rates, immunity disorders, social admissions, cardiomyopathies, and pregnancy in the third trimester. We demonstrate that the PIKS technique produces results consistent with other techniques such as the auto-encoder. However, the auto-encoder needs to be trained, which requires several parameters to be tuned. In comparison, the PIKS technique has far fewer parameters to tune. This makes it advantageous for fast, "out-of-the-box" data exploration. The PIKS technique is scalable and can readily ingest new datasets. Hence, it can provide valuable, up-to-date insights to citizens, patients and policy-makers. We have made our code open source, and with the availability of open data, other researchers can easily reproduce and extend our work. This will help promote a deeper understanding of healthcare policies and public health issues.
<div id='section'>Paperid: <span id='pid'>1374, <a href='https://arxiv.org/pdf/2304.02189.pdf' target='_blank'>https://arxiv.org/pdf/2304.02189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Ravishankar Rao, Daniel Clarke, Subrata Garai, Soumyabrata Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02189">A system for exploring big data: an iterative k-means searchlight for outlier detection on open health data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The interactive exploration of large and evolving datasets is challenging as relationships between underlying variables may not be fully understood. There may be hidden trends and patterns in the data that are worthy of further exploration and analysis. We present a system that methodically explores multiple combinations of variables using a searchlight technique and identifies outliers. An iterative k-means clustering algorithm is applied to features derived through a split-apply-combine paradigm used in the database literature. Outliers are identified as singleton or small clusters. This algorithm is swept across the dataset in a searchlight manner. The dimensions that contain outliers are combined in pairs with other dimensions using a susbset scan technique to gain further insight into the outliers. We illustrate this system by anaylzing open health care data released by New York State. We apply our iterative k-means searchlight followed by subset scanning. Several anomalous trends in the data are identified, including cost overruns at specific hospitals, and increases in diagnoses such as suicides. These constitute novel findings in the literature, and are of potential use to regulatory agencies, policy makers and concerned citizens.
<div id='section'>Paperid: <span id='pid'>1375, <a href='https://arxiv.org/pdf/2303.12698.pdf' target='_blank'>https://arxiv.org/pdf/2303.12698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Zhao, Dawei Du, Anthony Hoogs, Christopher Funk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.12698">Open Set Action Recognition via Multi-Label Evidential Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing methods for open-set action recognition focus on novelty detection that assumes video clips show a single action, which is unrealistic in the real world. We propose a new method for open set action recognition and novelty detection via MUlti-Label Evidential learning (MULE), that goes beyond previous novel action detection methods by addressing the more general problems of single or multiple actors in the same scene, with simultaneous action(s) by any actor. Our Beta Evidential Neural Network estimates multi-action uncertainty with Beta densities based on actor-context-object relation representations. An evidence debiasing constraint is added to the objective function for optimization to reduce the static bias of video representations, which can incorrectly correlate predictions and static cues. We develop a learning algorithm based on a primal-dual average scheme update to optimize the proposed problem. Theoretical analysis of the optimization algorithm demonstrates the convergence of the primal solution sequence and bounds for both the loss function and the debiasing constraint. Uncertainty and belief-based novelty estimation mechanisms are formulated to detect novel actions. Extensive experiments on two real-world video datasets show that our proposed approach achieves promising performance in single/multi-actor, single/multi-action settings.
<div id='section'>Paperid: <span id='pid'>1376, <a href='https://arxiv.org/pdf/2303.07668.pdf' target='_blank'>https://arxiv.org/pdf/2303.07668.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Hua, Tao Li, Ling Pei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07668">PIEKF-VIWO: Visual-Inertial-Wheel Odometry using Partial Invariant Extended Kalman Filter</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Invariant Extended Kalman Filter (IEKF) has been successfully applied in Visual-inertial Odometry (VIO) as an advanced achievement of Kalman filter, showing great potential in sensor fusion. In this paper, we propose partial IEKF (PIEKF), which only incorporates rotation-velocity state into the Lie group structure and apply it for Visual-Inertial-Wheel Odometry (VIWO) to improve positioning accuracy and consistency. Specifically, we derive the rotation-velocity measurement model, which combines wheel measurements with kinematic constraints. The model circumvents the wheel odometer's 3D integration and covariance propagation, which is essential for filter consistency. And a plane constraint is also introduced to enhance the position accuracy. A dynamic outlier detection method is adopted, leveraging the velocity state output. Through the simulation and real-world test, we validate the effectiveness of our approach, which outperforms the standard Multi-State Constraint Kalman Filter (MSCKF) based VIWO in consistency and accuracy.
<div id='section'>Paperid: <span id='pid'>1377, <a href='https://arxiv.org/pdf/2302.12565.pdf' target='_blank'>https://arxiv.org/pdf/2302.12565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis A. Ortega, SimÃ³n RodrÃ­guez Santana, Daniel HernÃ¡ndez-Lobato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12565">Variational Linearized Laplace Approximation for Bayesian Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Linearized Laplace Approximation (LLA) has been recently used to perform uncertainty estimation on the predictions of pre-trained deep neural networks (DNNs). However, its widespread application is hindered by significant computational costs, particularly in scenarios with a large number of training points or DNN parameters. Consequently, additional approximations of LLA, such as Kronecker-factored or diagonal approximate GGN matrices, are utilized, potentially compromising the model's performance. To address these challenges, we propose a new method for approximating LLA using a variational sparse Gaussian Process (GP). Our method is based on the dual RKHS formulation of GPs and retains, as the predictive mean, the output of the original DNN. Furthermore, it allows for efficient stochastic optimization, which results in sub-linear training time in the size of the training dataset. Specifically, its training cost is independent of the number of training points. We compare our proposed method against accelerated LLA (ELLA), which relies on the NystrÃ¶m approximation, as well as other LLA variants employing the sample-then-optimize principle. Experimental results, both on regression and classification datasets, show that our method outperforms these already existing efficient variants of LLA, both in terms of the quality of the predictive distribution and in terms of total computational time.
<div id='section'>Paperid: <span id='pid'>1378, <a href='https://arxiv.org/pdf/2302.11234.pdf' target='_blank'>https://arxiv.org/pdf/2302.11234.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maximilian B. Toller, Bernhard C. Geiger, Roman Kern
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11234">Cluster Purging: Efficient Outlier Detection based on Rate-Distortion Theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rate-distortion theory-based outlier detection builds upon the rationale that a good data compression will encode outliers with unique symbols. Based on this rationale, we propose Cluster Purging, which is an extension of clustering-based outlier detection. This extension allows one to assess the representivity of clusterings, and to find data that are best represented by individual unique clusters. We propose two efficient algorithms for performing Cluster Purging, one being parameter-free, while the other algorithm has a parameter that controls representivity estimations, allowing it to be tuned in supervised setups. In an experimental evaluation, we show that Cluster Purging improves upon outliers detected from raw clusterings, and that Cluster Purging competes strongly against state-of-the-art alternatives.
<div id='section'>Paperid: <span id='pid'>1379, <a href='https://arxiv.org/pdf/2302.10739.pdf' target='_blank'>https://arxiv.org/pdf/2302.10739.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aqib Rashid, Jose Such
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10739">MalProtect: Stateful Defense Against Adversarial Query Attacks in ML-based Malware Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>ML models are known to be vulnerable to adversarial query attacks. In these attacks, queries are iteratively perturbed towards a particular class without any knowledge of the target model besides its output. The prevalence of remotely-hosted ML classification models and Machine-Learning-as-a-Service platforms means that query attacks pose a real threat to the security of these systems. To deal with this, stateful defenses have been proposed to detect query attacks and prevent the generation of adversarial examples by monitoring and analyzing the sequence of queries received by the system. Several stateful defenses have been proposed in recent years. However, these defenses rely solely on similarity or out-of-distribution detection methods that may be effective in other domains. In the malware detection domain, the methods to generate adversarial examples are inherently different, and therefore we find that such detection mechanisms are significantly less effective. Hence, in this paper, we present MalProtect, which is a stateful defense against query attacks in the malware detection domain. MalProtect uses several threat indicators to detect attacks. Our results show that it reduces the evasion rate of adversarial query attacks by 80+\% in Android and Windows malware, across a range of attacker scenarios. In the first evaluation of its kind, we show that MalProtect outperforms prior stateful defenses, especially under the peak adversarial threat.
<div id='section'>Paperid: <span id='pid'>1380, <a href='https://arxiv.org/pdf/2302.10706.pdf' target='_blank'>https://arxiv.org/pdf/2302.10706.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tristan Cinquin, Tammo Rukat, Philipp Schmidt, Martin Wistuba, Artur Bekasov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10706">Variational Boosted Soft Trees</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gradient boosting machines (GBMs) based on decision trees consistently demonstrate state-of-the-art results on regression and classification tasks with tabular data, often outperforming deep neural networks. However, these models do not provide well-calibrated predictive uncertainties, which prevents their use for decision making in high-risk applications. The Bayesian treatment is known to improve predictive uncertainty calibration, but previously proposed Bayesian GBM methods are either computationally expensive, or resort to crude approximations. Variational inference is often used to implement Bayesian neural networks, but is difficult to apply to GBMs, because the decision trees used as weak learners are non-differentiable. In this paper, we propose to implement Bayesian GBMs using variational inference with soft decision trees, a fully differentiable alternative to standard decision trees introduced by Irsoy et al. Our experiments demonstrate that variational soft trees and variational soft GBMs provide useful uncertainty estimates, while retaining good predictive performance. The proposed models show higher test likelihoods when compared to the state-of-the-art Bayesian GBMs in 7/10 tabular regression datasets and improved out-of-distribution detection in 5/10 datasets.
<div id='section'>Paperid: <span id='pid'>1381, <a href='https://arxiv.org/pdf/2302.02834.pdf' target='_blank'>https://arxiv.org/pdf/2302.02834.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leonid Erlygin, Vladimir Zholobov, Valeriia Baklanova, Evgeny Sokolovskiy, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02834">Surrogate uncertainty estimation for your time series forecasting black-box: learn when to trust</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models play a vital role in time series forecasting. These models, however, often overlook an important element: point uncertainty estimates. Incorporating these estimates is crucial for effective risk management, informed model selection, and decision-making.To address this issue, our research introduces a method for uncertainty estimation. We employ a surrogate Gaussian process regression model. It enhances any base regression model with reasonable uncertainty estimates. This approach stands out for its computational efficiency. It only necessitates training one supplementary surrogate and avoids any data-specific assumptions. Furthermore, this method for work requires only the presence of the base model as a black box and its respective training data. The effectiveness of our approach is supported by experimental results. Using various time-series forecasting data, we found that our surrogate model-based technique delivers significantly more accurate confidence intervals. These techniques outperform both bootstrap-based and built-in methods in a medium-data regime. This superiority holds across a range of base model types, including a linear regression, ARIMA, gradient boosting and a neural network.
<div id='section'>Paperid: <span id='pid'>1382, <a href='https://arxiv.org/pdf/2301.13527.pdf' target='_blank'>https://arxiv.org/pdf/2301.13527.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marek Wadinger, Michal Kvasnica
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.13527">Real-Time Outlier Detection with Dynamic Process Limits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection methods are part of the systems where rare events may endanger an operation's profitability, safety, and environmental aspects. Although many state-of-the-art anomaly detection methods were developed to date, their deployment is limited to the operation conditions present during the model training. Online anomaly detection brings the capability to adapt to data drifts and change points that may not be represented during model development resulting in prolonged service life. This paper proposes an online anomaly detection algorithm for existing real-time infrastructures where low-latency detection is required and novel patterns in data occur unpredictably. The online inverse cumulative distribution-based approach is introduced to eliminate common problems of offline anomaly detectors, meanwhile providing dynamic process limits to normal operation. The benefit of the proposed method is the ease of use, fast computation, and deployability as shown in two case studies of real microgrid operation data.
<div id='section'>Paperid: <span id='pid'>1383, <a href='https://arxiv.org/pdf/2301.13012.pdf' target='_blank'>https://arxiv.org/pdf/2301.13012.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaeyoung Kim, Seo Taek Kong, Dongbin Na, Kyu-Hwan Jung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.13012">Key Feature Replacement of In-Distribution Samples for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection can be used in deep learning-based applications to reject outlier samples from being unreliably classified by deep neural networks. Learning to classify between OOD and in-distribution samples is difficult because data comprising the former is extremely diverse. It has been observed that an auxiliary OOD dataset is most effective in training a "rejection" network when its samples are semantically similar to in-distribution images. We first deduce that OOD images are perceived by a deep neural network to be semantically similar to in-distribution samples when they share a common background, as deep networks are observed to incorrectly classify such images with high confidence. We then propose a simple yet effective Key In-distribution feature Replacement BY inpainting (KIRBY) procedure that constructs a surrogate OOD dataset by replacing class-discriminative features of in-distribution samples with marginal background features. The procedure can be implemented using off-the-shelf vision algorithms, where each step within the algorithm is shown to make the surrogate data increasingly similar to in-distribution data. Design choices in each step are studied extensively, and an exhaustive comparison with state-of-the-art algorithms demonstrates KIRBY's competitiveness on various benchmarks.
<div id='section'>Paperid: <span id='pid'>1384, <a href='https://arxiv.org/pdf/2301.11556.pdf' target='_blank'>https://arxiv.org/pdf/2301.11556.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyi Liang, Yanfei Zhou, Matteo Sesia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.11556">Conformal inference is (almost) free for neural networks trained with early stopping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Early stopping based on hold-out data is a popular regularization technique designed to mitigate overfitting and increase the predictive accuracy of neural networks. Models trained with early stopping often provide relatively accurate predictions, but they generally still lack precise statistical guarantees unless they are further calibrated using independent hold-out data. This paper addresses the above limitation with conformalized early stopping: a novel method that combines early stopping with conformal calibration while efficiently recycling the same hold-out data. This leads to models that are both accurate and able to provide exact predictive inferences without multiple data splits nor overly conservative adjustments. Practical implementations are developed for different learning tasks -- outlier detection, multi-class classification, regression -- and their competitive performance is demonstrated on real data.
<div id='section'>Paperid: <span id='pid'>1385, <a href='https://arxiv.org/pdf/2301.07533.pdf' target='_blank'>https://arxiv.org/pdf/2301.07533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongzheng Huang, Tao Wang, Yuanzheng Cai, Lingyu Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.07533">A Multi-Scale Framework for Out-of-Distribution Detection in Dermoscopic Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The automatic detection of skin diseases via dermoscopic images can improve the efficiency in diagnosis and help doctors make more accurate judgments. However, conventional skin disease recognition systems may produce high confidence for out-of-distribution (OOD) data, which may become a major security vulnerability in practical applications. In this paper, we propose a multi-scale detection framework to detect out-of-distribution skin disease image data to ensure the robustness of the system. Our framework extracts features from different layers of the neural network. In the early layers, rectified activation is used to make the output features closer to the well-behaved distribution, and then an one-class SVM is trained to detect OOD data; in the penultimate layer, an adapted Gram matrix is used to calculate the features after rectified activation, and finally the layer with the best performance is chosen to compute a normality score. Experiments show that the proposed framework achieves superior performance when compared with other state-of-the-art methods in the task of skin disease recognition.
<div id='section'>Paperid: <span id='pid'>1386, <a href='https://arxiv.org/pdf/2301.02933.pdf' target='_blank'>https://arxiv.org/pdf/2301.02933.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pushpak Pati, Guillaume Jaume, Zeineb Ayadi, Kevin Thandiackal, Behzad Bozorgtabar, Maria Gabrani, Orcun Goksel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02933">Weakly Supervised Joint Whole-Slide Segmentation and Classification in Prostate Cancer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The segmentation and automatic identification of histological regions of diagnostic interest offer a valuable aid to pathologists. However, segmentation methods are hampered by the difficulty of obtaining pixel-level annotations, which are tedious and expensive to obtain for Whole-Slide images (WSI). To remedy this, weakly supervised methods have been developed to exploit the annotations directly available at the image level. However, to our knowledge, none of these techniques is adapted to deal with WSIs. In this paper, we propose WholeSIGHT, a weakly-supervised method, to simultaneously segment and classify WSIs of arbitrary shapes and sizes. Formally, WholeSIGHT first constructs a tissue-graph representation of the WSI, where the nodes and edges depict tissue regions and their interactions, respectively. During training, a graph classification head classifies the WSI and produces node-level pseudo labels via post-hoc feature attribution. These pseudo labels are then used to train a node classification head for WSI segmentation. During testing, both heads simultaneously render class prediction and segmentation for an input WSI. We evaluated WholeSIGHT on three public prostate cancer WSI datasets. Our method achieved state-of-the-art weakly-supervised segmentation performance on all datasets while resulting in better or comparable classification with respect to state-of-the-art weakly-supervised WSI classification methods. Additionally, we quantify the generalization capability of our method in terms of segmentation and classification performance, uncertainty estimation, and model calibration.
<div id='section'>Paperid: <span id='pid'>1387, <a href='https://arxiv.org/pdf/2211.16158.pdf' target='_blank'>https://arxiv.org/pdf/2211.16158.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joris GuÃ©rin, Kevin Delmas, Raul Sena Ferreira, JÃ©rÃ©mie Guiochet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.16158">Out-Of-Distribution Detection Is Not All You Need</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The usage of deep neural networks in safety-critical systems is limited by our ability to guarantee their correct behavior. Runtime monitors are components aiming to identify unsafe predictions and discard them before they can lead to catastrophic consequences. Several recent works on runtime monitoring have focused on out-of-distribution (OOD) detection, i.e., identifying inputs that are different from the training data. In this work, we argue that OOD detection is not a well-suited framework to design efficient runtime monitors and that it is more relevant to evaluate monitors based on their ability to discard incorrect predictions. We call this setting out-ofmodel-scope detection and discuss the conceptual differences with OOD. We also conduct extensive experiments on popular datasets from the literature to show that studying monitors in the OOD setting can be misleading: 1. very good OOD results can give a false impression of safety, 2. comparison under the OOD setting does not allow identifying the best monitor to detect errors. Finally, we also show that removing erroneous training data samples helps to train better monitors.
<div id='section'>Paperid: <span id='pid'>1388, <a href='https://arxiv.org/pdf/2211.14293.pdf' target='_blank'>https://arxiv.org/pdf/2211.14293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nazir Nayal, MÄ±sra Yavuz, JoÃ£o F. Henriques, Fatma GÃ¼ney
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.14293">RbA: Segmenting Unknown Regions Rejected by All</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard semantic segmentation models owe their success to curated datasets with a fixed set of semantic categories, without contemplating the possibility of identifying unknown objects from novel categories. Existing methods in outlier detection suffer from a lack of smoothness and objectness in their predictions, due to limitations of the per-pixel classification paradigm. Furthermore, additional training for detecting outliers harms the performance of known classes. In this paper, we explore another paradigm with region-level classification to better segment unknown objects. We show that the object queries in mask classification tend to behave like one \vs all classifiers. Based on this finding, we propose a novel outlier scoring function called RbA by defining the event of being an outlier as being rejected by all known classes. Our extensive experiments show that mask classification improves the performance of the existing outlier detection methods, and the best results are achieved with the proposed RbA. We also propose an objective to optimize RbA using minimal outlier supervision. Further fine-tuning with outliers improves the unknown performance, and unlike previous methods, it does not degrade the inlier performance.
<div id='section'>Paperid: <span id='pid'>1389, <a href='https://arxiv.org/pdf/2211.09593.pdf' target='_blank'>https://arxiv.org/pdf/2211.09593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongying Deng, Rihuan Ke, Carola-Bibiane Schonlieb, Angelica I Aviles-Rivero
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.09593">NorMatch: Matching Normalizing Flows with Discriminative Classifiers for Semi-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-Supervised Learning (SSL) aims to learn a model using a tiny labeled set and massive amounts of unlabeled data. To better exploit the unlabeled data the latest SSL methods use pseudo-labels predicted from a single discriminative classifier. However, the generated pseudo-labels are inevitably linked to inherent confirmation bias and noise which greatly affects the model performance. In this work we introduce a new framework for SSL named NorMatch. Firstly, we introduce a new uncertainty estimation scheme based on normalizing flows, as an auxiliary classifier, to enforce highly certain pseudo-labels yielding a boost of the discriminative classifiers. Secondly, we introduce a threshold-free sample weighting strategy to exploit better both high and low confidence pseudo-labels. Furthermore, we utilize normalizing flows to model, in an unsupervised fashion, the distribution of unlabeled data. This modelling assumption can further improve the performance of generative classifiers via unlabeled data, and thus, implicitly contributing to training a better discriminative classifier. We demonstrate, through numerical and visual results, that NorMatch achieves state-of-the-art performance on several datasets.
<div id='section'>Paperid: <span id='pid'>1390, <a href='https://arxiv.org/pdf/2210.09767.pdf' target='_blank'>https://arxiv.org/pdf/2210.09767.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucio Anderlini, Constantine Chimpoesh, Nikita Kazeev, Agata Shishigina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.09767">Generative models uncertainty estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years fully-parametric fast simulation methods based on generative models have been proposed for a variety of high-energy physics detectors. By their nature, the quality of data-driven models degrades in the regions of the phase space where the data are sparse. Since machine-learning models are hard to analyse from the physical principles, the commonly used testing procedures are performed in a data-driven way and can't be reliably used in such regions. In our work we propose three methods to estimate the uncertainty of generative models inside and outside of the training phase space region, along with data-driven calibration techniques. A test of the proposed methods on the LHCb RICH fast simulation is also presented.
<div id='section'>Paperid: <span id='pid'>1391, <a href='https://arxiv.org/pdf/2210.06302.pdf' target='_blank'>https://arxiv.org/pdf/2210.06302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Elwood, Marco Leonardi, Ashraf Mohamed, Alessandro Rozza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.06302">Maximum entropy exploration in contextual bandits with neural networks and energy based models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contextual bandits can solve a huge range of real-world problems. However, current popular algorithms to solve them either rely on linear models, or unreliable uncertainty estimation in non-linear models, which are required to deal with the exploration-exploitation trade-off. Inspired by theories of human cognition, we introduce novel techniques that use maximum entropy exploration, relying on neural networks to find optimal policies in settings with both continuous and discrete action spaces. We present two classes of models, one with neural networks as reward estimators, and the other with energy based models, which model the probability of obtaining an optimal reward given an action. We evaluate the performance of these models in static and dynamic contextual bandit simulation environments. We show that both techniques outperform well-known standard algorithms, where energy based models have the best overall performance. This provides practitioners with new techniques that perform well in static and dynamic settings, and are particularly well suited to non-linear scenarios with continuous action spaces.
<div id='section'>Paperid: <span id='pid'>1392, <a href='https://arxiv.org/pdf/2209.01611.pdf' target='_blank'>https://arxiv.org/pdf/2209.01611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>FÃ¡bio MendonÃ§a, Sheikh Shanawaz Mostafa, Fernando Morgado-Dias, Antonio G. Ravelo-GarcÃ­a, MÃ¡rio A. T. Figueiredo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.01611">ProBoost: a Boosting Method for Probabilistic Classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>ProBoost, a new boosting algorithm for probabilistic classifiers, is proposed in this work. This algorithm uses the epistemic uncertainty of each training sample to determine the most challenging/uncertain ones; the relevance of these samples is then increased for the next weak learner, producing a sequence that progressively focuses on the samples found to have the highest uncertainty. In the end, the weak learners' outputs are combined into a weighted ensemble of classifiers. Three methods are proposed to manipulate the training set: undersampling, oversampling, and weighting the training samples according to the uncertainty estimated by the weak learners. Furthermore, two approaches are studied regarding the ensemble combination. The weak learner herein considered is a standard convolutional neural network, and the probabilistic models underlying the uncertainty estimation use either variational inference or Monte Carlo dropout. The experimental evaluation carried out on MNIST benchmark datasets shows that ProBoost yields a significant performance improvement. The results are further highlighted by assessing the relative achievable improvement, a metric proposed in this work, which shows that a model with only four weak learners leads to an improvement exceeding 12% in this metric (for either accuracy, sensitivity, or specificity), in comparison to the model learned without ProBoost.
<div id='section'>Paperid: <span id='pid'>1393, <a href='https://arxiv.org/pdf/2208.13579.pdf' target='_blank'>https://arxiv.org/pdf/2208.13579.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Barath Mohan Umapathi, Kushal Chauhan, Pradeep Shenoy, Devarajan Sridharan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.13579">Shaken, and Stirred: Long-Range Dependencies Enable Robust Outlier Detection with PixelCNN++</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable outlier detection is critical for real-world deployment of deep learning models. Although extensively studied, likelihoods produced by deep generative models have been largely dismissed as being impractical for outlier detection. First, deep generative model likelihoods are readily biased by low-level input statistics. Second, many recent solutions for correcting these biases are computationally expensive, or do not generalize well to complex, natural datasets. Here, we explore outlier detection with a state-of-the-art deep autoregressive model: PixelCNN++. We show that biases in PixelCNN++ likelihoods arise primarily from predictions based on local dependencies. We propose two families of bijective transformations -- ``stirring'' and ``shaking'' -- which ameliorate low-level biases and isolate the contribution of long-range dependencies to PixelCNN++ likelihoods. These transformations are inexpensive and readily computed at evaluation time. We test our approaches extensively with five grayscale and six natural image datasets and show that they achieve or exceed state-of-the-art outlier detection, particularly on datasets with complex, natural images. We also show that our solutions work well with other types of generative models (generative flows and variational autoencoders) and that their efficacy is governed by each model's reliance on local dependencies. In sum, lightweight remedies suffice to achieve robust outlier detection on image data with deep generative models.
<div id='section'>Paperid: <span id='pid'>1394, <a href='https://arxiv.org/pdf/2207.09031.pdf' target='_blank'>https://arxiv.org/pdf/2207.09031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christopher Wiedeman, Ge Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.09031">Decorrelative Network Architecture for Robust Electrocardiogram Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence has made great progress in medical data analysis, but the lack of robustness and trustworthiness has kept these methods from being widely deployed. As it is not possible to train networks that are accurate in all scenarios, models must recognize situations where they cannot operate confidently. Bayesian deep learning methods sample the model parameter space to estimate uncertainty, but these parameters are often subject to the same vulnerabilities, which can be exploited by adversarial attacks. We propose a novel ensemble approach based on feature decorrelation and Fourier partitioning for teaching networks diverse complementary features, reducing the chance of perturbation-based fooling. We test our approach on single and multi-channel electrocardiogram classification, and adapt adversarial training and DVERGE into the Bayesian ensemble framework for comparison. Our results indicate that the combination of decorrelation and Fourier partitioning generally maintains performance on unperturbed data while demonstrating superior robustness and uncertainty estimation on projected gradient descent and smooth adversarial attacks of various magnitudes. Furthermore, our approach does not require expensive optimization with adversarial samples, adding much less compute to the training process than adversarial training or DVERGE. These methods can be applied to other tasks for more robust and trustworthy models.
<div id='section'>Paperid: <span id='pid'>1395, <a href='https://arxiv.org/pdf/2205.09548.pdf' target='_blank'>https://arxiv.org/pdf/2205.09548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lixue Cheng, Ziyi Yang, Changyu Hsieh, Benben Liao, Shengyu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.09548">ODBO: Bayesian Optimization with Search Space Prescreening for Directed Protein Evolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Directed evolution is a versatile technique in protein engineering that mimics the process of natural selection by iteratively alternating between mutagenesis and screening in order to search for sequences that optimize a given property of interest, such as catalytic activity and binding affinity to a specified target. However, the space of possible proteins is too large to search exhaustively in the laboratory, and functional proteins are scarce in the vast sequence space. Machine learning (ML) approaches can accelerate directed evolution by learning to map protein sequences to functions without building a detailed model of the underlying physics, chemistry and biological pathways. Despite the great potentials held by these ML methods, they encounter severe challenges in identifying the most suitable sequences for a targeted function. These failures can be attributed to the common practice of adopting a high-dimensional feature representation for protein sequences and inefficient search methods. To address these issues, we propose an efficient, experimental design-oriented closed-loop optimization framework for protein directed evolution, termed ODBO, which employs a combination of novel low-dimensional protein encoding strategy and Bayesian optimization enhanced with search space prescreening via outlier detection. We further design an initial sample selection strategy to minimize the number of experimental samples for training ML models. We conduct and report four protein directed evolution experiments that substantiate the capability of the proposed framework for finding of the variants with properties of interest. We expect the ODBO framework to greatly reduce the experimental cost and time cost of directed evolution, and can be further generalized as a powerful tool for adaptive experimental design in a broader context.
<div id='section'>Paperid: <span id='pid'>1396, <a href='https://arxiv.org/pdf/2202.13059.pdf' target='_blank'>https://arxiv.org/pdf/2202.13059.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Takashi Furuya, Hiroyuki Kusumoto, Koichi Taniguchi, Naoya Kanno, Kazuma Suetake
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.13059">Theoretical Error Analysis of Entropy Approximation for Gaussian Mixtures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gaussian mixture distributions are commonly employed to represent general probability distributions. Despite the importance of using Gaussian mixtures for uncertainty estimation, the entropy of a Gaussian mixture cannot be calculated analytically. In this paper, we study the approximate entropy represented as the sum of the entropies of unimodal Gaussian distributions with mixing coefficients. This approximation is easy to calculate analytically regardless of dimension, but there is a lack of theoretical guarantees. We theoretically analyze the approximation error between the true and the approximate entropy to reveal when this approximation works effectively. This error is essentially controlled by how far apart each Gaussian component of the Gaussian mixture is. To measure such separation, we introduce the ratios of the distances between the means to the sum of the variances of each Gaussian component of the Gaussian mixture, and we reveal that the error converges to zero as the ratios tend to infinity. In addition, the probabilistic estimate indicates that this convergence situation is more likely to occur in higher-dimensional spaces. Therefore, our results provide a guarantee that this approximation works well for high-dimensional problems, such as neural networks that involve a large number of parameters.
<div id='section'>Paperid: <span id='pid'>1397, <a href='https://arxiv.org/pdf/2201.12682.pdf' target='_blank'>https://arxiv.org/pdf/2201.12682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jake S. Rhodes, Adele Cutler, Kevin R. Moon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.12682">Geometry- and Accuracy-Preserving Random Forest Proximities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Random forests are considered one of the best out-of-the-box classification and regression algorithms due to their high level of predictive performance with relatively little tuning. Pairwise proximities can be computed from a trained random forest and measure the similarity between data points relative to the supervised task. Random forest proximities have been used in many applications including the identification of variable importance, data imputation, outlier detection, and data visualization. However, existing definitions of random forest proximities do not accurately reflect the data geometry learned by the random forest. In this paper, we introduce a novel definition of random forest proximities called Random Forest-Geometry- and Accuracy-Preserving proximities (RF-GAP). We prove that the proximity-weighted sum (regression) or majority vote (classification) using RF-GAP exactly matches the out-of-bag random forest prediction, thus capturing the data geometry learned by the random forest. We empirically show that this improved geometric representation outperforms traditional random forest proximities in tasks such as data imputation and provides outlier detection and visualization results consistent with the learned data geometry.
<div id='section'>Paperid: <span id='pid'>1398, <a href='https://arxiv.org/pdf/2110.11012.pdf' target='_blank'>https://arxiv.org/pdf/2110.11012.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhishek Singh Sambyal, Narayanan C. Krishnan, Deepti R. Bathula
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.11012">Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In safety-critical applications like medical diagnosis, certainty associated with a model's prediction is just as important as its accuracy. Consequently, uncertainty estimation and reduction play a crucial role. Uncertainty in predictions can be attributed to noise or randomness in data (aleatoric) and incorrect model inferences (epistemic). While model uncertainty can be reduced with more data or bigger models, aleatoric uncertainty is more intricate. This work proposes a novel approach that interprets data uncertainty estimated from a self-supervised task as noise inherent to the data and utilizes it to reduce aleatoric uncertainty in another task related to the same dataset via data augmentation. The proposed method was evaluated on a benchmark medical imaging dataset with image reconstruction as the self-supervised task and segmentation as the image analysis task. Our findings demonstrate the effectiveness of the proposed approach in significantly reducing the aleatoric uncertainty in the image segmentation task while achieving better or on-par performance compared to the standard augmentation techniques.
<div id='section'>Paperid: <span id='pid'>1399, <a href='https://arxiv.org/pdf/2108.09375.pdf' target='_blank'>https://arxiv.org/pdf/2108.09375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Glauco Amigo, Justin M. Bui, Charles Baylis, Robert J. Marks
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2108.09375">Cascade Watchdog: A Multi-tiered Adversarial Guard for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The identification of out-of-distribution content is critical to the successful implementation of neural networks. Watchdog techniques have been developed to support the detection of these inputs, but the performance can be limited by the amount of available data. Generative adversarial networks have displayed numerous capabilities, including the ability to generate facsimiles with excellent accuracy. This paper presents and empirically evaluates a multi-tiered watchdog, which is developed using GAN generated data, for improved out-of-distribution detection. The cascade watchdog uses adversarial training to increase the amount of available data similar to the out-of-distribution elements that are more difficult to detect. Then, a specialized second guard is added in sequential order. The results show a solid and significant improvement on the detection of the most challenging out-of-distribution inputs while preserving an extremely low false positive rate.
<div id='section'>Paperid: <span id='pid'>1400, <a href='https://arxiv.org/pdf/2102.01336.pdf' target='_blank'>https://arxiv.org/pdf/2102.01336.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gagandeep Singh, Ishan Mishra, Deepak Mishra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2102.01336">Probabilistic Trust Intervals for Out of Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability of a deep learning network to distinguish between in-distribution (ID) and out-of-distribution (OOD) inputs is crucial for ensuring the reliability and trustworthiness of AI systems. Existing OOD detection methods often involve complex architectural innovations, such as ensemble models, which, while enhancing detection accuracy, significantly increase model complexity and training time. Other methods utilize surrogate samples to simulate OOD inputs, but these may not generalize well across different types of OOD data. In this paper, we propose a straightforward yet novel technique to enhance OOD detection in pre-trained networks without altering its original parameters. Our approach defines probabilistic trust intervals for each network weight, determined using in-distribution data. During inference, additional weight values are sampled, and the resulting disagreements among outputs are utilized for OOD detection. We propose a metric to quantify this disagreement and validate its effectiveness with empirical evidence. Our method significantly outperforms various baseline methods across multiple OOD datasets without requiring actual or surrogate OOD samples. We evaluate our approach on MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100 and CIFAR-10-C (a corruption-augmented version of CIFAR-10), across various neural network architectures (e.g., VGG-16, ResNet-20, DenseNet-100). On the MNIST-FashionMNIST setup, our method achieves a False Positive Rate (FPR) of 12.46\% at 95\% True Positive Rate (TPR), compared to 27.09\% achieved by the best baseline. On adversarial and corrupted datasets such as CIFAR-10-C, our proposed method easily differentiate between clean and noisy inputs. These results demonstrate the robustness of our approach in identifying corrupted and adversarial inputs, all without requiring OOD samples during training.
<div id='section'>Paperid: <span id='pid'>1401, <a href='https://arxiv.org/pdf/2012.15772.pdf' target='_blank'>https://arxiv.org/pdf/2012.15772.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew Ng, Fumin Guo, Labonny Biswas, Steffen E. Petersen, Stefan K. Piechnik, Stefan Neubauer, Graham Wright
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2012.15772">Estimating Uncertainty in Neural Networks for Cardiac MRI Segmentation: A Benchmark Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Objective: Convolutional neural networks (CNNs) have demonstrated promise in automated cardiac magnetic resonance image segmentation. However, when using CNNs in a large real-world dataset, it is important to quantify segmentation uncertainty and identify segmentations which could be problematic. In this work, we performed a systematic study of Bayesian and non-Bayesian methods for estimating uncertainty in segmentation neural networks.
  Methods: We evaluated Bayes by Backprop, Monte Carlo Dropout, Deep Ensembles, and Stochastic Segmentation Networks in terms of segmentation accuracy, probability calibration, uncertainty on out-of-distribution images, and segmentation quality control.
  Results: We observed that Deep Ensembles outperformed the other methods except for images with heavy noise and blurring distortions. We showed that Bayes by Backprop is more robust to noise distortions while Stochastic Segmentation Networks are more resistant to blurring distortions. For segmentation quality control, we showed that segmentation uncertainty is correlated with segmentation accuracy for all the methods. With the incorporation of uncertainty estimates, we were able to reduce the percentage of poor segmentation to 5% by flagging 31--48% of the most uncertain segmentations for manual review, substantially lower than random review without using neural network uncertainty (reviewing 75--78% of all images).
  Conclusion: This work provides a comprehensive evaluation of uncertainty estimation methods and showed that Deep Ensembles outperformed other methods in most cases.
  Significance: Neural network uncertainty measures can help identify potentially inaccurate segmentations and alert users for manual review.
<div id='section'>Paperid: <span id='pid'>1402, <a href='https://arxiv.org/pdf/2510.06007.pdf' target='_blank'>https://arxiv.org/pdf/2510.06007.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hans Weytjens, Wouter Verbeke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06007">Uncertainty in Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This book chapter introduces the principles and practical applications of uncertainty quantification in machine learning. It explains how to identify and distinguish between different types of uncertainty and presents methods for quantifying uncertainty in predictive models, including linear regression, random forests, and neural networks. The chapter also covers conformal prediction as a framework for generating predictions with predefined confidence intervals. Finally, it explores how uncertainty estimation can be leveraged to improve business decision-making, enhance model reliability, and support risk-aware strategies.
<div id='section'>Paperid: <span id='pid'>1403, <a href='https://arxiv.org/pdf/2509.25437.pdf' target='_blank'>https://arxiv.org/pdf/2509.25437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mabel Heffring, Lincoln Linlin Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25437">Bayesian Transformer for Pan-Arctic Sea Ice Concentration Mapping and Uncertainty Estimation using Sentinel-1, RCM, and AMSR2 Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although high-resolution mapping of Pan-Arctic sea ice with reliable corresponding uncertainty is essential for operational sea ice concentration (SIC) charting, it is a difficult task due to some key challenges, e.g., the subtle nature of ice signature features, model uncertainty, and data heterogeneity. This letter presents a novel Bayesian Transformer approach for Pan-Arctic SIC mapping and uncertainty quantification using Sentinel-1, RADARSAT Constellation Mission (RCM), and Advanced Microwave Scanning Radiometer 2 (AMSR2) data. First, to improve feature extraction, we design a novel high-resolution Transformer model with both global and local modules that can better discern the subtle differences in sea ice patterns. Second, to improve uncertainty quantification, we design a Bayesian extension of the proposed Transformer model, treating its parameters as random variables to more effectively capture uncertainties. Third, to address data heterogeneity, we fuse three different data types (Sentinel-1, RCM, and AMSR2) at decision-level to improve both SIC mapping and uncertainty quantification. The proposed approach is tested on Pan-Arctic datasets from September 2021, and the results demonstrate that the proposed model can achieve both high-resolution SIC maps and robust uncertainty maps compared to other uncertainty quantification approaches.
<div id='section'>Paperid: <span id='pid'>1404, <a href='https://arxiv.org/pdf/2509.23480.pdf' target='_blank'>https://arxiv.org/pdf/2509.23480.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shourya Verma, Mengbo Wang, Nadia Atallah Lanman, Ananth Grama
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.23480">RestoRect: Degraded Image Restoration via Latent Rectified Flow & Feature Distillation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current approaches for restoration of degraded images face a critical trade-off: high-performance models are too slow for practical use, while fast models produce poor results. Knowledge distillation transfers teacher knowledge to students, but existing static feature matching methods cannot capture how modern transformer architectures dynamically generate features. We propose 'RestoRect', a novel Latent Rectified Flow Feature Distillation method for restoring degraded images. We apply rectified flow to reformulate feature distillation as a generative process where students learn to synthesize teacher-quality features through learnable trajectories in latent space. Our framework combines Retinex theory for physics-based decomposition with learnable anisotropic diffusion constraints, and trigonometric color space polarization. We introduce a Feature Layer Extraction loss for robust knowledge transfer between different network architectures through cross-normalized transformer feature alignment with percentile-based outlier detection. RestoRect achieves better training stability, and faster convergence and inference while preserving restoration quality. We demonstrate superior results across 15 image restoration datasets, covering 4 tasks, on 8 metrics.
<div id='section'>Paperid: <span id='pid'>1405, <a href='https://arxiv.org/pdf/2509.21943.pdf' target='_blank'>https://arxiv.org/pdf/2509.21943.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlo Dindorf, Jonas Dully, Steven Simon, Dennis Perchthaler, Stephan Becker, Hannah Ehmann, Kjell Heitmann, Bernd Stetter, Christian Diers, Michael Fröhlich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21943">Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Plantar pressure mapping is essential in clinical diagnostics and sports science, yet large heterogeneous datasets often contain outliers from technical errors or procedural inconsistencies. Statistical Parametric Mapping (SPM) provides interpretable analyses but is sensitive to alignment and its capacity for robust outlier detection remains unclear. This study compares an SPM approach with an explainable machine learning (ML) approach to establish transparent quality-control pipelines for plantar pressure datasets. Data from multiple centers were annotated by expert consensus and enriched with synthetic anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a non-parametric, registration-dependent SPM approach and (ii) a convolutional neural network (CNN), explained using SHapley Additive exPlanations (SHAP). Performance was assessed via nested cross-validation; explanation quality via a semantic differential survey with domain experts. The ML model reached high accuracy and outperformed SPM, which misclassified clinically meaningful variations and missed true outliers. Experts perceived both SPM and SHAP explanations as clear, useful, and trustworthy, though SPM was assessed less complex. These findings highlight the complementary potential of SPM and explainable ML as approaches for automated outlier detection in plantar pressure data, and underscore the importance of explainability in translating complex model outputs into interpretable insights that can effectively inform decision-making.
<div id='section'>Paperid: <span id='pid'>1406, <a href='https://arxiv.org/pdf/2509.19366.pdf' target='_blank'>https://arxiv.org/pdf/2509.19366.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Buhe Li, Berkay Kaplan, Maksym Lazirko, Aleksandr Kogan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19366">Unsupervised Outlier Detection in Audit Analytics: A Case Study Using USA Spending Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the effectiveness of unsupervised outlier detection methods in audit analytics, utilizing USA spending data from the U.S. Department of Health and Human Services (DHHS) as a case example. We employ and compare multiple outlier detection algorithms, including Histogram-based Outlier Score (HBOS), Robust Principal Component Analysis (PCA), Minimum Covariance Determinant (MCD), and K-Nearest Neighbors (KNN) to identify anomalies in federal spending patterns. The research addresses the growing need for efficient and accurate anomaly detection in large-scale governmental datasets, where traditional auditing methods may fall short. Our methodology involves data preparation, algorithm implementation, and performance evaluation using precision, recall, and F1 scores. Results indicate that a hybrid approach, combining multiple detection strategies, enhances the robustness and accuracy of outlier identification in complex financial data. This study contributes to the field of audit analytics by providing insights into the comparative effectiveness of various outlier detection models and demonstrating the potential of unsupervised learning techniques in improving audit quality and efficiency. The findings have implications for auditors, policymakers, and researchers seeking to leverage advanced analytics in governmental financial oversight and risk management.
<div id='section'>Paperid: <span id='pid'>1407, <a href='https://arxiv.org/pdf/2509.18111.pdf' target='_blank'>https://arxiv.org/pdf/2509.18111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Faizul Rakib Sayem, Shahana Ibrahim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18111">Prompt Optimization Meets Subspace Representation Learning for Few-shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The reliability of artificial intelligence (AI) systems in open-world settings depends heavily on their ability to flag out-of-distribution (OOD) inputs unseen during training. Recent advances in large-scale vision-language models (VLMs) have enabled promising few-shot OOD detection frameworks using only a handful of in-distribution (ID) samples. However, existing prompt learning-based OOD methods rely solely on softmax probabilities, overlooking the rich discriminative potential of the feature embeddings learned by VLMs trained on millions of samples. To address this limitation, we propose a novel context optimization (CoOp)-based framework that integrates subspace representation learning with prompt tuning. Our approach improves ID-OOD separability by projecting the ID features into a subspace spanned by prompt vectors, while projecting ID-irrelevant features into an orthogonal null space. To train such OOD detection framework, we design an easy-to-handle end-to-end learning criterion that ensures strong OOD detection performance as well as high ID classification accuracy. Experiments on real-world datasets showcase the effectiveness of our approach.
<div id='section'>Paperid: <span id='pid'>1408, <a href='https://arxiv.org/pdf/2509.15256.pdf' target='_blank'>https://arxiv.org/pdf/2509.15256.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zimo Yan, Jie Zhang, Zheng Xie, Yiping Song, Hao Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15256">A Multi-Scale Graph Neural Process with Cross-Drug Co-Attention for Drug-Drug Interactions Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of drug-drug interactions (DDI) is crucial for medication safety and effective drug development. However, existing methods often struggle to capture structural information across different scales, from local functional groups to global molecular topology, and typically lack mechanisms to quantify prediction confidence. To address these limitations, we propose MPNP-DDI, a novel Multi-scale Graph Neural Process framework. The core of MPNP-DDI is a unique message-passing scheme that, by being iteratively applied, learns a hierarchy of graph representations at multiple scales. Crucially, a cross-drug co-attention mechanism then dynamically fuses these multi-scale representations to generate context-aware embeddings for interacting drug pairs, while an integrated neural process module provides principled uncertainty estimation. Extensive experiments demonstrate that MPNP-DDI significantly outperforms state-of-the-art baselines on benchmark datasets. By providing accurate, generalizable, and uncertainty-aware predictions built upon multi-scale structural features, MPNP-DDI represents a powerful computational tool for pharmacovigilance, polypharmacy risk assessment, and precision medicine.
<div id='section'>Paperid: <span id='pid'>1409, <a href='https://arxiv.org/pdf/2509.14622.pdf' target='_blank'>https://arxiv.org/pdf/2509.14622.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihao Guo, Haocheng Bian, Liutong Zhou, Ze Wang, Zhaoyi Zhang, Francois Kawala, Milan Dean, Ian Fischer, Yuantao Peng, Noyan Tokgozoglu, Ivan Barrientos, Riyaaz Shaik, Rachel Li, Chandru Venkataraman, Reza Shifteh Far, Moses Pawar, Venkat Sundaranatha, Michael Xu, Frank Chu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14622">Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the deployment of Large Language Models (LLMs) in interactive applications, online malicious intent detection has become increasingly critical. However, existing approaches fall short of handling diverse and complex user queries in real time. To address these challenges, we introduce ADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework for robust and efficient online malicious intent detection. In the training stage, a high-capacity teacher model is trained on adversarially perturbed, retrieval-augmented inputs to learn robust decision boundaries over diverse and complex user queries. In the inference stage, a distillation scheduler transfers the teacher's knowledge into a compact student model, with a continually updated knowledge base collected online. At deployment, the compact student model leverages top-K similar safety exemplars retrieved from the online-updated knowledge base to enable both online and real-time malicious query detection. Evaluations across ten safety benchmarks demonstrate that ADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's performance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on out-of-distribution detection, while simultaneously delivering up to 5.6x lower latency at 300 queries per second (QPS) in real-time applications.
<div id='section'>Paperid: <span id='pid'>1410, <a href='https://arxiv.org/pdf/2509.11689.pdf' target='_blank'>https://arxiv.org/pdf/2509.11689.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeremiah Fadugba, Petru Manescu, Bolanle Oladejo, Delmiro Fernandez-Reyes, Philipp Berens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11689">Uncertainty-Aware Retinal Vessel Segmentation via Ensemble Distillation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is critical for reliable medical image segmentation, particularly in retinal vessel analysis, where accurate predictions are essential for diagnostic applications. Deep Ensembles, where multiple networks are trained individually, are widely used to improve medical image segmentation performance. However, training and testing costs increase with the number of ensembles. In this work, we propose Ensemble Distillation as a robust alternative to commonly used uncertainty estimation techniques by distilling the knowledge of multiple ensemble models into a single model. Through extensive experiments on the DRIVE and FIVES datasets, we demonstrate that Ensemble Distillation achieves comparable performance via calibration and segmentation metrics, while significantly reducing computational complexity. These findings suggest that Ensemble distillation provides an efficient and reliable approach for uncertainty estimation in the segmentation of the retinal vessels, making it a promising tool for medical imaging applications.
<div id='section'>Paperid: <span id='pid'>1411, <a href='https://arxiv.org/pdf/2509.08947.pdf' target='_blank'>https://arxiv.org/pdf/2509.08947.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yancheng Cai, Robert Wanat, Rafal Mantiuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08947">CameraVDP: Perceptual Display Assessment with Uncertainty Estimation via Camera and Visual Difference Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate measurement of images produced by electronic displays is critical for the evaluation of both traditional and computational displays. Traditional display measurement methods based on sparse radiometric sampling and fitting a model are inadequate for capturing spatially varying display artifacts, as they fail to capture high-frequency and pixel-level distortions. While cameras offer sufficient spatial resolution, they introduce optical, sampling, and photometric distortions. Furthermore, the physical measurement must be combined with a model of a visual system to assess whether the distortions are going to be visible. To enable perceptual assessment of displays, we propose a combination of a camera-based reconstruction pipeline with a visual difference predictor, which account for both the inaccuracy of camera measurements and visual difference prediction. The reconstruction pipeline combines HDR image stacking, MTF inversion, vignetting correction, geometric undistortion, homography transformation, and color correction, enabling cameras to function as precise display measurement instruments. By incorporating a Visual Difference Predictor (VDP), our system models the visibility of various stimuli under different viewing conditions for the human visual system. We validate the proposed CameraVDP framework through three applications: defective pixel detection, color fringing awareness, and display non-uniformity evaluation. Our uncertainty analysis framework enables the estimation of the theoretical upper bound for defect pixel detection performance and provides confidence intervals for VDP quality scores.
<div id='section'>Paperid: <span id='pid'>1412, <a href='https://arxiv.org/pdf/2509.08926.pdf' target='_blank'>https://arxiv.org/pdf/2509.08926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Waqar Ahmad, Evan Murphy, Vladimir A. Krylov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08926">Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Object re-identification (Re-ID) methods are highly sensitive to label noise, which typically leads to significant performance degradation. We address this challenge by reframing Re-ID as a supervised image similarity task and adopting a Siamese network architecture trained to capture discriminative pairwise relationships. Central to our approach is a novel statistical outlier detection (OD) framework, termed Beta-SOD (Beta mixture Similarity-based Outlier Detection), which models the distribution of cosine similarities between embedding pairs using a two-component Beta distribution mixture model. We establish a novel identifiability result for mixtures of two Beta distributions, ensuring that our learning task is well-posed. The proposed OD step complements the Re-ID architecture combining binary cross-entropy, contrastive, and cosine embedding losses that jointly optimize feature-level similarity learning. We demonstrate the effectiveness of Beta-SOD in de-noising and Re-ID tasks for person Re-ID, on CUHK03 and Market-1501 datasets, and vehicle Re-ID, on VeRi-776 dataset. Our method shows superior performance compared to the state-of-the-art methods across various noise levels (10-30\%), demonstrating both robustness and broad applicability in noisy Re-ID scenarios. The implementation of Beta-SOD is available at: github.com/waqar3411/Beta-SOD
<div id='section'>Paperid: <span id='pid'>1413, <a href='https://arxiv.org/pdf/2509.07415.pdf' target='_blank'>https://arxiv.org/pdf/2509.07415.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arslan Majal, Aamir Hussain Chughtai, Muhammad Tahir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07415">EMORF-II: Adaptive EM-based Outlier-Robust Filtering with Correlated Measurement Noise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a learning-based outlier-robust filter for a general setup where the measurement noise can be correlated. Since it is an enhanced version of EM-based outlier robust filter (EMORF), we call it as EMORF-II. As it is equipped with an additional powerful feature to learn the outlier characteristics during inference along with outlier-detection, EMORF-II has improved outlier-mitigation capability. Numerical experiments confirm performance gains as compared to the state-of-the-art methods in terms of accuracy with an increased computational overhead. However, thankfully the computational complexity order remains at par with other practical methods making it a useful choice for diverse applications.
<div id='section'>Paperid: <span id='pid'>1414, <a href='https://arxiv.org/pdf/2509.06918.pdf' target='_blank'>https://arxiv.org/pdf/2509.06918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tarhib Al Azad, Shahana Ibrahim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06918">Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution Detection via Loss Correction and Low-rank Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robust out-of-distribution (OOD) detection is an indispensable component of modern artificial intelligence (AI) systems, especially in safety-critical applications where models must identify inputs from unfamiliar classes not seen during training. While OOD detection has been extensively studied in the machine learning literature--with both post hoc and training-based approaches--its effectiveness under noisy training labels remains underexplored. Recent studies suggest that label noise can significantly degrade OOD performance, yet principled solutions to this issue are lacking. In this work, we demonstrate that directly combining existing label noise-robust methods with OOD detection strategies is insufficient to address this critical challenge. To overcome this, we propose a robust OOD detection framework that integrates loss correction techniques from the noisy label learning literature with low-rank and sparse decomposition methods from signal processing. Extensive experiments on both synthetic and real-world datasets demonstrate that our method significantly outperforms the state-of-the-art OOD detection techniques, particularly under severe noisy label settings.
<div id='section'>Paperid: <span id='pid'>1415, <a href='https://arxiv.org/pdf/2509.05877.pdf' target='_blank'>https://arxiv.org/pdf/2509.05877.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marzieh Ajirak, Anand Ravishankar, Petar M. Djuric
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05877">Uncertainty Quantification in Probabilistic Machine Learning Models: Theory, Methods, and Insights</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty Quantification (UQ) is essential in probabilistic machine learning models, particularly for assessing the reliability of predictions. In this paper, we present a systematic framework for estimating both epistemic and aleatoric uncertainty in probabilistic models. We focus on Gaussian Process Latent Variable Models and employ scalable Random Fourier Features-based Gaussian Processes to approximate predictive distributions efficiently. We derive a theoretical formulation for UQ, propose a Monte Carlo sampling-based estimation method, and conduct experiments to evaluate the impact of uncertainty estimation. Our results provide insights into the sources of predictive uncertainty and illustrate the effectiveness of our approach in quantifying the confidence in the predictions.
<div id='section'>Paperid: <span id='pid'>1416, <a href='https://arxiv.org/pdf/2508.21773.pdf' target='_blank'>https://arxiv.org/pdf/2508.21773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nattapong Kurpukdee, Adrian G. Bors
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21773">Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a realistic scenario for the unsupervised video learning where neither task boundaries nor labels are provided when learning a succession of tasks. We also provide a non-parametric learning solution for the under-explored problem of unsupervised video continual learning. Videos represent a complex and rich spatio-temporal media information, widely used in many applications, but which have not been sufficiently explored in unsupervised continual learning. Prior studies have only focused on supervised continual learning, relying on the knowledge of labels and task boundaries, while having labeled data is costly and not practical. To address this gap, we study the unsupervised video continual learning (uVCL). uVCL raises more challenges due to the additional computational and memory requirements of processing videos when compared to images. We introduce a general benchmark experimental protocol for uVCL by considering the learning of unstructured video data categories during each task. We propose to use the Kernel Density Estimation (KDE) of deep embedded video features extracted by unsupervised video transformer networks as a non-parametric probabilistic representation of the data. We introduce a novelty detection criterion for the incoming new task data, dynamically enabling the expansion of memory clusters, aiming to capture new knowledge when learning a succession of tasks. We leverage the use of transfer learning from the previous tasks as an initial state for the knowledge transfer to the current learning task. We found that the proposed methodology substantially enhances the performance of the model when successively learning many tasks. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, without using any labels or class boundaries.
<div id='section'>Paperid: <span id='pid'>1417, <a href='https://arxiv.org/pdf/2508.21773.pdf' target='_blank'>https://arxiv.org/pdf/2508.21773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nattapong Kurpukdee, Adrian G. Bors
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21773">Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a realistic scenario for the unsupervised video learning where neither task boundaries nor labels are provided when learning a succession of tasks. We also provide a non-parametric learning solution for the under-explored problem of unsupervised video continual learning. Videos represent a complex and rich spatio-temporal media information, widely used in many applications, but which have not been sufficiently explored in unsupervised continual learning. Prior studies have only focused on supervised continual learning, relying on the knowledge of labels and task boundaries, while having labeled data is costly and not practical. To address this gap, we study the unsupervised video continual learning (uVCL). uVCL raises more challenges due to the additional computational and memory requirements of processing videos when compared to images. We introduce a general benchmark experimental protocol for uVCL by considering the learning of unstructured video data categories during each task. We propose to use the Kernel Density Estimation (KDE) of deep embedded video features extracted by unsupervised video transformer networks as a non-parametric probabilistic representation of the data. We introduce a novelty detection criterion for the incoming new task data, dynamically enabling the expansion of memory clusters, aiming to capture new knowledge when learning a succession of tasks. We leverage the use of transfer learning from the previous tasks as an initial state for the knowledge transfer to the current learning task. We found that the proposed methodology substantially enhances the performance of the model when successively learning many tasks. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, without using any labels or class boundaries.
<div id='section'>Paperid: <span id='pid'>1418, <a href='https://arxiv.org/pdf/2508.18903.pdf' target='_blank'>https://arxiv.org/pdf/2508.18903.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aishwarya Venkataramanan, Joachim Denzler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18903">Distance-informed Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the Distance-informed Neural Process (DNP), a novel variant of Neural Processes that improves uncertainty estimation by combining global and distance-aware local latent structures. Standard Neural Processes (NPs) often rely on a global latent variable and struggle with uncertainty calibration and capturing local data dependencies. DNP addresses these limitations by introducing a global latent variable to model task-level variations and a local latent variable to capture input similarity within a distance-preserving latent space. This is achieved through bi-Lipschitz regularization, which bounds distortions in input relationships and encourages the preservation of relative distances in the latent space. This modeling approach allows DNP to produce better-calibrated uncertainty estimates and more effectively distinguish in- from out-of-distribution data. Empirical results demonstrate that DNP achieves strong predictive performance and improved uncertainty calibration across regression and classification tasks.
<div id='section'>Paperid: <span id='pid'>1419, <a href='https://arxiv.org/pdf/2508.15737.pdf' target='_blank'>https://arxiv.org/pdf/2508.15737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joonas JÃ¤rve, Karl Kaspar Haavel, Meelis Kull
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15737">Probability Density from Latent Diffusion Models for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite rapid advances in AI, safety remains the main bottleneck to deploying machine-learning systems. A critical safety component is out-of-distribution detection: given an input, decide whether it comes from the same distribution as the training data. In generative models, the most natural OOD score is the data likelihood. Actually, under the assumption of uniformly distributed OOD data, the likelihood is even the optimal OOD detector, as we show in this work. However, earlier work reported that likelihood often fails in practice, raising doubts about its usefulness. We explore whether, in practice, the representation space also suffers from the inability to learn good density estimation for OOD detection, or if it is merely a problem of the pixel space typically used in generative models. To test this, we trained a Variational Diffusion Model not on images, but on the representation space of a pre-trained ResNet-18 to assess the performance of our likelihood-based detector in comparison to state-of-the-art methods from the OpenOOD suite.
<div id='section'>Paperid: <span id='pid'>1420, <a href='https://arxiv.org/pdf/2508.15119.pdf' target='_blank'>https://arxiv.org/pdf/2508.15119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rachel Ma, Jingyi Qu, Andreea Bobu, Dylan Hadfield-Menell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15119">Open-Universe Assistance Games</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Embodied AI agents must infer and act in an interpretable way on diverse human goals and preferences that are not predefined. To formalize this setting, we introduce Open-Universe Assistance Games (OU-AGs), a framework where the agent must reason over an unbounded and evolving space of possible goals. In this context, we introduce GOOD (GOals from Open-ended Dialogue), a data-efficient, online method that extracts goals in the form of natural language during an interaction with a human, and infers a distribution over natural language goals. GOOD prompts an LLM to simulate users with different complex intents, using its responses to perform probabilistic inference over candidate goals. This approach enables rich goal representations and uncertainty estimation without requiring large offline datasets. We evaluate GOOD in a text-based grocery shopping domain and in a text-operated simulated household robotics environment (AI2Thor), using synthetic user profiles. Our method outperforms a baseline without explicit goal tracking, as confirmed by both LLM-based and human evaluations.
<div id='section'>Paperid: <span id='pid'>1421, <a href='https://arxiv.org/pdf/2508.06096.pdf' target='_blank'>https://arxiv.org/pdf/2508.06096.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric Jing, Abdeslam Boularias
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06096">Bounding Distributional Shifts in World Modeling through Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent work on visual world models shows significant promise in latent state dynamics obtained from pre-trained image backbones. However, most of the current approaches are sensitive to training quality, requiring near-complete coverage of the action and state space during training to prevent divergence during inference. To make a model-based planning algorithm more robust to the quality of the learned world model, we propose in this work to use a variational autoencoder as a novelty detector to ensure that proposed action trajectories during planning do not cause the learned model to deviate from the training data distribution. To evaluate the effectiveness of this approach, a series of experiments in challenging simulated robot environments was carried out, with the proposed method incorporated into a model-predictive control policy loop extending the DINO-WM architecture. The results clearly show that the proposed method improves over state-of-the-art solutions in terms of data efficiency.
<div id='section'>Paperid: <span id='pid'>1422, <a href='https://arxiv.org/pdf/2508.03108.pdf' target='_blank'>https://arxiv.org/pdf/2508.03108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tarhib Al Azad, Faizul Rakib Sayem, Shahana Ibrahim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03108">Pseudo-label Induced Subspace Representation Learning for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection lies at the heart of robust artificial intelligence (AI), aiming to identify samples from novel distributions beyond the training set. Recent approaches have exploited feature representations as distinguishing signatures for OOD detection. However, most existing methods rely on restrictive assumptions on the feature space that limit the separability between in-distribution (ID) and OOD samples. In this work, we propose a novel OOD detection framework based on a pseudo-label-induced subspace representation, that works under more relaxed and natural assumptions compared to existing feature-based techniques. In addition, we introduce a simple yet effective learning criterion that integrates a cross-entropy-based ID classification loss with a subspace distance-based regularization loss to enhance ID-OOD separability. Extensive experiments validate the effectiveness of our framework.
<div id='section'>Paperid: <span id='pid'>1423, <a href='https://arxiv.org/pdf/2507.21521.pdf' target='_blank'>https://arxiv.org/pdf/2507.21521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Athmanarayanan Lakshmi Narayanan, Amrutha Machireddy, Ranganath Krishnan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21521">Optimizing Active Learning in Vision-Language Models via Parameter-Efficient Uncertainty Calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active Learning (AL) has emerged as a powerful approach for minimizing labeling costs by selectively sampling the most informative data for neural network model development. Effective AL for large-scale vision-language models necessitates addressing challenges in uncertainty estimation and efficient sampling given the vast number of parameters involved. In this work, we introduce a novel parameter-efficient learning methodology that incorporates uncertainty calibration loss within the AL framework. We propose a differentiable loss function that promotes uncertainty calibration for effectively selecting fewer and most informative data samples for fine-tuning. Through extensive experiments across several datasets and vision backbones, we demonstrate that our solution can match and exceed the performance of complex feature-based sampling techniques while being computationally very efficient. Additionally, we investigate the efficacy of Prompt learning versus Low-rank adaptation (LoRA) in sample selection, providing a detailed comparative analysis of these methods in the context of efficient AL.
<div id='section'>Paperid: <span id='pid'>1424, <a href='https://arxiv.org/pdf/2507.18106.pdf' target='_blank'>https://arxiv.org/pdf/2507.18106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JinYoung Kim, DaeUng Jo, Kimin Yun, Jeonghyo Song, Youngjoon Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18106">Distributional Uncertainty for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating uncertainty from deep neural networks is a widely used approach for detecting out-of-distribution (OoD) samples, which typically exhibit high predictive uncertainty. However, conventional methods such as Monte Carlo (MC) Dropout often focus solely on either model or data uncertainty, failing to align with the semantic objective of OoD detection. To address this, we propose the Free-Energy Posterior Network, a novel framework that jointly models distributional uncertainty and identifying OoD and misclassified regions using free energy. Our method introduces two key contributions: (1) a free-energy-based density estimator parameterized by a Beta distribution, which enables fine-grained uncertainty estimation near ambiguous or unseen regions; and (2) a loss integrated within a posterior network, allowing direct uncertainty estimation from learned parameters without requiring stochastic sampling. By integrating our approach with the residual prediction branch (RPL) framework, the proposed method goes beyond post-hoc energy thresholding and enables the network to learn OoD regions by leveraging the variance of the Beta distribution, resulting in a semantically meaningful and computationally efficient solution for uncertainty-aware segmentation. We validate the effectiveness of our method on challenging real-world benchmarks, including Fishyscapes, RoadAnomaly, and Segment-Me-If-You-Can.
<div id='section'>Paperid: <span id='pid'>1425, <a href='https://arxiv.org/pdf/2507.16424.pdf' target='_blank'>https://arxiv.org/pdf/2507.16424.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hui Xiang, Jinqiao Shi, Ting Zhang, Xiaojie Zhao, Yong Liu, Yong Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16424">PromptAL: Sample-Aware Dynamic Soft Prompts for Few-Shot Active Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active learning (AL) aims to optimize model training and reduce annotation costs by selecting the most informative samples for labeling. Typically, AL methods rely on the empirical distribution of labeled data to define the decision boundary and perform uncertainty or diversity estimation, subsequently identifying potential high-quality samples. In few-shot scenarios, the empirical distribution often diverges significantly from the target distribution, causing the decision boundary to shift away from its optimal position. However, existing methods overlook the role of unlabeled samples in enhancing the empirical distribution to better align with the target distribution, resulting in a suboptimal decision boundary and the selection of samples that inadequately represent the target distribution. To address this, we propose a hybrid AL framework, termed \textbf{PromptAL} (Sample-Aware Dynamic Soft \textbf{Prompts} for Few-Shot \textbf{A}ctive \textbf{L}earning). This framework accounts for the contribution of each unlabeled data point in aligning the current empirical distribution with the target distribution, thereby optimizing the decision boundary. Specifically, PromptAL first leverages unlabeled data to construct sample-aware dynamic soft prompts that adjust the model's predictive distribution and decision boundary. Subsequently, based on the adjusted decision boundary, it integrates uncertainty estimation with both global and local diversity to select high-quality samples that more accurately represent the target distribution. Experimental results on six in-domain and three out-of-domain datasets show that PromptAL achieves superior performance over nine baselines. Our codebase is openly accessible.
<div id='section'>Paperid: <span id='pid'>1426, <a href='https://arxiv.org/pdf/2507.07714.pdf' target='_blank'>https://arxiv.org/pdf/2507.07714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julio Garrido, Javier Vales, Diego Silva-MuÃ±iz, Enrique Riveiro, Pablo LÃ³pez-Matencio, JosuÃ© Rivera-Andrade
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07714">Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cable-Driven Parallel Robots (CDPRs) are increasingly used for load manipulation tasks involving predefined toolpaths with intermediate stops. At each stop, where the platform maintains a fixed pose and the motors keep the cables under tension, the system must evaluate whether it is safe to proceed by detecting anomalies that could compromise performance (e.g., wind gusts or cable impacts). This paper investigates whether anomalies can be detected using only motor torque data, without additional sensors. It introduces an adaptive, unsupervised outlier detection algorithm based on Gaussian Mixture Models (GMMs) to identify anomalies from torque signals. The method starts with a brief calibration period, just a few seconds, during which a GMM is fit on known anomaly-free data. Real-time torque measurements are then evaluated using Mahalanobis distance from the GMM, with statistically derived thresholds triggering anomaly flags. Model parameters are periodically updated using the latest segments identified as anomaly-free to adapt to changing conditions. Validation includes 14 long-duration test sessions simulating varied wind intensities. The proposed method achieves a 100% true positive rate and 95.4% average true negative rate, with 1-second detection latency. Comparative evaluation against power threshold and non-adaptive GMM methods indicates higher robustness to drift and environmental variation.
<div id='section'>Paperid: <span id='pid'>1427, <a href='https://arxiv.org/pdf/2507.06624.pdf' target='_blank'>https://arxiv.org/pdf/2507.06624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dazhi Fu, Jicong Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06624">UniOD: A Universal Model for Outlier Detection across Diverse Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) seeks to distinguish inliers and outliers in completely unlabeled datasets and plays a vital role in science and engineering. Most existing OD methods require troublesome dataset-specific hyperparameter tuning and costly model training before they can be deployed to identify outliers. In this work, we propose UniOD, a universal OD framework that leverages labeled datasets to train a single model capable of detecting outliers of datasets from diverse domains. Specifically, UniOD converts each dataset into multiple graphs, produces consistent node features, and frames outlier detection as a node-classification task, and is able to generalize to unseen domains. As a result, UniOD avoids effort on model selection and hyperparameter tuning, reduces computational cost, and effectively utilizes the knowledge from historical datasets, which improves the convenience and accuracy in real applications. We evaluate UniOD on 15 benchmark OD datasets against 15 state-of-the-art baselines, demonstrating its effectiveness.
<div id='section'>Paperid: <span id='pid'>1428, <a href='https://arxiv.org/pdf/2507.05904.pdf' target='_blank'>https://arxiv.org/pdf/2507.05904.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Astrid Franz, Frederik Hoppe, Marianne Michaelis, Udo GÃ¶bel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05904">Universal Embeddings of Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tabular data in relational databases represents a significant portion of industrial data. Hence, analyzing and interpreting tabular data is of utmost importance. Application tasks on tabular data are manifold and are often not specified when setting up an industrial database. To address this, we present a novel framework for generating universal, i.e., task-independent embeddings of tabular data for performing downstream tasks without predefined targets. Our method transforms tabular data into a graph structure, leverages Graph Auto-Encoders to create entity embeddings, which are subsequently aggregated to obtain embeddings for each table row, i.e., each data sample. This two-step approach has the advantage that unseen samples, consisting of similar entities, can be embedded without additional training. Downstream tasks such as regression, classification or outlier detection, can then be performed by applying a distance-based similarity measure in the embedding space. Experiments on real-world datasets demonstrate that our method achieves superior performance compared to existing universal tabular data embedding techniques.
<div id='section'>Paperid: <span id='pid'>1429, <a href='https://arxiv.org/pdf/2507.01541.pdf' target='_blank'>https://arxiv.org/pdf/2507.01541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ãlvaro Zaera, Diana Nicoleta Popa, Ivan Sekulic, Paolo Rosso
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01541">Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-scope (OOS) intent detection is a critical challenge in task-oriented dialogue systems (TODS), as it ensures robustness to unseen and ambiguous queries. In this work, we propose a novel but simple modular framework that combines uncertainty modeling with fine-tuned large language models (LLMs) for efficient and accurate OOS detection. The first step applies uncertainty estimation to the output of an in-scope intent detection classifier, which is currently deployed in a real-world TODS handling tens of thousands of user interactions daily. The second step then leverages an emerging LLM-based approach, where a fine-tuned LLM is triggered to make a final decision on instances with high uncertainty. Unlike prior approaches, our method effectively balances computational efficiency and performance, combining traditional approaches with LLMs and yielding state-of-the-art results on key OOS detection benchmarks, including real-world OOS data acquired from a deployed TODS.
<div id='section'>Paperid: <span id='pid'>1430, <a href='https://arxiv.org/pdf/2507.00866.pdf' target='_blank'>https://arxiv.org/pdf/2507.00866.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas Chris Ferrao, Dickson Dias, Pranav Naik, Glory D'Cruz, Anish Naik, Siya Khandeparkar, Manisha Gokuldas Fal Dessai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00866">Template-Fitting Meets Deep Learning: Redshift Estimation Using Physics-Guided Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate photometric redshift estimation is critical for observational cosmology, especially in large-scale surveys where spectroscopic measurements are impractical. Traditional approaches include template fitting and machine learning, each with distinct strengths and limitations. We present a hybrid method that integrates template fitting with deep learning using physics-guided neural networks. By embedding spectral energy distribution templates into the network architecture, our model encodes physical priors into the training process. The system employs a multimodal design, incorporating cross-attention mechanisms to fuse photometric and image data, along with Bayesian layers for uncertainty estimation. We evaluate our model on the publicly available PREML dataset, which includes approximately 400,000 galaxies from the Hyper Suprime-Cam PDR3 release, with 5-band photometry, multi-band imaging, and spectroscopic redshifts. Our approach achieves an RMS error of 0.0507, a 3-sigma catastrophic outlier rate of 0.13%, and a bias of 0.0028. The model satisfies two of the three LSST photometric redshift requirements for redshifts below 3. These results highlight the potential of combining physically motivated templates with data-driven models for robust redshift estimation in upcoming cosmological surveys.
<div id='section'>Paperid: <span id='pid'>1431, <a href='https://arxiv.org/pdf/2507.00756.pdf' target='_blank'>https://arxiv.org/pdf/2507.00756.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Xing, Kai Zhe Boey, Gordon Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00756">Towards Open-World Human Action Segmentation Using Graph Convolutional Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human-object interaction segmentation is a fundamental task of daily activity understanding, which plays a crucial role in applications such as assistive robotics, healthcare, and autonomous systems. Most existing learning-based methods excel in closed-world action segmentation, they struggle to generalize to open-world scenarios where novel actions emerge. Collecting exhaustive action categories for training is impractical due to the dynamic diversity of human activities, necessitating models that detect and segment out-of-distribution actions without manual annotation. To address this issue, we formally define the open-world action segmentation problem and propose a structured framework for detecting and segmenting unseen actions. Our framework introduces three key innovations: 1) an Enhanced Pyramid Graph Convolutional Network (EPGCN) with a novel decoder module for robust spatiotemporal feature upsampling. 2) Mixup-based training to synthesize out-of-distribution data, eliminating reliance on manual annotations. 3) A novel Temporal Clustering loss that groups in-distribution actions while distancing out-of-distribution samples.
  We evaluate our framework on two challenging human-object interaction recognition datasets: Bimanual Actions and 2 Hands and Object (H2O) datasets. Experimental results demonstrate significant improvements over state-of-the-art action segmentation models across multiple open-set evaluation metrics, achieving 16.9% and 34.6% relative gains in open-set segmentation (F1@50) and out-of-distribution detection performances (AUROC), respectively. Additionally, we conduct an in-depth ablation study to assess the impact of each proposed component, identifying the optimal framework configuration for open-world action segmentation.
<div id='section'>Paperid: <span id='pid'>1432, <a href='https://arxiv.org/pdf/2506.22511.pdf' target='_blank'>https://arxiv.org/pdf/2506.22511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingting Zhou, Feng Zhang, Haoyang Fu, Baoxiang Pan, Renhe Zhang, Feng Lu, Zhixin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22511">Lighting the Night with Generative Artificial Intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The visible light reflectance data from geostationary satellites is crucial for meteorological observations and plays an important role in weather monitoring and forecasting. However, due to the lack of visible light at night, it is impossible to conduct continuous all-day weather observations using visible light reflectance data. This study pioneers the use of generative diffusion models to address this limitation. Based on the multi-band thermal infrared brightness temperature data from the Advanced Geostationary Radiation Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we developed a high-precision visible light reflectance generative model, called Reflectance Diffusion (RefDiff), which enables 0.47~Î¼\mathrm{m}, 0.65~Î¼\mathrm{m}, and 0.825~Î¼\mathrm{m} bands visible light reflectance generation at night. Compared to the classical models, RefDiff not only significantly improves accuracy through ensemble averaging but also provides uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90, with particularly significant improvements in areas with complex cloud structures and thick clouds. The model's nighttime generation capability was validated using VIIRS nighttime product, demonstrating comparable performance to its daytime counterpart. In summary, this research has made substantial progress in the ability to generate visible light reflectance at night, with the potential to expand the application of nighttime visible light data.
<div id='section'>Paperid: <span id='pid'>1433, <a href='https://arxiv.org/pdf/2506.17672.pdf' target='_blank'>https://arxiv.org/pdf/2506.17672.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weiming Mai, Jie Gao, Oded Cats
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17672">Learning Personalized Utility Functions for Drivers in Ride-hailing Systems Using Ensemble Hypernetworks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In ride-hailing systems, drivers decide whether to accept or reject ride requests based on factors such as order characteristics, traffic conditions, and personal preferences. Accurately predicting these decisions is essential for improving the efficiency and reliability of these systems. Traditional models, such as the Random Utility Maximization (RUM) approach, typically predict drivers' decisions by assuming linear correlations among attributes. However, these models often fall short because they fail to account for non-linear interactions between attributes and do not cater to the unique, personalized preferences of individual drivers. In this paper, we develop a method for learning personalized utility functions using hypernetwork and ensemble learning. Hypernetworks dynamically generate weights for a linear utility function based on trip request data and driver profiles, capturing the non-linear relationships. An ensemble of hypernetworks trained on different data segments further improve model adaptability and generalization by introducing controlled randomness, thereby reducing over-fitting. We validate the performance of our ensemble hypernetworks model in terms of prediction accuracy and uncertainty estimation in a real-world dataset. The results demonstrate that our approach not only accurately predicts each driver's utility but also effectively balances the needs for explainability and uncertainty quantification. Additionally, our model serves as a powerful tool for revealing the personalized preferences of different drivers, clearly illustrating which attributes largely impact their rider acceptance decisions.
<div id='section'>Paperid: <span id='pid'>1434, <a href='https://arxiv.org/pdf/2506.14497.pdf' target='_blank'>https://arxiv.org/pdf/2506.14497.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Franco Matzkin, Agostina Larrazabal, Diego H Milone, Jose Dolz, Enzo Ferrante
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14497">Towards Reliable WMH Segmentation under Domain Shift: An Application Study using Maximum Entropy Regularization to Improve Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate segmentation of white matter hyperintensities (WMH) is crucial for clinical decision-making, particularly in the context of multiple sclerosis. However, domain shifts, such as variations in MRI machine types or acquisition parameters, pose significant challenges to model calibration and uncertainty estimation. This study investigates the impact of domain shift on WMH segmentation by proposing maximum-entropy regularization techniques to enhance model calibration and uncertainty estimation, with the purpose of identifying errors post-deployment using predictive uncertainty as a proxy measure that does not require ground-truth labels. To do this, we conducted experiments using a U-Net architecture to evaluate these regularization schemes on two publicly available datasets, assessing performance with the Dice coefficient, expected calibration error, and entropy-based uncertainty estimates. Our results show that entropy-based uncertainty estimates can anticipate segmentation errors, and that maximum-entropy regularization further strengthens the correlation between uncertainty and segmentation performance while also improving model calibration under domain shift.
<div id='section'>Paperid: <span id='pid'>1435, <a href='https://arxiv.org/pdf/2506.14194.pdf' target='_blank'>https://arxiv.org/pdf/2506.14194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sudeepta Mondal, Zhuolin Jiang, Ganesh Sundaramoorthi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14194">A Variational Information Theoretic Approach to Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a theory for the construction of out-of-distribution (OOD) detection features for neural networks. We introduce random features for OOD through a novel information-theoretic loss functional consisting of two terms, the first based on the KL divergence separates resulting in-distribution (ID) and OOD feature distributions and the second term is the Information Bottleneck, which favors compressed features that retain the OOD information. We formulate a variational procedure to optimize the loss and obtain OOD features. Based on assumptions on OOD distributions, one can recover properties of existing OOD features, i.e., shaping functions. Furthermore, we show that our theory can predict a new shaping function that out-performs existing ones on OOD benchmarks. Our theory provides a general framework for constructing a variety of new features with clear explainability.
<div id='section'>Paperid: <span id='pid'>1436, <a href='https://arxiv.org/pdf/2506.09270.pdf' target='_blank'>https://arxiv.org/pdf/2506.09270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rodrigo Carrasco-Davis, Sebastian Lee, Claudia Clopath, Will Dabney
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09270">Uncertainty Prioritized Experience Replay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prioritized experience replay, which improves sample efficiency by selecting relevant transitions to update parameter estimates, is a crucial component of contemporary value-based deep reinforcement learning models. Typically, transitions are prioritized based on their temporal difference error. However, this approach is prone to favoring noisy transitions, even when the value estimation closely approximates the target mean. This phenomenon resembles the noisy TV problem postulated in the exploration literature, in which exploration-guided agents get stuck by mistaking noise for novelty. To mitigate the disruptive effects of noise in value estimation, we propose using epistemic uncertainty estimation to guide the prioritization of transitions from the replay buffer. Epistemic uncertainty quantifies the uncertainty that can be reduced by learning, hence reducing transitions sampled from the buffer generated by unpredictable random processes. We first illustrate the benefits of epistemic uncertainty prioritized replay in two tabular toy models: a simple multi-arm bandit task, and a noisy gridworld. Subsequently, we evaluate our prioritization scheme on the Atari suite, outperforming quantile regression deep Q-learning benchmarks; thus forging a path for the use of uncertainty prioritized replay in reinforcement learning agents.
<div id='section'>Paperid: <span id='pid'>1437, <a href='https://arxiv.org/pdf/2506.01994.pdf' target='_blank'>https://arxiv.org/pdf/2506.01994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wanshan Cui, Yejin Jeong, Inwook Song, Gyuri Kim, Minsang Kwon, Donghun Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01994">Re-experiment Smart: a Novel Method to Enhance Data-driven Prediction of Mechanical Properties of Epoxy Polymers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of polymer material properties through data-driven approaches greatly accelerates novel material development by reducing redundant experiments and trial-and-error processes. However, inevitable outliers in empirical measurements can severely skew machine learning results, leading to erroneous prediction models and suboptimal material designs. To address this limitation, we propose a novel approach to enhance dataset quality efficiently by integrating multi-algorithm outlier detection with selective re-experimentation of unreliable outlier cases. To validate the empirical effectiveness of the approach, we systematically construct a new dataset containing 701 measurements of three key mechanical properties: glass transition temperature ($T_g$), tan $Î´$ peak, and crosslinking density ($v_{c}$). To demonstrate its general applicability, we report the performance improvements across multiple machine learning models, including Elastic Net, SVR, Random Forest, and TPOT, to predict the three key properties. Our method reliably reduces prediction error (RMSE) and significantly improves accuracy with minimal additional experimental work, requiring only about 5% of the dataset to be re-measured. These findings highlight the importance of data quality enhancement in achieving reliable machine learning applications in polymer science and present a scalable strategy for improving predictive reliability in materials science.
<div id='section'>Paperid: <span id='pid'>1438, <a href='https://arxiv.org/pdf/2505.19750.pdf' target='_blank'>https://arxiv.org/pdf/2505.19750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huaiyuan Zhang, Hang Chen, Yu Cheng, Shunyi Wu, Linghao Sun, Linao Han, Zeyu Shi, Lei Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19750">SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this technical report, we present our solution to the CVPR 2025 Visual Anomaly and Novelty Detection (VAND) 3.0 Workshop Challenge Track 1: Adapt & Detect: Robust Anomaly Detection in Real-World Applications. In real-world industrial anomaly detection, it is crucial to accurately identify anomalies with physical complexity, such as transparent or reflective surfaces, occlusions, and low-contrast contaminations. The recently proposed MVTec AD 2 dataset significantly narrows the gap between publicly available benchmarks and anomalies found in real-world industrial environments. To address the challenges posed by this dataset--such as complex and varying lighting conditions and real anomalies with large scale differences--we propose a fully training-free anomaly detection and segmentation method based on feature extraction using the DINOv2 model named SuperAD. Our method carefully selects a small number of normal reference images and constructs a memory bank by leveraging the strong representational power of DINOv2. Anomalies are then segmented by performing nearest neighbor matching between test image features and the memory bank. Our method achieves competitive results on both test sets of the MVTec AD 2 dataset.
<div id='section'>Paperid: <span id='pid'>1439, <a href='https://arxiv.org/pdf/2505.15443.pdf' target='_blank'>https://arxiv.org/pdf/2505.15443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Artem Zabolotnyi, Roman Makarov, Mile Mitrovic, Polina Proskura, Oleg Travkin, Roman Alferov, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15443">AdUE: Improving uncertainty estimation head for LoRA adapters in LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation remains a critical challenge in adapting pre-trained language models to classification tasks, particularly under parameter-efficient fine-tuning approaches such as adapters. We introduce AdUE1, an efficient post-hoc uncertainty estimation (UE) method, to enhance softmax-based estimates. Our approach (1) uses a differentiable approximation of the maximum function and (2) applies additional regularization through L2-SP, anchoring the fine-tuned head weights and regularizing the model. Evaluations on five NLP classification datasets across four language models (RoBERTa, ELECTRA, LLaMA-2, Qwen) demonstrate that our method consistently outperforms established baselines such as Mahalanobis distance and softmax response. Our approach is lightweight (no base-model changes) and produces better-calibrated confidence.
<div id='section'>Paperid: <span id='pid'>1440, <a href='https://arxiv.org/pdf/2505.08639.pdf' target='_blank'>https://arxiv.org/pdf/2505.08639.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyi Zhou, Dongzhuo Liu, Songtao Guo, Yuanyuan Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08639">Robust Indoor Localization via Conformal Methods and Variational Bayesian Adaptive Filtering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Indoor localization is critical for IoT applications, yet challenges such as non-Gaussian noise, environmental interference, and measurement outliers hinder the robustness of traditional methods. Existing approaches, including Kalman filtering and its variants, often rely on Gaussian assumptions or static thresholds, limiting adaptability in dynamic environments. This paper proposes a hierarchical robust framework integrating Variational Bayesian (VB) parameter learning, Huber M-estimation, and Conformal Outlier Detection (COD) to address these limitations. First, VB inference jointly estimates state and noise parameters, adapting to time-varying uncertainties. Second, Huber-based robust filtering suppresses mild outliers while preserving Gaussian efficiency. Third, COD provides statistical guarantees for outlier detection via dynamically calibrated thresholds, ensuring a user-controlled false alarm rate. Theoretically, we prove the Semi-positive Definiteness of Huber-based Kalman filtering covariance and the coverage of sliding window conformal prediction. Experiments on geomagnetic fingerprint datasets demonstrate significant improvements: fingerprint matching accuracy increases from 81.25% to 93.75%, and positioning errors decrease from 0.62-6.87 m to 0.03-0.35 m. Comparative studies further validate the framework's robustness, showing consistent performance gains under non-Gaussian noise and outlier conditions.
<div id='section'>Paperid: <span id='pid'>1441, <a href='https://arxiv.org/pdf/2505.06516.pdf' target='_blank'>https://arxiv.org/pdf/2505.06516.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yilin Dong, Tianyun Zhu, Xinde Li, Jean Dezert, Rigui Zhou, Changming Zhu, Lei Cao, Shuzhi Sam Ge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06516">Quantum Conflict Measurement in Decision Making for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantum Dempster-Shafer Theory (QDST) uses quantum interference effects to derive a quantum mass function (QMF) as a fuzzy metric type from information obtained from various data sources. In addition, QDST uses quantum parallel computing to speed up computation. Nevertheless, the effective management of conflicts between multiple QMFs in QDST is a challenging question. This work aims to address this problem by proposing a Quantum Conflict Indicator (QCI) that measures the conflict between two QMFs in decision-making. Then, the properties of the QCI are carefully investigated. The obtained results validate its compliance with desirable conflict measurement properties such as non-negativity, symmetry, boundedness, extreme consistency and insensitivity to refinement. We then apply the proposed QCI in conflict fusion methods and compare its performance with several commonly used fusion approaches. This comparison demonstrates the superiority of the QCI-based conflict fusion method. Moreover, the Class Description Domain Space (C-DDS) and its optimized version, C-DDS+ by utilizing the QCI-based fusion method, are proposed to address the Out-of-Distribution (OOD) detection task. The experimental results show that the proposed approach gives better OOD performance with respect to several state-of-the-art baseline OOD detection methods. Specifically, it achieves an average increase in Area Under the Receiver Operating Characteristic Curve (AUC) of 1.2% and a corresponding average decrease in False Positive Rate at 95% True Negative Rate (FPR95) of 5.4% compared to the optimal baseline method.
<div id='section'>Paperid: <span id='pid'>1442, <a href='https://arxiv.org/pdf/2505.02402.pdf' target='_blank'>https://arxiv.org/pdf/2505.02402.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thibault de Surrel, Florian Yger, Fabien Lotte, Sylvain Chevallier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02402">A probabilistic view on Riemannian machine learning models for SPD matrices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of this paper is to show how different machine learning tools on the Riemannian manifold $\mathcal{P}_d$ of Symmetric Positive Definite (SPD) matrices can be united under a probabilistic framework. For this, we will need several Gaussian distributions defined on $\mathcal{P}_d$. We will show how popular classifiers on $\mathcal{P}_d$ can be reinterpreted as Bayes Classifiers using these Gaussian distributions. These distributions will also be used for outlier detection and dimension reduction. By showing that those distributions are pervasive in the tools used on $\mathcal{P}_d$, we allow for other machine learning tools to be extended to $\mathcal{P}_d$.
<div id='section'>Paperid: <span id='pid'>1443, <a href='https://arxiv.org/pdf/2504.21247.pdf' target='_blank'>https://arxiv.org/pdf/2504.21247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangyang Qu, Dazhi Fu, Jicong Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.21247">Subject Information Extraction for Novelty Detection with Domain Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised novelty detection (UND), aimed at identifying novel samples, is essential in fields like medical diagnosis, cybersecurity, and industrial quality control. Most existing UND methods assume that the training data and testing normal data originate from the same domain and only consider the distribution variation between training data and testing data. However, in real scenarios, it is common for normal testing and training data to originate from different domains, a challenge known as domain shift. The discrepancies between training and testing data often lead to incorrect classification of normal data as novel by existing methods. A typical situation is that testing normal data and training data describe the same subject, yet they differ in the background conditions. To address this problem, we introduce a novel method that separates subject information from background variation encapsulating the domain information to enhance detection performance under domain shifts. The proposed method minimizes the mutual information between the representations of the subject and background while modelling the background variation using a deep Gaussian mixture model, where the novelty detection is conducted on the subject representations solely and hence is not affected by the variation of domains. Extensive experiments demonstrate that our model generalizes effectively to unseen domains and significantly outperforms baseline methods, especially under substantial domain shifts between training and testing data.
<div id='section'>Paperid: <span id='pid'>1444, <a href='https://arxiv.org/pdf/2504.14704.pdf' target='_blank'>https://arxiv.org/pdf/2504.14704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Yang, Qi Yu, Travis Desel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.14704">Can We Ignore Labels In Out of Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection methods have recently become more prominent, serving as a core element in safety-critical autonomous systems. One major purpose of OOD detection is to reject invalid inputs that could lead to unpredictable errors and compromise safety. Due to the cost of labeled data, recent works have investigated the feasibility of self-supervised learning (SSL) OOD detection, unlabeled OOD detection, and zero shot OOD detection. In this work, we identify a set of conditions for a theoretical guarantee of failure in unlabeled OOD detection algorithms from an information-theoretic perspective. These conditions are present in all OOD tasks dealing with real-world data: I) we provide theoretical proof of unlabeled OOD detection failure when there exists zero mutual information between the learning objective and the in-distribution labels, a.k.a. 'label blindness', II) we define a new OOD task - Adjacent OOD detection - that tests for label blindness and accounts for a previously ignored safety gap in all OOD detection benchmarks, and III) we perform experiments demonstrating that existing unlabeled OOD methods fail under conditions suggested by our label blindness theory and analyze the implications for future research in unlabeled OOD methods.
<div id='section'>Paperid: <span id='pid'>1445, <a href='https://arxiv.org/pdf/2504.14704.pdf' target='_blank'>https://arxiv.org/pdf/2504.14704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Yang, Qi Yu, Travis Desell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.14704">Can We Ignore Labels In Out of Distribution Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection methods have recently become more prominent, serving as a core element in safety-critical autonomous systems. One major purpose of OOD detection is to reject invalid inputs that could lead to unpredictable errors and compromise safety. Due to the cost of labeled data, recent works have investigated the feasibility of self-supervised learning (SSL) OOD detection, unlabeled OOD detection, and zero shot OOD detection. In this work, we identify a set of conditions for a theoretical guarantee of failure in unlabeled OOD detection algorithms from an information-theoretic perspective. These conditions are present in all OOD tasks dealing with real-world data: I) we provide theoretical proof of unlabeled OOD detection failure when there exists zero mutual information between the learning objective and the in-distribution labels, a.k.a. 'label blindness', II) we define a new OOD task - Adjacent OOD detection - that tests for label blindness and accounts for a previously ignored safety gap in all OOD detection benchmarks, and III) we perform experiments demonstrating that existing unlabeled OOD methods fail under conditions suggested by our label blindness theory and analyze the implications for future research in unlabeled OOD methods.
<div id='section'>Paperid: <span id='pid'>1446, <a href='https://arxiv.org/pdf/2504.13465.pdf' target='_blank'>https://arxiv.org/pdf/2504.13465.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Duy A. Nguyen, Quan Huu Do, Khoa D. Doan, Minh N. Do
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13465">Are you SURE? Enhancing Multimodal Pretraining with Missing Modalities through Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal learning has demonstrated incredible successes by integrating diverse data sources, yet it often relies on the availability of all modalities - an assumption that rarely holds in real-world applications. Pretrained multimodal models, while effective, struggle when confronted with small-scale and incomplete datasets (i.e., missing modalities), limiting their practical applicability. Previous studies on reconstructing missing modalities have overlooked the reconstruction's potential unreliability, which could compromise the quality of the final outputs. We present SURE (Scalable Uncertainty and Reconstruction Estimation), a novel framework that extends the capabilities of pretrained multimodal models by introducing latent space reconstruction and uncertainty estimation for both reconstructed modalities and downstream tasks. Our method is architecture-agnostic, reconstructs missing modalities, and delivers reliable uncertainty estimates, improving both interpretability and performance. SURE introduces a unique Pearson Correlation-based loss and applies statistical error propagation in deep networks for the first time, allowing precise quantification of uncertainties from missing data and model predictions. Extensive experiments across tasks such as sentiment analysis, genre classification, and action recognition show that SURE consistently achieves state-of-the-art performance, ensuring robust predictions even in the presence of incomplete data.
<div id='section'>Paperid: <span id='pid'>1447, <a href='https://arxiv.org/pdf/2504.11307.pdf' target='_blank'>https://arxiv.org/pdf/2504.11307.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sonia Laguna, Lin Zhang, Can Deniz Bezek, Monika Farkas, Dieter Schweizer, Rahel A. Kubik-Huch, Orcun Goksel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11307">Uncertainty Estimation for Trust Attribution to Speed-of-Sound Reconstruction with Variational Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speed-of-sound (SoS) is a biomechanical characteristic of tissue, and its imaging can provide a promising biomarker for diagnosis. Reconstructing SoS images from ultrasound acquisitions can be cast as a limited-angle computed-tomography problem, with Variational Networks being a promising model-based deep learning solution. Some acquired data frames may, however, get corrupted by noise due to, e.g., motion, lack of contact, and acoustic shadows, which in turn negatively affects the resulting SoS reconstructions. We propose to use the uncertainty in SoS reconstructions to attribute trust to each individual acquired frame. Given multiple acquisitions, we then use an uncertainty based automatic selection among these retrospectively, to improve diagnostic decisions. We investigate uncertainty estimation based on Monte Carlo Dropout and Bayesian Variational Inference. We assess our automatic frame selection method for differential diagnosis of breast cancer, distinguishing between benign fibroadenoma and malignant carcinoma. We evaluate 21 lesions classified as BI-RADS~4, which represents suspicious cases for probable malignancy. The most trustworthy frame among four acquisitions of each lesion was identified using uncertainty based criteria. Selecting a frame informed by uncertainty achieved an area under curve of 76% and 80% for Monte Carlo Dropout and Bayesian Variational Inference, respectively, superior to any uncertainty-uninformed baselines with the best one achieving 64%. A novel use of uncertainty estimation is proposed for selecting one of multiple data acquisitions for further processing and decision making.
<div id='section'>Paperid: <span id='pid'>1448, <a href='https://arxiv.org/pdf/2504.04583.pdf' target='_blank'>https://arxiv.org/pdf/2504.04583.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal TeÅ¡nar, Bilal Wehbe, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04583">Modeling of AUV Dynamics with Limited Resources: Efficient Online Learning Using Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning proves effective in constructing dynamics models from data, especially for underwater vehicles. Continuous refinement of these models using incoming data streams, however, often requires storage of an overwhelming amount of redundant data. This work investigates the use of uncertainty in the selection of data points to rehearse in online learning when storage capacity is constrained. The models are learned using an ensemble of multilayer perceptrons as they perform well at predicting epistemic uncertainty. We present three novel approaches: the Threshold method, which excludes samples with uncertainty below a specified threshold, the Greedy method, designed to maximize uncertainty among the stored points, and Threshold-Greedy, which combines the previous two approaches. The methods are assessed on data collected by an underwater vehicle Dagon. Comparison with baselines reveals that the Threshold exhibits enhanced stability throughout the learning process and also yields a model with the least cumulative testing loss. We also conducted detailed analyses on the impact of model parameters and storage size on the performance of the models, as well as a comparison of three different uncertainty estimation methods.
<div id='section'>Paperid: <span id='pid'>1449, <a href='https://arxiv.org/pdf/2503.18817.pdf' target='_blank'>https://arxiv.org/pdf/2503.18817.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeonghyeon Kim, Sangheum Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18817">Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prior research on out-of-distribution detection (OoDD) has primarily focused on single-modality models. Recently, with the advent of large-scale pretrained vision-language models such as CLIP, OoDD methods utilizing such multi-modal representations through zero-shot and prompt learning strategies have emerged. However, these methods typically involve either freezing the pretrained weights or only partially tuning them, which can be suboptimal for downstream datasets. In this paper, we highlight that multi-modal fine-tuning (MMFT) can achieve notable OoDD performance. Despite some recent works demonstrating the impact of fine-tuning methods for OoDD, there remains significant potential for performance improvement. We investigate the limitation of naÃ¯ve fine-tuning methods, examining why they fail to fully leverage the pretrained knowledge. Our empirical analysis suggests that this issue could stem from the modality gap within in-distribution (ID) embeddings. To address this, we propose a training objective that enhances cross-modal alignment by regularizing the distances between image and text embeddings of ID data. This adjustment helps in better utilizing pretrained textual information by aligning similar semantics from different modalities (i.e., text and image) more closely in the hyperspherical representation space. We theoretically demonstrate that the proposed regularization corresponds to the maximum likelihood estimation of an energy-based model on a hypersphere. Utilizing ImageNet-1k OoD benchmark datasets, we show that our method, combined with post-hoc OoDD approaches leveraging pretrained knowledge (e.g., NegLabel), significantly outperforms existing methods, achieving state-of-the-art OoDD performance and leading ID accuracy.
<div id='section'>Paperid: <span id='pid'>1450, <a href='https://arxiv.org/pdf/2503.15583.pdf' target='_blank'>https://arxiv.org/pdf/2503.15583.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabian Denoodt, JosÃ© Oramas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15583">Efficient Post-Hoc Uncertainty Calibration via Variance-Based Smoothing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since state-of-the-art uncertainty estimation methods are often computationally demanding, we investigate whether incorporating prior information can improve uncertainty estimates in conventional deep neural networks. Our focus is on machine learning tasks where meaningful predictions can be made from sub-parts of the input. For example, in speaker classification, the speech waveform can be divided into sequential patches, each containing information about the same speaker. We observe that the variance between sub-predictions serves as a reliable proxy for uncertainty in such settings. Our proposed variance-based scaling framework produces competitive uncertainty estimates in classification while being less computationally demanding and allowing for integration as a post-hoc calibration tool. This approach also leads to a simple extension of deep ensembles, improving the expressiveness of their predicted distributions.
<div id='section'>Paperid: <span id='pid'>1451, <a href='https://arxiv.org/pdf/2503.13909.pdf' target='_blank'>https://arxiv.org/pdf/2503.13909.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pavia Bera, Sanjukta Bhanja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13909">Quantification of Uncertainties in Probabilistic Deep Neural Network by Implementing Boosting of Variational Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern neural network architectures have achieved remarkable accuracies but remain highly dependent on their training data, often lacking interpretability in their learned mappings. While effective on large datasets, they tend to overfit on smaller ones. Probabilistic neural networks, such as those utilizing variational inference, address this limitation by incorporating uncertainty estimation through weight distributions rather than point estimates. However, standard variational inference often relies on a single-density approximation, which can lead to poor posterior estimates and hinder model performance. We propose Boosted Bayesian Neural Networks (BBNN), a novel approach that enhances neural network weight distribution approximations using Boosting Variational Inference (BVI). By iteratively constructing a mixture of densities, BVI expands the approximating family, enabling a more expressive posterior that leads to improved generalization and uncertainty estimation. While this approach increases computational complexity, it significantly enhances accuracy an essential tradeoff, particularly in high-stakes applications such as medical diagnostics, where false negatives can have severe consequences. Our experimental results demonstrate that BBNN achieves ~5% higher accuracy compared to conventional neural networks while providing superior uncertainty quantification. This improvement highlights the effectiveness of leveraging a mixture-based variational family to better approximate the posterior distribution, ultimately advancing probabilistic deep learning.
<div id='section'>Paperid: <span id='pid'>1452, <a href='https://arxiv.org/pdf/2503.13246.pdf' target='_blank'>https://arxiv.org/pdf/2503.13246.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guoyou Sun, Panagiotis Karras, Qi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13246">Highly Efficient Direct Analytics on Semantic-aware Time Series Data Compression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic communication has emerged as a promising paradigm to tackle the challenges of massive growing data traffic and sustainable data communication. It shifts the focus from data fidelity to goal-oriented or task-oriented semantic transmission. While deep learning-based methods are commonly used for semantic encoding and decoding, they struggle with the sequential nature of time series data and high computation cost, particularly in resource-constrained IoT environments. Data compression plays a crucial role in reducing transmission and storage costs, yet traditional data compression methods fall short of the demands of goal-oriented communication systems. In this paper, we propose a novel method for direct analytics on time series data compressed by the SHRINK compression algorithm. Through experimentation using outlier detection as a case study, we show that our method outperforms baselines running on uncompressed data in multiple cases, with merely 1% difference in the worst case. Additionally, it achieves four times lower runtime on average and accesses approximately 10% of the data volume, which enables edge analytics with limited storage and computation power. These results demonstrate that our approach offers reliable, high-speed outlier detection analytics for diverse IoT applications while extracting semantics from time-series data, achieving high compression, and reducing data transmission.
<div id='section'>Paperid: <span id='pid'>1453, <a href='https://arxiv.org/pdf/2503.11851.pdf' target='_blank'>https://arxiv.org/pdf/2503.11851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jutika Borah, Hidam Kumarjit Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.11851">DCAT: Dual Cross-Attention Fusion for Disease Classification in Radiological Images with Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and reliable image classification is crucial in radiology, where diagnostic decisions significantly impact patient outcomes. Conventional deep learning models tend to produce overconfident predictions despite underlying uncertainties, potentially leading to misdiagnoses. Attention mechanisms have emerged as powerful tools in deep learning, enabling models to focus on relevant parts of the input data. Combined with feature fusion, they can be effective in addressing uncertainty challenges. Cross-attention has become increasingly important in medical image analysis for capturing dependencies across features and modalities. This paper proposes a novel dual cross-attention fusion model for medical image analysis by addressing key challenges in feature integration and interpretability. Our approach introduces a bidirectional cross-attention mechanism with refined channel and spatial attention that dynamically fuses feature maps from EfficientNetB4 and ResNet34 leveraging multi-network contextual dependencies. The refined features through channel and spatial attention highlights discriminative patterns crucial for accurate classification. The proposed model achieved AUC of 99.75%, 100%, 99.93% and 98.69% and AUPR of 99.81%, 100%, 99.97%, and 96.36% on Covid-19, Tuberculosis, Pneumonia Chest X-ray images and Retinal OCT images respectively. The entropy values and several high uncertain samples give an interpretable visualization from the model enhancing transparency. By combining multi-scale feature extraction, bidirectional attention and uncertainty estimation, our proposed model strongly impacts medical image analysis.
<div id='section'>Paperid: <span id='pid'>1454, <a href='https://arxiv.org/pdf/2503.01688.pdf' target='_blank'>https://arxiv.org/pdf/2503.01688.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Petr Sychev, Andrey Goncharov, Daniil Vyazhev, Edvard Khalafyan, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.01688">When an LLM is apprehensive about its answers -- and when its uncertainty is justified</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is crucial for evaluating Large Language Models (LLMs), particularly in high-stakes domains where incorrect answers result in significant consequences. Numerous approaches consider this problem, while focusing on a specific type of uncertainty, ignoring others. We investigate what estimates, specifically token-wise entropy and model-as-judge (MASJ), would work for multiple-choice question-answering tasks for different question topics. Our experiments consider three LLMs: Phi-4, Mistral, and Qwen of different sizes from 1.5B to 72B and $14$ topics. While MASJ performs similarly to a random error predictor, the response entropy predicts model error in knowledge-dependent domains and serves as an effective indicator of question difficulty: for biology ROC AUC is $0.73$. This correlation vanishes for the reasoning-dependent domain: for math questions ROC-AUC is $0.55$. More principally, we found out that the entropy measure required a reasoning amount. Thus, data-uncertainty related entropy should be integrated within uncertainty estimates frameworks, while MASJ requires refinement. Moreover, existing MMLU-Pro samples are biased, and should balance required amount of reasoning for different subdomains to provide a more fair assessment of LLMs performance.
<div id='section'>Paperid: <span id='pid'>1455, <a href='https://arxiv.org/pdf/2502.19700.pdf' target='_blank'>https://arxiv.org/pdf/2502.19700.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yimin Zhu, Lincoln Linlin Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19700">Language-Informed Hyperspectral Image Synthesis for Imbalanced-Small Sample Classification via Semi-Supervised Conditional Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data augmentation effectively addresses the imbalanced-small sample data (ISSD) problem in hyperspectral image classification (HSIC). While most methodologies extend features in the latent space, few leverage text-driven generation to create realistic and diverse samples. Recently, text-guided diffusion models have gained significant attention due to their ability to generate highly diverse and high-quality images based on text prompts in natural image synthesis. Motivated by this, this paper proposes Txt2HSI-LDM(VAE), a novel language-informed hyperspectral image synthesis method to address the ISSD in HSIC. The proposed approach uses a denoising diffusion model, which iteratively removes Gaussian noise to generate hyperspectral samples conditioned on textual descriptions. First, to address the high-dimensionality of hyperspectral data, a universal variational autoencoder (VAE) is designed to map the data into a low-dimensional latent space, which provides stable features and reduces the inference complexity of diffusion model. Second, a semi-supervised diffusion model is designed to fully take advantage of unlabeled data. Random polygon spatial clipping (RPSC) and uncertainty estimation of latent feature (LF-UE) are used to simulate the varying degrees of mixing. Third, the VAE decodes HSI from latent space generated by the diffusion model with the language conditions as input. In our experiments, we fully evaluate synthetic samples' effectiveness from statistical characteristics and data distribution in 2D-PCA space. Additionally, visual-linguistic cross-attention is visualized on the pixel level to prove that our proposed model can capture the spatial layout and geometry of the generated data. Experiments demonstrate that the performance of the proposed Txt2HSI-LDM(VAE) surpasses the classical backbone models, state-of-the-art CNNs, and semi-supervised methods.
<div id='section'>Paperid: <span id='pid'>1456, <a href='https://arxiv.org/pdf/2502.19122.pdf' target='_blank'>https://arxiv.org/pdf/2502.19122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian ChwilczyÅski, Dariusz Brzezinski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19122">Random Similarity Isolation Forests</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With predictive models becoming prevalent, companies are expanding the types of data they gather. As a result, the collected datasets consist not only of simple numerical features but also more complex objects such as time series, images, or graphs. Such multi-modal data have the potential to improve performance in predictive tasks like outlier detection, where the goal is to identify objects deviating from the main data distribution. However, current outlier detection algorithms are dedicated to individual types of data. Consequently, working with mixed types of data requires either fusing multiple data-specific models or transforming all of the representations into a single format, both of which can hinder predictive performance. In this paper, we propose a multi-modal outlier detection algorithm called Random Similarity Isolation Forest. Our method combines the notions of isolation and similarity-based projection to handle datasets with mixtures of features of arbitrary data types. Experiments performed on 47 benchmark datasets demonstrate that Random Similarity Isolation Forest outperforms five state-of-the-art competitors. Our study shows that the use of multiple modalities can indeed improve the detection of anomalies and highlights the need for new outlier detection benchmarks tailored for multi-modal algorithms.
<div id='section'>Paperid: <span id='pid'>1457, <a href='https://arxiv.org/pdf/2502.18389.pdf' target='_blank'>https://arxiv.org/pdf/2502.18389.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicola Cecere, Andrea Bacciu, Ignacio FernÃ¡ndez TobÃ­as, Amin Mantrach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18389">Monte Carlo Temperature: a robust sampling strategy for LLM's uncertainty quantification methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification (UQ) in Large Language Models (LLMs) is essential for their safe and reliable deployment, particularly in critical applications where incorrect outputs can have serious consequences. Current UQ methods typically rely on querying the model multiple times using non-zero temperature sampling to generate diverse outputs for uncertainty estimation. However, the impact of selecting a given temperature parameter is understudied, and our analysis reveals that temperature plays a fundamental role in the quality of uncertainty estimates. The conventional approach of identifying optimal temperature values requires expensive hyperparameter optimization (HPO) that must be repeated for each new model-dataset combination. We propose Monte Carlo Temperature (MCT), a robust sampling strategy that eliminates the need for temperature calibration. Our analysis reveals that: 1) MCT provides more robust uncertainty estimates across a wide range of temperatures, 2) MCT improves the performance of UQ methods by replacing fixed-temperature strategies that do not rely on HPO, and 3) MCT achieves statistical parity with oracle temperatures, which represent the ideal outcome of a well-tuned but computationally expensive HPO process. These findings demonstrate that effective UQ can be achieved without the computational burden of temperature parameter calibration.
<div id='section'>Paperid: <span id='pid'>1458, <a href='https://arxiv.org/pdf/2502.14698.pdf' target='_blank'>https://arxiv.org/pdf/2502.14698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Schmitt, John Shawe-Taylor, Hado van Hasselt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14698">General Uncertainty Estimation with Delta Variances</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Decision makers may suffer from uncertainty induced by limited data. This may be mitigated by accounting for epistemic uncertainty, which is however challenging to estimate efficiently for large neural networks. To this extent we investigate Delta Variances, a family of algorithms for epistemic uncertainty quantification, that is computationally efficient and convenient to implement. It can be applied to neural networks and more general functions composed of neural networks. As an example we consider a weather simulator with a neural-network-based step function inside -- here Delta Variances empirically obtain competitive results at the cost of a single gradient computation. The approach is convenient as it requires no changes to the neural network architecture or training procedure. We discuss multiple ways to derive Delta Variances theoretically noting that special cases recover popular techniques and present a unified perspective on multiple related methods. Finally we observe that this general perspective gives rise to a natural extension and empirically show its benefit.
<div id='section'>Paperid: <span id='pid'>1459, <a href='https://arxiv.org/pdf/2502.04381.pdf' target='_blank'>https://arxiv.org/pdf/2502.04381.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Kim, Anna Podlasek, Kie Shidara, Feng Liu, Ahmed Alaa, Danilo Bernardo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04381">Limitations of Large Language Models in Clinical Problem-Solving Arising from Inflexible Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have attained human-level accuracy on medical question-answer (QA) benchmarks. However, their limitations in navigating open-ended clinical scenarios have recently been shown, raising concerns about the robustness and generalizability of LLM reasoning across diverse, real-world medical tasks. To probe potential LLM failure modes in clinical problem-solving, we present the medical abstraction and reasoning corpus (M-ARC). M-ARC assesses clinical reasoning through scenarios designed to exploit the Einstellung effect -- the fixation of thought arising from prior experience, targeting LLM inductive biases toward inflexible pattern matching from their training data rather than engaging in flexible reasoning. We find that LLMs, including current state-of-the-art o1 and Gemini models, perform poorly compared to physicians on M-ARC, often demonstrating lack of commonsense medical reasoning and a propensity to hallucinate. In addition, uncertainty estimation analyses indicate that LLMs exhibit overconfidence in their answers, despite their limited accuracy. The failure modes revealed by M-ARC in LLM medical reasoning underscore the need to exercise caution when deploying these models in clinical settings.
<div id='section'>Paperid: <span id='pid'>1460, <a href='https://arxiv.org/pdf/2502.02537.pdf' target='_blank'>https://arxiv.org/pdf/2502.02537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huiqun Huang, Cong Chen, Jean-Philippe Monteuuis, Jonathan Petit, Fei Miao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.02537">Uncertainty Quantification for Collaborative Object Detection Under Adversarial Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Collaborative Object Detection (COD) and collaborative perception can integrate data or features from various entities, and improve object detection accuracy compared with individual perception. However, adversarial attacks pose a potential threat to the deep learning COD models, and introduce high output uncertainty. With unknown attack models, it becomes even more challenging to improve COD resiliency and quantify the output uncertainty for highly dynamic perception scenes such as autonomous vehicles. In this study, we propose the Trusted Uncertainty Quantification in Collaborative Perception framework (TUQCP). TUQCP leverages both adversarial training and uncertainty quantification techniques to enhance the adversarial robustness of existing COD models. More specifically, TUQCP first adds perturbations to the shared information of randomly selected agents during object detection collaboration by adversarial training. TUQCP then alleviates the impacts of adversarial attacks by providing output uncertainty estimation through learning-based module and uncertainty calibration through conformal prediction. Our framework works for early and intermediate collaboration COD models and single-agent object detection models. We evaluate TUQCP on V2X-Sim, a comprehensive collaborative perception dataset for autonomous driving, and demonstrate a 80.41% improvement in object detection accuracy compared to the baselines under the same adversarial attacks. TUQCP demonstrates the importance of uncertainty quantification to COD under adversarial attacks.
<div id='section'>Paperid: <span id='pid'>1461, <a href='https://arxiv.org/pdf/2501.04577.pdf' target='_blank'>https://arxiv.org/pdf/2501.04577.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zephan M. Enciso, Boyang Cheng, Likai Pei, Jianbo Liu, Steven Davis, Michael Niemier, Ningyuan Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04577">A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is an indispensable capability for AI-enabled, safety-critical applications, e.g. autonomous vehicles or medical diagnosis. Bayesian neural networks (BNNs) use Bayesian statistics to provide both classification predictions and uncertainty estimation, but they suffer from high computational overhead associated with random number generation and repeated sample iterations. Furthermore, BNNs are not immediately amenable to acceleration through compute-in-memory architectures due to the frequent memory writes necessary after each RNG operation. To address these challenges, we present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the SRAM memory words. This integration reduces RNG overhead and enables fully-parallel compute-in-memory operations for BNNs. The prototype chip achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput while occupying 0.45 mm2, bringing AI uncertainty estimation to edge computation.
<div id='section'>Paperid: <span id='pid'>1462, <a href='https://arxiv.org/pdf/2412.20918.pdf' target='_blank'>https://arxiv.org/pdf/2412.20918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Chen, Chih-Li Sung, Arpan Kusari, Xiaoyang Song, Wenbo Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20918">Uncertainty-Aware Out-of-Distribution Detection with Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) are often constructed under the closed-world assumption, which may fail to generalize to the out-of-distribution (OOD) data. This leads to DNNs producing overconfident wrong predictions and can result in disastrous consequences in safety-critical applications. Existing OOD detection methods mainly rely on curating a set of OOD data for model training or hyper-parameter tuning to distinguish OOD data from training data (also known as in-distribution data or InD data). However, OOD samples are not always available during the training phase in real-world applications, hindering the OOD detection accuracy. To overcome this limitation, we propose a Gaussian-process-based OOD detection method to establish a decision boundary based on InD data only. The basic idea is to perform uncertainty quantification of the unconstrained softmax scores of a DNN via a multi-class Gaussian process (GP), and then define a score function to separate InD and potential OOD data based on their fundamental differences in the posterior predictive distribution from the GP. Two case studies on conventional image classification datasets and real-world image datasets are conducted to demonstrate that the proposed method outperforms the state-of-the-art OOD detection methods when OOD samples are not observed in the training phase.
<div id='section'>Paperid: <span id='pid'>1463, <a href='https://arxiv.org/pdf/2412.20007.pdf' target='_blank'>https://arxiv.org/pdf/2412.20007.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elhoucine Elfatimi, Pratik Shah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20007">Uncertainty Quantified Deep Learning and Regression Analysis Framework for Image Segmentation of Skin Cancer Lesions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models (DLMs) frequently achieve accurate segmentation and classification of tumors from medical images. However, DLMs lacking feedback on their image segmentation mechanisms, such as Dice coefficients and confidence in their performance, face challenges when processing previously unseen images in real-world clinical settings. Uncertainty estimates to identify DLM predictions at the cellular or single-pixel level that require clinician review can enhance trust. However, their deployment requires significant computational resources. This study reports two DLMs, one trained from scratch and another based on transfer learning, with Monte Carlo dropout or Bayes-by-backprop uncertainty estimations to segment lesions from the publicly available The International Skin Imaging Collaboration-19 dermoscopy image database with cancerous lesions. A novel approach to compute pixel-by-pixel uncertainty estimations of DLM segmentation performance in multiple clinical regions from a single dermoscopy image with corresponding Dice scores is reported for the first time. Image-level uncertainty maps demonstrated correspondence between imperfect DLM segmentation and high uncertainty levels in specific skin tissue regions, with or without lesions. Four new linear regression models that can predict the Dice performance of DLM segmentation using constants and uncertainty measures, either individually or in combination from lesions, tissue structures, and non-tissue pixel regions critical for clinical diagnosis and prognostication in skin images (Spearman's correlation, p < 0.05), are reported for the first time for low-compute uncertainty estimation workflows.
<div id='section'>Paperid: <span id='pid'>1464, <a href='https://arxiv.org/pdf/2412.12890.pdf' target='_blank'>https://arxiv.org/pdf/2412.12890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shijing Wang, Yaping Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12890">Suppressing Uncertainty in Gaze Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty in gaze estimation manifests in two aspects: 1) low-quality images caused by occlusion, blurriness, inconsistent eye movements, or even non-face images; 2) incorrect labels resulting from the misalignment between the labeled and actual gaze points during the annotation process. Allowing these uncertainties to participate in training hinders the improvement of gaze estimation. To tackle these challenges, in this paper, we propose an effective solution, named Suppressing Uncertainty in Gaze Estimation (SUGE), which introduces a novel triplet-label consistency measurement to estimate and reduce the uncertainties. Specifically, for each training sample, we propose to estimate a novel ``neighboring label'' calculated by a linearly weighted projection from the neighbors to capture the similarity relationship between image features and their corresponding labels, which can be incorporated with the predicted pseudo label and ground-truth label for uncertainty estimation. By modeling such triplet-label consistency, we can measure the qualities of both images and labels, and further largely reduce the negative effects of unqualified images and wrong labels through our designed sample weighting and label correction strategies. Experimental results on the gaze estimation benchmarks indicate that our proposed SUGE achieves state-of-the-art performance.
<div id='section'>Paperid: <span id='pid'>1465, <a href='https://arxiv.org/pdf/2412.07961.pdf' target='_blank'>https://arxiv.org/pdf/2412.07961.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric Bigelow, Ari Holtzman, Hidenori Tanaka, Tomer Ullman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07961">Forking Paths in Neural Text Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating uncertainty in Large Language Models (LLMs) is important for properly evaluating LLMs, and ensuring safety for users. However, prior approaches to uncertainty estimation focus on the final answer in generated text, ignoring intermediate steps that might dramatically impact the outcome. We hypothesize that there exist key forking tokens, such that re-sampling the system at those specific tokens, but not others, leads to very different outcomes. To test this empirically, we develop a novel approach to representing uncertainty dynamics across individual tokens of text generation, and applying statistical models to test our hypothesis. Our approach is highly flexible: it can be applied to any dataset and any LLM, without fine tuning or accessing model weights. We use our method to analyze LLM responses on 7 different tasks across 4 domains, spanning a wide range of typical use cases. We find many examples of forking tokens, including surprising ones such as punctuation marks, suggesting that LLMs are often just a single token away from saying something very different.
<div id='section'>Paperid: <span id='pid'>1466, <a href='https://arxiv.org/pdf/2412.07565.pdf' target='_blank'>https://arxiv.org/pdf/2412.07565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Kristoffersson Lind, Rudolph Triebel, Volker KrÃ¼ger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07565">Making the Flow Glow -- Robot Perception under Severe Lighting Conditions using Normalizing Flow Gradients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern robotic perception is highly dependent on neural networks. It is well known that neural network-based perception can be unreliable in real-world deployment, especially in difficult imaging conditions. Out-of-distribution detection is commonly proposed as a solution for ensuring reliability in real-world deployment. Previous work has shown that normalizing flow models can be used for out-of-distribution detection to improve reliability of robotic perception tasks. Specifically, camera parameters can be optimized with respect to the likelihood output from a normalizing flow, which allows a perception system to adapt to difficult vision scenarios. With this work we propose to use the absolute gradient values from a normalizing flow, which allows the perception system to optimize local regions rather than the whole image. By setting up a table top picking experiment with exceptionally difficult lighting conditions, we show that our method achieves a 60% higher success rate for an object detection task compared to previous methods.
<div id='section'>Paperid: <span id='pid'>1467, <a href='https://arxiv.org/pdf/2412.05669.pdf' target='_blank'>https://arxiv.org/pdf/2412.05669.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Li, Shuliang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05669">Detecting outliers by clustering algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clustering and outlier detection are two important tasks in data mining. Outliers frequently interfere with clustering algorithms to determine the similarity between objects, resulting in unreliable clustering results. Currently, only a few clustering algorithms (e.g., DBSCAN) have the ability to detect outliers to eliminate interference. For other clustering algorithms, it is tedious to introduce another outlier detection task to eliminate outliers before each clustering process. Obviously, how to equip more clustering algorithms with outlier detection ability is very meaningful. Although a common strategy allows clustering algorithms to detect outliers based on the distance between objects and clusters, it is contradictory to improving the performance of clustering algorithms on the datasets with outliers. In this paper, we propose a novel outlier detection approach, called ODAR, for clustering. ODAR maps outliers and normal objects into two separated clusters by feature transformation. As a result, any clustering algorithm can detect outliers by identifying clusters. Experiments show that ODAR is robust to diverse datasets. Compared with baseline methods, the clustering algorithms achieve the best on 7 out of 10 datasets with the help of ODAR, with at least 5% improvement in accuracy.
<div id='section'>Paperid: <span id='pid'>1468, <a href='https://arxiv.org/pdf/2412.02875.pdf' target='_blank'>https://arxiv.org/pdf/2412.02875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ankita Samaddar, Nicholas Potteiger, Xenofon Koutsoukos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02875">Out-of-Distribution Detection for Neurosymbolic Autonomous Cyber Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous agents for cyber applications take advantage of modern defense techniques by adopting intelligent agents with conventional and learning-enabled components. These intelligent agents are trained via reinforcement learning (RL) algorithms, and can learn, adapt to, reason about and deploy security rules to defend networked computer systems while maintaining critical operational workflows. However, the knowledge available during training about the state of the operational network and its environment may be limited. The agents should be trustworthy so that they can reliably detect situations they cannot handle, and hand them over to cyber experts. In this work, we develop an out-of-distribution (OOD) Monitoring algorithm that uses a Probabilistic Neural Network (PNN) to detect anomalous or OOD situations of RL-based agents with discrete states and discrete actions. To demonstrate the effectiveness of the proposed approach, we integrate the OOD monitoring algorithm with a neurosymbolic autonomous cyber agent that uses behavior trees with learning-enabled components. We evaluate the proposed approach in a simulated cyber environment under different adversarial strategies. Experimental results over a large number of episodes illustrate the overall efficiency of our proposed approach.
<div id='section'>Paperid: <span id='pid'>1469, <a href='https://arxiv.org/pdf/2412.02408.pdf' target='_blank'>https://arxiv.org/pdf/2412.02408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shabnam Fazliani, Mohammad Mowlavi Sorond, Arsalan Masoudifard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02408">Leveraging Ensemble-Based Semi-Supervised Learning for Illicit Account Detection in Ethereum DeFi Transactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advent of smart contracts has enabled the rapid rise of Decentralized Finance (DeFi) on the Ethereum blockchain, offering substantial rewards in financial innovation and inclusivity. However, this growth has also introduced significant security risks, including the proliferation of illicit accounts involved in fraudulent activities. Traditional detection methods are limited by the scarcity of labeled data and the evolving tactics of malicious actors. In this paper, we propose a novel Self-Learning Ensemble-based Illicit account Detection (SLEID) framework to address these challenges. SLEID employs an Isolation Forest for initial outlier detection and a self-training mechanism to iteratively generate pseudo-labels for unlabeled accounts, thereby enhancing detection accuracy. Extensive experiments demonstrate that SLEID significantly outperforms traditional supervised approaches and recent semi-supervised models, achieving superior precision, recall, and F1-scores, particularly in detecting illicit accounts. Compared to state-of-the-art methods, our approach achieves better detection performance while reducing reliance on labeled data. The results affirm SLEID's efficacy as a robust solution for safeguarding the DeFi ecosystem and mitigating risks posed by malicious accounts.
<div id='section'>Paperid: <span id='pid'>1470, <a href='https://arxiv.org/pdf/2412.00401.pdf' target='_blank'>https://arxiv.org/pdf/2412.00401.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Zhou, Marlen Neubert, Yuri Koide, Yumeng Zhang, Van-Quan Vuong, Tobias SchlÃ¶der, Stefanie Dehnen, Pascal Friederich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00401">PAL -- Parallel active learning for machine-learned potentials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing datasets representative of the target domain is essential for training effective machine learning models. Active learning (AL) is a promising method that iteratively extends training data to enhance model performance while minimizing data acquisition costs. However, current AL workflows often require human intervention and lack parallelism, leading to inefficiencies and underutilization of modern computational resources. In this work, we introduce PAL, an automated, modular, and parallel active learning library that integrates AL tasks and manages their execution and communication on shared- and distributed-memory systems using the Message Passing Interface (MPI). PAL provides users with the flexibility to design and customize all components of their active learning scenarios, including machine learning models with uncertainty estimation, oracles for ground truth labeling, and strategies for exploring the target space. We demonstrate that PAL significantly reduces computational overhead and improves scalability, achieving substantial speed-ups through asynchronous parallelization on CPU and GPU hardware. Applications of PAL to several real-world scenarios - including ground-state reactions in biomolecular systems, excited-state dynamics of molecules, simulations of inorganic clusters, and thermo-fluid dynamics - illustrate its effectiveness in accelerating the development of machine learning models. Our results show that PAL enables efficient utilization of high-performance computing resources in active learning workflows, fostering advancements in scientific research and engineering applications.
<div id='section'>Paperid: <span id='pid'>1471, <a href='https://arxiv.org/pdf/2412.00278.pdf' target='_blank'>https://arxiv.org/pdf/2412.00278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Sun, Sander BohtÃ©
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00278">Average-Over-Time Spiking Neural Networks for Uncertainty Estimation in Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a standard tool to quantify the reliability of modern deep learning models, and crucial for many real-world applications. However, efficient uncertainty estimation methods for spiking neural networks, particularly for regression models, have been lacking. Here, we introduce two methods that adapt the Average-Over-Time Spiking Neural Network (AOT-SNN) framework to regression tasks, enhancing uncertainty estimation in event-driven models. The first method uses the heteroscedastic Gaussian approach, where SNNs predict both the mean and variance at each time step, thereby generating a conditional probability distribution of the target variable. The second method leverages the Regression-as-Classification (RAC) approach, reformulating regression as a classification problem to facilitate uncertainty estimation. We evaluate our approaches on both a toy dataset and several benchmark datasets, demonstrating that the proposed AOT-SNN models achieve performance comparable to or better than state-of-the-art deep neural network methods, particularly in uncertainty estimation. Our findings highlight the potential of SNNs for uncertainty estimation in regression tasks, providing an efficient and biologically inspired alternative for applications requiring both accuracy and energy efficiency.
<div id='section'>Paperid: <span id='pid'>1472, <a href='https://arxiv.org/pdf/2411.11935.pdf' target='_blank'>https://arxiv.org/pdf/2411.11935.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanieh Shojaei Miandashti, Qianqian Zou, Claus Brenner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11935">Calibrated and Efficient Sampling-Free Confidence Estimation for LiDAR Scene Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable deep learning models require not only accurate predictions but also well-calibrated confidence estimates to ensure dependable uncertainty estimation. This is crucial in safety-critical applications like autonomous driving, which depend on rapid and precise semantic segmentation of LiDAR point clouds for real-time 3D scene understanding. In this work, we introduce a sampling-free approach for estimating well-calibrated confidence values for classification tasks, achieving alignment with true classification accuracy and significantly reducing inference time compared to sampling-based methods. Our evaluation using the Adaptive Calibration Error (ACE) metric for LiDAR semantic segmentation shows that our approach maintains well-calibrated confidence values while achieving increased processing speed compared to a sampling baseline. Additionally, reliability diagrams reveal that our method produces underconfidence rather than overconfident predictions, an advantage for safety-critical applications. Our sampling-free approach offers well-calibrated and time-efficient predictions for LiDAR scene semantic segmentation.
<div id='section'>Paperid: <span id='pid'>1473, <a href='https://arxiv.org/pdf/2411.11132.pdf' target='_blank'>https://arxiv.org/pdf/2411.11132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alisa Sheinkman, Sara Wade
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11132">Variational Bayesian Bow tie Neural Networks with Shrinkage</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the dominant role of deep models in machine learning, limitations persist, including overconfident predictions, susceptibility to adversarial attacks, and underestimation of variability in predictions. The Bayesian paradigm provides a natural framework to overcome such issues and has become the gold standard for uncertainty estimation with deep models, also providing improved accuracy and a framework for tuning critical hyperparameters. However, exact Bayesian inference is challenging, typically involving variational algorithms that impose strong independence and distributional assumptions. Moreover, existing methods are sensitive to the architectural choice of the network. We address these issues by focusing on a stochastic relaxation of the standard feed-forward rectified neural network and using sparsity-promoting priors on the weights of the neural network for increased robustness to architectural design. Thanks to Polya-Gamma data augmentation tricks, which render a conditionally linear and Gaussian model, we derive a fast, approximate variational inference algorithm that avoids distributional assumptions and independence across layers. Suitable strategies to further improve scalability and account for multimodality are considered.
<div id='section'>Paperid: <span id='pid'>1474, <a href='https://arxiv.org/pdf/2411.05324.pdf' target='_blank'>https://arxiv.org/pdf/2411.05324.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weijie Chen, Alan McMillan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05324">SASWISE-UE: Segmentation and Synthesis with Interpretable Scalable Ensembles for Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces an efficient sub-model ensemble framework aimed at enhancing the interpretability of medical deep learning models, thus increasing their clinical applicability. By generating uncertainty maps, this framework enables end-users to evaluate the reliability of model outputs. We developed a strategy to develop diverse models from a single well-trained checkpoint, facilitating the training of a model family. This involves producing multiple outputs from a single input, fusing them into a final output, and estimating uncertainty based on output disagreements. Implemented using U-Net and UNETR models for segmentation and synthesis tasks, this approach was tested on CT body segmentation and MR-CT synthesis datasets. It achieved a mean Dice coefficient of 0.814 in segmentation and a Mean Absolute Error of 88.17 HU in synthesis, improved from 89.43 HU by pruning. Additionally, the framework was evaluated under corruption and undersampling, maintaining correlation between uncertainty and error, which highlights its robustness. These results suggest that the proposed approach not only maintains the performance of well-trained models but also enhances interpretability through effective uncertainty estimation, applicable to both convolutional and transformer models in a range of imaging tasks.
<div id='section'>Paperid: <span id='pid'>1475, <a href='https://arxiv.org/pdf/2411.04090.pdf' target='_blank'>https://arxiv.org/pdf/2411.04090.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guillermo Villate-Castillo, Javier Del Ser, Borja Sanz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04090">A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Content moderation typically combines the efforts of human moderators and machine learning models. However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception. Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content,an insight missed when only the majority label is considered. In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement. Our approach uses multitask learning, where toxicity classification serves as the primary task and annotation disagreement is addressed as an auxiliary task. Additionally, we leverage uncertainty estimation techniques, specifically Conformal Prediction, to account for both the ambiguity in comment annotations and the model's inherent uncertainty in predicting toxicity and disagreement.The framework also allows moderators to adjust thresholds for annotation disagreement, offering flexibility in determining when ambiguity should trigger a review. We demonstrate that our joint approach enhances model performance, calibration, and uncertainty estimation, while offering greater parameter efficiency and improving the review process in comparison to single-task methods.
<div id='section'>Paperid: <span id='pid'>1476, <a href='https://arxiv.org/pdf/2411.04090.pdf' target='_blank'>https://arxiv.org/pdf/2411.04090.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guillermo Villate-Castillo, Javier Del Ser, Borja Sanz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04090">A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Content moderation typically combines the efforts of human moderators and machine learning models. However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception. Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content,an insight missed when only the majority label is considered. In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement. Our approach uses multitask learning, where toxicity classification serves as the primary task and annotation disagreement is addressed as an auxiliary task. Additionally, we leverage uncertainty estimation techniques, specifically Conformal Prediction, to account for both the ambiguity in comment annotations and the model's inherent uncertainty in predicting toxicity and disagreement.The framework also allows moderators to adjust thresholds for annotation disagreement, offering flexibility in determining when ambiguity should trigger a review. We demonstrate that our joint approach enhances model performance, calibration, and uncertainty estimation, while offering greater parameter efficiency and improving the review process in comparison to single-task methods.
<div id='section'>Paperid: <span id='pid'>1477, <a href='https://arxiv.org/pdf/2410.21081.pdf' target='_blank'>https://arxiv.org/pdf/2410.21081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benjamin Schiffer, Lucas Janson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21081">Foundations of Safe Online Reinforcement Learning in the Linear Quadratic Regulator: Generalized Baselines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many practical applications of online reinforcement learning require the satisfaction of safety constraints while learning about the unknown environment. In this work, we establish theoretical foundations for reinforcement learning with safety constraints by studying the canonical problem of Linear Quadratic Regulator learning with unknown dynamics, but with the additional constraint that the position must stay within a safe region for the entire trajectory with high probability. Our primary contribution is a general framework for studying stronger baselines of nonlinear controllers that are better suited for constrained problems than linear controllers. Due to the difficulty of analyzing non-linear controllers in a constrained problem, we focus on 1-dimensional state- and action- spaces, however we also discuss how we expect the high-level takeaways can generalize to higher dimensions. Using our framework, we show that for \emph{any} non-linear baseline satisfying natural assumptions, $\tilde{O}_T(\sqrt{T})$-regret is possible when the noise distribution has sufficiently large support, and $\tilde{O}_T(T^{2/3})$-regret is possible for \emph{any} subgaussian noise distribution. In proving these results, we introduce a new uncertainty estimation bound for nonlinear controls which shows that enforcing safety in the presence of sufficient noise can provide ``free exploration'' that compensates for the added cost of uncertainty in safety-constrained control.
<div id='section'>Paperid: <span id='pid'>1478, <a href='https://arxiv.org/pdf/2410.14582.pdf' target='_blank'>https://arxiv.org/pdf/2410.14582.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juyeon Heo, Miao Xiong, Christina Heinze-Deml, Jaya Narain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14582">Do LLMs estimate uncertainty well in instruction-following?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) could be valuable personal AI agents across various domains, provided they can precisely follow user instructions. However, recent studies have shown significant limitations in LLMs' instruction-following capabilities, raising concerns about their reliability in high-stakes applications. Accurately estimating LLMs' uncertainty in adhering to instructions is critical to mitigating deployment risks. We present, to our knowledge, the first systematic evaluation of the uncertainty estimation abilities of LLMs in the context of instruction-following. Our study identifies key challenges with existing instruction-following benchmarks, where multiple factors are entangled with uncertainty stems from instruction-following, complicating the isolation and comparison across methods and models. To address these issues, we introduce a controlled evaluation setup with two benchmark versions of data, enabling a comprehensive comparison of uncertainty estimation methods under various conditions. Our findings show that existing uncertainty methods struggle, particularly when models make subtle errors in instruction following. While internal model states provide some improvement, they remain inadequate in more complex scenarios. The insights from our controlled evaluation setups provide a crucial understanding of LLMs' limitations and potential for uncertainty estimation in instruction-following tasks, paving the way for more trustworthy AI agents.
<div id='section'>Paperid: <span id='pid'>1479, <a href='https://arxiv.org/pdf/2410.04544.pdf' target='_blank'>https://arxiv.org/pdf/2410.04544.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vinesh Sridhar, Rolf Svenning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04544">Fast Area-Weighted Peeling of Convex Hulls for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel 2D convex hull peeling algorithm for outlier detection, which repeatedly removes the point on the hull that decreases the hull's area the most. To find k outliers among n points, one simply peels k points. The algorithm is an efficient heuristic for exact methods, which find the k points whose removal together results in the smallest convex hull. Our algorithm runs in O(nlogn) time using O(n) space for any choice of k. This is a significant speedup compared to the fastest exact algorithms, which run in O(n^2logn + (n - k)^3) time using O(n\logn + (n-k)^3) space by Eppstein et al., and O(nlogn + 4k_C_2k (3k)^k n) time by Atanassov et al. Existing heuristic peeling approaches are not area-based. Instead, an approach by Harsh et al. repeatedly removes the point furthest from the mean using various distance metrics and runs in O(nlogn + kn) time. Other approaches greedily peel one convex layer at a time, which is efficient when using an O(nlogn) time algorithm by Chazelle to compute the convex layers. However, in many cases this fails to recover outliers. For most values of n and k, our approach is the fastest and first practical choice for finding outliers based on minimizing the area of the convex hull. Our algorithm also generalizes to other objectives such as perimeter.
<div id='section'>Paperid: <span id='pid'>1480, <a href='https://arxiv.org/pdf/2410.04544.pdf' target='_blank'>https://arxiv.org/pdf/2410.04544.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vinesh Sridhar, Rolf Svenning
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04544">Fast Area-Weighted Peeling of Convex Hulls for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel 2D convex hull peeling algorithm for outlier detection, which repeatedly removes the point on the hull that decreases the hull's area the most. To find k outliers among n points, one simply peels k points. The algorithm is an efficient heuristic for exact methods, which find the k points whose removal together results in the smallest convex hull. Our algorithm runs in O(nlogn) time using O(n) space for any choice of k. This is a significant speedup compared to the fastest exact algorithms, which run in O(n^2logn + (n - k)^3) time using O(n\logn + (n-k)^3) space by Eppstein et al., and O(nlogn + 4k_C_2k (3k)^k n) time by Atanassov et al. Existing heuristic peeling approaches are not area-based. Instead, an approach by Harsh et al. repeatedly removes the point furthest from the mean using various distance metrics and runs in O(nlogn + kn) time. Other approaches greedily peel one convex layer at a time, which is efficient when using an O(nlogn) time algorithm by Chazelle to compute the convex layers. However, in many cases this fails to recover outliers. For most values of n and k, our approach is the fastest and first practical choice for finding outliers based on minimizing the area of the convex hull. Our algorithm also generalizes to other objectives such as perimeter.
<div id='section'>Paperid: <span id='pid'>1481, <a href='https://arxiv.org/pdf/2409.13466.pdf' target='_blank'>https://arxiv.org/pdf/2409.13466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniele Malpetti, Laura Azzimonti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13466">Global Outlier Detection in a Federated Learning Setting with Isolation Forest</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel strategy for detecting global outliers in a federated learning setting, targeting in particular cross-silo scenarios. Our approach involves the use of two servers and the transmission of masked local data from clients to one of the servers. The masking of the data prevents the disclosure of sensitive information while still permitting the identification of outliers. Moreover, to further safeguard privacy, a permutation mechanism is implemented so that the server does not know which client owns any masked data point. The server performs outlier detection on the masked data, using either Isolation Forest or its extended version, and then communicates outlier information back to the clients, allowing them to identify and remove outliers in their local datasets before starting any subsequent federated model training. This approach provides comparable results to a centralized execution of Isolation Forest algorithms on plain data.
<div id='section'>Paperid: <span id='pid'>1482, <a href='https://arxiv.org/pdf/2409.12535.pdf' target='_blank'>https://arxiv.org/pdf/2409.12535.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simone Fassio, Simone Monaco, Daniele Apiletti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.12535">Deep Probability Segmentation: Are segmentation models probability estimators?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has revolutionized various fields by enabling highly accurate predictions and estimates. One important application is probabilistic prediction, where models estimate the probability of events rather than deterministic outcomes. This approach is particularly relevant and, therefore, still unexplored for segmentation tasks where each pixel in an image needs to be classified. Conventional models often overlook the probabilistic nature of labels, but accurate uncertainty estimation is crucial for improving the reliability and applicability of models.
  In this study, we applied Calibrated Probability Estimation (CaPE) to segmentation tasks to evaluate its impact on model calibration. Our results indicate that while CaPE improves calibration, its effect is less pronounced compared to classification tasks, suggesting that segmentation models can inherently provide better probability estimates. We also investigated the influence of dataset size and bin optimization on the effectiveness of calibration. Our results emphasize the expressive power of segmentation models as probability estimators and incorporate probabilistic reasoning, which is crucial for applications requiring precise uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>1483, <a href='https://arxiv.org/pdf/2409.01980.pdf' target='_blank'>https://arxiv.org/pdf/2409.01980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiyao Xu, Kaize Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01980">Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting anomalies or out-of-distribution (OOD) samples is critical for maintaining the reliability and trustworthiness of machine learning systems. Recently, Large Language Models (LLMs) have demonstrated their effectiveness not only in natural language processing but also in broader applications due to their advanced comprehension and generative capabilities. The integration of LLMs into anomaly and OOD detection marks a significant shift from the traditional paradigm in the field. This survey focuses on the problem of anomaly and OOD detection under the context of LLMs. We propose a new taxonomy to categorize existing approaches into two classes based on the role played by LLMs. Following our proposed taxonomy, we further discuss the related work under each of the categories and finally discuss potential challenges and directions for future research in this field. We also provide an up-to-date reading list of relevant papers.
<div id='section'>Paperid: <span id='pid'>1484, <a href='https://arxiv.org/pdf/2409.01175.pdf' target='_blank'>https://arxiv.org/pdf/2409.01175.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrija Djurisic, Rosanne Liu, Mladen Nikolic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01175">Logit Scaling for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The safe deployment of machine learning and AI models in open-world settings hinges critically on the ability to detect out-of-distribution (OOD) data accurately, data samples that contrast vastly from what the model was trained with. Current approaches to OOD detection often require further training the model, and/or statistics about the training data which may no longer be accessible. Additionally, many existing OOD detection methods struggle to maintain performance when transferred across different architectures. Our research tackles these issues by proposing a simple, post-hoc method that does not require access to the training data distribution, keeps a trained network intact, and holds strong performance across a variety of architectures. Our method, Logit Scaling (LTS), as the name suggests, simply scales the logits in a manner that effectively distinguishes between in-distribution (ID) and OOD samples. We tested our method on benchmarks across various scales, including CIFAR-10, CIFAR-100, ImageNet and OpenOOD. The experiments cover 3 ID and 14 OOD datasets, as well as 9 model architectures. Overall, we demonstrate state-of-the-art performance, robustness and adaptability across different architectures, paving the way towards a universally applicable solution for advanced OOD detection.
<div id='section'>Paperid: <span id='pid'>1485, <a href='https://arxiv.org/pdf/2408.14229.pdf' target='_blank'>https://arxiv.org/pdf/2408.14229.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leonid Erlygin, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14229">Holistic Uncertainty Estimation For Open-Set Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty estimation is a critical challenge in open-set recognition, where a probe biometric sample may belong to an unknown identity. It can be addressed through sample quality estimation via probabilistic embeddings. However, the low variance of probabilistic embedding only partly implies a low identification error probability: an embedding of a sample could be close to several classes in a gallery, thus yielding high uncertainty despite high sample quality. We propose HolUE - a holistic uncertainty estimation method based on a Bayesian probabilistic model; it is aware of two sources of ambiguity in the open-set recognition system: (1) the gallery uncertainty caused by overlapping classes and (2) the uncertainty of embeddings. Challenging open-set recognition datasets, such as IJB-C for the image domain and VoxBlink for the audio domain, serve as a testbed for our method. We also provide a new open-set recognition protocol for the identification of whales and dolphins. In all cases, HolUE better identifies recognition errors than alternative uncertainty estimation methods, including those based solely on sample quality.
<div id='section'>Paperid: <span id='pid'>1486, <a href='https://arxiv.org/pdf/2408.12322.pdf' target='_blank'>https://arxiv.org/pdf/2408.12322.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>TamÃ¡s Matuszka, PÃ©ter Hajas, DÃ¡vid Szeghy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12322">Multimodal Foundational Models for Unsupervised 3D General Obstacle Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current autonomous driving perception models primarily rely on supervised learning with predefined categories. However, these models struggle to detect general obstacles not included in the fixed category set due to their variability and numerous edge cases. To address this issue, we propose a combination of multimodal foundational model-based obstacle segmentation with traditional unsupervised computational geometry-based outlier detection. Our approach operates offline, allowing us to leverage non-causality, and utilizes training-free methods. This enables the detection of general obstacles in 3D without the need for expensive retraining. To overcome the limitations of publicly available obstacle detection datasets, we collected and annotated our dataset, which includes various obstacles even in distant regions.
<div id='section'>Paperid: <span id='pid'>1487, <a href='https://arxiv.org/pdf/2408.09791.pdf' target='_blank'>https://arxiv.org/pdf/2408.09791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seoyoung Cho, Jaesung Hwang, Kwan-Young Bak, Dongha Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09791">ALTBI: Constructing Improved Outlier Detection Models via Optimization of Inlier-Memorization Effect</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) is the task of identifying unusual observations (or outliers) from a given or upcoming data by learning unique patterns of normal observations (or inliers). Recently, a study introduced a powerful unsupervised OD (UOD) solver based on a new observation of deep generative models, called inlier-memorization (IM) effect, which suggests that generative models memorize inliers before outliers in early learning stages. In this study, we aim to develop a theoretically principled method to address UOD tasks by maximally utilizing the IM effect. We begin by observing that the IM effect is observed more clearly when the given training data contain fewer outliers. This finding indicates a potential for enhancing the IM effect in UOD regimes if we can effectively exclude outliers from mini-batches when designing the loss function. To this end, we introduce two main techniques: 1) increasing the mini-batch size as the model training proceeds and 2) using an adaptive threshold to calculate the truncated loss function. We theoretically show that these two techniques effectively filter out outliers from the truncated loss function, allowing us to utilize the IM effect to the fullest. Coupled with an additional ensemble strategy, we propose our method and term it Adaptive Loss Truncation with Batch Increment (ALTBI). We provide extensive experimental results to demonstrate that ALTBI achieves state-of-the-art performance in identifying outliers compared to other recent methods, even with significantly lower computation costs. Additionally, we show that our method yields robust performances when combined with privacy-preserving algorithms.
<div id='section'>Paperid: <span id='pid'>1488, <a href='https://arxiv.org/pdf/2408.08432.pdf' target='_blank'>https://arxiv.org/pdf/2408.08432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdur R. Fayjie, Jutika Borah, Florencia Carbone, Jan Tack, Patrick Vandewalle
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08432">Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has shown tremendous progress in a wide range of digital pathology and medical image classification tasks. Its integration into safe clinical decision-making support requires robust and reliable models. However, real-world data comes with diversities that often lie outside the intended source distribution. Moreover, when test samples are dramatically different, clinical decision-making is greatly affected. Quantifying predictive uncertainty in models is crucial for well-calibrated predictions and determining when (or not) to trust a model. Unfortunately, many works have overlooked the importance of predictive uncertainty estimation. This paper evaluates whether predictive uncertainty estimation adds robustness to deep learning-based diagnostic decision-making systems. We investigate the effect of various carcinoma distribution shift scenarios on predictive performance and calibration. We first systematically investigate three popular methods for improving predictive uncertainty: Monte Carlo dropout, deep ensemble, and few-shot learning on lung adenocarcinoma classification as a primary disease in whole slide images. Secondly, we compare the effectiveness of the methods in terms of performance and calibration under clinically relevant distribution shifts such as in-distribution shifts comprising primary disease sub-types and other characterization analysis data; out-of-distribution shifts comprising well-differentiated cases, different organ origin, and imaging modality shifts. While studies on uncertainty estimation exist, to our best knowledge, no rigorous large-scale benchmark compares predictive uncertainty estimation including these dataset shifts for lung carcinoma classification.
<div id='section'>Paperid: <span id='pid'>1489, <a href='https://arxiv.org/pdf/2408.02908.pdf' target='_blank'>https://arxiv.org/pdf/2408.02908.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryohei Oura, Yuji Ito
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02908">Dirichlet Logistic Gaussian Processes for Evaluation of Black-Box Stochastic Systems under Complex Requirements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The requirement-driven performance evaluation of a black-box cyber-physical system (CPS) that utilizes machine learning methods has proven to be an effective way to assess the quality of the CPS. However, the distributional evaluation of the performance has been poorly considered. Although many uncertainty estimation methods have been advocated, they have not successfully estimated highly complex performance distributions under small data. In this paper, we propose a method to distributionally evaluate the performance under complex requirements using small input-trajectory data. To handle the unknown complex probability distributions under small data, we discretize the corresponding performance measure, yielding a discrete random process over an input region. Then, we propose a semiparametric Bayesian model of the discrete process based on a Dirichlet random field whose parameter function is represented by multiple logistic Gaussian processes (LGPs). The Dirichlet posterior parameter function is estimated through the LGP posteriors in a reasonable and conservative fashion. We show that the proposed Bayesian model converges to the true discrete random process as the number of data becomes large enough. We also empirically demonstrate the effectiveness of the proposed method by simulation.
<div id='section'>Paperid: <span id='pid'>1490, <a href='https://arxiv.org/pdf/2408.02052.pdf' target='_blank'>https://arxiv.org/pdf/2408.02052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mateusz Ochal, Massimiliano Patacchiola, Malik Boudiaf, Sen Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02052">EOL: Transductive Few-Shot Open-Set Recognition by Enhancing Outlier Logits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In Few-Shot Learning (FSL), models are trained to recognise unseen objects from a query set, given a few labelled examples from a support set. In standard FSL, models are evaluated on query instances sampled from the same class distribution of the support set. In this work, we explore the more nuanced and practical challenge of Open-Set Few-Shot Recognition (OSFSL). Unlike standard FSL, OSFSL incorporates unknown classes into the query set, thereby requiring the model not only to classify known classes but also to identify outliers. Building on the groundwork laid by previous studies, we define a novel transductive inference technique that leverages the InfoMax principle to exploit the unlabelled query set. We called our approach the Enhanced Outlier Logit (EOL) method. EOL refines class prototype representations through model calibration, effectively balancing the inlier-outlier ratio. This calibration enhances pseudo-label accuracy for the query set and improves the optimisation objective within the transductive inference process. We provide a comprehensive empirical evaluation demonstrating that EOL consistently surpasses traditional methods, recording performance improvements ranging from approximately $+1.3%$ to $+6.3%$ across a variety of classification and outlier detection metrics and benchmarks, even in the presence of inlier-outlier imbalance.
<div id='section'>Paperid: <span id='pid'>1491, <a href='https://arxiv.org/pdf/2407.21263.pdf' target='_blank'>https://arxiv.org/pdf/2407.21263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Tariqul Islam, Jason W. Fleischer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21263">Outlier Detection in Large Radiological Datasets using UMAP</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The success of machine learning algorithms heavily relies on the quality of samples and the accuracy of their corresponding labels. However, building and maintaining large, high-quality datasets is an enormous task. This is especially true for biomedical data and for meta-sets that are compiled from smaller ones, as variations in image quality, labeling, reports, and archiving can lead to errors, inconsistencies, and repeated samples. Here, we show that the uniform manifold approximation and projection (UMAP) algorithm can find these anomalies essentially by forming independent clusters that are distinct from the main (good) data but similar to other points with the same error type. As a representative example, we apply UMAP to discover outliers in the publicly available ChestX-ray14, CheXpert, and MURA datasets. While the results are archival and retrospective and focus on radiological images, the graph-based methods work for any data type and will prove equally beneficial for curation at the time of dataset creation.
<div id='section'>Paperid: <span id='pid'>1492, <a href='https://arxiv.org/pdf/2407.17356.pdf' target='_blank'>https://arxiv.org/pdf/2407.17356.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Hummos, Felipe del RÃ­o, Brabeeba Mien Wang, Julio Hurtado, Cristian B. Calderon, Guangyu Robert Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.17356">Gradient-based inference of abstract task representations for generalization in neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Humans and many animals show remarkably adaptive behavior and can respond differently to the same input depending on their internal goals. The brain not only represents the intermediate abstractions needed to perform a computation but also actively maintains a representation of the computation itself (task abstraction). Such separation of the computation and its abstraction is associated with faster learning, flexible decision-making, and broad generalization capacity. We investigate if such benefits might extend to neural networks trained with task abstractions. For such benefits to emerge, one needs a task inference mechanism that possesses two crucial abilities: First, the ability to infer abstract task representations when no longer explicitly provided (task inference), and second, manipulate task representations to adapt to novel problems (task recomposition). To tackle this, we cast task inference as an optimization problem from a variational inference perspective and ground our approach in an expectation-maximization framework. We show that gradients backpropagated through a neural network to a task representation layer are an efficient heuristic to infer current task demands, a process we refer to as gradient-based inference (GBI). Further iterative optimization of the task representation layer allows for recomposing abstractions to adapt to novel situations. Using a toy example, a novel image classifier, and a language model, we demonstrate that GBI provides higher learning efficiency and generalization to novel tasks and limits forgetting. Moreover, we show that GBI has unique advantages such as preserving information for uncertainty estimation and detecting out-of-distribution samples.
<div id='section'>Paperid: <span id='pid'>1493, <a href='https://arxiv.org/pdf/2407.11873.pdf' target='_blank'>https://arxiv.org/pdf/2407.11873.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Zozoulenko, Thomas Cass, Lukas Gonon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11873">Infinite-dimensional Mahalanobis Distance with Applications to Kernelized Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Mahalanobis distance is a classical tool used to measure the covariance-adjusted distance between points in $\bbR^d$. In this work, we extend the concept of Mahalanobis distance to separable Banach spaces by reinterpreting it as a Cameron-Martin norm associated with a probability measure. This approach leads to a basis-free, data-driven notion of anomaly distance through the so-called variance norm, which can naturally be estimated using empirical measures of a sample. Our framework generalizes the classical $\bbR^d$, functional $(L^2[0,1])^d$, and kernelized settings; importantly, it incorporates non-injective covariance operators. We prove that the variance norm is invariant under invertible bounded linear transformations of the data, extending previous results which are limited to unitary operators. In the Hilbert space setting, we connect the variance norm to the RKHS of the covariance operator and establish consistency and convergence results for estimation using empirical measures. Using the variance norm, we introduce the notion of a kernelized nearest-neighbour Mahalanobis distance. In an empirical study on 12 real-world data sets, we demonstrate that the kernelized nearest-neighbour Mahalanobis distance outperforms the traditional kernelized Mahalanobis distance for multivariate time series novelty detection, using state-of-the-art time series kernels such as the signature, global alignment, and Volterra reservoir kernels.
<div id='section'>Paperid: <span id='pid'>1494, <a href='https://arxiv.org/pdf/2407.11181.pdf' target='_blank'>https://arxiv.org/pdf/2407.11181.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ekaterina Zaychenkova, Dmitrii Iarchuk, Sergey Korchagin, Alexey Zaitsev, Egor Ershov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11181">Expert-aware uncertainty estimation for quality control of neural-based blood typing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In medical diagnostics, accurate uncertainty estimation for neural-based models is essential for complementing second-opinion systems. Despite neural network ensembles' proficiency in this problem, a gap persists between actual uncertainties and predicted estimates. A major difficulty here is the lack of labels on the hardness of examples: a typical dataset includes only ground truth target labels, making the uncertainty estimation problem almost unsupervised. Our novel approach narrows this gap by integrating expert assessments of case complexity into the neural network's learning process, utilizing both definitive target labels and supplementary complexity ratings. We validate our methodology for blood typing, leveraging a new dataset "BloodyWell" unique in augmenting labeled reaction images with complexity scores from six medical specialists. Experiments demonstrate enhancement of our approach in uncertainty prediction, achieving a 2.5-fold improvement with expert labels and a 35% increase in performance with estimates of neural-based expert consensus.
<div id='section'>Paperid: <span id='pid'>1495, <a href='https://arxiv.org/pdf/2407.10844.pdf' target='_blank'>https://arxiv.org/pdf/2407.10844.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joseph Musielewicz, Janice Lan, Matt Uyttendaele, John R. Kitchin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10844">Improved Uncertainty Estimation of Graph Neural Network Potentials Using Engineered Latent Space Distances</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph neural networks (GNNs) have been shown to be astonishingly capable models for molecular property prediction, particularly as surrogates for expensive density functional theory calculations of relaxed energy for novel material discovery. However, one limitation of GNNs in this context is the lack of useful uncertainty prediction methods, as this is critical to the material discovery pipeline. In this work, we show that uncertainty quantification for relaxed energy calculations is more complex than uncertainty quantification for other kinds of molecular property prediction, due to the effect that structure optimizations have on the error distribution. We propose that distribution-free techniques are more useful tools for assessing calibration, recalibrating, and developing uncertainty prediction methods for GNNs performing relaxed energy calculations. We also develop a relaxed energy task for evaluating uncertainty methods for equivariant GNNs, based on distribution-free recalibration and using the Open Catalyst Project dataset. We benchmark a set of popular uncertainty prediction methods on this task, and show that latent distance methods, with our novel improvements, are the most well-calibrated and economical approach for relaxed energy calculations. Finally, we demonstrate that our latent space distance method produces results which align with our expectations on a clustering example, and on specific equation of state and adsorbate coverage examples from outside the training dataset.
<div id='section'>Paperid: <span id='pid'>1496, <a href='https://arxiv.org/pdf/2407.02089.pdf' target='_blank'>https://arxiv.org/pdf/2407.02089.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriele Franch, Elena Tomasi, Rishabh Wanjari, Virginia Poli, Chiara Cardinali, Pier Paolo Alberoni, Marco Cristoforetti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02089">GPTCast: a weather language model for precipitation nowcasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces GPTCast, a generative deep-learning method for ensemble nowcast of radar-based precipitation, inspired by advancements in large language models (LLMs). We employ a GPT model as a forecaster to learn spatiotemporal precipitation dynamics using tokenized radar images. The tokenizer is based on a Quantized Variational Autoencoder featuring a novel reconstruction loss tailored for the skewed distribution of precipitation that promotes faithful reconstruction of high rainfall rates. The approach produces realistic ensemble forecasts and provides probabilistic outputs with accurate uncertainty estimation. The model is trained without resorting to randomness, all variability is learned solely from the data and exposed by model at inference for ensemble generation. We train and test GPTCast using a 6-year radar dataset over the Emilia-Romagna region in Northern Italy, showing superior results compared to state-of-the-art ensemble extrapolation methods.
<div id='section'>Paperid: <span id='pid'>1497, <a href='https://arxiv.org/pdf/2406.10943.pdf' target='_blank'>https://arxiv.org/pdf/2406.10943.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weiqing Xiao, Wei Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10943">Rectified Iterative Disparity for Stereo Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Both uncertainty-assisted and iteration-based methods have achieved great success in stereo matching. However, existing uncertainty estimation methods take a single image and the corresponding disparity as input, which imposes higher demands on the estimation network. In this paper, we propose Cost volume-based disparity Uncertainty Estimation (UEC). Based on the rich similarity information in the cost volume coming from the image pairs, the proposed UEC can achieve competitive performance with low computational cost. Secondly, we propose two methods of uncertainty-assisted disparity estimation, Uncertainty-based Disparity Rectification (UDR) and Uncertainty-based Disparity update Conditioning (UDC). These two methods optimise the disparity update process of the iterative-based approach without adding extra parameters. In addition, we propose Disparity Rectification loss that significantly improves the accuracy of small amount of disparity updates. We present a high-performance stereo architecture, DR Stereo, which is a combination of the proposed methods. Experimental results from SceneFlow, KITTI, Middlebury 2014, and ETH3D show that DR-Stereo achieves very competitive disparity estimation performance.
<div id='section'>Paperid: <span id='pid'>1498, <a href='https://arxiv.org/pdf/2406.04317.pdf' target='_blank'>https://arxiv.org/pdf/2406.04317.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tristan Cinquin, Robert Bamler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04317">Regularized KL-Divergence for Well-Defined Function-Space Variational Inference in Bayesian neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian neural networks (BNN) promise to combine the predictive performance of neural networks with principled uncertainty modeling important for safety-critical systems and decision making. However, posterior uncertainty estimates depend on the choice of prior, and finding informative priors in weight-space has proven difficult. This has motivated variational inference (VI) methods that pose priors directly on the function generated by the BNN rather than on weights. In this paper, we address a fundamental issue with such function-space VI approaches pointed out by Burt et al. (2020), who showed that the objective function (ELBO) is negative infinite for most priors of interest. Our solution builds on generalized VI (Knoblauch et al., 2019) with the regularized KL divergence (Quang, 2019) and is, to the best of our knowledge, the first well-defined variational objective for function-space inference in BNNs with Gaussian process (GP) priors. Experiments show that our method incorporates the properties specified by the GP prior on synthetic and small real-world data sets, and provides competitive uncertainty estimates for regression, classification and out-of-distribution detection compared to BNN baselines with both function and weight-space priors.
<div id='section'>Paperid: <span id='pid'>1499, <a href='https://arxiv.org/pdf/2405.18176.pdf' target='_blank'>https://arxiv.org/pdf/2405.18176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ilia Azizi, Marc-Olivier Boldi, ValÃ©rie Chavez-Demoulin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18176">SEMF: Supervised Expectation-Maximization Framework for Predicting Intervals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces the Supervised Expectation-Maximization Framework (SEMF), a versatile and model-agnostic approach for generating prediction intervals with any ML model. SEMF extends the Expectation-Maximization algorithm, traditionally used in unsupervised learning, to a supervised context, leveraging latent variable modeling for uncertainty estimation. Through extensive empirical evaluation of diverse simulated distributions and 11 real-world tabular datasets, SEMF consistently produces narrower prediction intervals while maintaining the desired coverage probability, outperforming traditional quantile regression methods. Furthermore, without using the quantile (pinball) loss, SEMF allows point predictors, including gradient-boosted trees and neural networks, to be calibrated with conformal quantile regression. The results indicate that SEMF enhances uncertainty quantification under diverse data distributions and is particularly effective for models that otherwise struggle with inherent uncertainty representation.
<div id='section'>Paperid: <span id='pid'>1500, <a href='https://arxiv.org/pdf/2405.18176.pdf' target='_blank'>https://arxiv.org/pdf/2405.18176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ilia Azizi, Marc-Olivier Boldi, Valérie Chavez-Demoulin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18176">SEMF: Supervised Expectation-Maximization Framework for Predicting Intervals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces the Supervised Expectation-Maximization Framework (SEMF), a versatile and model-agnostic approach for generating prediction intervals with any ML model. SEMF extends the Expectation-Maximization algorithm, traditionally used in unsupervised learning, to a supervised context, leveraging latent variable modeling for uncertainty estimation. Through extensive empirical evaluation of diverse simulated distributions and 11 real-world tabular datasets, SEMF consistently produces narrower prediction intervals while maintaining the desired coverage probability, outperforming traditional quantile regression methods. Furthermore, without using the quantile (pinball) loss, SEMF allows point predictors, including gradient-boosted trees and neural networks, to be calibrated with conformal quantile regression. The results indicate that SEMF enhances uncertainty quantification under diverse data distributions and is particularly effective for models that otherwise struggle with inherent uncertainty representation.
<div id='section'>Paperid: <span id='pid'>1501, <a href='https://arxiv.org/pdf/2405.12658.pdf' target='_blank'>https://arxiv.org/pdf/2405.12658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Azizmalayeri, Ameen Abu-Hanna, Giovanni CinÃ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12658">Mitigating Overconfidence in Out-of-Distribution Detection by Capturing Extreme Activations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) instances is crucial for the reliable deployment of machine learning models in real-world scenarios. OOD inputs are commonly expected to cause a more uncertain prediction in the primary task; however, there are OOD cases for which the model returns a highly confident prediction. This phenomenon, denoted as "overconfidence", presents a challenge to OOD detection. Specifically, theoretical evidence indicates that overconfidence is an intrinsic property of certain neural network architectures, leading to poor OOD detection. In this work, we address this issue by measuring extreme activation values in the penultimate layer of neural networks and then leverage this proxy of overconfidence to improve on several OOD detection baselines. We test our method on a wide array of experiments spanning synthetic data and real-world data, tabular and image datasets, multiple architectures such as ResNet and Transformer, different training loss functions, and include the scenarios examined in previous theoretical work. Compared to the baselines, our method often grants substantial improvements, with double-digit increases in OOD detection AUC, and it does not damage performance in any scenario.
<div id='section'>Paperid: <span id='pid'>1502, <a href='https://arxiv.org/pdf/2404.10314.pdf' target='_blank'>https://arxiv.org/pdf/2404.10314.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexey Kornaev, Elena Kornaeva, Oleg Ivanov, Ilya Pershin, Danis Alukaev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10314">Awareness of uncertainty in classification using a multivariate model and multi-views</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One of the ways to make artificial intelligence more natural is to give it some room for doubt. Two main questions should be resolved in that way. First, how to train a model to estimate uncertainties of its own predictions? And then, what to do with the uncertain predictions if they appear? First, we proposed an uncertainty-aware negative log-likelihood loss for the case of N-dimensional multivariate normal distribution with spherical variance matrix to the solution of N-classes classification tasks. The loss is similar to the heteroscedastic regression loss. The proposed model regularizes uncertain predictions, and trains to calculate both the predictions and their uncertainty estimations. The model fits well with the label smoothing technique. Second, we expanded the limits of data augmentation at the training and test stages, and made the trained model to give multiple predictions for a given number of augmented versions of each test sample. Given the multi-view predictions together with their uncertainties and confidences, we proposed several methods to calculate final predictions, including mode values and bin counts with soft and hard weights. For the latter method, we formalized the model tuning task in the form of multimodal optimization with non-differentiable criteria of maximum accuracy, and applied particle swarm optimization to solve the tuning task. The proposed methodology was tested using CIFAR-10 dataset with clean and noisy labels and demonstrated good results in comparison with other uncertainty estimation methods related to sample selection, co-teaching, and label smoothing.
<div id='section'>Paperid: <span id='pid'>1503, <a href='https://arxiv.org/pdf/2404.07815.pdf' target='_blank'>https://arxiv.org/pdf/2404.07815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rishabh Ranjan, Saurabh Garg, Mrigank Raman, Carlos Guestrin, Zachary Lipton
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07815">Post-Hoc Reversal: Are We Selecting Models Prematurely?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trained models are often composed with post-hoc transforms such as temperature scaling (TS), ensembling and stochastic weight averaging (SWA) to improve performance, robustness, uncertainty estimation, etc. However, such transforms are typically applied only after the base models have already been finalized by standard means. In this paper, we challenge this practice with an extensive empirical study. In particular, we demonstrate a phenomenon that we call post-hoc reversal, where performance trends are reversed after applying post-hoc transforms. This phenomenon is especially prominent in high-noise settings. For example, while base models overfit badly early in training, both ensembling and SWA favor base models trained for more epochs. Post-hoc reversal can also prevent the appearance of double descent and mitigate mismatches between test loss and test error seen in base models. Preliminary analyses suggest that these transforms induce reversal by suppressing the influence of mislabeled examples, exploiting differences in their learning dynamics from those of clean examples. Based on our findings, we propose post-hoc selection, a simple technique whereby post-hoc metrics inform model development decisions such as early stopping, checkpointing, and broader hyperparameter choices. Our experiments span real-world vision, language, tabular and graph datasets. On an LLM instruction tuning dataset, post-hoc selection results in >1.5x MMLU improvement compared to naive selection.
<div id='section'>Paperid: <span id='pid'>1504, <a href='https://arxiv.org/pdf/2404.04456.pdf' target='_blank'>https://arxiv.org/pdf/2404.04456.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Asad, Ihsan Ullah, Ganesh Sistu, Michael G. Madden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04456">Beyond the Known: Adversarial Autoencoders in Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In novelty detection, the goal is to decide if a new data point should be categorized as an inlier or an outlier, given a training dataset that primarily captures the inlier distribution. Recent approaches typically use deep encoder and decoder network frameworks to derive a reconstruction error, and employ this error either to determine a novelty score, or as the basis for a one-class classifier. In this research, we use a similar framework but with a lightweight deep network, and we adopt a probabilistic score with reconstruction error. Our methodology calculates the probability of whether the sample comes from the inlier distribution or not. This work makes two key contributions. The first is that we compute the novelty probability by linearizing the manifold that holds the structure of the inlier distribution. This allows us to interpret how the probability is distributed and can be determined in relation to the local coordinates of the manifold tangent space. The second contribution is that we improve the training protocol for the network. Our results indicate that our approach is effective at learning the target class, and it outperforms recent state-of-the-art methods on several benchmark datasets.
<div id='section'>Paperid: <span id='pid'>1505, <a href='https://arxiv.org/pdf/2404.00589.pdf' target='_blank'>https://arxiv.org/pdf/2404.00589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenyu Qian, Yiming Qian, Yuting Song, Fei Gao, Hai Jin, Chen Yu, Xia Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00589">Harnessing the Power of Large Language Model for Uncertainty Aware Graph Processing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Handling graph data is one of the most difficult tasks. Traditional techniques, such as those based on geometry and matrix factorization, rely on assumptions about the data relations that become inadequate when handling large and complex graph data. On the other hand, deep learning approaches demonstrate promising results in handling large graph data, but they often fall short of providing interpretable explanations. To equip the graph processing with both high accuracy and explainability, we introduce a novel approach that harnesses the power of a large language model (LLM), enhanced by an uncertainty-aware module to provide a confidence score on the generated answer. We experiment with our approach on two graph processing tasks: few-shot knowledge graph completion and graph classification. Our results demonstrate that through parameter efficient fine-tuning, the LLM surpasses state-of-the-art algorithms by a substantial margin across ten diverse benchmark datasets. Moreover, to address the challenge of explainability, we propose an uncertainty estimation based on perturbation, along with a calibration scheme to quantify the confidence scores of the generated answers. Our confidence measure achieves an AUC of 0.8 or higher on seven out of the ten datasets in predicting the correctness of the answer generated by LLM.
<div id='section'>Paperid: <span id='pid'>1506, <a href='https://arxiv.org/pdf/2403.17224.pdf' target='_blank'>https://arxiv.org/pdf/2403.17224.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mihir Mulye, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17224">Uncertainty Quantification for Gradient-based Explanations in Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explanation methods help understand the reasons for a model's prediction. These methods are increasingly involved in model debugging, performance optimization, and gaining insights into the workings of a model. With such critical applications of these methods, it is imperative to measure the uncertainty associated with the explanations generated by these methods. In this paper, we propose a pipeline to ascertain the explanation uncertainty of neural networks by combining uncertainty estimation methods and explanation methods. We use this pipeline to produce explanation distributions for the CIFAR-10, FER+, and California Housing datasets. By computing the coefficient of variation of these distributions, we evaluate the confidence in the explanation and determine that the explanations generated using Guided Backpropagation have low uncertainty associated with them. Additionally, we compute modified pixel insertion/deletion metrics to evaluate the quality of the generated explanations.
<div id='section'>Paperid: <span id='pid'>1507, <a href='https://arxiv.org/pdf/2403.17212.pdf' target='_blank'>https://arxiv.org/pdf/2403.17212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matias Valdenegro-Toro, Mihir Mulye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17212">Sanity Checks for Explanation Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explanations for machine learning models can be hard to interpret or be wrong. Combining an explanation method with an uncertainty estimation method produces explanation uncertainty. Evaluating explanation uncertainty is difficult. In this paper we propose sanity checks for uncertainty explanation methods, where a weight and data randomization tests are defined for explanations with uncertainty, allowing for quick tests to combinations of uncertainty and explanation methods. We experimentally show the validity and effectiveness of these tests on the CIFAR10 and California Housing datasets, noting that Ensembles seem to consistently pass both tests with Guided Backpropagation, Integrated Gradients, and LIME explanations.
<div id='section'>Paperid: <span id='pid'>1508, <a href='https://arxiv.org/pdf/2403.13324.pdf' target='_blank'>https://arxiv.org/pdf/2403.13324.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>K Huang, G Song, Hanwen Su, Jiyan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13324">Out-of-Distribution Detection Using Peer-Class Generated by Large Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical task to ensure the reliability and security of machine learning models deployed in real-world applications. Conventional methods for OOD detection that rely on single-modal information, often struggle to capture the rich variety of OOD instances. The primary difficulty in OOD detection arises when an input image has numerous similarities to a particular class in the in-distribution (ID) dataset, e.g., wolf to dog, causing the model to misclassify it. Nevertheless, it may be easy to distinguish these classes in the semantic domain. To this end, in this paper, a novel method called ODPC is proposed, in which specific prompts to generate OOD peer classes of ID semantics are designed by a large language model as an auxiliary modality to facilitate detection. Moreover, a contrastive loss based on OOD peer classes is devised to learn compact representations of ID classes and improve the clarity of boundaries between different classes. The extensive experiments on five benchmark datasets show that the method we propose can yield state-of-the-art results.
<div id='section'>Paperid: <span id='pid'>1509, <a href='https://arxiv.org/pdf/2403.13170.pdf' target='_blank'>https://arxiv.org/pdf/2403.13170.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jagatpreet Singh Nir, Dennis Giaya, Hanumant Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13170">On Designing Consistent Covariance Recovery from a Deep Learning Visual Odometry Engine</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning techniques have significantly advanced in providing accurate visual odometry solutions by leveraging large datasets. However, generating uncertainty estimates for these methods remains a challenge. Traditional sensor fusion approaches in a Bayesian framework are well-established, but deep learning techniques with millions of parameters lack efficient methods for uncertainty estimation.
  This paper addresses the issue of uncertainty estimation for pre-trained deep-learning models in monocular visual odometry. We propose formulating a factor graph on an implicit layer of the deep learning network to recover relative covariance estimates, which allows us to determine the covariance of the Visual Odometry (VO) solution. We showcase the consistency of the deep learning engine's covariance approximation with an empirical analysis of the covariance model on the EUROC datasets to demonstrate the correctness of our formulation.
<div id='section'>Paperid: <span id='pid'>1510, <a href='https://arxiv.org/pdf/2403.11532.pdf' target='_blank'>https://arxiv.org/pdf/2403.11532.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Novello, Joseba Dalmau, LÃ©o Andeol
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11532">Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Research on Out-Of-Distribution (OOD) detection focuses mainly on building scores that efficiently distinguish OOD data from In Distribution (ID) data. On the other hand, Conformal Prediction (CP) uses non-conformity scores to construct prediction sets with probabilistic coverage guarantees. In this work, we propose to use CP to better assess the efficiency of OOD scores. Specifically, we emphasize that in standard OOD benchmark settings, evaluation metrics can be overly optimistic due to the finite sample size of the test dataset. Based on the work of (Bates et al., 2022), we define new conformal AUROC and conformal FRP@TPR95 metrics, which are corrections that provide probabilistic conservativeness guarantees on the variability of these metrics. We show the effect of these corrections on two reference OOD and anomaly detection benchmarks, OpenOOD (Yang et al., 2022) and ADBench (Han et al., 2022). We also show that the benefits of using OOD together with CP apply the other way around by using OOD scores as non-conformity scores, which results in improving upon current CP methods. One of the key messages of these contributions is that since OOD is concerned with designing scores and CP with interpreting these scores, the two fields may be inherently intertwined.
<div id='section'>Paperid: <span id='pid'>1511, <a href='https://arxiv.org/pdf/2403.11418.pdf' target='_blank'>https://arxiv.org/pdf/2403.11418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jurijs Nazarovs, Zhichun Huang, Xingjian Zhen, Sourav Pal, Rudrasis Chakraborty, Vikas Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11418">Variational Sampling of Temporal Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A deterministic temporal process can be determined by its trajectory, an element in the product space of (a) initial condition $z_0 \in \mathcal{Z}$ and (b) transition function $f: (\mathcal{Z}, \mathcal{T}) \to \mathcal{Z}$ often influenced by the control of the underlying dynamical system. Existing methods often model the transition function as a differential equation or as a recurrent neural network. Despite their effectiveness in predicting future measurements, few results have successfully established a method for sampling and statistical inference of trajectories using neural networks, partially due to constraints in the parameterization. In this work, we introduce a mechanism to learn the distribution of trajectories by parameterizing the transition function $f$ explicitly as an element in a function space. Our framework allows efficient synthesis of novel trajectories, while also directly providing a convenient tool for inference, i.e., uncertainty estimation, likelihood evaluations and out of distribution detection for abnormal trajectories. These capabilities can have implications for various downstream tasks, e.g., simulation and evaluation for reinforcement learning.
<div id='section'>Paperid: <span id='pid'>1512, <a href='https://arxiv.org/pdf/2403.06681.pdf' target='_blank'>https://arxiv.org/pdf/2403.06681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jintao Huang, Yiu-Ming Cheung, Chi-Man Vong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06681">PLOOD: Partial Label Learning with Out-of-distribution Objects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing Partial Label Learning (PLL) methods posit that training and test data adhere to the same distribution, a premise that frequently does not hold in practical application where Out-of-Distribution (OOD) objects are present. We introduce the OODPLL paradigm to tackle this significant yet underexplored issue. And our newly proposed PLOOD framework enables PLL to tackle OOD objects through Positive-Negative Sample Augmented (PNSA) feature learning and Partial Energy (PE)-based label refinement. The PNSA module enhances feature discrimination and OOD recognition by simulating in- and out-of-distribution instances, which employ structured positive and negative sample augmentation, in contrast to conventional PLL methods struggling to distinguish OOD samples. The PE scoring mechanism combines label confidence with energy-based uncertainty estimation, thereby reducing the impact of imprecise supervision and effectively achieving label disambiguation. Experimental results on CIFAR-10 and CIFAR-100, alongside various OOD datasets, demonstrate that conventional PLL methods exhibit substantial degradation in OOD scenarios, underscoring the necessity of incorporating OOD considerations in PLL approaches. Ablation studies show that PNSA feature learning and PE-based label refinement are necessary for PLOOD to work, offering a robust solution for open-set PLL problems.
<div id='section'>Paperid: <span id='pid'>1513, <a href='https://arxiv.org/pdf/2402.17686.pdf' target='_blank'>https://arxiv.org/pdf/2402.17686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis Itza Vazquez-Salazar, Silvan KÃ¤ser, Markus Meuwly
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17686">Outlier-Detection for Reactive Machine Learned Potential Energy Surfaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification (UQ) to detect samples with large expected errors (outliers) is applied to reactive molecular potential energy surfaces (PESs). Three methods - Ensembles, Deep Evidential Regression (DER), and Gaussian Mixture Models (GMM) - were applied to the H-transfer reaction between ${\it syn-}$Criegee and vinyl hydroxyperoxide. The results indicate that ensemble models provide the best results for detecting outliers, followed by GMM. For example, from a pool of 1000 structures with the largest uncertainty, the detection quality for outliers is $\sim 90$ \% and $\sim 50$ \%, respectively, if 25 or 1000 structures with large errors are sought. On the contrary, the limitations of the statistical assumptions of DER greatly impacted its prediction capabilities. Finally, a structure-based indicator was found to be correlated with large average error, which may help to rapidly classify new structures into those that provide an advantage for refining the neural network.
<div id='section'>Paperid: <span id='pid'>1514, <a href='https://arxiv.org/pdf/2402.14892.pdf' target='_blank'>https://arxiv.org/pdf/2402.14892.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paola Arrubarrena, Maud Lemercier, Bojan Nikolic, Terry Lyons, Thomas Cass
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14892">Novelty Detection on Radio Astronomy Data using Signatures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce SigNova, a new semi-supervised framework for detecting anomalies in streamed data. While our initial examples focus on detecting radio-frequency interference (RFI) in digitized signals within the field of radio astronomy, it is important to note that SigNova's applicability extends to any type of streamed data. The framework comprises three primary components. Firstly, we use the signature transform to extract a canonical collection of summary statistics from observational sequences. This allows us to represent variable-length visibility samples as finite-dimensional feature vectors. Secondly, each feature vector is assigned a novelty score, calculated as the Mahalanobis distance to its nearest neighbor in an RFI-free training set. By thresholding these scores we identify observation ranges that deviate from the expected behavior of RFI-free visibility samples without relying on stringent distributional assumptions. Thirdly, we integrate this anomaly detector with Pysegments, a segmentation algorithm, to localize consecutive observations contaminated with RFI, if any. This approach provides a compelling alternative to classical windowing techniques commonly used for RFI detection. Importantly, the complexity of our algorithm depends on the RFI pattern rather than on the size of the observation window. We demonstrate how SigNova improves the detection of various types of RFI (e.g., broadband and narrowband) in time-frequency visibility data. We validate our framework on the Murchison Widefield Array (MWA) telescope and simulated data and the Hydrogen Epoch of Reionization Array (HERA).
<div id='section'>Paperid: <span id='pid'>1515, <a href='https://arxiv.org/pdf/2402.14418.pdf' target='_blank'>https://arxiv.org/pdf/2402.14418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasily Kostumov, Bulat Nutfullin, Oleg Pilipenko, Eugene Ilyushin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14418">Uncertainty-Aware Evaluation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in popularity recently due to their impressive performance in several vision-language tasks. Current evaluation methods, however, overlook an essential component: uncertainty, which is crucial for a comprehensive assessment of VLMs. Addressing this oversight, we present a benchmark incorporating uncertainty quantification into evaluating VLMs.
  Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question Answering (VQA) task. We examine models on 5 datasets that evaluate various vision-language capabilities.
  Using conformal prediction as an uncertainty estimation approach, we demonstrate that the models' uncertainty is not aligned with their accuracy. Specifically, we show that models with the highest accuracy may also have the highest uncertainty, which confirms the importance of measuring it for VLMs. Our empirical findings also reveal a correlation between model uncertainty and its language model part.
<div id='section'>Paperid: <span id='pid'>1516, <a href='https://arxiv.org/pdf/2402.14184.pdf' target='_blank'>https://arxiv.org/pdf/2402.14184.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Polina Proskura, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14184">Beyond Simple Averaging: Improving NLP Ensemble Performance with Topological-Data-Analysis-Based Weighting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In machine learning, ensembles are important tools for improving the model performance. In natural language processing specifically, ensembles boost the performance of a method due to multiple large models available in open source. However, existing approaches mostly rely on simple averaging of predictions by ensembles with equal weights for each model, ignoring differences in the quality and conformity of models. We propose to estimate weights for ensembles of NLP models using not only knowledge of their individual performance but also their similarity to each other. By adopting distance measures based on Topological Data Analysis (TDA), we improve our ensemble. The quality improves for both text classification accuracy and relevant uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1517, <a href='https://arxiv.org/pdf/2402.10477.pdf' target='_blank'>https://arxiv.org/pdf/2402.10477.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Genki Osada, Tsubasa Takahashi, Takashi Nishide
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10477">Understanding Likelihood of Normalizing Flow and Image Complexity through the Lens of Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial to safety-critical machine learning applications and has been extensively studied. While recent studies have predominantly focused on classifier-based methods, research on deep generative model (DGM)-based methods have lagged relatively. This disparity may be attributed to a perplexing phenomenon: DGMs often assign higher likelihoods to unknown OOD inputs than to their known training data. This paper focuses on explaining the underlying mechanism of this phenomenon. We propose a hypothesis that less complex images concentrate in high-density regions in the latent space, resulting in a higher likelihood assignment in the Normalizing Flow (NF). We experimentally demonstrate its validity for five NF architectures, concluding that their likelihood is untrustworthy. Additionally, we show that this problem can be alleviated by treating image complexity as an independent variable. Finally, we provide evidence of the potential applicability of our hypothesis in another DGM, PixelCNN++.
<div id='section'>Paperid: <span id='pid'>1518, <a href='https://arxiv.org/pdf/2402.06537.pdf' target='_blank'>https://arxiv.org/pdf/2402.06537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Evan D. Cook, Marc-Antoine Lavoie, Steven L. Waslander
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06537">Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.
<div id='section'>Paperid: <span id='pid'>1519, <a href='https://arxiv.org/pdf/2402.06509.pdf' target='_blank'>https://arxiv.org/pdf/2402.06509.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alberto Testoni, Raquel FernÃ¡ndez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06509">Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importance of equipping dialogue systems with the ability to assess their own uncertainty and exploit in interaction.
<div id='section'>Paperid: <span id='pid'>1520, <a href='https://arxiv.org/pdf/2401.09492.pdf' target='_blank'>https://arxiv.org/pdf/2401.09492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>RubÃ©n Antonio GarcÃ­a-Ruiz, JosÃ© Luis Blanco-Claraco, Javier LÃ³pez-MartÃ­nez, Ãngel JesÃºs CallejÃ³n-Ferre
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.09492">Uncertainty-Aware Calibration of a Hot-Wire Anemometer With Gaussian Process Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Expensive ultrasonic anemometers are usually required to measure wind speed accurately. The aim of this work is to overcome the loss of accuracy of a low cost hot-wire anemometer caused by the changes of air temperature, by means of a probabilistic calibration using Gaussian Process Regression. Gaussian Process Regression is a non-parametric, Bayesian, and supervised learning method designed to make predictions of an unknown target variable as a function of one or more known input variables. Our approach is validated against real datasets, obtaining a good performance in inferring the actual wind speed values. By performing, before its real use in the field, a calibration of the hot-wire anemometer taking into account air temperature, permits that the wind speed can be estimated for the typical range of ambient temperatures, including a grounded uncertainty estimation for each speed measure.
<div id='section'>Paperid: <span id='pid'>1521, <a href='https://arxiv.org/pdf/2401.05453.pdf' target='_blank'>https://arxiv.org/pdf/2401.05453.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alastair Anderberg, James Bailey, Ricardo J. G. B. Campello, Michael E. Houle, Henrique O. Marques, MiloÅ¡ RadovanoviÄ, Arthur Zimek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05453">Dimensionality-Aware Outlier Detection: Theoretical and Experimental Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a nonparametric method for outlier detection that takes full account of local variations in intrinsic dimensionality within the dataset. Using the theory of Local Intrinsic Dimensionality (LID), our 'dimensionality-aware' outlier detection method, DAO, is derived as an estimator of an asymptotic local expected density ratio involving the query point and a close neighbor drawn at random. The dimensionality-aware behavior of DAO is due to its use of local estimation of LID values in a theoretically-justified way. Through comprehensive experimentation on more than 800 synthetic and real datasets, we show that DAO significantly outperforms three popular and important benchmark outlier detection methods: Local Outlier Factor (LOF), Simplified LOF, and kNN.
<div id='section'>Paperid: <span id='pid'>1522, <a href='https://arxiv.org/pdf/2312.17601.pdf' target='_blank'>https://arxiv.org/pdf/2312.17601.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dhruv Dhamani, Mary Lou Maher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.17601">The Tyranny of Possibilities in the Design of Task-Oriented LLM Systems: A Scoping Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This scoping survey focuses on our current understanding of the design space for task-oriented LLM systems and elaborates on definitions and relationships among the available design parameters. The paper begins by defining a minimal task-oriented LLM system and exploring the design space of such systems through a thought experiment contemplating the performance of diverse LLM system configurations (involving single LLMs, single LLM-based agents, and multiple LLM-based agent systems) on a complex software development task and hypothesizes the results. We discuss a pattern in our results and formulate them into three conjectures. While these conjectures may be partly based on faulty assumptions, they provide a starting point for future research. The paper then surveys a select few design parameters: covering and organizing research in LLM augmentation, prompting techniques, and uncertainty estimation, and discussing their significance. The paper notes the lack of focus on computational and energy efficiency in evaluating research in these areas. Our survey findings provide a basis for developing the concept of linear and non-linear contexts, which we define and use to enable an agent-centric projection of prompting techniques providing a lens through which prompting techniques can be viewed as multi-agent systems. The paper discusses the implications of this lens, for the cross-pollination of research between LLM prompting and LLM-based multi-agent systems; and also, for the generation of synthetic training data based on existing prompting techniques in research. In all, the scoping survey presents seven conjectures that can help guide future research efforts.
<div id='section'>Paperid: <span id='pid'>1523, <a href='https://arxiv.org/pdf/2312.17411.pdf' target='_blank'>https://arxiv.org/pdf/2312.17411.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Melrose Roderick, Felix Berkenkamp, Fatemeh Sheikholeslami, Zico Kolter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.17411">Generative Posterior Networks for Approximately Bayesian Epistemic Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many real-world problems, there is a limited set of training data, but an abundance of unlabeled data. We propose a new method, Generative Posterior Networks (GPNs), that uses unlabeled data to estimate epistemic uncertainty in high-dimensional problems. A GPN is a generative model that, given a prior distribution over functions, approximates the posterior distribution directly by regularizing the network towards samples from the prior. We prove theoretically that our method indeed approximates the Bayesian posterior and show empirically that it improves epistemic uncertainty estimation and scalability over competing methods.
<div id='section'>Paperid: <span id='pid'>1524, <a href='https://arxiv.org/pdf/2312.07101.pdf' target='_blank'>https://arxiv.org/pdf/2312.07101.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Madalina Olteanu, Fabrice Rossi, Florian Yger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.07101">Meta-survey on outlier and anomaly detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The impact of outliers and anomalies on model estimation and data  processing is of paramount importance, as evidenced by the extensive  body of research spanning various fields over several decades:  thousands of research papers have been published on the subject.  As  a consequence, numerous reviews, surveys, and textbooks have sought  to summarize the existing literature, encompassing a wide range of  methods from both the statistical and data mining  communities. While these endeavors to organize and summarize the  research are invaluable, they face inherent challenges due to the  pervasive nature of outliers and anomalies in all data-intensive  applications, irrespective of the specific application field or  scientific discipline. As a result, the resulting collection of  papers remains voluminous and somewhat heterogeneous.  To address the need for knowledge organization in this domain, this  paper implements the first systematic meta-survey of general surveys  and reviews on outlier and anomaly detection. Employing a classical  systematic survey approach, the study collects nearly 500 papers  using two specialized scientific search engines. From this  comprehensive collection, a subset of 56 papers that claim to be  general surveys on outlier detection is selected using a snowball  search technique to enhance field coverage. A meticulous quality  assessment phase further refines the selection to a subset of 25  high-quality general surveys.   Using this curated collection, the paper investigates the evolution  of the outlier detection field over a 20-year period, revealing  emerging themes and methods. Furthermore, an analysis of the surveys  sheds light on the survey writing practices adopted by scholars from  different communities who have contributed to this field.    Finally, the paper delves into several topics where consensus has  emerged from the literature. These include taxonomies of outlier  types, challenges posed by high-dimensional data, the importance of  anomaly scores, the impact of learning conditions, difficulties in  benchmarking, and the significance of neural  networks. Non-consensual aspects are also discussed, particularly  the distinction between local and global outliers and the challenges  in organizing detection methods into meaningful taxonomies.
<div id='section'>Paperid: <span id='pid'>1525, <a href='https://arxiv.org/pdf/2311.14754.pdf' target='_blank'>https://arxiv.org/pdf/2311.14754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Naveen Karunanayake, Suranga Seneviratne, Sanjay Chawla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.14754">ExCeL : Combined Extreme and Collective Logit Information for Enhancing Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models often exhibit overconfidence in predicting out-of-distribution (OOD) data, underscoring the crucial role of OOD detection in ensuring reliability in predictions. Among various OOD detection approaches, post-hoc detectors have gained significant popularity, primarily due to their ease of use and implementation. However, the effectiveness of most post-hoc OOD detectors has been constrained as they rely solely either on extreme information, such as the maximum logit, or on the collective information (i.e., information spanned across classes or training samples) embedded within the output layer. In this paper, we propose ExCeL that combines both extreme and collective information within the output layer for enhanced accuracy in OOD detection. We leverage the logit of the top predicted class as the extreme information (i.e., the maximum logit), while the collective information is derived in a novel approach that involves assessing the likelihood of other classes appearing in subsequent ranks across various training samples. Our idea is motivated by the observation that, for in-distribution (ID) data, the ranking of classes beyond the predicted class is more deterministic compared to that in OOD data. Experiments conducted on CIFAR100 and ImageNet-200 datasets demonstrate that ExCeL consistently is among the five top-performing methods out of twenty-one existing post-hoc baselines when the joint performance on near-OOD and far-OOD is considered (i.e., in terms of AUROC and FPR95). Furthermore, ExCeL shows the best overall performance across both datasets, unlike other baselines that work best on one dataset but has a performance drop in the other.
<div id='section'>Paperid: <span id='pid'>1526, <a href='https://arxiv.org/pdf/2311.09004.pdf' target='_blank'>https://arxiv.org/pdf/2311.09004.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simone Caldarella, Elisa Ricci, Rahaf Aljundi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09004">Incremental Object-Based Novelty Detection with Feedback Loop</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Object-based Novelty Detection (ND) aims to identify unknown objects that do not belong to classes seen during training by an object detection model. The task is particularly crucial in real-world applications, as it allows to avoid potentially harmful behaviours, e.g. as in the case of object detection models adopted in a self-driving car or in an autonomous robot. Traditional approaches to ND focus on one time offline post processing of the pretrained object detection output, leaving no possibility to improve the model robustness after training and discarding the abundant amount of out-of-distribution data encountered during deployment. In this work, we propose a novel framework for object-based ND, assuming that human feedback can be requested on the predicted output and later incorporated to refine the ND model without negatively affecting the main object detection performance. This refinement operation is repeated whenever new feedback is available. To tackle this new formulation of the problem for object detection, we propose a lightweight ND module attached on top of a pre-trained object detection model, which is incrementally updated through a feedback loop. We also propose a new benchmark to evaluate methods on this new setting and test extensively our ND approach against baselines, showing increased robustness and a successful incorporation of the received feedback.
<div id='section'>Paperid: <span id='pid'>1527, <a href='https://arxiv.org/pdf/2311.06958.pdf' target='_blank'>https://arxiv.org/pdf/2311.06958.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christina Winkler, David Rolnick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.06958">Towards Climate Variable Prediction with Conditioned Spatio-Temporal Normalizing Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates how conditional normalizing flows can be applied to remote sensing data products in climate science for spatio-temporal prediction. The method is chosen due to its desired properties such as exact likelihood computation, predictive uncertainty estimation and efficient inference and sampling which facilitates faster exploration of climate scenarios. Experimental findings reveal that the conditioned spatio-temporal flow surpasses both deterministic and stochastic baselines in prolonged rollout scenarios. It exhibits stable extrapolation beyond the training time horizon for extended rollout durations. These findings contribute valuable insights to the field of spatio-temporal modeling, with potential applications spanning diverse scientific disciplines.
<div id='section'>Paperid: <span id='pid'>1528, <a href='https://arxiv.org/pdf/2311.05473.pdf' target='_blank'>https://arxiv.org/pdf/2311.05473.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Walter Nelson, Jonathan Ranisau, Jeremy Petch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.05473">Do Ensembling and Meta-Learning Improve Outlier Detection in Randomized Controlled Trials?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern multi-centre randomized controlled trials (MCRCTs) collect massive amounts of tabular data, and are monitored intensively for irregularities by humans. We began by empirically evaluating 6 modern machine learning-based outlier detection algorithms on the task of identifying irregular data in 838 datasets from 7 real-world MCRCTs with a total of 77,001 patients from over 44 countries. Our results reinforce key findings from prior work in the outlier detection literature on data from other domains. Existing algorithms often succeed at identifying irregularities without any supervision, with at least one algorithm exhibiting positive performance 70.6% of the time. However, performance across datasets varies substantially with no single algorithm performing consistently well, motivating new techniques for unsupervised model selection or other means of aggregating potentially discordant predictions from multiple candidate models. We propose the Meta-learned Probabilistic Ensemble (MePE), a simple algorithm for aggregating the predictions of multiple unsupervised models, and show that it performs favourably compared to recent meta-learning approaches for outlier detection model selection. While meta-learning shows promise, small ensembles outperform all forms of meta-learning on average, a negative result that may guide the application of current outlier detection approaches in healthcare and other real-world domains.
<div id='section'>Paperid: <span id='pid'>1529, <a href='https://arxiv.org/pdf/2310.14960.pdf' target='_blank'>https://arxiv.org/pdf/2310.14960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaituo Zhang, Wei Huang, Bingyang Zhang, Jinshan Xu, Xuhua Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14960">Robust Outlier Detection Method Based on Local Entropy and Global Density</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>By now, most outlier-detection algorithms struggle to accurately detect both point anomalies and cluster anomalies simultaneously. Furthermore, a few K-nearest-neighbor-based anomaly-detection methods exhibit excellent performance on many datasets, but their sensitivity to the value of K is a critical issue that needs to be addressed. To address these challenges, we propose a novel robust anomaly detection method, called Entropy Density Ratio Outlier Detection (EDROD). This method incorporates the probability density of each sample as the global feature, and the local entropy around each sample as the local feature, to obtain a comprehensive indicator of abnormality for each sample, which is called Entropy Density Ratio (EDR) for short in this paper. By comparing several competing anomaly detection methods on both synthetic and real-world datasets, it is found that the EDROD method can detect both point anomalies and cluster anomalies simultaneously with accurate performance. In addition, it is also found that the EDROD method exhibits strong robustness to the number of selected neighboring samples, the dimension of samples in the dataset, and the size of the dataset. Therefore, the proposed EDROD method can be applied to a variety of real-world datasets to detect anomalies with accurate and robust performances.
<div id='section'>Paperid: <span id='pid'>1530, <a href='https://arxiv.org/pdf/2310.09926.pdf' target='_blank'>https://arxiv.org/pdf/2310.09926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiladitya Dutta, Hongbo Wei, Lars van der Laan, Ahmed M. Alaa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.09926">Estimating Uncertainty in Multimodal Foundation Models using Public Internet Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models are trained on vast amounts of data at scale using self-supervised learning, enabling adaptation to a wide range of downstream tasks. At test time, these models exhibit zero-shot capabilities through which they can classify previously unseen (user-specified) categories. In this paper, we address the problem of quantifying uncertainty in these zero-shot predictions. We propose a heuristic approach for uncertainty estimation in zero-shot settings using conformal prediction with web data. Given a set of classes at test time, we conduct zero-shot classification with CLIP-style models using a prompt template, e.g., "an image of a <category>", and use the same template as a search query to source calibration data from the open web. Given a web-based calibration set, we apply conformal prediction with a novel conformity score that accounts for potential errors in retrieved web data. We evaluate the utility of our proposed method in Biomedical foundation models; our preliminary results show that web-based conformal prediction sets achieve the target coverage with satisfactory efficiency on a variety of biomedical datasets.
<div id='section'>Paperid: <span id='pid'>1531, <a href='https://arxiv.org/pdf/2310.07493.pdf' target='_blank'>https://arxiv.org/pdf/2310.07493.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Finn Rietz, Johannes Andreas Stork
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07493">Diversity for Contingency: Learning Diverse Behaviors for Efficient Adaptation and Transfer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discovering all useful solutions for a given task is crucial for transferable RL agents, to account for changes in the task or transition dynamics. This is not considered by classical RL algorithms that are only concerned with finding the optimal policy, given the current task and dynamics. We propose a simple method for discovering all possible solutions of a given task, to obtain an agent that performs well in the transfer setting and adapts quickly to changes in the task or transition dynamics. Our method iteratively learns a set of policies, while each subsequent policy is constrained to yield a solution that is unlikely under all previous policies. Unlike prior methods, our approach does not require learning additional models for novelty detection and avoids balancing task and novelty reward signals, by directly incorporating the constraint into the action selection and optimization steps.
<div id='section'>Paperid: <span id='pid'>1532, <a href='https://arxiv.org/pdf/2310.06572.pdf' target='_blank'>https://arxiv.org/pdf/2310.06572.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geoffrey Daniel, Mohamed Bahi Yahiaoui, Claude Comtat, Sebastien Jan, Olga Kochebina, Jean-Marc Martinez, Viktoriya Sergeyeva, Viatcheslav Sharyy, Chi-Hsun Sung, Dominique Yvon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06572">Deep Learning reconstruction with uncertainty estimation for $Î³$ photon interaction in fast scintillator detectors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This article presents a physics-informed deep learning method for the quantitative estimation of the spatial coordinates of gamma interactions within a monolithic scintillator, with a focus on Positron Emission Tomography (PET) imaging. A Density Neural Network approach is designed to estimate the 2-dimensional gamma photon interaction coordinates in a fast lead tungstate (PbWO4) monolithic scintillator detector. We introduce a custom loss function to estimate the inherent uncertainties associated with the reconstruction process and to incorporate the physical constraints of the detector.
  This unique combination allows for more robust and reliable position estimations and the obtained results demonstrate the effectiveness of the proposed approach and highlights the significant benefits of the uncertainties estimation. We discuss its potential impact on improving PET imaging quality and show how the results can be used to improve the exploitation of the model, to bring benefits to the application and how to evaluate the validity of the given prediction and the associated uncertainties. Importantly, our proposed methodology extends beyond this specific use case, as it can be generalized to other applications beyond PET imaging.
<div id='section'>Paperid: <span id='pid'>1533, <a href='https://arxiv.org/pdf/2310.05198.pdf' target='_blank'>https://arxiv.org/pdf/2310.05198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xibo Li, Shruti Patel, David Stronzek-Pfeifer, Christof BÃ¼skens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05198">Indoor Localization for an Autonomous Model Car: A Marker-Based Multi-Sensor Fusion Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Global navigation satellite systems readily provide accurate position information when localizing a robot outdoors. However, an analogous standard solution does not exist yet for mobile robots operating indoors. This paper presents an integrated framework for indoor localization and experimental validation of an autonomous driving system based on an advanced driver-assistance system (ADAS) model car. The global pose of the model car is obtained by fusing information from fiducial markers, inertial sensors and wheel odometry. In order to achieve robust localization, we investigate and compare two extensions to the Extended Kalman Filter; first with adaptive noise tuning and second with Chi-squared test for measurement outlier detection. An efficient and low-cost ground truth measurement method using a single LiDAR sensor is also proposed to validate the results. The performance of the localization algorithms is tested on a complete autonomous driving system with trajectory planning and model predictive control.
<div id='section'>Paperid: <span id='pid'>1534, <a href='https://arxiv.org/pdf/2309.16220.pdf' target='_blank'>https://arxiv.org/pdf/2309.16220.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Azizmalayeri, Ameen Abu-Hanna, Giovanni CinÃ¡
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16220">Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite their success, Machine Learning (ML) models do not generalize effectively to data not originating from the training distribution. To reliably employ ML models in real-world healthcare systems and avoid inaccurate predictions on out-of-distribution (OOD) data, it is crucial to detect OOD samples. Numerous OOD detection approaches have been suggested in other fields - especially in computer vision - but it remains unclear whether the challenge is resolved when dealing with medical tabular data. To answer this pressing need, we propose an extensive reproducible benchmark to compare different methods across a suite of tests including both near and far OODs. Our benchmark leverages the latest versions of eICU and MIMIC-IV, two public datasets encompassing tens of thousands of ICU patients in several hospitals. We consider a wide array of density-based methods and SOTA post-hoc detectors across diverse predictive architectures, including MLP, ResNet, and Transformer. Our findings show that i) the problem appears to be solved for far-OODs, but remains open for near-OODs; ii) post-hoc methods alone perform poorly, but improve substantially when coupled with distance-based mechanisms; iii) the transformer architecture is far less overconfident compared to MLP and ResNet.
<div id='section'>Paperid: <span id='pid'>1535, <a href='https://arxiv.org/pdf/2309.04837.pdf' target='_blank'>https://arxiv.org/pdf/2309.04837.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sudeepta Mondal, Ganesh Sundaramoorthi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04837">HAct: Out-of-Distribution Detection with Neural Net Activation Histograms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a simple, efficient, and accurate method for detecting out-of-distribution (OOD) data for trained neural networks. We propose a novel descriptor, HAct - activation histograms, for OOD detection, that is, probability distributions (approximated by histograms) of output values of neural network layers under the influence of incoming data. We formulate an OOD detector based on HAct descriptors. We demonstrate that HAct is significantly more accurate than state-of-the-art in OOD detection on multiple image classification benchmarks. For instance, our approach achieves a true positive rate (TPR) of 95% with only 0.03% false-positives using Resnet-50 on standard OOD benchmarks, outperforming previous state-of-the-art by 20.67% in the false positive rate (at the same TPR of 95%). The computational efficiency and the ease of implementation makes HAct suitable for online implementation in monitoring deployed neural networks in practice at scale.
<div id='section'>Paperid: <span id='pid'>1536, <a href='https://arxiv.org/pdf/2309.04755.pdf' target='_blank'>https://arxiv.org/pdf/2309.04755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haotian Guan, Jinping Dong, Wei-Ning Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04755">A Novel Training Framework for Physics-informed Neural Networks: Towards Real-time Applications in Ultrafast Ultrasound Blood Flow Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultrafast ultrasound blood flow imaging is a state-of-the-art technique for depiction of complex blood flow dynamics in vivo through thousands of full-view image data (or, timestamps) acquired per second. Physics-informed Neural Network (PINN) is one of the most preeminent solvers of the Navier-Stokes equations, widely used as the governing equation of blood flow. However, that current approaches rely on full Navier-Stokes equations is impractical for ultrafast ultrasound. We hereby propose a novel PINN training framework for solving the Navier-Stokes equations. It involves discretizing Navier-Stokes equations into steady state and sequentially solving them with test-time adaptation. The novel training framework is coined as SeqPINN. Upon its success, we propose a parallel training scheme for all timestamps based on averaged constant stochastic gradient descent as initialization. Uncertainty estimation through Stochastic Weight Averaging Gaussian is then used as an indicator of generalizability of the initialization. This algorithm, named SP-PINN, further expedites training of PINN while achieving comparable accuracy with SeqPINN. The performance of SeqPINN and SP-PINN was evaluated through finite-element simulations and in vitro phantoms of single-branch and trifurcate blood vessels. Results show that both algorithms were manyfold faster than the original design of PINN, while respectively achieving Root Mean Square Errors of 0.63 cm/s and 0.81 cm/s on the straight vessel and 1.35 cm/s and 1.63 cm/s on the trifurcate vessel when recovering blood flow velocities. The successful implementation of SeqPINN and SP-PINN open the gate for real-time training of PINN for Navier-Stokes equations and subsequently reliable imaging-based blood flow assessment in clinical practice.
<div id='section'>Paperid: <span id='pid'>1537, <a href='https://arxiv.org/pdf/2309.02206.pdf' target='_blank'>https://arxiv.org/pdf/2309.02206.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Quentin Fournier, Daniel Aloise, Leandro R. Costa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02206">Language Models for Novelty Detection in System Call Traces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the complexity of modern computer systems, novel and unexpected behaviors frequently occur. Such deviations are either normal occurrences, such as software updates and new user activities, or abnormalities, such as misconfigurations, latency issues, intrusions, and software bugs. Regardless, novel behaviors are of great interest to developers, and there is a genuine need for efficient and effective methods to detect them. Nowadays, researchers consider system calls to be the most fine-grained and accurate source of information to investigate the behavior of computer systems. Accordingly, this paper introduces a novelty detection methodology that relies on a probability distribution over sequences of system calls, which can be seen as a language model. Language models estimate the likelihood of sequences, and since novelties deviate from previously observed behaviors by definition, they would be unlikely under the model. Following the success of neural networks for language models, three architectures are evaluated in this work: the widespread LSTM, the state-of-the-art Transformer, and the lower-complexity Longformer. However, large neural networks typically require an enormous amount of data to be trained effectively, and to the best of our knowledge, no massive modern datasets of kernel traces are publicly available. This paper addresses this limitation by introducing a new open-source dataset of kernel traces comprising over 2 million web requests with seven distinct behaviors. The proposed methodology requires minimal expert hand-crafting and achieves an F-score and AuROC greater than 95% on most novelties while being data- and task-agnostic. The source code and trained models are publicly available on GitHub while the datasets are available on Zenodo.
<div id='section'>Paperid: <span id='pid'>1538, <a href='https://arxiv.org/pdf/2308.16175.pdf' target='_blank'>https://arxiv.org/pdf/2308.16175.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiuhai Chen, Jonas Mueller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16175">Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, whose training data remains unknown. By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that cautions when not to trust this response. Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDetector more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT). By sampling multiple responses from the LLM and considering the one with the highest confidence score, we can additionally obtain more accurate responses from the same LLM, without any extra training steps. In applications involving automated evaluation with LLMs, accounting for our confidence scores leads to more reliable evaluation in both human-in-the-loop and fully-automated settings (across both GPT 3.5 and 4).
<div id='section'>Paperid: <span id='pid'>1539, <a href='https://arxiv.org/pdf/2308.13792.pdf' target='_blank'>https://arxiv.org/pdf/2308.13792.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seyedeh Fatemeh Razavi, Mohammad Mahdi Mehmanchi, Reshad Hosseini, Mostafa Tavassolipour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.13792">Out-of-distribution detection using normalizing flows on the data manifold</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Using the intuition that out-of-distribution data have lower likelihoods, a common approach for out-of-distribution detection involves estimating the underlying data distribution. Normalizing flows are likelihood-based generative models providing a tractable density estimation via dimension-preserving invertible transformations. Conventional normalizing flows are prone to fail in out-of-distribution detection, because of the well-known curse of dimensionality problem of the likelihood-based models. To solve the problem of likelihood-based models, some works try to modify likelihood for example by incorporating a data complexity measure. We observed that these modifications are still insufficient. According to the manifold hypothesis, real-world data often lie on a low-dimensional manifold. Therefore, we proceed by estimating the density on a low-dimensional manifold and calculating a distance from the manifold as a measure for out-of-distribution detection. We propose a powerful criterion that combines this measure with the modified likelihood measure based on data complexity. Extensive experimental results show that incorporating manifold learning while accounting for the estimation of data complexity improves the out-of-distribution detection ability of normalizing flows. This improvement is achieved without modifying the model structure or using auxiliary out-of-distribution data during training.
<div id='section'>Paperid: <span id='pid'>1540, <a href='https://arxiv.org/pdf/2308.11295.pdf' target='_blank'>https://arxiv.org/pdf/2308.11295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elizaveta Kostenok, Daniil Cherniavskii, Alexey Zaytsev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.11295">Uncertainty Estimation of Transformers' Predictions via Topological Analysis of the Attention Matrices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformer-based language models have set new benchmarks across a wide range of NLP tasks, yet reliably estimating the uncertainty of their predictions remains a significant challenge. Existing uncertainty estimation (UE) techniques often fall short in classification tasks, either offering minimal improvements over basic heuristics or relying on costly ensemble models. Moreover, attempts to leverage common embeddings for UE in linear probing scenarios have yielded only modest gains, indicating that alternative model components should be explored.
  We tackle these limitations by harnessing the geometry of attention maps across multiple heads and layers to assess model confidence. Our approach extracts topological features from attention matrices, providing a low-dimensional, interpretable representation of the model's internal dynamics. Additionally, we introduce topological features to compare attention patterns across heads and layers. Our method significantly outperforms existing UE techniques on benchmarks for acceptability judgments and artificial text detection, offering a more efficient and interpretable solution for uncertainty estimation in large-scale language models.
<div id='section'>Paperid: <span id='pid'>1541, <a href='https://arxiv.org/pdf/2308.04886.pdf' target='_blank'>https://arxiv.org/pdf/2308.04886.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sourya Dipta Das, Yash Vadi, Abhishek Unnam, Kuldeep Yadav
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04886">Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dialect classification is used in a variety of applications, such as machine translation and speech recognition, to improve the overall performance of the system. In a real-world scenario, a deployed dialect classification model can encounter anomalous inputs that differ from the training data distribution, also called out-of-distribution (OOD) samples. Those OOD samples can lead to unexpected outputs, as dialects of those samples are unseen during model training. Out-of-distribution detection is a new research area that has received little attention in the context of dialect classification. Towards this, we proposed a simple yet effective unsupervised Mahalanobis distance feature-based method to detect out-of-distribution samples. We utilize the latent embeddings from all intermediate layers of a wav2vec 2.0 transformer-based dialect classifier model for multi-task learning. Our proposed approach outperforms other state-of-the-art OOD detection methods significantly.
<div id='section'>Paperid: <span id='pid'>1542, <a href='https://arxiv.org/pdf/2308.02184.pdf' target='_blank'>https://arxiv.org/pdf/2308.02184.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin Bikandi, Gorka Velez, Naiara Aginako, Itziar Irigoien
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02184">Synthetic outlier generation for anomaly detection in autonomous driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection, or outlier detection, is a crucial task in various domains to identify instances that significantly deviate from established patterns or the majority of data. In the context of autonomous driving, the identification of anomalies is particularly important to prevent safety-critical incidents, as deep learning models often exhibit overconfidence in anomalous or outlier samples. In this study, we explore different strategies for training an image semantic segmentation model with an anomaly detection module. By introducing modifications to the training stage of the state-of-the-art DenseHybrid model, we achieve significant performance improvements in anomaly detection. Moreover, we propose a simplified detector that achieves comparable results to our modified DenseHybrid approach, while also surpassing the performance of the original DenseHybrid model. These findings demonstrate the efficacy of our proposed strategies for enhancing anomaly detection in the context of autonomous driving.
<div id='section'>Paperid: <span id='pid'>1543, <a href='https://arxiv.org/pdf/2307.02736.pdf' target='_blank'>https://arxiv.org/pdf/2307.02736.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaoxing Huang, Vincent Wai Sun Wong, Queenie Chan, Winnie Chiu Wing Chu, Weitian Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.02736">An Uncertainty Aided Framework for Learning based Liver $T_1Ï$ Mapping and Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Objective: Quantitative $T_1Ï$ imaging has potential for assessment of biochemical alterations of liver pathologies. Deep learning methods have been employed to accelerate quantitative $T_1Ï$ imaging. To employ artificial intelligence-based quantitative imaging methods in complicated clinical environment, it is valuable to estimate the uncertainty of the predicated $T_1Ï$ values to provide the confidence level of the quantification results. The uncertainty should also be utilized to aid the post-hoc quantitative analysis and model learning tasks. Approach: To address this need, we propose a parametric map refinement approach for learning-based $T_1Ï$ mapping and train the model in a probabilistic way to model the uncertainty. We also propose to utilize the uncertainty map to spatially weight the training of an improved $T_1Ï$ mapping network to further improve the mapping performance and to remove pixels with unreliable $T_1Ï$ values in the region of interest. The framework was tested on a dataset of 51 patients with different liver fibrosis stages. Main results: Our results indicate that the learning-based map refinement method leads to a relative mapping error of less than 3% and provides uncertainty estimation simultaneously. The estimated uncertainty reflects the actual error level, and it can be used to further reduce relative $T_1Ï$ mapping error to 2.60% as well as removing unreliable pixels in the region of interest effectively. Significance: Our studies demonstrate the proposed approach has potential to provide a learning-based quantitative MRI system for trustworthy $T_1Ï$ mapping of the liver.
<div id='section'>Paperid: <span id='pid'>1544, <a href='https://arxiv.org/pdf/2307.02073.pdf' target='_blank'>https://arxiv.org/pdf/2307.02073.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdalaziz Rashid Al-Maeeni, Aziz Temirkhanov, Artem Ryzhikov, Mikhail Hushchyn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.02073">Performance Modeling of Data Storage Systems using Generative Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-precision modeling of systems is one of the main areas of industrial data analysis. Models of systems, their digital twins, are used to predict their behavior under various conditions. We have developed several models of a storage system using machine learning-based generative models. The system consists of several components: hard disk drive (HDD) and solid-state drive (SSD) storage pools with different RAID schemes and cache. Each storage component is represented by a probabilistic model that describes the probability distribution of the component performance in terms of IOPS and latency, depending on their configuration and external data load parameters. The results of the experiments demonstrate the errors of 4-10 % for IOPS and 3-16 % for latency predictions depending on the components and models of the system. The predictions show up to 0.99 Pearson correlation with Little's law, which can be used for unsupervised reliability checks of the models. In addition, we present novel data sets that can be used for benchmarking regression algorithms, conditional generative models, and uncertainty estimation methods in machine learning.
<div id='section'>Paperid: <span id='pid'>1545, <a href='https://arxiv.org/pdf/2306.14920.pdf' target='_blank'>https://arxiv.org/pdf/2306.14920.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nguyen Ngoc-Hieu, Nguyen Hung-Quang, The-Anh Ta, Thanh Nguyen-Tang, Khoa D Doan, Hoang Thanh-Tung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14920">A Cosine Similarity-based Method for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to detect OOD data is a crucial aspect of practical machine learning applications. In this work, we show that cosine similarity between the test feature and the typical ID feature is a good indicator of OOD data. We propose Class Typical Matching (CTM), a post hoc OOD detection algorithm that uses a cosine similarity scoring function. Extensive experiments on multiple benchmarks show that CTM outperforms existing post hoc OOD detection methods.
<div id='section'>Paperid: <span id='pid'>1546, <a href='https://arxiv.org/pdf/2306.08601.pdf' target='_blank'>https://arxiv.org/pdf/2306.08601.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmad Tarraf, Alexis Bandet, Francieli Boito, Guillaume Pallez, Felix Wolf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08601">Capturing Periodic I/O Using Frequency Techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many HPC applications perform their I/O in bursts that follow a periodic pattern. This allows for making predictions as to when a burst occurs. System providers can take advantage of such knowledge to reduce file-system contention by actively scheduling I/O bandwidth. The effectiveness of this approach, however, depends on the ability to detect and quantify the periodicity of I/O patterns online. In this paper, we introduce FTIO, an online method to detect periodic I/O phases, which is based on discrete Fourier transform (DFT), combined with outlier detection. We provide metrics that gauge the confidence in the output and tell how far from being periodic the signal is. We validate our approach with large-scale experiments on a production system and examine its limitations extensively. Our experiments show that FTIO has a mean error below 11%. Finally, we demonstrate that FTIO allowed the I/O scheduler Set- 10 to boost system utilization by 26% and reduce I/O slowdown by 56%.
<div id='section'>Paperid: <span id='pid'>1547, <a href='https://arxiv.org/pdf/2306.06408.pdf' target='_blank'>https://arxiv.org/pdf/2306.06408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JosuÃ© Page VizcaÃ­no, Panagiotis Symvoulidis, Zeguan Wang, Jonas Jelten, Paolo Favaro, Edward S. Boyden, Tobias Lasser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06408">Fast light-field 3D microscopy with out-of-distribution detection and adaptation through Conditional Normalizing Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-time 3D fluorescence microscopy is crucial for the spatiotemporal analysis of live organisms, such as neural activity monitoring. The eXtended field-of-view light field microscope (XLFM), also known as Fourier light field microscope, is a straightforward, single snapshot solution to achieve this. The XLFM acquires spatial-angular information in a single camera exposure. In a subsequent step, a 3D volume can be algorithmically reconstructed, making it exceptionally well-suited for real-time 3D acquisition and potential analysis. Unfortunately, traditional reconstruction methods (like deconvolution) require lengthy processing times (0.0220 Hz), hampering the speed advantages of the XLFM. Neural network architectures can overcome the speed constraints at the expense of lacking certainty metrics, which renders them untrustworthy for the biomedical realm. This work proposes a novel architecture to perform fast 3D reconstructions of live immobilized zebrafish neural activity based on a conditional normalizing flow. It reconstructs volumes at 8 Hz spanning 512x512x96 voxels, and it can be trained in under two hours due to the small dataset requirements (10 image-volume pairs). Furthermore, normalizing flows allow for exact Likelihood computation, enabling distribution monitoring, followed by out-of-distribution detection and retraining of the system when a novel sample is detected. We evaluate the proposed method on a cross-validation approach involving multiple in-distribution samples (genetically identical zebrafish) and various out-of-distribution ones.
<div id='section'>Paperid: <span id='pid'>1548, <a href='https://arxiv.org/pdf/2306.04072.pdf' target='_blank'>https://arxiv.org/pdf/2306.04072.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jarrod Haas, William Yolland, Bernhard Rabus
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04072">Exploring Simple, High Quality Out-of-Distribution Detection with L2 Normalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We demonstrate that L2 normalization over feature space can produce capable performance for Out-of-Distribution (OoD) detection for some models and datasets. Although it does not demonstrate outright state-of-the-art performance, this method is notable for its extreme simplicity: it requires only two addition lines of code, and does not need specialized loss functions, image augmentations, outlier exposure or extra parameter tuning. We also observe that training may be more efficient for some datasets and architectures. Notably, only 60 epochs with ResNet18 on CIFAR10 (or 100 epochs with ResNet50) can produce performance within two percentage points (AUROC) of several state-of-the-art methods for some near and far OoD datasets. We provide theoretical and empirical support for this method, and demonstrate viability across five architectures and three In-Distribution (ID) datasets.
<div id='section'>Paperid: <span id='pid'>1549, <a href='https://arxiv.org/pdf/2306.00560.pdf' target='_blank'>https://arxiv.org/pdf/2306.00560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziliang Xiong, Arvi Jonnarth, Abdelrahman Eldesokey, Joakim Johnander, Bastian Wandt, Per-Erik Forssen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.00560">Hinge-Wasserstein: Estimating Multimodal Aleatoric Uncertainty in Regression Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computer vision systems that are deployed in safety-critical applications need to quantify their output uncertainty. We study regression from images to parameter values and here it is common to detect uncertainty by predicting probability distributions. In this context, we investigate the regression-by-classification paradigm which can represent multimodal distributions, without a prior assumption on the number of modes. Through experiments on a specifically designed synthetic dataset, we demonstrate that traditional loss functions lead to poor probability distribution estimates and severe overconfidence, in the absence of full ground truth distributions. In order to alleviate these issues, we propose hinge-Wasserstein -- a simple improvement of the Wasserstein loss that reduces the penalty for weak secondary modes during training. This enables prediction of complex distributions with multiple modes, and allows training on datasets where full ground truth distributions are not available. In extensive experiments, we show that the proposed loss leads to substantially better uncertainty estimation on two challenging computer vision tasks: horizon line detection and stereo disparity estimation.
<div id='section'>Paperid: <span id='pid'>1550, <a href='https://arxiv.org/pdf/2305.18406.pdf' target='_blank'>https://arxiv.org/pdf/2305.18406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tullio Traverso, Francesco Coletti, Luca Magri, Tassos G. Karayiannis, Omar K. Matar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18406">A machine learning approach to the prediction of heat-transfer coefficients in micro-channels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The accurate prediction of the two-phase heat transfer coefficient (HTC) as a function of working fluids, channel geometries and process conditions is key to the optimal design and operation of compact heat exchangers. Advances in artificial intelligence research have recently boosted the application of machine learning (ML) algorithms to obtain data-driven surrogate models for the HTC. For most supervised learning algorithms, the task is that of a nonlinear regression problem. Despite the fact that these models have been proven capable of outperforming traditional empirical correlations, they have key limitations such as overfitting the data, the lack of uncertainty estimation, and interpretability of the results. To address these limitations, in this paper, we use a multi-output Gaussian process regression (GPR) to estimate the HTC in microchannels as a function of the mass flow rate, heat flux, system pressure and channel diameter and length. The model is trained using the Brunel Two-Phase Flow database of high-fidelity experimental data. The advantages of GPR are data efficiency, the small number of hyperparameters to be trained (typically of the same order of the number of input dimensions), and the automatic trade-off between data fit and model complexity guaranteed by the maximization of the marginal likelihood (Bayesian approach). Our paper proposes research directions to improve the performance of the GPR-based model in extrapolation.
<div id='section'>Paperid: <span id='pid'>1551, <a href='https://arxiv.org/pdf/2305.14977.pdf' target='_blank'>https://arxiv.org/pdf/2305.14977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florian Heidecker, Ahmad El-Khateeb, Bernhard Sick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.14977">Sampling-based Uncertainty Estimation for an Instance Segmentation Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The examination of uncertainty in the predictions of machine learning (ML) models is receiving increasing attention. One uncertainty modeling technique used for this purpose is Monte-Carlo (MC)-Dropout, where repeated predictions are generated for a single input. Therefore, clustering is required to describe the resulting uncertainty, but only through efficient clustering is it possible to describe the uncertainty from the model attached to each object. This article uses Bayesian Gaussian Mixture (BGM) to solve this problem. In addition, we investigate different values for the dropout rate and other techniques, such as focal loss and calibration, which we integrate into the Mask-RCNN model to obtain the most accurate uncertainty approximation of each instance and showcase it graphically.
<div id='section'>Paperid: <span id='pid'>1552, <a href='https://arxiv.org/pdf/2305.13849.pdf' target='_blank'>https://arxiv.org/pdf/2305.13849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aishwarya Venkataramanan, Assia Benbihi, Martin Laviale, Cedric Pradalier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.13849">Gaussian Latent Representations for Uncertainty Estimation using Mahalanobis Distance in Deep Classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent works show that the data distribution in a network's latent space is useful for estimating classification uncertainty and detecting Out-of-distribution (OOD) samples. To obtain a well-regularized latent space that is conducive for uncertainty estimation, existing methods bring in significant changes to model architectures and training procedures. In this paper, we present a lightweight, fast, and high-performance regularization method for Mahalanobis distance-based uncertainty prediction, and that requires minimal changes to the network's architecture. To derive Gaussian latent representation favourable for Mahalanobis Distance calculation, we introduce a self-supervised representation learning method that separates in-class representations into multiple Gaussians. Classes with non-Gaussian representations are automatically identified and dynamically clustered into multiple new classes that are approximately Gaussian. Evaluation on standard OOD benchmarks shows that our method achieves state-of-the-art results on OOD detection with minimal inference time, and is very competitive on predictive probability calibration. Finally, we show the applicability of our method to a real-life computer vision use case on microorganism classification.
<div id='section'>Paperid: <span id='pid'>1553, <a href='https://arxiv.org/pdf/2305.12068.pdf' target='_blank'>https://arxiv.org/pdf/2305.12068.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hui Li, Carlos A. Pena Solorzano, Susan Wei, Davis J. McCarthy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.12068">Technical outlier detection via convolutional variational autoencoder for the ADMANI breast mammogram dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ADMANI datasets (annotated digital mammograms and associated non-image datasets) from the Transforming Breast Cancer Screening with AI programme (BRAIx) run by BreastScreen Victoria in Australia are multi-centre, large scale, clinically curated, real-world databases. The datasets are expected to aid in the development of clinically relevant Artificial Intelligence (AI) algorithms for breast cancer detection, early diagnosis, and other applications. To ensure high data quality, technical outliers must be removed before any downstream algorithm development. As a first step, we randomly select 30,000 individual mammograms and use Convolutional Variational Autoencoder (CVAE), a deep generative neural network, to detect outliers. CVAE is expected to detect all sorts of outliers, although its detection performance differs among different types of outliers. Traditional image processing techniques such as erosion and pectoral muscle analysis can compensate for the poor performance of CVAE in certain outlier types. We identify seven types of technical outliers: implant, pacemaker, cardiac loop recorder, improper radiography, atypical lesion/calcification, incorrect exposure parameter and improper placement. The outlier recall rate for the test set is 61% if CVAE, erosion and pectoral muscle analysis each select the top 1% images ranked in ascending or descending order according to image outlier score under each detection method, and 83% if each selects the top 5% images. This study offers an overview of technical outliers in the ADMANI dataset and suggests future directions to improve outlier detection effectiveness.
<div id='section'>Paperid: <span id='pid'>1554, <a href='https://arxiv.org/pdf/2305.09293.pdf' target='_blank'>https://arxiv.org/pdf/2305.09293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Kristoffersson Lind, Rudolph Triebel, Luigi Nardi, Volker Krueger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09293">Out-of-Distribution Detection for Adaptive Computer Vision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It is well known that computer vision can be unreliable when faced with previously unseen imaging conditions. This paper proposes a method to adapt camera parameters according to a normalizing flow-based out-of-distibution detector. A small-scale study is conducted which shows that adapting camera parameters according to this out-of-distibution detector leads to an average increase of 3 to 4 percentage points in mAP, mAR and F1 performance metrics of a YOLOv4 object detector. As a secondary result, this paper also shows that it is possible to train a normalizing flow model for out-of-distribution detection on the COCO dataset, which is larger and more diverse than most benchmarks for out-of-distibution detectors.
<div id='section'>Paperid: <span id='pid'>1555, <a href='https://arxiv.org/pdf/2305.07639.pdf' target='_blank'>https://arxiv.org/pdf/2305.07639.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabyasachi Ghosh, Sanyam Saxena, Ajit Rajwade
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.07639">Efficient Neural Network based Classification and Outlier Detection for Image Moderation using Compressed Sensing and Group Testing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Popular social media platforms employ neural network based image moderation engines to classify images uploaded on them as having potentially objectionable content. Such moderation engines must answer a large number of queries with heavy computational cost, even though the actual number of images with objectionable content is usually a tiny fraction. Inspired by recent work on Neural Group Testing, we propose an approach which exploits this fact to reduce the overall computational cost of such engines using the technique of Compressed Sensing (CS). We present the quantitative matrix-pooled neural network (QMPNN), which takes as input $n$ images, and a $m \times n$ binary pooling matrix with $m < n$, whose rows indicate $m$ pools of images i.e. selections of $r$ images out of $n$. The QMPNN efficiently outputs the product of this matrix with the unknown sparse binary vector indicating whether each image is objectionable or not, i.e. it outputs the number of objectionable images in each pool. For suitable matrices, this is decoded using CS decoding algorithms to predict which images were objectionable. The computational cost of running the QMPNN and the CS algorithms is significantly lower than the cost of using a neural network with the same number of parameters separately on each image to classify the images, which we demonstrate via extensive experiments. Our technique is inherently resilient to moderate levels of errors in the prediction from the QMPNN. Furthermore, we present pooled deep outlier detection, which brings CS and group testing techniques to deep outlier detection, to provide for the case when the objectionable images do not belong to a set of pre-defined classes. This technique enables efficient automated moderation of off-topic images shared on topical forums dedicated to sharing images of a certain single class, many of which are currently human-moderated.
<div id='section'>Paperid: <span id='pid'>1556, <a href='https://arxiv.org/pdf/2305.05542.pdf' target='_blank'>https://arxiv.org/pdf/2305.05542.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Armin Abdehkakha, Craig Snoeyink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.05542">Localization of Ultra-dense Emitters with Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Single-Molecule Localization Microscopy (SMLM) has expanded our ability to visualize subcellular structures but is limited in its temporal resolution. Increasing emitter density will improve temporal resolution, but current analysis algorithms struggle as emitter images significantly overlap. Here we present a deep convolutional neural network called LUENN which utilizes a unique architecture that rejects the isolated emitter assumption; it can smoothly accommodate emitters that range from completely isolated to co-located. This architecture, alongside an accurate estimator of location uncertainty, extends the range of usable emitter densities by a factor of 6 to over 31 emitters per micrometer-squared with reduced penalty to localization precision and improved temporal resolution. Apart from providing uncertainty estimation, the algorithm improves usability in laboratories by reducing imaging times and easing requirements for successful experiments.
<div id='section'>Paperid: <span id='pid'>1557, <a href='https://arxiv.org/pdf/2305.05344.pdf' target='_blank'>https://arxiv.org/pdf/2305.05344.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanfei Hu, Tianyi Xia, Ying Cui, Quchen Zou, Yuancheng Wang, Wenbo Xiao, Shenghong Ju, Xinde Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.05344">Trustworthy Multi-phase Liver Tumor Segmentation via Evidence-based Uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-phase liver contrast-enhanced computed tomography (CECT) images convey the complementary multi-phase information for liver tumor segmentation (LiTS), which are crucial to assist the diagnosis of liver cancer clinically. However, the performances of existing multi-phase liver tumor segmentation (MPLiTS)-based methods suffer from redundancy and weak interpretability, % of the fused result, resulting in the implicit unreliability of clinical applications. In this paper, we propose a novel trustworthy multi-phase liver tumor segmentation (TMPLiTS), which is a unified framework jointly conducting segmentation and uncertainty estimation. The trustworthy results could assist the clinicians to make a reliable diagnosis. Specifically, Dempster-Shafer Evidence Theory (DST) is introduced to parameterize the segmentation and uncertainty as evidence following Dirichlet distribution. The reliability of segmentation results among multi-phase CECT images is quantified explicitly. Meanwhile, a multi-expert mixture scheme (MEMS) is proposed to fuse the multi-phase evidences, which can guarantee the effect of fusion procedure based on theoretical analysis. Experimental results demonstrate the superiority of TMPLiTS compared with the state-of-the-art methods. Meanwhile, the robustness of TMPLiTS is verified, where the reliable performance can be guaranteed against the perturbations.
<div id='section'>Paperid: <span id='pid'>1558, <a href='https://arxiv.org/pdf/2304.14589.pdf' target='_blank'>https://arxiv.org/pdf/2304.14589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziheng Wang, Andrea Mariani, Arianna Menciassi, Elena De Momi, Ann Majewicz Fey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.14589">Uncertainty-aware Self-supervised Learning for Cross-domain Technical Skill Assessment in Robot-assisted Surgery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Objective technical skill assessment is crucial for effective training of new surgeons in robot-assisted surgery. With advancements in surgical training programs in both physical and virtual environments, it is imperative to develop generalizable methods for automatically assessing skills. In this paper, we propose a novel approach for skill assessment by transferring domain knowledge from labeled kinematic data to unlabeled data. Our approach leverages labeled data from common surgical training tasks such as Suturing, Needle Passing, and Knot Tying to jointly train a model with both labeled and unlabeled data. Pseudo labels are generated for the unlabeled data through an iterative manner that incorporates uncertainty estimation to ensure accurate labeling. We evaluate our method on a virtual reality simulated training task (Ring Transfer) using data from the da Vinci Research Kit (dVRK). The results show that trainees with robotic assistance have significantly higher expert probability compared to these without any assistance, p < 0.05, which aligns with previous studies showing the benefits of robotic assistance in improving training proficiency. Our method offers a significant advantage over other existing works as it does not require manual labeling or prior knowledge of the surgical training task for robot-assisted surgery.
<div id='section'>Paperid: <span id='pid'>1559, <a href='https://arxiv.org/pdf/2304.10707.pdf' target='_blank'>https://arxiv.org/pdf/2304.10707.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinwei Zhang, Zhiqiang Tan, Zhijian Ou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10707">Persistently Trained, Diffusion-assisted Energy-based Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Maximum likelihood (ML) learning for energy-based models (EBMs) is challenging, partly due to non-convergence of Markov chain Monte Carlo.Several variations of ML learning have been proposed, but existing methods all fail to achieve both post-training image generation and proper density estimation. We propose to introduce diffusion data and learn a joint EBM, called diffusion assisted-EBMs, through persistent training (i.e., using persistent contrastive divergence) with an enhanced sampling algorithm to properly sample from complex, multimodal distributions. We present results from a 2D illustrative experiment and image experiments and demonstrate that, for the first time for image data, persistently trained EBMs can {\it simultaneously} achieve long-run stability, post-training image generation, and superior out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>1560, <a href='https://arxiv.org/pdf/2304.10191.pdf' target='_blank'>https://arxiv.org/pdf/2304.10191.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Sun, Bojian Yin, Sander Bohte
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10191">Efficient Uncertainty Estimation in Spiking Neural Networks via MC-dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spiking neural networks (SNNs) have gained attention as models of sparse and event-driven communication of biological neurons, and as such have shown increasing promise for energy-efficient applications in neuromorphic hardware. As with classical artificial neural networks (ANNs), predictive uncertainties are important for decision making in high-stakes applications, such as autonomous vehicles, medical diagnosis, and high frequency trading. Yet, discussion of uncertainty estimation in SNNs is limited, and approaches for uncertainty estimation in artificial neural networks (ANNs) are not directly applicable to SNNs. Here, we propose an efficient Monte Carlo(MC)-dropout based approach for uncertainty estimation in SNNs. Our approach exploits the time-step mechanism of SNNs to enable MC-dropout in a computationally efficient manner, without introducing significant overheads during training and inference while demonstrating high accuracy and uncertainty quality.
<div id='section'>Paperid: <span id='pid'>1561, <a href='https://arxiv.org/pdf/2304.08645.pdf' target='_blank'>https://arxiv.org/pdf/2304.08645.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacob Deery, Chang Won Lee, Steven Waslander
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.08645">ProPanDL: A Modular Architecture for Uncertainty-Aware Panoptic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce ProPanDL, a family of networks capable of uncertainty-aware panoptic segmentation. Unlike existing segmentation methods, ProPanDL is capable of estimating full probability distributions for both the semantic and spatial aspects of panoptic segmentation. We implement and evaluate ProPanDL variants capable of estimating both parametric (Variance Network) and parameter-free (SampleNet) distributions quantifying pixel-wise spatial uncertainty. We couple these approaches with two methods (Temperature Scaling and Evidential Deep Learning) for semantic uncertainty estimation. To evaluate the uncertainty-aware panoptic segmentation task, we address limitations with existing approaches by proposing new metrics that enable separate evaluation of spatial and semantic uncertainty. We additionally propose the use of the energy score, a proper scoring rule, for more robust evaluation of spatial output distributions. Using these metrics, we conduct an extensive evaluation of ProPanDL variants. Our results demonstrate that ProPanDL is capable of estimating well-calibrated and meaningful output distributions while still retaining strong performance on the base panoptic segmentation task.
<div id='section'>Paperid: <span id='pid'>1562, <a href='https://arxiv.org/pdf/2304.03522.pdf' target='_blank'>https://arxiv.org/pdf/2304.03522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wonjun Yi, Jung-Woo Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.03522">On-site Noise Exposure technique for noise-robust machine fault classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In-situ classification of faulty sounds is an important issue in machine health monitoring and diagnosis. However, in a noisy environment such as a factory, machine sound is always mixed up with environmental noises, and noise-only periods can exist when a machine is not in operation. Therefore, a deep neural network (DNN)-based fault classifier has to be able to distinguish noise from machine sound and be robust to mixed noises. To deal with these problems, we investigate on-site noise exposure (ONE) that exposes a DNN model to the noises recorded in the same environment where the machine operates. Like the outlier exposure technique, noise exposure trains a DNN classifier to produce a uniform predicted probability distribution against noise-only data. During inference, the DNN classifier trained by ONE outputs the maximum softmax probability as the noise score and determines the noise-only period. We mix machine sound and noises of the ToyADMOS2 dataset to simulate highly noisy data. A ResNet-based classifier trained by ONE is evaluated and compared with those trained by other out-of-distribution detection techniques. The test results show that exposing a model to on-site noises can make a model more robust than using other noises or detection techniques.
<div id='section'>Paperid: <span id='pid'>1563, <a href='https://arxiv.org/pdf/2304.02098.pdf' target='_blank'>https://arxiv.org/pdf/2304.02098.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Smith, Frank Ferrie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02098">Uncertainty estimation in Deep Learning for Panoptic segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As deep learning-based computer vision algorithms continue to advance the state of the art, their robustness to real-world data continues to be an issue, making it difficult to bring an algorithm from the lab to the real world. Ensemble-based uncertainty estimation approaches such as Monte Carlo Dropout have been successfully used in many applications in an attempt to address this robustness issue. Unfortunately, it is not always clear if such ensemble-based approaches can be applied to a new problem domain. This is the case with panoptic segmentation, where the structure of the problem and architectures designed to solve it means that unlike image classification or even semantic segmentation, the typical solution of using a mean across samples cannot be directly applied. In this paper, we demonstrate how ensemble-based uncertainty estimation approaches such as Monte Carlo Dropout can be used in the panoptic segmentation domain with no changes to an existing network, providing both improved performance and more importantly a better measure of uncertainty for predictions made by the network. Results are demonstrated quantitatively and qualitatively on the COCO, KITTI-STEP and VIPER datasets.
<div id='section'>Paperid: <span id='pid'>1564, <a href='https://arxiv.org/pdf/2303.14716.pdf' target='_blank'>https://arxiv.org/pdf/2303.14716.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Beeson, Giovanni Montana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14716">Balancing policy constraint and ensemble size in uncertainty-based offline reinforcement learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline reinforcement learning agents seek optimal policies from fixed data sets. With environmental interaction prohibited, agents face significant challenges in preventing errors in value estimates from compounding and subsequently causing the learning process to collapse. Uncertainty estimation using ensembles compensates for this by penalising high-variance value estimates, allowing agents to learn robust policies based on data-driven actions. However, the requirement for large ensembles to facilitate sufficient penalisation results in significant computational overhead. In this work, we examine the role of policy constraints as a mechanism for regulating uncertainty, and the corresponding balance between level of constraint and ensemble size. By incorporating behavioural cloning into policy updates, we show empirically that sufficient penalisation can be achieved with a much smaller ensemble size, substantially reducing computational demand while retaining state-of-the-art performance on benchmarking tasks. Furthermore, we show how such an approach can facilitate stable online fine tuning, allowing for continued policy improvement while avoiding severe performance drops.
<div id='section'>Paperid: <span id='pid'>1565, <a href='https://arxiv.org/pdf/2303.08193.pdf' target='_blank'>https://arxiv.org/pdf/2303.08193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lara Kuhlmann, Daniel Wilmes, Emmanuel MÃ¼ller, Markus Pauly, Daniel Horn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08193">RODD: Robust Outlier Detection in Data Cubes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data cubes are multidimensional databases, often built from several separate databases, that serve as flexible basis for data analysis. Surprisingly, outlier detection on data cubes has not yet been treated extensively. In this work, we provide the first framework to evaluate robust outlier detection methods in data cubes (RODD). We introduce a novel random forest-based outlier detection approach (RODD-RF) and compare it with more traditional methods based on robust location estimators. We propose a general type of test data and examine all methods in a simulation study. Moreover, we apply ROOD-RF to real world data. The results show that RODD-RF can lead to improved outlier detection.
<div id='section'>Paperid: <span id='pid'>1566, <a href='https://arxiv.org/pdf/2303.04115.pdf' target='_blank'>https://arxiv.org/pdf/2303.04115.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Yang, William Gebhardt, Alexander G. Ororbia, Travis Desell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.04115">Predicted Embedding Power Regression for Large-Scale Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) inputs can compromise the performance and safety of real world machine learning systems. While many methods exist for OOD detection and work well on small scale datasets with lower resolution and few classes, few methods have been developed for large-scale OOD detection. Existing large-scale methods generally depend on maximum classification probability, such as the state-of-the-art grouped softmax method. In this work, we develop a novel approach that calculates the probability of the predicted class label based on label distributions learned during the training process. Our method performs better than current state-of-the-art methods with only a negligible increase in compute cost. We evaluate our method against contemporary methods across $14$ datasets and achieve a statistically significant improvement with respect to AUROC (84.2 vs 82.4) and AUPR (96.2 vs 93.7).
<div id='section'>Paperid: <span id='pid'>1567, <a href='https://arxiv.org/pdf/2301.04452.pdf' target='_blank'>https://arxiv.org/pdf/2301.04452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriella Chouraqui, Liron Cohen, Gil Einziger, Liel Leman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.04452">Uncertainty Estimation based on Geometric Separation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In machine learning, accurately predicting the probability that a specific input is correct is crucial for risk management. This process, known as uncertainty (or confidence) estimation, is particularly important in mission-critical applications such as autonomous driving. In this work, we put forward a novel geometric-based approach for improving uncertainty estimations in machine learning models. Our approach involves using the geometric distance of the current input from existing training inputs as a signal for estimating uncertainty, and then calibrating this signal using standard post-hoc techniques. We demonstrate that our method leads to more accurate uncertainty estimations than recently proposed approaches through extensive evaluation on a variety of datasets and models. Additionally, we optimize our approach so that it can be implemented on large datasets in near real-time applications, making it suitable for time-sensitive scenarios.
<div id='section'>Paperid: <span id='pid'>1568, <a href='https://arxiv.org/pdf/2212.01976.pdf' target='_blank'>https://arxiv.org/pdf/2212.01976.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyejun Jeong, Hamin Son, Seohu Lee, Jayun Hyun, Tai-Myoung Chung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.01976">FedCC: Robust Federated Learning against Model Poisoning Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated learning is a distributed framework designed to address privacy concerns. However, it introduces new attack surfaces, which are especially prone when data is non-Independently and Identically Distributed. Existing approaches fail to effectively mitigate the malicious influence in this setting; previous approaches often tackle non-IID data and poisoning attacks separately. To address both challenges simultaneously, we present FedCC, a simple yet effective novel defense algorithm against model poisoning attacks. It leverages the Centered Kernel Alignment similarity of Penultimate Layer Representations for clustering, allowing the identification and filtration of malicious clients, even in non-IID data settings. The penultimate layer representations are meaningful since the later layers are more sensitive to local data distributions, which allows better detection of malicious clients. The sophisticated utilization of layer-wise Centered Kernel Alignment similarity allows attack mitigation while leveraging useful knowledge obtained. Our extensive experiments demonstrate the effectiveness of FedCC in mitigating both untargeted model poisoning and targeted backdoor attacks. Compared to existing outlier detection-based and first-order statistics-based methods, FedCC consistently reduces attack confidence to zero. Specifically, it significantly minimizes the average degradation of global performance by 65.5\%. We believe that this new perspective on aggregation makes it a valuable contribution to the field of FL model security and privacy. The code will be made available upon acceptance.
<div id='section'>Paperid: <span id='pid'>1569, <a href='https://arxiv.org/pdf/2211.13314.pdf' target='_blank'>https://arxiv.org/pdf/2211.13314.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andreas Lohrer, Daniyal Kazempour, Maximilian HÃ¼nemÃ¶rder, Peer KrÃ¶ger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.13314">CoMadOut -- A Robust Outlier Detection Algorithm based on CoMAD</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised learning methods are well established in the area of anomaly detection and achieve state of the art performances on outlier datasets. Outliers play a significant role, since they bear the potential to distort the predictions of a machine learning algorithm on a given dataset. Especially among PCA-based methods, outliers have an additional destructive potential regarding the result: they may not only distort the orientation and translation of the principal components, they also make it more complicated to detect outliers. To address this problem, we propose the robust outlier detection algorithm CoMadOut, which satisfies two required properties: (1) being robust towards outliers and (2) detecting them. Our CoMadOut outlier detection variants using comedian PCA define, dependent on its variant, an inlier region with a robust noise margin by measures of in-distribution (variant CMO) and optimized scores by measures of out-of-distribution (variants CMO*), e.g. kurtosis-weighting by CMO+k. These measures allow distribution based outlier scoring for each principal component, and thus, an appropriate alignment of the degree of outlierness between normal and abnormal instances. Experiments comparing CoMadOut with traditional, deep and other comparable robust outlier detection methods showed that the performance of the introduced CoMadOut approach is competitive to well established methods related to average precision (AP), area under the precision recall curve (AUPRC) and area under the receiver operating characteristic (AUROC) curve. In summary our approach can be seen as a robust alternative for outlier detection tasks.
<div id='section'>Paperid: <span id='pid'>1570, <a href='https://arxiv.org/pdf/2211.11296.pdf' target='_blank'>https://arxiv.org/pdf/2211.11296.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicolas Larue, Ngoc-Son Vu, Vitomir Struc, Peter Peer, Vassilis Christophides
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.11296">SeeABLE: Soft Discrepancies and Bounded Contrastive Learning for Exposing Deepfakes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern deepfake detectors have achieved encouraging results, when training and test images are drawn from the same data collection. However, when these detectors are applied to images produced with unknown deepfake-generation techniques, considerable performance degradations are commonly observed. In this paper, we propose a novel deepfake detector, called SeeABLE, that formalizes the detection problem as a (one-class) out-of-distribution detection task and generalizes better to unseen deepfakes. Specifically, SeeABLE first generates local image perturbations (referred to as soft-discrepancies) and then pushes the perturbed faces towards predefined prototypes using a novel regression-based bounded contrastive loss. To strengthen the generalization performance of SeeABLE to unknown deepfake types, we generate a rich set of soft discrepancies and train the detector: (i) to localize, which part of the face was modified, and (ii) to identify the alteration type. To demonstrate the capabilities of SeeABLE, we perform rigorous experiments on several widely-used deepfake datasets and show that our model convincingly outperforms competing state-of-the-art detectors, while exhibiting highly encouraging generalization capabilities.
<div id='section'>Paperid: <span id='pid'>1571, <a href='https://arxiv.org/pdf/2211.10892.pdf' target='_blank'>https://arxiv.org/pdf/2211.10892.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vahid Reza Khazaie, Anthony Wong, Mohammad Sabokrou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.10892">Towards Realistic Out-of-Distribution Detection: A Novel Evaluation Framework for Improving Generalization in OOD Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel evaluation framework for Out-of-Distribution (OOD) detection that aims to assess the performance of machine learning models in more realistic settings. We observed that the real-world requirements for testing OOD detection methods are not satisfied by the current testing protocols. They usually encourage methods to have a strong bias towards a low level of diversity in normal data. To address this limitation, we propose new OOD test datasets (CIFAR-10-R, CIFAR-100-R, and ImageNet-30-R) that can allow researchers to benchmark OOD detection performance under realistic distribution shifts. Additionally, we introduce a Generalizability Score (GS) to measure the generalization ability of a model during OOD detection. Our experiments demonstrate that improving the performance on existing benchmark datasets does not necessarily improve the usability of OOD detection models in real-world scenarios. While leveraging deep pre-trained features has been identified as a promising avenue for OOD detection research, our experiments show that state-of-the-art pre-trained models tested on our proposed datasets suffer a significant drop in performance. To address this issue, we propose a post-processing stage for adapting pre-trained features under these distribution shifts before calculating the OOD scores, which significantly enhances the performance of state-of-the-art pre-trained models on our benchmarks.
<div id='section'>Paperid: <span id='pid'>1572, <a href='https://arxiv.org/pdf/2211.09981.pdf' target='_blank'>https://arxiv.org/pdf/2211.09981.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangjun Ruan, Saurabh Singh, Warren Morningstar, Alexander A. Alemi, Sergey Ioffe, Ian Fischer, Joshua V. Dillon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.09981">Weighted Ensemble Self-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensembling has proven to be a powerful technique for boosting model performance, uncertainty estimation, and robustness in supervised learning. Advances in self-supervised learning (SSL) enable leveraging large unlabeled corpora for state-of-the-art few-shot and supervised learning performance. In this paper, we explore how ensemble methods can improve recent SSL techniques by developing a framework that permits data-dependent weighted cross-entropy losses. We refrain from ensembling the representation backbone; this choice yields an efficient ensemble method that incurs a small training cost and requires no architectural changes or computational overhead to downstream evaluation. The effectiveness of our method is demonstrated with two state-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al., 2022). Our method outperforms both in multiple evaluation metrics on ImageNet-1K, particularly in the few-shot setting. We explore several weighting schemes and find that those which increase the diversity of ensemble heads lead to better downstream evaluation results. Thorough experiments yield improved prior art baselines which our method still surpasses; e.g., our overall improvement with MSN ViT-B/16 is 3.9 p.p. for 1-shot learning.
<div id='section'>Paperid: <span id='pid'>1573, <a href='https://arxiv.org/pdf/2211.03054.pdf' target='_blank'>https://arxiv.org/pdf/2211.03054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yafei Shen, Tao Zhang, Zhiwei Liu, Kalliopi Kostelidou, Ying Xu, Ling Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.03054">ODBAE: a high-performance model identifying complex phenotypes in high-dimensional biological datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying complex phenotypes from high-dimensional biological data is challenging due to the intricate interdependencies among different physiological indicators. Traditional approaches often focus on detecting outliers in single variables, overlooking the broader network of interactions that contribute to phenotype emergence. Here, we introduce ODBAE (Outlier Detection using Balanced Autoencoders), a machine learning method designed to uncover both subtle and extreme outliers by capturing latent relationships among multiple physiological parameters. ODBAE's revised loss function enhances its ability to detect two key types of outliers: influential points (IP), which disrupt latent correlations between dimensions, and high leverage points (HLP), which deviate from the norm but go undetected by traditional autoencoder-based methods. Using data from the International Mouse Phenotyping Consortium (IMPC), we show that ODBAE can identify knockout mice with complex, multi-indicator phenotypes - normal in individual traits, but abnormal when considered together. In addition, this method reveals novel metabolism-related genes and uncovers coordinated abnormalities across metabolic indicators. Our results highlight the utility of ODBAE in detecting joint abnormalities and advancing our understanding of homeostatic perturbations in biological systems.
<div id='section'>Paperid: <span id='pid'>1574, <a href='https://arxiv.org/pdf/2209.09858.pdf' target='_blank'>https://arxiv.org/pdf/2209.09858.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrija Djurisic, Nebojsa Bozanic, Arjun Ashok, Rosanne Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.09858">Extremely Simple Activation Shaping for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The separation between training and deployment of machine learning models implies that not all scenarios encountered in deployment can be anticipated during training, and therefore relying solely on advancements in training has its limits. Out-of-distribution (OOD) detection is an important area that stress-tests a model's ability to handle unseen situations: Do models know when they don't know? Existing OOD detection methods either incur extra training steps, additional data or make nontrivial modifications to the trained network. In contrast, in this work, we propose an extremely simple, post-hoc, on-the-fly activation shaping method, ASH, where a large portion (e.g. 90%) of a sample's activation at a late layer is removed, and the rest (e.g. 10%) simplified or lightly adjusted. The shaping is applied at inference time, and does not require any statistics calculated from training data. Experiments show that such a simple treatment enhances in-distribution and out-of-distribution distinction so as to allow state-of-the-art OOD detection on ImageNet, and does not noticeably deteriorate the in-distribution accuracy. Video, animation and code can be found at: https://andrijazz.github.io/ash
<div id='section'>Paperid: <span id='pid'>1575, <a href='https://arxiv.org/pdf/2209.08378.pdf' target='_blank'>https://arxiv.org/pdf/2209.08378.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jarrod Haas, William Yolland, Bernhard Rabus
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.08378">Linking Neural Collapse and L2 Normalization with Improved Out-of-Distribution Detection in Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a simple modification to standard ResNet architectures--L2 normalization over feature space--that substantially improves out-of-distribution (OoD) performance on the previously proposed Deep Deterministic Uncertainty (DDU) benchmark. We show that this change also induces early Neural Collapse (NC), an effect linked to better OoD performance. Our method achieves comparable or superior OoD detection scores and classification accuracy in a small fraction of the training time of the benchmark. Additionally, it substantially improves worst case OoD performance over multiple, randomly initialized models. Though we do not suggest that NC is the sole mechanism or a comprehensive explanation for OoD behaviour in deep neural networks (DNN), we believe NC's simple mathematical and geometric structure can provide a framework for analysis of this complex phenomenon in future work.
<div id='section'>Paperid: <span id='pid'>1576, <a href='https://arxiv.org/pdf/2208.14024.pdf' target='_blank'>https://arxiv.org/pdf/2208.14024.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Robert Schmier, Ullrich KÃ¶the, Christoph-Nikolas Straehle
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.14024">Positive Difference Distribution for Image Outlier Detection using Normalizing Flows and Contrastive Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting test data deviating from training data is a central problem for safe and robust machine learning. Likelihoods learned by a generative model, e.g., a normalizing flow via standard log-likelihood training, perform poorly as an outlier score. We propose to use an unlabelled auxiliary dataset and a probabilistic outlier score for outlier detection. We use a self-supervised feature extractor trained on the auxiliary dataset and train a normalizing flow on the extracted features by maximizing the likelihood on in-distribution data and minimizing the likelihood on the contrastive dataset. We show that this is equivalent to learning the normalized positive difference between the in-distribution and the contrastive feature density. We conduct experiments on benchmark datasets and compare to the likelihood, the likelihood ratio and state-of-the-art anomaly detection methods.
<div id='section'>Paperid: <span id='pid'>1577, <a href='https://arxiv.org/pdf/2206.11736.pdf' target='_blank'>https://arxiv.org/pdf/2206.11736.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Patrick Feeney, Sarah Schneider, Panagiotis Lymperopoulos, Li-Ping Liu, Matthias Scheutz, Michael C. Hughes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.11736">NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects of varying size within the complex 3D scene that may impact gameplay. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. Further multimodal novelty detection experiments suggest that methods that fuse both visual and symbolic information can improve time until detection as well as overall discrimination. Finally, our evaluation of recent generalized category discovery methods suggests that adapting to new imbalanced categories in complex scenes remains an exciting open problem.
<div id='section'>Paperid: <span id='pid'>1578, <a href='https://arxiv.org/pdf/2202.05538.pdf' target='_blank'>https://arxiv.org/pdf/2202.05538.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ayman Elhalwagy, Tatiana Kalganova
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.05538">Hybridization of Capsule and LSTM Networks for unsupervised anomaly detection on multivariate data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning techniques have recently shown promise in the field of anomaly detection, providing a flexible and effective method of modelling systems in comparison to traditional statistical modelling and signal processing-based methods. However, there are a few well publicised issues Neural Networks (NN)s face such as generalisation ability, requiring large volumes of labelled data to be able to train effectively and understanding spatial context in data. This paper introduces a novel NN architecture which hybridises the Long-Short-Term-Memory (LSTM) and Capsule Networks into a single network in a branched input Autoencoder architecture for use on multivariate time series data. The proposed method uses an unsupervised learning technique to overcome the issues with finding large volumes of labelled training data. Experimental results show that without hyperparameter optimisation, using Capsules significantly reduces overfitting and improves the training efficiency. Additionally, results also show that the branched input models can learn multivariate data more consistently with or without Capsules in comparison to the non-branched input models. The proposed model architecture was also tested on an open-source benchmark, where it achieved state-of-the-art performance in outlier detection, and overall performs best over the metrics tested in comparison to current state-of-the art methods.
<div id='section'>Paperid: <span id='pid'>1579, <a href='https://arxiv.org/pdf/2112.06760.pdf' target='_blank'>https://arxiv.org/pdf/2112.06760.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuan Ma, Jianhua Zhao, Yue Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.06760">Robust factored principal component analysis for matrix-valued outlier accommodation and detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Principal component analysis (PCA) is a popular dimension reduction technique for vector data. Factored PCA (FPCA) is a probabilistic extension of PCA for matrix data, which can substantially reduce the number of parameters in PCA while yield satisfactory performance. However, FPCA is based on the Gaussian assumption and thereby susceptible to outliers. Although the multivariate $t$ distribution as a robust modeling tool for vector data has a very long history, its application to matrix data is very limited. The main reason is that the dimension of the vectorized matrix data is often very high and the higher the dimension, the lower the breakdown point that measures the robustness. To solve the robustness problem suffered by FPCA and make it applicable to matrix data, in this paper we propose a robust extension of FPCA (RFPCA), which is built upon a $t$-type distribution called matrix-variate $t$ distribution. Like the multivariate $t$ distribution, the matrix-variate $t$ distribution can adaptively down-weight outliers and yield robust estimates. We develop a fast EM-type algorithm for parameter estimation. Experiments on synthetic and real-world datasets reveal that RFPCA is compared favorably with several related methods and RFPCA is a simple but powerful tool for matrix-valued outlier detection.
<div id='section'>Paperid: <span id='pid'>1580, <a href='https://arxiv.org/pdf/2112.04643.pdf' target='_blank'>https://arxiv.org/pdf/2112.04643.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Phillip Si, Allan Bishop, Volodymyr Kuleshov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.04643">Autoregressive Quantile Flows for Predictive Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerous applications of machine learning involve representing probability distributions over high-dimensional data. We propose autoregressive quantile flows, a flexible class of normalizing flow models trained using a novel objective based on proper scoring rules. Our objective does not require calculating computationally expensive determinants of Jacobians during training and supports new types of neural architectures, such as neural autoregressive flows from which it is easy to sample.
  We leverage these models in quantile flow regression, an approach that parameterizes predictive conditional distributions with flows, resulting in improved probabilistic predictions on tasks such as time series forecasting and object detection. Our novel objective functions and neural flow parameterizations also yield improvements on popular generation and density estimation tasks, and represent a step beyond maximum likelihood learning of flows.
<div id='section'>Paperid: <span id='pid'>1581, <a href='https://arxiv.org/pdf/2112.03765.pdf' target='_blank'>https://arxiv.org/pdf/2112.03765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Hartwell, Felipe Montana, Will Jacobs, Visakan Kadirkamanathan, Andrew R Mills, Tom Clark
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.03765">In-flight Novelty Detection with Convolutional Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gas turbine engines are complex machines that typically generate a vast amount of data, and require careful monitoring to allow for cost-effective preventative maintenance. In aerospace applications, returning all measured data to ground is prohibitively expensive, often causing useful, high value, data to be discarded. The ability to detect, prioritise, and return useful data in real-time is therefore vital. This paper proposes that system output measurements, described by a convolutional neural network model of normality, are prioritised in real-time for the attention of preventative maintenance decision makers.
  Due to the complexity of gas turbine engine time-varying behaviours, deriving accurate physical models is difficult, and often leads to models with low prediction accuracy and incompatibility with real-time execution. Data-driven modelling is a desirable alternative producing high accuracy, asset specific models without the need for derivation from first principles.
  We present a data-driven system for online detection and prioritisation of anomalous data. Biased data assessment deriving from novel operating conditions is avoided by uncertainty management integrated into the deep neural predictive model. Testing is performed on real and synthetic data, showing sensitivity to both real and synthetic faults. The system is capable of running in real-time on low-power embedded hardware and is currently in deployment on the Rolls-Royce Pearl 15 engine flight trials.
<div id='section'>Paperid: <span id='pid'>1582, <a href='https://arxiv.org/pdf/2110.03051.pdf' target='_blank'>https://arxiv.org/pdf/2110.03051.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dennis Ulmer, Christian Hardmeier, Jes Frellsen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.03051">Prior and Posterior Networks: A Survey on Evidential Deep Learning Methods For Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Popular approaches for quantifying predictive uncertainty in deep neural networks often involve distributions over weights or multiple models, for instance via Markov Chain sampling, ensembling, or Monte Carlo dropout. These techniques usually incur overhead by having to train multiple model instances or do not produce very diverse predictions. This comprehensive and extensive survey aims to familiarize the reader with an alternative class of models based on the concept of Evidential Deep Learning: For unfamiliar data, they aim to admit "what they don't know", and fall back onto a prior belief. Furthermore, they allow uncertainty estimation in a single model and forward pass by parameterizing distributions over distributions. This survey recapitulates existing works, focusing on the implementation in a classification setting, before surveying the application of the same paradigm to regression. We also reflect on the strengths and weaknesses compared to other existing methods and provide the most fundamental derivations using a unified notation to aid future research.
<div id='section'>Paperid: <span id='pid'>1583, <a href='https://arxiv.org/pdf/2109.07295.pdf' target='_blank'>https://arxiv.org/pdf/2109.07295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Zhang, Yu Dong, Hanyu Peng, Shifeng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2109.07295">New Perspective on Progressive GANs Distillation for One-class Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One-class novelty detection is conducted to identify anomalous instances, with different distributions from the expected normal instances. In this paper, the Generative Adversarial Network based on the Encoder-Decoder-Encoder scheme (EDE-GAN) achieves state-of-the-art performance. The two factors bellow serve the above purpose: 1) The EDE-GAN calculates the distance between two latent vectors as the anomaly score, which is unlike the previous methods by utilizing the reconstruction error between images. 2) The model obtains best results when the batch size is set to 1. To illustrate their superiority, we design a new GAN architecture, and compare performances according to different batch sizes. Moreover, with experimentation leads to discovery, our result implies there is also evidence of just how beneficial constraint on the latent space are when engaging in model training. In an attempt to learn compact and fast models, we present a new technology, Progressive Knowledge Distillation with GANs (P-KDGAN), which connects two standard GANs through the designed distillation loss. Two-step progressive learning continuously augments the performance of student GANs with improved results over single-step approach. Our experimental results on CIFAR-10, MNIST, and FMNIST datasets illustrate that P-KDGAN improves the performance of the student GAN by 2.44%, 1.77%, and 1.73% when compressing the computationat ratios of 24.45:1, 311.11:1, and 700:1, respectively.
<div id='section'>Paperid: <span id='pid'>1584, <a href='https://arxiv.org/pdf/2105.05716.pdf' target='_blank'>https://arxiv.org/pdf/2105.05716.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adrian Remonda, Eduardo Veas, Granit Luzhnica
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2105.05716">Acting upon Imagination: when to trust imagined trajectories in model based reinforcement learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model-based reinforcement learning (MBRL) aims to learn model(s) of the environment dynamics that can predict the outcome of its actions. Forward application of the model yields so called imagined trajectories (sequences of action, predicted state-reward) used to optimize the set of candidate actions that maximize expected reward. The outcome, an ideal imagined trajectory or plan, is imperfect and typically MBRL relies on model predictive control (MPC) to overcome this by continuously re-planning from scratch, incurring thus major computational cost and increasing complexity in tasks with longer receding horizon. We propose uncertainty estimation methods for online evaluation of imagined trajectories to assess whether further planned actions can be trusted to deliver acceptable reward. These methods include comparing the error after performing the last action with the standard expected error and using model uncertainty to assess the deviation from expected outcomes. Additionally, we introduce methods that exploit the forward propagation of the dynamics model to evaluate if the remainder of the plan aligns with expected results and assess the remainder of the plan in terms of the expected reward. Our experiments demonstrate the effectiveness of the proposed uncertainty estimation methods by applying them to avoid unnecessary trajectory replanning in a shooting MBRL setting. Results highlight significant reduction on computational costs without sacrificing performance.
<div id='section'>Paperid: <span id='pid'>1585, <a href='https://arxiv.org/pdf/2010.12995.pdf' target='_blank'>https://arxiv.org/pdf/2010.12995.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yann Pequignot, Mathieu Alain, Patrick Dallaire, Alireza Yeganehparast, Pascal Germain, JosÃ©e Desharnais, FranÃ§ois Laviolette
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2010.12995">Out-of-distribution detection for regression tasks: parameter versus predictor entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It is crucial to detect when an instance lies downright too far from the training samples for the machine learning model to be trusted, a challenge known as out-of-distribution (OOD) detection. For neural networks, one approach to this task consists of learning a diversity of predictors that all can explain the training data. This information can be used to estimate the epistemic uncertainty at a given newly observed instance in terms of a measure of the disagreement of the predictions. Evaluation and certification of the ability of a method to detect OOD require specifying instances which are likely to occur in deployment yet on which no prediction is available. Focusing on regression tasks, we choose a simple yet insightful model for this OOD distribution and conduct an empirical evaluation of the ability of various methods to discriminate OOD samples from the data. Moreover, we exhibit evidence that a diversity of parameters may fail to translate to a diversity of predictors. Based on the choice of an OOD distribution, we propose a new way of estimating the entropy of a distribution on predictors based on nearest neighbors in function space. This leads to a variational objective which, combined with the family of distributions given by a generative neural network, systematically produces a diversity of predictors that provides a robust way to detect OOD samples.
<div id='section'>Paperid: <span id='pid'>1586, <a href='https://arxiv.org/pdf/1906.02433.pdf' target='_blank'>https://arxiv.org/pdf/1906.02433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cho-Ying Wu, Jian-Jiun Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1906.02433">Nonconvex Approach for Sparse and Low-Rank Constrained Models with Dual Momentum</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this manuscript, we research on the behaviors of surrogates for the rank function on different image processing problems and their optimization algorithms. We first propose a novel nonconvex rank surrogate on the general rank minimization problem and apply this to the corrupted image completion problem. Then, we propose that nonconvex rank surrogates can be introduced into two well-known sparse and low-rank models: Robust Principal Component Analysis (RPCA) and Low-Rank Representation (LRR). For optimization, we use alternating direction method of multipliers (ADMM) and propose a trick, which is called the dual momentum. We add the difference of the dual variable between the current and the last iteration with a weight. This trick can avoid the local minimum problem and make the algorithm converge to a solution with smaller recovery error in the nonconvex optimization problem. Also, it can boost the convergence when the variable updates too slowly. We also give a severe proof and verify that the proposed algorithms are convergent. Then, several experiments are conducted, including image completion, denoising, and spectral clustering with outlier detection. These experiments show that the proposed methods are effective in image and signal processing applications, and have the best performance compared with state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1587, <a href='https://arxiv.org/pdf/2510.06025.pdf' target='_blank'>https://arxiv.org/pdf/2510.06025.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Raina, Tanya Schmah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06025">Out-of-Distribution Detection from Small Training Sets using Bayesian Neural Network Classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution (OOD) detection is critical to AI reliability and safety, yet in many practical settings, only a limited amount of training data is available. Bayesian Neural Networks (BNNs) are a promising class of model on which to base OOD detection, because they explicitly represent epistemic (i.e. model) uncertainty. In the small training data regime, BNNs are especially valuable because they can incorporate prior model information. We introduce a new family of Bayesian posthoc OOD scores based on expected logit vectors, and compare 5 Bayesian and 4 deterministic posthoc OOD scores. Experiments on MNIST and CIFAR-10 In-Distributions, with 5000 training samples or less, show that the Bayesian methods outperform corresponding deterministic methods.
<div id='section'>Paperid: <span id='pid'>1588, <a href='https://arxiv.org/pdf/2510.05782.pdf' target='_blank'>https://arxiv.org/pdf/2510.05782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>I. M. De la Jara, C. Rodriguez-Opazo, D. Teney, D. Ranasinghe, E. Abbasnejad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05782">Mysteries of the Deep: Role of Intermediate Representations in Out of Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for reliably deploying machine learning models in the wild. Yet, most methods treat large pre-trained models as monolithic encoders and rely solely on their final-layer representations for detection. We challenge this wisdom. We reveal the \textit{intermediate layers} of pre-trained models, shaped by residual connections that subtly transform input projections, \textit{can} encode \textit{surprisingly rich and diverse signals} for detecting distributional shifts. Importantly, to exploit latent representation diversity across layers, we introduce an entropy-based criterion to \textit{automatically} identify layers offering the most complementary information in a training-free setting -- \textit{without access to OOD data}. We show that selectively incorporating these intermediate representations can increase the accuracy of OOD detection by up to \textbf{$10\%$} in far-OOD and over \textbf{$7\%$} in near-OOD benchmarks compared to state-of-the-art training-free methods across various model architectures and training objectives. Our findings reveal a new avenue for OOD detection research and uncover the impact of various training objectives and model architectures on confidence-based OOD detection methods.
<div id='section'>Paperid: <span id='pid'>1589, <a href='https://arxiv.org/pdf/2510.04776.pdf' target='_blank'>https://arxiv.org/pdf/2510.04776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ebenezer Awotoro, Chisom Ezekannagha, Florian Schwarz, Johannes Tauscher, Dominik Heider, Katharina Ladewig, Christel Le Bon, Karine Moncoq, Bruno Miroux, Georges Hattab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04776">MetaMP: Seamless Metadata Enrichment and AI Application Framework for Enhanced Membrane Protein Visualization and Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structural biology has made significant progress in determining membrane proteins, leading to a remarkable increase in the number of available structures in dedicated databases. The inherent complexity of membrane protein structures, coupled with challenges such as missing data, inconsistencies, and computational barriers from disparate sources, underscores the need for improved database integration. To address this gap, we present MetaMP, a framework that unifies membrane-protein databases within a web application and uses machine learning for classification. MetaMP improves data quality by enriching metadata, offering a user-friendly interface, and providing eight interactive views for streamlined exploration. MetaMP was effective across tasks of varying difficulty, demonstrating advantages across different levels without compromising speed or accuracy, according to user evaluations. Moreover, MetaMP supports essential functions such as structure classification and outlier detection. We present three practical applications of Artificial Intelligence (AI) in membrane protein research: predicting transmembrane segments, reconciling legacy databases, and classifying structures with explainable AI support. In a validation focused on statistics, MetaMP resolved 77% of data discrepancies and accurately predicted the class of newly identified membrane proteins 98% of the time and overtook expert curation. Altogether, MetaMP is a much-needed resource that harmonizes current knowledge and empowers AI-driven exploration of membrane-protein architecture.
<div id='section'>Paperid: <span id='pid'>1590, <a href='https://arxiv.org/pdf/2510.03911.pdf' target='_blank'>https://arxiv.org/pdf/2510.03911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yadav Mahesh Lorik, Kaushik Sarveswaran, Nagaraj Sundaramahalingam, Aravindakumar Venugopalan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03911">THEMIS: Unlocking Pretrained Knowledge with Foundation Model Embeddings for Anomaly Detection in Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time series anomaly detection forms a very crucial area in several domains but poses substantial challenges. Due to time series data possessing seasonality, trends, noise, and evolving patterns (concept drift), it becomes very difficult to set a general notion of what constitutes normal behavior. Anomalies themselves could be varied, ranging from a single outlier to contextual or collective anomalies, and are normally very rare; hence, the dataset is largely imbalanced. Additional layers of complexities arise due to the problems of increased dimensionality of modern time series, real-time detection criteria, setting up appropriate detection thresholds, and arriving at results that are interpretable. To embrace these multifaceted challenges, very strong, flexible, and interpretable approaches are required. This paper presents THEMIS, a new framework for time series anomaly detection that exploits pretrained knowledge from foundation models. THEMIS extracts embeddings from the encoder of the Chronos time series foundation model and applies outlier detection techniques like Local Outlier Factor and Spectral Decomposition on the self-similarity matrix, to spot anomalies in the data. Our experiments show that this modular method achieves SOTA results on the MSL dataset and performs quite competitively on the SMAP and SWAT$^*$ datasets. Notably, THEMIS exceeds models trained specifically for anomaly detection, presenting hyperparameter robustness and interpretability by default. This paper advocates for pretrained representations from foundation models for performing efficient and adaptable anomaly detection for time series data.
<div id='section'>Paperid: <span id='pid'>1591, <a href='https://arxiv.org/pdf/2510.01829.pdf' target='_blank'>https://arxiv.org/pdf/2510.01829.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cornelius Schröder, Marius-Raphael Schlüter, Markus Lienkamp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01829">Calibrating the Full Predictive Class Distribution of 3D Object Detectors for Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In autonomous systems, precise object detection and uncertainty estimation are critical for self-aware and safe operation. This work addresses confidence calibration for the classification task of 3D object detectors. We argue that it is necessary to regard the calibration of the full predictive confidence distribution over all classes and deduce a metric which captures the calibration of dominant and secondary class predictions. We propose two auxiliary regularizing loss terms which introduce either calibration of the dominant prediction or the full prediction vector as a training goal. We evaluate a range of post-hoc and train-time methods for CenterPoint, PillarNet and DSVT-Pillar and find that combining our loss term, which regularizes for calibration of the full class prediction, and isotonic regression lead to the best calibration of CenterPoint and PillarNet with respect to both dominant and secondary class predictions. We further find that DSVT-Pillar can not be jointly calibrated for dominant and secondary predictions using the same method.
<div id='section'>Paperid: <span id='pid'>1592, <a href='https://arxiv.org/pdf/2510.00029.pdf' target='_blank'>https://arxiv.org/pdf/2510.00029.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Madhushan Ramalingam, Yaish Riaz, Priyanthi Rajamanoharan, Piyumi Dasanayaka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00029">Enhancing Safety in Diabetic Retinopathy Detection: Uncertainty-Aware Deep Learning Models with Rejection Capabilities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diabetic retinopathy (DR) is a major cause of visual impairment, and effective treatment options depend heavily on timely and accurate diagnosis. Deep learning models have demonstrated great success identifying DR from retinal images. However, relying only on predictions made by models, without any indication of model confidence, creates uncertainty and poses significant risk in clinical settings. This paper investigates an alternative in uncertainty-aware deep learning models, including a rejection mechanism to reject low-confidence predictions, contextualized by deferred decision-making in clinical practice. The results show there is a trade-off between prediction coverage and coverage reliability. The Variational Bayesian model adopted a more conservative strategy when predicting DR, subsequently rejecting the uncertain predictions. The model is evaluated by means of important performance metrics such as Accuracy on accepted predictions, the proportion of accepted cases (coverage), the rejection-ratio, and Expected Calibration Error (ECE). The findings also demonstrate a clear trade-off between accuracy and caution, establishing that the use of uncertainty estimation and selective rejection improves the model's reliability in safety-critical diagnostic use cases.
<div id='section'>Paperid: <span id='pid'>1593, <a href='https://arxiv.org/pdf/2510.00001.pdf' target='_blank'>https://arxiv.org/pdf/2510.00001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Noah Broestl, Adel Nasser Abdalla, Rajprakash Bale, Hersh Gupta, Max Struever
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00001">Methodological Framework for Quantifying Semantic Test Coverage in RAG Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliably determining the performance of Retrieval-Augmented Generation (RAG) systems depends on comprehensive test questions. While a proliferation of evaluation frameworks for LLM-powered applications exists, current practices lack a systematic method to ensure these test sets adequately cover the underlying knowledge base, leaving developers with significant blind spots. To address this, we present a novel, applied methodology to quantify the semantic coverage of RAG test questions against their underlying documents. Our approach leverages existing technologies, including vector embeddings and clustering algorithms, to create a practical framework for validating test comprehensiveness. Our methodology embeds document chunks and test questions into a unified vector space, enabling the calculation of multiple coverage metrics: basic proximity, content-weighted coverage, and multi-topic question coverage. Furthermore, we incorporate outlier detection to filter irrelevant questions, allowing for the refinement of test sets. Experimental evidence from two distinct use cases demonstrates that our framework effectively quantifies test coverage, identifies specific content areas with inadequate representation, and provides concrete recommendations for generating new, high-value test questions. This work provides RAG developers with essential tools to build more robust test suites, thereby improving system reliability and extending to applications such as identifying misaligned documents.
<div id='section'>Paperid: <span id='pid'>1594, <a href='https://arxiv.org/pdf/2509.22014.pdf' target='_blank'>https://arxiv.org/pdf/2509.22014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurav Jha, Stefan K. Ehrlich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22014">Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Healthcare robotics requires robust multimodal perception and reasoning to ensure safety in dynamic clinical environments. Current Vision-Language Models (VLMs) demonstrate strong general-purpose capabilities but remain limited in temporal reasoning, uncertainty estimation, and structured outputs needed for robotic planning. We present a lightweight agentic multimodal framework for video-based scene understanding. Combining the Qwen2.5-VL-3B-Instruct model with a SmolAgent-based orchestration layer, it supports chain-of-thought reasoning, speech-vision fusion, and dynamic tool invocation. The framework generates structured scene graphs and leverages a hybrid retrieval module for interpretable and adaptive reasoning. Evaluations on the Video-MME benchmark and a custom clinical dataset show competitive accuracy and improved robustness compared to state-of-the-art VLMs, demonstrating its potential for applications in robot-assisted surgery, patient monitoring, and decision support.
<div id='section'>Paperid: <span id='pid'>1595, <a href='https://arxiv.org/pdf/2509.19408.pdf' target='_blank'>https://arxiv.org/pdf/2509.19408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Obu-Amoah Ampomah, Edmund Agyemang, Kofi Acheampong, Louis Agyekum
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19408">Enhancing Credit Default Prediction Using Boruta Feature Selection and DBSCAN Algorithm with Different Resampling Techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study examines credit default prediction by comparing three techniques, namely SMOTE, SMOTE-Tomek, and ADASYN, that are commonly used to address the class imbalance problem in credit default situations. Recognizing that credit default datasets are typically skewed, with defaulters comprising a much smaller proportion than non-defaulters, we began our analysis by evaluating machine learning (ML) models on the imbalanced data without any resampling to establish baseline performance. These baseline results provide a reference point for understanding the impact of subsequent balancing methods. In addition to traditional classifiers such as Naive Bayes and K-Nearest Neighbors (KNN), our study also explores the suitability of advanced ensemble boosting algorithms, including Extreme Gradient Boosting (XGBoost), AdaBoost, Gradient Boosting Machines (GBM), and Light GBM for credit default prediction using Boruta feature selection and DBSCAN-based outlier detection, both before and after resampling. A real-world credit default data set sourced from the University of Cleveland ML Repository was used to build ML classifiers, and their performances were tested. The criteria chosen to measure model performance are the area under the receiver operating characteristic curve (ROC-AUC), area under the precision-recall curve (PR-AUC), G-mean, and F1-scores. The results from this empirical study indicate that the Boruta+DBSCAN+SMOTE-Tomek+GBM classifier outperformed the other ML models (F1-score: 82.56%, G-mean: 82.98%, ROC-AUC: 90.90%, PR-AUC: 91.85%) in a credit default context. The findings establish a foundation for future progress in creating more resilient and adaptive credit default systems, which will be essential as credit-based transactions continue to rise worldwide.
<div id='section'>Paperid: <span id='pid'>1596, <a href='https://arxiv.org/pdf/2509.16354.pdf' target='_blank'>https://arxiv.org/pdf/2509.16354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sivan Sarafian, Yehudit Aperstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16354">Improving Deep Tabular Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tabular data remain a dominant form of real-world information but pose persistent challenges for deep learning due to heterogeneous feature types, lack of natural structure, and limited label-preserving augmentations. As a result, ensemble models based on decision trees continue to dominate benchmark leaderboards. In this work, we introduce RuleNet, a transformer-based architecture specifically designed for deep tabular learning. RuleNet incorporates learnable rule embeddings in a decoder, a piecewise linear quantile projection for numerical features, and feature masking ensembles for robustness and uncertainty estimation. Evaluated on eight benchmark datasets, RuleNet matches or surpasses state-of-the-art tree-based methods in most cases, while remaining computationally efficient, offering a practical neural alternative for tabular prediction tasks.
<div id='section'>Paperid: <span id='pid'>1597, <a href='https://arxiv.org/pdf/2509.13713.pdf' target='_blank'>https://arxiv.org/pdf/2509.13713.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tae-Wook Um, Ki-Hyeon Kim, Hyun-Duck Choi, Hyo-Sung Ahn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13713">UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monocular depth estimation has been increasingly adopted in robotics and autonomous driving for its ability to infer scene geometry from a single camera. In self-supervised monocular depth estimation frameworks, the network jointly generates and exploits depth and pose estimates during training, thereby eliminating the need for depth labels. However, these methods remain challenged by uncertainty in the input data, such as low-texture or dynamic regions, which can cause reduced depth accuracy. To address this, we introduce UM-Depth, a framework that combines motion- and uncertainty-aware refinement to enhance depth accuracy at dynamic object boundaries and in textureless regions. Specifically, we develop a teacherstudent training strategy that embeds uncertainty estimation into both the training pipeline and network architecture, thereby strengthening supervision where photometric signals are weak. Unlike prior motion-aware approaches that incur inference-time overhead and rely on additional labels or auxiliary networks for real-time generation, our method uses optical flow exclusively within the teacher network during training, which eliminating extra labeling demands and any runtime cost. Extensive experiments on the KITTI and Cityscapes datasets demonstrate the effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves state-of-the-art results in both self-supervised depth and pose estimation on the KITTI datasets.
<div id='section'>Paperid: <span id='pid'>1598, <a href='https://arxiv.org/pdf/2509.13577.pdf' target='_blank'>https://arxiv.org/pdf/2509.13577.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tongfei Guo, Lili Su
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13577">Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trajectory prediction is central to the safe and seamless operation of autonomous vehicles (AVs). In deployment, however, prediction models inevitably face distribution shifts between training data and real-world conditions, where rare or underrepresented traffic scenarios induce out-of-distribution (OOD) cases. While most prior OOD detection research in AVs has concentrated on computer vision tasks such as object detection and segmentation, trajectory-level OOD detection remains largely underexplored. A recent study formulated this problem as a quickest change detection (QCD) task, providing formal guarantees on the trade-off between detection delay and false alarms [1]. Building on this foundation, we propose a new framework that introduces adaptive mechanisms to achieve robust detection in complex driving environments. Empirical analysis across multiple real-world datasets reveals that prediction errors -- even on in-distribution samples -- exhibit mode-dependent distributions that evolve over time with dataset-specific dynamics. By explicitly modeling these error modes, our method achieves substantial improvements in both detection delay and false alarm rates. Comprehensive experiments on established trajectory prediction benchmarks show that our framework significantly outperforms prior UQ- and vision-based OOD approaches in both accuracy and computational efficiency, offering a practical path toward reliable, driving-aware autonomy.
<div id='section'>Paperid: <span id='pid'>1599, <a href='https://arxiv.org/pdf/2509.10560.pdf' target='_blank'>https://arxiv.org/pdf/2509.10560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuechen Liang, Xiaoxing He, Shengdao Wang, Jean-Philippe Montillet, Zhengkai Huang, Gaël Kermarrec, Shunqiang Hu, Yu Zhou, Jiahui Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10560">GTS_Forecaster: a novel deep learning based geodetic time series forecasting toolbox with python</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geodetic time series -- such as Global Navigation Satellite System (GNSS) positions, satellite altimetry-derived sea surface height (SSH), and tide gauge (TG) records -- is essential for monitoring surface deformation and sea level change. Accurate forecasts of these variables can enhance early warning systems and support hazard mitigation for earthquakes, landslides, coastal storm surge, and long-term sea level. However, the nonlinear, non-stationary, and incomplete nature of such variables presents significant challenges for classic models, which often fail to capture long-term dependencies and complex spatiotemporal dynamics. We introduce GTS Forecaster, an open-source Python package for geodetic time series forecasting. It integrates advanced deep learning models -- including kernel attention networks (KAN), graph neural network-based gated recurrent units (GNNGRU), and time-aware graph neural networks (TimeGNN) -- to effectively model nonlinear spatial-temporal patterns. The package also provides robust preprocessing tools, including outlier detection and a reinforcement learning-based gap-filling algorithm, the Kalman-TransFusion Interpolation Framework (KTIF). GTS Forecaster currently supports forecasting, visualization, and evaluation of GNSS, SSH, and TG datasets, and is adaptable to general time series applications. By combining cutting-edge models with an accessible interface, it facilitates the application of deep learning in geodetic forecasting tasks.
<div id='section'>Paperid: <span id='pid'>1600, <a href='https://arxiv.org/pdf/2509.08069.pdf' target='_blank'>https://arxiv.org/pdf/2509.08069.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiping Ma, Haoming Zhang, Marc Toussaint
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08069">SVN-ICP: Uncertainty Estimation of ICP-based LiDAR Odometry using Stein Variational Newton</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This letter introduces SVN-ICP, a novel Iterative Closest Point (ICP) algorithm with uncertainty estimation that leverages Stein Variational Newton (SVN) on manifold. Designed specifically for fusing LiDAR odometry in multisensor systems, the proposed method ensures accurate pose estimation and consistent noise parameter inference, even in LiDAR-degraded environments. By approximating the posterior distribution using particles within the Stein Variational Inference framework, SVN-ICP eliminates the need for explicit noise modeling or manual parameter tuning. To evaluate its effectiveness, we integrate SVN-ICP into a simple error-state Kalman filter alongside an IMU and test it across multiple datasets spanning diverse environments and robot types. Extensive experimental results demonstrate that our approach outperforms best-in-class methods on challenging scenarios while providing reliable uncertainty estimates.
<div id='section'>Paperid: <span id='pid'>1601, <a href='https://arxiv.org/pdf/2509.06554.pdf' target='_blank'>https://arxiv.org/pdf/2509.06554.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dietmar Saupe, Tim Bleile
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06554">Robustness and accuracy of mean opinion scores with hard and soft outlier detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In subjective assessment of image and video quality, observers rate or compare selected stimuli. Before calculating the mean opinion scores (MOS) for these stimuli from the ratings, it is recommended to identify and deal with outliers that may have given unreliable ratings. Several methods are available for this purpose, some of which have been standardized. These methods are typically based on statistics and sometimes tested by introducing synthetic ratings from artificial outliers, such as random clickers. However, a reliable and comprehensive approach is lacking for comparative performance analysis of outlier detection methods. To fill this gap, this work proposes and applies an empirical worst-case analysis as a general solution. Our method involves evolutionary optimization of an adversarial black-box attack on outlier detection algorithms, where the adversary maximizes the distortion of scale values with respect to ground truth. We apply our analysis to several hard and soft outlier detection methods for absolute category ratings and show their differing performance in this stress test. In addition, we propose two new outlier detection methods with low complexity and excellent worst-case performance. Software for adversarial attacks and data analysis is available.
<div id='section'>Paperid: <span id='pid'>1602, <a href='https://arxiv.org/pdf/2509.05360.pdf' target='_blank'>https://arxiv.org/pdf/2509.05360.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jerry Li, Evangelos Papalexakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05360">Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have demonstrated effectiveness across a wide variety of tasks involving natural language, however, a fundamental problem of hallucinations still plagues these models, limiting their trustworthiness in generating consistent, truthful information. Detecting hallucinations has quickly become an important topic, with various methods such as uncertainty estimation, LLM Judges, retrieval augmented generation (RAG), and consistency checks showing promise. Many of these methods build upon foundational metrics, such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth necessary to detect hallucinations effectively. In this work, we propose a novel approach inspired by ROUGE that constructs an N-Gram frequency tensor from LLM-generated text. This tensor captures richer semantic structure by encoding co-occurrence patterns, enabling better differentiation between factual and hallucinated content. We demonstrate this by applying tensor decomposition methods to extract singular values from each mode and use these as input features to train a multi-layer perceptron (MLP) binary classifier for hallucinations. Our method is evaluated on the HaluEval dataset and demonstrates significant improvements over traditional baselines, as well as competitive performance against state-of-the-art LLM judges.
<div id='section'>Paperid: <span id='pid'>1603, <a href='https://arxiv.org/pdf/2509.02826.pdf' target='_blank'>https://arxiv.org/pdf/2509.02826.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Towhidul Islam, Md Sumon Ali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02826">Ensemble Learning for Healthcare: A Comparative Analysis of Hybrid Voting and Ensemble Stacking in Obesity Risk Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Obesity is a critical global health issue driven by dietary, physiological, and environmental factors, and is strongly associated with chronic diseases such as diabetes, cardiovascular disorders, and cancer. Machine learning has emerged as a promising approach for early obesity risk prediction, yet a comparative evaluation of ensemble techniques -- particularly hybrid majority voting and ensemble stacking -- remains limited. This study aims to compare hybrid majority voting and ensemble stacking methods for obesity risk prediction, identifying which approach delivers higher accuracy and efficiency. The analysis seeks to highlight the complementary strengths of these ensemble techniques in guiding better predictive model selection for healthcare applications. Two datasets were utilized to evaluate three ensemble models: Majority Hard Voting, Weighted Hard Voting, and Stacking (with a Multi-Layer Perceptron as meta-classifier). A pool of nine Machine Learning (ML) algorithms, evaluated across a total of 50 hyperparameter configurations, was analyzed to identify the top three models to serve as base learners for the ensemble methods. Preprocessing steps involved dataset balancing, and outlier detection, and model performance was evaluated using Accuracy and F1-Score. On Dataset-1, weighted hard voting and stacking achieved nearly identical performance (Accuracy: 0.920304, F1: 0.920070), outperforming majority hard voting. On Dataset-2, stacking demonstrated superior results (Accuracy: 0.989837, F1: 0.989825) compared to majority hard voting (Accuracy: 0.981707, F1: 0.981675) and weighted hard voting, which showed the lowest performance. The findings confirm that ensemble stacking provides stronger predictive capability, particularly for complex data distributions, while hybrid majority voting remains a robust alternative.
<div id='section'>Paperid: <span id='pid'>1604, <a href='https://arxiv.org/pdf/2508.16617.pdf' target='_blank'>https://arxiv.org/pdf/2508.16617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>KÃ©vin Ducharlet, Louise TravÃ©-MassuyÃ¨s, Jean-Bernard Lasserre, Marie-VÃ©ronique Le Lann, Youssef Miloudi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16617">Leveraging the Christoffel Function for Outlier Detection in Data Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection holds significant importance in the realm of data mining, particularly with the growing pervasiveness of data acquisition methods. The ability to identify outliers in data streams is essential for maintaining data quality and detecting faults. However, dealing with data streams presents challenges due to the non-stationary nature of distributions and the ever-increasing data volume. While numerous methods have been proposed to tackle this challenge, a common drawback is the lack of straightforward parameterization in many of them. This article introduces two novel methods: DyCF and DyCG. DyCF leverages the Christoffel function from the theory of approximation and orthogonal polynomials. Conversely, DyCG capitalizes on the growth properties of the Christoffel function, eliminating the need for tuning parameters. Both approaches are firmly rooted in a well-defined algebraic framework, meeting crucial demands for data stream processing, with a specific focus on addressing low-dimensional aspects and maintaining data history without memory cost. A comprehensive comparison between DyCF, DyCG, and state-of-the-art methods is presented, using both synthetic and real industrial data streams. The results show that DyCF outperforms fine-tuning methods, offering superior performance in terms of execution time and memory usage. DyCG performs less well, but has the considerable advantage of requiring no tuning at all.
<div id='section'>Paperid: <span id='pid'>1605, <a href='https://arxiv.org/pdf/2508.16527.pdf' target='_blank'>https://arxiv.org/pdf/2508.16527.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrei-Stefan Bulzan, Cosmin Cernazanu-Glavan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16527">Towards Open World Detection: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For decades, Computer Vision has aimed at enabling machines to perceive the external world. Initial limitations led to the development of highly specialized niches. As success in each task accrued and research progressed, increasingly complex perception tasks emerged. This survey charts the convergence of these tasks and, in doing so, introduces Open World Detection (OWD), an umbrella term we propose to unify class-agnostic and generally applicable detection models in the vision domain. We start from the history of foundational vision subdomains and cover key concepts, methodologies and datasets making up today's state-of-the-art landscape. This traverses topics starting from early saliency detection, foreground/background separation, out of distribution detection and leading up to open world object detection, zero-shot detection and Vision Large Language Models (VLLMs). We explore the overlap between these subdomains, their increasing convergence, and their potential to unify into a singular domain in the future, perception.
<div id='section'>Paperid: <span id='pid'>1606, <a href='https://arxiv.org/pdf/2508.14597.pdf' target='_blank'>https://arxiv.org/pdf/2508.14597.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nitish Kumar Mahala, Muzammil Khan, Pushpendra Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14597">Reliable Smoke Detection via Optical Flow-Guided Feature Fusion and Transformer-Based Uncertainty Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fire outbreaks pose critical threats to human life and infrastructure, necessitating high-fidelity early-warning systems that detect combustion precursors such as smoke. However, smoke plumes exhibit complex spatiotemporal dynamics influenced by illumination variability, flow kinematics, and environmental noise, undermining the reliability of traditional detectors. To address these challenges without the logistical complexity of multi-sensor arrays, we propose an information-fusion framework by integrating smoke feature representations extracted from monocular imagery. Specifically, a Two-Phase Uncertainty-Aware Shifted Windows Transformer for robust and reliable smoke detection, leveraging a novel smoke segmentation dataset, constructed via optical flow-based motion encoding, is proposed. The optical flow estimation is performed with a four-color-theorem-inspired dual-phase level-set fractional-order variational model, which preserves motion discontinuities. The resulting color-encoded optical flow maps are fused with appearance cues via a Gaussian Mixture Model to generate binary segmentation masks of the smoke regions. These fused representations are fed into the novel Shifted-Windows Transformer, which is augmented with a multi-scale uncertainty estimation head and trained under a two-phase learning regimen. First learning phase optimizes smoke detection accuracy, while during the second phase, the model learns to estimate plausibility confidence in its predictions by jointly modeling aleatoric and epistemic uncertainties. Extensive experiments using multiple evaluation metrics and comparative analysis with state-of-the-art approaches demonstrate superior generalization and robustness, offering a reliable solution for early fire detection in surveillance, industrial safety, and autonomous monitoring applications.
<div id='section'>Paperid: <span id='pid'>1607, <a href='https://arxiv.org/pdf/2508.13568.pdf' target='_blank'>https://arxiv.org/pdf/2508.13568.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Diego Correa da Silva, Denis Robson Dantas Boaventura, Mayki dos Santos Oliveira, Eduardo Ferreira da Silva, Joel Machado Pires, Frederico AraÃºjo DurÃ£o
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13568">Understanding Distribution Structure on Calibrated Recommendation Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional recommender systems aim to generate a recommendation list comprising the most relevant or similar items to the user's profile. These approaches can create recommendation lists that omit item genres from the less prominent areas of a user's profile, thereby undermining the user's experience. To solve this problem, the calibrated recommendation system provides a guarantee of including less representative areas in the recommended list. The calibrated context works with three distributions. The first is from the user's profile, the second is from the candidate items, and the last is from the recommendation list. These distributions are G-dimensional, where G is the total number of genres in the system. This high dimensionality requires a different evaluation method, considering that traditional recommenders operate in a one-dimensional data space. In this sense, we implement fifteen models that help to understand how these distributions are structured. We evaluate the users' patterns in three datasets from the movie domain. The results indicate that the models of outlier detection provide a better understanding of the structures. The calibrated system creates recommendation lists that act similarly to traditional recommendation lists, allowing users to change their groups of preferences to the same degree.
<div id='section'>Paperid: <span id='pid'>1608, <a href='https://arxiv.org/pdf/2508.11460.pdf' target='_blank'>https://arxiv.org/pdf/2508.11460.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aurora Grefsrud, Nello Blaser, Trygve Buanes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.11460">Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rigorous statistical methods, including parameter estimation with accompanying uncertainties, underpin the validity of scientific discovery, especially in the natural sciences. With increasingly complex data models such as deep learning techniques, uncertainty quantification has become exceedingly difficult and a plethora of techniques have been proposed. In this case study, we use the unifying framework of approximate Bayesian inference combined with empirical tests on carefully created synthetic classification datasets to investigate qualitative properties of six different probabilistic machine learning algorithms for class probability and uncertainty estimation: (i) a neural network ensemble, (ii) neural network ensemble with conflictual loss, (iii) evidential deep learning, (iv) a single neural network with Monte Carlo Dropout, (v) Gaussian process classification and (vi) a Dirichlet process mixture model. We check if the algorithms produce uncertainty estimates which reflect commonly desired properties, such as being well calibrated and exhibiting an increase in uncertainty for out-of-distribution data points. Our results indicate that all algorithms are well calibrated, but none of the deep learning based algorithms provide uncertainties that consistently reflect lack of experimental evidence for out-of-distribution data points. We hope our study may serve as a clarifying example for researchers developing new methods of uncertainty estimation for scientific data-driven modeling.
<div id='section'>Paperid: <span id='pid'>1609, <a href='https://arxiv.org/pdf/2508.11338.pdf' target='_blank'>https://arxiv.org/pdf/2508.11338.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prathamesh Devadiga, Yashmitha Shailesh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.11338">RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce RegimeNAS, a novel differentiable architecture search framework specifically designed to enhance cryptocurrency trading performance by explicitly integrating market regime awareness. Addressing the limitations of static deep learning models in highly dynamic financial environments, RegimeNAS features three core innovations: (1) a theoretically grounded Bayesian search space optimizing architectures with provable convergence properties; (2) specialized, dynamically activated neural modules (Volatility, Trend, and Range blocks) tailored for distinct market conditions; and (3) a multi-objective loss function incorporating market-specific penalties (e.g., volatility matching, transition smoothness) alongside mathematically enforced Lipschitz stability constraints. Regime identification leverages multi-head attention across multiple timeframes for improved accuracy and uncertainty estimation. Rigorous empirical evaluation on extensive real-world cryptocurrency data demonstrates that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving an 80.3% Mean Absolute Error reduction compared to the best traditional recurrent baseline and converging substantially faster (9 vs. 50+ epochs). Ablation studies and regime-specific analysis confirm the critical contribution of each component, particularly the regime-aware adaptation mechanism. This work underscores the imperative of embedding domain-specific knowledge, such as market regimes, directly within the NAS process to develop robust and adaptive models for challenging financial applications.
<div id='section'>Paperid: <span id='pid'>1610, <a href='https://arxiv.org/pdf/2508.10148.pdf' target='_blank'>https://arxiv.org/pdf/2508.10148.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maria Stoica, Francesco Leofante, Alessio Lomuscio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10148">Out-of-Distribution Detection using Counterfactual Distance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and explainable out-of-distribution (OOD) detection is required to use machine learning systems safely. Previous work has shown that feature distance to decision boundaries can be used to identify OOD data effectively. In this paper, we build on this intuition and propose a post-hoc OOD detection method that, given an input, calculates the distance to decision boundaries by leveraging counterfactual explanations. Since computing explanations can be expensive for large architectures, we also propose strategies to improve scalability by computing counterfactuals directly in embedding space. Crucially, as the method employs counterfactual explanations, we can seamlessly use them to help interpret the results of our detector. We show that our method is in line with the state of the art on CIFAR-10, achieving 93.50% AUROC and 25.80% FPR95. Our method outperforms these methods on CIFAR-100 with 97.05% AUROC and 13.79% FPR95 and on ImageNet-200 with 92.55% AUROC and 33.55% FPR95 across four OOD datasets
<div id='section'>Paperid: <span id='pid'>1611, <a href='https://arxiv.org/pdf/2508.05454.pdf' target='_blank'>https://arxiv.org/pdf/2508.05454.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Li, Zixin Wang, Qizheng Sun, Qixiang Gao, Fenglei Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05454">EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty Estimation for Energy Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and reliable energy time series prediction is of great significance for power generation planning and allocation. At present, deep learning time series prediction has become the mainstream method. However, the multi-scale time dynamics and the irregularity of real data lead to the limitations of the existing methods. Therefore, we propose EnergyPatchTST, which is an extension of the Patch Time Series Transformer specially designed for energy forecasting. The main innovations of our method are as follows: (1) multi-scale feature extraction mechanism to capture patterns with different time resolutions; (2) probability prediction framework to estimate uncertainty through Monte Carlo elimination; (3) integration path of future known variables (such as temperature and wind conditions); And (4) Pre-training and Fine-tuning examples to enhance the performance of limited energy data sets. A series of experiments on common energy data sets show that EnergyPatchTST is superior to other commonly used methods, the prediction error is reduced by 7-12%, and reliable uncertainty estimation is provided, which provides an important reference for time series prediction in the energy field.
<div id='section'>Paperid: <span id='pid'>1612, <a href='https://arxiv.org/pdf/2508.03405.pdf' target='_blank'>https://arxiv.org/pdf/2508.03405.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fei Shuang, Zixiong Wei, Kai Liu, Wei Gao, Poulumi Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03405">Model Accuracy and Data Heterogeneity Shape Uncertainty Quantification in Machine Learning Interatomic Potentials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning interatomic potentials (MLIPs) enable accurate atomistic modelling, but reliable uncertainty quantification (UQ) remains elusive. In this study, we investigate two UQ strategies, ensemble learning and D-optimality, within the atomic cluster expansion framework. It is revealed that higher model accuracy strengthens the correlation between predicted uncertainties and actual errors and improves novelty detection, with D-optimality yielding more conservative estimates. Both methods deliver well calibrated uncertainties on homogeneous training sets, yet they underpredict errors and exhibit reduced novelty sensitivity on heterogeneous datasets. To address this limitation, we introduce clustering-enhanced local D-optimality, which partitions configuration space into clusters during training and applies D-optimality within each cluster. This approach substantially improves the detection of novel atomic environments in heterogeneous datasets. Our findings clarify the roles of model fidelity and data heterogeneity in UQ performance and provide a practical route to robust active learning and adaptive sampling strategies for MLIP development.
<div id='section'>Paperid: <span id='pid'>1613, <a href='https://arxiv.org/pdf/2507.18366.pdf' target='_blank'>https://arxiv.org/pdf/2507.18366.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lakshmana Sri Harsha Nemani, P. K. Srijith, Tomasz KuÅmierczyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18366">Efficient Uncertainty in LLMs through Evidential Knowledge Distillation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate uncertainty quantification remains a key challenge for standard LLMs, prompting the adoption of Bayesian and ensemble-based methods. However, such methods typically necessitate computationally expensive sampling, involving multiple forward passes to effectively estimate predictive uncertainty.
  In this paper, we introduce a novel approach enabling efficient and effective uncertainty estimation in LLMs without sacrificing performance. Specifically, we distill uncertainty-aware teacher models - originally requiring multiple forward passes - into compact student models sharing the same architecture but fine-tuned using Low-Rank Adaptation (LoRA). We compare two distinct distillation strategies: one in which the student employs traditional softmax-based outputs, and another in which the student leverages Dirichlet-distributed outputs to explicitly model epistemic uncertainty via evidential learning.
  Empirical evaluations on classification datasets demonstrate that such students can achieve comparable or superior predictive and uncertainty quantification performance relative to their teacher models, while critically requiring only a single forward pass. To our knowledge, this is the first demonstration that immediate and robust uncertainty quantification can be achieved in LLMs through evidential distillation.
<div id='section'>Paperid: <span id='pid'>1614, <a href='https://arxiv.org/pdf/2507.16952.pdf' target='_blank'>https://arxiv.org/pdf/2507.16952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Min-Ha-Zul Abedin, Tazqia Mehrub
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16952">Evaluating Ensemble and Deep Learning Models for Static Malware Detection with Dimensionality Reduction Using the EMBER Dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the effectiveness of several machine learning algorithms for static malware detection using the EMBER dataset, which contains feature representations of Portable Executable (PE) files. We evaluate eight classification models: LightGBM, XGBoost, CatBoost, Random Forest, Extra Trees, HistGradientBoosting, k-Nearest Neighbors (KNN), and TabNet, under three preprocessing settings: original feature space, Principal Component Analysis (PCA), and Linear Discriminant Analysis (LDA). The models are assessed on accuracy, precision, recall, F1 score, and AUC to examine both predictive performance and robustness. Ensemble methods, especially LightGBM and XGBoost, show the best overall performance across all configurations, with minimal sensitivity to PCA and consistent generalization. LDA improves KNN performance but significantly reduces accuracy for boosting models. TabNet, while promising in theory, underperformed under feature reduction, likely due to architectural sensitivity to input structure. The analysis is supported by detailed exploratory data analysis (EDA), including mutual information ranking, PCA or t-SNE visualizations, and outlier detection using Isolation Forest and Local Outlier Factor (LOF), which confirm the discriminatory capacity of key features in the EMBER dataset. The results suggest that boosting models remain the most reliable choice for high-dimensional static malware detection, and that dimensionality reduction should be applied selectively based on model type. This work provides a benchmark for comparing classification models and preprocessing strategies in malware detection tasks and contributes insights that can guide future system development and real-world deployment.
<div id='section'>Paperid: <span id='pid'>1615, <a href='https://arxiv.org/pdf/2507.14649.pdf' target='_blank'>https://arxiv.org/pdf/2507.14649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minsuh Joo, Hyunsoo Cho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14649">Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the outstanding performance of large language models (LLMs) across various NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate responses--remains as a critical problem as it can be directly connected to a crisis of building safe and reliable LLMs. Uncertainty estimation is primarily used to measure hallucination levels in LLM responses so that correct and incorrect answers can be distinguished clearly. This study proposes an effective uncertainty estimation approach, \textbf{Cl}ust\textbf{e}ring-based sem\textbf{an}tic con\textbf{s}ist\textbf{e}ncy (\textbf{Cleanse}). Cleanse quantifies the uncertainty with the proportion of the intra-cluster consistency in the total consistency between LLM hidden embeddings which contain adequate semantic information of generations, by employing clustering. The effectiveness of Cleanse for detecting hallucination is validated using four off-the-shelf models, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two question-answering benchmarks, SQuAD and CoQA.
<div id='section'>Paperid: <span id='pid'>1616, <a href='https://arxiv.org/pdf/2507.14588.pdf' target='_blank'>https://arxiv.org/pdf/2507.14588.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Usayd Shahul, J. Harshan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14588">FORTA: Byzantine-Resilient FL Aggregation via DFT-Guided Krum</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Secure federated learning enables collaborative model training across decentralized users while preserving data privacy. A key component is secure aggregation, which keeps individual updates hidden from both the server and users, while also defending against Byzantine users who corrupt the aggregation. To this end, Jinhyun So et al. recently developed a Byzantine-resilient secure aggregation scheme using a secret-sharing strategy over finite-field arithmetic. However, such an approach can suffer from numerical errors and overflows when applied to real-valued model updates, motivating the need for secure aggregation methods that operate directly over the real domain. We propose FORTA, a Byzantine-resilient secure aggregation framework that operates entirely in the real domain. FORTA leverages Discrete Fourier Transform (DFT) codes for privacy and employs Krum-based outlier detection for robustness. While DFT decoder is error-free under infinite precision, finite precision introduces numerical perturbations that can distort distance estimates and allow malicious updates to evade detection. To address this, FORTA refines Krum using feedback from DFT decoder, improving the selection of trustworthy updates. Theoretical analysis and experiments show that our modification of Krum offers improved robustness and more accurate aggregation than standard Krum.
<div id='section'>Paperid: <span id='pid'>1617, <a href='https://arxiv.org/pdf/2507.11106.pdf' target='_blank'>https://arxiv.org/pdf/2507.11106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>VÃ­ctor Blanco, Inmaculada Espejo, RaÃºl PÃ¡ez, Antonio M. RodrÃ­guez-ChÃ­a
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11106">A Mathematical Optimization Approach to Multisphere Support Vector Data Description</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel mathematical optimization framework for outlier detection in multimodal datasets, extending Support Vector Data Description approaches. We provide a primal formulation, in the shape of a Mixed Integer Second Order Cone model, that constructs Euclidean hyperspheres to identify anomalous observations. Building on this, we develop a dual model that enables the application of the kernel trick, thus allowing for the detection of outliers within complex, non-linear data structures. An extensive computational study demonstrates the effectiveness of our exact method, showing clear advantages over existing heuristic techniques in terms of accuracy and robustness.
<div id='section'>Paperid: <span id='pid'>1618, <a href='https://arxiv.org/pdf/2507.06111.pdf' target='_blank'>https://arxiv.org/pdf/2507.06111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamad H. Danesh, Maxime Wabartha, Stanley Wu, Joelle Pineau, Hsiu-Chin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06111">Safe Domain Randomization via Uncertainty-Aware Out-of-Distribution Detection and Policy Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying reinforcement learning (RL) policies in real-world involves significant challenges, including distribution shifts, safety concerns, and the impracticality of direct interactions during policy refinement. Existing methods, such as domain randomization (DR) and off-dynamics RL, enhance policy robustness by direct interaction with the target domain, an inherently unsafe practice. We propose Uncertainty-Aware RL (UARL), a novel framework that prioritizes safety during training by addressing Out-Of-Distribution (OOD) detection and policy adaptation without requiring direct interactions in target domain. UARL employs an ensemble of critics to quantify policy uncertainty and incorporates progressive environmental randomization to prepare the policy for diverse real-world conditions. By iteratively refining over high-uncertainty regions of the state space in simulated environments, UARL enhances robust generalization to the target domain without explicitly training on it. We evaluate UARL on MuJoCo benchmarks and a quadrupedal robot, demonstrating its effectiveness in reliable OOD detection, improved performance, and enhanced sample efficiency compared to baselines.
<div id='section'>Paperid: <span id='pid'>1619, <a href='https://arxiv.org/pdf/2507.02256.pdf' target='_blank'>https://arxiv.org/pdf/2507.02256.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Yang, Xiaolu Zhou, Bosong Ding, Miao Xin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02256">Uncertainty-aware Reward Design Process</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing effective reward functions is a cornerstone of reinforcement learning (RL), yet it remains a challenging process due to the inefficiencies and inconsistencies inherent in conventional reward engineering methodologies. Recent advances have explored leveraging large language models (LLMs) to automate reward function design. However, their suboptimal performance in numerical optimization often yields unsatisfactory reward quality, while the evolutionary search paradigm demonstrates inefficient utilization of simulation resources, resulting in prohibitively lengthy design cycles with disproportionate computational overhead. To address these challenges, we propose the Uncertainty-aware Reward Design Process (URDP), a novel framework that integrates large language models to streamline reward function design and evaluation in RL environments. URDP quantifies candidate reward function uncertainty based on self-consistency analysis, enabling simulation-free identification of ineffective reward components while discovering novel reward components. Furthermore, we introduce uncertainty-aware Bayesian optimization (UABO), which incorporates uncertainty estimation to significantly enhance hyperparameter configuration efficiency. Finally, we construct a bi-level optimization architecture by decoupling the reward component optimization and the hyperparameter tuning. URDP orchestrates synergistic collaboration between the reward logic reasoning of the LLMs and the numerical optimization strengths of the Bayesian Optimization. We conduct a comprehensive evaluation of URDP across 35 diverse tasks spanning three benchmark environments. Our experimental results demonstrate that URDP not only generates higher-quality reward functions but also achieves significant improvements in the efficiency of automated reward design compared to existing approaches.
<div id='section'>Paperid: <span id='pid'>1620, <a href='https://arxiv.org/pdf/2507.00368.pdf' target='_blank'>https://arxiv.org/pdf/2507.00368.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hikaru Shijo, Yutaka Yoshihama, Kenichi Yadani, Norifumi Murata
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00368">Out-of-Distribution Detection with Adaptive Top-K Logits Integration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks often make overconfident predictions from out-of-distribution (OOD) samples. Detection of OOD data is therefore crucial to improve the safety of machine learning. The simplest and most powerful method for OOD detection is MaxLogit, which uses the model's maximum logit to provide an OOD score. We have discovered that, in addition to the maximum logit, some other logits are also useful for OOD detection. Based on this finding, we propose a new method called ATLI (Adaptive Top-k Logits Integration), which adaptively determines effective top-k logits that are specific to each model and combines the maximum logit with the other top-k logits. In this study we evaluate our proposed method using ImageNet-1K benchmark. Extensive experiments showed our proposed method to reduce the false positive rate (FPR95) by 6.73% compared to the MaxLogit approach, and decreased FPR95 by an additional 2.67% compared to other state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1621, <a href='https://arxiv.org/pdf/2506.23446.pdf' target='_blank'>https://arxiv.org/pdf/2506.23446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Elbasheer, Adewale Akinfaderin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23446">User-Based Sequential Modeling with Transformer Encoders for Insider Threat Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Insider threat detection presents unique challenges due to the authorized status of malicious actors and the subtlety of anomalous behaviors. Existing machine learning methods often treat user activity as isolated events, thereby failing to leverage sequential dependencies in user behavior. In this study, we propose a User-Based Sequencing (UBS) methodology, transforming the CERT insider threat dataset into structured temporal sequences suitable for deep sequential modeling. We deploy a Transformer Encoder architecture to model benign user activity and employ its reconstruction errors as anomaly scores. These scores are subsequently evaluated using three unsupervised outlier detection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and Isolation Forest (iForest). Across four rigorously designed test sets, including combinations of multiple CERT dataset releases, our UBS-Transformer pipeline consistently achieves state-of-the-art performance - notably 96.61% accuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low false negative (0.0057) and false positive (0.0571) rates. Comparative analyses demonstrate that our approach substantially outperforms tabular and conventional autoencoder baselines, underscoring the efficacy of sequential user modeling and advanced anomaly detection in the insider threat domain.
<div id='section'>Paperid: <span id='pid'>1622, <a href='https://arxiv.org/pdf/2506.19895.pdf' target='_blank'>https://arxiv.org/pdf/2506.19895.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miguel N. Font, JosÃ© L. Jorro-Aragoneses, Carlos M. AlaÃ­z
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19895">A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Networks have high accuracy in solving problems where it is difficult to detect patterns or create a logical model. However, these algorithms sometimes return wrong solutions, which become problematic in high-risk domains like medical diagnosis or autonomous driving. One strategy to detect and mitigate these errors is the measurement of the uncertainty over neural network decisions. In this paper, we present a novel post-hoc framework for measuring the uncertainty of a decision based on retrieved training cases that have a similar activation vector to the query for each layer. Based on these retrieved cases, we propose two new metrics: Decision Change and Layer Uncertainty, which capture changes in nearest-neighbor class distributions across layers. We evaluated our approach in a classification model for two datasets: CIFAR-10 and MNIST. The results show that these metrics enhance uncertainty estimation, especially in challenging classification tasks, outperforming softmax-based confidence.
<div id='section'>Paperid: <span id='pid'>1623, <a href='https://arxiv.org/pdf/2506.18283.pdf' target='_blank'>https://arxiv.org/pdf/2506.18283.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuli Slavutsky, David M. Blei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18283">Quantifying Uncertainty in the Presence of Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks make accurate predictions but often fail to provide reliable uncertainty estimates, especially under covariate distribution shifts between training and testing. To address this problem, we propose a Bayesian framework for uncertainty estimation that explicitly accounts for covariate shifts. While conventional approaches rely on fixed priors, the key idea of our method is an adaptive prior, conditioned on both training and new covariates. This prior naturally increases uncertainty for inputs that lie far from the training distribution in regions where predictive performance is likely to degrade. To efficiently approximate the resulting posterior predictive distribution, we employ amortized variational inference. Finally, we construct synthetic environments by drawing small bootstrap samples from the training data, simulating a range of plausible covariate shift using only the original dataset. We evaluate our method on both synthetic and real-world data. It yields substantially improved uncertainty estimates under distribution shifts.
<div id='section'>Paperid: <span id='pid'>1624, <a href='https://arxiv.org/pdf/2506.18162.pdf' target='_blank'>https://arxiv.org/pdf/2506.18162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hendrik Mehrtens, Tabea Bucher, Titus J. Brinker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18162">Pitfalls of Conformal Predictions for Medical Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty estimation is one of the major challenges for medical classification tasks. While many approaches have been proposed, recently the statistical framework of conformal predictions has gained a lot of attention, due to its ability to provide provable calibration guarantees. Nonetheless, the application of conformal predictions in safety-critical areas such as medicine comes with pitfalls, limitations and assumptions that practitioners need to be aware of. We demonstrate through examples from dermatology and histopathology that conformal predictions are unreliable under distributional shifts in input and label variables. Additionally, conformal predictions should not be used for selecting predictions to improve accuracy and are not reliable for subsets of the data, such as individual classes or patient attributes. Moreover, in classification settings with a small number of classes, which are common in medical image classification tasks, conformal predictions have limited practical value.
<div id='section'>Paperid: <span id='pid'>1625, <a href='https://arxiv.org/pdf/2506.15851.pdf' target='_blank'>https://arxiv.org/pdf/2506.15851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiyuan Wu, Mark Campbell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15851">Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The uncertainty quantification of sensor measurements coupled with deep learning networks is crucial for many robotics systems, especially for safety-critical applications such as self-driving cars. This paper develops an uncertainty quantification approach in the context of visual localization for autonomous driving, where locations are selected based on images. Key to our approach is to learn the measurement uncertainty using light-weight sensor error model, which maps both image feature and semantic information to 2-dimensional error distribution. Our approach enables uncertainty estimation conditioned on the specific context of the matched image pair, implicitly capturing other critical, unannotated factors (e.g., city vs highway, dynamic vs static scenes, winter vs summer) in a latent manner. We demonstrate the accuracy of our uncertainty prediction framework using the Ithaca365 dataset, which includes variations in lighting and weather (sunny, night, snowy). Both the uncertainty quantification of the sensor+network is evaluated, along with Bayesian localization filters using unique sensor gating method. Results show that the measurement error does not follow a Gaussian distribution with poor weather and lighting conditions, and is better predicted by our Gaussian Mixture model.
<div id='section'>Paperid: <span id='pid'>1626, <a href='https://arxiv.org/pdf/2506.14390.pdf' target='_blank'>https://arxiv.org/pdf/2506.14390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Conrad Orglmeister, Erik Bochinski, Volker Eiselein, Elvira Fleig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14390">Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the decision-making and trusting the reliability of Deep Machine Learning Models is crucial for adopting such methods to safety-relevant applications. We extend self-explainable Prototypical Variational models with autoencoder-based out-of-distribution (OOD) detection: A Variational Autoencoder is applied to learn a meaningful latent space which can be used for distance-based classification, likelihood estimation for OOD detection, and reconstruction. The In-Distribution (ID) region is defined by a Gaussian mixture distribution with learned prototypes representing the center of each mode. Furthermore, a novel restriction loss is introduced that promotes a compact ID region in the latent space without collapsing it into single points. The reconstructive capabilities of the Autoencoder ensure the explainability of the prototypes and the ID region of the classifier, further aiding the discrimination of OOD samples. Extensive evaluations on common OOD detection benchmarks as well as a large-scale dataset from a real-world railway application demonstrate the usefulness of the approach, outperforming previous methods.
<div id='section'>Paperid: <span id='pid'>1627, <a href='https://arxiv.org/pdf/2506.10769.pdf' target='_blank'>https://arxiv.org/pdf/2506.10769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alberto Testoni, Iacer Calixto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10769">Mind the Gap: Benchmarking LLM Uncertainty, Discrimination, and Calibration in Specialty-Aware Clinical QA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable uncertainty quantification (UQ) is essential when employing large language models (LLMs) in high-risk domains such as clinical question answering (QA). In this work, we evaluate uncertainty estimation methods for clinical QA focusing, for the first time, on eleven clinical specialties and six question types, and across ten open-source LLMs (general-purpose, biomedical, and reasoning models). We analyze score-based UQ methods, present a case study introducing a novel lightweight method based on behavioral features derived from reasoning-oriented models, and examine conformal prediction as a complementary set-based approach. Our findings reveal that uncertainty reliability is not a monolithic property, but one that depends on clinical specialty and question type due to shifts in calibration and discrimination. Our results highlight the need to select or ensemble models based on their distinct, complementary strengths and clinical use.
<div id='section'>Paperid: <span id='pid'>1628, <a href='https://arxiv.org/pdf/2506.06907.pdf' target='_blank'>https://arxiv.org/pdf/2506.06907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fred Xu, Thomas Markovich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06907">Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks have achieved impressive results across diverse network modeling tasks, but accurately estimating uncertainty on graphs remains difficult, especially under distributional shifts. Unlike traditional uncertainty estimation, graph-based uncertainty must account for randomness arising from both the graph's structure and its label distribution, which adds complexity. In this paper, making an analogy between the evolution of a stochastic partial differential equation (SPDE) driven by Matern Gaussian Process and message passing using GNN layers, we present a principled way to design a novel message passing scheme that incorporates spatial-temporal noises motivated by the Gaussian Process approach to SPDE. Our method simultaneously captures uncertainty across space and time and allows explicit control over the covariance kernel smoothness, thereby enhancing uncertainty estimates on graphs with both low and high label informativeness. Our extensive experiments on Out-of-Distribution (OOD) detection on graph datasets with varying label informativeness demonstrate the soundness and superiority of our model to existing approaches.
<div id='section'>Paperid: <span id='pid'>1629, <a href='https://arxiv.org/pdf/2506.04241.pdf' target='_blank'>https://arxiv.org/pdf/2506.04241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Konstantin Kirchheim, Frank Ortmeier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.04241">Improving Out-of-Distribution Detection with Markov Logic Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for ensuring the reliability of deep learning models operating in open-world scenarios. Current OOD detectors mainly rely on statistical models to identify unusual patterns in the latent representations of a deep neural network. This work proposes to augment existing OOD detectors with probabilistic reasoning, utilizing Markov logic networks (MLNs). MLNs connect first-order logic with probabilistic reasoning to assign probabilities to inputs based on weighted logical constraints defined over human-understandable concepts, which offers improved explainability. Through extensive experiments on multiple datasets, we demonstrate that MLNs can significantly enhance the performance of a wide range of existing OOD detectors while maintaining computational efficiency. Furthermore, we introduce a simple algorithm for learning logical constraints for OOD detection from a dataset and showcase its effectiveness.
<div id='section'>Paperid: <span id='pid'>1630, <a href='https://arxiv.org/pdf/2506.03657.pdf' target='_blank'>https://arxiv.org/pdf/2506.03657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leonardo Martins Bianco, Christine Keribin, Zacharie Naulet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.03657">SubSearch: Robust Estimation and Outlier Detection for Stochastic Block Models via Subgraph Search</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Community detection is a fundamental task in graph analysis, with methods often relying on fitting models like the Stochastic Block Model (SBM) to observed networks. While many algorithms can accurately estimate SBM parameters when the input graph is a perfect sample from the model, real-world graphs rarely conform to such idealized assumptions. Therefore, robust algorithms are crucial-ones that can recover model parameters even when the data deviates from the assumed distribution. In this work, we propose SubSearch, an algorithm for robustly estimating SBM parameters by exploring the space of subgraphs in search of one that closely aligns with the model's assumptions. Our approach also functions as an outlier detection method, properly identifying nodes responsible for the graph's deviation from the model and going beyond simple techniques like pruning high-degree nodes. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our method.
<div id='section'>Paperid: <span id='pid'>1631, <a href='https://arxiv.org/pdf/2506.00662.pdf' target='_blank'>https://arxiv.org/pdf/2506.00662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeho Jo, Eun Hye Lee, Alzheimer's Disease Sequencing Project
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00662">Uncertainty-Aware Genomic Classification of Alzheimer's Disease: A Transformer-Based Ensemble Approach with Monte Carlo Dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>INTRODUCTION: Alzheimer's disease (AD) is genetically complex, complicating robust classification from genomic data. METHODS: We developed a transformer-based ensemble model (TrUE-Net) using Monte Carlo Dropout for uncertainty estimation in AD classification from whole-genome sequencing (WGS). We combined a transformer that preserves single-nucleotide polymorphism (SNP) sequence structure with a concurrent random forest using flattened genotypes. An uncertainty threshold separated samples into an uncertain (high-variance) group and a more certain (low-variance) group. RESULTS: We analyzed 1050 individuals, holding out half for testing. Overall accuracy and area under the receiver operating characteristic (ROC) curve (AUC) were 0.6514 and 0.6636, respectively. Excluding the uncertain group improved accuracy from 0.6263 to 0.7287 (10.24% increase) and F1 from 0.5843 to 0.8205 (23.62% increase). DISCUSSION: Monte Carlo Dropout-driven uncertainty helps identify ambiguous cases that may require further clinical evaluation, thus improving reliability in AD genomic classification.
<div id='section'>Paperid: <span id='pid'>1632, <a href='https://arxiv.org/pdf/2505.23845.pdf' target='_blank'>https://arxiv.org/pdf/2505.23845.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jakub Podolak, Rajeev Verma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23845">Read Your Own Mind: Reasoning Helps Surface Self-Confidence Signals in LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the source of uncertainty in DeepSeek R1-32B by analyzing its self-reported verbal confidence on question answering (QA) tasks. In the default answer-then-confidence setting, the model is regularly over-confident, whereas semantic entropy - obtained by sampling many responses - remains reliable. We hypothesize that this is because of semantic entropy's larger test-time compute, which lets us explore the model's predictive distribution. We show that granting DeepSeek the budget to explore its distribution by forcing a long chain-of-thought before the final answer greatly improves its verbal score effectiveness, even on simple fact-retrieval questions that normally require no reasoning. Furthermore, a separate reader model that sees only the chain can reconstruct very similar confidences, indicating the verbal score might be merely a statistic of the alternatives surfaced during reasoning. Our analysis concludes that reliable uncertainty estimation requires explicit exploration of the generative space, and self-reported confidence is trustworthy only after such exploration.
<div id='section'>Paperid: <span id='pid'>1633, <a href='https://arxiv.org/pdf/2505.20691.pdf' target='_blank'>https://arxiv.org/pdf/2505.20691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shenkai Zhao, Xinao Zhang, Lipeng Pan, Xiaobin Xu, Danilo Pelusi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20691">Evidential Deep Active Learning for Semi-Supervised Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semi-supervised classification based on active learning has made significant progress, but the existing methods often ignore the uncertainty estimation (or reliability) of the prediction results during the learning process, which makes it questionable whether the selected samples can effectively update the model. Hence, this paper proposes an evidential deep active learning approach for semi-supervised classification (EDALSSC). EDALSSC builds a semi-supervised learning framework to simultaneously quantify the uncertainty estimation of labeled and unlabeled data during the learning process. The uncertainty estimation of the former is associated with evidential deep learning, while that of the latter is modeled by combining ignorance information and conflict information of the evidence from the perspective of the T-conorm operator. Furthermore, this article constructs a heuristic method to dynamically balance the influence of evidence and the number of classes on uncertainty estimation to ensure that it does not produce counter-intuitive results in EDALSSC. For the sample selection strategy, EDALSSC selects the sample with the greatest uncertainty estimation that is calculated in the form of a sum when the training loss increases in the latter half of the learning process. Experimental results demonstrate that EDALSSC outperforms existing semi-supervised and supervised active learning approaches on image classification datasets.
<div id='section'>Paperid: <span id='pid'>1634, <a href='https://arxiv.org/pdf/2505.16320.pdf' target='_blank'>https://arxiv.org/pdf/2505.16320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>P. Huijse, J. De Ridder, L. Eyer, L. Rimoldini, B. Holl, N. Chornay, J. Roquette, K. Nienartowicz, G. Jevardat de Fombelle, D. J. Fritzewski, A. Kemp, V. Vanlaer, M. Vanrespaille, H. Wang, M. I. Carnerero, C. M. Raiteri, G. Marton, M. Madarász, G. Clementini, P. Gavras, C. Aerts
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16320">Learning novel representations of variable sources from multi-modal $\textit{Gaia}$ data via autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gaia Data Release 3 (DR3) published for the first time epoch photometry, BP/RP (XP) low-resolution mean spectra, and supervised classification results for millions of variable sources. This extensive dataset offers a unique opportunity to study their variability by combining multiple Gaia data products. In preparation for DR4, we propose and evaluate a machine learning methodology capable of ingesting multiple Gaia data products to achieve an unsupervised classification of stellar and quasar variability. A dataset of 4 million Gaia DR3 sources is used to train three variational autoencoders (VAE), which are artificial neural networks (ANNs) designed for data compression and generation. One VAE is trained on Gaia XP low-resolution spectra, another on a novel approach based on the distribution of magnitude differences in the Gaia G band, and the third on folded Gaia G band light curves. Each Gaia source is compressed into 15 numbers, representing the coordinates in a 15-dimensional latent space generated by combining the outputs of these three models. The learned latent representation produced by the ANN effectively distinguishes between the main variability classes present in Gaia DR3, as demonstrated through both supervised and unsupervised classification analysis of the latent space. The results highlight a strong synergy between light curves and low-resolution spectral data, emphasising the benefits of combining the different Gaia data products. A two-dimensional projection of the latent variables reveals numerous overdensities, most of which strongly correlate with astrophysical properties, showing the potential of this latent space for astrophysical discovery. We show that the properties of our novel latent representation make it highly valuable for variability analysis tasks, including classification, clustering and outlier detection.
<div id='section'>Paperid: <span id='pid'>1635, <a href='https://arxiv.org/pdf/2505.14285.pdf' target='_blank'>https://arxiv.org/pdf/2505.14285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eirini Panteli, Paulo E. Santos, Nabil Humphrey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14285">AquaSignal: An Integrated Framework for Robust Underwater Acoustic Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents AquaSignal, a modular and scalable pipeline for preprocessing, denoising, classification, and novelty detection of underwater acoustic signals. Designed to operate effectively in noisy and dynamic marine environments, AquaSignal integrates state-of-the-art deep learning architectures to enhance the reliability and accuracy of acoustic signal analysis. The system is evaluated on a combined dataset from the Deepship and Ocean Networks Canada (ONC) benchmarks, providing a diverse set of real-world underwater scenarios. AquaSignal employs a U-Net architecture for denoising, a ResNet18 convolutional neural network for classifying known acoustic events, and an AutoEncoder-based model for unsupervised detection of novel or anomalous signals. To our knowledge, this is the first comprehensive study to apply and evaluate this combination of techniques on maritime vessel acoustic data. Experimental results show that AquaSignal improves signal clarity and task performance, achieving 71% classification accuracy and 91% accuracy in novelty detection. Despite slightly lower classification performance compared to some state-of-the-art models, differences in data partitioning strategies limit direct comparisons. Overall, AquaSignal demonstrates strong potential for real-time underwater acoustic monitoring in scientific, environmental, and maritime domains.
<div id='section'>Paperid: <span id='pid'>1636, <a href='https://arxiv.org/pdf/2505.12353.pdf' target='_blank'>https://arxiv.org/pdf/2505.12353.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prakash Palanivelu Rajmohan, Fred Roosta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12353">Importance Sampling for Nonlinear Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While norm-based and leverage-score-based methods have been extensively studied for identifying "important" data points in linear models, analogous tools for nonlinear models remain significantly underdeveloped. By introducing the concept of the adjoint operator of a nonlinear map, we address this gap and generalize norm-based and leverage-score-based importance sampling to nonlinear settings. We demonstrate that sampling based on these generalized notions of norm and leverage scores provides approximation guarantees for the underlying nonlinear mapping, similar to linear subspace embeddings. As direct applications, these nonlinear scores not only reduce the computational complexity of training nonlinear models by enabling efficient sampling over large datasets but also offer a novel mechanism for model explainability and outlier detection. Our contributions are supported by both theoretical analyses and experimental results across a variety of supervised learning scenarios.
<div id='section'>Paperid: <span id='pid'>1637, <a href='https://arxiv.org/pdf/2505.11804.pdf' target='_blank'>https://arxiv.org/pdf/2505.11804.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi Wang, Eric Nalisnick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11804">Are vision language models robust to uncertain inputs?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robustness against uncertain and ambiguous inputs is a critical challenge for deep learning models. While recent advancements in large scale vision language models (VLMs, e.g. GPT4o) might suggest that increasing model and training dataset size would mitigate this issue, our empirical evaluation shows a more complicated picture. Testing models using two classic uncertainty quantification tasks, anomaly detection and classification under inherently ambiguous conditions, we find that newer and larger VLMs indeed exhibit improved robustness compared to earlier models, but still suffer from a tendency to strictly follow instructions, often causing them to hallucinate confident responses even when faced with unclear or anomalous inputs. Remarkably, for natural images such as ImageNet, this limitation can be overcome without pipeline modifications: simply prompting models to abstain from uncertain predictions enables significant reliability gains, achieving near-perfect robustness in several settings. However, for domain-specific tasks such as galaxy morphology classification, a lack of specialized knowledge prevents reliable uncertainty estimation. Finally, we propose a novel mechanism based on caption diversity to reveal a model's internal uncertainty, enabling practitioners to predict when models will successfully abstain without relying on labeled data.
<div id='section'>Paperid: <span id='pid'>1638, <a href='https://arxiv.org/pdf/2505.09319.pdf' target='_blank'>https://arxiv.org/pdf/2505.09319.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaustabha Ray, Nelson Mimura Gonzalez, Bruno Wassermann, Rachel Tzoref-Brill, Dean H. Lorenz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09319">Statistical Modeling and Uncertainty Estimation of LLM Inference Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Model (LLM) inference systems present significant challenges in statistical performance characterization due to dynamic workload variations, diverse hardware architectures, and complex interactions between model size, batch processing, and throughput requirements. Accurate statistical characterization enables better workload scheduling, adaptive resource provisioning, and cost-aware inference optimization, making it crucial for improving efficiency in large-scale AI deployments. Traditional analytical models provide explainability but cannot cover the vast diversity of real-world workloads, making it impossible to benchmark every scenario in advance. Machine learning (ML) approaches effectively predict performance for non-benchmarked cases but struggle when extrapolating beyond their observed training space. To address these limitations for LLM inference systems, we propose an Analytical with Learning Augmentation (ALA) framework that bridges analytical modeling with \ml for robust statistical prediction and uncertainty estimation in LLM inference workloads. Our method employs an analytical throughput model with parameters estimated for benchmarked workloads, then extends to unobserved configurations using \ml predictions. We enhance this with simulated annealing to exploit subsets of the workload data point combinations and develop an error predictor. Finally, we quantify uncertainty based on vector space similarity between new and observed workloads to ensure robust generalization. Through extensive experimentation on diverse LLM inference workloads, we demonstrate that our framework achieves low median errors while maintaining adaptability to new inference scenarios.
<div id='section'>Paperid: <span id='pid'>1639, <a href='https://arxiv.org/pdf/2505.08940.pdf' target='_blank'>https://arxiv.org/pdf/2505.08940.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeremie Blanchard, Lisa Casino, Jordan Gierschendorf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08940">NeurIPS 2024 Ariel Data Challenge: Characterisation of Exoplanetary Atmospheres Using a Data-Centric Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The characterization of exoplanetary atmospheres through spectral analysis is a complex challenge. The NeurIPS 2024 Ariel Data Challenge, in collaboration with the European Space Agency's (ESA) Ariel mission, provided an opportunity to explore machine learning techniques for extracting atmospheric compositions from simulated spectral data. In this work, we focus on a data-centric business approach, prioritizing generalization over competition-specific optimization. We briefly outline multiple experimental axes, including feature extraction, signal transformation, and heteroskedastic uncertainty modeling. Our experiments demonstrate that uncertainty estimation plays a crucial role in the Gaussian Log-Likelihood (GLL) score, impacting performance by several percentage points. Despite improving the GLL score by 11%, our results highlight the inherent limitations of tabular modeling and feature engineering for this task, as well as the constraints of a business-driven approach within a Kaggle-style competition framework. Our findings emphasize the trade-offs between model simplicity, interpretability, and generalization in astrophysical data analysis.
<div id='section'>Paperid: <span id='pid'>1640, <a href='https://arxiv.org/pdf/2505.08489.pdf' target='_blank'>https://arxiv.org/pdf/2505.08489.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Ulrich, Jan KrÅÃ¡vek, Roman Å enkeÅÃ­k, Zuzana KomÃ­nkovÃ¡ OplatkovÃ¡, Radek Vala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08489">Isolation Forest in Novelty Detection Scenario</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data mining offers a diverse toolbox for extracting meaningful structures from complex datasets, with anomaly detection emerging as a critical subfield particularly in the context of streaming or real-time data. Within anomaly detection, novelty detection focuses on identifying previously unseen patterns after training solely on regular data. While classic algorithms such as One-Class SVM or Local Outlier Factor (LOF) have been widely applied, they often lack interpretability and scalability. In this work, we explore the Half-Space Tree (HST) algorithm, originally proposed for streaming anomaly detection, and propose a novel theoretical modification to adapt it specifically for novelty detection tasks. Our approach is grounded in the idea that anomalies i.e., novelties tend to appear in the higher leaves of the tree, which are less frequently visited by regular instances. We analytically demonstrate the effectiveness of this approach using probabilistic analysis, expected depth (EXD) calculations, and combinatorial reasoning. A comparative analysis of expected depths between our modified HST and the original Isolation Forest highlights that novelty points are significantly more isolated in our approach. This supports the hypothesis that HSTs, with appropriate structural adaptation, can serve as interpretable and efficient novelty detectors. The paper contributes a theoretical foundation and supporting analysis for this adaptation, setting the stage for further application and experimentation.
<div id='section'>Paperid: <span id='pid'>1641, <a href='https://arxiv.org/pdf/2505.06459.pdf' target='_blank'>https://arxiv.org/pdf/2505.06459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Flores, Olga Graf, Pavlos Protopapas, Karim Pichara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06459">Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have been widely used to obtain solutions to various physical phenomena modeled as Differential Equations. As PINNs are not naturally equipped with mechanisms for Uncertainty Quantification, some work has been done to quantify the different uncertainties that arise when dealing with PINNs. In this paper, we use a two-step procedure to train Bayesian Neural Networks that provide uncertainties over the solutions to differential equation systems provided by PINNs. We use available error bounds over PINNs to formulate a heteroscedastic variance that improves the uncertainty estimation. Furthermore, we solve forward problems and utilize the obtained uncertainties when doing parameter estimation in inverse problems in cosmology.
<div id='section'>Paperid: <span id='pid'>1642, <a href='https://arxiv.org/pdf/2504.20174.pdf' target='_blank'>https://arxiv.org/pdf/2504.20174.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yashat Tavakoli, Amilcar Soares, Lourdes Pena
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20174">A Novel Multilevel Taxonomical Approach for Describing High-Dimensional Unlabeled Movement Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Movement data is prevalent across various applications and scientific fields, often characterized by its massive scale and complexity. Exploratory Data Analysis (EDA) plays a crucial role in summarizing and describing such data, enabling researchers to generate insights and support scientific hypotheses. Despite its importance, traditional EDA practices face limitations when applied to high-dimensional, unlabeled movement data. The complexity and multi-faceted nature of this type of data require more advanced methods that go beyond the capabilities of current EDA techniques. This study addresses the gap in current EDA practices by proposing a novel approach that leverages movement variable taxonomies and outlier detection. We hypothesize that organizing movement features into a taxonomy, and applying anomaly detection to combinations of taxonomic nodes, can reveal meaningful patterns and lead to more interpretable descriptions of the data. To test this hypothesis, we introduce TUMD, a new method that integrates movement taxonomies with outlier detection to enhance data analysis and interpretation. TUMD was evaluated across four diverse datasets of moving objects using fixed parameter values. Its effectiveness was assessed through two passes: the first pass categorized the majority of movement patterns as Kinematic, Geometric, or Hybrid for all datasets, while the second pass refined these behaviors into more specific categories such as Speed, Acceleration, or Indentation. TUMD met the effectiveness criteria in three datasets, demonstrating its ability to describe and refine movement behaviors. The results confirmed our hypothesis, showing that the combination of movement taxonomies and anomaly detection successfully uncovers meaningful and interpretable patterns within high-dimensional, unlabeled movement data.
<div id='section'>Paperid: <span id='pid'>1643, <a href='https://arxiv.org/pdf/2504.12718.pdf' target='_blank'>https://arxiv.org/pdf/2504.12718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Walid Rehamnia, Alexandra Getmanskaya, Evgeniy Vasilyev, Vadim Turlapov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12718">TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole Slide Images of Histology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Digital pathology, augmented by artificial intelligence (AI), holds significant promise for improving the workflow of pathologists. However, challenges such as the labor-intensive annotation of whole slide images (WSIs), high computational demands, and trust concerns arising from the absence of uncertainty estimation in predictions hinder the practical application of current AI methodologies in histopathology. To address these issues, we present a novel trustful fully unsupervised multi-level segmentation methodology (TUMLS) for WSIs. TUMLS adopts an autoencoder (AE) as a feature extractor to identify the different tissue types within low-resolution training data. It selects representative patches from each identified group based on an uncertainty measure and then does unsupervised nuclei segmentation in their respective higher-resolution space without using any ML algorithms. Crucially, this solution integrates seamlessly into clinicians workflows, transforming the examination of a whole WSI into a review of concise, interpretable cross-level insights. This integration significantly enhances and accelerates the workflow while ensuring transparency. We evaluated our approach using the UPENN-GBM dataset, where the AE achieved a mean squared error (MSE) of 0.0016. Additionally, nucleus segmentation is assessed on the MoNuSeg dataset, outperforming all unsupervised approaches with an F1 score of 77.46% and a Jaccard score of 63.35%. These results demonstrate the efficacy of TUMLS in advancing the field of digital pathology.
<div id='section'>Paperid: <span id='pid'>1644, <a href='https://arxiv.org/pdf/2504.07370.pdf' target='_blank'>https://arxiv.org/pdf/2504.07370.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenyu Han, Corentin Dumery
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07370">View-Dependent Uncertainty Estimation of 3D Gaussian Splatting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>3D Gaussian Splatting (3DGS) has become increasingly popular in 3D scene reconstruction for its high visual accuracy. However, uncertainty estimation of 3DGS scenes remains underexplored and is crucial to downstream tasks such as asset extraction and scene completion. Since the appearance of 3D gaussians is view-dependent, the color of a gaussian can thus be certain from an angle and uncertain from another. We thus propose to model uncertainty in 3DGS as an additional view-dependent per-gaussian feature that can be modeled with spherical harmonics. This simple yet effective modeling is easily interpretable and can be integrated into the traditional 3DGS pipeline. It is also significantly faster than ensemble methods while maintaining high accuracy, as demonstrated in our experiments.
<div id='section'>Paperid: <span id='pid'>1645, <a href='https://arxiv.org/pdf/2503.15953.pdf' target='_blank'>https://arxiv.org/pdf/2503.15953.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammed Attaoui, Fabrizio Pastore
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15953">GAN-enhanced Simulation-driven DNN Testing in Absence of Ground Truth</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The generation of synthetic inputs via simulators driven by search algorithms is essential for cost-effective testing of Deep Neural Network (DNN) components for safety-critical systems. However, in many applications, simulators are unable to produce the ground-truth data needed for automated test oracles and to guide the search process.
  To tackle this issue, we propose an approach for the generation of inputs for computer vision DNNs that integrates a generative network to ensure simulator fidelity and employs heuristic-based search fitnesses that leverage transformation consistency, noise resistance, surprise adequacy, and uncertainty estimation. We compare the performance of our fitnesses with that of a traditional fitness function leveraging ground truth; further, we assess how the integration of a GAN not leveraging the ground truth impacts on test and retraining effectiveness.
  Our results suggest that leveraging transformation consistency is the best option to generate inputs for both DNN testing and retraining; it maximizes input diversity, spots the inputs leading to worse DNN performance, and leads to best DNN performance after retraining. Besides enabling simulator-based testing in the absence of ground truth, our findings pave the way for testing solutions that replace costly simulators with diffusion and large language models, which might be more affordable than simulators, but cannot generate ground-truth data.
<div id='section'>Paperid: <span id='pid'>1646, <a href='https://arxiv.org/pdf/2503.07119.pdf' target='_blank'>https://arxiv.org/pdf/2503.07119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danil Kuzin, Olga Isupova, Steven Reece, Brooke D Simmons
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07119">Improving Deep Ensembles by Estimating Confusion Matrices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensembling in deep learning improves accuracy and calibration over single networks. The traditional aggregation approach, ensemble averaging, treats all individual networks equally by averaging their outputs. Inspired by crowdsourcing we propose an aggregation method called soft Dawid Skene for deep ensembles that estimates confusion matrices of ensemble members and weighs them according to their inferred performance. Soft Dawid Skene aggregates soft labels in contrast to hard labels often used in crowdsourcing. We empirically show the superiority of soft Dawid Skene in accuracy, calibration and out of distribution detection in comparison to ensemble averaging in extensive experiments.
<div id='section'>Paperid: <span id='pid'>1647, <a href='https://arxiv.org/pdf/2503.05757.pdf' target='_blank'>https://arxiv.org/pdf/2503.05757.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prasenjit Dey, Srujana Merugu, Sivaramakrishnan Kaveri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05757">Uncertainty-Aware Fusion: An Ensemble Framework for Mitigating Hallucinations in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) are known to hallucinate and generate non-factual outputs which can undermine user trust. Traditional methods to directly mitigate hallucinations, such as representation editing and contrastive decoding, often require additional training data and involve high implementation complexity. While ensemble-based approaches harness multiple LLMs to tap into the "wisdom of crowds", these methods overlook uncertainties in individual model responses. Recent studies reveal that uncertainty estimation can enable LLMs to self-assess the likelihood of generating hallucinations. In this work, we focus on factoid question answering (QA) and observe that LLMs accuracy and self-assessment capabilities vary widely with different models excelling in different scenarios. Leveraging this insight, we propose Uncertainty-Aware Fusion (UAF), an ensemble framework to reduces hallucinations by strategically combining multiple LLM based on their accuracy and self-assessment abilities. Empirical results on several public benchmark datasets show that UAF outperforms state-of-the-art hallucination mitigation methods by $8\%$ in factual accuracy, while either narrowing or surpassing the performance gap with GPT-4.
<div id='section'>Paperid: <span id='pid'>1648, <a href='https://arxiv.org/pdf/2502.18122.pdf' target='_blank'>https://arxiv.org/pdf/2502.18122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>B. Sun, P. LiÃ²
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18122">EU-Nets: Enhanced, Explainable and Parsimonious U-Nets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we propose MHEX+, a framework adaptable to any U-Net architecture. Built upon MHEX+, we introduce novel U-Net variants, EU-Nets, which enhance explainability and uncertainty estimation, addressing the limitations of traditional U-Net models while improving performance and stability. A key innovation is the Equivalent Convolutional Kernel, which unifies consecutive convolutional layers, boosting interpretability. For uncertainty estimation, we propose the collaboration gradient approach, measuring gradient consistency across decoder layers. Notably, EU-Nets achieve an average accuracy improvement of 1.389\% and a variance reduction of 0.83\% across all networks and datasets in our experiments, requiring fewer than 0.1M parameters.
<div id='section'>Paperid: <span id='pid'>1649, <a href='https://arxiv.org/pdf/2502.16124.pdf' target='_blank'>https://arxiv.org/pdf/2502.16124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditi De, NeuroBits Labs
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16124">ZIA: A Theoretical Framework for Zero-Input AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Zero-Input AI (ZIA) introduces a novel framework for human-computer interaction by enabling proactive intent prediction without explicit user commands. It integrates gaze tracking, bio-signals (EEG, heart rate), and contextual data (time, location, usage history) into a multi-modal model for real-time inference, targeting <100 ms latency. The proposed architecture employs a transformer-based model with cross-modal attention, variational Bayesian inference for uncertainty estimation, and reinforcement learning for adaptive optimization. To support deployment on edge devices (CPUs, TPUs, NPUs), ZIA utilizes quantization, weight pruning, and linear attention to reduce complexity from quadratic to linear with sequence length. Theoretical analysis establishes an information-theoretic bound on prediction error and demonstrates how multi-modal fusion improves accuracy over single-modal approaches. Expected performance suggests 85-90% accuracy with EEG integration and 60-100 ms inference latency. ZIA provides a scalable, privacy-preserving framework for accessibility, healthcare, and consumer applications, advancing AI toward anticipatory intelligence.
<div id='section'>Paperid: <span id='pid'>1650, <a href='https://arxiv.org/pdf/2502.11620.pdf' target='_blank'>https://arxiv.org/pdf/2502.11620.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arindam Sharma, Cristina David
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11620">Assessing Correctness in LLM-Based Code Generation via Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we explore uncertainty estimation as a proxy for correctness in LLM-generated code. To this end, we adapt two state-of-the-art techniques from natural language generation -- one based on entropy and another on mutual information -- to the domain of code generation. Given the distinct semantic properties of code, we introduce modifications, including a semantic equivalence check based on symbolic execution. Our findings indicate a strong correlation between the uncertainty computed through these techniques and correctness, highlighting the potential of uncertainty estimation for quality assessment. Additionally, we propose a simplified version of the entropy-based method that assumes a uniform distribution over the LLM's responses, demonstrating comparable effectiveness. Using these techniques, we develop an abstention policy that prevents the model from making predictions when uncertainty is high, reducing incorrect outputs to near zero. Our evaluation on the LiveCodeBench shows that our approach significantly outperforms a baseline relying solely on LLM-reported log-probabilities.
<div id='section'>Paperid: <span id='pid'>1651, <a href='https://arxiv.org/pdf/2502.08593.pdf' target='_blank'>https://arxiv.org/pdf/2502.08593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aram Ebtekar, Yuhao Wang, Dominik Janzing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08593">Toward Universal Laws of Outlier Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When a variety of anomalous features motivate flagging different samples as outliers, Algorithmic Information Theory (AIT) offers a principled way to unify them in terms of a sample's randomness deficiency. Subject to the algorithmic Markov condition on a causal Bayesian network, we show that the randomness deficiency of a joint sample decomposes into a sum of randomness deficiencies at each causal mechanism. Consequently, anomalous observations can be attributed to their root causes, i.e., the mechanisms that behaved anomalously. As an extension of Levin's law of randomness conservation, we show that weak outliers cannot cause strong ones. We show how these information theoretic laws clarify our understanding of outlier detection and attribution, in the context of more specialized outlier scores from prior literature.
<div id='section'>Paperid: <span id='pid'>1652, <a href='https://arxiv.org/pdf/2502.01335.pdf' target='_blank'>https://arxiv.org/pdf/2502.01335.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Costin F. Ciusdel, Alex Serban, Tiziano Passerini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01335">ConceptVAE: Self-Supervised Fine-Grained Concept Disentanglement from 2D Echocardiographies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While traditional self-supervised learning methods improve performance and robustness across various medical tasks, they rely on single-vector embeddings that may not capture fine-grained concepts such as anatomical structures or organs. The ability to identify such concepts and their characteristics without supervision has the potential to improve pre-training methods, and enable novel applications such as fine-grained image retrieval and concept-based outlier detection. In this paper, we introduce ConceptVAE, a novel pre-training framework that detects and disentangles fine-grained concepts from their style characteristics in a self-supervised manner. We present a suite of loss terms and model architecture primitives designed to discretise input data into a preset number of concepts along with their local style. We validate ConceptVAE both qualitatively and quantitatively, demonstrating its ability to detect fine-grained anatomical structures such as blood pools and septum walls from 2D cardiac echocardiographies. Quantitatively, ConceptVAE outperforms traditional self-supervised methods in tasks such as region-based instance retrieval, semantic segmentation, out-of-distribution detection, and object detection. Additionally, we explore the generation of in-distribution synthetic data that maintains the same concepts as the training data but with distinct styles, highlighting its potential for more calibrated data generation. Overall, our study introduces and validates a promising new pre-training technique based on concept-style disentanglement, opening multiple avenues for developing models for medical image analysis that are more interpretable and explainable than black-box approaches.
<div id='section'>Paperid: <span id='pid'>1653, <a href='https://arxiv.org/pdf/2501.16718.pdf' target='_blank'>https://arxiv.org/pdf/2501.16718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hengzhuang Li, Teng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16718">Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is crucial for developing trustworthy and reliable machine learning systems. Recent advances in training with auxiliary OOD data demonstrate efficacy in enhancing detection capabilities. Nonetheless, these methods heavily rely on acquiring a large pool of high-quality natural outliers. Some prior methods try to alleviate this problem by synthesizing virtual outliers but suffer from either poor quality or high cost due to the monotonous sampling strategy and the heavy-parameterized generative models. In this paper, we overcome all these problems by proposing the Hamiltonian Monte Carlo Outlier Synthesis (HamOS) framework, which views the synthesis process as sampling from Markov chains. Based solely on the in-distribution data, the Markov chains can extensively traverse the feature space and generate diverse and representative outliers, hence exposing the model to miscellaneous potential OOD scenarios. The Hamiltonian Monte Carlo with sampling acceptance rate almost close to 1 also makes our framework enjoy great efficiency. By empirically competing with SOTA baselines on both standard and large-scale benchmarks, we verify the efficacy and efficiency of our proposed HamOS.
<div id='section'>Paperid: <span id='pid'>1654, <a href='https://arxiv.org/pdf/2501.12204.pdf' target='_blank'>https://arxiv.org/pdf/2501.12204.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edward T. Reehorst, Philip Schniter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12204">Score Combining for Contrastive OOD Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In out-of-distribution (OOD) detection, one is asked to classify whether a test sample comes from a known inlier distribution or not. We focus on the case where the inlier distribution is defined by a training dataset and there exists no additional knowledge about the novelties that one is likely to encounter. This problem is also referred to as novelty detection, one-class classification, and unsupervised anomaly detection. The current literature suggests that contrastive learning techniques are state-of-the-art for OOD detection. We aim to improve on those techniques by combining/ensembling their scores using the framework of null hypothesis testing and, in particular, a novel generalized likelihood ratio test (GLRT). We demonstrate that our proposed GLRT-based technique outperforms the state-of-the-art CSI and SupCSI techniques from Tack et al. 2020 in dataset-vs-dataset experiments with CIFAR-10, SVHN, LSUN, ImageNet, and CIFAR-100, as well as leave-one-class-out experiments with CIFAR-10. We also demonstrate that our GLRT outperforms the score-combining methods of Fisher, Bonferroni, Simes, Benjamini-Hochwald, and Stouffer in our application.
<div id='section'>Paperid: <span id='pid'>1655, <a href='https://arxiv.org/pdf/2501.12178.pdf' target='_blank'>https://arxiv.org/pdf/2501.12178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maxime Di Folco, Gabriel Bernardino, Patrick Clarysse, Nicolas Duchateau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12178">High-dimensional multimodal uncertainty estimation by manifold alignment:Application to 3D right ventricular strain computations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Confidence in the results is a key ingredient to improve the adoption of machine learning methods by clinicians. Uncertainties on the results have been considered in the literature, but mostly those originating from the learning and processing methods. Uncertainty on the data is hardly challenged, as a single sample is often considered representative enough of each subject included in the analysis. In this paper, we propose a representation learning strategy to estimate local uncertainties on a physiological descriptor (here, myocardial deformation) previously obtained from medical images by different definitions or computations. We first use manifold alignment to match the latent representations associated to different high-dimensional input descriptors. Then, we formulate plausible distributions of latent uncertainties, and finally exploit them to reconstruct uncertainties on the input high-dimensional descriptors. We demonstrate its relevance for the quantification of myocardial deformation (strain) from 3D echocardiographic image sequences of the right ventricle, for which a lack of consensus exists in its definition and which directional component to use. We used a database of 100 control subjects with right ventricle overload, for which different types of strain are available at each point of the right ventricle endocardial surface mesh. Our approach quantifies local uncertainties on myocardial deformation from different descriptors defining this physiological concept. Such uncertainties cannot be directly estimated by local statistics on such descriptors, potentially of heterogeneous types. Beyond this controlled illustrative application, our methodology has the potential to be generalized to many other population analyses considering heterogeneous high-dimensional descriptors.
<div id='section'>Paperid: <span id='pid'>1656, <a href='https://arxiv.org/pdf/2501.11638.pdf' target='_blank'>https://arxiv.org/pdf/2501.11638.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>F. S. Pezzicoli, V. Ros, F. P. Landes, M. Baity-Jesi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11638">Class Imbalance in Anomaly Detection: Learning from an Exactly Solvable Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Class imbalance (CI) is a longstanding problem in machine learning, slowing down training and reducing performances. Although empirical remedies exist, it is often unclear which ones work best and when, due to the lack of an overarching theory. We address a common case of imbalance, that of anomaly (or outlier) detection. We provide a theoretical framework to analyze, interpret and address CI. It is based on an exact solution of the teacher-student perceptron model, through replica theory. Within this framework, one can distinguish several sources of CI: either intrinsic, train or test imbalance. Our analysis reveals that the optimal train imbalance is generally different from 50%, with a non trivial dependence on the intrinsic imbalance, the abundance of data and on the noise in the learning. Moreover, there is a crossover between a small noise training regime where results are independent of the noise level to a high noise regime where performances quickly degrade with noise. Our results challenge some of the conventional wisdom on CI and offer practical guidelines to address it.
<div id='section'>Paperid: <span id='pid'>1657, <a href='https://arxiv.org/pdf/2501.11054.pdf' target='_blank'>https://arxiv.org/pdf/2501.11054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohit Mapakshi, Sayma Akther, Mark Stamp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11054">Temporal Analysis of Adversarial Attacks in Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we experimentally analyze the robustness of selected Federated Learning (FL) systems in the presence of adversarial clients. We find that temporal attacks significantly affect model performance in the FL models tested, especially when the adversaries are active throughout or during the later rounds. We consider a variety of classic learning models, including Multinominal Logistic Regression (MLR), Random Forest, XGBoost, Support Vector Classifier (SVC), as well as various Neural Network models including Multilayer Perceptron (MLP), Convolution Neural Network (CNN), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM). Our results highlight the effectiveness of temporal attacks and the need to develop strategies to make the FL process more robust against such attacks. We also briefly consider the effectiveness of defense mechanisms, including outlier detection in the aggregation algorithm.
<div id='section'>Paperid: <span id='pid'>1658, <a href='https://arxiv.org/pdf/2501.10920.pdf' target='_blank'>https://arxiv.org/pdf/2501.10920.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Konrad Sundsgaard, Kutay BÃ¶lat, Guangya Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.10920">Data Enrichment Opportunities for Distribution Grid Cable Networks using Variational Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electricity distribution cable networks suffer from incomplete and unbalanced data, hindering the effectiveness of machine learning models for predictive maintenance and reliability evaluation. Features such as the installation date of the cables are frequently missing. To address data scarcity, this study investigates the application of Variational Autoencoders (VAEs) for data enrichment, synthetic data generation, imbalanced data handling, and outlier detection. Based on a proof-of-concept case study for Denmark, targeting the imputation of missing age information in cable network asset registers, the analysis underlines the potential of generative models to support data-driven maintenance. However, the study also highlights several areas for improvement, including enhanced feature importance analysis, incorporating network characteristics and external features, and handling biases in missing data. Future initiatives should expand the application of VAEs by incorporating semi-supervised learning, advanced sampling techniques, and additional distribution grid elements, including low-voltage networks, into the analysis.
<div id='section'>Paperid: <span id='pid'>1659, <a href='https://arxiv.org/pdf/2501.05809.pdf' target='_blank'>https://arxiv.org/pdf/2501.05809.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fuhang Liang, Rucong Xu, Deng Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05809">AdaPRL: Adaptive Pairwise Regression Learning with Uncertainty Estimation for Universal Regression Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current deep regression models usually learn in a point-wise way that treats each sample as an independent input, neglecting the relative ordering among different data. Consequently, the regression model could neglect the data's interrelationships, potentially resulting in suboptimal performance. Moreover, the existence of aleatoric uncertainty in the training data may drive the model to capture non-generalizable patterns, contributing to increased overfitting. To address these issues, we propose a novel adaptive pairwise learning framework for regression tasks (AdaPRL) which leverages the relative differences between data points and integrates with deep probabilistic models to quantify the uncertainty associated with the predictions. Additionally, we adapt AdaPRL for applications in multi-task learning and multivariate time series forecasting. Extensive experiments with several real-world regression datasets including recommendation systems, age prediction, time series forecasting, natural language understanding, finance, and industry datasets show that AdaPRL is compatible with different backbone networks in various tasks and achieves state-of-the-art performance on the vast majority of tasks without extra inference cost, highlighting its notable potential including enhancing prediction accuracy and ranking ability, increasing generalization capability, improving robustness to noisy data, improving resilience to reduced data, and enhancing interpretability. Experiments also show that AdaPRL can be seamlessly incorporated into recently proposed regression frameworks to gain performance improvement.
<div id='section'>Paperid: <span id='pid'>1660, <a href='https://arxiv.org/pdf/2501.05228.pdf' target='_blank'>https://arxiv.org/pdf/2501.05228.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Kang Lee, Jun-Cheng Chen, Ja-Ling Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05228">Harnessing Large Language and Vision-Language Models for Robust Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection has seen significant advancements with zero-shot approaches by leveraging the powerful Vision-Language Models (VLMs) such as CLIP. However, prior research works have predominantly focused on enhancing Far-OOD performance, while potentially compromising Near-OOD efficacy, as observed from our pilot study. To address this issue, we propose a novel strategy to enhance zero-shot OOD detection performances for both Far-OOD and Near-OOD scenarios by innovatively harnessing Large Language Models (LLMs) and VLMs. Our approach first exploit an LLM to generate superclasses of the ID labels and their corresponding background descriptions followed by feature extraction using CLIP. We then isolate the core semantic features for ID data by subtracting background features from the superclass features. The refined representation facilitates the selection of more appropriate negative labels for OOD data from a comprehensive candidate label set of WordNet, thereby enhancing the performance of zero-shot OOD detection in both scenarios. Furthermore, we introduce novel few-shot prompt tuning and visual prompt tuning to adapt the proposed framework to better align with the target distribution. Experimental results demonstrate that the proposed approach consistently outperforms current state-of-the-art methods across multiple benchmarks, with an improvement of up to 2.9% in AUROC and a reduction of up to 12.6% in FPR95. Additionally, our method exhibits superior robustness against covariate shift across different domains, further highlighting its effectiveness in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>1661, <a href='https://arxiv.org/pdf/2501.03402.pdf' target='_blank'>https://arxiv.org/pdf/2501.03402.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Louis L Chen, Roberto Szechtman, Matan Seri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03402">On the Adversarial Robustness of Benjamini Hochberg</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Benjamini-Hochberg (BH) procedure is widely used to control the false detection rate (FDR) in multiple testing. Applications of this control abound in drug discovery, forensics, anomaly detection, and, in particular, machine learning, ranging from nonparametric outlier detection to out-of-distribution detection and one-class classification methods. Considering this control could be relied upon in critical safety/security contexts, we investigate its adversarial robustness. More precisely, we study under what conditions BH does and does not exhibit adversarial robustness, we present a class of simple and easily implementable adversarial test-perturbation algorithms, and we perform computational experiments. With our algorithms, we demonstrate that there are conditions under which BH's control can be significantly broken with relatively few (even just one) test score perturbation(s), and provide non-asymptotic guarantees on the expected adversarial-adjustment to FDR. Our technical analysis involves a combinatorial reframing of the BH procedure as a ``balls into bins'' process, and drawing a connection to generalized ballot problems to facilitate an information-theoretic approach for deriving non-asymptotic lower bounds.
<div id='section'>Paperid: <span id='pid'>1662, <a href='https://arxiv.org/pdf/2501.01061.pdf' target='_blank'>https://arxiv.org/pdf/2501.01061.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Hu, Luc, Chen, Yiwei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01061">An Efficient Outlier Detection Algorithm for Data Streaming</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The nature of modern data is increasingly real-time, making outlier detection crucial in any data-related field, such as finance for fraud detection and healthcare for monitoring patient vitals. Traditional outlier detection methods, such as the Local Outlier Factor (LOF) algorithm, struggle with real-time data due to the need for extensive recalculations with each new data point, limiting their application in real-time environments. While the Incremental LOF (ILOF) algorithm has been developed to tackle the challenges of online anomaly detection, it remains computationally expensive when processing large streams of data points, and its detection performance may degrade after a certain threshold of points have streamed in. In this paper, we propose a novel approach to enhance the efficiency of LOF algorithms for online anomaly detection, named the Efficient Incremental LOF (EILOF) algorithm. The EILOF algorithm only computes the LOF scores of new points without altering the LOF scores of existing data points. Although exact LOF scores have not yet been computed for the existing points in the new algorithm, datasets often contain noise, and minor deviations in LOF score calculations do not necessarily degrade detection performance. In fact, such deviations can sometimes enhance outlier detection. We systematically tested this approach on both simulated and real-world datasets, demonstrating that EILOF outperforms ILOF as the volume of streaming data increases across various scenarios. The EILOF algorithm not only significantly reduces computational costs, but also systematically improves detection accuracy when the number of additional points increases compared to the ILOF algorithm.
<div id='section'>Paperid: <span id='pid'>1663, <a href='https://arxiv.org/pdf/2412.20586.pdf' target='_blank'>https://arxiv.org/pdf/2412.20586.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufei Wu, Stefan Radev, Francis Tuerlinckx
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20586">Testing and Improving the Robustness of Amortized Bayesian Inference for Cognitive Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contaminant observations and outliers often cause problems when estimating the parameters of cognitive models, which are statistical models representing cognitive processes. In this study, we test and improve the robustness of parameter estimation using amortized Bayesian inference (ABI) with neural networks. To this end, we conduct systematic analyses on a toy example and analyze both synthetic and real data using a popular cognitive model, the Drift Diffusion Models (DDM). First, we study the sensitivity of ABI to contaminants with tools from robust statistics: the empirical influence function and the breakdown point. Next, we propose a data augmentation or noise injection approach that incorporates a contamination distribution into the data-generating process during training. We examine several candidate distributions and evaluate their performance and cost in terms of accuracy and efficiency loss relative to a standard estimator. Introducing contaminants from a Cauchy distribution during training considerably increases the robustness of the neural density estimator as measured by bounded influence functions and a much higher breakdown point. Overall, the proposed method is straightforward and practical to implement and has a broad applicability in fields where outlier detection or removal is challenging.
<div id='section'>Paperid: <span id='pid'>1664, <a href='https://arxiv.org/pdf/2412.05010.pdf' target='_blank'>https://arxiv.org/pdf/2412.05010.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>ZeinabSadat Taghavi, Hossein Mirzaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05010">Backdooring Outlier Detection Methods: A Novel Attack Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There have been several efforts in backdoor attacks, but these have primarily focused on the closed-set performance of classifiers (i.e., classification). This has left a gap in addressing the threat to classifiers' open-set performance, referred to as outlier detection in the literature. Reliable outlier detection is crucial for deploying classifiers in critical real-world applications such as autonomous driving and medical image analysis. First, we show that existing backdoor attacks fall short in affecting the open-set performance of classifiers, as they have been specifically designed to confuse intra-closed-set decision boundaries. In contrast, an effective backdoor attack for outlier detection needs to confuse the decision boundary between the closed and open sets. Motivated by this, in this study, we propose BATOD, a novel Backdoor Attack targeting the Outlier Detection task. Specifically, we design two categories of triggers to shift inlier samples to outliers and vice versa. We evaluate BATOD using various real-world datasets and demonstrate its superior ability to degrade the open-set performance of classifiers compared to previous attacks, both before and after applying defenses.
<div id='section'>Paperid: <span id='pid'>1665, <a href='https://arxiv.org/pdf/2412.01193.pdf' target='_blank'>https://arxiv.org/pdf/2412.01193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnav Kharbanda, Advait Chandorkar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01193">Divergent Ensemble Networks: Enhancing Uncertainty Estimation with Shared Representations and Independent Branching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensemble learning has proven effective in improving predictive performance and estimating uncertainty in neural networks. However, conventional ensemble methods often suffer from redundant parameter usage and computational inefficiencies due to entirely independent network training. To address these challenges, we propose the Divergent Ensemble Network (DEN), a novel architecture that combines shared representation learning with independent branching. DEN employs a shared input layer to capture common features across all branches, followed by divergent, independently trainable layers that form an ensemble. This shared-to-branching structure reduces parameter redundancy while maintaining ensemble diversity, enabling efficient and scalable learning.
<div id='section'>Paperid: <span id='pid'>1666, <a href='https://arxiv.org/pdf/2412.00205.pdf' target='_blank'>https://arxiv.org/pdf/2412.00205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michele De Vita, Vasileios Belagiannis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00205">Diffusion Model Guided Sampling with Pixel-Wise Aleatoric Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the remarkable progress in generative modelling, current diffusion models lack a quantitative approach to assess image quality. To address this limitation, we propose to estimate the pixel-wise aleatoric uncertainty during the sampling phase of diffusion models and utilise the uncertainty to improve the sample generation quality. The uncertainty is computed as the variance of the denoising scores with a perturbation scheme that is specifically designed for diffusion models. We then show that the aleatoric uncertainty estimates are related to the second-order derivative of the diffusion noise distribution. We evaluate our uncertainty estimation algorithm and the uncertainty-guided sampling on the ImageNet and CIFAR-10 datasets. In our comparisons with the related work, we demonstrate promising results in filtering out low quality samples. Furthermore, we show that our guided approach leads to better sample generation in terms of FID scores.
<div id='section'>Paperid: <span id='pid'>1667, <a href='https://arxiv.org/pdf/2411.16427.pdf' target='_blank'>https://arxiv.org/pdf/2411.16427.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Somjit Nath, Yik Chau Lui, Siqi Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16427">Unsupervised Event Outlier Detection in Continuous Time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Event sequence data record the occurrences of events in continuous time. Event sequence forecasting based on temporal point processes (TPPs) has been extensively studied, but outlier or anomaly detection, especially without any supervision from humans, is still underexplored. In this work, we develop, to the best our knowledge, the first unsupervised outlier detection approach to detecting abnormal events. Our novel unsupervised outlier detection framework is based on ideas from generative adversarial networks (GANs) and reinforcement learning (RL). We train a 'generator' that corrects outliers in the data with a 'discriminator' that learns to discriminate the corrected data from the real data, which may contain outliers. A key insight is that if the generator made a mistake in the correction, it would generate anomalies that are different from the anomalies in the real data, so it serves as data augmentation for the discriminator learning. Different from typical GAN-based outlier detection approaches, our method employs the generator to detect outliers in an online manner. The experimental results show that our method can detect event outliers more accurately than the state-of-the-art approaches.
<div id='section'>Paperid: <span id='pid'>1668, <a href='https://arxiv.org/pdf/2411.16370.pdf' target='_blank'>https://arxiv.org/pdf/2411.16370.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. M. A. Valiuddin, R. J. G. van Sloun, C. G. A. Viviers, P. H. N. de With, F. van der Sommen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16370">A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in architectural design, data availability, and compute have driven remarkable progress in semantic segmentation. Yet, these models often rely on relaxed Bayesian assumptions, omitting critical uncertainty information needed for robust decision-making. The resulting reliance on point estimates has fueled interest in probabilistic segmentation, but the literature remains fragmented. In response, this review consolidates and contextualizes foundational concepts in uncertainty modeling, including the non-trivial task of distinguishing between epistemic and aleatoric uncertainty and examining their roles across four key downstream segmentation tasks, highlighting Active Learning as particularly promising. By unifying theory, terminology, and applications, we provide a coherent foundation for researchers and identify critical challenges, such as strong assumptions in spatial aggregation, lack of standardized benchmarks, and pitfalls in current uncertainty quantification methods. We identify trends such as the adoption of contemporary generative models, driven by advances in the broader field of generative modeling, with segmentation-specific innovation primarily in the conditioning mechanisms. Moreover, we observe growing interest in distribution- and sampling-free approaches to uncertainty estimation. We further propose directions for advancing uncertainty-aware segmentation in deep learning, including pragmatic strategies for disentangling different sources of uncertainty, novel uncertainty modeling approaches and improved Transformer-based backbones. In this way, we aim to support the development of more reliable, efficient, and interpretable segmentation models that effectively incorporate uncertainty into real-world applications.
<div id='section'>Paperid: <span id='pid'>1669, <a href='https://arxiv.org/pdf/2411.15944.pdf' target='_blank'>https://arxiv.org/pdf/2411.15944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinzhe Cao, Yadong Xu, Xiaofeng Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15944">Customer Lifetime Value Prediction with Uncertainty Estimation Using Monte Carlo Dropout</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting customer Lifetime Value (LTV) is crucial for companies to optimize their revenue strategies. Traditional deep learning models for LTV prediction are effective but typically provide only point estimates and fail to capture model uncertainty in modeling user behaviors. To address this limitation, we propose a novel approach that enhances the architecture of purely neural network models by incorporating the Monte Carlo Dropout (MCD) framework. We benchmarked the proposed method using data from one of the most downloaded mobile games in the world, and demonstrated a substantial improvement in predictive Top 5\% Mean Absolute Percentage Error compared to existing state-of-the-art methods. Additionally, our approach provides confidence metric as an extra dimension for performance evaluation across various neural network models, facilitating more informed business decisions.
<div id='section'>Paperid: <span id='pid'>1670, <a href='https://arxiv.org/pdf/2411.14457.pdf' target='_blank'>https://arxiv.org/pdf/2411.14457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maryam Shoaeinaeini, Brent Harrison
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14457">Guiding Reinforcement Learning Using Uncertainty-Aware Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human guidance in reinforcement learning (RL) is often impractical for large-scale applications due to high costs and time constraints. Large Language Models (LLMs) offer a promising alternative to mitigate RL sample inefficiency and potentially replace human trainers. However, applying LLMs as RL trainers is challenging due to their overconfidence and less reliable solutions in sequential tasks. We address this limitation by introducing a calibrated guidance system that uses Monte Carlo Dropout to enhance LLM advice reliability by assessing prediction variances from multiple forward passes. Additionally, we develop a novel RL policy shaping method based on dynamic model average entropy to adjust the LLM's influence on RL policies according to guidance uncertainty. This approach ensures robust RL training by relying on reliable LLM guidance. To validate our contributions, we conduct extensive experiments in a Minigrid environment with three goals in varying environment sizes. The results showcase superior model performance compared to uncalibrated LLMs, unguided RL, and calibrated LLMs with different shaping policies. Moreover, we analyze various uncertainty estimation methods, demonstrating the effectiveness of average entropy in reflecting higher uncertainty in incorrect guidance. These findings highlight the persistent overconfidence in fine-tuned LLMs and underscore the importance of effective calibration in sequential decision-making problems.
<div id='section'>Paperid: <span id='pid'>1671, <a href='https://arxiv.org/pdf/2411.12102.pdf' target='_blank'>https://arxiv.org/pdf/2411.12102.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Richard Kurle, Alexej Klushyn, Ralf Herbrich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.12102">BALI: Learning Neural Networks via Bayesian Layerwise Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a new method for learning Bayesian neural networks, treating them as a stack of multivariate Bayesian linear regression models. The main idea is to infer the layerwise posterior exactly if we know the target outputs of each layer. We define these pseudo-targets as the layer outputs from the forward pass, updated by the backpropagated gradients of the objective function. The resulting layerwise posterior is a matrix-normal distribution with a Kronecker-factorized covariance matrix, which can be efficiently inverted. Our method extends to the stochastic mini-batch setting using an exponential moving average over natural-parameter terms, thus gradually forgetting older data. The method converges in few iterations and performs as well as or better than leading Bayesian neural network methods on various regression, classification, and out-of-distribution detection benchmarks.
<div id='section'>Paperid: <span id='pid'>1672, <a href='https://arxiv.org/pdf/2411.08867.pdf' target='_blank'>https://arxiv.org/pdf/2411.08867.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kushankur Ghosh, Murilo Coelho Naldi, JÃ¶rg Sander, Euijin Choo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08867">Unsupervised Parameter-free Outlier Detection using HDBSCAN* Outlier Profiles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In machine learning and data mining, outliers are data points that significantly differ from the dataset and often introduce irrelevant information that can induce bias in its statistics and models. Therefore, unsupervised methods are crucial to detect outliers if there is limited or no information about them. Global-Local Outlier Scores based on Hierarchies (GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a state-of-the-art hierarchical clustering method. GLOSH estimates outlier scores for each data point by comparing its density to the highest density of the region they reside in the HDBSCAN* hierarchy. GLOSH may be sensitive to HDBSCAN*'s minpts parameter that influences density estimation. With limited knowledge about the data, choosing an appropriate minpts value beforehand is challenging as one or some minpts values may better represent the underlying cluster structure than others. Additionally, in the process of searching for ``potential outliers'', one has to define the number of outliers n a dataset has, which may be impractical and is often unknown. In this paper, we propose an unsupervised strategy to find the ``best'' minpts value, leveraging the range of GLOSH scores across minpts values to identify the value for which GLOSH scores can best identify outliers from the rest of the dataset. Moreover, we propose an unsupervised strategy to estimate a threshold for classifying points into inliers and (potential) outliers without the need to pre-define any value. Our experiments show that our strategies can automatically find the minpts value and threshold that yield the best or near best outlier detection results using GLOSH.
<div id='section'>Paperid: <span id='pid'>1673, <a href='https://arxiv.org/pdf/2411.03082.pdf' target='_blank'>https://arxiv.org/pdf/2411.03082.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Irum Mehboob, Li Sun, Alireza Astegarpanah, Rustam Stolkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.03082">Self-supervised cross-modality learning for uncertainty-aware object detection and recognition in applications which lack pre-labelled training data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper shows how an uncertainty-aware, deep neural network can be trained to detect, recognise and localise objects in 2D RGB images, in applications lacking annotated train-ng datasets. We propose a self-supervising teacher-student pipeline, in which a relatively simple teacher classifier, trained with only a few labelled 2D thumbnails, automatically processes a larger body of unlabelled RGB-D data to teach a student network based on a modified YOLOv3 architecture. Firstly, 3D object detection with back projection is used to automatically extract and teach 2D detection and localisation information to the student network. Secondly, a weakly supervised 2D thumbnail classifier, with minimal training on a small number of hand-labelled images, is used to teach object category recognition. Thirdly, we use a Gaussian Process GP to encode and teach a robust uncertainty estimation functionality, so that the student can output confidence scores with each categorization. The resulting student significantly outperforms the same YOLO architecture trained directly on the same amount of labelled data. Our GP-based approach yields robust and meaningful uncertainty estimations for complex industrial object classifications. The end-to-end network is also capable of real-time processing, needed for robotics applications. Our method can be applied to many important industrial tasks, where labelled datasets are typically unavailable. In this paper, we demonstrate an example of detection, localisation, and object category recognition of nuclear mixed-waste materials in highly cluttered and unstructured scenes. This is critical for robotic sorting and handling of legacy nuclear waste, which poses complex environmental remediation challenges in many nuclearised nations.
<div id='section'>Paperid: <span id='pid'>1674, <a href='https://arxiv.org/pdf/2411.00259.pdf' target='_blank'>https://arxiv.org/pdf/2411.00259.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Smerkous, Qinxun Bai, Fuxin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00259">Enhancing Diversity in Bayesian Deep Learning via Hyperspherical Energy Minimization of CKA</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Particle-based Bayesian deep learning often requires a similarity metric to compare two networks. However, naive similarity metrics lack permutation invariance and are inappropriate for comparing networks. Centered Kernel Alignment (CKA) on feature kernels has been proposed to compare deep networks but has not been used as an optimization objective in Bayesian deep learning. In this paper, we explore the use of CKA in Bayesian deep learning to generate diverse ensembles and hypernetworks that output a network posterior. Noting that CKA projects kernels onto a unit hypersphere and that directly optimizing the CKA objective leads to diminishing gradients when two networks are very similar. We propose adopting the approach of hyperspherical energy (HE) on top of CKA kernels to address this drawback and improve training stability. Additionally, by leveraging CKA-based feature kernels, we derive feature repulsive terms applied to synthetically generated outlier examples. Experiments on both diverse ensembles and hypernetworks show that our approach significantly outperforms baselines in terms of uncertainty quantification in both synthetic and realistic outlier detection tasks.
<div id='section'>Paperid: <span id='pid'>1675, <a href='https://arxiv.org/pdf/2410.22685.pdf' target='_blank'>https://arxiv.org/pdf/2410.22685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yashvir S. Grewal, Edwin V. Bonilla, Thang D. Bui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.22685">Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the-art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional entailment criteria between multiple generated responses and also depend on sequence likelihoods. While effective, these approaches often overestimate uncertainty due to their sensitivity to minor wording differences, additional correct information, and non-important words in the sequence. We propose a novel approach that leverages semantic embeddings to achieve smoother and more robust estimation of semantic uncertainty in LLMs. By capturing semantic similarities without depending on sequence likelihoods, our method inherently reduces any biases introduced by irrelevant words in the answers. Furthermore, we introduce an amortised version of our approach by explicitly modelling semantics as latent variables in a joint probabilistic model. This allows for uncertainty estimation in the embedding space with a single forward pass, significantly reducing computational overhead compared to existing multi-pass methods. Experiments across multiple question-answering datasets and frontier LLMs demonstrate that our embedding-based methods provide more accurate and nuanced uncertainty quantification than traditional approaches.
<div id='section'>Paperid: <span id='pid'>1676, <a href='https://arxiv.org/pdf/2410.21797.pdf' target='_blank'>https://arxiv.org/pdf/2410.21797.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seunghyeon Shin, Seokjin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21797">Representational learning for an anomalous sound detection system with source separation model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of anomalous sounds in machinery operation presents a significant challenge due to the difficulty in generalizing anomalous acoustic patterns. This task is typically approached as an unsupervised learning or novelty detection problem, given the complexities associated with the acquisition of comprehensive anomalous acoustic data. Conventional methodologies for training anomalous sound detection systems primarily employ auto-encoder architectures or representational learning with auxiliary tasks. However, both approaches have inherent limitations. Auto-encoder structures are constrained to utilizing only the target machine's operational sounds, while training with auxiliary tasks, although capable of incorporating diverse acoustic inputs, may yield representations that lack correlation with the characteristic acoustic signatures of anomalous conditions. We propose a training method based on the source separation model (CMGAN) that aims to isolate non-target machine sounds from a mixture of target and non-target class acoustic signals. This approach enables the effective utilization of diverse machine sounds and facilitates the training of complex neural network architectures with limited sample sizes. Our experimental results demonstrate that the proposed method yields better performance compared to both conventional auto-encoder training approaches and source separation techniques that focus on isolating target machine signals. Moreover, our experimental results demonstrate that the proposed method exhibits the potential for enhanced representation learning as the quantity of non-target data increases, even while maintaining a constant volume of target class data.
<div id='section'>Paperid: <span id='pid'>1677, <a href='https://arxiv.org/pdf/2410.21006.pdf' target='_blank'>https://arxiv.org/pdf/2410.21006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pau Ferrer-Cid, Jose M. Barcelo-Ordinas, Jorge Garcia-Vidal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21006">A Review of Graph-Powered Data Quality Applications for IoT Monitoring Sensor Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of Internet of Things (IoT) technologies has led to the widespread adoption of monitoring networks for a wide variety of applications, such as smart cities, environmental monitoring, and precision agriculture. A major research focus in recent years has been the development of graph-based techniques to improve the quality of data from sensor networks, a key aspect for the use of sensed data in decision-making processes, digital twins, and other applications. Emphasis has been placed on the development of machine learning and signal processing techniques over graphs, taking advantage of the benefits provided by the use of structured data through a graph topology. Many technologies such as the graph signal processing (GSP) or the successful graph neural networks (GNNs) have been used for data quality enhancement tasks. In this survey, we focus on graph-based models for data quality control in monitoring sensor networks. Furthermore, we delve into the technical details that are commonly leveraged for providing powerful graph-based solutions for data quality tasks in sensor networks, including missing value imputation, outlier detection, or virtual sensing. To conclude, we have identified future trends and challenges such as graph-based models for digital twins or model transferability and generalization.
<div id='section'>Paperid: <span id='pid'>1678, <a href='https://arxiv.org/pdf/2410.17851.pdf' target='_blank'>https://arxiv.org/pdf/2410.17851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>K. Darshana Abeyrathna, Sara El Mekkaoui, Andreas Hafver, Christian Agrell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.17851">The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tsetlin Machines (TMs) have emerged as a compelling alternative to conventional deep learning methods, offering notable advantages such as smaller memory footprint, faster inference, fault-tolerant properties, and interpretability. Although various adaptations of TMs have expanded their applicability across diverse domains, a fundamental gap remains in understanding how TMs quantify uncertainty in their predictions. In response, this paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed at providing a robust, reliable, and interpretable approach for uncertainty quantification. Unlike the original TM, the PTM learns the probability of staying on each state of each Tsetlin Automaton (TA) across all clauses. These probabilities are updated using the feedback tables that are part of the TM framework: Type I and Type II feedback. During inference, TAs decide their actions by sampling states based on learned probability distributions, akin to Bayesian neural networks when generating weight values. In our experimental analysis, we first illustrate the spread of the probabilities across TA states for the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models using both simulated and real-world datasets. The experiments on the simulated dataset reveal the PTM's effectiveness in uncertainty quantification, particularly in delineating decision boundaries and identifying regions of high uncertainty. Moreover, when applied to multiclass classification tasks using the Iris dataset, the PTM demonstrates competitive performance in terms of predictive entropy and expected calibration error, showcasing its potential as a reliable tool for uncertainty estimation. Our findings underscore the importance of selecting appropriate models for accurate uncertainty quantification in predictive tasks, with the PTM offering a particularly interpretable and effective solution.
<div id='section'>Paperid: <span id='pid'>1679, <a href='https://arxiv.org/pdf/2410.17142.pdf' target='_blank'>https://arxiv.org/pdf/2410.17142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. V. Kornilov, V. S. Korolev, K. L. Malanchev, A. D. Lavrukhina, E. Russeil, T. A. Semenikhin, E. Gangler, E. E. O. Ishida, M. V. Pruzhinskaya, A. A. Volnova, S. Sreejith
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.17142">Coniferest: a complete active anomaly detection framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present coniferest, an open source generic purpose active anomaly detection framework written in Python. The package design and implemented algorithms are described. Currently, static outlier detection analysis is supported via the Isolation forest algorithm. Moreover, Active Anomaly Discovery (AAD) and Pineforest algorithms are available to tackle active anomaly detection problems. The algorithms and package performance are evaluated on a series of synthetic datasets. We also describe a few success cases which resulted from applying the package to real astronomical data in active anomaly detection tasks within the SNAD project.
<div id='section'>Paperid: <span id='pid'>1680, <a href='https://arxiv.org/pdf/2410.12250.pdf' target='_blank'>https://arxiv.org/pdf/2410.12250.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ng Wen Zheng Terence, Chen Jianda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12250">Dual Action Policy for Robust Sim-to-Real Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents Dual Action Policy (DAP), a novel approach to address the dynamics mismatch inherent in the sim-to-real gap of reinforcement learning. DAP uses a single policy to predict two sets of actions: one for maximizing task rewards in simulation and another specifically for domain adaptation via reward adjustments. This decoupling makes it easier to maximize the overall reward in the source domain during training. Additionally, DAP incorporates uncertainty-based exploration during training to enhance agent robustness. Experimental results demonstrate DAP's effectiveness in bridging the sim-to-real gap, outperforming baselines on challenging tasks in simulation, and further improvement is achieved by incorporating uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1681, <a href='https://arxiv.org/pdf/2410.08958.pdf' target='_blank'>https://arxiv.org/pdf/2410.08958.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Salnikov, Kevin Michalewicz, Dan Leonte
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08958">Lifted Coefficient of Determination: Fast model-free prediction intervals and likelihood-free model comparison</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the $\textit{lifted linear model}$, and derive model-free prediction intervals that become tighter as the correlation between predictions and observations increases. These intervals motivate the $\textit{Lifted Coefficient of Determination}$, a model comparison criterion for arbitrary loss functions in prediction-based settings, e.g., regression, classification or counts. We extend the prediction intervals to more general error distributions, and propose a fast model-free outlier detection algorithm for regression. Finally, we illustrate the framework via numerical experiments.
<div id='section'>Paperid: <span id='pid'>1682, <a href='https://arxiv.org/pdf/2410.08687.pdf' target='_blank'>https://arxiv.org/pdf/2410.08687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanieh Shojaei, Qianqian Zou, Max Mehltretter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08687">Uncertainty Estimation and Out-of-Distribution Detection for LiDAR Scene Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safe navigation in new environments requires autonomous vehicles and robots to accurately interpret their surroundings, relying on LiDAR scene segmentation, out-of-distribution (OOD) obstacle detection, and uncertainty computation. We propose a method to distinguish in-distribution (ID) from OOD samples and quantify both epistemic and aleatoric uncertainties using the feature space of a single deterministic model. After training a semantic segmentation network, a Gaussian Mixture Model (GMM) is fitted to its feature space. OOD samples are detected by checking if their squared Mahalanobis distances to each Gaussian component conform to a chi-squared distribution, eliminating the need for an additional OOD training set. Given that the estimated mean and covariance matrix of a multivariate Gaussian distribution follow Gaussian and Inverse-Wishart distributions, multiple GMMs are generated by sampling from these distributions to assess epistemic uncertainty through classification variability. Aleatoric uncertainty is derived from the entropy of responsibility values within Gaussian components. Comparing our method with deep ensembles and logit-sampling for uncertainty computation demonstrates its superior performance in real-world applications for quantifying epistemic and aleatoric uncertainty, as well as detecting OOD samples. While deep ensembles miss some highly uncertain samples, our method successfully detects them and assigns high epistemic uncertainty.
<div id='section'>Paperid: <span id='pid'>1683, <a href='https://arxiv.org/pdf/2410.06120.pdf' target='_blank'>https://arxiv.org/pdf/2410.06120.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giovanni Messuti, ortensia Amoroso, Ferdinando Napolitano, Mariarosaria Falanga, Paolo Capuano, Silvia Scarpetta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06120">Uncertainty estimation via ensembles of deep learning models and dropout layers for seismic traces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models have demonstrated remarkable success in various fields, including seismology. However, one major challenge in deep learning is the presence of mislabeled examples. Additionally, accurately estimating model uncertainty is another challenge in machine learning. In this study, we develop Convolutional Neural Networks (CNNs) to classify seismic waveforms based on first-motion polarity. We trained multiple CNN models with different settings. We also constructed ensembles of networks to estimate uncertainty. The results showed that each training setting achieved satisfactory performances, with the ensemble method outperforming individual networks in uncertainty estimation. We observe that the uncertainty estimation ability of the ensembles of networks can be enhanced using dropout layers. In addition, comparisons among different training settings revealed that the use of dropout improved the robustness of networks to mislabeled examples.
<div id='section'>Paperid: <span id='pid'>1684, <a href='https://arxiv.org/pdf/2409.18628.pdf' target='_blank'>https://arxiv.org/pdf/2409.18628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marvin Tom Teichmann, Manasi Datar, Lisa Kratzke, Fernando Vega, Florin C. Ghesu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18628">Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The precision of contouring target structures and organs-at-risk (OAR) in radiotherapy planning is crucial for ensuring treatment efficacy and patient safety. Recent advancements in deep learning (DL) have significantly improved OAR contouring performance, yet the reliability of these models, especially in the presence of out-of-distribution (OOD) scenarios, remains a concern in clinical settings. This application study explores the integration of epistemic uncertainty estimation within the OAR contouring workflow to enable OOD detection in clinically relevant scenarios, using specifically compiled data. Furthermore, we introduce an advanced statistical method for OOD detection to enhance the methodological framework of uncertainty estimation. Our empirical evaluation demonstrates that epistemic uncertainty estimation is effective in identifying instances where model predictions are unreliable and may require an expert review. Notably, our approach achieves an AUC-ROC of 0.95 for OOD detection, with a specificity of 0.95 and a sensitivity of 0.92 for implant cases, underscoring its efficacy. This study addresses significant gaps in the current research landscape, such as the lack of ground truth for uncertainty estimation and limited empirical evaluations. Additionally, it provides a clinically relevant application of epistemic uncertainty estimation in an FDA-approved and widely used clinical solution for OAR segmentation from Varian, a Siemens Healthineers company, highlighting its practical benefits.
<div id='section'>Paperid: <span id='pid'>1685, <a href='https://arxiv.org/pdf/2409.08754.pdf' target='_blank'>https://arxiv.org/pdf/2409.08754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeseong Yoon, Heeyoung Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08754">Uncertainty Estimation by Density Aware Evidential Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evidential deep learning (EDL) has shown remarkable success in uncertainty estimation. However, there is still room for improvement, particularly in out-of-distribution (OOD) detection and classification tasks. The limited OOD detection performance of EDL arises from its inability to reflect the distance between the testing example and training data when quantifying uncertainty, while its limited classification performance stems from its parameterization of the concentration parameters. To address these limitations, we propose a novel method called Density Aware Evidential Deep Learning (DAEDL). DAEDL integrates the feature space density of the testing example with the output of EDL during the prediction stage, while using a novel parameterization that resolves the issues in the conventional parameterization. We prove that DAEDL enjoys a number of favorable theoretical properties. DAEDL demonstrates state-of-the-art performance across diverse downstream tasks related to uncertainty estimation and classification
<div id='section'>Paperid: <span id='pid'>1686, <a href='https://arxiv.org/pdf/2409.05234.pdf' target='_blank'>https://arxiv.org/pdf/2409.05234.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Javad Ghorbanian, Nicholas Casaprima, Audrey Olivier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.05234">Empowering Bayesian Neural Networks with Functional Priors through Anchored Ensembling for Mechanics Surrogate Modeling Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, neural networks (NNs) have become increasingly popular for surrogate modeling tasks in mechanics and materials modeling applications. While traditional NNs are deterministic functions that rely solely on data to learn the input--output mapping, casting NN training within a Bayesian framework allows to quantify uncertainties, in particular epistemic uncertainties that arise from lack of training data, and to integrate a priori knowledge via the Bayesian prior. However, the high dimensionality and non-physicality of the NN parameter space, and the complex relationship between parameters (NN weights) and predicted outputs, renders both prior design and posterior inference challenging. In this work we present a novel BNN training scheme based on anchored ensembling that can integrate a priori information available in the function space, from e.g. low-fidelity models. The anchoring scheme makes use of low-rank correlations between NN parameters, learnt from pre-training to realizations of the functional prior. We also perform a study to demonstrate how correlations between NN weights, which are often neglected in existing BNN implementations, is critical to appropriately transfer knowledge between the function-space and parameter-space priors. Performance of our novel BNN algorithm is first studied on a small 1D example to illustrate the algorithm's behavior in both interpolation and extrapolation settings. Then, a thorough assessment is performed on a multi--input--output materials surrogate modeling example, where we demonstrate the algorithm's capabilities both in terms of accuracy and quality of the uncertainty estimation, for both in-distribution and out-of-distribution data.
<div id='section'>Paperid: <span id='pid'>1687, <a href='https://arxiv.org/pdf/2409.02976.pdf' target='_blank'>https://arxiv.org/pdf/2409.02976.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Y. Arteaga, Thomas B. SchÃ¶n, Nicolas Pielawski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02976">Hallucination Detection in LLMs: Fast and Memory-Efficient Fine-Tuned Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation is a necessary component when implementing AI in high-risk settings, such as autonomous cars, medicine, or insurances. Large Language Models (LLMs) have seen a surge in popularity in recent years, but they are subject to hallucinations, which may cause serious harm in high-risk settings. Despite their success, LLMs are expensive to train and run: they need a large amount of computations and memory, preventing the use of ensembling methods in practice. In this work, we present a novel method that allows for fast and memory-friendly training of LLM ensembles. We show that the resulting ensembles can detect hallucinations and are a viable approach in practice as only one GPU is needed for training and inference.
<div id='section'>Paperid: <span id='pid'>1688, <a href='https://arxiv.org/pdf/2409.02478.pdf' target='_blank'>https://arxiv.org/pdf/2409.02478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Petter Uvdal, Mohsen Mirkhalaf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02478">Test-time data augmentation: improving predictions of recurrent neural network models of composites</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recurrent Neural Networks (RNNs) have emerged as an interesting alternative to conventional material modeling approaches, particularly for nonlinear path dependent materials. Remarkable computational enhancements are obtained using RNNs compared to classical approaches such as the computational homogenization method. However, RNN predictive errors accumulate, leading to issues when predicting temporal dependencies in time series data. This study aims to address and mitigate inaccuracies induced by neural networks in predicting path dependent plastic deformations of short fiber reinforced composite materials. We propose using an approach of Test Time data Augmentation (TTA), which, to the best of the authors knowledge, is previously untested in the context of RNNs. The method is based on augmenting the input test data using random rotations and subsequently rotating back the predicted output signal. By aggregating the back rotated predictions, a more accurate prediction compared to individual predictions is obtained. Our analysis also demonstrates improved shape consistency between the prediction and the target pseudo time signal. Additionally, this method provides an uncertainty estimation which correlates with the absolute prediction error. The TTA approach is reproducible with different randomly generated data augmentations, establishing a promising framework for optimizing predictions of deep learning models. We believe there are broader implications of the proposed method for various fields reliant on accurate predictive data driven modeling.
<div id='section'>Paperid: <span id='pid'>1689, <a href='https://arxiv.org/pdf/2409.00980.pdf' target='_blank'>https://arxiv.org/pdf/2409.00980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Priyanka Chudasama, Anil Surisetty, Aakarsh Malhotra, Alok Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00980">DNN-GDITD: Out-of-distribution detection via Deep Neural Network based Gaussian Descriptor for Imbalanced Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Classification tasks present challenges due to class imbalances and evolving data distributions. Addressing these issues requires a robust method to handle imbalances while effectively detecting out-of-distribution (OOD) samples not encountered during training. This study introduces a novel OOD detection algorithm designed for tabular datasets, titled Deep Neural Network-based Gaussian Descriptor for Imbalanced Tabular Data (DNN-GDITD). The DNN-GDITD algorithm can be placed on top of any DNN to facilitate better classification of imbalanced data and OOD detection using spherical decision boundaries. Using a combination of Push, Score-based, and focal losses, DNN-GDITD assigns confidence scores to test data points, categorizing them as known classes or as an OOD sample. Extensive experimentation on tabular datasets demonstrates the effectiveness of DNN-GDITD compared to three OOD algorithms. Evaluation encompasses imbalanced and balanced scenarios on diverse tabular datasets, including a synthetic financial dispute dataset and publicly available tabular datasets like Gas Sensor, Drive Diagnosis, and MNIST, showcasing DNN-GDITD's versatility.
<div id='section'>Paperid: <span id='pid'>1690, <a href='https://arxiv.org/pdf/2408.11249.pdf' target='_blank'>https://arxiv.org/pdf/2408.11249.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matias Valdenegro-Toro, Radina Stoykova
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11249">The Dilemma of Uncertainty Estimation for General Purpose AI in the EU AI Act</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The AI act is the European Union-wide regulation of AI systems. It includes specific provisions for general-purpose AI models which however need to be further interpreted in terms of technical standards and state-of-art studies to ensure practical compliance solutions. This paper examines the AI act requirements for providers and deployers of general-purpose AI and further proposes uncertainty estimation as a suitable measure for legal compliance and quality assurance in training of such models. We argue that uncertainty estimation should be a required component for deploying models in the real world, and under the EU AI Act, it could fulfill several requirements for transparency, accuracy, and trustworthiness. However, generally using uncertainty estimation methods increases the amount of computation, producing a dilemma, as computation might go over the threshold ($10^{25}$ FLOPS) to classify the model as a systemic risk system which bears more regulatory burden.
<div id='section'>Paperid: <span id='pid'>1691, <a href='https://arxiv.org/pdf/2408.08142.pdf' target='_blank'>https://arxiv.org/pdf/2408.08142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sangita Das, Subhrajyoti Maji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08142">Impact of Comprehensive Data Preprocessing on Predictive Modelling of COVID-19 Mortality</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate predictive models are crucial for analysing COVID-19 mortality trends. This study evaluates the impact of a custom data preprocessing pipeline on ten machine learning models predicting COVID-19 mortality using data from Our World in Data (OWID). Our pipeline differs from a standard preprocessing pipeline through four key steps. Firstly, it transforms weekly reported totals into daily updates, correcting reporting biases and providing more accurate estimates. Secondly, it uses localised outlier detection and processing to preserve data variance and enhance accuracy. Thirdly, it utilises computational dependencies among columns to ensure data consistency. Finally, it incorporates an iterative feature selection process to optimise the feature set and improve model performance. Results show a significant improvement with the custom pipeline: the MLP Regressor achieved a test RMSE of 66.556 and a test R-squared of 0.991, surpassing the DecisionTree Regressor from the standard pipeline, which had a test RMSE of 222.858 and a test R-squared of 0.817. These findings highlight the importance of tailored preprocessing techniques in enhancing predictive modelling accuracy for COVID-19 mortality. Although specific to this study, these methodologies offer valuable insights into diverse datasets and domains, improving predictive performance across various contexts.
<div id='section'>Paperid: <span id='pid'>1692, <a href='https://arxiv.org/pdf/2408.02295.pdf' target='_blank'>https://arxiv.org/pdf/2408.02295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seyeon Kim, Joonhun Lee, Namhoon Cho, Sungjun Han, Wooseop Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02295">Generalized Gaussian Temporal Difference Error for Uncertainty-aware Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional uncertainty-aware temporal difference (TD) learning often assumes a zero-mean Gaussian distribution for TD errors, leading to inaccurate error representations and compromised uncertainty estimation. We introduce a novel framework for generalized Gaussian error modeling in deep reinforcement learning to enhance the flexibility of error distribution modeling by incorporating additional higher-order moment, particularly kurtosis, thereby improving the estimation and mitigation of data-dependent aleatoric uncertainty. We examine the influence of the shape parameter of the generalized Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form expression that demonstrates an inverse relationship between uncertainty and the shape parameter. Additionally, we propose a theoretically grounded weighting scheme to address epistemic uncertainty by fully leveraging the GGD. We refine batch inverse variance weighting with bias reduction and kurtosis considerations, enhancing robustness. Experiments with policy gradient algorithms demonstrate significant performance gains.
<div id='section'>Paperid: <span id='pid'>1693, <a href='https://arxiv.org/pdf/2408.01301.pdf' target='_blank'>https://arxiv.org/pdf/2408.01301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gregory Canal, Vladimir Leung, Philip Sage, Eric Heim, I-Jeng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01301">A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI) has revolutionized decision-making processes and systems throughout society and, in particular, has emerged as a significant technology in high-impact scenarios of national interest. Yet, despite AI's impressive predictive capabilities in controlled settings, it still suffers from a range of practical setbacks preventing its widespread use in various critical scenarios. In particular, it is generally unclear if a given AI system's predictions can be trusted by decision-makers in downstream applications. To address the need for more transparent, robust, and trustworthy AI systems, a suite of tools has been developed to quantify the uncertainty of AI predictions and, more generally, enable AI to "self-assess" the reliability of its predictions. In this manuscript, we categorize methods for AI self-assessment along several key dimensions and provide guidelines for selecting and designing the appropriate method for a practitioner's needs. In particular, we focus on uncertainty estimation techniques that consider the impact of self-assessment on the choices made by downstream decision-makers and on the resulting costs and benefits of decision outcomes. To demonstrate the utility of our methodology for self-assessment design, we illustrate its use for two realistic national-interest scenarios. This manuscript is a practical guide for machine learning engineers and AI system users to select the ideal self-assessment techniques for each problem.
<div id='section'>Paperid: <span id='pid'>1694, <a href='https://arxiv.org/pdf/2407.16119.pdf' target='_blank'>https://arxiv.org/pdf/2407.16119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atul Kumar, Siddharth Garg, Soumya Dutta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16119">Uncertainty-Aware Deep Neural Representations for Visual Analysis of Vector Field Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The widespread use of Deep Neural Networks (DNNs) has recently resulted in their application to challenging scientific visualization tasks. While advanced DNNs demonstrate impressive generalization abilities, understanding factors like prediction quality, confidence, robustness, and uncertainty is crucial. These insights aid application scientists in making informed decisions. However, DNNs lack inherent mechanisms to measure prediction uncertainty, prompting the creation of distinct frameworks for constructing robust uncertainty-aware models tailored to various visualization tasks. In this work, we develop uncertainty-aware implicit neural representations to model steady-state vector fields effectively. We comprehensively evaluate the efficacy of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout, aimed at enabling uncertainty-informed visual analysis of features within steady vector field data. Our detailed exploration using several vector data sets indicate that uncertainty-aware models generate informative visualization results of vector field features. Furthermore, incorporating prediction uncertainty improves the resilience and interpretability of our DNN model, rendering it applicable for the analysis of non-trivial vector field data sets.
<div id='section'>Paperid: <span id='pid'>1695, <a href='https://arxiv.org/pdf/2407.12609.pdf' target='_blank'>https://arxiv.org/pdf/2407.12609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>LuÃ­s Almeida, InÃªs Dutra, Francesco Renna
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12609">Instance-wise Uncertainty for Class Imbalance in Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic segmentation is a fundamental computer vision task with a vast number of applications. State of the art methods increasingly rely on deep learning models, known to incorrectly estimate uncertainty and being overconfident in predictions, especially in data not seen during training. This is particularly problematic in semantic segmentation due to inherent class imbalance. Popular uncertainty quantification approaches are task-agnostic and fail to leverage spatial pixel correlations in uncertainty estimates, crucial in this task. In this work, a novel training methodology specifically designed for semantic segmentation is presented. Training samples are weighted by instance-wise uncertainty masks computed by an ensemble. This is shown to increase performance on minority classes, boost model generalization and robustness to domain-shift when compared to using the inverse of class proportions or no class weights at all. This method addresses the challenges of class imbalance and uncertainty estimation in semantic segmentation, potentially enhancing model performance and reliability across various applications.
<div id='section'>Paperid: <span id='pid'>1696, <a href='https://arxiv.org/pdf/2407.11006.pdf' target='_blank'>https://arxiv.org/pdf/2407.11006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oluyemi Enoch Amujo, Shanchieh Jay Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11006">Evaluating the Efficacy of Foundational Models: Advancing Benchmarking Practices to Enhance Fine-Tuning Decision-Making</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, large language models (LLMs) have expanded into various domains. However, there remains a need to evaluate how these models perform when prompted with commonplace queries compared to domain-specific queries, which may be useful for benchmarking prior to fine-tuning for domain-specific downstream tasks. This study evaluates LLMs, specifically Gemma-2B and Gemma-7B, across diverse domains, including cybersecurity, medicine, and finance, compared to common knowledge queries. This study utilizes a comprehensive methodology to assess foundational models, which includes problem formulation, data analysis, and the development of ThroughCut, a novel outlier detection technique that automatically identifies response throughput outliers based on their conciseness. This methodological rigor enhances the credibility of the presented evaluation frameworks. This study focused on assessing inference time, response length, throughput, quality, and resource utilization and investigated the correlations between these factors. The results indicate that model size and types of prompts used for inference significantly influenced response length and quality. In addition, common prompts, which include various types of queries, generate diverse and inconsistent responses at irregular intervals. In contrast, domain-specific prompts consistently generate concise responses within a reasonable time. Overall, this study underscores the need for comprehensive evaluation frameworks to enhance the reliability of benchmarking procedures in multidomain AI research.
<div id='section'>Paperid: <span id='pid'>1697, <a href='https://arxiv.org/pdf/2407.03791.pdf' target='_blank'>https://arxiv.org/pdf/2407.03791.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Florian Schneider, Sunayana Sitaram
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03791">M5 -- A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since the release of ChatGPT, the field of Natural Language Processing has experienced rapid advancements, particularly in Large Language Models (LLMs) and their multimodal counterparts, Large Multimodal Models (LMMs). Despite their impressive capabilities, LLMs often exhibit significant performance disparities across different languages and cultural contexts, as demonstrated by various text-only benchmarks. However, current research lacks such benchmarks for multimodal visio-linguistic settings. This work fills this gap by introducing M5, the first comprehensive benchmark designed to evaluate LMMs on diverse vision-language tasks within a multilingual and multicultural context. M5 includes eight datasets covering five tasks and $41$ languages, with a focus on underrepresented languages and culturally diverse images. Furthermore, we introduce two novel datasets, M5-VGR and M5-VLOD, including a new Visio-Linguistic Outlier Detection task, in which all evaluated open-source models fail to significantly surpass the random baseline. Through extensive evaluation and analyses, we highlight substantial task-agnostic performance disparities between high- and low-resource languages. Moreover, we show that larger models do not necessarily outperform smaller ones in a multilingual setting.
<div id='section'>Paperid: <span id='pid'>1698, <a href='https://arxiv.org/pdf/2407.03489.pdf' target='_blank'>https://arxiv.org/pdf/2407.03489.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saandeep Aathreya, Shaun Canavan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03489">FlowCon: Out-of-Distribution Detection using Flow-Based Contrastive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying Out-of-distribution (OOD) data is becoming increasingly critical as the real-world applications of deep learning methods expand. Post-hoc methods modify softmax scores fine-tuned on outlier data or leverage intermediate feature layers to identify distinctive patterns between In-Distribution (ID) and OOD samples. Other methods focus on employing diverse OOD samples to learn discrepancies between ID and OOD. These techniques, however, are typically dependent on the quality of the outlier samples assumed. Density-based methods explicitly model class-conditioned distributions but this requires long training time or retraining the classifier. To tackle these issues, we introduce \textit{FlowCon}, a new density-based OOD detection technique. Our main innovation lies in efficiently combining the properties of normalizing flow with supervised contrastive learning, ensuring robust representation learning with tractable density estimation. Empirical evaluation shows the enhanced performance of our method across common vision datasets such as CIFAR-10 and CIFAR-100 pretrained on ResNet18 and WideResNet classifiers. We also perform quantitative analysis using likelihood plots and qualitative visualization using UMAP embeddings and demonstrate the robustness of the proposed method under various OOD contexts. Code will be open-sourced post decision.
<div id='section'>Paperid: <span id='pid'>1699, <a href='https://arxiv.org/pdf/2407.03140.pdf' target='_blank'>https://arxiv.org/pdf/2407.03140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elizabeth Hou, Ross Greenwood, Piyush Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03140">Machine Learning Models for Improved Tracking from Range-Doppler Map Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Statistical tracking filters depend on accurate target measurements and uncertainty estimates for good tracking performance. In this work, we propose novel machine learning models for target detection and uncertainty estimation in range-Doppler map (RDM) images for Ground Moving Target Indicator (GMTI) radars. We show that by using the outputs of these models, we can significantly improve the performance of a multiple hypothesis tracker for complex multi-target air-to-ground tracking scenarios.
<div id='section'>Paperid: <span id='pid'>1700, <a href='https://arxiv.org/pdf/2407.02926.pdf' target='_blank'>https://arxiv.org/pdf/2407.02926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Victor WÃ¥hlstrand SkÃ¤rstrÃ¶m, Lisa Johansson, Jennifer AlvÃ©n, Mattias Lorentzon, Ida HÃ¤ggstrÃ¶m
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02926">Explainable vertebral fracture analysis with uncertainty estimation using differentiable rule-based classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel method for explainable vertebral fracture assessment (XVFA) in low-dose radiographs using deep neural networks, incorporating vertebra detection and keypoint localization with uncertainty estimates. We incorporate Genant's semi-quantitative criteria as a differentiable rule-based means of classifying both vertebra fracture grade and morphology. Unlike previous work, XVFA provides explainable classifications relatable to current clinical methodology, as well as uncertainty estimations, while at the same time surpassing state-of-the art methods with a vertebra-level sensitivity of 93% and end-to-end AUC of 97% in a challenging setting. Moreover, we compare intra-reader agreement with model uncertainty estimates, with model reliability on par with human annotators.
<div id='section'>Paperid: <span id='pid'>1701, <a href='https://arxiv.org/pdf/2407.02271.pdf' target='_blank'>https://arxiv.org/pdf/2407.02271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hilarie Sit, Brendan Keith, Karianne Bergen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02271">Improving Explainability of Softmax Classifiers Using a Prototype-Based Joint Embedding Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a prototype-based approach for improving explainability of softmax classifiers that provides an understandable prediction confidence, generated through stochastic sampling of prototypes, and demonstrates potential for out of distribution detection (OOD). By modifying the model architecture and training to make predictions using similarities to any set of class examples from the training dataset, we acquire the ability to sample for prototypical examples that contributed to the prediction, which provide an instance-based explanation for the model's decision. Furthermore, by learning relationships between images from the training dataset through relative distances within the model's latent space, we obtain a metric for uncertainty that is better able to detect out of distribution data than softmax confidence.
<div id='section'>Paperid: <span id='pid'>1702, <a href='https://arxiv.org/pdf/2407.00295.pdf' target='_blank'>https://arxiv.org/pdf/2407.00295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geng Li, Di Qiu, Lok Ming Lui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00295">A deep neural network framework for dynamic multi-valued mapping estimation and its applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the problem of modeling and estimating dynamic multi-valued mappings. While most mathematical models provide a unique solution for a given input, real-world applications often lack deterministic solutions. In such scenarios, estimating dynamic multi-valued mappings is necessary to suggest different reasonable solutions for each input. This paper introduces a deep neural network framework incorporating a generative network and a classification component. The objective is to model the dynamic multi-valued mapping between the input and output by providing a reliable uncertainty measurement. Generating multiple solutions for a given input involves utilizing a discrete codebook comprising finite variables. These variables are fed into a generative network along with the input, producing various output possibilities. The discreteness of the codebook enables efficient estimation of the output's conditional probability distribution for any given input using a classifier. By jointly optimizing the discrete codebook and its uncertainty estimation during training using a specially designed loss function, a highly accurate approximation is achieved. The effectiveness of our proposed framework is demonstrated through its application to various imaging problems, using both synthetic and real imaging data. Experimental results show that our framework accurately estimates the dynamic multi-valued mapping with uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1703, <a href='https://arxiv.org/pdf/2406.12915.pdf' target='_blank'>https://arxiv.org/pdf/2406.12915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijin Zhou, Yutang Ge, Xiaowen Dong, Yuguang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12915">How Out-of-Distribution Detection Learning Theory Enhances Transformer: Learnability and Reliability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformers excel in natural language processing and computer vision tasks. However, they still face challenges in generalizing to Out-of-Distribution (OOD) datasets, i.e. data whose distribution differs from that seen during training. OOD detection aims to distinguish outliers while preserving in-distribution (ID) data performance. This paper introduces the OOD detection Probably Approximately Correct (PAC) Theory for transformers, which establishes the conditions for data distribution and model configurations for the OOD detection learnability of transformers. It shows that outliers can be accurately represented and distinguished with sufficient data under conditions. The theoretical implications highlight the trade-off between theoretical principles and practical training paradigms. By examining this trade-off, we naturally derived the rationale for leveraging auxiliary outliers to enhance OOD detection. Our theory suggests that by penalizing the misclassification of outliers within the loss function and strategically generating soft synthetic outliers, one can robustly bolster the reliability of transformer networks. This approach yields a novel algorithm that ensures learnability and refines the decision boundaries between inliers and outliers. In practice, the algorithm consistently achieves state-of-the-art (SOTA) performance across various data formats.
<div id='section'>Paperid: <span id='pid'>1704, <a href='https://arxiv.org/pdf/2406.10686.pdf' target='_blank'>https://arxiv.org/pdf/2406.10686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuang Wu, Arash A. Amini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10686">Graph Neural Thompson Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider an online decision-making problem with a reward function defined over graph-structured data. We formally formulate the problem as an instance of graph action bandit. We then propose \texttt{GNN-TS}, a Graph Neural Network (GNN) powered Thompson Sampling (TS) algorithm which employs a GNN approximator for estimating the mean reward function and the graph neural tangent features for uncertainty estimation. We prove that, under certain boundness assumptions on the reward function, GNN-TS achieves a state-of-the-art regret bound which is (1) sub-linear of order $\tilde{\mathcal{O}}((\tilde{d} T)^{1/2})$ in the number of interaction rounds, $T$, and a notion of effective dimension $\tilde{d}$, and (2) independent of the number of graph nodes. Empirical results validate that our proposed \texttt{GNN-TS} exhibits competitive performance and scales well on graph action bandit problems.
<div id='section'>Paperid: <span id='pid'>1705, <a href='https://arxiv.org/pdf/2406.06946.pdf' target='_blank'>https://arxiv.org/pdf/2406.06946.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeinab Abboud, Herve Lombaert, Samuel Kadoury
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06946">Sparse Bayesian Networks: Efficient Uncertainty Quantification in Medical Image Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficiently quantifying predictive uncertainty in medical images remains a challenge. While Bayesian neural networks (BNN) offer predictive uncertainty, they require substantial computational resources to train. Although Bayesian approximations such as ensembles have shown promise, they still suffer from high training and inference costs. Existing approaches mainly address the costs of BNN inference post-training, with little focus on improving training efficiency and reducing parameter complexity. This study introduces a training procedure for a sparse (partial) Bayesian network. Our method selectively assigns a subset of parameters as Bayesian by assessing their deterministic saliency through gradient sensitivity analysis. The resulting network combines deterministic and Bayesian parameters, exploiting the advantages of both representations to achieve high task-specific performance and minimize predictive uncertainty. Demonstrated on multi-label ChestMNIST for classification and ISIC, LIDC-IDRI for segmentation, our approach achieves competitive performance and predictive uncertainty estimation by reducing Bayesian parameters by over 95\%, significantly reducing computational expenses compared to fully Bayesian and ensemble methods.
<div id='section'>Paperid: <span id='pid'>1706, <a href='https://arxiv.org/pdf/2406.00332.pdf' target='_blank'>https://arxiv.org/pdf/2406.00332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fahimeh Fakour, Ali Mosleh, Ramin Ramezani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00332">A Structured Review of Literature on Uncertainty in Machine Learning & Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The adaptation and use of Machine Learning (ML) in our daily lives has led to concerns in lack of transparency, privacy, reliability, among others. As a result, we are seeing research in niche areas such as interpretability, causality, bias and fairness, and reliability. In this survey paper, we focus on a critical concern for adaptation of ML in risk-sensitive applications, namely understanding and quantifying uncertainty. Our paper approaches this topic in a structured way, providing a review of the literature in the various facets that uncertainty is enveloped in the ML process. We begin by defining uncertainty and its categories (e.g., aleatoric and epistemic), understanding sources of uncertainty (e.g., data and model), and how uncertainty can be assessed in terms of uncertainty quantification techniques (Ensembles, Bayesian Neural Networks, etc.). As part of our assessment and understanding of uncertainty in the ML realm, we cover metrics for uncertainty quantification for a single sample, dataset, and metrics for accuracy of the uncertainty estimation itself. This is followed by discussions on calibration (model and uncertainty), and decision making under uncertainty. Thus, we provide a more complete treatment of uncertainty: from the sources of uncertainty to the decision-making process. We have focused the review of uncertainty quantification methods on Deep Learning (DL), while providing the necessary background for uncertainty discussion within ML in general. Key contributions in this review are broadening the scope of uncertainty discussion, as well as an updated review of uncertainty quantification methods in DL.
<div id='section'>Paperid: <span id='pid'>1707, <a href='https://arxiv.org/pdf/2405.13907.pdf' target='_blank'>https://arxiv.org/pdf/2405.13907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Yang, Chen Chen, Konstantinos Pitas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13907">Just rephrase it! Uncertainty estimation in closed-source language models via multiple rephrased queries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State-of-the-art large language models are sometimes distributed as open-source software but are also increasingly provided as a closed-source service. These closed-source large-language models typically see the widest usage by the public, however, they often do not provide an estimate of their uncertainty when responding to queries. As even the best models are prone to ``hallucinating" false information with high confidence, a lack of a reliable estimate of uncertainty limits the applicability of these models in critical settings. We explore estimating the uncertainty of closed-source LLMs via multiple rephrasings of an original base query. Specifically, we ask the model, multiple rephrased questions, and use the similarity of the answers as an estimate of uncertainty. We diverge from previous work in i) providing rules for rephrasing that are simple to memorize and use in practice ii) proposing a theoretical framework for why multiple rephrased queries obtain calibrated uncertainty estimates. Our method demonstrates significant improvements in the calibration of uncertainty estimates compared to the baseline and provides intuition as to how query strategies should be designed for optimal test calibration.
<div id='section'>Paperid: <span id='pid'>1708, <a href='https://arxiv.org/pdf/2405.13285.pdf' target='_blank'>https://arxiv.org/pdf/2405.13285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Pogorzelski, Peter Arlinghaus, Wenyan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13285">Enhancing Active Learning for Sentinel 2 Imagery through Contrastive Learning and Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce a novel method designed to enhance label efficiency in satellite imagery analysis by integrating semi-supervised learning (SSL) with active learning strategies. Our approach utilizes contrastive learning together with uncertainty estimations via Monte Carlo Dropout (MC Dropout), with a particular focus on Sentinel-2 imagery analyzed using the Eurosat dataset. We explore the effectiveness of our method in scenarios featuring both balanced and unbalanced class distributions. Our results show that the proposed method performs better than several other popular methods in this field, enabling significant savings in labeling effort while maintaining high classification accuracy. These findings highlight the potential of our approach to facilitate scalable and cost-effective satellite image analysis, particularly advantageous for extensive environmental monitoring and land use classification tasks.
<div id='section'>Paperid: <span id='pid'>1709, <a href='https://arxiv.org/pdf/2405.11816.pdf' target='_blank'>https://arxiv.org/pdf/2405.11816.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anastasios Foliadis, Mario H. CastaÃ±eda, Richard A. Stirling-Gallacher, Reiner S. ThomÃ¤
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11816">Transfer Learning for CSI-based Positioning with Multi-environment Meta-learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Utilizing deep learning (DL) techniques for radio-based positioning of user equipment (UE) through channel state information (CSI) fingerprints has demonstrated significant potential. DL models can extract complex characteristics from the CSI fingerprints of a particular environment and accurately predict the position of a UE. Nonetheless, the effectiveness of the DL model trained on CSI fingerprints is highly dependent on the particular training environment, limiting the trained model's applicability across different environments. This paper proposes a novel DL model structure consisting of two parts, where the first part aims at identifying features that are independent from any specific environment, while the second part combines those features in an environment specific way with the goal of positioning. To train such a two-part model, we propose the multi-environment meta-learning (MEML) approach for the first part to facilitate training across various environments, while the second part of the model is trained solely on data from a specific environment. Our findings indicate that employing the MEML approach for initializing the weights of the DL model for a new unseen environment significantly boosts the accuracy of UE positioning in the new target environment as well the reliability of its uncertainty estimation. This method outperforms traditional transfer learning methods, whether direct transfer learning (DTL) between environments or completely training from scratch with data from a new environment. The proposed approach is verified with real measurements for both line-of-sight (LOS) and non-LOS (NLOS) environments.
<div id='section'>Paperid: <span id='pid'>1710, <a href='https://arxiv.org/pdf/2405.06293.pdf' target='_blank'>https://arxiv.org/pdf/2405.06293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>V. Kisielius, E. Illarionov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06293">Machine learning for reconstruction of polarity inversion lines from solar filaments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solar filaments are well-known tracers of polarity inversion lines that separate two opposite magnetic polarities on the solar photosphere. Because observations of filaments began long before the systematic observations of solar magnetic fields, historical filament catalogs can facilitate the reconstruction of magnetic polarity maps at times when direct magnetic observations were not yet available. In practice, this reconstruction is often ambiguous and typically performed manually. We propose an automatic approach based on a machine-learning model that generates a variety of magnetic polarity maps consistent with filament observations. To evaluate the model and discuss the results we use the catalog of solar filaments and polarity maps compiled by McIntosh. We realize that the process of manual compilation of polarity maps includes not only information on filaments, but also a large amount of prior information, which is difficult to formalize. In order to compensate for the lack of prior knowledge for the machine-learning model, we provide it with polarity information at several reference points. We demonstrate that this process, which can be considered as the user-guided reconstruction or super-resolution, leads to polarity maps that are reasonably close to hand-drawn ones, and additionally allows for uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1711, <a href='https://arxiv.org/pdf/2405.04759.pdf' target='_blank'>https://arxiv.org/pdf/2405.04759.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihan Mei, Xinyu Wang, Dell Zhang, Xiaoling Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.04759">Multi-Label Out-of-Distribution Detection with Spectral Normalized Joint Energy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In today's interconnected world, achieving reliable out-of-distribution (OOD) detection poses a significant challenge for machine learning models. While numerous studies have introduced improved approaches for multi-class OOD detection tasks, the investigation into multi-label OOD detection tasks has been notably limited. We introduce Spectral Normalized Joint Energy (SNoJoE), a method that consolidates label-specific information across multiple labels through the theoretically justified concept of an energy-based function. Throughout the training process, we employ spectral normalization to manage the model's feature space, thereby enhancing model efficacy and generalization, in addition to bolstering robustness. Our findings indicate that the application of spectral normalization to joint energy scores notably amplifies the model's capability for OOD detection. We perform OOD detection experiments utilizing PASCAL-VOC as the in-distribution dataset and ImageNet-22K or Texture as the out-of-distribution datasets. Our experimental results reveal that, in comparison to prior top performances, SNoJoE achieves 11% and 54% relative reductions in FPR95 on the respective OOD datasets, thereby defining the new state of the art in this field of study.
<div id='section'>Paperid: <span id='pid'>1712, <a href='https://arxiv.org/pdf/2405.02917.pdf' target='_blank'>https://arxiv.org/pdf/2405.02917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tobias Groot, Matias Valdenegro-Toro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02917">Overconfidence is Key: Verbalized Uncertainty Evaluation in Large Language and Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language and Vision-Language Models (LLMs/VLMs) have revolutionized the field of AI by their ability to generate human-like text and understand images, but ensuring their reliability is crucial. This paper aims to evaluate the ability of LLMs (GPT4, GPT-3.5, LLaMA2, and PaLM 2) and VLMs (GPT4V and Gemini Pro Vision) to estimate their verbalized uncertainty via prompting. We propose the new Japanese Uncertain Scenes (JUS) dataset, aimed at testing VLM capabilities via difficult queries and object counting, and the Net Calibration Error (NCE) to measure direction of miscalibration. Results show that both LLMs and VLMs have a high calibration error and are overconfident most of the time, indicating a poor capability for uncertainty estimation. Additionally we develop prompts for regression tasks, and we show that VLMs have poor calibration when producing mean/standard deviation and 95% confidence intervals.
<div id='section'>Paperid: <span id='pid'>1713, <a href='https://arxiv.org/pdf/2404.17023.pdf' target='_blank'>https://arxiv.org/pdf/2404.17023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mojtaba Abolfazli, Mohammad Zaeri Amirani, Anders HÃ¸st-Madsen, June Zhang, Andras Bratincsak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17023">Out-of-Distribution Detection using Maximum Entropy Coding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given a default distribution $P$ and a set of test data $x^M=\{x_1,x_2,\ldots,x_M\}$ this paper seeks to answer the question if it was likely that $x^M$ was generated by $P$. For discrete distributions, the definitive answer is in principle given by Kolmogorov-Martin-LÃ¶f randomness. In this paper we seek to generalize this to continuous distributions. We consider a set of statistics $T_1(x^M),T_2(x^M),\ldots$. To each statistic we associate its maximum entropy distribution and with this a universal source coder. The maximum entropy distributions are subsequently combined to give a total codelength, which is compared with $-\log P(x^M)$. We show that this approach satisfied a number of theoretical properties.
  For real world data $P$ usually is unknown. We transform data into a standard distribution in the latent space using a bidirectional generate network and use maximum entropy coding there. We compare the resulting method to other methods that also used generative neural networks to detect anomalies. In most cases, our results show better performance.
<div id='section'>Paperid: <span id='pid'>1714, <a href='https://arxiv.org/pdf/2404.11929.pdf' target='_blank'>https://arxiv.org/pdf/2404.11929.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Walid Abdullah Al, Il Dong Yun, Yun Jung Bae
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.11929">A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease With Enhanced Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dopamine transporter (DAT) imaging is commonly used for monitoring Parkinson's disease (PD), where striatal DAT uptake amount is computed to assess PD severity. However, DAT imaging has a high cost and the risk of radiance exposure and is not available in general clinics. Recently, MRI patch of the nigral region has been proposed as a safer and easier alternative. This paper proposes a symmetric regressor for predicting the DAT uptake amount from the nigral MRI patch. Acknowledging the symmetry between the right and left nigrae, the proposed regressor incorporates a paired input-output model that simultaneously predicts the DAT uptake amounts for both the right and left striata. Moreover, it employs a symmetric loss that imposes a constraint on the difference between right-to-left predictions, resembling the high correlation in DAT uptake amounts in the two lateral sides. Additionally, we propose a symmetric Monte-Carlo (MC) dropout method for providing a fruitful uncertainty estimate of the DAT uptake prediction, which utilizes the above symmetry. We evaluated the proposed approach on 734 nigral patches, which demonstrated significantly improved performance of the symmetric regressor compared with the standard regressors while giving better explainability and feature representation. The symmetric MC dropout also gave precise uncertainty ranges with a high probability of including the true DAT uptake amounts within the range.
<div id='section'>Paperid: <span id='pid'>1715, <a href='https://arxiv.org/pdf/2404.09821.pdf' target='_blank'>https://arxiv.org/pdf/2404.09821.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuri Kinoshita, Taro Toyoizumi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.09821">A provable control of sensitivity of neural networks through a direct parameterization of the overall bi-Lipschitzness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While neural networks can enjoy an outstanding flexibility and exhibit unprecedented performance, the mechanism behind their behavior is still not well-understood. To tackle this fundamental challenge, researchers have tried to restrict and manipulate some of their properties in order to gain new insights and better control on them. Especially, throughout the past few years, the concept of \emph{bi-Lipschitzness} has been proved as a beneficial inductive bias in many areas. However, due to its complexity, the design and control of bi-Lipschitz architectures are falling behind, and a model that is precisely designed for bi-Lipschitzness realizing a direct and simple control of the constants along with solid theoretical analysis is lacking. In this work, we investigate and propose a novel framework for bi-Lipschitzness that can achieve such a clear and tight control based on convex neural networks and the Legendre-Fenchel duality. Its desirable properties are illustrated with concrete experiments. We also apply this framework to uncertainty estimation and monotone problem settings to illustrate its broad range of applications.
<div id='section'>Paperid: <span id='pid'>1716, <a href='https://arxiv.org/pdf/2404.06198.pdf' target='_blank'>https://arxiv.org/pdf/2404.06198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Claudia Ehrig, Benedikt Sonnleitner, Ursula Neumann, Catherine Cleophas, Germain Forestier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06198">The impact of data set similarity and diversity on transfer learning success in time series forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained models have become pivotal in enhancing the efficiency and accuracy of time series forecasting on target data sets by leveraging transfer learning. While benchmarks validate the performance of model generalization on various target data sets, there is no structured research providing similarity and diversity measures to explain which characteristics of source and target data lead to transfer learning success. Our study pioneers in systematically evaluating the impact of source-target similarity and source diversity on zero-shot and fine-tuned forecasting outcomes in terms of accuracy, bias, and uncertainty estimation. We investigate these dynamics using pre-trained neural networks across five public source datasets, applied to forecasting five target data sets, including real-world wholesales data. We identify two feature-based similarity and diversity measures, finding that source-target similarity reduces forecasting bias, while source diversity improves forecasting accuracy and uncertainty estimation, but increases the bias.
<div id='section'>Paperid: <span id='pid'>1717, <a href='https://arxiv.org/pdf/2404.03495.pdf' target='_blank'>https://arxiv.org/pdf/2404.03495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Klüttermann, Emmanuel Müller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.03495">Deep Transductive Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection (OD) is one of the core challenges in machine learning. Transductive learning, which leverages test data during training, has shown promise in related machine learning tasks, yet remains largely unexplored for modern OD. We present Doust, the first end-to-end transductive deep learning algorithm for outlier detection, which explicitly leverages unlabeled test data to boost accuracy. On the comprehensive ADBench benchmark, Doust achieves an average ROC-AUC of $89%$, outperforming all 21 competitors by roughly $10%$. Our analysis identifies both the potential and a limitation of transductive OD: while performance gains can be substantial in favorable conditions, very low contamination rates can hinder improvements unless the dataset is sufficiently large.
<div id='section'>Paperid: <span id='pid'>1718, <a href='https://arxiv.org/pdf/2403.19826.pdf' target='_blank'>https://arxiv.org/pdf/2403.19826.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qitian Ma, Shyam Nanda Rai, Carlo Masone, Tatiana Tommasi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.19826">Segmentation Re-thinking Uncertainty Estimation Metrics for Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the domain of computer vision, semantic segmentation emerges as a fundamental application within machine learning, wherein individual pixels of an image are classified into distinct semantic categories. This task transcends traditional accuracy metrics by incorporating uncertainty quantification, a critical measure for assessing the reliability of each segmentation prediction. Such quantification is instrumental in facilitating informed decision-making, particularly in applications where precision is paramount. Within this nuanced framework, the metric known as PAvPU (Patch Accuracy versus Patch Uncertainty) has been developed as a specialized tool for evaluating entropy-based uncertainty in image segmentation tasks. However, our investigation identifies three core deficiencies within the PAvPU framework and proposes robust solutions aimed at refining the metric. By addressing these issues, we aim to enhance the reliability and applicability of uncertainty quantification, especially in scenarios that demand high levels of safety and accuracy, thus contributing to the advancement of semantic segmentation methodologies in critical applications.
<div id='section'>Paperid: <span id='pid'>1719, <a href='https://arxiv.org/pdf/2403.08652.pdf' target='_blank'>https://arxiv.org/pdf/2403.08652.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Ardis, Arjuna Flenner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08652">Extracting Explanations, Justification, and Uncertainty from Black-Box Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Neural Networks (DNNs) do not inherently compute or exhibit empirically-justified task confidence. In mission critical applications, it is important to both understand associated DNN reasoning and its supporting evidence. In this paper, we propose a novel Bayesian approach to extract explanations, justifications, and uncertainty estimates from DNNs. Our approach is efficient both in terms of memory and computation, and can be applied to any black box DNN without any retraining, including applications to anomaly detection and out-of-distribution detection tasks. We validate our approach on the CIFAR-10 dataset, and show that it can significantly improve the interpretability and reliability of DNNs.
<div id='section'>Paperid: <span id='pid'>1720, <a href='https://arxiv.org/pdf/2403.06874.pdf' target='_blank'>https://arxiv.org/pdf/2403.06874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>L. E. Hogeweg, R. Gangireddy, D. Brunink, V. J. Kalkman, L. Cornelissen, J. W. Kamminga
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06874">COOD: Combined out-of-distribution detection using multiple measures for anomaly & novel class detection in large-scale hierarchical classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-performing out-of-distribution (OOD) detection, both anomaly and novel class, is an important prerequisite for the practical use of classification models. In this paper, we focus on the species recognition task in images concerned with large databases, a large number of fine-grained hierarchical classes, severe class imbalance, and varying image quality. We propose a framework for combining individual OOD measures into one combined OOD (COOD) measure using a supervised model. The individual measures are several existing state-of-the-art measures and several novel OOD measures developed with novel class detection and hierarchical class structure in mind. COOD was extensively evaluated on three large-scale (500k+ images) biodiversity datasets in the context of anomaly and novel class detection. We show that COOD outperforms individual, including state-of-the-art, OOD measures by a large margin in terms of TPR@1% FPR in the majority of experiments, e.g., improving detecting ImageNet images (OOD) from 54.3% to 85.4% for the iNaturalist 2018 dataset. SHAP (feature contribution) analysis shows that different individual OOD measures are essential for various tasks, indicating that multiple OOD measures and combinations are needed to generalize. Additionally, we show that explicitly considering ID images that are incorrectly classified for the original (species) recognition task is important for constructing high-performing OOD detection methods and for practical applicability. The framework can easily be extended or adapted to other tasks and media modalities.
<div id='section'>Paperid: <span id='pid'>1721, <a href='https://arxiv.org/pdf/2402.18960.pdf' target='_blank'>https://arxiv.org/pdf/2402.18960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jennie Karlsson, Marisa Wodrich, Niels Christian Overgaard, Freja Sahlin, Kristina LÃ¥ng, Anders Heyden, Ida Arvidsson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18960">Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has shown to have great potential in medical applications. In critical domains as such, it is of high interest to have trustworthy algorithms which are able to tell when reliable assessments cannot be guaranteed. Detecting out-of-distribution (OOD) samples is a crucial step towards building a safe classifier. Following a previous study, showing that it is possible to classify breast cancer in point-of-care ultrasound images, this study investigates OOD detection using three different methods: softmax, energy score and deep ensembles. All methods are tested on three different OOD data sets. The results show that the energy score method outperforms the softmax method, performing well on two of the data sets. The ensemble method is the most robust, performing the best at detecting OOD samples for all three OOD data sets.
<div id='section'>Paperid: <span id='pid'>1722, <a href='https://arxiv.org/pdf/2402.15143.pdf' target='_blank'>https://arxiv.org/pdf/2402.15143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shota Sugawara, Ryuji Imamura
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.15143">PUAD: Frustratingly Simple Method for Robust Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing an accurate and fast anomaly detection model is an important task in real-time computer vision applications. There has been much research to develop a single model that detects either structural or logical anomalies, which are inherently distinct. The majority of the existing approaches implicitly assume that the anomaly can be represented by identifying the anomalous location. However, we argue that logical anomalies, such as the wrong number of objects, can not be well-represented by the spatial feature maps and require an alternative approach. In addition, we focused on the possibility of detecting logical anomalies by using an out-of-distribution detection approach on the feature space, which aggregates the spatial information of the feature map. As a demonstration, we propose a method that incorporates a simple out-of-distribution detection method on the feature space against state-of-the-art reconstruction-based approaches. Despite the simplicity of our proposal, our method PUAD (Picturable and Unpicturable Anomaly Detection) achieves state-of-the-art performance on the MVTec LOCO AD dataset.
<div id='section'>Paperid: <span id='pid'>1723, <a href='https://arxiv.org/pdf/2402.06937.pdf' target='_blank'>https://arxiv.org/pdf/2402.06937.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masoumeh Javanbakhat, Md Tasnimul Hasan, Cristoph Lippert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06937">Assessing Uncertainty Estimation Methods for 3D Image Segmentation under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, machine learning has witnessed extensive adoption across various sectors, yet its application in medical image-based disease detection and diagnosis remains challenging due to distribution shifts in real-world data. In practical settings, deployed models encounter samples that differ significantly from the training dataset, especially in the health domain, leading to potential performance issues. This limitation hinders the expressiveness and reliability of deep learning models in health applications. Thus, it becomes crucial to identify methods capable of producing reliable uncertainty estimation in the context of distribution shifts in the health sector. In this paper, we explore the feasibility of using cutting-edge Bayesian and non-Bayesian methods to detect distributionally shifted samples, aiming to achieve reliable and trustworthy diagnostic predictions in segmentation task. Specifically, we compare three distinct uncertainty estimation methods, each designed to capture either unimodal or multimodal aspects in the posterior distribution. Our findings demonstrate that methods capable of addressing multimodal characteristics in the posterior distribution, offer more dependable uncertainty estimates. This research contributes to enhancing the utility of deep learning in healthcare, making diagnostic predictions more robust and trustworthy.
<div id='section'>Paperid: <span id='pid'>1724, <a href='https://arxiv.org/pdf/2401.17814.pdf' target='_blank'>https://arxiv.org/pdf/2401.17814.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Laurens P. Stoop, Erik Duijm, Ad J. Feelders, Machteld van den Broek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.17814">Detection of Critical Events in Renewable Energy Production Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The introduction of more renewable energy sources into the energy system increases the variability and weather dependence of electricity generation. Power system simulations are used to assess the adequacy and reliability of the electricity grid over decades, but often become computational intractable for such long simulation periods with high technical detail. To alleviate this computational burden, we investigate the use of outlier detection algorithms to find periods of extreme renewable energy generation which enables detailed modelling of the performance of power systems under these circumstances. Specifically, we apply the Maximum Divergent Intervals (MDI) algorithm to power generation time series that have been derived from ERA5 historical climate reanalysis covering the period from 1950 through 2019. By applying the MDI algorithm on these time series, we identified intervals of extreme low and high energy production. To determine the outlierness of an interval different divergence measures can be used. Where the cross-entropy measure results in shorter and strongly peaking outliers, the unbiased Kullback-Leibler divergence tends to detect longer and more persistent intervals. These intervals are regarded as potential risks for the electricity grid by domain experts, showcasing the capability of the MDI algorithm to detect critical events in these time series. For the historical period analysed, we found no trend in outlier intensity, or shift and lengthening of the outliers that could be attributed to climate change. By applying MDI on climate model output, power system modellers can investigate the adequacy and possible changes of risk for the current and future electricity grid under a wider range of scenarios.
<div id='section'>Paperid: <span id='pid'>1725, <a href='https://arxiv.org/pdf/2401.17013.pdf' target='_blank'>https://arxiv.org/pdf/2401.17013.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jens Henriksson, Christian Berger, Stig Ursing, Markus Borg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.17013">Evaluation of Out-of-Distribution Detection Performance on Autonomous Driving Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Safety measures need to be systemically investigated to what extent they evaluate the intended performance of Deep Neural Networks (DNNs) for critical applications. Due to a lack of verification methods for high-dimensional DNNs, a trade-off is needed between accepted performance and handling of out-of-distribution (OOD) samples.
  This work evaluates rejecting outputs from semantic segmentation DNNs by applying a Mahalanobis distance (MD) based on the most probable class-conditional Gaussian distribution for the predicted class as an OOD score. The evaluation follows three DNNs trained on the Cityscapes dataset and tested on four automotive datasets and finds that classification risk can drastically be reduced at the cost of pixel coverage, even when applied on unseen datasets. The applicability of our findings will support legitimizing safety measures and motivate their usage when arguing for safe usage of DNNs in automotive perception.
<div id='section'>Paperid: <span id='pid'>1726, <a href='https://arxiv.org/pdf/2401.05594.pdf' target='_blank'>https://arxiv.org/pdf/2401.05594.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prakash Mallick, Feras Dayoub, Jamie Sherrah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05594">Wasserstein Distance-based Expansion of Low-Density Latent Regions for Unknown Class Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the significant challenge in open-set object detection (OSOD): the tendency of state-of-the-art detectors to erroneously classify unknown objects as known categories with high confidence. We present a novel approach that effectively identifies unknown objects by distinguishing between high and low-density regions in latent space. Our method builds upon the Open-Det (OD) framework, introducing two new elements to the loss function. These elements enhance the known embedding space's clustering and expand the unknown space's low-density regions. The first addition is the Class Wasserstein Anchor (CWA), a new function that refines the classification boundaries. The second is a spectral normalisation step, improving the robustness of the model. Together, these augmentations to the existing Contrastive Feature Learner (CFL) and Unknown Probability Learner (UPL) loss functions significantly improve OSOD performance. Our proposed OpenDet-CWA (OD-CWA) method demonstrates: a) a reduction in open-set errors by approximately 17%-22%, b) an enhancement in novelty detection capability by 1.5%-16%, and c) a decrease in the wilderness index by 2%-20% across various open-set scenarios. These results represent a substantial advancement in the field, showcasing the potential of our approach in managing the complexities of open-set object detection.
<div id='section'>Paperid: <span id='pid'>1727, <a href='https://arxiv.org/pdf/2401.04144.pdf' target='_blank'>https://arxiv.org/pdf/2401.04144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sankalp Gilda, Neel Bhandari, Wendy Mak, Andrea Panizza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04144">Robust Calibration For Improved Weather Prediction Under Distributional Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present results on improving out-of-domain weather prediction and uncertainty estimation as part of the \texttt{Shifts Challenge on Robustness and Uncertainty under Real-World Distributional Shift} challenge. We find that by leveraging a mixture of experts in conjunction with an advanced data augmentation technique borrowed from the computer vision domain, in conjunction with robust \textit{post-hoc} calibration of predictive uncertainties, we can potentially achieve more accurate and better-calibrated results with deep neural networks than with boosted tree models for tabular data. We quantify our predictions using several metrics and propose several future lines of inquiry and experimentation to boost performance.
<div id='section'>Paperid: <span id='pid'>1728, <a href='https://arxiv.org/pdf/2401.00773.pdf' target='_blank'>https://arxiv.org/pdf/2401.00773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongwook Kim, Juyeon Park, Hee Cheol Chung, Seonghyun Jeong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00773">Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Probabilistic mixture models are recognized as effective tools for unsupervised outlier detection owing to their interpretability and global characteristics. Among these, Dirichlet process mixture models stand out as a strong alternative to conventional finite mixture models for both clustering and outlier detection tasks. Unlike finite mixture models, Dirichlet process mixtures are infinite mixture models that automatically determine the number of mixture components based on the data. Despite their advantages, the adoption of Dirichlet process mixture models for unsupervised outlier detection has been limited by challenges related to computational inefficiency and sensitivity to outliers in the construction of outlier detectors. Additionally, Dirichlet process Gaussian mixtures struggle to effectively model non-Gaussian data with discrete or binary features. To address these challenges, we propose a novel outlier detection method that utilizes ensembles of Dirichlet process Gaussian mixtures. This unsupervised algorithm employs random subspace and subsampling ensembles to ensure efficient computation and improve the robustness of the outlier detector. The ensemble approach further improves the suitability of the proposed method for detecting outliers in non-Gaussian data. Furthermore, our method uses variational inference for Dirichlet process mixtures, which ensures both efficient and rapid computation. Empirical analyses using benchmark datasets demonstrate that our method outperforms existing approaches in unsupervised outlier detection.
<div id='section'>Paperid: <span id='pid'>1729, <a href='https://arxiv.org/pdf/2312.15576.pdf' target='_blank'>https://arxiv.org/pdf/2312.15576.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shreyas Verma, Kien Tran, Yusuf Ali, Guangyu Min
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.15576">Reducing LLM Hallucinations using Epistemic Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reducing and detecting hallucinations in large language models is an open research problem. In this project, we attempt to leverage recent advances in the field of uncertainty estimation to reduce hallucinations in frozen large language models. Epistemic neural networks have recently been proposed to improve output joint distributions for large pre-trained models. ENNs are small networks attached to large, frozen models to improve the model's joint distributions and uncertainty estimates. In this work, we train an epistemic neural network on top of the Llama-2 7B model combined with a contrastive decoding feature enhancement technique. We are the first to train an ENN for the next token prediction task and explore the efficacy of this method in reducing hallucinations on the TruthfulQA dataset. In essence, we provide a method that leverages a pre-trained model's latent embeddings to reduce hallucinations.
<div id='section'>Paperid: <span id='pid'>1730, <a href='https://arxiv.org/pdf/2312.15288.pdf' target='_blank'>https://arxiv.org/pdf/2312.15288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tai Le-Gia, Jaehyun Ahn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.15288">Understanding normalization in contrastive representation learning and out-of-distribution detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contrastive representation learning has emerged as an outstanding approach for anomaly detection. In this work, we explore the $\ell_2$-norm of contrastive features and its applications in out-of-distribution detection. We propose a simple method based on contrastive learning, which incorporates out-of-distribution data by discriminating against normal samples in the contrastive layer space. Our approach can be applied flexibly as an outlier exposure (OE) approach, where the out-of-distribution data is a huge collective of random images, or as a fully self-supervised learning approach, where the out-of-distribution data is self-generated by applying distribution-shifting transformations. The ability to incorporate additional out-of-distribution samples enables a feasible solution for datasets where AD methods based on contrastive learning generally underperform, such as aerial images or microscopy images. Furthermore, the high-quality features learned through contrastive learning consistently enhance performance in OE scenarios, even when the available out-of-distribution dataset is not diverse enough. Our extensive experiments demonstrate the superiority of our proposed method under various scenarios, including unimodal and multimodal settings, with various image datasets.
<div id='section'>Paperid: <span id='pid'>1731, <a href='https://arxiv.org/pdf/2312.05459.pdf' target='_blank'>https://arxiv.org/pdf/2312.05459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Venkata Raghava Kurada, Pallava Kumar Baruah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.05459">FLoW3 -- Web3 Empowered Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated Learning is susceptible to various kinds of attacks like Data Poisoning, Model Poisoning and Man in the Middle attack. We perceive Federated Learning as a hierarchical structure, a federation of nodes with validators as the head. The process of validation is done through consensus by employing Novelty Detection and Snowball protocol, to identify valuable and relevant updates while filtering out potentially malicious or irrelevant updates, thus preventing Model Poisoning attacks. The opinion of the validators is recorded in blockchain and trust score is calculated. In case of lack of consensus, trust score is used to determine the impact of validators on the global model. A hyperparameter is introduced to guide the model generation process, either to rely on consensus or on trust score. This approach ensures transparency and reliability in the aggregation process and allows the global model to benefit from insights of most trusted nodes. In the training phase, the combination of IPFS , PGP encryption provides : a) secure and decentralized storage b) mitigates single point of failure making this system reliable and c) resilient against man in the middle attack. The system is realized by implementing in python and Foundry for smart contract development. Global Model is tested against data poisoning by flipping the labels and by introducing malicious nodes. Results found to be similar to that of Flower.
<div id='section'>Paperid: <span id='pid'>1732, <a href='https://arxiv.org/pdf/2312.03895.pdf' target='_blank'>https://arxiv.org/pdf/2312.03895.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>ClÃ©mence Allietta, Jean-Philippe Condomines, Jean-Yves Tourneret, Emmanuel Lochin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03895">HLoOP -- Hyperbolic 2-space Local Outlier Probabilities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hyperbolic geometry has recently garnered considerable attention in machine learning due to its capacity to embed hierarchical graph structures with low distortions for further downstream processing. This paper introduces a simple framework to detect local outliers for datasets grounded in hyperbolic 2-space referred to as HLoOP (Hyperbolic Local Outlier Probability). Within a Euclidean space, well-known techniques for local outlier detection are based on the Local Outlier Factor (LOF) and its variant, the LoOP (Local Outlier Probability), which incorporates probabilistic concepts to model the outlier level of a data vector. The developed HLoOP combines the idea of finding nearest neighbors, density-based outlier scoring with a probabilistic, statistically oriented approach. Therefore, the method consists in computing the Riemmanian distance of a data point to its nearest neighbors following a Gaussian probability density function expressed in a hyperbolic space. This is achieved by defining a Gaussian cumulative distribution in this space. The HLoOP algorithm is tested on the WordNet dataset yielding promising results. Code and data will be made available on request for reproductibility.
<div id='section'>Paperid: <span id='pid'>1733, <a href='https://arxiv.org/pdf/2312.02167.pdf' target='_blank'>https://arxiv.org/pdf/2312.02167.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>F. Terhag, P. Knechtges, A. Basermann, R. Tempone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.02167">Uncertainty Quantification in Machine Learning Based Segmentation: A Post-Hoc Approach for Left Ventricle Volume Estimation in MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent studies have confirmed cardiovascular diseases remain responsible for highest death toll amongst non-communicable diseases. Accurate left ventricular (LV) volume estimation is critical for valid diagnosis and management of various cardiovascular conditions, but poses significant challenge due to inherent uncertainties associated with segmentation algorithms in magnetic resonance imaging (MRI). Recent machine learning advancements, particularly U-Net-like convolutional networks, have facilitated automated segmentation for medical images, but struggles under certain pathologies and/or different scanner vendors and imaging protocols. This study proposes a novel methodology for post-hoc uncertainty estimation in LV volume prediction using ItÃ´ stochastic differential equations (SDEs) to model path-wise behavior for the prediction error. The model describes the area of the left ventricle along the heart's long axis. The method is agnostic to the underlying segmentation algorithm, facilitating its use with various existing and future segmentation technologies. The proposed approach provides a mechanism for quantifying uncertainty, enabling medical professionals to intervene for unreliable predictions. This is of utmost importance in critical applications such as medical diagnosis, where prediction accuracy and reliability can directly impact patient outcomes. The method is also robust to dataset changes, enabling application for medical centers with limited access to labeled data. Our findings highlight the proposed uncertainty estimation methodology's potential to enhance automated segmentation robustness and generalizability, paving the way for more reliable and accurate LV volume estimation in clinical settings as well as opening new avenues for uncertainty quantification in biomedical image segmentation, providing promising directions for future research.
<div id='section'>Paperid: <span id='pid'>1734, <a href='https://arxiv.org/pdf/2311.17093.pdf' target='_blank'>https://arxiv.org/pdf/2311.17093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Evelyn Mannix, Howard Bondell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.17093">A Mixture of Exemplars Approach for Efficient Out-of-Distribution Detection with Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One of the early weaknesses identified in deep neural networks trained for image classification tasks was their inability to provide low confidence predictions on out-of-distribution (OOD) data that was significantly different from the in-distribution (ID) data used to train them. Representation learning, where neural networks are trained in specific ways that improve their ability to detect OOD examples, has emerged as a promising solution. However, these approaches require long training times and can add additional overhead to detect OOD examples. Recent developments in Vision Transformer (ViT) foundation models$\unicode{x2013}$large networks trained on large and diverse datasets with self-supervised approaches$\unicode{x2013}$also show strong performance in OOD detection, and could address these challenges. This paper presents Mixture of Exemplars (MoLAR), an efficient approach to tackling OOD detection challenges that is designed to maximise the benefit of training a classifier with a high quality, frozen, pretrained foundation model backbone. MoLAR provides strong OOD detection performance when only comparing the similarity of OOD examples to the exemplars, a small set of images chosen to be representative of the dataset, leading to significantly reduced overhead for OOD detection inference over other methods that provide best performance when the full ID dataset is used. Extensive experiments demonstrate the improved OOD detection performance of MoLAR in comparison to comparable approaches in both supervised and semi-supervised settings, and code is available at github.com/emannix/molar-mixture-of-exemplars.
<div id='section'>Paperid: <span id='pid'>1735, <a href='https://arxiv.org/pdf/2311.13821.pdf' target='_blank'>https://arxiv.org/pdf/2311.13821.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Uddeshya Upadhyay, Sairam Bade, Arjun Puranik, Shahir Asfahan, Melwin Babu, Francisco Lopez-Jimenez, Samuel J. Asirvatham, Ashim Prasad, Ajit Rajasekharan, Samir Awasthi, Rakesh Barve
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13821">HypUC: Hyperfine Uncertainty Calibration with Gradient-boosted Corrections for Reliable Regression on Imbalanced Electrocardiograms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The automated analysis of medical time series, such as the electrocardiogram (ECG), electroencephalogram (EEG), pulse oximetry, etc, has the potential to serve as a valuable tool for diagnostic decisions, allowing for remote monitoring of patients and more efficient use of expensive and time-consuming medical procedures. Deep neural networks (DNNs) have been demonstrated to process such signals effectively. However, previous research has primarily focused on classifying medical time series rather than attempting to regress the continuous-valued physiological parameters central to diagnosis. One significant challenge in this regard is the imbalanced nature of the dataset, as a low prevalence of abnormal conditions can lead to heavily skewed data that results in inaccurate predictions and a lack of certainty in such predictions when deployed. To address these challenges, we propose HypUC, a framework for imbalanced probabilistic regression in medical time series, making several contributions. (i) We introduce a simple kernel density-based technique to tackle the imbalanced regression problem with medical time series. (ii) Moreover, we employ a probabilistic regression framework that allows uncertainty estimation for the predicted continuous values. (iii) We also present a new approach to calibrate the predicted uncertainty further. (iv) Finally, we demonstrate a technique to use calibrated uncertainty estimates to improve the predicted continuous value and show the efficacy of the calibrated uncertainty estimates to flag unreliable predictions. HypUC is evaluated on a large, diverse, real-world dataset of ECGs collected from millions of patients, outperforming several conventional baselines on various diagnostic tasks, suggesting a potential use-case for the reliable clinical deployment of deep learning models.
<div id='section'>Paperid: <span id='pid'>1736, <a href='https://arxiv.org/pdf/2311.12076.pdf' target='_blank'>https://arxiv.org/pdf/2311.12076.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiuqing Dong, Yongbin Gao, Heng Zhou, Jun Cen, Yifan Yao, Sook Yoon, Park Dong Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12076">Towards Few-shot Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical for ensuring the reliability of open-world intelligent systems. Despite the notable advancements in existing OOD detection methodologies, our study identifies a significant performance drop under the scarcity of training samples. In this context, we introduce a novel few-shot OOD detection benchmark, carefully constructed to address this gap. Our empirical analysis reveals the superiority of ParameterEfficient Fine-Tuning (PEFT) strategies, such as visual prompt tuning and visual adapter tuning, over conventional techniques, including fully fine-tuning and linear probing tuning in the few-shot OOD detection task. Recognizing some crucial information from the pre-trained model, which is pivotal for OOD detection, may be lost during the fine-tuning process, we propose a method termed DomainSpecific and General Knowledge Fusion (DSGF). This approach is designed to be compatible with diverse fine-tuning frameworks. Our experiments show that the integration of DSGF significantly enhances the few-shot OOD detection capabilities across various methods and fine-tuning methodologies, including fully fine-tuning, visual adapter tuning, and visual prompt tuning. The code will be released.
<div id='section'>Paperid: <span id='pid'>1737, <a href='https://arxiv.org/pdf/2311.09639.pdf' target='_blank'>https://arxiv.org/pdf/2311.09639.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sirui Bi, Victor Fung, Jiaxin Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09639">On the Quantification of Image Reconstruction Uncertainty without Training Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational imaging plays a pivotal role in determining hidden information from sparse measurements. A robust inverse solver is crucial to fully characterize the uncertainty induced by these measurements, as it allows for the estimation of the complete posterior of unrecoverable targets. This, in turn, facilitates a probabilistic interpretation of observational data for decision-making. In this study, we propose a deep variational framework that leverages a deep generative model to learn an approximate posterior distribution to effectively quantify image reconstruction uncertainty without the need for training data. We parameterize the target posterior using a flow-based model and minimize their Kullback-Leibler (KL) divergence to achieve accurate uncertainty estimation. To bolster stability, we introduce a robust flow-based model with bi-directional regularization and enhance expressivity through gradient boosting. Additionally, we incorporate a space-filling design to achieve substantial variance reduction on both latent prior space and target posterior space. We validate our method on several benchmark tasks and two real-world applications, namely fastMRI and black hole image reconstruction. Our results indicate that our method provides reliable and high-quality image reconstruction with robust uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1738, <a href='https://arxiv.org/pdf/2311.09145.pdf' target='_blank'>https://arxiv.org/pdf/2311.09145.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrea Pugnana, Carlos Mougan, Dan Saattrup Nielsen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09145">Model Agnostic Explainable Selective Regression via Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the wide adoption of machine learning techniques, requirements have evolved beyond sheer high performance, often requiring models to be trustworthy. A common approach to increase the trustworthiness of such systems is to allow them to refrain from predicting. Such a framework is known as selective prediction. While selective prediction for classification tasks has been widely analyzed, the problem of selective regression is understudied. This paper presents a novel approach to selective regression that utilizes model-agnostic non-parametric uncertainty estimation. Our proposed framework showcases superior performance compared to state-of-the-art selective regressors, as demonstrated through comprehensive benchmarking on 69 datasets. Finally, we use explainable AI techniques to gain an understanding of the drivers behind selective regression. We implement our selective regression method in the open-source Python package doubt and release the code used to reproduce our experiments.
<div id='section'>Paperid: <span id='pid'>1739, <a href='https://arxiv.org/pdf/2311.03722.pdf' target='_blank'>https://arxiv.org/pdf/2311.03722.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seongwook Yoon, Jaehyun Kim, Sanghoon Sull
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.03722">Inertial Guided Uncertainty Estimation of Feature Correspondence in Visual-Inertial Odometry/SLAM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual odometry and Simultaneous Localization And Mapping (SLAM) has been studied as one of the most important tasks in the areas of computer vision and robotics, to contribute to autonomous navigation and augmented reality systems. In case of feature-based odometry/SLAM, a moving visual sensor observes a set of 3D points from different viewpoints, correspondences between the projected 2D points in each image are usually established by feature tracking and matching. However, since the corresponding point could be erroneous and noisy, reliable uncertainty estimation can improve the accuracy of odometry/SLAM methods. In addition, inertial measurement unit is utilized to aid the visual sensor in terms of Visual-Inertial fusion. In this paper, we propose a method to estimate the uncertainty of feature correspondence using an inertial guidance robust to image degradation caused by motion blur, illumination change and occlusion. Modeling a guidance distribution to sample possible correspondence, we fit the distribution to an energy function based on image error, yielding more robust uncertainty than conventional methods. We also demonstrate the feasibility of our approach by incorporating it into one of recent visual-inertial odometry/SLAM algorithms for public datasets.
<div id='section'>Paperid: <span id='pid'>1740, <a href='https://arxiv.org/pdf/2311.00808.pdf' target='_blank'>https://arxiv.org/pdf/2311.00808.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Connor Mclaughlin, Jason Matterer, Michael Yee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00808">Mahalanobis-Aware Training for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While deep learning models have seen widespread success in controlled environments, there are still barriers to their adoption in open-world settings. One critical task for safe deployment is the detection of anomalous or out-of-distribution samples that may require human intervention. In this work, we present a novel loss function and recipe for training networks with improved density-based out-of-distribution sensitivity. We demonstrate the effectiveness of our method on CIFAR-10, notably reducing the false-positive rate of the relative Mahalanobis distance method on far-OOD tasks by over 50%.
<div id='section'>Paperid: <span id='pid'>1741, <a href='https://arxiv.org/pdf/2310.19119.pdf' target='_blank'>https://arxiv.org/pdf/2310.19119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianhao Zhang, Shenglin Wang, Nidhal Bouaynaya, Radu Calinescu, Lyudmila Mihaylova
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19119">Out-of-distribution Object Detection through Bayesian Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The superior performance of object detectors is often established under the condition that the test samples are in the same distribution as the training data. However, in many practical applications, out-of-distribution (OOD) instances are inevitable and usually lead to uncertainty in the results. In this paper, we propose a novel, intuitive, and scalable probabilistic object detection method for OOD detection. Unlike other uncertainty-modeling methods that either require huge computational costs to infer the weight distributions or rely on model training through synthetic outlier data, our method is able to distinguish between in-distribution (ID) data and OOD data via weight parameter sampling from proposed Gaussian distributions based on pre-trained networks. We demonstrate that our Bayesian object detector can achieve satisfactory OOD identification performance by reducing the FPR95 score by up to 8.19% and increasing the AUROC score by up to 13.94% when trained on BDD100k and VOC datasets as the ID datasets and evaluated on COCO2017 dataset as the OOD dataset.
<div id='section'>Paperid: <span id='pid'>1742, <a href='https://arxiv.org/pdf/2310.18108.pdf' target='_blank'>https://arxiv.org/pdf/2310.18108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ulysse Gazin, Gilles Blanchard, Etienne Roquain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18108">Transductive conformal inference with adaptive scores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conformal inference is a fundamental and versatile tool that provides distribution-free guarantees for many machine learning tasks. We consider the transductive setting, where decisions are made on a test sample of $m$ new points, giving rise to $m$ conformal $p$-values. While classical results only concern their marginal distribution, we show that their joint distribution follows a PÃ³lya urn model, and establish a concentration inequality for their empirical distribution function. The results hold for arbitrary exchangeable scores, including adaptive ones that can use the covariates of the test+calibration samples at training stage for increased accuracy. We demonstrate the usefulness of these theoretical results through uniform, in-probability guarantees for two machine learning tasks of current interest: interval prediction for transductive transfer learning and novelty detection based on two-class classification.
<div id='section'>Paperid: <span id='pid'>1743, <a href='https://arxiv.org/pdf/2310.17432.pdf' target='_blank'>https://arxiv.org/pdf/2310.17432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joseph Goodier, Neill D. F. Campbell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.17432">Likelihood-based Out-of-Distribution Detection with Denoising Diffusion Probabilistic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-Distribution detection between dataset pairs has been extensively explored with generative models. We show that likelihood-based Out-of-Distribution detection can be extended to diffusion models by leveraging the fact that they, like other likelihood-based generative models, are dramatically affected by the input sample complexity. Currently, all Out-of-Distribution detection methods with Diffusion Models are reconstruction-based. We propose a new likelihood ratio for Out-of-Distribution detection with Deep Denoising Diffusion Models, which we call the Complexity Corrected Likelihood Ratio. Our likelihood ratio is constructed using Evidence Lower-Bound evaluations from an individual model at various noising levels. We present results that are comparable to state-of-the-art Out-of-Distribution detection methods with generative models.
<div id='section'>Paperid: <span id='pid'>1744, <a href='https://arxiv.org/pdf/2310.14864.pdf' target='_blank'>https://arxiv.org/pdf/2310.14864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenfan Weng, Zhongguo Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14864">Diverse Priors for Deep Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In Reinforcement Learning (RL), agents aim at maximizing cumulative rewards in a given environment. During the learning process, RL agents face the dilemma of exploitation and exploration: leveraging existing knowledge to acquire rewards or seeking potentially higher ones. Using uncertainty as a guiding principle provides an active and effective approach to solving this dilemma and ensemble-based methods are one of the prominent avenues for quantifying uncertainty. Nevertheless, conventional ensemble-based uncertainty estimation lacks an explicit prior, deviating from Bayesian principles. Besides, this method requires diversity among members to generate less biased uncertainty estimation results. To address the above problems, previous research has incorporated random functions as priors. Building upon these foundational efforts, our work introduces an innovative approach with delicately designed prior NNs, which can incorporate maximal diversity in the initial value functions of RL. Our method has demonstrated superior performance compared with the random prior approaches in solving classic control problems and general exploration tasks, significantly improving sample efficiency.
<div id='section'>Paperid: <span id='pid'>1745, <a href='https://arxiv.org/pdf/2310.14063.pdf' target='_blank'>https://arxiv.org/pdf/2310.14063.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditya Kapoor, Vartika Sengar, Nijil George, Vighnesh Vatsal, Jayavardhana Gubbi, Balamuralidhar P, Arpan Pal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14063">Concept-based Anomaly Detection in Retail Stores for Automatic Correction using Mobile Robots</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tracking of inventory and rearrangement of misplaced items are some of the most labor-intensive tasks in a retail environment. While there have been attempts at using vision-based techniques for these tasks, they mostly use planogram compliance for detection of any anomalies, a technique that has been found lacking in robustness and scalability. Moreover, existing systems rely on human intervention to perform corrective actions after detection. In this paper, we present Co-AD, a Concept-based Anomaly Detection approach using a Vision Transformer (ViT) that is able to flag misplaced objects without using a prior knowledge base such as a planogram. It uses an auto-encoder architecture followed by outlier detection in the latent space. Co-AD has a peak success rate of 89.90% on anomaly detection image sets of retail objects drawn from the RP2K dataset, compared to 80.81% on the best-performing baseline of a standard ViT auto-encoder. To demonstrate its utility, we describe a robotic mobile manipulation pipeline to autonomously correct the anomalies flagged by Co-AD. This work is ultimately aimed towards developing autonomous mobile robot solutions that reduce the need for human intervention in retail store management.
<div id='section'>Paperid: <span id='pid'>1746, <a href='https://arxiv.org/pdf/2310.11532.pdf' target='_blank'>https://arxiv.org/pdf/2310.11532.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jie Pu, Thai-Son Nguyen, Sebastian StÃ¼ker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11532">Multi-stage Large Language Model Correction for Speech Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we investigate the usage of large language models (LLMs) to improve the performance of competitive speech recognition systems. Different from previous LLM-based ASR error correction methods, we propose a novel multi-stage approach that utilizes uncertainty estimation of ASR outputs and reasoning capability of LLMs. Specifically, the proposed approach has two stages: the first stage is about ASR uncertainty estimation and exploits N-best list hypotheses to identify less reliable transcriptions; The second stage works on these identified transcriptions and performs LLM-based corrections. This correction task is formulated as a multi-step rule-based LLM reasoning process, which uses explicitly written rules in prompts to decompose the task into concrete reasoning steps. Our experimental results demonstrate the effectiveness of the proposed method by showing 10% ~ 20% relative improvement in WER over competitive ASR systems -- across multiple test domains and in zero-shot settings.
<div id='section'>Paperid: <span id='pid'>1747, <a href='https://arxiv.org/pdf/2310.08390.pdf' target='_blank'>https://arxiv.org/pdf/2310.08390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiyang Yan, Zongxuan Liu, Lin Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08390">Hyp-UML: Hyperbolic Image Retrieval with Uncertainty-aware Metric Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Metric learning plays a critical role in training image retrieval and classification. It is also a key algorithm in representation learning, e.g., for feature learning and its alignment in metric space. Hyperbolic embedding has been recently developed. Compared to the conventional Euclidean embedding in most of the previously developed models, Hyperbolic embedding can be more effective in representing the hierarchical data structure. Second, uncertainty estimation/measurement is a long-lasting challenge in artificial intelligence. Successful uncertainty estimation can improve a machine learning model's performance, robustness, and security. In Hyperbolic space, uncertainty measurement is at least with equivalent, if not more, critical importance. In this paper, we develop a Hyperbolic image embedding with uncertainty-aware metric learning for image retrieval. We call our method Hyp-UML: Hyperbolic Uncertainty-aware Metric Learning. Our contribution are threefold: we propose an image embedding algorithm based on Hyperbolic space, with their corresponding uncertainty value; we propose two types of uncertainty-aware metric learning, for the popular Contrastive learning and conventional margin-based metric learning, respectively. We perform extensive experimental validations to prove that the proposed algorithm can achieve state-of-the-art results among related methods. The comprehensive ablation study validates the effectiveness of each component of the proposed algorithm.
<div id='section'>Paperid: <span id='pid'>1748, <a href='https://arxiv.org/pdf/2310.07376.pdf' target='_blank'>https://arxiv.org/pdf/2310.07376.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kosuke Nakayama, Hiroto Fukuta, Hiroshi Watanabe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07376">Point Cloud Denoising and Outlier Detection with Local Geometric Structure by Dynamic Graph CNN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The digitalization of society is rapidly developing toward the realization of the digital twin and metaverse. In particular, point clouds are attracting attention as a media format for 3D space. Point cloud data is contaminated with noise and outliers due to measurement errors. Therefore, denoising and outlier detection are necessary for point cloud processing. Among them, PointCleanNet is an effective method for point cloud denoising and outlier detection. However, it does not consider the local geometric structure of the patch. We solve this problem by applying two types of graph convolutional layer designed based on the Dynamic Graph CNN. Experimental results show that the proposed methods outperform the conventional method in AUPR, which indicates outlier detection accuracy, and Chamfer Distance, which indicates denoising accuracy.
<div id='section'>Paperid: <span id='pid'>1749, <a href='https://arxiv.org/pdf/2309.15130.pdf' target='_blank'>https://arxiv.org/pdf/2309.15130.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julio J. ValdÃ©s, Alain B. Tchagang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.15130">Understanding the Structure of QM7b and QM9 Quantum Mechanical Datasets Using Unsupervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores the internal structure of two quantum mechanics datasets (QM7b, QM9), composed of several thousands of organic molecules and described in terms of electronic properties. Understanding the structure and characteristics of this kind of data is important when predicting the atomic composition from the properties in inverse molecular designs. Intrinsic dimension analysis, clustering, and outlier detection methods were used in the study. They revealed that for both datasets the intrinsic dimensionality is several times smaller than the descriptive dimensions. The QM7b data is composed of well defined clusters related to atomic composition. The QM9 data consists of an outer region predominantly composed of outliers, and an inner core region that concentrates clustered, inliner objects. A significant relationship exists between the number of atoms in the molecule and its outlier/inner nature. Despite the structural differences, the predictability of variables of interest for inverse molecular design is high. This is exemplified with models estimating the number of atoms of the molecule from both the original properties, and from lower dimensional embedding spaces.
<div id='section'>Paperid: <span id='pid'>1750, <a href='https://arxiv.org/pdf/2309.11450.pdf' target='_blank'>https://arxiv.org/pdf/2309.11450.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hichem Dhouib, Alissa Wilms, Paul Boes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.11450">Distribution and volume based scoring for Isolation Forests</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We make two contributions to the Isolation Forest method for anomaly and outlier detection. The first contribution is an information-theoretically motivated generalisation of the score function that is used to aggregate the scores across random tree estimators. This generalisation allows one to take into account not just the ensemble average across trees but instead the whole distribution. The second contribution is an alternative scoring function at the level of the individual tree estimator, in which we replace the depth-based scoring of the Isolation Forest with one based on hyper-volumes associated to an isolation tree's leaf nodes.
  We motivate the use of both of these methods on generated data and also evaluate them on 34 datasets from the recent and exhaustive ``ADBench'' benchmark, finding significant improvement over the standard isolation forest for both variants on some datasets and improvement on average across all datasets for one of the two variants. The code to reproduce our results is made available as part of the submission.
<div id='section'>Paperid: <span id='pid'>1751, <a href='https://arxiv.org/pdf/2309.10513.pdf' target='_blank'>https://arxiv.org/pdf/2309.10513.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qasim M. K. Siddiqui, Sebastian Starke, Peter Steinbach
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10513">Uncertainty Estimation in Instance Segmentation with Star-convex Shapes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Instance segmentation has witnessed promising advancements through deep neural network-based algorithms. However, these models often exhibit incorrect predictions with unwarranted confidence levels. Consequently, evaluating prediction uncertainty becomes critical for informed decision-making. Existing methods primarily focus on quantifying uncertainty in classification or regression tasks, lacking emphasis on instance segmentation. Our research addresses the challenge of estimating spatial certainty associated with the location of instances with star-convex shapes. Two distinct clustering approaches are evaluated which compute spatial and fractional certainty per instance employing samples by the Monte-Carlo Dropout or Deep Ensemble technique. Our study demonstrates that combining spatial and fractional certainty scores yields improved calibrated estimation over individual certainty scores. Notably, our experimental results show that the Deep Ensemble technique alongside our novel radial clustering approach proves to be an effective strategy. Our findings emphasize the significance of evaluating the calibration of estimated certainties for model reliability and decision-making.
<div id='section'>Paperid: <span id='pid'>1752, <a href='https://arxiv.org/pdf/2309.06655.pdf' target='_blank'>https://arxiv.org/pdf/2309.06655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alonso Marco, Elias Morley, Claire J. Tomlin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.06655">Out of Distribution Detection via Domain-Informed Gaussian Process State Space Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In order for robots to safely navigate in unseen scenarios using learning-based methods, it is important to accurately detect out-of-training-distribution (OoD) situations online. Recently, Gaussian process state-space models (GPSSMs) have proven useful to discriminate unexpected observations by comparing them against probabilistic predictions. However, the capability for the model to correctly distinguish between in- and out-of-training distribution observations hinges on the accuracy of these predictions, primarily affected by the class of functions the GPSSM kernel can represent. In this paper, we propose (i) a novel approach to embed existing domain knowledge in the kernel and (ii) an OoD online runtime monitor, based on receding-horizon predictions. Domain knowledge is provided in the form of a dataset, collected either in simulation or by using a nominal model. Numerical results show that the informed kernel yields better regression quality with smaller datasets, as compared to standard kernel choices. We demonstrate the effectiveness of the OoD monitor on a real quadruped navigating an indoor setting, which reliably classifies previously unseen terrains.
<div id='section'>Paperid: <span id='pid'>1753, <a href='https://arxiv.org/pdf/2309.06628.pdf' target='_blank'>https://arxiv.org/pdf/2309.06628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atticus Beachy, Harok Bae, Jose Camberos, Ramana Grandhi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.06628">Epistemic Modeling Uncertainty of Rapid Neural Network Ensembles for Adaptive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Emulator embedded neural networks, which are a type of physics informed neural network, leverage multi-fidelity data sources for efficient design exploration of aerospace engineering systems. Multiple realizations of the neural network models are trained with different random initializations. The ensemble of model realizations is used to assess epistemic modeling uncertainty caused due to lack of training samples. This uncertainty estimation is crucial information for successful goal-oriented adaptive learning in an aerospace system design exploration. However, the costs of training the ensemble models often become prohibitive and pose a computational challenge, especially when the models are not trained in parallel during adaptive learning. In this work, a new type of emulator embedded neural network is presented using the rapid neural network paradigm. Unlike the conventional neural network training that optimizes the weights and biases of all the network layers by using gradient-based backpropagation, rapid neural network training adjusts only the last layer connection weights by applying a linear regression technique. It is found that the proposed emulator embedded neural network trains near-instantaneously, typically without loss of prediction accuracy. The proposed method is demonstrated on multiple analytical examples, as well as an aerospace flight parameter study of a generic hypersonic vehicle.
<div id='section'>Paperid: <span id='pid'>1754, <a href='https://arxiv.org/pdf/2309.05630.pdf' target='_blank'>https://arxiv.org/pdf/2309.05630.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sheikh Arafat, Na Sun, Maria L. Weese, Waldyn G. Martinez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05630">Boundary Peeling: Outlier Detection Method Using One-Class Peeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised outlier detection constitutes a crucial phase within data analysis and remains a dynamic realm of research. A good outlier detection algorithm should be computationally efficient, robust to tuning parameter selection, and perform consistently well across diverse underlying data distributions. We introduce One-Class Boundary Peeling, an unsupervised outlier detection algorithm. One-class Boundary Peeling uses the average signed distance from iteratively-peeled, flexible boundaries generated by one-class support vector machines. One-class Boundary Peeling has robust hyperparameter settings and, for increased flexibility, can be cast as an ensemble method. In synthetic data simulations One-Class Boundary Peeling outperforms all state of the art methods when no outliers are present while maintaining comparable or superior performance in the presence of outliers, as compared to benchmark methods. One-Class Boundary Peeling performs competitively in terms of correct classification, AUC, and processing time using common benchmark data sets.
<div id='section'>Paperid: <span id='pid'>1755, <a href='https://arxiv.org/pdf/2309.04799.pdf' target='_blank'>https://arxiv.org/pdf/2309.04799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhengru Wang, Xin Wang, Shuhao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04799">MOStream: A Modular and Self-Optimizing Data Stream Clustering Algorithm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data stream clustering is a critical operation in various real-world applications, ranging from the Internet of Things (IoT) to social media and financial systems. Existing data stream clustering algorithms, while effective to varying extents, often lack the flexibility and self-optimization capabilities needed to adapt to diverse workload characteristics such as outlier, cluster evolution and changing dimensions in data points. These limitations manifest in suboptimal clustering accuracy and computational inefficiency. In this paper, we introduce MOStream, a modular and self-optimizing data stream clustering algorithm designed to dynamically balance clustering accuracy and computational efficiency at runtime. MOStream distinguishes itself by its adaptivity, clearly demarcating four pivotal design dimensions: the summarizing data structure, the window model for handling data temporality, the outlier detection mechanism, and the refinement strategy for improving cluster quality. This clear separation facilitates flexible adaptation to varying design choices and enhances its adaptability to a wide array of application contexts. We conduct a rigorous performance evaluation of MOStream, employing diverse configurations and benchmarking it against 9 representative data stream clustering algorithms on 4 real-world datasets and 3 synthetic datasets. Our empirical results demonstrate that MOStream consistently surpasses competing algorithms in terms of clustering accuracy, processing throughput, and adaptability to varying data stream characteristics.
<div id='section'>Paperid: <span id='pid'>1756, <a href='https://arxiv.org/pdf/2309.02551.pdf' target='_blank'>https://arxiv.org/pdf/2309.02551.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abe Ejilemele, Jorge Mendez-Mendez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02551">Continual Improvement of Threshold-Based Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When evaluated in dynamic, open-world situations, neural networks struggle to detect unseen classes. This issue complicates the deployment of continual learners in realistic environments where agents are not explicitly informed when novel categories are encountered. A common family of techniques for detecting novelty relies on thresholds of similarity between observed data points and the data used for training. However, these methods often require manually specifying (ahead of time) the value of these thresholds, and are therefore incapable of adapting to the nature of the data. We propose a new method for automatically selecting these thresholds utilizing a linear search and leave-one-out cross-validation on the ID classes. We demonstrate that this novel method for selecting thresholds results in improved total accuracy on MNIST, Fashion MNIST, and CIFAR-10.
<div id='section'>Paperid: <span id='pid'>1757, <a href='https://arxiv.org/pdf/2309.01312.pdf' target='_blank'>https://arxiv.org/pdf/2309.01312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Audrey Paleczny, Shubham Parab, Maxwell Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.01312">Enhancing Automated and Early Detection of Alzheimer's Disease Using Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>More than 10.7% of people aged 65 and older are affected by Alzheimer's disease. Early diagnosis and treatment are crucial as most Alzheimer's patients are unaware of having it until the effects become detrimental. AI has been known to use magnetic resonance imaging (MRI) to diagnose Alzheimer's. However, models which produce low rates of false diagnoses are critical to prevent unnecessary treatments. Thus, we trained supervised Random Forest models with segmented brain volumes and Convolutional Neural Network (CNN) outputs to classify different Alzheimer's stages. We then applied out-of-distribution (OOD) detection to the CNN model, enabling it to report OOD if misclassification is likely, thereby reducing false diagnoses. With an accuracy of 98% for detection and 95% for classification, our model based on CNN results outperformed our segmented volume model, which had detection and classification accuracies of 93% and 87%, respectively. Applying OOD detection to the CNN model enabled it to flag brain tumor images as OOD with 96% accuracy and minimal overall accuracy reduction. By using OOD detection to enhance the reliability of MRI classification using CNNs, we lowered the rate of false positives and eliminated a significant disadvantage of using Machine Learning models for healthcare tasks. Source code available upon request.
<div id='section'>Paperid: <span id='pid'>1758, <a href='https://arxiv.org/pdf/2308.08465.pdf' target='_blank'>https://arxiv.org/pdf/2308.08465.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyu Bai, Wenjia Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08465">Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning a medical image segmentation model is an inherently ambiguous task, as uncertainties exist in both images (noise) and manual annotations (human errors and bias) used for model training. To build a trustworthy image segmentation model, it is important to not just evaluate its performance but also estimate the uncertainty of the model prediction. Most state-of-the-art image segmentation networks adopt a hierarchical encoder architecture, extracting image features at multiple resolution levels from fine to coarse. In this work, we leverage this hierarchical image representation and propose a simple yet effective method for estimating uncertainties at multiple levels. The multi-level uncertainties are modelled via the skip-connection module and then sampled to generate an uncertainty map for the predicted image segmentation. We demonstrate that a deep learning segmentation network such as U-net, when implemented with such hierarchical uncertainty estimation module, can achieve a high segmentation performance, while at the same time provide meaningful uncertainty maps that can be used for out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>1759, <a href='https://arxiv.org/pdf/2308.07477.pdf' target='_blank'>https://arxiv.org/pdf/2308.07477.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Baumann, Thomas RoÃberg, Michael Schmitt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07477">Probabilistic MIMO U-Net: Efficient and Accurate Uncertainty Estimation for Pixel-wise Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty estimation in machine learning is paramount for enhancing the reliability and interpretability of predictive models, especially in high-stakes real-world scenarios. Despite the availability of numerous methods, they often pose a trade-off between the quality of uncertainty estimation and computational efficiency. Addressing this challenge, we present an adaptation of the Multiple-Input Multiple-Output (MIMO) framework -- an approach exploiting the overparameterization of deep neural networks -- for pixel-wise regression tasks. Our MIMO variant expands the applicability of the approach from simple image classification to broader computer vision domains. For that purpose, we adapted the U-Net architecture to train multiple subnetworks within a single model, harnessing the overparameterization in deep neural networks. Additionally, we introduce a novel procedure for synchronizing subnetwork performance within the MIMO framework. Our comprehensive evaluations of the resulting MIMO U-Net on two orthogonal datasets demonstrate comparable accuracy to existing models, superior calibration on in-distribution data, robust out-of-distribution detection capabilities, and considerable improvements in parameter size and inference time. Code available at github.com/antonbaumann/MIMO-Unet
<div id='section'>Paperid: <span id='pid'>1760, <a href='https://arxiv.org/pdf/2308.07441.pdf' target='_blank'>https://arxiv.org/pdf/2308.07441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lianfa Li, Roxana Khalili, Frederick Lurmann, Nathan Pavlovic, Jun Wu, Yan Xu, Yisi Liu, Karl O'Sharkey, Beate Ritz, Luke Oman, Meredith Franklin, Theresa Bastain, Shohreh F. Farzan, Carrie Breton, Rima Habre
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07441">Physics-Informed Deep Learning to Reduce the Bias in Joint Prediction of Nitrogen Oxides</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Atmospheric nitrogen oxides (NOx) primarily from fuel combustion have recognized acute and chronic health and environmental effects. Machine learning (ML) methods have significantly enhanced our capacity to predict NOx concentrations at ground-level with high spatiotemporal resolution but may suffer from high estimation bias since they lack physical and chemical knowledge about air pollution dynamics. Chemical transport models (CTMs) leverage this knowledge; however, accurate predictions of ground-level concentrations typically necessitate extensive post-calibration. Here, we present a physics-informed deep learning framework that encodes advection-diffusion mechanisms and fluid dynamics constraints to jointly predict NO2 and NOx and reduce ML model bias by 21-42%. Our approach captures fine-scale transport of NO2 and NOx, generates robust spatial extrapolation, and provides explicit uncertainty estimation. The framework fuses knowledge-driven physicochemical principles of CTMs with the predictive power of ML for air quality exposure, health, and policy applications. Our approach offers significant improvements over purely data-driven ML methods and has unprecedented bias reduction in joint NO2 and NOx prediction.
<div id='section'>Paperid: <span id='pid'>1761, <a href='https://arxiv.org/pdf/2308.07072.pdf' target='_blank'>https://arxiv.org/pdf/2308.07072.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shangxuan Li, Yu Du, Li Ye, Chichi Li, Yanshu Fang, Cheng Wang, Wu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07072">Teeth And Root Canals Segmentation Using ZXYFormer With Uncertainty Guidance And Weight Transfer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study attempts to segment teeth and root-canals simultaneously from CBCT images, but there are very challenging problems in this process. First, the clinical CBCT image data is very large (e.g., 672 *688 * 688), and the use of downsampling operation will lose useful information about teeth and root canals. Second, teeth and root canals are very different in morphology, and it is difficult for a simple network to identify them precisely. In addition, there are weak edges at the tooth, between tooth and root canal, which makes it very difficult to segment such weak edges. To this end, we propose a coarse-to-fine segmentation method based on inverse feature fusion transformer and uncertainty estimation to address above challenging problems. First, we use the downscaled volume data (e.g., 128 * 128 * 128) to conduct coarse segmentation and map it to the original volume to obtain the area of teeth and root canals. Then, we design a transformer with reverse feature fusion, which can bring better segmentation effect of different morphological objects by transferring deeper features to shallow features. Finally, we design an auxiliary branch to calculate and refine the difficult areas in order to improve the weak edge segmentation performance of teeth and root canals. Through the combined tooth and root canal segmentation experiment of 157 clinical high-resolution CBCT data, it is verified that the proposed method is superior to the existing tooth or root canal segmentation methods.
<div id='section'>Paperid: <span id='pid'>1762, <a href='https://arxiv.org/pdf/2308.06714.pdf' target='_blank'>https://arxiv.org/pdf/2308.06714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Song, Donglin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06714">Learning on Graphs with Out-of-Distribution Nodes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) are state-of-the-art models for performing prediction tasks on graphs. While existing GNNs have shown great performance on various tasks related to graphs, little attention has been paid to the scenario where out-of-distribution (OOD) nodes exist in the graph during training and inference. Borrowing the concept from CV and NLP, we define OOD nodes as nodes with labels unseen from the training set. Since a lot of networks are automatically constructed by programs, real-world graphs are often noisy and may contain nodes from unknown distributions. In this work, we define the problem of graph learning with out-of-distribution nodes. Specifically, we aim to accomplish two tasks: 1) detect nodes which do not belong to the known distribution and 2) classify the remaining nodes to be one of the known classes. We demonstrate that the connection patterns in graphs are informative for outlier detection, and propose Out-of-Distribution Graph Attention Network (OODGAT), a novel GNN model which explicitly models the interaction between different kinds of nodes and separate inliers from outliers during feature propagation. Extensive experiments show that OODGAT outperforms existing outlier detection methods by a large margin, while being better or comparable in terms of in-distribution classification.
<div id='section'>Paperid: <span id='pid'>1763, <a href='https://arxiv.org/pdf/2308.06299.pdf' target='_blank'>https://arxiv.org/pdf/2308.06299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hendrik Vogt, Stefan Buehler, Mark Schutera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06299">Defensive Perception: Estimation and Monitoring of Neural Network Performance under Deployment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a method for addressing the issue of unnoticed catastrophic deployment and domain shift in neural networks for semantic segmentation in autonomous driving. Our approach is based on the idea that deep learning-based perception for autonomous driving is uncertain and best represented as a probability distribution. As autonomous vehicles' safety is paramount, it is crucial for perception systems to recognize when the vehicle is leaving its operational design domain, anticipate hazardous uncertainty, and reduce the performance of the perception system. To address this, we propose to encapsulate the neural network under deployment within an uncertainty estimation envelope that is based on the epistemic uncertainty estimation through the Monte Carlo Dropout approach. This approach does not require modification of the deployed neural network and guarantees expected model performance. Our defensive perception envelope has the capability to estimate a neural network's performance, enabling monitoring and notification of entering domains of reduced neural network performance under deployment. Furthermore, our envelope is extended by novel methods to improve the application in deployment settings, including reducing compute expenses and confining estimation noise. Finally, we demonstrate the applicability of our method for multiple different potential deployment shifts relevant to autonomous driving, such as transitions into the night, rainy, or snowy domain. Overall, our approach shows great potential for application in deployment settings and enables operational design domain recognition via uncertainty, which allows for defensive perception, safe state triggers, warning notifications, and feedback for testing or development and adaptation of the perception stack.
<div id='section'>Paperid: <span id='pid'>1764, <a href='https://arxiv.org/pdf/2308.05120.pdf' target='_blank'>https://arxiv.org/pdf/2308.05120.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edward Chen, Han Bao, Nam Dinh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05120">Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation & Control Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, the field of data-driven neural network-based machine learning (ML) algorithms has grown significantly and spurred research in its applicability to instrumentation and control systems. While they are promising in operational contexts, the trustworthiness of such algorithms is not adequately assessed. Failures of ML-integrated systems are poorly understood; the lack of comprehensive risk modeling can degrade the trustworthiness of these systems. In recent reports by the National Institute for Standards and Technology, trustworthiness in ML is a critical barrier to adoption and will play a vital role in intelligent systems' safe and accountable operation. Thus, in this work, we demonstrate a real-time model-agnostic method to evaluate the relative reliability of ML predictions by incorporating out-of-distribution detection on the training dataset. It is well documented that ML algorithms excel at interpolation (or near-interpolation) tasks but significantly degrade at extrapolation. This occurs when new samples are "far" from training samples. The method, referred to as the Laplacian distributed decay for reliability (LADDR), determines the difference between the operational and training datasets, which is used to calculate a prediction's relative reliability. LADDR is demonstrated on a feedforward neural network-based model used to predict safety significant factors during different loss-of-flow transients. LADDR is intended as a "data supervisor" and determines the appropriateness of well-trained ML models in the context of operational conditions. Ultimately, LADDR illustrates how training data can be used as evidence to support the trustworthiness of ML predictions when utilized for conventional interpolation tasks.
<div id='section'>Paperid: <span id='pid'>1765, <a href='https://arxiv.org/pdf/2308.01271.pdf' target='_blank'>https://arxiv.org/pdf/2308.01271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masoumeh Javanbakhat, Christoph Lippert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.01271">A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.
<div id='section'>Paperid: <span id='pid'>1766, <a href='https://arxiv.org/pdf/2307.12301.pdf' target='_blank'>https://arxiv.org/pdf/2307.12301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen-Han Tsai, Yu-Shao Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.12301">Image Outlier Detection Without Training using RANSAC</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image outlier detection (OD) is an essential tool to ensure the quality of images used in computer vision tasks. Existing algorithms often involve training a model to represent the inlier distribution, and outliers are determined by some deviation measure. Although existing methods proved effective when trained on strictly inlier samples, their performance remains questionable when undesired outliers are included during training. As a result of this limitation, it is necessary to carefully examine the data when developing OD models for new domains. In this work, we present a novel image OD algorithm called RANSAC-NN that eliminates the need of data examination and model training altogether. Unlike existing approaches, RANSAC-NN can be directly applied on datasets containing outliers by sampling and comparing subsets of the data. Our algorithm maintains favorable performance compared to existing methods on a range of benchmarks. Furthermore, we show that RANSAC-NN can enhance the robustness of existing methods by incorporating our algorithm as part of the data preparation process.
<div id='section'>Paperid: <span id='pid'>1767, <a href='https://arxiv.org/pdf/2307.11823.pdf' target='_blank'>https://arxiv.org/pdf/2307.11823.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehmet Kerim Yucel, Ramazan Gokberk Cinbis, Pinar Duygulu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.11823">HybridAugment++: Unified Frequency Spectra Perturbations for Model Robustness</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Convolutional Neural Networks (CNN) are known to exhibit poor generalization performance under distribution shifts. Their generalization have been studied extensively, and one line of work approaches the problem from a frequency-centric perspective. These studies highlight the fact that humans and CNNs might focus on different frequency components of an image. First, inspired by these observations, we propose a simple yet effective data augmentation method HybridAugment that reduces the reliance of CNNs on high-frequency components, and thus improves their robustness while keeping their clean accuracy high. Second, we propose HybridAugment++, which is a hierarchical augmentation method that attempts to unify various frequency-spectrum augmentations. HybridAugment++ builds on HybridAugment, and also reduces the reliance of CNNs on the amplitude component of images, and promotes phase information instead. This unification results in competitive to or better than state-of-the-art results on clean accuracy (CIFAR-10/100 and ImageNet), corruption benchmarks (ImageNet-C, CIFAR-10-C and CIFAR-100-C), adversarial robustness on CIFAR-10 and out-of-distribution detection on various datasets. HybridAugment and HybridAugment++ are implemented in a few lines of code, does not require extra data, ensemble models or additional networks.
<div id='section'>Paperid: <span id='pid'>1768, <a href='https://arxiv.org/pdf/2307.11239.pdf' target='_blank'>https://arxiv.org/pdf/2307.11239.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christopher Rieser, Anne Ruiz-Gazen, Christine Thomas-Agnan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.11239">Edgewise outliers of network indexed signals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider models for network indexed multivariate data involving a dependence between variables as well as across graph nodes.
  In the framework of these models, we focus on outliers detection and introduce the concept of edgewise outliers. For this purpose, we first derive the distribution of some sums of squares, in particular squared Mahalanobis distances that can be used to fix detection rules and thresholds for outlier detection. We then propose a robust version of the deterministic MCD algorithm that we call edgewise MCD. An application on simulated data shows the interest of taking the dependence structure into account. We also illustrate the utility of the proposed method with a real data set.
<div id='section'>Paperid: <span id='pid'>1769, <a href='https://arxiv.org/pdf/2307.05975.pdf' target='_blank'>https://arxiv.org/pdf/2307.05975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>AndrÃ©s GÃ³mez, JosÃ© Neto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.05975">Outlier detection in regression: conic quadratic formulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many applications, when building linear regression models, it is important to account for the presence of outliers, i.e., corrupted input data points. Such problems can be formulated as mixed-integer optimization problems involving cubic terms, each given by the product of a binary variable and a quadratic term of the continuous variables. Existing approaches in the literature, typically relying on the linearization of the cubic terms using big-M constraints, suffer from weak relaxation and poor performance in practice. In this work we derive stronger second-order conic relaxations that do not involve big-M constraints. Our computational experiments indicate that the proposed formulations are several orders-of-magnitude faster than existing big-M formulations in the literature for this problem.
<div id='section'>Paperid: <span id='pid'>1770, <a href='https://arxiv.org/pdf/2307.01325.pdf' target='_blank'>https://arxiv.org/pdf/2307.01325.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Becktor, Frederik Scholler, Evangelos Boukas, Lazaros Nalpantidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.01325">Robust Uncertainty Estimation for Classification of Maritime Objects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore the use of uncertainty estimation in the maritime domain, showing the efficacy on toy datasets (CIFAR10) and proving it on an in-house dataset, SHIPS. We present a method joining the intra-class uncertainty achieved using Monte Carlo Dropout, with recent discoveries in the field of outlier detection, to gain more holistic uncertainty measures. We explore the relationship between the introduced uncertainty measures and examine how well they work on CIFAR10 and in a real-life setting. Our work improves the FPR95 by 8% compared to the current highest-performing work when the models are trained without out-of-distribution data. We increase the performance by 77% compared to a vanilla implementation of the Wide ResNet. We release the SHIPS dataset and show the effectiveness of our method by improving the FPR95 by 44.2% with respect to the baseline. Our approach is model agnostic, easy to implement, and often does not require model retraining.
<div id='section'>Paperid: <span id='pid'>1771, <a href='https://arxiv.org/pdf/2306.15324.pdf' target='_blank'>https://arxiv.org/pdf/2306.15324.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dmitrii Gavrilev, Evgeny Burnaev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.15324">Anomaly Detection in Networks via Score-Based Generative Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Node outlier detection in attributed graphs is a challenging problem for which there is no method that would work well across different datasets. Motivated by the state-of-the-art results of score-based models in graph generative modeling, we propose to incorporate them into the aforementioned problem. Our method achieves competitive results on small-scale graphs. We provide an empirical analysis of the Dirichlet energy, and show that generative models might struggle to accurately reconstruct it.
<div id='section'>Paperid: <span id='pid'>1772, <a href='https://arxiv.org/pdf/2306.13500.pdf' target='_blank'>https://arxiv.org/pdf/2306.13500.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Yang, Hao Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13500">Cascade Subspace Clustering for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many methods based on sparse and low-rank representation been developed along with guarantees of correct outlier detection. Self-representation states that a point in a subspace can always be expressed as a linear combination of other points in the subspace. A suitable Markov Chain can be defined on the self-representation and it allows us to recognize the difference between inliers and outliers. However, the reconstruction error of self-representation that is still informative to detect outlier detection, is neglected.Inspired by the gradient boosting, in this paper, we propose a new outlier detection framework that combines a series of weak "outlier detectors" into a single strong one in an iterative fashion by constructing multi-pass self-representation. At each stage, we construct a self-representation based on elastic-net and define a suitable Markov Chain on it to detect outliers. The residual of the self-representation is used for the next stage to learn the next weaker outlier detector. Such a stage will repeat many times. And the final decision of outliers is generated by the previous all results. Experimental results on image and speaker datasets demonstrate its superiority with respect to state-of-the-art sparse and low-rank outlier detection methods.
<div id='section'>Paperid: <span id='pid'>1773, <a href='https://arxiv.org/pdf/2306.12497.pdf' target='_blank'>https://arxiv.org/pdf/2306.12497.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yookoon Park, David M. Blei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.12497">Density Uncertainty Layers for Reliable Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Assessing the predictive uncertainty of deep neural networks is crucial for safety-related applications of deep learning. Although Bayesian deep learning offers a principled framework for estimating model uncertainty, the common approaches that approximate the parameter posterior often fail to deliver reliable estimates of predictive uncertainty. In this paper, we propose a novel criterion for reliable predictive uncertainty: a model's predictive variance should be grounded in the empirical density of the input. That is, the model should produce higher uncertainty for inputs that are improbable in the training data and lower uncertainty for inputs that are more probable. To operationalize this criterion, we develop the density uncertainty layer, a stochastic neural network architecture that satisfies the density uncertain criterion by design. We study density uncertainty layers on the UCI and CIFAR-10/100 uncertainty benchmarks. Compared to existing approaches, density uncertainty layers provide more reliable uncertainty estimates and robust out-of-distribution detection performance.
<div id='section'>Paperid: <span id='pid'>1774, <a href='https://arxiv.org/pdf/2306.06139.pdf' target='_blank'>https://arxiv.org/pdf/2306.06139.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ravindrakumar Purohit, Jai Prakash Verma, Rachna Jain, Madhuri Bhavsar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06139">WePaMaDM-Outlier Detection: Weighted Outlier Detection using Pattern Approaches for Mass Data Mining</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Weighted Outlier Detection is a method for identifying unusual or anomalous data points in a dataset, which can be caused by various factors like human error, fraud, or equipment malfunctions. Detecting outliers can reveal vital information about system faults, fraudulent activities, and patterns in the data, assisting experts in addressing the root causes of these anomalies. However,creating a model of normal data patterns to identify outliers can be challenging due to the nature of input data, labeled data availability, and specific requirements of the problem. This article proposed the WePaMaDM-Outlier Detection with distinct mass data mining domain, demonstrating that such techniques are domain-dependent and usually developed for specific problem formulations. Nevertheless, similar domains can adapt solutions with modifications. This work also investigates the significance of data modeling in outlier detection techniques in surveillance, fault detection, and trend analysis, also referred to as novelty detection, a semisupervised task where the algorithm learns to recognize abnormality while being taught the normal class.
<div id='section'>Paperid: <span id='pid'>1775, <a href='https://arxiv.org/pdf/2306.04754.pdf' target='_blank'>https://arxiv.org/pdf/2306.04754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Temtam, L. Pei, K. Iftekharuddin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04754">Computational Modeling of Deep Multiresolution-Fractal Texture and Its Application to Abnormal Brain Tissue Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational modeling of Multiresolution- Fractional Brownian motion (fBm) has been effective in stochastic multiscale fractal texture feature extraction and machine learning of abnormal brain tissue segmentation. Further, deep multiresolution methods have been used for pixel-wise brain tissue segmentation. Robust tissue segmentation and volumetric measurement may provide more objective quantification of disease burden and offer improved tracking of treatment response for the disease. However, we posit that computational modeling of deep multiresolution fractal texture features may offer elegant feature learning. Consequently, this work proposes novel modeling of Multiresolution Fractal Deep Neural Network (MFDNN) and its computational implementation that mathematically combines a multiresolution fBm model and deep multiresolution analysis. The proposed full 3D MFDNN model offers the desirable properties of estimating multiresolution stochastic texture features by analyzing large amount of raw MRI image data for brain tumor segmentation. We apply the proposed MFDNN to estimate stochastic deep multiresolution fractal texture features for tumor tissues in brain MRI images. The MFDNN model is evaluated using 1251 patient cases for brain tumor segmentation using the most recent BRATS 2021 Challenges dataset. The evaluation of the proposed model using Dice overlap score, Husdorff distance and associated uncertainty estimation offers either better or comparable performances in abnormal brain tissue segmentation when compared to the state-of-the-art methods in the literature. Index Terms: Computational Modeling, Multiresolution Fractional Brownian Motion (fBm), Deep Multiresolution Analysis, Fractal Dimension (FD), Texture Features, Brain tumor segmentation, Deep Learning.
<div id='section'>Paperid: <span id='pid'>1776, <a href='https://arxiv.org/pdf/2306.03783.pdf' target='_blank'>https://arxiv.org/pdf/2306.03783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youngsoo Baek, Samuel I. Berchuck, Sayan Mukherjee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03783">Asymptotics of Bayesian Uncertainty Estimation in Random Features Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper we compare and contrast the behavior of the posterior predictive distribution to the risk of the maximum a posteriori estimator for the random features regression model in the overparameterized regime. We will focus on the variance of the posterior predictive distribution (Bayesian model average) and compare its asymptotics to that of the risk of the MAP estimator. In the regime where the model dimensions grow faster than any constant multiple of the number of samples, asymptotic agreement between these two quantities is governed by the phase transition in the signal-to-noise ratio. They also asymptotically agree with each other when the number of samples grow faster than any constant multiple of model dimensions. Numerical simulations illustrate finer distributional properties of the two quantities for finite dimensions. We conjecture they have Gaussian fluctuations and exhibit similar properties as found by previous authors in a Gaussian sequence model, which is of independent theoretical interest.
<div id='section'>Paperid: <span id='pid'>1777, <a href='https://arxiv.org/pdf/2305.16502.pdf' target='_blank'>https://arxiv.org/pdf/2305.16502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ifueko Igbinedion, Sertac Karaman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.16502">Learning When to Ask for Help: Efficient Interactive Navigation via Implicit Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robots operating alongside humans often encounter unfamiliar environments that make autonomous task completion challenging. Though improving models and increasing dataset size can enhance a robot's performance in unseen environments, data collection and model refinement may be impractical in every environment. Approaches that utilize human demonstrations through manual operation can aid in refinement and generalization, but often require significant data collection efforts to generate enough demonstration data to achieve satisfactory task performance. Interactive approaches allow for humans to provide correction to robot action in real time, but intervention policies are often based on explicit factors related to state and task understanding that may be difficult to generalize. Addressing these challenges, we train a lightweight interaction policy that allows robots to decide when to proceed autonomously or request expert assistance at estimated times of uncertainty. An implicit estimate of uncertainty is learned via evaluating the feature extraction capabilities of the robot's visual navigation policy. By incorporating part-time human interaction, robots recover quickly from their mistakes, significantly improving the odds of task completion. Incorporating part-time interaction yields an increase in success of 0.38 with only a 0.3 expert interaction rate within the Habitat simulation environment using a simulated human expert. We further show success transferring this approach to a new domain with a real human expert, improving success from less than 0.1 with an autonomous agent to 0.92 with a 0.23 human interaction rate. This approach provides a practical means for robots to interact and learn from humans in real-world settings.
<div id='section'>Paperid: <span id='pid'>1778, <a href='https://arxiv.org/pdf/2305.09907.pdf' target='_blank'>https://arxiv.org/pdf/2305.09907.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vivek Yelleti, Ch Priyanka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09907">Incremental Outlier Detection Modelling Using Streaming Analytics in Finance & Health Care</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the era of real-time data, traditional methods often struggle to keep pace with the dynamic nature of streaming environments. In this paper, we proposed a hybrid framework where in (i) stage-I follows a traditional approach where the model is built once and evaluated in a real-time environment, and (ii) stage-II employs an incremental learning approach where the model is continuously retrained as new data arrives, enabling it to adapt and stay up to date. To implement these frameworks, we employed 8 distinct state-of-the-art outlier detection models, including one-class support vector machine (OCSVM), isolation forest adaptive sliding window approach (IForest ASD), exact storm (ES), angle-based outlier detection (ABOD), local outlier factor (LOF), Kitsunes online algorithm (KitNet), and K-nearest neighbour conformal density and distance based (KNN CAD). We evaluated the performance of these models across seven financial and healthcare prediction tasks, including credit card fraud detection, churn prediction, Ethereum fraud detection, heart stroke prediction, and diabetes prediction. The results indicate that our proposed incremental learning framework significantly improves performance, particularly on highly imbalanced datasets. Among all models, the IForest ASD model consistently ranked among the top three best-performing models, demonstrating superior effectiveness across various datasets.
<div id='section'>Paperid: <span id='pid'>1779, <a href='https://arxiv.org/pdf/2305.09446.pdf' target='_blank'>https://arxiv.org/pdf/2305.09446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Muhr, Michael Affenzeller, Josef KÃ¼ng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09446">A Probabilistic Transformation of Distance-Based Outliers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The scores of distance-based outlier detection methods are difficult to interpret, making it challenging to determine a cut-off threshold between normal and outlier data points without additional context. We describe a generic transformation of distance-based outlier scores into interpretable, probabilistic estimates. The transformation is ranking-stable and increases the contrast between normal and outlier data points. Determining distance relationships between data points is necessary to identify the nearest-neighbor relationships in the data, yet, most of the computed distances are typically discarded. We show that the distances to other data points can be used to model distance probability distributions and, subsequently, use the distributions to turn distance-based outlier scores into outlier probabilities. Our experiments show that the probabilistic transformation does not impact detection performance over numerous tabular and image benchmark datasets but results in interpretable outlier scores with increased contrast between normal and outlier samples. Our work generalizes to a wide range of distance-based outlier detection methods, and because existing distance computations are used, it adds no significant computational overhead.
<div id='section'>Paperid: <span id='pid'>1780, <a href='https://arxiv.org/pdf/2305.08874.pdf' target='_blank'>https://arxiv.org/pdf/2305.08874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maximiliano A. Sacco, Manuel Pulido, Juan J. Ruiz, Pierre Tandeo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.08874">Online machine-learning forecast uncertainty estimation for sequential data assimilation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantifying forecast uncertainty is a key aspect of state-of-the-art numerical weather prediction and data assimilation systems. Ensemble-based data assimilation systems incorporate state-dependent uncertainty quantification based on multiple model integrations. However, this approach is demanding in terms of computations and development. In this work a machine learning method is presented based on convolutional neural networks that estimates the state-dependent forecast uncertainty represented by the forecast error covariance matrix using a single dynamical model integration. This is achieved by the use of a loss function that takes into account the fact that the forecast errors are heterodastic. The performance of this approach is examined within a hybrid data assimilation method that combines a Kalman-like analysis update and the machine learning based estimation of a state-dependent forecast error covariance matrix. Observing system simulation experiments are conducted using the Lorenz'96 model as a proof-of-concept. The promising results show that the machine learning method is able to predict precise values of the forecast covariance matrix in relatively high-dimensional states. Moreover, the hybrid data assimilation method shows similar performance to the ensemble Kalman filter outperforming it when the ensembles are relatively small.
<div id='section'>Paperid: <span id='pid'>1781, <a href='https://arxiv.org/pdf/2305.04275.pdf' target='_blank'>https://arxiv.org/pdf/2305.04275.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ge Zhang, Wangzhe Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.04275">RSC-VAE: Recoding Semantic Consistency Based VAE for One-Class Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, there is an increasing interests in reconstruction based generative models for image One-Class Novelty Detection, most of which only focus on image-level information. While in this paper, we further exploit the latent space of Variational Auto-encoder (VAE), a typical reconstruction based model, and we innovatively divide it into three regions: Normal/Anomalous/Unknown-semantic-region. Based on this hypothesis, we propose a new VAE architecture, Recoding Semantic Consistency Based VAE (RSC-VAE), combining VAE with recoding mechanism and constraining the semantic consistency of two encodings. We come up with three training modes of RSC-VAE: 1. One-Class Training Mode, alleviating False Positive problem of normal samples; 2. Distributionally-Shifted Training Mode, alleviating False Negative problem of anomalous samples; 3. Extremely-Imbalanced Training Mode, introducing a small number of anomalous samples for training to enhance the second mode. The experimental results on multiple datasets demonstrate that our mechanism achieves state-of-the-art performance in various baselines including VAE.
<div id='section'>Paperid: <span id='pid'>1782, <a href='https://arxiv.org/pdf/2305.00982.pdf' target='_blank'>https://arxiv.org/pdf/2305.00982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emmanuel Aboah Boateng, Jerry Bruce
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.00982">Two-phase Dual COPOD Method for Anomaly Detection in Industrial Control System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Critical infrastructures like water treatment facilities and power plants depend on industrial control systems (ICS) for monitoring and control, making them vulnerable to cyber attacks and system malfunctions. Traditional ICS anomaly detection methods lack transparency and interpretability, which make it difficult for practitioners to understand and trust the results. This paper proposes a two-phase dual Copula-based Outlier Detection (COPOD) method that addresses these challenges. The first phase removes unwanted outliers using an empirical cumulative distribution algorithm, and the second phase develops two parallel COPOD models based on the output data of phase 1. The method is based on empirical distribution functions, parameter-free, and provides interpretability by quantifying each feature's contribution to an anomaly. The method is also computationally and memory-efficient, suitable for low- and high-dimensional datasets. Experimental results demonstrate superior performance in terms of F1-score and recall on three open-source ICS datasets, enabling real-time ICS anomaly detection.
<div id='section'>Paperid: <span id='pid'>1783, <a href='https://arxiv.org/pdf/2304.10511.pdf' target='_blank'>https://arxiv.org/pdf/2304.10511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hadi Eskandari, Michael Bewong, Sabih ur Rehman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10511">OutCenTR: A novel semi-supervised framework for predicting exploits of vulnerabilities in high-dimensional datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An ever-growing number of vulnerabilities are reported every day. Yet these vulnerabilities are not all the same; Some are more targeted than others. Correctly estimating the likelihood of a vulnerability being exploited is a critical task for system administrators. This aids the system administrators in prioritizing and patching the right vulnerabilities. Our work makes use of outlier detection techniques to predict vulnerabilities that are likely to be exploited in highly imbalanced and high-dimensional datasets such as the National Vulnerability Database. We propose a dimensionality reduction technique, OutCenTR, that enhances the baseline outlier detection models. We further demonstrate the effectiveness and efficiency of OutCenTR empirically with 4 benchmark and 12 synthetic datasets. The results of our experiments show on average a 5-fold improvement of F1 score in comparison with state-of-the-art dimensionality reduction techniques such as PCA and GRP.
<div id='section'>Paperid: <span id='pid'>1784, <a href='https://arxiv.org/pdf/2304.06813.pdf' target='_blank'>https://arxiv.org/pdf/2304.06813.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Reza Averly, Wei-Lun Chao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06813">Unified Out-Of-Distribution Detection: A Model-Specific Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection aims to identify test examples that do not belong to the training distribution and are thus unlikely to be predicted reliably. Despite a plethora of existing works, most of them focused only on the scenario where OOD examples come from semantic shift (e.g., unseen categories), ignoring other possible causes (e.g., covariate shift). In this paper, we present a novel, unifying framework to study OOD detection in a broader scope. Instead of detecting OOD examples from a particular cause, we propose to detect examples that a deployed machine learning model (e.g., an image classifier) is unable to predict correctly. That is, whether a test example should be detected and rejected or not is ``model-specific''. We show that this framework unifies the detection of OOD examples caused by semantic shift and covariate shift, and closely addresses the concern of applying a machine learning model to uncontrolled environments. We provide an extensive analysis that involves a variety of models (e.g., different architectures and training strategies), sources of OOD examples, and OOD detection approaches, and reveal several insights into improving and understanding OOD detection in uncontrolled environments.
<div id='section'>Paperid: <span id='pid'>1785, <a href='https://arxiv.org/pdf/2304.06696.pdf' target='_blank'>https://arxiv.org/pdf/2304.06696.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miguel SimÃ£o, Pedro Neto, Olivier Gibaru
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06696">Improving novelty detection with generative adversarial networks on hand gesture data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel way of solving the issue of classification of out-of-vocabulary gestures using Artificial Neural Networks (ANNs) trained in the Generative Adversarial Network (GAN) framework. A generative model augments the data set in an online fashion with new samples and stochastic target vectors, while a discriminative model determines the class of the samples. The approach was evaluated on the UC2017 SG and UC2018 DualMyo data sets. The generative models performance was measured with a distance metric between generated and real samples. The discriminative models were evaluated by their accuracy on trained and novel classes. In terms of sample generation quality, the GAN is significantly better than a random distribution (noise) in mean distance, for all classes. In the classification tests, the baseline neural network was not capable of identifying untrained gestures. When the proposed methodology was implemented, we found that there is a trade-off between the detection of trained and untrained gestures, with some trained samples being mistaken as novelty. Nevertheless, a novelty detection accuracy of 95.4% or 90.2% (depending on the data set) was achieved with just 5% loss of accuracy on trained classes.
<div id='section'>Paperid: <span id='pid'>1786, <a href='https://arxiv.org/pdf/2304.06015.pdf' target='_blank'>https://arxiv.org/pdf/2304.06015.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md. Maidul Islam, Tanzina Nasrin Tania, Sharmin Akter, Kazi Hassan Shakib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06015">An Improved Heart Disease Prediction Using Stacked Ensemble Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Heart disorder has just overtaken cancer as the world's biggest cause of mortality. Several cardiac failures, heart disease mortality, and diagnostic costs can all be reduced with early identification and treatment. Medical data is collected in large quantities by the healthcare industry, but it is not well mined. The discovery of previously unknown patterns and connections in this information can help with an improved decision when it comes to forecasting heart disorder risk. In the proposed study, we constructed an ML-based diagnostic system for heart illness forecasting, using a heart disorder dataset. We used data preprocessing techniques like outlier detection and removal, checking and removing missing entries, feature normalization, cross-validation, nine classification algorithms like RF, MLP, KNN, ETC, XGB, SVC, ADB, DT, and GBM, and eight classifier measuring performance metrics like ramification accuracy, precision, F1 score, specificity, ROC, sensitivity, log-loss, and Matthews' correlation coefficient, as well as eight classification performance evaluations. Our method can easily differentiate between people who have cardiac disease and those are normal. Receiver optimistic curves and also the region under the curves were determined by every classifier. Most of the classifiers, pretreatment strategies, validation methods, and performance assessment metrics for classification models have been discussed in this study. The performance of the proposed scheme has been confirmed, utilizing all of its capabilities. In this work, the impact of clinical decision support systems was evaluated using a stacked ensemble approach that included these nine algorithms
<div id='section'>Paperid: <span id='pid'>1787, <a href='https://arxiv.org/pdf/2303.17658.pdf' target='_blank'>https://arxiv.org/pdf/2303.17658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Noah Fleischmann, Walter Bennette, Nathan Inkawhich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.17658">Establishing baselines and introducing TernaryMixOE for fine-grained out-of-distribution detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models deployed in the open world may encounter observations that they were not trained to recognize, and they risk misclassifying such observations with high confidence. Therefore, it is essential that these models are able to ascertain what is in-distribution (ID) and out-of-distribution (OOD), to avoid this misclassification. In recent years, huge strides have been made in creating models that are robust to this distinction. As a result, the current state-of-the-art has reached near perfect performance on relatively coarse-grained OOD detection tasks, such as distinguishing horses from trucks, while struggling with finer-grained classification, like differentiating models of commercial aircraft. In this paper, we describe a new theoretical framework for understanding fine- and coarse-grained OOD detection, we re-conceptualize fine grained classification into a three part problem, and we propose a new baseline task for OOD models on two fine-grained hierarchical data sets, two new evaluation methods to differentiate fine- and coarse-grained OOD performance, along with a new loss function for models in this task.
<div id='section'>Paperid: <span id='pid'>1788, <a href='https://arxiv.org/pdf/2303.16616.pdf' target='_blank'>https://arxiv.org/pdf/2303.16616.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dajana DimitriÄ, Mitar SimiÄ, Vladimir RisojeviÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.16616">Nearest Neighbor Based Out-of-Distribution Detection in Remote Sensing Scene Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models for image classification are typically trained under the "closed-world" assumption with a predefined set of image classes. However, when the models are deployed they may be faced with input images not belonging to the classes encountered during training. This type of scenario is common in remote sensing image classification where images come from different geographic areas, sensors, and imaging conditions. In this paper we deal with the problem of detecting remote sensing images coming from a different distribution compared to the training data - out of distribution images. We propose a benchmark for out of distribution detection in remote sensing scene classification and evaluate detectors based on maximum softmax probability and nearest neighbors. The experimental results show convincing advantages of the method based on nearest neighbors.
<div id='section'>Paperid: <span id='pid'>1789, <a href='https://arxiv.org/pdf/2303.11702.pdf' target='_blank'>https://arxiv.org/pdf/2303.11702.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emile Reyn Engelbrecht, Johan du Preez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11702">On the link between generative semi-supervised learning and generative open-set recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the relationship between semi-supervised learning (SSL, which is training off partially labelled datasets) and open-set recognition (OSR, which is classification with simultaneous novelty detection) under the context of generative adversarial networks (GANs). Although no previous study has formally linked SSL and OSR, their respective methods share striking similarities. Specifically, SSL-GANs and OSR-GANs require their generators to produce 'bad-looking' samples which are used to regularise their classifier networks. We hypothesise that the definitions of bad-looking samples in SSL and OSR represents the same concept and realises the same goal. More formally, bad-looking samples lie in the complementary space, which is the area between and around the boundaries of the labelled categories within the classifier's embedding space. By regularising a classifier with samples in the complementary space, classifiers achieve improved generalisation for SSL and also generalise the open space for OSR. To test this hypothesis, we compare a foundational SSL-GAN with the state-of-the-art OSR-GAN under the same SSL-OSR experimental conditions. Our results find that SSL-GANs achieve near identical results to OSR-GANs, proving the SSL-OSR link. Subsequently, to further this new research path, we compare several SSL-GANs various SSL-OSR setups which this first benchmark results. A combined framework of SSL-OSR certainly improves the practicality and cost-efficiency of classifier training, and so further theoretical and application studies are also discussed.
<div id='section'>Paperid: <span id='pid'>1790, <a href='https://arxiv.org/pdf/2303.06920.pdf' target='_blank'>https://arxiv.org/pdf/2303.06920.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kira Maag, Tobias Riedlinger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.06920">Pixel-wise Gradient Uncertainty for Convolutional Neural Networks applied to Out-of-Distribution Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, deep neural networks have defined the state-of-the-art in semantic segmentation where their predictions are constrained to a predefined set of semantic classes. They are to be deployed in applications such as automated driving, although their categorically confined expressive power runs contrary to such open world scenarios. Thus, the detection and segmentation of objects from outside their predefined semantic space, i.e., out-of-distribution (OoD) objects, is of highest interest. Since uncertainty estimation methods like softmax entropy or Bayesian models are sensitive to erroneous predictions, these methods are a natural baseline for OoD detection. Here, we present a method for obtaining uncertainty scores from pixel-wise loss gradients which can be computed efficiently during inference. Our approach is simple to implement for a large class of models, does not require any additional training or auxiliary data and can be readily used on pre-trained segmentation models. Our experiments show the ability of our method to identify wrong pixel classifications and to estimate prediction quality at negligible computational overhead. In particular, we observe superior performance in terms of OoD segmentation to comparable baselines on the SegmentMeIfYouCan benchmark, clearly outperforming other methods.
<div id='section'>Paperid: <span id='pid'>1791, <a href='https://arxiv.org/pdf/2303.05789.pdf' target='_blank'>https://arxiv.org/pdf/2303.05789.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aminul Huq, Md Tanzim Reza, Shahriar Hossain, Shakib Mahmud Dipto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.05789">AnoMalNet: Outlier Detection based Malaria Cell Image Classification Method Leveraging Deep Autoencoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Class imbalance is a pervasive issue in the field of disease classification from medical images. It is necessary to balance out the class distribution while training a model for decent results. However, in the case of rare medical diseases, images from affected patients are much harder to come by compared to images from non-affected patients, resulting in unwanted class imbalance. Various processes of tackling class imbalance issues have been explored so far, each having its fair share of drawbacks. In this research, we propose an outlier detection based binary medical image classification technique which can handle even the most extreme case of class imbalance. We have utilized a dataset of malaria parasitized and uninfected cells. An autoencoder model titled AnoMalNet is trained with only the uninfected cell images at the beginning and then used to classify both the affected and non-affected cell images by thresholding a loss value. We have achieved an accuracy, precision, recall, and F1 score of 98.49%, 97.07%, 100%, and 98.52% respectively, performing better than large deep learning models and other published works. As our proposed approach can provide competitive results without needing the disease-positive samples during training, it should prove to be useful in binary disease classification on imbalanced datasets.
<div id='section'>Paperid: <span id='pid'>1792, <a href='https://arxiv.org/pdf/2303.03925.pdf' target='_blank'>https://arxiv.org/pdf/2303.03925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jack W Barker, Neelanjan Bhowmik, Yona Falinie A Gaus, Toby P Breckon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03925">Robust Semi-Supervised Anomaly Detection via Adversarially Learned Continuous Noise Corruption</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection is the task of recognising novel samples which deviate significantly from pre-establishednormality. Abnormal classes are not present during training meaning that models must learn effective rep-resentations solely across normal class data samples. Deep Autoencoders (AE) have been widely used foranomaly detection tasks, but suffer from overfitting to a null identity function. To address this problem, weimplement a training scheme applied to a Denoising Autoencoder (DAE) which introduces an efficient methodof producing Adversarially Learned Continuous Noise (ALCN) to maximally globally corrupt the input priorto denoising. Prior methods have applied similar approaches of adversarial training to increase the robustnessof DAE, however they exhibit limitations such as slow inference speed reducing their real-world applicabilityor producing generalised obfuscation which is more trivial to denoise. We show through rigorous evaluationthat our ALCN method of regularisation during training improves AUC performance during inference whileremaining efficient over both classical, leave-one-out novelty detection tasks with the variations-: 9 (normal)vs. 1 (abnormal) & 1 (normal) vs. 9 (abnormal); MNIST - AUCavg: 0.890 & 0.989, CIFAR-10 - AUCavg: 0.670& 0.742, in addition to challenging real-world anomaly detection tasks: industrial inspection (MVTEC-AD -AUCavg: 0.780) and plant disease detection (Plant Village - AUC: 0.770) when compared to prior approaches.
<div id='section'>Paperid: <span id='pid'>1793, <a href='https://arxiv.org/pdf/2303.01170.pdf' target='_blank'>https://arxiv.org/pdf/2303.01170.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alberto Castagna, Ivana Dusparic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01170">Expert-Free Online Transfer Learning in Multi-Agent Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transfer learning in Reinforcement Learning (RL) has been widely studied to overcome training issues of Deep-RL, i.e., exploration cost, data availability and convergence time, by introducing a way to enhance training phase with external knowledge. Generally, knowledge is transferred from expert-agents to novices. While this fixes the issue for a novice agent, a good understanding of the task on expert agent is required for such transfer to be effective. As an alternative, in this paper we propose Expert-Free Online Transfer Learning (EF-OnTL), an algorithm that enables expert-free real-time dynamic transfer learning in multi-agent system. No dedicated expert exists, and transfer source agent and knowledge to be transferred are dynamically selected at each transfer step based on agents' performance and uncertainty. To improve uncertainty estimation, we also propose State Action Reward Next-State Random Network Distillation (sars-RND), an extension of RND that estimates uncertainty from RL agent-environment interaction. We demonstrate EF-OnTL effectiveness against a no-transfer scenario and advice-based baselines, with and without expert agents, in three benchmark tasks: Cart-Pole, a grid-based Multi-Team Predator-Prey (mt-pp) and Half Field Offense (HFO). Our results show that EF-OnTL achieve overall comparable performance when compared against advice-based baselines while not requiring any external input nor threshold tuning. EF-OnTL outperforms no-transfer with an improvement related to the complexity of the task addressed.
<div id='section'>Paperid: <span id='pid'>1794, <a href='https://arxiv.org/pdf/2302.14552.pdf' target='_blank'>https://arxiv.org/pdf/2302.14552.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yana Stoyanova, Soroush Ghandi, Maryam Tavakol
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.14552">Toward Robust Uncertainty Estimation with Random Activation Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks are in the limelight of machine learning with their excellent performance in many data-driven applications. However, they can lead to inaccurate predictions when queried in out-of-distribution data points, which can have detrimental effects especially in sensitive domains, such as healthcare and transportation, where erroneous predictions can be very costly and/or dangerous. Subsequently, quantifying the uncertainty of the output of a neural network is often leveraged to evaluate the confidence of its predictions, and ensemble models have proved to be effective in measuring the uncertainty by utilizing the variance of predictions over a pool of models. In this paper, we propose a novel approach for uncertainty quantification via ensembles, called Random Activation Functions (RAFs) Ensemble, that aims at improving the ensemble diversity toward a more robust estimation, by accommodating each neural network with a different (random) activation function. Extensive empirical study demonstrates that RAFs Ensemble outperforms state-of-the-art ensemble uncertainty quantification methods on both synthetic and real-world datasets in a series of regression tasks.
<div id='section'>Paperid: <span id='pid'>1795, <a href='https://arxiv.org/pdf/2302.12606.pdf' target='_blank'>https://arxiv.org/pdf/2302.12606.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>NataÅ¡a Tagasovska, Firat Ozdemir, Axel Brando
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12606">Retrospective Uncertainties for Deep Models using Vine Copulas</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the major progress of deep models as learning machines, uncertainty estimation remains a major challenge. Existing solutions rely on modified loss functions or architectural changes. We propose to compensate for the lack of built-in uncertainty estimates by supplementing any network, retrospectively, with a subsequent vine copula model, in an overall compound we call Vine-Copula Neural Network (VCNN). Through synthetic and real-data experiments, we show that VCNNs could be task (regression/classification) and architecture (recurrent, fully connected) agnostic while providing reliable and better-calibrated uncertainty estimates, comparable to state-of-the-art built-in uncertainty solutions.
<div id='section'>Paperid: <span id='pid'>1796, <a href='https://arxiv.org/pdf/2302.11563.pdf' target='_blank'>https://arxiv.org/pdf/2302.11563.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matej PechÃ¡Ä, Michal Chovanec, Igor FarkaÅ¡
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11563">Self-supervised network distillation: an effective approach to exploration in sparse reward environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning can solve decision-making problems and train an agent to behave in an environment according to a predesigned reward function. However, such an approach becomes very problematic if the reward is too sparse and so the agent does not come across the reward during the environmental exploration. The solution to such a problem may be to equip the agent with an intrinsic motivation that will provide informed exploration during which the agent is likely to also encounter external reward. Novelty detection is one of the promising branches of intrinsic motivation research. We present Self-supervised Network Distillation (SND), a class of intrinsic motivation algorithms based on the distillation error as a novelty indicator, where the predictor model and the target model are both trained. We adapted three existing self-supervised methods for this purpose and experimentally tested them on a set of ten environments that are considered difficult to explore. The results show that our approach achieves faster growth and higher external reward for the same training time compared to the baseline models, which implies improved exploration in a very sparse reward environment. In addition, the analytical methods we applied provide valuable explanatory insights into our proposed models.
<div id='section'>Paperid: <span id='pid'>1797, <a href='https://arxiv.org/pdf/2302.08618.pdf' target='_blank'>https://arxiv.org/pdf/2302.08618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ege Erdogan, Unat Teksen, Mehmet Salih Celiktenyildiz, Alptekin Kupcu, A. Ercument Cicek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08618">SplitOut: Out-of-the-Box Training-Hijacking Detection in Split Learning via Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Split learning enables efficient and privacy-aware training of a deep neural network by splitting a neural network so that the clients (data holders) compute the first layers and only share the intermediate output with the central compute-heavy server. This paradigm introduces a new attack medium in which the server has full control over what the client models learn, which has already been exploited to infer the private data of clients and to implement backdoors in the client models. Although previous work has shown that clients can successfully detect such training-hijacking attacks, the proposed methods rely on heuristics, require tuning of many hyperparameters, and do not fully utilize the clients' capabilities. In this work, we show that given modest assumptions regarding the clients' compute capabilities, an out-of-the-box outlier detection method can be used to detect existing training-hijacking attacks with almost-zero false positive rates. We conclude through experiments on different tasks that the simplicity of our approach we name \textit{SplitOut} makes it a more viable and reliable alternative compared to the earlier detection methods.
<div id='section'>Paperid: <span id='pid'>1798, <a href='https://arxiv.org/pdf/2302.07608.pdf' target='_blank'>https://arxiv.org/pdf/2302.07608.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mouxiao Huang, Yu Qiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.07608">Uncertainty-Estimation with Normalized Logits for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is critical for preventing deep learning models from making incorrect predictions to ensure the safety of artificial intelligence systems. Especially in safety-critical applications such as medical diagnosis and autonomous driving, the cost of incorrect decisions is usually unbearable. However, neural networks often suffer from the overconfidence issue, making high confidence for OOD data which are never seen during training process and may be irrelevant to training data, namely in-distribution (ID) data. Determining the reliability of the prediction is still a difficult and challenging task. In this work, we propose Uncertainty-Estimation with Normalized Logits (UE-NL), a robust learning method for OOD detection, which has three main benefits. (1) Neural networks with UE-NL treat every ID sample equally by predicting the uncertainty score of input data and the uncertainty is added into softmax function to adjust the learning strength of easy and hard samples during training phase, making the model learn robustly and accurately. (2) UE-NL enforces a constant vector norm on the logits to decouple the effect of the increasing output norm from optimization process, which causes the overconfidence issue to some extent. (3) UE-NL provides a new metric, the magnitude of uncertainty score, to detect OOD data. Experiments demonstrate that UE-NL achieves top performance on common OOD benchmarks and is more robust to noisy ID data that may be misjudged as OOD data by other methods.
<div id='section'>Paperid: <span id='pid'>1799, <a href='https://arxiv.org/pdf/2302.02598.pdf' target='_blank'>https://arxiv.org/pdf/2302.02598.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Menglong Chen, Xingtai Gui, Shicai Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.02598">Cluster-aware Contrastive Learning for Unsupervised Out-of-distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised out-of-distribution (OOD) Detection aims to separate the samples falling outside the distribution of training data without label information. Among numerous branches, contrastive learning has shown its excellent capability of learning discriminative representation in OOD detection. However, for its limited vision, merely focusing on instance-level relationship between augmented samples, it lacks attention to the relationship between samples with same semantics. Based on the classic contrastive learning, we propose Cluster-aware Contrastive Learning (CCL) framework for unsupervised OOD detection, which considers both instance-level and semantic-level information. Specifically, we study a cooperation strategy of clustering and contrastive learning to effectively extract the latent semantics and design a cluster-aware contrastive loss function to enhance OOD discriminative ability. The loss function can simultaneously pay attention to the global and local relationships by treating both the cluster centers and the samples belonging to the same cluster as positive samples. We conducted sufficient experiments to verify the effectiveness of our framework and the model achieves significant improvement on various image benchmarks.
<div id='section'>Paperid: <span id='pid'>1800, <a href='https://arxiv.org/pdf/2301.08949.pdf' target='_blank'>https://arxiv.org/pdf/2301.08949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Denis SelimoviÄ, Franko HrÅ¾iÄ, Jasna PrpiÄ-OrÅ¡iÄ, Jonatan Lerga
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.08949">Estimation of Sea State Parameters from Ship Motion Responses Using Attention-based Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>On-site estimation of sea state parameters is crucial for ship navigation systems' accuracy, stability, and efficiency. Extensive research has been conducted on model-based estimating methods utilizing only ship motion responses. Model-free approaches based on machine learning (ML) have recently gained popularity, and estimation from time-series of ship motion responses using deep learning (DL) methods has given promising results. Accordingly, in this study, we apply the novel, attention-based neural network (AT-NN) for estimating sea state parameters (wave height, zero-crossing period, and relative wave direction) from raw time-series data of ship pitch, heave, and roll motions. Despite using reduced input data, it has been successfully demonstrated that the proposed approaches by modified state-of-the-art techniques (based on convolutional neural networks (CNN) for regression, multivariate long short-term memory CNN, and sliding puzzle neural network) reduced estimation MSE by 23% and MAE by 16% compared to the original methods. Furthermore, the proposed technique based on AT-NN outperformed all tested methods (original and enhanced), reducing estimation MSE by up to 94% and MAE by up to 70%. Finally, we also proposed a novel approach for interpreting the uncertainty estimation of neural network outputs based on the Monte-Carlo dropout method to enhance the model's trustworthiness.
<div id='section'>Paperid: <span id='pid'>1801, <a href='https://arxiv.org/pdf/2301.06229.pdf' target='_blank'>https://arxiv.org/pdf/2301.06229.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taylor Bradley, Elie Alhajjar, Nathaniel Bastian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.06229">Novelty Detection in Network Traffic: Using Survival Analysis for Feature Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intrusion Detection Systems are an important component of many organizations' cyber defense and resiliency strategies. However, one downside of these systems is their reliance on known attack signatures for detection of malicious network events. When it comes to unknown attack types and zero-day exploits, modern Intrusion Detection Systems often fall short. In this paper, we introduce an unconventional approach to identifying network traffic features that influence novelty detection based on survival analysis techniques. Specifically, we combine several Cox proportional hazards models and implement Kaplan-Meier estimates to predict the probability that a classifier identifies novelty after the injection of an unknown network attack at any given time. The proposed model is successful at pinpointing PSH Flag Count, ACK Flag Count, URG Flag Count, and Down/Up Ratio as the main features to impact novelty detection via Random Forest, Bayesian Ridge, and Linear Support Vector Regression classifiers.
<div id='section'>Paperid: <span id='pid'>1802, <a href='https://arxiv.org/pdf/2301.05297.pdf' target='_blank'>https://arxiv.org/pdf/2301.05297.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabio Arnez, Huascar Espinoza, Ansgar Radermacher, FranÃ§ois Terrier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.05297">Towards Dependable Autonomous Systems Based on Bayesian Deep Learning Components</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As autonomous systems increasingly rely on Deep Neural Networks (DNN) to implement the navigation pipeline functions, uncertainty estimation methods have become paramount for estimating confidence in DNN predictions. Bayesian Deep Learning (BDL) offers a principled approach to model uncertainties in DNNs. However, in DNN-based systems, not all the components use uncertainty estimation methods and typically ignore the uncertainty propagation between them. This paper provides a method that considers the uncertainty and the interaction between BDL components to capture the overall system uncertainty. We study the effect of uncertainty propagation in a BDL-based system for autonomous aerial navigation. Experiments show that our approach allows us to capture useful uncertainty estimates while slightly improving the system's performance in its final task. In addition, we discuss the benefits, challenges, and implications of adopting BDL to build dependable autonomous systems.
<div id='section'>Paperid: <span id='pid'>1803, <a href='https://arxiv.org/pdf/2211.01234.pdf' target='_blank'>https://arxiv.org/pdf/2211.01234.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matteo Vaghi, Augusto Luis Ballardini, Simone Fontana, Domenico Giorgio Sorrenti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.01234">Uncertainty-Aware DNN for Multi-Modal Camera Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Camera localization, i.e., camera pose regression, represents an important task in computer vision since it has many practical applications such as in the context of intelligent vehicles and their localization. Having reliable estimates of the regression uncertainties is also important, as it would allow us to catch dangerous localization failures. In the literature, uncertainty estimation in Deep Neural Networks (DNNs) is often performed through sampling methods, such as Monte Carlo Dropout (MCD) and Deep Ensemble (DE), at the expense of undesirable execution time or an increase in hardware resources. In this work, we considered an uncertainty estimation approach named Deep Evidential Regression (DER) that avoids any sampling technique, providing direct uncertainty estimates. Our goal is to provide a systematic approach to intercept localization failures of camera localization systems based on DNNs architectures, by analyzing the generated uncertainties. We propose to exploit CMRNet, a DNN approach for multi-modal image to LiDAR map registration, by modifying its internal configuration to allow for extensive experimental activity on the KITTI dataset. The experimental section highlights CMRNet's major flaws and proves that our proposal does not compromise the original localization performances but also provides, at the same time, the necessary introspection measures that would allow end-users to act accordingly.
<div id='section'>Paperid: <span id='pid'>1804, <a href='https://arxiv.org/pdf/2210.16334.pdf' target='_blank'>https://arxiv.org/pdf/2210.16334.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Vafaei Sadr, Bruce A. Bassett, Emmanuel Sekyi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.16334">Learning to Detect Interesting Anomalies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomaly detection algorithms are typically applied to static, unchanging, data features hand-crafted by the user. But how does a user systematically craft good features for anomalies that have never been seen? Here we couple deep learning with active learning -- in which an Oracle iteratively labels small amounts of data selected algorithmically over a series of rounds -- to automatically and dynamically improve the data features for efficient outlier detection. This approach, AHUNT, shows excellent performance on MNIST, CIFAR10, and Galaxy-DESI data, significantly outperforming both standard anomaly detection and active learning algorithms with static feature spaces. Beyond improved performance, AHUNT also allows the number of anomaly classes to grow organically in response to Oracle's evaluations. Extensive ablation studies explore the impact of Oracle question selection strategy and loss function on performance. We illustrate how the dynamic anomaly class taxonomy represents another step towards fully personalized rankings of different anomaly classes that reflect a user's interests, allowing the algorithm to learn to ignore statistically significant but uninteresting outliers (e.g., noise). This should prove useful in the era of massive astronomical datasets serving diverse sets of users who can only review a tiny subset of the incoming data.
<div id='section'>Paperid: <span id='pid'>1805, <a href='https://arxiv.org/pdf/2210.13917.pdf' target='_blank'>https://arxiv.org/pdf/2210.13917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seyyed Morteza Hashemi, Parvaneh Aliniya, Parvin Razzaghi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.13917">Connective Reconstruction-based Novelty Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detection of out-of-distribution samples is one of the critical tasks for real-world applications of computer vision. The advancement of deep learning has enabled us to analyze real-world data which contain unexplained samples, accentuating the need to detect out-of-distribution instances more than before. GAN-based approaches have been widely used to address this problem due to their ability to perform distribution fitting; however, they are accompanied by training instability and mode collapse. We propose a simple yet efficient reconstruction-based method that avoids adding complexities to compensate for the limitations of GAN models while outperforming them. Unlike previous reconstruction-based works that only utilize reconstruction error or generated samples, our proposed method simultaneously incorporates both of them in the detection task. Our model, which we call "Connective Novelty Detection" has two subnetworks, an autoencoder, and a binary classifier. The autoencoder learns the representation of the positive class by reconstructing them. Then, the model creates negative and connected positive examples using real and generated samples. Negative instances are generated via manipulating the real data, so their distribution is close to the positive class to achieve a more accurate boundary for the classifier. To boost the robustness of the detection to reconstruction error, connected positive samples are created by combining the real and generated samples. Finally, the binary classifier is trained using connected positive and negative examples. We demonstrate a considerable improvement in novelty detection over state-of-the-art methods on MNIST and Caltech-256 datasets.
<div id='section'>Paperid: <span id='pid'>1806, <a href='https://arxiv.org/pdf/2209.06720.pdf' target='_blank'>https://arxiv.org/pdf/2209.06720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anagh Chattopadhyay, Soumya Sankar Ghosh, Samir Karmakar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.06720">On Language Clustering: A Non-parametric Statistical Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Any approach aimed at pasteurizing and quantifying a particular phenomenon must include the use of robust statistical methodologies for data analysis. With this in mind, the purpose of this study is to present statistical approaches that may be employed in nonparametric nonhomogeneous data frameworks, as well as to examine their application in the field of natural language processing and language clustering. Furthermore, this paper discusses the many uses of nonparametric approaches in linguistic data mining and processing. The data depth idea allows for the centre-outward ordering of points in any dimension, resulting in a new nonparametric multivariate statistical analysis that does not require any distributional assumptions. The concept of hierarchy is used in historical language categorisation and structuring, and it aims to organise and cluster languages into subfamilies using the same premise. In this regard, the current study presents a novel approach to language family structuring based on non-parametric approaches produced from a typological structure of words in various languages, which is then converted into a Cartesian framework using MDS. This statistical-depth-based architecture allows for the use of data-depth-based methodologies for robust outlier detection, which is extremely useful in understanding the categorization of diverse borderline languages and allows for the re-evaluation of existing classification systems. Other depth-based approaches are also applied to processes such as unsupervised and supervised clustering. This paper therefore provides an overview of procedures that can be applied to nonhomogeneous language classification systems in a nonparametric framework.
<div id='section'>Paperid: <span id='pid'>1807, <a href='https://arxiv.org/pdf/2207.07572.pdf' target='_blank'>https://arxiv.org/pdf/2207.07572.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sara Summerton, Ann Tivey, Rohan Shotton, Gavin Brown, Oliver C. Redfern, Rachel Oakley, John Radford, David C. Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.07572">Outlier detection of vital sign trajectories from COVID-19 patients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present a novel trajectory comparison algorithm to identify abnormal vital sign trends, with the aim of improving recognition of deteriorating health.
  There is growing interest in continuous wearable vital sign sensors for monitoring patients remotely at home. These monitors are usually coupled to an alerting system, which is triggered when vital sign measurements fall outside a predefined normal range. Trends in vital signs, such as increasing heart rate, are often indicative of deteriorating health, but are rarely incorporated into alerting systems.
  We introduce a dynamic time warp distance-based measure to compare time series trajectories. We split each multi-variable sign time series into 180 minute, non-overlapping epochs. We then calculate the distance between all pairs of epochs. Each epoch is characterized by its mean pairwise distance (average link distance) to all other epochs, with clusters forming with nearby epochs.
  We demonstrate in synthetically generated data that this method can identify abnormal epochs and cluster epochs with similar trajectories. We then apply this method to a real-world data set of vital signs from 8 patients who had recently been discharged from hospital after contracting COVID-19. We show how outlier epochs correspond well with the abnormal vital signs and identify patients who were subsequently readmitted to hospital.
<div id='section'>Paperid: <span id='pid'>1808, <a href='https://arxiv.org/pdf/2201.10001.pdf' target='_blank'>https://arxiv.org/pdf/2201.10001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ye Gao, Brian Baucom, Karen Rose, Kristina Gordon, Hongning Wang, John Stankovic
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.10001">E-ADDA: Unsupervised Adversarial Domain Adaptation Enhanced by a New Mahalanobis Distance Loss for Smart Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In smart computing, the labels of training samples for a specific task are not always abundant. However, the labels of samples in a relevant but different dataset are available. As a result, researchers have relied on unsupervised domain adaptation to leverage the labels in a dataset (the source domain) to perform better classification in a different, unlabeled dataset (target domain). Existing non-generative adversarial solutions for UDA aim at achieving domain confusion through adversarial training. The ideal scenario is that perfect domain confusion is achieved, but this is not guaranteed to be true. To further enforce domain confusion on top of the adversarial training, we propose a novel UDA algorithm, \textit{E-ADDA}, which uses both a novel variation of the Mahalanobis distance loss and an out-of-distribution detection subroutine. The Mahalanobis distance loss minimizes the distribution-wise distance between the encoded target samples and the distribution of the source domain, thus enforcing additional domain confusion on top of adversarial training. Then, the OOD subroutine further eliminates samples on which the domain confusion is unsuccessful. We have performed extensive and comprehensive evaluations of E-ADDA in the acoustic and computer vision modalities. In the acoustic modality, E-ADDA outperforms several state-of-the-art UDA algorithms by up to 29.8%, measured in the f1 score. In the computer vision modality, the evaluation results suggest that we achieve new state-of-the-art performance on popular UDA benchmarks such as Office-31 and Office-Home, outperforming the second best-performing algorithms by up to 17.9%.
<div id='section'>Paperid: <span id='pid'>1809, <a href='https://arxiv.org/pdf/2201.02596.pdf' target='_blank'>https://arxiv.org/pdf/2201.02596.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yumin Liu, Kate Duffy, Jennifer G. Dy, Auroop R. Ganguly
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.02596">Explainable deep learning for insights in El NiÃ±o and river flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The El NiÃ±o Southern Oscillation (ENSO) is a semi-periodic fluctuation in sea surface temperature (SST) over the tropical central and eastern Pacific Ocean that influences interannual variability in regional hydrology across the world through long-range dependence or teleconnections. Recent research has demonstrated the value of Deep Learning (DL) methods for improving ENSO prediction as well as Complex Networks (CN) for understanding teleconnections. However, gaps in predictive understanding of ENSO-driven river flows include the black box nature of DL, the use of simple ENSO indices to describe a complex phenomenon and translating DL-based ENSO predictions to river flow predictions. Here we show that eXplainable DL (XDL) methods, based on saliency maps, can extract interpretable predictive information contained in global SST and discover SST information regions and dependence structures relevant for river flows which, in tandem with climate network constructions, enable improved predictive understanding. Our results reveal additional information content in global SST beyond ENSO indices, develop understanding of how SSTs influence river flows, and generate improved river flow prediction, including uncertainty estimation. Observations, reanalysis data, and earth system model simulations are used to demonstrate the value of the XDL-CN based methods for future interannual and decadal scale climate projections.
<div id='section'>Paperid: <span id='pid'>1810, <a href='https://arxiv.org/pdf/2107.14796.pdf' target='_blank'>https://arxiv.org/pdf/2107.14796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charles L. BÃ©rubÃ©, Pierre BÃ©rubÃ©
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2107.14796">Data-driven modeling of time-domain induced polarization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel approach for data-driven modeling of the time-domain induced polarization (IP) phenomenon using variational autoencoders (VAE). VAEs are Bayesian neural networks that aim to learn a latent statistical distribution to encode extensive data sets as lower dimension representations. We collected 1 600 319 IP decay curves in various regions of Canada, the United States and Kazakhstan, and compiled them to train a deep VAE. The proposed deep learning approach is strictly unsupervised and data-driven: it does not require manual processing or ground truth labeling of IP data. Moreover, our VAE approach avoids the pitfalls of IP parametrization with the empirical Cole-Cole and Debye decomposition models, simple power-law models, or other sophisticated mechanistic models. We demonstrate four applications of VAEs to model and process IP data: (1) representative synthetic data generation, (2) unsupervised Bayesian denoising and data uncertainty estimation, (3) quantitative evaluation of the signal-to-noise ratio, and (4) automated outlier detection. We also interpret the IP compilation's latent representation and reveal a strong correlation between its first dimension and the average chargeability of IP decays. Finally, we experiment with varying VAE latent space dimensions and demonstrate that a single real-valued scalar parameter contains sufficient information to encode our extensive IP data compilation. This new finding suggests that modeling time-domain IP data using mathematical models governed by more than one free parameter is ambiguous, whereas modeling only the average chargeability is justified. A pre-trained implementation of our model -- readily applicable to new IP data from any geolocation -- is available as open-source Python code for the applied geophysics community.
<div id='section'>Paperid: <span id='pid'>1811, <a href='https://arxiv.org/pdf/2107.07564.pdf' target='_blank'>https://arxiv.org/pdf/2107.07564.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>John Mitros, Brian Mac Namee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2107.07564">On the Importance of Regularisation & Auxiliary Information in OOD Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks are often utilised in critical domain applications (e.g. self-driving cars, financial markets, and aerospace engineering), even though they exhibit overconfident predictions for ambiguous inputs. This deficiency demonstrates a fundamental flaw indicating that neural networks often overfit on spurious correlations. To address this problem in this work we present two novel objectives that improve the ability of a network to detect out-of-distribution samples and therefore avoid overconfident predictions for ambiguous inputs. We empirically demonstrate that our methods outperform the baseline and perform better than the majority of existing approaches while still maintaining a competitive performance against the rest. Additionally, we empirically demonstrate the robustness of our approach against common corruptions and demonstrate the importance of regularisation and auxiliary information in out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>1812, <a href='https://arxiv.org/pdf/2105.09095.pdf' target='_blank'>https://arxiv.org/pdf/2105.09095.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JÃ¶rg Martin, Clemens Elster
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2105.09095">Aleatoric uncertainty for Errors-in-Variables models in deep regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A Bayesian treatment of deep learning allows for the computation of uncertainties associated with the predictions of deep neural networks. We show how the concept of Errors-in-Variables can be used in Bayesian deep regression to also account for the uncertainty associated with the input of the employed neural network. The presented approach thereby exploits a relevant, but generally overlooked, source of uncertainty and yields a decomposition of the predictive uncertainty into an aleatoric and epistemic part that is more complete and, in many cases, more consistent from a statistical perspective. We discuss the approach along various simulated and real examples and observe that using an Errors-in-Variables model leads to an increase in the uncertainty while preserving the prediction performance of models without Errors-in-Variables. For examples with known regression function we observe that this ground truth is substantially better covered by the Errors-in-Variables model, indicating that the presented approach leads to a more reliable uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1813, <a href='https://arxiv.org/pdf/2008.01468.pdf' target='_blank'>https://arxiv.org/pdf/2008.01468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Fischer, Jonas Schneider
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2008.01468">On Feature Relevance Uncertainty: A Monte Carlo Dropout Sampling Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding decisions made by neural networks is key for the deployment of intelligent systems in real world applications. However, the opaque decision making process of these systems is a disadvantage where interpretability is essential. Many feature-based explanation techniques have been introduced over the last few years in the field of machine learning to better understand decisions made by neural networks and have become an important component to verify their reasoning capabilities. However, existing methods do not allow statements to be made about the uncertainty regarding a feature's relevance for the prediction. In this paper, we introduce Monte Carlo Relevance Propagation (MCRP) for feature relevance uncertainty estimation. A simple but powerful method based on Monte Carlo estimation of the feature relevance distribution to compute feature relevance uncertainty scores that allow a deeper understanding of a neural network's perception and reasoning.
<div id='section'>Paperid: <span id='pid'>1814, <a href='https://arxiv.org/pdf/2509.18132.pdf' target='_blank'>https://arxiv.org/pdf/2509.18132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiuyi Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18132">Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty is a fundamental challenge in medical practice, but current medical AI systems fail to explicitly quantify or communicate uncertainty in a way that aligns with clinical reasoning. Existing XAI works focus on interpreting model predictions but do not capture the confidence or reliability of these predictions. Conversely, uncertainty estimation (UE) techniques provide confidence measures but lack intuitive explanations. The disconnect between these two areas limits AI adoption in medicine. To address this gap, we propose Explainable Uncertainty Estimation (XUE) that integrates explainability with uncertainty quantification to enhance trust and usability in medical AI. We systematically map medical uncertainty to AI uncertainty concepts and identify key challenges in implementing XUE. We outline technical directions for advancing XUE, including multimodal uncertainty quantification, model-agnostic visualization techniques, and uncertainty-aware decision support systems. Lastly, we propose guiding principles to ensure effective XUE realisation. Our analysis highlights the need for AI systems that not only generate reliable predictions but also articulate confidence levels in a clinically meaningful way. This work contributes to the development of trustworthy medical AI by bridging explainability and uncertainty, paving the way for AI systems that are aligned with real-world clinical complexities.
<div id='section'>Paperid: <span id='pid'>1815, <a href='https://arxiv.org/pdf/2509.10048.pdf' target='_blank'>https://arxiv.org/pdf/2509.10048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Madhushan Ramalingam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10048">Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predictive models are being increasingly used across a wide range of domains, including safety-critical applications such as medical diagnosis and criminal justice. Reliable uncertainty estimation is a crucial task in such settings. Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine learning foundation model for tabular dataset, which uses a generative transformer architecture. Variational Bayesian Last Layers (VBLL) is a state-of-the-art lightweight variational formulation that effectively improves uncertainty estimation with minimal computational overhead. In this work we aim to evaluate the performance of VBLL integrated with the recently proposed TabPFN in uncertainty calibration. Our experiments, conducted on three benchmark medical tabular datasets, compare the performance of the original TabPFN and the VBLL-integrated version. Contrary to expectations, we observed that original TabPFN consistently outperforms VBLL integrated TabPFN in uncertainty calibration across all datasets.
<div id='section'>Paperid: <span id='pid'>1816, <a href='https://arxiv.org/pdf/2509.06902.pdf' target='_blank'>https://arxiv.org/pdf/2509.06902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aivin V. Solatorio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06902">Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) as stochastic systems may generate numbers that deviate from available data, a failure known as \emph{numeric hallucination}. Existing safeguards -- retrieval-augmented generation, citations, and uncertainty estimation -- improve transparency but cannot guarantee fidelity: fabricated or misquoted values may still be displayed as if correct. We propose \textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that enforces numeric fidelity through mechanical verification. Under PCN, numeric spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a verifier checks each token under a declared policy (e.g., exact equality, rounding, aliases, or tolerance with qualifiers). Crucially, PCN places verification in the \emph{renderer}, not the model: only claim-checked numbers are marked as verified, and all others default to unverified. This separation prevents spoofing and guarantees fail-closed behavior. We formalize PCN and prove soundness, completeness under honest tokens, fail-closed behavior, and monotonicity under policy refinement. PCN is lightweight and model-agnostic, integrates seamlessly into existing applications, and can be extended with cryptographic commitments. By enforcing verification as a mandatory step before display, PCN establishes a simple contract for numerically sensitive settings: \emph{trust is earned only by proof}, while the absence of a mark communicates uncertainty.
<div id='section'>Paperid: <span id='pid'>1817, <a href='https://arxiv.org/pdf/2508.21463.pdf' target='_blank'>https://arxiv.org/pdf/2508.21463.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Rakotoarivony
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21463">Multi-Method Ensemble for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is essential for neural networks operating in open-world settings, particularly in safety-critical applications. Existing methods have improved OOD detection by leveraging two main techniques: feature truncation, which increases the separation between in-distribution (ID) and OOD samples, and scoring functions, which assign scores to distinguish between ID and OOD data. However, most approaches either focus on a single family of techniques or evaluate their effectiveness on a specific type of OOD dataset, overlooking the potential of combining multiple existing solutions. Motivated by this observation, we theoretically and empirically demonstrate that state-of-the-art feature truncation and scoring functions can be effectively combined. Moreover, we show that aggregating multiple scoring functions enhances robustness against various types of OOD samples. Based on these insights, we propose the Multi-Method Ensemble (MME) score, which unifies state-of-the-art OOD detectors into a single, more effective scoring function. Extensive experiments on both large-scale and small-scale benchmarks, covering near-OOD and far-OOD scenarios, show that MME significantly outperforms recent state-of-the-art methods across all benchmarks. Notably, using the BiT model, our method achieves an average FPR95 of 27.57% on the challenging ImageNet-1K benchmark, improving performance by 6% over the best existing baseline.
<div id='section'>Paperid: <span id='pid'>1818, <a href='https://arxiv.org/pdf/2508.21463.pdf' target='_blank'>https://arxiv.org/pdf/2508.21463.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lucas Rakotoarivony
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21463">Multi-Method Ensemble for Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting out-of-distribution (OOD) samples is essential for neural networks operating in open-world settings, particularly in safety-critical applications. Existing methods have improved OOD detection by leveraging two main techniques: feature truncation, which increases the separation between in-distribution (ID) and OOD samples, and scoring functions, which assign scores to distinguish between ID and OOD data. However, most approaches either focus on a single family of techniques or evaluate their effectiveness on a specific type of OOD dataset, overlooking the potential of combining multiple existing solutions. Motivated by this observation, we theoretically and empirically demonstrate that state-of-the-art feature truncation and scoring functions can be effectively combined. Moreover, we show that aggregating multiple scoring functions enhances robustness against various types of OOD samples. Based on these insights, we propose the Multi-Method Ensemble (MME) score, which unifies state-of-the-art OOD detectors into a single, more effective scoring function. Extensive experiments on both large-scale and small-scale benchmarks, covering near-OOD and far-OOD scenarios, show that MME significantly outperforms recent state-of-the-art methods across all benchmarks. Notably, using the BiT model, our method achieves an average FPR95 of 27.57% on the challenging ImageNet-1K benchmark, improving performance by 6% over the best existing baseline.
<div id='section'>Paperid: <span id='pid'>1819, <a href='https://arxiv.org/pdf/2508.18001.pdf' target='_blank'>https://arxiv.org/pdf/2508.18001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian G. Gruber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18001">A Novel Framework for Uncertainty Quantification via Proper Scores for Classification and Beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this PhD thesis, we propose a novel framework for uncertainty quantification in machine learning, which is based on proper scores. Uncertainty quantification is an important cornerstone for trustworthy and reliable machine learning applications in practice. Usually, approaches to uncertainty quantification are problem-specific, and solutions and insights cannot be readily transferred from one task to another. Proper scores are loss functions minimized by predicting the target distribution. Due to their very general definition, proper scores apply to regression, classification, or even generative modeling tasks. We contribute several theoretical results, that connect epistemic uncertainty, aleatoric uncertainty, and model calibration with proper scores, resulting in a general and widely applicable framework. We achieve this by introducing a general bias-variance decomposition for strictly proper scores via functional Bregman divergences. Specifically, we use the kernel score, a kernel-based proper score, for evaluating sample-based generative models in various domains, like image, audio, and natural language generation. This includes a novel approach for uncertainty estimation of large language models, which outperforms state-of-the-art baselines. Further, we generalize the calibration-sharpness decomposition beyond classification, which motivates the definition of proper calibration errors. We then introduce a novel estimator for proper calibration errors in classification, and a novel risk-based approach to compare different estimators for squared calibration errors. Last, we offer a decomposition of the kernel spherical score, another kernel-based proper score, allowing a more fine-grained and interpretable evaluation of generative image models.
<div id='section'>Paperid: <span id='pid'>1820, <a href='https://arxiv.org/pdf/2508.15019.pdf' target='_blank'>https://arxiv.org/pdf/2508.15019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos Stein Brito
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15019">Twin-Boot: Uncertainty-Aware Optimization via Online Two-Sample Bootstrapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard gradient descent methods yield point estimates with no measure of confidence. This limitation is acute in overparameterized and low-data regimes, where models have many parameters relative to available data and can easily overfit. Bootstrapping is a classical statistical framework for uncertainty estimation based on resampling, but naively applying it to deep learning is impractical: it requires training many replicas, produces post-hoc estimates that cannot guide learning, and implicitly assumes comparable optima across runs - an assumption that fails in non-convex landscapes. We introduce Twin-Bootstrap Gradient Descent (Twin-Boot), a resampling-based training procedure that integrates uncertainty estimation into optimization. Two identical models are trained in parallel on independent bootstrap samples, and a periodic mean-reset keeps both trajectories in the same basin so that their divergence reflects local (within-basin) uncertainty. During training, we use this estimate to sample weights in an adaptive, data-driven way, providing regularization that favors flatter solutions. In deep neural networks and complex high-dimensional inverse problems, the approach improves calibration and generalization and yields interpretable uncertainty maps.
<div id='section'>Paperid: <span id='pid'>1821, <a href='https://arxiv.org/pdf/2508.13121.pdf' target='_blank'>https://arxiv.org/pdf/2508.13121.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos Celemin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13121">Bayesian Optimization-based Search for Agent Control in Automated Game Testing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces an automated testing approach that employs agents controlling game characters to detect potential bugs within a game level. Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient search, the method determines the next sampling point by analyzing the data collected so far and calculates the data point that will maximize information acquisition. To support the BO process, we introduce a game testing-specific model built on top of a grid map, that features the smoothness and uncertainty estimation required by BO, however and most importantly, it does not suffer the scalability issues that traditional models carry. The experiments demonstrate that the approach significantly improves map coverage capabilities in both time efficiency and exploration distribution.
<div id='section'>Paperid: <span id='pid'>1822, <a href='https://arxiv.org/pdf/2508.07948.pdf' target='_blank'>https://arxiv.org/pdf/2508.07948.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>John D. Mayfield
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07948">Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Progressive neurodegenerative diseases, including Alzheimer's disease (AD), multiple sclerosis (MS), Parkinson's disease (PD), and amyotrophic lateral sclerosis (ALS), exhibit complex, nonlinear trajectories that challenge deterministic modeling. Traditional time-domain analyses of multiomic and neuroimaging data often fail to capture hidden oscillatory patterns, limiting predictive accuracy. We propose a theoretical mathematical framework that transforms time-series data into frequency or s-domain using Fourier and Laplace transforms, models neuronal dynamics via Hamiltonian formulations, and employs quantum-classical hybrid computing with variational quantum eigensolvers (VQE) for enhanced pattern detection. This theoretical construct serves as a foundation for future empirical works in quantum-enhanced analysis of neurodegenerative diseases. We extend this to quaternionic representations with three imaginary axes ($i, j, k$) to model multistate Hamiltonians in multifaceted disorders, drawing from quantum neuromorphic computing to capture entangled neural dynamics \citep{Pehle2020, Emani2019}. This approach leverages quantum advantages in handling high-dimensional amplitude-phase data, enabling outlier detection and frequency signature analysis. Potential clinical applications include identifying high-risk patients with rapid progression or therapy resistance using s-domain biomarkers, supported by quantum machine learning (QML) precedents achieving up to 99.89% accuracy in Alzheimer's classification \citep{Belay2024, Bhowmik2025}. This framework aims to lay the groundwork for redefining precision medicine for neurodegenerative diseases through future validations.
<div id='section'>Paperid: <span id='pid'>1823, <a href='https://arxiv.org/pdf/2508.07556.pdf' target='_blank'>https://arxiv.org/pdf/2508.07556.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stephan Rabanser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07556">Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) systems are increasingly deployed in high-stakes domains where reliability is paramount. This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, focusing on selective prediction -- where models abstain when confidence is low. We first show that a model's training trajectory contains rich uncertainty signals that can be exploited without altering its architecture or loss. By ensembling predictions from intermediate checkpoints, we propose a lightweight, post-hoc abstention method that works across tasks, avoids the cost of deep ensembles, and achieves state-of-the-art selective prediction performance. Crucially, this approach is fully compatible with differential privacy (DP), allowing us to study how privacy noise affects uncertainty quality. We find that while many methods degrade under DP, our trajectory-based approach remains robust, and we introduce a framework for isolating the privacy-uncertainty trade-off. Next, we then develop a finite-sample decomposition of the selective classification gap -- the deviation from the oracle accuracy-coverage curve -- identifying five interpretable error sources and clarifying which interventions can close the gap. This explains why calibration alone cannot fix ranking errors, motivating methods that improve uncertainty ordering. Finally, we show that uncertainty signals can be adversarially manipulated to hide errors or deny service while maintaining high accuracy, and we design defenses combining calibration audits with verifiable inference. Together, these contributions advance reliable ML by improving, evaluating, and safeguarding uncertainty estimation, enabling models that not only make accurate predictions -- but also know when to say "I do not know".
<div id='section'>Paperid: <span id='pid'>1824, <a href='https://arxiv.org/pdf/2508.03720.pdf' target='_blank'>https://arxiv.org/pdf/2508.03720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmet GÃ¶khan Poyraz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03720">Outlier Detection Algorithm for Circle Fitting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Circle fitting methods are extensively utilized in various industries, particularly in quality control processes and design applications. The effectiveness of these algorithms can be significantly compromised when the point sets to be predicted are noisy. To mitigate this issue, outlier detection and removal algorithms are often applied before the circle fitting procedure. This study introduces the Polar Coordinate-Based Outlier Detection (PCOD) algorithm, which can be effectively employed in circle fitting applications. In the proposed approach, the point set is first transformed into polar coordinates, followed by the calculation of both local and global standard deviations. Outliers are then identified by comparing local mean values with the global standard deviation. The practicality and efficiency of the proposed method are demonstrated by focusing on the high-precision diameter measurement of industrial washer parts. Images from a machine vision system are processed through preprocessing steps, including sub-pixel edge detection. The resulting sub-pixel edge points are then cleaned using the proposed outlier detection and removal algorithm, after which circle fitting is performed. A comparison is made using ten different circle fitting algorithms and five distinct outlier detection methods. The results indicate that the proposed method outperforms the other approaches, delivering the best performance in terms of accuracy within the dataset, thereby demonstrating its potential for enhancing circle fitting applications in industrial environments.
<div id='section'>Paperid: <span id='pid'>1825, <a href='https://arxiv.org/pdf/2507.22915.pdf' target='_blank'>https://arxiv.org/pdf/2507.22915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Esmail Gumaan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22915">Theoretical Foundations and Mitigation of Hallucination in Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hallucination in Large Language Models (LLMs) refers to the generation of content that is not faithful to the input or the real-world facts. This paper provides a rigorous treatment of hallucination in LLMs, including formal definitions and theoretical analyses. We distinguish between intrinsic and extrinsic hallucinations, and define a \textit{hallucination risk} for models. We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes and Rademacher complexity). We then survey detection strategies for hallucinations, such as token-level uncertainty estimation, confidence calibration, and attention alignment checks. On the mitigation side, we discuss approaches including retrieval-augmented generation, hallucination-aware fine-tuning, logit calibration, and the incorporation of fact-verification modules. We propose a unified detection and mitigation workflow, illustrated with a diagram, to integrate these strategies. Finally, we outline evaluation protocols for hallucination, recommending datasets, metrics, and experimental setups to quantify and reduce hallucinations. Our work lays a theoretical foundation and practical guidelines for addressing the crucial challenge of hallucination in LLMs.
<div id='section'>Paperid: <span id='pid'>1826, <a href='https://arxiv.org/pdf/2507.21203.pdf' target='_blank'>https://arxiv.org/pdf/2507.21203.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcello D'Orazio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21203">An empirical comparison of some outlier detection methods with longitudinal data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This note investigates the problem of detecting outliers in longitudinal data. It compares well-known methods used in official statistics with proposals from the fields of data mining and machine learning that are based on the distance between observations or binary partitioning trees. This is achieved by applying the methods to panel survey data related to different types of statistical units. Traditional methods are quite simple, enabling the direct identification of potential outliers, but they require specific assumptions. In contrast, recent methods provide only a score whose magnitude is directly related to the likelihood of an outlier being present. All the methods require the user to set a number of tuning parameters. However, the most recent methods are more flexible and sometimes more effective than traditional methods. In addition, these methods can be applied to multidimensional data.
<div id='section'>Paperid: <span id='pid'>1827, <a href='https://arxiv.org/pdf/2507.14960.pdf' target='_blank'>https://arxiv.org/pdf/2507.14960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Letteri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14960">A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The detection of outliers within cryptocurrency limit order books (LOBs) is of paramount importance for comprehending market dynamics, particularly in highly volatile and nascent regulatory environments. This study conducts a comprehensive comparative analysis of robust statistical methods and advanced machine learning techniques for real-time anomaly identification in cryptocurrency LOBs. Within a unified testing environment, named AITA Order Book Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to identify which approaches are most suitable for detecting potentially manipulative trading behaviours. An empirical evaluation, conducted via backtesting on a dataset of 26,204 records from a major exchange, demonstrates that the top-performing model, Empirical Covariance (EC), achieves a 6.70% gain, significantly outperforming a standard Buy-and-Hold benchmark. These findings underscore the effectiveness of outlier-driven strategies and provide insights into the trade-offs between model complexity, trade frequency, and performance. This study contributes to the growing corpus of research on cryptocurrency market microstructure by furnishing a rigorous benchmark of anomaly detection models and highlighting their potential for augmenting algorithmic trading and risk management.
<div id='section'>Paperid: <span id='pid'>1828, <a href='https://arxiv.org/pdf/2507.06269.pdf' target='_blank'>https://arxiv.org/pdf/2507.06269.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rushil Desai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06269">BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate surface estimation is critical for downstream tasks in scientific simulation, and quantifying uncertainty in implicit neural 3D representations still remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. However, current neural implicit surface models do not offer a principled way to quantify uncertainty, limiting their reliability in real-world applications. Inspired by recent probabilistic rendering approaches, we introduce BayesSDF, a novel probabilistic framework for uncertainty estimation in neural implicit 3D representations. Unlike radiance-based models such as Neural Radiance Fields (NeRF) or 3D Gaussian Splatting, Signed Distance Functions (SDFs) provide continuous, differentiable surface representations, making them especially well-suited for uncertainty-aware modeling. BayesSDF applies a Laplace approximation over SDF weights and derives Hessian-based metrics to estimate local geometric instability. We empirically demonstrate that these uncertainty estimates correlate strongly with surface reconstruction error across both synthetic and real-world benchmarks. By enabling surface-aware uncertainty quantification, BayesSDF lays the groundwork for more robust, interpretable, and actionable 3D perception systems.
<div id='section'>Paperid: <span id='pid'>1829, <a href='https://arxiv.org/pdf/2506.22809.pdf' target='_blank'>https://arxiv.org/pdf/2506.22809.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cooper Doyle
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22809">Low-rank variational dropout: Uncertainty and rank selection in adapters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parameter-efficient fine-tuning (PEFT) methods such as LoRA adapt large language models by inserting low-rank adapters, but they leave open two key questions: how to give the adapted model calibrated uncertainty, and how to choose the adapter rank. Existing approaches to uncertainty are typically post-hoc, while rank selection is manual and task-specific. BayesLoRA revisits variational dropout in the LoRA setting and shows that the natural unit of stochasticity is not individual weights but entire ranks of the adapter. By placing rank-wise variational distributions over adapter components, BayesLoRA defines a posterior that (i) yields calibrated predictions through adapter-only Monte Carlo sampling and (ii) prunes redundant ranks automatically via an ARD-style KL term. Theoretical analysis shows that this rank-parameterized posterior localizes uncertainty to the adapted subspace and explains amplification under distribution shift. Empirically, BayesLoRA improves calibration while at the same time producing lighter, faster adapters, removing the need to tune ranks by hand. This dual role of uncertainty estimation and uncertainty-driven pruning suggests BayesLoRA may offer a practical default for reliable and efficient PEFT.
<div id='section'>Paperid: <span id='pid'>1830, <a href='https://arxiv.org/pdf/2506.13828.pdf' target='_blank'>https://arxiv.org/pdf/2506.13828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdullah Burkan Bereketoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13828">Hybrid Meta-Learning Framework for Anomaly Forecasting in Nonlinear Dynamical Systems via Physics-Inspired Simulation and Deep Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a hybrid meta-learning framework for forecasting and anomaly detection in nonlinear dynamical systems characterized by nonstationary and stochastic behavior. The approach integrates a physics-inspired simulator that captures nonlinear growth-relaxation dynamics with random perturbations, representative of many complex physical, industrial, and cyber-physical systems. We use CNN-LSTM architectures for spatio-temporal feature extraction, Variational Autoencoders (VAE) for unsupervised anomaly scoring, and Isolation Forests for residual-based outlier detection in addition to a Dual-Stage Attention Recurrent Neural Network (DA-RNN) for one-step forecasting on top of the generated simulation data. To create composite anomaly forecasts, these models are combined using a meta-learner that combines forecasting outputs, reconstruction errors, and residual scores. The hybrid ensemble performs better than standalone models in anomaly localization, generalization, and robustness to nonlinear deviations, according to simulation-based experiments. The framework provides a broad, data-driven approach to early defect identification and predictive monitoring in nonlinear systems, which may be applied to a variety of scenarios where complete physical models might not be accessible.
<div id='section'>Paperid: <span id='pid'>1831, <a href='https://arxiv.org/pdf/2505.12061.pdf' target='_blank'>https://arxiv.org/pdf/2505.12061.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel T. M. Ball
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12061">Bayesian Deep Learning Approaches for Uncertainty-Aware Retinal OCT Image Segmentation for Multiple Sclerosis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optical Coherence Tomography (OCT) provides valuable insights in ophthalmology, cardiology, and neurology due to high-resolution, cross-sectional images of the retina. One critical task for ophthalmologists using OCT is delineation of retinal layers within scans. This process is time-consuming and prone to human bias, affecting the accuracy and reliability of diagnoses. Previous efforts to automate delineation using deep learning face challenges in uptake from clinicians and statisticians due to the absence of uncertainty estimation, leading to "confidently wrong" models via hallucinations. In this study, we address these challenges by applying Bayesian convolutional neural networks (BCNNs) to segment an openly available OCT imaging dataset containing 35 human retina OCTs split between healthy controls and patients with multiple sclerosis. Our findings demonstrate that Bayesian models can be used to provide uncertainty maps of the segmentation, which can further be used to identify highly uncertain samples that exhibit recording artefacts such as noise or miscalibration at inference time. Our method also allows for uncertainty-estimation for important secondary measurements such as layer thicknesses, that are medically relevant for patients. We show that these features come in addition to greater performance compared to similar work over all delineations; with an overall Dice score of 95.65%. Our work brings greater clinical applicability, statistical robustness, and performance to retinal OCT segmentation.
<div id='section'>Paperid: <span id='pid'>1832, <a href='https://arxiv.org/pdf/2505.07528.pdf' target='_blank'>https://arxiv.org/pdf/2505.07528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07528">SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Retrieval-Augmented Generation (RAG) models frequently encounter hallucination phenomena when integrating external information with internal parametric knowledge. Empirical studies demonstrate that the disequilibrium between external contextual information and internal parametric knowledge constitutes a primary factor in hallucination generation. Existing hallucination detection methodologies predominantly emphasize either the external or internal mechanism in isolation, thereby overlooking their synergistic effects. The recently proposed ReDeEP framework decouples these dual mechanisms, identifying two critical contributors to hallucinations: excessive reliance on parametric knowledge encoded in feed-forward networks (FFN) and insufficient utilization of external information by attention mechanisms (particularly copy heads). ReDeEP quantitatively assesses these factors to detect hallucinations and dynamically modulates the contributions of FFNs and copy heads to attenuate their occurrence. Nevertheless, ReDeEP and numerous other hallucination detection approaches have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, inadequately address the semantic dimensions of model responses, resulting in inconsistent hallucination assessments in RAG implementations. Building upon ReDeEP's foundation, this paper introduces SEReDeEP, which enhances computational processes through semantic entropy captured via trained linear probes, thereby achieving hallucination assessments that more accurately reflect ground truth evaluations.
<div id='section'>Paperid: <span id='pid'>1833, <a href='https://arxiv.org/pdf/2504.18650.pdf' target='_blank'>https://arxiv.org/pdf/2504.18650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bruce Collins
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18650">Unsupervised outlier detection to improve bird audio dataset labels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Xeno-Canto bird audio repository is an invaluable resource for those interested in vocalizations and other sounds made by birds around the world. This is particularly the case for machine learning researchers attempting to improve on the bird species recognition accuracy of classification models. However, the task of extracting labeled datasets from the recordings found in this crowd-sourced repository faces several challenges. One challenge of particular significance to machine learning practitioners is that one bird species label is applied to each audio recording, but frequently other sounds are also captured including other bird species, other animal sounds, anthropogenic and other ambient sounds. These non-target bird species sounds can result in dataset labeling discrepancies referred to as label noise. In this work we present a cleaning process consisting of audio preprocessing followed by dimensionality reduction and unsupervised outlier detection (UOD) to reduce the label noise in a dataset derived from Xeno-Canto recordings. We investigate three neural network dimensionality reduction techniques: two flavors of convolutional autoencoders and variational deep embedding (VaDE (Jiang, 2017)). While both methods show some degree of effectiveness at detecting outliers for most bird species datasets, we found significant variation in the performance of the methods from one species to the next. We believe that the results of this investigation demonstrate that the application of our cleaning process can meaningfully reduce the label noise of bird species datasets derived from Xeno-Canto audio repository but results vary across species.
<div id='section'>Paperid: <span id='pid'>1834, <a href='https://arxiv.org/pdf/2504.15562.pdf' target='_blank'>https://arxiv.org/pdf/2504.15562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dip Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15562">Bayesian Autoencoder for Medical Anomaly Detection: Uncertainty-Aware Approach for Brain 2 MRI Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In medical imaging, anomaly detection is a vital element of healthcare diagnostics, especially for neurological conditions which can be life-threatening. Conventional deterministic methods often fall short when it comes to capturing the inherent uncertainty of anomaly detection tasks. This paper introduces a Bayesian Variational Autoencoder (VAE) equipped with multi-head attention mechanisms for detecting anomalies in brain magnetic resonance imaging (MRI). For the purpose of improving anomaly detection performance, we incorporate both epistemic and aleatoric uncertainty estimation through Bayesian inference. The model was tested on the BraTS2020 dataset, and the findings were a 0.83 ROC AUC and a 0.83 PR AUC. The data in our paper suggests that modeling uncertainty is an essential component of anomaly detection, enhancing both performance and interpretability and providing confidence estimates, as well as anomaly predictions, for clinicians to leverage in making medical decisions.
<div id='section'>Paperid: <span id='pid'>1835, <a href='https://arxiv.org/pdf/2504.14372.pdf' target='_blank'>https://arxiv.org/pdf/2504.14372.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Marie Antonio Minoza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.14372">Learning Enhanced Structural Representations with Block-Based Uncertainties for Ocean Floor Mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate ocean modeling and coastal hazard prediction depend on high-resolution bathymetric data; yet, current worldwide datasets are too coarse for exact numerical simulations. While recent deep learning advances have improved earth observation data resolution, existing methods struggle with the unique challenges of producing detailed ocean floor maps, especially in maintaining physical structure consistency and quantifying uncertainties. This work presents a novel uncertainty-aware mechanism using spatial blocks to efficiently capture local bathymetric complexity based on block-based conformal prediction. Using the Vector Quantized Variational Autoencoder (VQ-VAE) architecture, the integration of this uncertainty quantification framework yields spatially adaptive confidence estimates while preserving topographical features via discrete latent representations. With smaller uncertainty widths in well-characterized areas and appropriately larger bounds in areas of complex seafloor structures, the block-based design adapts uncertainty estimates to local bathymetric complexity. Compared to conventional techniques, experimental results over several ocean regions show notable increases in both reconstruction quality and uncertainty estimation reliability. This framework increases the reliability of bathymetric reconstructions by preserving structural integrity while offering spatially adaptive uncertainty estimates, so opening the path for more solid climate modeling and coastal hazard assessment.
<div id='section'>Paperid: <span id='pid'>1836, <a href='https://arxiv.org/pdf/2504.02432.pdf' target='_blank'>https://arxiv.org/pdf/2504.02432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aidan Tiruvan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02432">Robust Randomized Low-Rank Approximation with Row-Wise Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robust low-rank approximation under row-wise adversarial corruption can be achieved with a single pass, randomized procedure that detects and removes outlier rows by thresholding their projected norms. We propose a scalable, non-iterative algorithm that efficiently recovers the underlying low-rank structure in the presence of row-wise adversarial corruption. By first compressing the data with a Johnson Lindenstrauss projection, our approach preserves the geometry of clean rows while dramatically reducing dimensionality. Robust statistical techniques based on the median and median absolute deviation then enable precise identification and removal of outlier rows with abnormally high norms. The subsequent rank-k approximation achieves near-optimal error bounds with a one pass procedure that scales linearly with the number of observations. Empirical results confirm that combining random sketches with robust statistics yields efficient, accurate decompositions even in the presence of large fractions of corrupted rows.
<div id='section'>Paperid: <span id='pid'>1837, <a href='https://arxiv.org/pdf/2503.22714.pdf' target='_blank'>https://arxiv.org/pdf/2503.22714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergio Torres Aguilar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22714">TRIDIS: A Comprehensive Medieval and Early Modern Corpus for HTR and NER</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces TRIDIS (Tria Digita Scribunt), an open-source corpus of medieval and early modern manuscripts. TRIDIS aggregates multiple legacy collections (all published under open licenses) and incorporates large metadata descriptions. While prior publications referenced some portions of this corpus, here we provide a unified overview with a stronger focus on its constitution. We describe (i) the narrative, chronological, and editorial background of each major sub-corpus, (ii) its semi-diplomatic transcription rules (expansion, normalization, punctuation), (iii) a strategy for challenging out-of-domain test splits driven by outlier detection in a joint embedding space, and (iv) preliminary baseline experiments using TrOCR and MiniCPM2.5 comparing random and outlier-based test partitions. Overall, TRIDIS is designed to stimulate joint robust Handwritten Text Recognition (HTR) and Named Entity Recognition (NER) research across medieval and early modern textual heritage.
<div id='section'>Paperid: <span id='pid'>1838, <a href='https://arxiv.org/pdf/2503.12354.pdf' target='_blank'>https://arxiv.org/pdf/2503.12354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Farhad Pourkamali-Anaraki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.12354">Probabilistic Neural Networks (PNNs) with t-Distributed Outputs: Adaptive Prediction Intervals Beyond Gaussian Assumptions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional neural network regression models provide only point estimates, failing to capture predictive uncertainty. Probabilistic neural networks (PNNs) address this limitation by producing output distributions, enabling the construction of prediction intervals. However, the common assumption of Gaussian output distributions often results in overly wide intervals, particularly in the presence of outliers or deviations from normality. To enhance the adaptability of PNNs, we propose t-Distributed Neural Networks (TDistNNs), which generate t-distributed outputs, parameterized by location, scale, and degrees of freedom. The degrees of freedom parameter allows TDistNNs to model heavy-tailed predictive distributions, improving robustness to non-Gaussian data and enabling more adaptive uncertainty quantification. We develop a novel loss function tailored for the t-distribution and derive efficient gradient computations for seamless integration into deep learning frameworks. Empirical evaluations on synthetic and real-world data demonstrate that TDistNNs improve the balance between coverage and interval width. Notably, for identical architectures, TDistNNs consistently produce narrower prediction intervals than Gaussian-based PNNs while maintaining proper coverage. This work contributes a flexible framework for uncertainty estimation in neural networks tasked with regression, particularly suited to settings involving complex output distributions.
<div id='section'>Paperid: <span id='pid'>1839, <a href='https://arxiv.org/pdf/2502.15648.pdf' target='_blank'>https://arxiv.org/pdf/2502.15648.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Raina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15648">Logit Disagreement: OoD Detection with Bayesian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian neural networks (BNNs), which estimate the full posterior distribution over model parameters, are well-known for their role in uncertainty quantification and its promising application in out-of-distribution detection (OoD). Amongst other uncertainty measures, BNNs provide a state-of-the art estimation of predictive entropy (total uncertainty) which can be decomposed as the sum of mutual information and expected entropy. In the context of OoD detection the estimation of predictive uncertainty in the form of the predictive entropy score confounds aleatoric and epistemic uncertainty, the latter being hypothesized to be high for OoD points. Despite these justifications, the mutual information score has been shown to perform worse than predictive entropy. Taking inspiration from Bayesian variational autoencoder (BVAE) literature, this work proposes to measure the disagreement between a corrected version of the pre-softmax quantities, otherwise known as logits, as an estimate of epistemic uncertainty for Bayesian NNs under mean field variational inference. The three proposed epistemic uncertainty scores demonstrate marked improvements over mutual information on a range of OoD experiments, with equal performance otherwise. Moreover, the epistemic uncertainty scores perform on par with the Bayesian benchmark predictive entropy on a range of MNIST and CIFAR10 experiments.
<div id='section'>Paperid: <span id='pid'>1840, <a href='https://arxiv.org/pdf/2502.07425.pdf' target='_blank'>https://arxiv.org/pdf/2502.07425.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keon Vin Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07425">Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws into neural network training. However, traditional PINN models are typically designed for single PDEs, limiting their generalizability across different physical systems. In this work, we explore the potential of a foundation PINN model capable of solving multiple PDEs within a unified architecture. We investigate the efficacy of a single PINN framework trained on four distinct PDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D Wave Equation, and the 2D Laplace Equation, demonstrating its ability to learn diverse physical dynamics.
  To enhance sample efficiency, we incorporate Active Learning (AL) using Monte Carlo (MC) Dropout-based uncertainty estimation, selecting the most informative training samples iteratively. We evaluate different active learning strategies, comparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset, and analyze their impact on solution accuracy. Our results indicate that targeted uncertainty sampling significantly improves performance with fewer training samples, leading to efficient learning across multiple PDEs.
  This work highlights the feasibility of a generalizable PINN-based foundation model, capable of adapting to different physics-based problems without redesigning network architectures. Our findings suggest that multi-PDE PINNs with active learning can serve as an effective approach for reducing computational costs while maintaining high accuracy in physics-based deep learning applications.
<div id='section'>Paperid: <span id='pid'>1841, <a href='https://arxiv.org/pdf/2502.05496.pdf' target='_blank'>https://arxiv.org/pdf/2502.05496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05496">Feature Explosion: a generic optimization strategy for outlier detection algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outlier detection tasks aim at discovering potential issues or opportunities and are widely used in cybersecurity, financial security, industrial inspection, etc. To date, thousands of outlier detection algorithms have been proposed. Clearly, in real-world scenarios, such a large number of algorithms is unnecessary. In other words, a large number of outlier detection algorithms are redundant. We believe the root cause of this redundancy lies in the current highly customized (i.e., non-generic) optimization strategies. Specifically, when researchers seek to improve the performance of existing outlier detection algorithms, they have to design separate optimized versions tailored to the principles of each algorithm, leading to an ever-growing number of outlier detection algorithms. To address this issue, in this paper, we introduce the explosion from physics into the outlier detection task and propose a generic optimization strategy based on feature explosion, called OSD (Optimization Strategy for outlier Detection algorithms). In the future, when improving the performance of existing outlier detection algorithms, it will be sufficient to invoke the OSD plugin without the need to design customized optimized versions for them. We compared the performances of 14 outlier detection algorithms on 24 datasets before and after invoking the OSD plugin. The experimental results show that the performances of all outlier detection algorithms are improved on almost all datasets. In terms of average accuracy, OSD make these outlier detection algorithms improve by 15% (AUC), 63.7% (AP).
<div id='section'>Paperid: <span id='pid'>1842, <a href='https://arxiv.org/pdf/2412.07520.pdf' target='_blank'>https://arxiv.org/pdf/2412.07520.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Koby Bibas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07520">Quantifying the Prediction Uncertainty of Machine Learning Models for Individual Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models have exhibited exceptional results in various domains. The most prevalent approach for learning is the empirical risk minimizer (ERM), which adapts the model's weights to reduce the loss on a training set and subsequently leverages these weights to predict the label for new test data. Nonetheless, ERM makes the assumption that the test distribution is similar to the training distribution, which may not always hold in real-world situations. In contrast, the predictive normalized maximum likelihood (pNML) was proposed as a min-max solution for the individual setting where no assumptions are made on the distribution of the tested input. This study investigates pNML's learnability for linear regression and neural networks, and demonstrates that pNML can improve the performance and robustness of these models on various tasks. Moreover, the pNML provides an accurate confidence measure for its output, showcasing state-of-the-art results for out-of-distribution detection, resistance to adversarial attacks, and active learning.
<div id='section'>Paperid: <span id='pid'>1843, <a href='https://arxiv.org/pdf/2412.03592.pdf' target='_blank'>https://arxiv.org/pdf/2412.03592.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harsh Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03592">Using Images to Find Context-Independent Word Representations in Vector Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many methods have been proposed to find vector representation for words, but most rely on capturing context from the text to find semantic relationships between these vectors. We propose a novel method of using dictionary meanings and image depictions to find word vectors independent of any context. We use auto-encoder on the word images to find meaningful representations and use them to calculate the word vectors. We finally evaluate our method on word similarity, concept categorization and outlier detection tasks. Our method performs comparably to context-based methods while taking much less training time.
<div id='section'>Paperid: <span id='pid'>1844, <a href='https://arxiv.org/pdf/2411.16457.pdf' target='_blank'>https://arxiv.org/pdf/2411.16457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoming Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16457">Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a novel trajectory prediction model for autonomous driving, combining a Characterized Diffusion Module and a Spatial-Temporal Interaction Network to address the challenges posed by dynamic and heterogeneous traffic environments. Our model enhances the accuracy and reliability of trajectory predictions by incorporating uncertainty estimation and complex agent interactions. Through extensive experimentation on public datasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms existing state-of-the-art methods. We demonstrate its ability to capture the underlying spatial-temporal dynamics of traffic scenarios and improve prediction precision, especially in complex environments. The proposed model showcases strong potential for application in real-world autonomous driving systems.
<div id='section'>Paperid: <span id='pid'>1845, <a href='https://arxiv.org/pdf/2410.00408.pdf' target='_blank'>https://arxiv.org/pdf/2410.00408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahamudul Hasan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00408">ECORS: An Ensembled Clustering Approach to Eradicate The Local And Global Outlier In Collaborative Filtering Recommender System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recommender systems are designed to suggest items based on user preferences, helping users navigate the vast amount of information available on the internet. Given the overwhelming content, outlier detection has emerged as a key research area in recommender systems. It involves identifying unusual or suspicious patterns in user behavior. However, existing studies in this field face several challenges, including the limited universality of algorithms, difficulties in selecting users, and a lack of optimization. In this paper, we propose an approach that addresses these challenges by employing various clustering algorithms. Specifically, we utilize a user-user matrix-based clustering technique to detect outliers. By constructing a user-user matrix, we can identify suspicious users in the system. Both local and global outliers are detected to ensure comprehensive analysis. Our experimental results demonstrate that this approach significantly improves the accuracy of outlier detection in recommender systems.
<div id='section'>Paperid: <span id='pid'>1846, <a href='https://arxiv.org/pdf/2409.13984.pdf' target='_blank'>https://arxiv.org/pdf/2409.13984.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geonuk Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13984">Cycle-Consistency Uncertainty Estimation for Visual Prompting based One-Shot Defect Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Industrial defect detection traditionally relies on supervised learning models trained on fixed datasets of known defect types. While effective within a closed set, these models struggle with new, unseen defects, necessitating frequent re-labeling and re-training. Recent advances in visual prompting offer a solution by allowing models to adaptively infer novel categories based on provided visual cues. However, a prevalent issue in these methods is the over-confdence problem, where models can mis-classify unknown objects as known objects with high certainty. To addresssing the fundamental concerns about the adaptability, we propose a solution to estimate uncertainty of the visual prompting process by cycle-consistency. We designed to check whether it can accurately restore the original prompt from its predictions. To quantify this, we measure the mean Intersection over Union (mIoU) between the restored prompt mask and the originally provided prompt mask. Without using complex designs or ensemble methods with multiple networks, our approach achieved a yield rate of 0.9175 in the VISION24 one-shot industrial challenge.
<div id='section'>Paperid: <span id='pid'>1847, <a href='https://arxiv.org/pdf/2409.02628.pdf' target='_blank'>https://arxiv.org/pdf/2409.02628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andreas Kirsch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02628">(Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in Large Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Epistemic uncertainty is crucial for safety-critical applications and data acquisition tasks. Yet, we find an important phenomenon in deep learning models: an epistemic uncertainty collapse as model complexity increases, challenging the assumption that larger models invariably offer better uncertainty quantification. We introduce implicit ensembling as a possible explanation for this phenomenon. To investigate this hypothesis, we provide theoretical analysis and experiments that demonstrate uncertainty collapse in explicit ensembles of ensembles and show experimental evidence of similar collapse in wider models across various architectures, from simple MLPs to state-of-the-art vision models including ResNets and Vision Transformers. We further develop implicit ensemble extraction techniques to decompose larger models into diverse sub-models, showing we can thus recover epistemic uncertainty. We explore the implications of these findings for uncertainty estimation.
<div id='section'>Paperid: <span id='pid'>1848, <a href='https://arxiv.org/pdf/2409.01154.pdf' target='_blank'>https://arxiv.org/pdf/2409.01154.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Morris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01154">Forecasting infectious disease prevalence with associated uncertainty using neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Infectious diseases pose significant human and economic burdens. Accurately forecasting disease incidence can enable public health agencies to respond effectively to existing or emerging diseases. Despite progress in the field, developing accurate forecasting models remains a significant challenge. This thesis proposes two methodological frameworks using neural networks (NNs) with associated uncertainty estimates - a critical component limiting the application of NNs to epidemic forecasting thus far. We develop our frameworks by forecasting influenza-like illness (ILI) in the United States. Our first proposed method uses Web search activity data in conjunction with historical ILI rates as observations for training NN architectures. Our models incorporate Bayesian layers to produce uncertainty intervals, positioning themselves as legitimate alternatives to more conventional approaches. The best performing architecture: iterative recurrent neural network (IRNN), reduces mean absolute error by 10.3% and improves Skill by 17.1% on average in forecasting tasks across four flu seasons compared to the state-of-the-art. We build on this method by introducing IRNNs, an architecture which changes the sampling procedure in the IRNN to improve the uncertainty estimation. Our second framework uses neural ordinary differential equations to bridge the gap between mechanistic compartmental models and NNs; benefiting from the physical constraints that compartmental models provide. We evaluate eight neural ODE models utilising a mixture of ILI rates and Web search activity data to provide forecasts. These are compared with the IRNN and IRNN0 - the IRNN using only ILI rates. Models trained without Web search activity data outperform the IRNN0 by 16% in terms of Skill. Future work should focus on more effectively using neural ODEs with Web search data to compete with the best performing IRNN.
<div id='section'>Paperid: <span id='pid'>1849, <a href='https://arxiv.org/pdf/2407.19684.pdf' target='_blank'>https://arxiv.org/pdf/2407.19684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinye Sha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.19684">Application of Computer Technology in Financial Investment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In order to understand the application of computer technology in financial investment, the author proposes a research on the application of computer technology in financial investment. The author used user transaction data from a certain online payment platform as a sample, with a total of 284908 sample records, including 593 positive samples (fraud samples) and 285214 negative samples (normal samples), to conduct an empirical study on user fraud detection based on data mining. In this process, facing the problem of imbalanced positive and negative samples, the author proposes to use the Under Sampling method to construct sub samples, and then perform feature scaling, outlier detection, feature screening and other processing on the sub samples. Then, four classification models, logistic regression, K-nearest neighbor algorithm, decision tree, and support vector machine, are trained on the processed sub samples. The prediction results of the four models are evaluated, and the results show that the recall rate, Fl score, and AUC value of the logistic regression model are the highest, indicating that the detection method based on computer data mining is practical and feasible.
<div id='section'>Paperid: <span id='pid'>1850, <a href='https://arxiv.org/pdf/2407.05357.pdf' target='_blank'>https://arxiv.org/pdf/2407.05357.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Welter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.05357">On the power of data augmentation for head pose estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has been impressively successful in the last decade in predicting human head poses from monocular images. However, for in-the-wild inputs the research community relies predominantly on a single training set, 300W-LP, of semisynthetic nature without many alternatives. This paper focuses on gradual extension and improvement of the data to explore the performance achievable with augmentation and synthesis strategies further. Modeling-wise a novel multitask head/loss design which includes uncertainty estimation is proposed. Overall, the thus obtained models are small, efficient, suitable for full 6 DoF pose estimation, and exhibit very competitive accuracy.
<div id='section'>Paperid: <span id='pid'>1851, <a href='https://arxiv.org/pdf/2407.01403.pdf' target='_blank'>https://arxiv.org/pdf/2407.01403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vitaly Bulgakov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01403">Optimization of Retrieval-Augmented Generation Context with Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we focus on methods to reduce the size and improve the quality of the prompt context required for question-answering systems. Attempts to increase the number of retrieved chunked documents and thereby enlarge the context related to the query can significantly complicate the processing and decrease the performance of a Large Language Model (LLM) when generating responses to queries. It is well known that a large set of documents retrieved from a database in response to a query may contain irrelevant information, which often leads to hallucinations in the resulting answers. Our goal is to select the most semantically relevant documents, treating the discarded ones as outliers. We propose and evaluate several methods for identifying outliers by creating features that utilize the distances of embedding vectors, retrieved from the vector database, to both the centroid and the query vectors. The methods were evaluated by comparing the similarities of the retrieved LLM responses to ground-truth answers obtained using the OpenAI GPT-4o model. It was found that the greatest improvements were achieved with increasing complexity of the questions and answers.
<div id='section'>Paperid: <span id='pid'>1852, <a href='https://arxiv.org/pdf/2406.09548.pdf' target='_blank'>https://arxiv.org/pdf/2406.09548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Feder Cooper
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09548">Between Randomness and Arbitrariness: Some Lessons for Reliable Machine Learning at Scale</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To develop rigorous knowledge about ML models -- and the systems in which they are embedded -- we need reliable measurements. But reliable measurement is fundamentally challenging, and touches on issues of reproducibility, scalability, uncertainty quantification, epistemology, and more. This dissertation addresses criteria needed to take reliability seriously: both criteria for designing meaningful metrics, and for methodologies that ensure that we can dependably and efficiently measure these metrics at scale and in practice. In doing so, this dissertation articulates a research vision for a new field of scholarship at the intersection of machine learning, law, and policy. Within this frame, we cover topics that fit under three different themes: (1) quantifying and mitigating sources of arbitrariness in ML, (2) taming randomness in uncertainty estimation and optimization algorithms, in order to achieve scalability without sacrificing reliability, and (3) providing methods for evaluating generative-AI systems, with specific focuses on quantifying memorization in language models and training latent diffusion models on open-licensed data. By making contributions in these three themes, this dissertation serves as an empirical proof by example that research on reliable measurement for machine learning is intimately and inescapably bound up with research in law and policy. These different disciplines pose similar research questions about reliable measurement in machine learning. They are, in fact, two complementary sides of the same research vision, which, broadly construed, aims to construct machine-learning systems that cohere with broader societal values.
<div id='section'>Paperid: <span id='pid'>1853, <a href='https://arxiv.org/pdf/2405.05097.pdf' target='_blank'>https://arxiv.org/pdf/2405.05097.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jarek Duda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.05097">Biology-inspired joint distribution neurons based on Hierarchical Correlation Reconstruction allowing for multidirectional neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biological neural networks seem qualitatively superior (e.g. in learning, flexibility, robustness) to current artificial like Multi-Layer Perceptron (MLP) or Kolmogorov-Arnold Network (KAN). Simultaneously, in contrast to them: biological have fundamentally multidirectional signal propagation \cite{axon}, also of probability distributions e.g. for uncertainty estimation, and are believed not being able to use standard backpropagation training \cite{backprop}. There are proposed novel artificial neurons based on HCR (Hierarchical Correlation Reconstruction) allowing to remove the above low level differences: with neurons containing local joint distribution model (of its connections), representing joint density on normalized variables as just linear combination of $(f_\mathbf{j})$ orthonormal polynomials: $Ï(\mathbf{x})=\sum_{\mathbf{j}\in B} a_\mathbf{j} f_\mathbf{j}(\mathbf{x})$ for $\mathbf{x} \in [0,1]^d$ and $B\subset \mathbb{N}^d$ some chosen basis. By various index summations of such $(a_\mathbf{j})_{\mathbf{j}\in B}$ tensor as neuron parameters, we get simple formulas for e.g. conditional expected values for propagation in any direction, like $E[x|y,z]$, $E[y|x]$, which degenerate to KAN-like parametrization if restricting to pairwise dependencies. Such HCR network can also propagate probability distributions (also joint) like $Ï(y,z|x)$. It also allows for additional training approaches, like direct $(a_\mathbf{j})$ estimation, through tensor decomposition, or more biologically plausible information bottleneck training: layers directly influencing only neighbors, optimizing content to maximize information about the next layer, and minimizing about the previous to remove noise, extract crucial information.
<div id='section'>Paperid: <span id='pid'>1854, <a href='https://arxiv.org/pdf/2405.00631.pdf' target='_blank'>https://arxiv.org/pdf/2405.00631.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Assefa Seyoum Wahd
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00631">Deep Metric Learning-Based Out-of-Distribution Detection with Synthetic Outlier Exposure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a novel approach that combines deep metric learning and synthetic data generation using diffusion models for out-of-distribution (OOD) detection. One popular approach for OOD detection is outlier exposure, where models are trained using a mixture of in-distribution (ID) samples and ``seen" OOD samples. For the OOD samples, the model is trained to minimize the KL divergence between the output probability and the uniform distribution while correctly classifying the in-distribution (ID) data. In this paper, we propose a label-mixup approach to generate synthetic OOD data using Denoising Diffusion Probabilistic Models (DDPMs). Additionally, we explore recent advancements in metric learning to train our models.
  In the experiments, we found that metric learning-based loss functions perform better than the softmax. Furthermore, the baseline models (including softmax, and metric learning) show a significant improvement when trained with the generated OOD data. Our approach outperforms strong baselines in conventional OOD detection metrics.
<div id='section'>Paperid: <span id='pid'>1855, <a href='https://arxiv.org/pdf/2404.04498.pdf' target='_blank'>https://arxiv.org/pdf/2404.04498.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomoya Wakayama
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04498">Bayesian Inference for Consistent Predictions in Overparameterized Nonlinear Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The remarkable generalization performance of large-scale models has been challenging the conventional wisdom of the statistical learning theory. Although recent theoretical studies have shed light on this behavior in linear models and nonlinear classifiers, a comprehensive understanding of overparameterization in nonlinear regression models is still lacking. This study explores the predictive properties of overparameterized nonlinear regression within the Bayesian framework, extending the methodology of the adaptive prior considering the intrinsic spectral structure of the data. Posterior contraction is established for generalized linear and single-neuron models with Lipschitz continuous activation functions, demonstrating the consistency in the predictions of the proposed approach. Moreover, the Bayesian framework enables uncertainty estimation of the predictions. The proposed method was validated via numerical simulations and a real data application, showing its ability to achieve accurate predictions and reliable uncertainty estimates. This work provides a theoretical understanding of the advantages of overparameterization and a principled Bayesian approach to large nonlinear models.
<div id='section'>Paperid: <span id='pid'>1856, <a href='https://arxiv.org/pdf/2403.15361.pdf' target='_blank'>https://arxiv.org/pdf/2403.15361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoling Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15361">Learning Topological Representations for Deep Image Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many scenarios, especially biomedical applications, the correct delineation of complex fine-scaled structures such as neurons, tissues, and vessels is critical for downstream analysis. Despite the strong predictive power of deep learning methods, they do not provide a satisfactory representation of these structures, thus creating significant barriers in scalable annotation and downstream analysis. In this dissertation, we tackle such challenges by proposing novel representations of these topological structures in a deep learning framework. We leverage the mathematical tools from topological data analysis, i.e., persistent homology and discrete Morse theory, to develop principled methods for better segmentation and uncertainty estimation, which will become powerful tools for scalable annotation.
<div id='section'>Paperid: <span id='pid'>1857, <a href='https://arxiv.org/pdf/2403.14678.pdf' target='_blank'>https://arxiv.org/pdf/2403.14678.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Romeo Valentin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14678">Towards a Framework for Deep Learning Certification in Safety-Critical Applications Using Inherently Safe Design and Run-Time Error Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although an ever-growing number of applications employ deep learning based systems for prediction, decision-making, or state estimation, almost no certification processes have been established that would allow such systems to be deployed in safety-critical applications. In this work we consider real-world problems arising in aviation and other safety-critical areas, and investigate their requirements for a certified model. To this end, we investigate methodologies from the machine learning research community aimed towards verifying robustness and reliability of deep learning systems, and evaluate these methodologies with regard to their applicability to real-world problems. Then, we establish a new framework towards deep learning certification based on (i) inherently safe design, and (ii) run-time error detection. Using a concrete use case from aviation, we show how deep learning models can recover disentangled variables through the use of weakly-supervised representation learning. We argue that such a system design is inherently less prone to common model failures, and can be verified to encode underlying mechanisms governing the data. Then, we investigate four techniques related to the run-time safety of a model, namely (i) uncertainty quantification, (ii) out-of-distribution detection, (iii) feature collapse, and (iv) adversarial attacks. We evaluate each for their applicability and formulate a set of desiderata that a certified model should fulfill. Finally, we propose a novel model structure that exhibits all desired properties discussed in this work, and is able to make regression and uncertainty predictions, as well as detect out-of-distribution inputs, while requiring no regression labels to train. We conclude with a discussion of the current state and expected future progress of deep learning certification, and its industrial and social implications.
<div id='section'>Paperid: <span id='pid'>1858, <a href='https://arxiv.org/pdf/2403.08198.pdf' target='_blank'>https://arxiv.org/pdf/2403.08198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Dunn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08198">Validating and Exploring Large Geographic Corpora</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates the impact of corpus creation decisions on large multi-lingual geographic web corpora. Beginning with a 427 billion word corpus derived from the Common Crawl, three methods are used to improve the quality of sub-corpora representing specific language-country pairs like New Zealand English: (i) the agreement of independent language identification systems, (ii) hash-based deduplication, and (iii) location-specific outlier detection. The impact of each of these steps is then evaluated at the language level and the country level by using corpus similarity measures to compare each resulting corpus with baseline data sets. The goal is to understand the impact of upstream data cleaning decisions on downstream corpora with a specific focus on under-represented languages and populations. The evaluation shows that the validity of sub-corpora is improved with each stage of cleaning but that this improvement is unevenly distributed across languages and populations. This result shows how standard corpus creation techniques can accidentally exclude under-represented populations.
<div id='section'>Paperid: <span id='pid'>1859, <a href='https://arxiv.org/pdf/2402.12307.pdf' target='_blank'>https://arxiv.org/pdf/2402.12307.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Enrique Garcia-Ceja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12307">Multi-View Conformal Learning for Heterogeneous Sensor Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Being able to assess the confidence of individual predictions in machine learning models is crucial for decision making scenarios. Specially, in critical applications such as medical diagnosis, security, and unmanned vehicles, to name a few. In the last years, complex predictive models have had great success in solving hard tasks and new methods are being proposed every day. While the majority of new developments in machine learning models focus on improving the overall performance, less effort is put on assessing the trustworthiness of individual predictions, and even to a lesser extent, in the context of sensor fusion. To this end, we build and test multi-view and single-view conformal models for heterogeneous sensor fusion. Our models provide theoretical marginal confidence guarantees since they are based on the conformal prediction framework. We also propose a multi-view semi-conformal model based on sets intersection. Through comprehensive experimentation, we show that multi-view models perform better than single-view models not only in terms of accuracy-based performance metrics (as it has already been shown in several previous works) but also in conformal measures that provide uncertainty estimation. Our results also showed that multi-view models generate prediction sets with less uncertainty compared to single-view models.
<div id='section'>Paperid: <span id='pid'>1860, <a href='https://arxiv.org/pdf/2401.07145.pdf' target='_blank'>https://arxiv.org/pdf/2401.07145.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soyed Tuhin Ahmed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.07145">Scalable and Efficient Methods for Uncertainty Estimation and Reduction in Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks (NNs) can achieved high performance in various fields such as computer vision, and natural language processing. However, deploying NNs in resource-constrained safety-critical systems has challenges due to uncertainty in the prediction caused by out-of-distribution data, and hardware non-idealities. To address the challenges of deploying NNs in resource-constrained safety-critical systems, this paper summarizes the (4th year) PhD thesis work that explores scalable and efficient methods for uncertainty estimation and reduction in deep learning, with a focus on Computation-in-Memory (CIM) using emerging resistive non-volatile memories. We tackle the inherent uncertainties arising from out-of-distribution inputs and hardware non-idealities, crucial in maintaining functional safety in automated decision-making systems. Our approach encompasses problem-aware training algorithms, novel NN topologies, and hardware co-design solutions, including dropout-based \emph{binary} Bayesian Neural Networks leveraging spintronic devices and variational inference techniques. These innovations significantly enhance OOD data detection, inference accuracy, and energy efficiency, thereby contributing to the reliability and robustness of NN implementations.
<div id='section'>Paperid: <span id='pid'>1861, <a href='https://arxiv.org/pdf/2310.15281.pdf' target='_blank'>https://arxiv.org/pdf/2310.15281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ilia Azizi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.15281">UncertaintyPlayground: A Fast and Simplified Python Library for Uncertainty Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces UncertaintyPlayground, a Python library built on PyTorch and GPyTorch for uncertainty estimation in supervised learning tasks. The library offers fast training for Gaussian and multi-modal outcome distributions through Sparse and Variational Gaussian Process Regressions (SVGPRs) for normally distributed outcomes and Mixed Density Networks (MDN) for mixed distributions. In addition to model training with various hyperparameters, UncertaintyPlayground can visualize the prediction intervals of one or more instances. Due to using tensor operations, the library can be trained both on CPU and GPU and offers various PyTorch-specific techniques for speed optimization. The library contains unit tests for each module and ensures multi-platform continuous integration with GitHub Workflows (online integration) and Tox (local integration). Finally, the code is documented with Google-style docstrings and offers a documentation website created with MkDocs and MkDocStrings.
<div id='section'>Paperid: <span id='pid'>1862, <a href='https://arxiv.org/pdf/2310.08176.pdf' target='_blank'>https://arxiv.org/pdf/2310.08176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunus Cobanoglu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08176">Infinite Width Graph Neural Networks for Node Regression/ Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work analyzes Graph Neural Networks, a generalization of Fully-Connected Deep Neural Nets on Graph structured data, when their width, that is the number of nodes in each fullyconnected layer is increasing to infinity. Infinite Width Neural Networks are connecting Deep Learning to Gaussian Processes and Kernels, both Machine Learning Frameworks with long traditions and extensive theoretical foundations. Gaussian Processes and Kernels have much less hyperparameters then Neural Networks and can be used for uncertainty estimation, making them more user friendly for applications. This works extends the increasing amount of research connecting Gaussian Processes and Kernels to Neural Networks. The Kernel and Gaussian Process closed forms are derived for a variety of architectures, namely the standard Graph Neural Network, the Graph Neural Network with Skip-Concatenate Connections and the Graph Attention Neural Network. All architectures are evaluated on a variety of datasets on the task of transductive Node Regression and Classification. Additionally, a Spectral Sparsification method known as Effective Resistance is used to improve runtime and memory requirements. Extending the setting to inductive graph learning tasks (Graph Regression/ Classification) is straightforward and is briefly discussed in 3.5.
<div id='section'>Paperid: <span id='pid'>1863, <a href='https://arxiv.org/pdf/2309.02332.pdf' target='_blank'>https://arxiv.org/pdf/2309.02332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin N. P. Nilsson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02332">Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the intricate architecture of the mammalian central nervous system, neurons form populations. Axonal bundles communicate between these clusters using spike trains. However, these neuron populations' precise encoding and operations have yet to be discovered. In our analysis, the starting point is a state-of-the-art mechanistic model of a generic neuron endowed with plasticity. From this simple framework emerges a subtle mathematical construct: The representation and manipulation of information can be precisely characterized by an algebra of convex cones. Furthermore, these neuron populations are not merely passive transmitters. They act as operators within this algebraic structure, mirroring the functionality of a low-level programming language. When these populations interconnect, they embody succinct yet potent algebraic expressions. These networks allow them to implement many operations, such as specialization, generalization, novelty detection, dimensionality reduction, inverse modeling, prediction, and associative memory. In broader terms, this work illuminates the potential of matrix embeddings in advancing our understanding in fields like cognitive science and AI. These embeddings enhance the capacity for concept processing and hierarchical description over their vector counterparts.
<div id='section'>Paperid: <span id='pid'>1864, <a href='https://arxiv.org/pdf/2308.13778.pdf' target='_blank'>https://arxiv.org/pdf/2308.13778.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Gepperth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.13778">Large-scale gradient-based training of Mixtures of Factor Analyzers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gaussian Mixture Models (GMMs) are a standard tool in data analysis. However, they face problems when applied to high-dimensional data (e.g., images) due to the size of the required full covariance matrices (CMs), whereas the use of diagonal or spherical CMs often imposes restrictions that are too severe. The Mixture of Factor analyzers (MFA) model is an important extension of GMMs, which allows to smoothly interpolate between diagonal and full CMs based on the number of \textit{factor loadings} $l$. MFA has successfully been applied for modeling high-dimensional image data. This article contributes both a theoretical analysis as well as a new method for efficient high-dimensional MFA training by stochastic gradient descent, starting from random centroid initializations. This greatly simplifies the training and initialization process, and avoids problems of batch-type algorithms such Expectation-Maximization (EM) when training with huge amounts of data. In addition, by exploiting the properties of the matrix determinant lemma, we prove that MFA training and inference/sampling can be performed based on precision matrices, which does not require matrix inversions after training is completed. At training time, the methods requires the inversion of $l\times l$ matrices only. Besides the theoretical analysis and proofs, we apply MFA to typical image datasets such as SVHN and MNIST, and demonstrate the ability to perform sample generation and outlier detection.
<div id='section'>Paperid: <span id='pid'>1865, <a href='https://arxiv.org/pdf/2308.02652.pdf' target='_blank'>https://arxiv.org/pdf/2308.02652.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ullrich KÃ¶the
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02652">A Review of Change of Variable Formulas for Generative Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Change-of-variables (CoV) formulas allow to reduce complicated probability densities to simpler ones by a learned transformation with tractable Jacobian determinant. They are thus powerful tools for maximum-likelihood learning, Bayesian inference, outlier detection, model selection, etc. CoV formulas have been derived for a large variety of model types, but this information is scattered over many separate works. We present a systematic treatment from the unifying perspective of encoder/decoder architectures, which collects 28 CoV formulas in a single place, reveals interesting relationships between seemingly diverse methods, emphasizes important distinctions that are not always clear in the literature, and identifies surprising gaps for future research.
<div id='section'>Paperid: <span id='pid'>1866, <a href='https://arxiv.org/pdf/2308.01222.pdf' target='_blank'>https://arxiv.org/pdf/2308.01222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.01222">Calibration in Deep Learning: A Survey of the State-of-the-Art</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications. Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions. Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively under-explored. Ideal deep models should have not only high predictive performance but also be well calibrated. There have been some recent advances in calibrating deep models. In this survey, we review the state-of-the-art calibration methods and their principles for performing model calibration. First, we start with the definition of model calibration and explain the root causes of model miscalibration. Then we introduce the key metrics that can measure this aspect. It is followed by a summary of calibration methods that we roughly classify into four categories: post-hoc calibration, regularization methods, uncertainty estimation, and composition methods. We also cover recent advancements in calibrating large models, particularly large language models (LLMs). Finally, we discuss some open issues, challenges, and potential directions.
<div id='section'>Paperid: <span id='pid'>1867, <a href='https://arxiv.org/pdf/2306.07056.pdf' target='_blank'>https://arxiv.org/pdf/2306.07056.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akira Tamamori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.07056">Kernel Random Projection Depth for Outlier Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
<div id='section'>Paperid: <span id='pid'>1868, <a href='https://arxiv.org/pdf/2306.02143.pdf' target='_blank'>https://arxiv.org/pdf/2306.02143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Faezeh Fallah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02143">Hierarchical Multiresolution Feature- and Prior-based Graphs for Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To incorporate spatial (neighborhood) and bidirectional hierarchical relationships as well as features and priors of the samples into their classification, we formulated the classification problem on three variants of multiresolution neighborhood graphs and the graph of a hierarchical conditional random field. Each of these graphs was weighted and undirected and could thus incorporate the spatial or hierarchical relationships in all directions. In addition, each variant of the proposed neighborhood graphs was composed of a spatial feature-based subgraph and an aspatial prior-based subgraph. It expanded on a random walker graph by using novel mechanisms to derive the edge weights of its spatial feature-based subgraph. These mechanisms included implicit and explicit edge detection to enhance detection of weak boundaries between different classes in spatial domain. The implicit edge detection relied on the outlier detection capability of the Tukey's function and the classification reliabilities of the samples estimated by a hierarchical random forest classifier. Similar mechanism was used to derive the edge weights and thus the energy function of the hierarchical conditional random field. This way, the classification problem boiled down to a system of linear equations and a minimization of the energy function which could be done via fast and efficient techniques.
<div id='section'>Paperid: <span id='pid'>1869, <a href='https://arxiv.org/pdf/2305.01720.pdf' target='_blank'>https://arxiv.org/pdf/2305.01720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lior Shamir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.01720">Outlier galaxy images in the Dark Energy Survey and their identification with unsupervised machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Dark Energy Survey is able to collect image data of an extremely large number of extragalactic objects, and it can be reasonably assumed that many unusual objects of high scientific interest are hidden inside these data. Due to the extreme size of DES data, identifying these objects among many millions of other celestial objects is a challenging task. The problem of outlier detection is further magnified by the presence of noisy or saturated images. When the number of tested objects is extremely high, even a small rate of noise or false positives leads to a very large number of false detections, making an automatic system impractical. This study applies an automatic method for automatic detection of outlier objects in the first data release of the Dark Energy Survey. By using machine learning-based outlier detection, the algorithm is able to identify objects that are visually different from the majority of the other objects in the database. An important feature of the algorithm is that it allows to control the false-positive rate, and therefore can be used for practical outlier detection. The algorithm does not provide perfect accuracy in the detection of outlier objects, but it reduces the data substantially to allow practical outlier detection. For instance, the selection of the top 250 objects after applying the algorithm to more than $2\cdot10^6$ DES images provides a collection of uncommon galaxies. Such collection would have been extremely time-consuming to compile by using manual inspection of the data.
<div id='section'>Paperid: <span id='pid'>1870, <a href='https://arxiv.org/pdf/2304.08334.pdf' target='_blank'>https://arxiv.org/pdf/2304.08334.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steve Huntsman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.08334">Magnitude of arithmetic scalar and matrix categories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop tools for explicitly constructing categories enriched over generating data and that compose via ordinary scalar and matrix arithmetic arithmetic operations. We characterize meaningful size maps, weightings, and magnitude that reveal features analogous to outliers that these same notions have previously been shown to reveal in the context of metric spaces. Throughout, we provide examples of such "outlier detection" relevant to the analysis of computer programs, neural networks, cyber-physical systems, and networks of communications channels.
<div id='section'>Paperid: <span id='pid'>1871, <a href='https://arxiv.org/pdf/2303.10800.pdf' target='_blank'>https://arxiv.org/pdf/2303.10800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nathan Inkawhich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10800">A Global Model Approach to Robust Few-Shot SAR Automatic Target Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world scenarios, it may not always be possible to collect hundreds of labeled samples per class for training deep learning-based SAR Automatic Target Recognition (ATR) models. This work specifically tackles the few-shot SAR ATR problem, where only a handful of labeled samples may be available to support the task of interest. Our approach is composed of two stages. In the first, a global representation model is trained via self-supervised learning on a large pool of diverse and unlabeled SAR data. In the second stage, the global model is used as a fixed feature extractor and a classifier is trained to partition the feature space given the few-shot support samples, while simultaneously being calibrated to detect anomalous inputs. Unlike competing approaches which require a pristine labeled dataset for pretraining via meta-learning, our approach learns highly transferable features from unlabeled data that have little-to-no relation to the downstream task. We evaluate our method in standard and extended MSTAR operating conditions and find it to achieve high accuracy and robust out-of-distribution detection in many different few-shot settings. Our results are particularly significant because they show the merit of a global model approach to SAR ATR, which makes minimal assumptions, and provides many axes for extendability.
<div id='section'>Paperid: <span id='pid'>1872, <a href='https://arxiv.org/pdf/2303.03887.pdf' target='_blank'>https://arxiv.org/pdf/2303.03887.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weili Zeng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03887">How to Construct Energy for Images? Denoising Autoencoder Can Be Energy Based Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Energy-based models parameterize the unnormalized log-probability of data samples, but there is a lack of guidance on how to construct the "energy". In this paper, we propose a Denoising-EBM which decomposes the image energy into "semantic energy" and "texture energy". We define the "semantic energy" in the latent space of DAE to model the high-level representations, and define the pixel-level reconstruction error for denoising as "texture energy". Inspired by score-based model, our model utilizes multi-scale noisy samples for maximum-likelihood training and it outputs a vector instead of a scalar for exploring a larger set of functions during optimization. After training, the semantics are first synthesized by fast MCMC through "semantic energy", and then the pixel-level refinement of semantic image will be performed to generate perfect samples based on "texture energy". Ultimately, our model can outperform most EBMs in image generation. And we also demonstrate that Denoising-EBM has top performance among EBMs for out-of-distribution detection.
<div id='section'>Paperid: <span id='pid'>1873, <a href='https://arxiv.org/pdf/2302.12002.pdf' target='_blank'>https://arxiv.org/pdf/2302.12002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sven Elflein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12002">Master's Thesis: Out-of-distribution Detection with Energy-based Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Today, deep learning is increasingly applied in security-critical situations such as autonomous driving and medical diagnosis. Despite its success, the behavior and robustness of deep networks are not fully understood yet, posing a significant risk. In particular, researchers recently found that neural networks are overly confident in their predictions, even on data they have never seen before. To tackle this issue, one can differentiate two approaches in the literature. One accounts for uncertainty in the predictions, while the second estimates the underlying density of the training data to decide whether a given input is close to the training data, and thus the network is able to perform as expected.In this thesis, we investigate the capabilities of EBMs at the task of fitting the training data distribution to perform detection of out-of-distribution (OOD) inputs. We find that on most datasets, EBMs do not inherently outperform other density estimators at detecting OOD data despite their flexibility. Thus, we additionally investigate the effects of supervision, dimensionality reduction, and architectural modifications on the performance of EBMs. Further, we propose Energy-Prior Network (EPN) which enables estimation of various uncertainties within an EBM for classification, bridging the gap between two approaches for tackling the OOD detection problem. We identify a connection between the concentration parameters of the Dirichlet distribution and the joint energy in an EBM. Additionally, this allows optimization without a held-out OOD dataset, which might not be available or costly to collect in some applications. Finally, we empirically demonstrate that Energy-Prior Network (EPN) is able to detect OOD inputs, datasets shifts, and adversarial examples. Theoretically, EPN offers favorable properties for the asymptotic case when inputs are far from the training data.
<div id='section'>Paperid: <span id='pid'>1874, <a href='https://arxiv.org/pdf/2210.13441.pdf' target='_blank'>https://arxiv.org/pdf/2210.13441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taoli Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.13441">Bridging Machine Learning and Sciences: Opportunities and Challenges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The application of machine learning in sciences has seen exciting advances in recent years. As a widely applicable technique, anomaly detection has been long studied in the machine learning community. Especially, deep neural nets-based out-of-distribution detection has made great progress for high-dimensional data. Recently, these techniques have been showing their potential in scientific disciplines. We take a critical look at their applicative prospects including data universality, experimental protocols, model robustness, etc. We discuss examples that display transferable practices and domain-specific challenges simultaneously, providing a starting point for establishing a novel interdisciplinary research paradigm in the near future.
<div id='section'>Paperid: <span id='pid'>1875, <a href='https://arxiv.org/pdf/2203.02194.pdf' target='_blank'>https://arxiv.org/pdf/2203.02194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yibo Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.02194">Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In some scenarios, classifier requires detecting out-of-distribution samples far from its training data. With desirable characteristics, reconstruction autoencoder-based methods deal with this problem by using input reconstruction error as a metric of novelty vs. normality. We formulate the essence of such approach as a quadruplet domain translation with an intrinsic bias to only query for a proxy of conditional data uncertainty. Accordingly, an improvement direction is formalized as maximumly compressing the autoencoder's latent space while ensuring its reconstructive power for acting as a described domain translator. From it, strategies are introduced including semantic reconstruction, data certainty decomposition and normalized L2 distance to substantially improve original methods, which together establish state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method works without any additional data, hard-to-implement structure, time-consuming pipeline, and even harming the classification accuracy of known classes.
